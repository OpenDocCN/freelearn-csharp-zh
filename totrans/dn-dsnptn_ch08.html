<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="z3998: http://www.daisy.org/z3998/2012/vocab/structure/#" lang="en" xml:lang="en">
<head>
    <title>8. Concurrent and Parallel Programming under .NET</title>
    <link href="epub.css" rel="stylesheet" type="text/css"/>
    <link href="68851547a55f.css" rel="stylesheet" type="text/css"/>
  </head>
  <body>
    <div id="sbo-rt-content">
      <div class="chapter" title="Chapter&#160;8.&#160;Concurrent and Parallel Programming under .NET">
        <div class="titlepage">
          <div>
            <div>
              <h1 class="title"><a id="ch08"></a>Chapter&#160;8.&#160;Concurrent and Parallel Programming under .NET</h1>
            </div>
          </div>
        </div>
        <p>So far, we have been mostly focusing on the GoF design patterns. When the catalog appeared, the computing world was mostly sequential, and the bias was reflected in the catalog. The world has changed a lot since the publication of the catalog in 1994. There was a shift towards language-level concurrency and parallelism due to the arrival of the Java and C# programming languages. The processor designers understood the limits of constructing powerful single-core CPUs, and began focusing on many core CPUs. This brought its own set of complexity in developing software using the existing paradigms. Even a language like C++, which relegated concurrency to libraries, added language-level concurrency features in its latest avatar, C++ 11/14. With the advent of functional programming features into the OOP world, the programming landscape changed drastically. In this chapter, you will learn some techniques for writing concurrent and parallel programs using the C# programming language and .NET platform features. In this chapter, we will cover the following points:</p>
        <div class="itemizedlist">
          <ul class="itemizedlist">
            <li class="listitem" style="list-style-type: disc">Factors that influenced evolution of concurrency and parallelization models</li>
            <li class="listitem" style="list-style-type: disc">Concurrency versus Parallelism</li>
            <li class="listitem" style="list-style-type: disc">.NET Parallel Programming libraries</li>
            <li class="listitem" style="list-style-type: disc">Some Parallel/Concurrent memes/idioms
<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Embarrassingly parallel</li>
<li class="listitem" style="list-style-type: disc">Fork/join parallelism</li>
<li class="listitem" style="list-style-type: disc">Producer/consumer paradigm</li>
</ul>
</div></li>
          </ul>
        </div>
        <div class="section" title="Days of Free Lunch">
          <div class="titlepage">
            <div>
              <div>
                <h1 class="title"><a id="ch08lvl1sec60"></a>Days of Free Lunch</h1>
              </div>
            </div>
          </div>
          <p>The celebrated Moore's law went on despite microprocessors hitting the clock-speed limits in terms of heat dissipation and achieving fabrications beyond nano-level. CPU designers found an intelligent workaround for this roadblock-that of leveraging the increased chip densities to scale the computation infrastructure horizontally as opposed to the traditional vertical way. This principle has deep consequences in modern day architecture and design, where application scalability (both vertical and horizontal) inherits natural elasticity with respect to the infrastructure that powers them. What resulted was a new generation of CPU architectures including hyper-threading, multi-core, and many-core. It wasn't too late before the developers realized that the <span class="strong"><strong>Free Lunch</strong></span> (just leveraging the conventional CPU performance gains through clock speed, execution optimization, and cache, with no change in their programs) was over. Herb Sutter wrote an influential article in Dr. Dobb's Journal about this, aptly titled, <span class="emphasis"><em>The Free Lunch Is Over: A Fundamental Turn toward Concurrency in Software</em></span>!</p>
          <div class="note" title="Note" style="">
            <div class="inner">
              <h3 class="title"><a id="note29"></a>Note</h3>
              <p>This realization that software was the gating factor in terms of achieving more with most of what was available was the dawn of a new revolution in software architecture and design.</p>
            </div>
          </div>
          <p>This new model helped remove many shortcomings in modeling real-world problem scenarios. It seemed though that we (developers) began adding justice to the grand concurrent design that went into modelling this world with interactions to be parallel as opposed to just being sequential and object-oriented. The prevalent parallelization techniques (leveraged mostly by the scientific community for doing embarrassingly parallel computations)-that of explicit threading with an affinity to hardware threads-was primitive and less scalable. Very few people had expertise (or rather felt comfortable) in working with the low-level constructs for leveraging multi-threading in their applications. This state of affairs brought in a strong imperative for creating better abstractions and the needed APIs to write the next generation software that would inherently leverage concurrency and parallelism to achieve more with most of what was available.</p>
        </div>
      </div>
    </div>


    <div id="sbo-rt-content">
      <div class="section" title="Days of Sponsored Lunch">
        <div class="titlepage">
          <div>
            <div>
              <h1 class="title"><a id="ch08lvl1sec61"></a>Days of Sponsored Lunch</h1>
            </div>
          </div>
        </div>
        <p>Microsoft's .Net <span class="strong"><strong>Common Language Runtime</strong></span> (<span class="strong"><strong>CLR</strong></span>) came to the rescue with the managed thread pool (which stabilized around version 2.0), which paved the way for a strong foundation layer on top of which the concurrency and parallelization models subsequently evolved.</p>
        <div class="note" title="Note" style="">
          <div class="inner">
            <h3 class="title"><a id="note30"></a>Note</h3>
            <p>The most notable ones include <span class="strong"><strong>Asynchronous Programming Model</strong></span> (<span class="strong"><strong>APM</strong></span>), <span class="strong"><strong>Concurrency and Coordination Runtime</strong></span> (<span class="strong"><strong>CCR</strong></span>), <span class="strong"><strong>Decentralized Software Services</strong></span> (<span class="strong"><strong>DSS</strong></span>), <span class="strong"><strong>Parallel LINQ</strong></span> (<span class="strong"><strong>PLINQ</strong></span>), <span class="strong"><strong>Task Parallel Library</strong></span> (<span class="strong"><strong>TPL</strong></span>), and the Task-based Async/Await model.</p>
          </div>
        </div>
        <p>Certain functional constructs and language features like Anonymous Methods, Lambda Expressions, Extension Methods, Anonymous Types, and <span class="strong"><strong>Language Integrated Query</strong></span> (<span class="strong"><strong>LINQ</strong></span>) were the core catalysts that aided this evolution. Major contributors and SMEs include Erik Meijer for LINQ, Joe Duffy and Jon Skeet for Multithreading in .NET), Stephen Toub, Ade Miller, Colin Campbell, and Ralph Johnson for Parallel Extensions, and Jeffrey Richter and George Chrysanthakopoulos for CCR.</p>
        <p>Of the aforementioned notable models, the major ones that matured and are advocated today are the following:</p>
        <div class="itemizedlist">
          <ul class="itemizedlist">
            <li class="listitem" style="list-style-type: disc">Task-based async/await model for concurrency</li>
            <li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Parallel Extensions</strong></span> (<span class="strong"><strong>PFX</strong></span>) including PLINQ and TPL for parallelization</li>
          </ul>
        </div>
        <p>
</p>
        <div class="mediaobject">
          <img src="graphics/B05691_08_01.jpg" alt="Days of Sponsored Lunch"/>
        </div>
        <p>
</p>
      </div>
    </div>


    <div id="sbo-rt-content">
      <div class="section" title="Concurrent versus parallel">
        <div class="titlepage">
          <div>
            <div>
              <h1 class="title"><a id="ch08lvl1sec62"></a>Concurrent versus parallel</h1>
            </div>
          </div>
        </div>
        <p>These are two key constructs are often confused by developers, and warrant clear demystification. The authors strongly feel that a thorough understanding of this distinction holds the key to effective software design for achieving more by effective utilization of the available infrastructure (processors, cores, hardware, and software threads). Let's start with the classical definition by Rob Pike (inventor of the Go programming language), and try to decode its meaning.
</p>
        <div class="blockquote">
          <table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote">
            <tbody><tr>
              <td valign="top">&#160;</td>
              <td valign="top">
                <p>
<span class="emphasis"><em>Parallelization is doing multiple tasks (related or non-related) at the same time whereas concurrency is about dealing with lots of things at once.
Concurrency is about structure; parallelism is about execution.
Concurrency provides a way to structure a solution to solve a problem that may (but not necessarily) be parallelizable.</em></span>
</p>
              </td>
              <td valign="top">&#160;</td>
            </tr>
            <tr>
              <td valign="top">&#160;</td>
              <td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>Rob Pike</em></span></span></td>
            </tr>
          </tbody>
</table>
        </div>
        <p>This clearly articulates the difference between these constructs, and goes further to illustrate how concurrency, as a model, helps to structure a program by breaking it into pieces that can be executed independently. This powerful consequence of a concurrent design model facilitates parallelism depending on the hardware support available for the program's runtime or compiler infrastructure.</p>
        <div class="note" title="Note" style="">
          <div class="inner">
            <h3 class="title"><a id="note31"></a>Note</h3>
            <p>This further means <span class="strong"><strong>write-once</strong></span>, <span class="strong"><strong>run-anywhere</strong></span>.</p>
          </div>
        </div>
        <p>The days of Free Lunch are back with this model, where a concurrent program can perform better on multiple cores by leveraging parallelization techniques (mostly abstracted or under the hood, and is dependent on the framework library or runtime that executes these programs). This could be understood very clearly as the way an asynchronous programming model works using <code class="literal">async</code> and <code class="literal">await</code>. This model helps to structure the program by breaking it into pieces that can be executed independently. These independent pieces become <span class="strong"><strong>tasks</strong></span> (part of the TPL), and are executed simultaneously, leveraging the available hardware (cores and threads). Now you see how parallelism becomes an interesting side-effect of a concurrent model. This is managed (in terms of the degree of parallelism that determines the number of cores to be leveraged for reducing contention) by the TPL API and CLR. So, the developer can focus on the core decomposition (with little or no shared state) of the process into independent tasks as opposed to getting entangled in the low-level constructs (threads and synchronization) for realizing concurrency and parallelization. The APIs have evolved quite intelligently to support this, thus making the code-base quite expressive, declarative, and readable.</p>
        <p>On the contrary, if you explicitly try to leverage basic naive parallelism (<code class="literal">Parallel.For</code> and PLINQ) for executing the decomposed tasks, there is a good chance you would end up blocking your threads, thus curtailing scalability and availability (especially for server-side programs).</p>
        <div class="blockquote">
          <table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote">
            <tbody><tr>
              <td valign="top">&#160;</td>
              <td valign="top">
                <p>
<span class="emphasis"><em>Don't Block your threads, Make Async I/O work for you</em></span>
</p>
              </td>
              <td valign="top">&#160;</td>
            </tr>
            <tr>
              <td valign="top">&#160;</td>
              <td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>Stephen Toub/Scott Hanselman</em></span></span></td>
            </tr>
          </tbody>
</table>
        </div>
        <p>This is the founding principle on which concurrent programming models work. The classic example is Node.js, which has gained prominence as a middleware and backend system with its inherent support for async I/O. Again, one needs to understand that the benefits are seen more in I/O and asynchronous service executions as opposed to long-running CPU-bound tasks (which wouldn't give you the benefit you typically desire, as these tend to block, and, in turn, cause thread starvation). This is a classic scenario, where developers complain that their program takes more time to execute (compared to the serial implementation) when task parallelism is employed with <code class="literal">Parallel.For</code> loops.</p>
        <p>Again, none of these imply that one shouldn't employ high-and low-level constructs for task creation, threading, and parallelism. As long as scalability and availability is not a high priority, task parallelism, with appropriate partitioning strategies, could be very effectively employed. This is because these libraries effectively load balance the work across the CLR threads to minimize contention, and maximize throughput through work stealing.</p>
        <p>The consequence of both these models is something to be kept in mind when designing effective algorithms that can leverage the best of what you have, and yet, scale. We will try to illustrate these in the coming sections.</p>
      </div>
    </div>


    <div id="sbo-rt-content">
      <div class="section" title="Some common patterns of parallel programming">
        <div class="titlepage">
          <div>
            <div>
              <h1 class="title"><a id="ch08lvl1sec63"></a>Some common patterns of parallel programming</h1>
            </div>
          </div>
        </div>
        <p>Now that we understand the power that these two models bring, one needs to be wary of the responsibility that this power brings forth. Typical abuse of concurrency and parallelism in the form of blanket code refactoring are often found counterproductive. Patterns become more pertinent in this paradigm, where developers push the limits of computing hardware.</p>
        <div class="blockquote">
          <table border="0" width="100%" cellspacing="0" cellpadding="0" class="blockquote" summary="Block quote">
            <tbody><tr>
              <td valign="top">&#160;</td>
              <td valign="top">
                <p>
<span class="emphasis"><em>Issues of races, deadlocks, livelocks, priority inversions, two-step dances, and lock convoys typically have no place in a sequential world, and avoiding such issues makes quality patterns all the more important</em></span>
</p>
              </td>
              <td valign="top">&#160;</td>
            </tr>
            <tr>
              <td valign="top">&#160;</td>
              <td colspan="2" align="right" valign="top" style="text-align: center">--<span class="attribution"><span class="emphasis"><em>Stephen Toub</em></span></span></td>
            </tr>
          </tbody>
</table>
        </div>
        <p>The authors wish to put in perspective the modelling/decomposition aspects of the problem, and illustrate the applicability of some of the key patterns, data structures, and synchronization constructs to these so as to aid the programmer to leverage concurrency and parallelism to its full potential. For detailed coverage in terms of patterns and primitive constructs, the authors strongly recommend developers to read <span class="emphasis"><em>Patterns of Parallel Programming</em></span> by Stephen Toub and <span class="emphasis"><em>Concurrent Programming on Windows</em></span> by Joe Duffy.</p>
        <div class="section" title="Embarrassingly or conveniently parallel">
          <div class="titlepage">
            <div>
              <div>
                <h2 class="title"><a id="ch08lvl2sec33"></a>Embarrassingly or conveniently parallel</h2>
              </div>
            </div>
          </div>
          <p>This is the foremost pattern we would cover. The candidate programs that can leverage these are ones that can be easily decomposed into tasks/operations which have little or no dependency. This independence makes parallel execution of these tasks/operations very convenient. We will stray a bit from the conventional examples (that of a ray tracer and matrix multiplication), plus instill a sense of adventure and accomplishment in creating an algorithm, which, in turn, is embarrassingly parallel in nature.</p>
          <div class="note" title="Note" style="">
            <div class="inner">
              <h3 class="title"><a id="tip32"></a>Tip</h3>
              <p>We would be articulating this pattern by creating a C# implementation of the <span class="emphasis"><em>Schönhage-Strassen</em></span> algorithm for rapidly multiplying large integers.</p>
            </div>
          </div>
          <div class="section" title="Problem statement">
            <div class="titlepage">
              <div>
                <div>
                  <h3 class="title"><a id="ch08lvl3sec7"></a>Problem statement</h3>
                </div>
              </div>
            </div>
            <p>As indicated, the problem statement seems straightforward in terms of having an ability to multiply large numbers (let's push ourselves a bit by further stating astronomically large numbers), which cannot even be represented (64-bit computing limit). We have consciously reduced the scope by restricting ourselves to just one operation (multiplication) for outlining the pattern. Nothing prevents any interested reader who is game to go ahead and implement other operations thereby devising their own <code class="literal">BigInteger</code> version with support for all mathematical operations.
</p>
          </div>
          <div class="section" title="Solutions approach">
            <div class="titlepage">
              <div>
                <div>
                  <h3 class="title"><a id="ch08lvl3sec8"></a>Solutions approach</h3>
                </div>
              </div>
            </div>
            <p>Let's start by outlining the algorithm to multiply two three-digit sequences (<span class="strong"><strong>456</strong></span> and <span class="strong"><strong>789</strong></span>):</p>
            <p>
</p>
            <div class="mediaobject">
              <img src="graphics/B05691_08_02.jpg" alt="Solutions approach"/>
            </div>
            <p>
</p>
            <p>The Schönhage-Strassen algorithm depends fundamentally on the convolution theorem, which provides an efficient way to compute the cyclic convolution of two sequences.</p>
            <div class="note" title="Note" style="">
              <div class="inner">
                <h3 class="title"><a id="tip33"></a>Tip</h3>
                <p>The authors wish to take a disclaimer here: the cyclic convolution computation is not done in the most efficient way here. The prescribed steps include that of taking the <span class="strong"><strong>Discrete Fourier Transform</strong></span> (<span class="strong"><strong>DFT</strong></span>) of each sequence, multiplying the resulting vectors element by element, and then taking the <span class="strong"><strong>Inverse Discrete Fourier Transform</strong></span> (<span class="strong"><strong>IDFT</strong></span>). In contrast to this, we adopt a naïve and computationally intensive algorithmic way. This results in a runtime bit complexity of O(n<sup>2</sup>) in Big-O notation for two <span class="emphasis"><em>n</em></span> digit numbers. The core idea here is to demonstrate the intrinsic parallel nature of the algorithm!</p>
              </div>
            </div>
            <p>As illustrated, the algorithm to compute the product of two three-digit sequences comprises of three major steps. We will look at&#160;the problem decomposition in detail, and interlude the steps with code to see this pattern in action, leveraging some of the core .NET parallelization constructs (specifically, the <code class="literal">For</code> method of the <code class="literal">Parallel</code> class in TPL-<code class="literal">Parallel.For</code>). In this process, you will understand how task decomposition is done effectively, taking into consideration the algorithmic and structural aspects of your application.</p>
            <div class="section" title="Step 1">
              <div class="titlepage">
                <div>
                  <div>
                    <h4 class="title"><a id="ch08lvl4sec0"></a>Step 1</h4>
                  </div>
                </div>
              </div>
              <p>We will start off multiplying the two numbers 456 (sequence-1) and 789 (sequence-2) using long multiplication with base 10 digits, without performing any carrying. The multiplication involves three further sub-steps as illustrated.</p>
              <p>
<span class="strong"><strong>Step 1.1</strong></span>
</p>
              <p>As part of the long multiplication, we multiply the least significant digit (9) from sequence-2 with all the digits of sequence-1, producing a sequence 36, 45, and 54.</p>
              <p>
<span class="strong"><strong>Step 1.2</strong></span>
</p>
              <p>We multiply the next least significant digit (8) from sequence-2 with all the digits of sequence-1, producing a sequence 32, 40, and 48.</p>
              <p>
<span class="strong"><strong>Step 1.3</strong></span>
</p>
              <p>Finally, we multiply the most significant digit (7) from sequence-2 with all the digits of sequence-1, producing a sequence 28, 35, and 42.</p>
            </div>
            <div class="section" title="Step 2">
              <div class="titlepage">
                <div>
                  <div>
                    <h4 class="title"><a id="ch08lvl4sec1"></a>Step 2</h4>
                  </div>
                </div>
              </div>
              <p>Add the respective column elements (again without carrying) to obtain the acyclic/linear convolution sequence (28, 67, 118, 93, 54) of sequence 1 and 2.</p>
            </div>
            <div class="section" title="Step 3">
              <div class="titlepage">
                <div>
                  <div>
                    <h4 class="title"><a id="ch08lvl4sec2"></a>Step 3</h4>
                  </div>
                </div>
              </div>
              <p>Perform the final step: that of doing the carrying operation (for example, in the rightmost column, keep the 4 and add the 5 to the column containing 93). In the given example, this yields the correct product, 359,784.</p>
              <p>The following is the serial implementation of this algorithm (it faithfully follows the preceding steps for clarity):</p>
              <pre class="programlisting">    //----------------------------Abstract Factory
     public interface INumeric
     { 
         BigNumOperations Operations ();
     }
    //----------------------------Abstract Product
    public abstract class BigNumOperations
    { 
       public abstract string Multiply (string x, string y);
       public virtual string Multiply (
         string x,
         string y,
         CancellationToken ct,
         BlockingCollection&lt;string&gt; log)
       {
         return this.Multiply(x, y); 
       }</pre>
              <div class="note" title="Note" style="">
                <div class="inner">
                  <h3 class="title"><a id="note34"></a>Note</h3>
                  <p>In the following <code class="literal">Power</code> method, we will employ Exponentiation by Squaring Algorithm, which relies on the fact that:&#160;<span class="emphasis"><em> x^y == (x*x)^(y/2)
</em></span>Using this, we will continuously divide the exponent (in this case <span class="emphasis"><em>y</em></span>) by two while squaring the base (in this case <span class="emphasis"><em>x</em></span>).That is, in order to find the result of 2^11, we will do [((2*2)*(2*2))*((2*2)*(2*2))] * [(2*2)] * [(2)] or, to put it simply, we will do 2^8 * 2^2 * 2^1.This algorithm achieves O(log n) efficiency!</p>
                </div>
              </div>
              <pre class="programlisting">    public string Power (string number, int exponent) 
    { 
        int remainingEvenExp = exponent / 2; 
        int remainingOddExp = exponent % 2; 
        string result = number; 
        if (remainingEvenExp &gt; 0) 
        { 
            string square = this.Multiply(number, number); 
            result = square; 
            if (remainingEvenExp &gt; 1) 
            { 
                if (remainingOddExp == 1) 
                { 
                    result = this.Multiply( 
                        this.Power(square, remainingEvenExp), 
                        number); 
                } 
                else 
                { 
                    result = this.Power(square, remainingEvenExp); 
                } 
             } 
             else 
             { 
                if (remainingOddExp == 1) 
                { 
                    result = this.Multiply(square, number); 
                } 
             } 
         } 
         return result; 
    } 
 
     // Creates, Initializes and Returns a Jagged Array 
 
     public static int[][] CreateMatrix (int rows, int cols) 
     { 
        int[][] result = new int[rows][]; 
        for (int i = 0; i &lt; rows; ++i) 
            result[i] = new int[cols]; 
        return result; 
     } 
   } 
 
    // ----------------------------Concrete Product-1 
 
    public class BigNumOperations1 : BigNumOperations 
    { 
        /// &lt;summary&gt; 
        /// Serial Implementation of Schönhage-Strassen Algorithm 
        /// &lt;param name="x"&gt;String number Sequence-1&lt;/param&gt; 
        /// &lt;param name="y"&gt;String number Sequence-2&lt;/param&gt; 
        /// &lt;returns&gt;String Equivalent Product Sequence&lt;/returns&gt; 
        /// &lt;/summary&gt; 
 
        public override string Multiply (string x, string y) 
        { 
            int n = x.Length; 
            int m = y.Length; 
            int prodDigits = n + m - 1; 
            int[] linearConvolution = new int[prodDigits]; 
            int[][] longMultiplication = CreateMatrix(m, prodDigits); 
 
            //----------------------------Step-1 
 
            for (int i = m - 1; i &gt;= 0; i--) 
            { 
                int row = m - 1 - i; 
                int col = 0; 
                int iProduct; 
                for (int j = n - 1; j &gt;= 0; j--) 
                { 
                    col = i + j; 
                    iProduct = (( int ) 
                      Char.GetNumericValue(y[i])) * 
                      (( int ) Char.GetNumericValue(x[j])); 
                    longMultiplication[row][col] = iProduct; 
                } 
            } 
 
            //----------------------------Step-2 
 
            for (int j = prodDigits - 1; j &gt;= 0; j--) 
            { 
                int sum = 0; 
                for (int i = 0; i &lt; m; i++) 
                { 
                    sum += longMultiplication[i][j]; 
                } 
                linearConvolution[j] = sum; 
            } 
 
            //----------------------------Step-3 
 
            int nextCarry = 0; 
            int[] product = new int[prodDigits]; 
            for (int i = (n + m - 2); i &gt;= 0; i--) 
            { 
                linearConvolution[i] += nextCarry; 
                product[i] = linearConvolution[i] % 10; 
                nextCarry = linearConvolution[i] / 10; 
            } 
            return (nextCarry &gt; 0 ? nextCarry.ToString() : "") + 
              new string 
              ( 
                  Array.ConvertAll&lt;int, char&gt; 
                  (product, c =&gt; Convert.ToChar(c + 0x30)) 
              ); 
        } 
    } 
 
    // Concrete Factory-1 
 
    public class BigNumber1 : INumeric 
    { 
      public BigNumOperations Operations() 
      { 
        return new BigNumOperations1(); 
      } 
    }</pre>
              <div class="note" title="Note" style="">
                <div class="inner">
                  <h3 class="title"><a id="note35"></a>Note</h3>
                  <p>If you closely evaluate the code, Step 1 and Step 2 in our algorithm are embarrassingly, or rather, conveniently parallelizable. Listed next is the equivalent lock-free parallel implementation of the same algorithm. This leverages the TPL&#160;<code class="literal">Parallel.For</code> parallelization construct.</p>
                </div>
              </div>
              <pre class="programlisting">    // Concrete Product-2 
 
    public class BigNumOperations2 : BigNumOperations 
    { 
        public override string Multiply (string x, string y) 
        { 
          int n = x.Length; 
          int m = y.Length; 
          int prodDigits = n + m - 1; 
          int[] linearConvolution = new int[prodDigits]; 
          int[][] longMultiplication = CreateMatrix(m, prodDigits); 
 
          //----------------------------Step-1 
 
          Parallel.For(0, m, i =&gt; 
          { 
              int row = m - 1 - i; 
              int col = 0; 
              int iProduct; 
              for (int j = 0; j &lt; n; j++) 
              { 
                  col = i + j; 
                  iProduct = (( int ) Char.GetNumericValue(y[i]))
                    * (( int ) Char.GetNumericValue(x[j])); 
                  longMultiplication[row][col] = iProduct; 
              } 
          }); 
 
          //----------------------------Step-2 
 
          Parallel.For(0, prodDigits, j =&gt; 
          { 
              int sum = 0; 
              for (int i = 0; i &lt; m; i++) 
              { 
                  sum += longMultiplication[i][j]; 
              } 
              linearConvolution[j] = sum; 
          }); 
 
          //----------------------------Step-3 
 
          //Use code from Concrete Product-1 here... 
        }  
    } 
 
    // Concrete Factory-2 
 
    public class BigNumber2 : INumeric 
    { 
      public BigNumOperations Operations() 
      { 
        return new BigNumOperations2(); 
      } 
    }</pre>
              <div class="note" title="Note" style="">
                <div class="inner">
                  <h3 class="title"><a id="note36"></a>Note</h3>
                  <p>Now, to really understand the leverage we got from the <code class="literal">Parallel.For</code> parallelization construct, we have to do a CPU-intensive operation, which would be best achieved by computing the power (as opposed to the product) utilizing the multiplication algorithm. Imagine solving the wheat and chess problem, or perhaps more, say, 2<sup>100,000</sup> (to the power of 100,000) in place of 2<sup>32</sup>. A recursive divide and conquer strategy has been applied to compute the exponential (default implementation of the <code class="literal">Power</code> method in the abstract class/product <code class="literal">BigNumOperations</code>, which further uses the overridden, concrete <code class="literal">Multiply</code> methods of the respective core product implementations).</p>
                </div>
              </div>
              <p>Can you really compute 2<sup>100,000</sup> (given our limit of 64-bit arithmetic operations)? Well, take a look at the following invocation code and result:</p>
              <pre class="programlisting">    public static void Power (string[] args) 
    { 
        var bigN1 = new BigNumber1(); 
        var bigN2 = new BigNumber2(); 
        var x = args[0]; 
        int y = Convert.ToInt32(args[1]); 
 
        var watch = Stopwatch.StartNew(); 
        var val1 = bigN1.Operations().Power(x, y); 
 
       Console.WriteLine(
         "Serial Computation of {0} ^ {1}: {2} seconds", 
          x, y, watch.ElapsedMilliseconds / 1000D); 
 
        watch = Stopwatch.StartNew(); 
        var val2 = bigN2.Operations().Power(x, y); 
 
        Console.WriteLine( 
          "Parallel Computation of {0} ^ {1}: {2} seconds", 
          x, y, watch.ElapsedMilliseconds / 1000D); 
             
        Console.WriteLine("Computed Values are {0}!!!",  
          val1.Equals(val2) ? "EQUAL" : "DIFFERENT"); 
    }</pre>
              <p>
</p>
              <div class="mediaobject">
                <img src="graphics/B05691_08_03.jpg" alt="Step 3"/>
              </div>
              <p>
</p>
              <p>Yes!!! It computed the values, and the parallel implementation took around half the time as compared to the serial one.</p>
              <div class="note" title="Note" style="">
                <div class="inner">
                  <h3 class="title"><a id="note37"></a>Note</h3>
                  <p>The qualifier here, that of taking half the time, is relative and will depend on the availability of cores and resources; it will also vary with environments.</p>
                </div>
              </div>
              <p>Also see how the task granularity seems to utilize the CPU (with all its available cores) to the maximum extent possible in the case of parallel execution (towards the right-hand side of the usage spectrum in all of the four cores):</p>
              <p>
</p>
              <div class="mediaobject">
                <img src="graphics/B05691_08_04.jpg" alt="Step 3"/>
              </div>
              <p>
</p>
              <p>The following is a quick summary of the key applicability of best practices and patterns in this implementation:</p>
              <div class="itemizedlist">
                <ul class="itemizedlist">
                  <li class="listitem" style="list-style-type: disc">This is a classic case, where data parallelism (applying a single operation to many data elements/inputs) is exploited to the core, and the parallelization construct (<code class="literal">Parallel.For</code>) we have chosen is best suited for this. We could also leverage the synchronization primitive <code class="literal">Barrier</code> (<code class="literal">System.Threading.Barrier</code>), which would enable various sub-tasks to cooperatively work in parallel through multiple phases/tasks. A <code class="literal">Barrier</code> is recommended when the phases are relatively large in number.</li>
                  <li class="listitem" style="list-style-type: disc">Choose a lock-free task data structure (here, a two dimensional array has been utilized to capture the product sequences from each iteration in step 1). The operations (reads/writes) are atomic if you examine them closely (including step 2). This makes the parallelization process very effective, as there wouldn't be any synchronization penalties (<span class="strong"><strong>locks,</strong></span> specifically) but a seamless utilization of resources (with the inherent load balancing provided by <code class="literal">Parallel.For</code>). It is best to leave <code class="literal">Parallel.For</code> to calibrate the <span class="strong"><strong>degree of parallelism</strong></span> (<span class="strong"><strong>DOP</strong></span>) itself so as to leverage all the available cores, and thereby prevent side-effects because of thread starvation or oversubscription. At best, we could specify <code class="literal">ParallelOptions</code> of <code class="literal">Parallel.For</code> to use <code class="literal">Environment.ProcessorCount</code> so as to explicitly state the usage of one thread per core (a recommended practice in parallelization). The biggest limitation would be in terms of the memory required for array allocation in this case. You would tend to hit the <code class="literal">OutOfMemory</code> exception beyond powers of 100,000 (again, specific to this algorithm and the associated data structures that it employs).</li>
                  <li class="listitem" style="list-style-type: disc">Fine-grained partitioning of tasks, as part of the decomposition process, enables throughput (again, it's a balance that needs to be achieved with careful analysis; any attempt to overdo can swing the performance pendulum to the other side).</li>
                  <li class="listitem" style="list-style-type: disc">Choose the data representation in string format to represent really big numbers. Of course, you do incur the penalty of data conversion (a necessary evil in this case). You could as well create an extension method for string type to support these big number operations (perhaps, with a validation for legal numbers).</li>
                  <li class="listitem" style="list-style-type: disc">Use of alternate algorithm (reverse long multiplication; that is, reversing steps 1.1 through 1.3) to leverage the parallel loop partition counter, which is forward only (as its purpose is only to partition, unlike that of a step counter in a conventional <code class="literal">for</code> loop). Restructuring your algorithm is better than tweaking the code that was originally designed to run serially.</li>
                  <li class="listitem" style="list-style-type: disc">And finally, leverage the abstract factory GoF design pattern to seamlessly support the various implementations (in this case, serial and parallel).</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="section" title="Fork/join or master/worker">
          <div class="titlepage">
            <div>
              <div>
                <h2 class="title"><a id="ch08lvl2sec34"></a>Fork/join or master/worker</h2>
              </div>
            </div>
          </div>
          <p>This is a pattern that you generally associate with task parallelism. When there are distinct asynchronous operations that can run simultaneously, you can temporarily fork a program's flow of control with tasks that can potentially execute in parallel. You can then wait for these forked tasks to complete.</p>
          <p>In the Microsoft® .NET Framework, tasks are implemented by the <code class="literal">Task</code> class in the <code class="literal">System.Threading.Tasks</code> namespace. Unlike threads, new tasks that are forked (using the <code class="literal">StartNew</code> method) don't necessarily begin executing immediately. They are managed internally by a task scheduler, and run based on a FIFO manner (from a work queue) as cores become available. The <code class="literal">Wait</code> (for task) and <code class="literal">WaitAll</code> (for task array) method ensures the join operation.</p>
          <p>Now, if you try to apply this pattern holistically to our original problem statement (to compute the power of big numbers), you will see the potential to leverage this for executing the tasks within the major phases (Steps 1, 2, and 3) concurrently (by forking off tasks), and have the phases blocking (joining these forked tasks within each phase) to mirror the sequential ordering (steps 1, 2, and 3) as advocated by the algorithm. See the following code that does lock-free parallel implementation of Schönhage-Strassen Algorithm by leveraging the <code class="literal">System.Threading.Tasks</code>&#160;concurrency construct:</p>
          <pre class="programlisting">    // Concrete Product-3 
 
    public class BigNumOperations3 : BigNumOperations 
    { 
        public override string Multiply (string x, string y,   
          CancellationToken ct, BlockingCollection&lt;string&gt; log) 
        { 
            int n = x.Length; 
            int m = y.Length; 
            int prodDigits = n + m - 1; 
            int[] linearConvolution = new int[prodDigits]; 
            int[][] longMultiplication = CreateMatrix(m, prodDigits); 
 
<span class="strong"><strong>            var degreeOfParallelism = Environment.ProcessorCount;
</strong></span>
<span class="strong"><strong>            var tasks = new Task[degreeOfParallelism];</strong></span> 
 
            //----------------------------Step-1 
 
            for (int taskNumber = 0;  
              taskNumber &lt; degreeOfParallelism;  
                taskNumber++) 
            { 
              int taskNumberCopy = taskNumber; 
              tasks[taskNumber] = Task.Factory.StartNew( 
                () =&gt; 
                { 
                    var max =  
                        m * (taskNumberCopy + 1) /  
                        degreeOfParallelism; 
                    var min =  
                        m * taskNumberCopy /  
                        degreeOfParallelism; 
                    for (int i = min; i &lt; max; i++) 
                    { 
                        int row = m - 1 - i; 
                        int col = 0; 
                        int iProduct; 
                        for (int j = 0; j &lt; n; j++) 
                        { 
                            col = i + j; 
                            iProduct =  
                                (( int ) Char 
                                .GetNumericValue(y[i])) * 
                                (( int ) Char 
                                .GetNumericValue(x[j])); 
                            longMultiplication[row][col] =  
                                iProduct; 
                        } 
                    } 
                }); 
        } 
 
        Task.WaitAll(tasks);        //Blocking Call 
 
        //----------------------------Step-2 
 
        for (int taskNumber = 0;  
            taskNumber &lt; degreeOfParallelism;  
            taskNumber++) 
        { 
            int taskNumberCopy = taskNumber; 
            tasks[taskNumber] = Task.Factory.StartNew( 
                () =&gt; 
                { 
                    var max =  
                        prodDigits * (taskNumberCopy + 1) /  
                        degreeOfParallelism; 
                    var min =  
                        prodDigits * taskNumberCopy /  
                        degreeOfParallelism; 
                    for (int j = min; j &lt; max; j++) 
                    { 
                        int sum = 0; 
                        for (int i = 0; i &lt; m; i++) 
                        { 
                            sum += longMultiplication[i][j]; 
                        } 
                        linearConvolution[j] = sum; 
                    } 
                }); 
        } 
 
        <span class="strong"><strong>Task.WaitAll(tasks);</strong></span>        //Blocking Call 
             
        //----------------------------Step-3 
 
        //Use code from Concrete Product-1 here... 
 
      } 
    } 
 
    // Concrete Factory-3 
 
    public class BigNumber3 : INumeric 
    { 
      public BigNumOperations Operations() 
      { 
        return new BigNumOperations3(); 
      } 
    }</pre>
          <p>The collective sample output along with the preceding code is as follows:</p>
          <p>
</p>
          <div class="mediaobject">
            <img src="graphics/B05691_08_05.jpg" alt="Fork/join or master/worker"/>
          </div>
          <p>
</p>
          <p>What we have done here in the preceding code is essentially explicit macro-range partitioning with respect to the available cores, and not spinning off in place of micro-range partitioning with respect to the outer loop. This is a strategy which has to be dealt with carefully, as results would vary with the resources available at your disposal. Deliberate calibration can yield much higher throughputs. In this context, we come to the next important pattern.
</p>
        </div>
      </div>
    </div>


    <div id="sbo-rt-content">
      <div class="section" title="Speculative execution">
        <div class="titlepage">
          <div>
            <div>
              <h1 class="title"><a id="ch08lvl1sec64"></a>Speculative execution</h1>
            </div>
          </div>
        </div>
        <p>Now that we have seen close to three different implementation strategies of the Schönhage-Strassen algorithm, how do we perform deliberate calibration, and decide which is the best strategy (now that we understand that it has a close co-relation with its environment and associated resources)?</p>
        <div class="note" title="Note" style="">
          <div class="inner">
            <h3 class="title"><a id="note38"></a>Note</h3>
            <p>This is where this important pattern really helps us make a decision, when deviations against anticipated results are unavoidable, and need to be smartly addressed.</p>
          </div>
        </div>
        <p>We would schedule asynchronous tasks for each of these strategies for execution, leverage the <code class="literal">WaitAny</code> method of the <code class="literal">Task</code> class to wait for one of the operations to complete (one that finishes first), and attempt to cancel all others. On a smart-learning front, this could be done periodically to continuously calibrate and cache your strategy for mass consumption. It's an aspect of machine learning where the program intelligently adapts to sieve and use effective algorithms. See the following code that incorporates options to cancel tasks upon determination of the winner by working out&#160;who is the fastest:</p>
        <pre class="programlisting">    // Concrete Product-4 
 
    public class BigNumOperations4 : BigNumOperations 
    { 
        /// &lt;summary&gt; 
        /// Serial Cancellable Implementation of  
        /// Schönhage-Strassen Algorithm 
        /// &lt;param name="x"&gt;String number Sequence-1&lt;/param&gt; 
        /// &lt;param name="y"&gt;String number Sequence-2&lt;/param&gt; 
        /// &lt;returns&gt;String Equivalent Product Sequence&lt;/returns&gt; 
        /// &lt;/summary&gt; 
 
        public override string Multiply ( 
            string x,  
            string y,  
<span class="strong"><strong>            CancellationToken ct, </strong></span> 
            BlockingCollection&lt;string&gt; log) 
        { 
<span class="strong"><strong>            if (ct.IsCancellationRequested == true)</strong></span> 
            { 
<span class="strong"><strong>                ct.ThrowIfCancellationRequested();</strong></span> 
            } 
            //Use code from Concrete Product-1 here... 
             
            //----------------------------Step-1 
 
            for (int i = m - 1; i &gt;= 0; i--) 
            { 
            //Use code from Concrete Product-1 here... 
 
                for (int j = n - 1; j &gt;= 0; j--) 
                { 
<span class="strong"><strong>                    if (ct.IsCancellationRequested)</strong></span> 
                    { 
<span class="strong"><strong>                        ct.ThrowIfCancellationRequested();</strong></span> 
                    } 
 
            //Use code from Concrete Product-1 here... 
 
                } 
            } 
 
            //----------------------------Step-2 
 
            for (int j = prodDigits - 1; j &gt;= 0; j--) 
            { 
<span class="strong"><strong>                if (ct.IsCancellationRequested)</strong></span> 
                { 
<span class="strong"><strong>                    ct.ThrowIfCancellationRequested();</strong></span> 
                } 
 
                //Use code from Concrete Product-1 here... 
            } 
 
                //----------------------------Step-3 
 
            for (int i = (n + m - 2); i &gt;= 0; i--) 
            { 
<span class="strong"><strong>                if (ct.IsCancellationRequested)</strong></span> 
                { 
<span class="strong"><strong>                    ct.ThrowIfCancellationRequested();</strong></span> 
                } 
 
                //Use code from Concrete Product-1 here... 
        } 
    }</pre>
        <div class="note" title="Note" style="">
          <div class="inner">
            <h3 class="title"><a id="note39"></a>Note</h3>
            <p>Similarly, concrete products 5 and 6 are created based on constructs employed in products 2 and 3. Please refer the relevant code sections in the companion website for these implementations.</p>
          </div>
        </div>
        <p>Now that we have executable parallel code that will respond to user interruptions, lets understand how we can do speculative execution.</p>
        <p>It's quite interesting, or rather an art, how we can achieve control over these constructs. It's just that you need to see through your algorithm, and determine how the decomposition helps you gain coarser or finer control on execution. You will see areas that pose limitations once you get into the finer intricacies of task parallelization and concurrency. You will also see the power of abstraction that these constructs bring to the table, and better appreciate the instrumentation and hooks that need to go in for aiding you in gaining better control of your program, as opposed to letting <span class="strong"><strong>heisenbugs</strong></span> haunt your programs. Let's observe the output that determined the fastest implementation:</p>
        <p>
</p>
        <div class="mediaobject">
          <img src="graphics/B05691_08_06.jpg" alt="Speculative execution"/>
        </div>
        <p>
</p>
        <p>Though the <code class="literal">Parallel.For</code> construct emerged the winner in all the three trials. This is not a certainty, as the outcome is determined by the available resources and the complexity of the algorithm (in terms of control flow and data flow), depending on input data provided. Something interesting has occurred here, which warrants an explanation, and will, thereby, demystify certain behaviors. Remember, everything ought to have an explanation (unless you are not in control, and have absolutely no idea how your code behaves)!</p>
        <p>In case you are wondering why the serial implementation got cancelled, before it started, only once, it's primarily related to the work load in the machine and the precedence/sequence in which the tasks started being executed by the CLR thread pool. Also, the reason why the <span class="strong"><strong>Tasks Implementation - Cancelled</strong></span> message comes only once is because <code class="literal">Console.WriteLine</code> blocks until the output has been written, as it calls the <code class="literal">Write</code> method of the underlying stream instance; the ones that don't get blocked appear on the console. You also need to ensure that the token cancellation detection code (<code class="literal">token.IsCancellationRequested</code>) is set at the required control flow points (forks, joins, and so on) to record near real-time cancellations, and throw <code class="literal">TaskCanceledException</code> via the <code class="literal">token.ThrowIfCancellationRequested</code> method (causing the task to transition to the faulted state). Please inspect the highlighted areas in the code to understand this.</p>
        <p>The limitation that we noticed in terms of the missing console messages is something that we would need to overcome, as, capturing relevant information during program execution is an important horizontal concern, irrespective of the execution model (synchronous or asynchronous). Ideally, this activity should happen without impacting the normal execution flow, or causing any performance penalties (in terms of blocking calls). Asynchronous I/O is typically a standard option used by logging libraries to capture information (user and system-driven) behind the scenes. We have already dealt with the logging library in <a class="link" href="dn-dsnptn_ch03.html" title="Chapter&#160;3.&#160;A Logging Library">Chapter 3</a>, <span class="emphasis"><em>A Logging Library</em></span>, and now we will see how to channel data and invoke these libraries asynchronously in the next pattern.</p>
        <p>Another relevant GoF pattern that could be leveraged here is the visitor pattern, where new strategic implementation of the algorithms could be declaratively tried out, without flooding consumers with concrete products.</p>
        <div class="section" title="Producer/consumer">
          <div class="titlepage">
            <div>
              <div>
                <h2 class="title"><a id="ch08lvl2sec35"></a>Producer/consumer</h2>
              </div>
            </div>
          </div>
          <p>This is a natural pattern that one can easily relate to from the moment you start modelling solutions for real-world problems. It is so intuitive that one may fail to appreciate the elegance of it, and yet many times we struggle with implementations associated with it.</p>
          <p>A &#160;producer&#160;producing something which a&#160;consumer wants is a common scenario in software modelling. And this can even happen at multiple levels or stages in your data flow. This is a typical pipeline in design parlance, and warrants good synchronization between stages. A seamless interplay between the stages in a pipeline warrants a regulated handshake, where we don't let consumers starve, and at the same time, ensure they are not overfed. Throttling this handshake involves laying down a communication protocol (publish-subscribe model, queue-based, and so on), which requires some of the boiler-plate concurrency constructs (be it data structures or synchronization primitives) to be in place, as opposed to one wiring these on their own. We have concurrent data structure starting with .NET 4.0, including <code class="literal">BlockingCollection&lt;T&gt;</code>, <code class="literal">ConcurrentBag&lt;T&gt;</code>, <code class="literal">ConcurrentDictionary(TKey, TValue)</code>, <code class="literal">ConcurrentQueue&lt;T&gt;,</code> and <code class="literal">ConcurrentStack&lt;T&gt;</code>, which help us in this task by abstracting out the synchronization pain-points, and giving us just the adequate blocking features for a seamless integration of concurrent execution scenarios.</p>
          <p>If you really look at our big-number multiplication algorithm, it involves a pipeline too, having three stages. The only thing is that our stages aren't concurrent, but serial (this is where, irrespective of the cores you have, you tend to reach the point of diminishing returns that Amdahl's law predicts). Additionally, our data structure (2D Array) gives non-blocking reads/writes for the concurrent producers within each stage.</p>
          <div class="note" title="Note" style="">
            <div class="inner">
              <h3 class="title"><a id="note40"></a>Note</h3>
              <p>The performance of a pipeline implementation is purely determined by the performance of its individual stages, and for efficiency, we need a concurrent model for each stage (which was achieved in our case).</p>
            </div>
          </div>
          <p>Let's look at a producer-consumer model-based implementation for non-blocking or asynchronous logging in the case of speculative execution. We want this primarily to overcome the limitation of blocking, and console-based stream writes (in production you can leverage asynchronous I/O for file or db writes).</p>
          <p>The code for the consumer is shown as follows:</p>
          <pre class="programlisting">    /// &lt;summary&gt; 
    /// Adaptive Speculation for determining the best strategy 
    /// for your environment. Leveraging Task.WaitAny method 
    /// &lt;/summary&gt; 
    /// &lt;param name="args"&gt;&lt;/param&gt; 
 
    public static void AdaptivePower (string[] args) 
    { 
        var bigN1 = new BigNumber4(); 
        var bigN2 = new BigNumber5(); 
        var bigN3 = new BigNumber6(); 
 
        var val1 = ""; 
        var val2 = ""; 
        var val3 = ""; 
 
        var x = args[0]; 
        int y = Convert.ToInt32(args[1]); 
 
        var tasks = new Task[3]; 
        var tokenSource = new CancellationTokenSource(); 
        var token = tokenSource.Token; 
<span class="strong"><strong>        BlockingCollection&lt;string&gt; log = new BlockingCollection&lt;string&gt;();</strong></span> 
        Stopwatch watch; 
 
        tasks[0] = Task.Factory.StartNew(() =&gt; 
        { 
            watch = Stopwatch.StartNew(); 
            val1 = bigN1.Operations() 
              .Power(x, y, token, log); 
 
            Console.WriteLine("Elapsed Time for Serial " + 
              "Computation of {0} ^ {1}: {2} seconds " + 
                "&gt;&gt; {3}", x, y, watch.ElapsedMilliseconds / 1000D, val1); 
        }, token); 
 
        tasks[1] = Task.Factory.StartNew(() =&gt; 
        { 
              watch = Stopwatch.StartNew(); 
              val2 = bigN2.Operations() 
                .Power(x, y, token, log); 
 
              Console.WriteLine("Elapsed Time for " + 
                "Parallel.For Computation of " + 
                  "{0} ^ {1}: {2} seconds &gt;&gt; {3}", x, y, 
                    watch.ElapsedMilliseconds / 1000D, val2); 
            }, token); 
 
        tasks[2] = Task.Factory.StartNew(() =&gt; 
        { 
              watch = Stopwatch.StartNew(); 
              val3 = bigN3.Operations() 
                .Power(x, y, token, log); 
              Console.WriteLine("Elapsed Time for Parallel " + 
                "Task Computation of {0} ^ {1}: {2} " + 
                  "seconds &gt;&gt; {3}", x, y,  
                    watch.ElapsedMilliseconds / 1000D, val3); 
        }, token); 
 
        Console.WriteLine("Determining Fastest Algorithm " 
          + "Implementation..."); 
             
        Task.WaitAny(tasks);    // Wait for fastest task to complete. 
        tokenSource.Cancel();   // Cancel all the other slower tasks. 
             
        try 
        { 
            Task.WaitAll(tasks); 
        } 
        catch (AggregateException ae) 
        { 
            ae.Flatten().Handle(e =&gt; e is OperationCanceledException); 
        } 
        finally 
        { 
            if (tokenSource != null) 
                tokenSource.Dispose(); 
            foreach (string logItem in log) 
            { 
<span class="strong"><strong>                Console.WriteLine(logItem);</strong></span> 
            } 
            Console.WriteLine("Adaptive Speculation Complete!!!"); 
        } 
    }</pre>
          <p>Here you can see that we are using a blocking collection to record logs. This needs to be passed as another parameter to the implementation, and, in turn, collects all the log information.</p>
          <p>The following is an indicative code for the logger (handled in the respective concrete products):</p>
          <pre class="programlisting">    // Concrete Product-4 
 
    public class BigNumOperations4 : BigNumOperations 
    { 
      /// &lt;summary&gt; 
      /// Serial Cancellable &amp; Loggable Implementation of  
      /// Schönhage-Strassen Algorithm 
      /// &lt;param name="x"&gt;String number Sequence-1&lt;/param&gt; 
      /// &lt;param name="y"&gt;String number Sequence-2&lt;/param&gt; 
      /// &lt;returns&gt;String Equivalent Product Sequence&lt;/returns&gt; 
      /// &lt;/summary&gt; 
 
      public override string Multiply (string x, string y,  
        CancellationToken ct, BlockingCollection&lt;string&gt; log) 
     { 
        if (ct.IsCancellationRequested == true) 
        { 
<span class="strong"><strong>          log.Add("Serial Implementation Task was " +</strong></span> 
          "cancelled before it got started!"); 
          ct.ThrowIfCancellationRequested(); 
        } 
        //Use code from Concrete Product-1 here... 
             
        //----------------------------Step-1 
 
            for (int i = m - 1; i &gt;= 0; i--) 
            { 
                //Use code from Concrete Product-1 here... 
 
                for (int j = n - 1; j &gt;= 0; j--) 
                { 
                    if (ct.IsCancellationRequested) 
                    { 
<span class="strong"><strong>                        log.Add("Serial Implementation Step1 " +</strong></span>
<span class="strong"><strong> 
                           "was cancelled!");</strong></span> 
                        ct.ThrowIfCancellationRequested(); 
                    } 
 
                    //Use code from Concrete Product-1 here... 
 
                } 
            } 
 
            //----------------------------Step-2 
 
            for (int j = prodDigits - 1; j &gt;= 0; j--) 
            { 
                if (ct.IsCancellationRequested) 
                { 
<span class="strong"><strong>                    log.Add("Serial Implementation Step2 " +
</strong></span>
<span class="strong"><strong>                      "was cancelled!");</strong></span> 
                    ct.ThrowIfCancellationRequested(); 
                } 
 
                //Use code from Concrete Product-1 here... 
            } 
 
            //----------------------------Step-3 
 
            for (int i = (n + m - 2); i &gt;= 0; i--) 
            { 
                if (ct.IsCancellationRequested) 
                { 
<span class="strong"><strong>                    log.Add("Serial Implementation Step3 " +</strong></span>
<span class="strong"><strong> 
                      "was cancelled!");</strong></span> 
                    ct.ThrowIfCancellationRequested(); 
                } 
 
                //Use code from Concrete Product-1 here... 
        } 
    }</pre>
          <p>So, we have seen some of the key patterns that play a major role in modelling concurrent tasks that could be run in parallel. Though the narration has been primarily based on a single example, we believe that, as a developer, you were able to understand the applicability of these in a real-world problem scenario. In terms of coverage, there is a lot one needs to learn and prototype. Exception handling is a chapter on its own, especially when dealing with concurrent scenarios, and that has been avoided for brevity. A sea of threads awaits you. Bon Voyage!</p>
        </div>
      </div>
    </div>


    <div id="sbo-rt-content">
      <div class="section" title="Summary">
        <div class="titlepage">
          <div>
            <div>
              <h1 class="title"><a id="ch08lvl1sec65"></a>Summary</h1>
            </div>
          </div>
        </div>
        <p>In this chapter, we just touched the surface of concurrent and parallel programming under .NET. The topic warrants a book dedicated for itself. Now you have enough background to learn about writing advanced software using features of the C# programming language, like LINQ, lambda, expression trees, extension methods, async/await, and so on. The next chapter will deal with the issue of better state management by leveraging these tools.</p>
      </div>
    </div>
</body>
</html>