

# 总结

到目前为止，我们已经发现了围绕微服务设计的一些模式和细微差别。现在，让我们从高层次上探索我们的模式，并将所有概念联系起来。确定哪种模式最适合每种情况是至关重要的。

微服务软件开发方法促进了自主过程的松散耦合和创建处理这些过程的独立软件组件。对这些过程进行范围的一个优秀方法是采用**领域驱动设计**（**DDD**）模式。在 DDD 中，我们将系统的功能分类到称为领域的子部分，然后使用这些领域来管理需要支持每个领域的服务或独立应用程序。然后我们使用聚合器模式来尝试确定每个服务所需的领域对象。

# 聚合器模式

我们确定了每个领域所需的数据以及需要在领域之间共享的数据。在这个阶段，我们确实面临在领域之间重复数据点的风险。然而，鉴于需要促进服务及其相应数据库的自主性，这是一个我们接受的条件。

在确定数据需求时，我们使用聚合器模式，这使我们能够定义不同实体将具有的各种数据需求和关系。聚合体代表了一组可以被视为单一单位的领域对象。在这个范围练习中，我们试图找到这个集群的根元素，其他所有实体都被视为与根关联的领域对象。

在按服务确定我们的领域对象时的一般想法是捕捉每个服务操作所需的最小数据量。这意味着我们将尝试避免在多个服务中存储整个领域记录，而是允许我们的服务进行通信以检索可能具有领域特定性并驻留在另一个服务中的详细信息。这就是我们需要我们的服务进行通信的地方。

# 同步和异步通信

我们的微服务需要不时地进行通信。我们采用的通信类型基于我们最终需要完成的操作类型。同步通信意味着一个服务将直接调用另一个服务并等待响应。然后它将使用这个响应来通知它试图完成的进程。这种方法适用于一个服务可能有一些数据而需要从另一个服务获取其余数据的情况。例如，预约服务知道患者的 ID 号码但没有其他信息。然后它需要向患者服务进行同步 API 调用并获取患者的详细信息。然后它可以携带这些详细信息进行处理。

当我们需要从另一个服务获得即时反馈时，同步通信是非常好的。然而，当必须咨询多个其他服务时，它可能会引入问题并增加响应时间。我们还有每次 API 调用尝试失败的风险，一次失败可能会导致完全失败。我们需要优雅地处理部分或完全失败，并相对于业务流程的规则来处理。为了减轻这种风险，我们必须采用异步通信策略，将其传递给一个更稳定且始终在线的中介，该中介将根据需要将数据传输到其他服务。

异步通信更适合需要其他服务参与但不需要即时反馈的过程。例如，预约过程将需要完成涉及其他微服务和第三方服务的多个操作。例如，该过程将获取并保存预约信息，创建日历条目，并发送多个电子邮件和通知。然后，我们可以使用异步消息系统（如 RabbitMQ 或 Azure Service Bus）作为中介系统，该系统将接收来自微服务的信 息。需要参与的其他服务被配置为监控消息系统并处理任何出现的数据。然后，每个服务都可以在其自己的时间独立地完成其操作。预约服务也可以根据其需求确认成功，而无需担心是否已经完成了一切。

随着我们分离业务流程和范围，并确定哪些操作需要同步通信以及哪些操作需要异步通信，我们发现我们需要更好的方式来格式化我们的代码，并正确地分离应用程序代码的移动部分。这就是我们开始查看更复杂的设计模式，如**命令和查询责任分离**（**CQRS**）的地方。

# CQRS

CQRS 是一种流行的模式，它允许开发者更好地组织应用逻辑。它是最初称为**命令查询分离**（**CQS**）的模式的改进，该模式旨在为开发者提供一种清晰的方式来分离增强数据库中数据（命令）的逻辑和检索数据的逻辑（查询）。

通过引入这种级别的分离，我们可以引入额外的抽象，并更容易地遵循我们的 SOLID 原则。在这里，我们引入了处理器的概念，它代表要执行的单个工作单元。这些处理器被实现为专门使用最少的资源和最少的依赖关系来完成操作。这使得代码更具可扩展性，并且更容易维护。

引入这种程度分离和抽象的一个缺点是文件和文件夹数量的显著增加。根据推荐方法完全实现基于 CQRS，我们可能还需要几个数据库来支持单个应用程序。这是因为用于查询操作的数据库需要优化，这通常意味着我们需要一个非规范化和高速查找的数据库结构。我们的命令操作可能使用不同的数据库，因为存储数据通常比读取数据有更严格的准则。

使用`NuGet`包，这些包帮助我们轻松实现此模式并减少整体开发开销。

最终，这种模式应该被用于具有更复杂业务逻辑需求的应用程序。鉴于其复杂性和项目膨胀，它不是推荐用于执行基本**创建、读取、更新和删除**（**CRUD**）操作的标准应用程序的方法。它还引入了一个新问题：保持我们的读取和写入数据库同步。

让我们采用使用单独的数据库进行查询和命令操作的方法。我们面临的风险是在操作之间，读取操作可能获得过时的数据。解决数据库之间断开连接的最佳解决方案被称为事件溯源。

# 事件溯源模式

事件溯源模式弥合了需要同步的数据库之间的差距。它们帮助我们跟踪系统中的更改，并作为幕后传输或查找系统，确保我们始终拥有最佳的数据表示。

首先，一个事件代表一个时间点。事件中包含的数据将指示采取的操作类型和结果数据。这些信息可以在系统内用于多个目的：

+   为需要用于其操作的结果数据的第三方服务完成任务

+   使用最新副本更新查询操作的数据库

+   作为版本控制机制添加到事件存储库

事件溯源可以在系统中扮演多个角色，并帮助我们完成多个常规和独特任务。在上下文中，常规任务可能包括更新我们的只读查询数据库，并作为在操作后基于最新数据执行的服务的事实来源。

较少的常规操作将依赖于实现事件存储库，另一个数据库用于跟踪每个事件及其数据副本。这充当了一个版本控制机制，使我们能够轻松地促进审计活动、时间点查找，甚至商业智能和分析操作。通过跟踪随时间推移的每个数据版本，我们可以看到记录的精确演变，并利用它来指导业务决策。

并不令人意外，这种模式与 CQRS 自然地结合在一起，因为我们可以从我们的处理程序中轻松且自然地触发事件。我们甚至可以使用事件存储作为我们的查询数据库查找位置，缓解与读取过时数据相关的紧张关系。然后我们可以扩展我们的查询能力，并利用我们现在可以访问的版本和特定时间点查找。

通过之前提到的允许我们实现 MediatR 模式的`NuGet`包，我们可以在操作结束时引发事件。我们还可以实现订阅特定事件的处理器，并在事件引发时执行其操作。这使得我们能够轻松扩展每个事件的订阅者数量，并单独且独特地实现每个事件执行的操作。

这些模式是按服务实现的，并且以任何方式都不会统一分散在多个独立应用程序中的代码。确保你选择的模式适用于微服务。在事件溯源和 CQRS 之间，我们已经将作用域数据库的数量从一个增加到可能三个。这可能会引入大量的基础设施需求和成本。

现在，让我们回顾一下我们应该如何处理微服务应用程序中的数据库需求。

# 每个服务一个数据库模式

微服务架构促进了服务的自主性和松散耦合。这种松散耦合的概念理想情况下应该在整个代码库和基础设施中得到实施。遗憾的是，由于成本原因，这只有在某些情况下才可能实现，尤其是在数据库层面。

数据库的许可、实施、托管和维护可能成本高昂。成本也根据数据库支持的服务需求以及所需存储类型而变化。拥有独立数据库的一个令人信服的理由是我们总是希望为每个微服务选择最佳的技术堆栈。每个都需要保持其独特性，数据库选择对于实现过程至关重要。

我们有不同的数据库类型，重要的是要欣赏它们之间的细微差别，并利用这些知识来为每个微服务可以存储的数据范围最佳数据库解决方案。让我们看看一些更受欢迎的选项。

## 关系型数据库

关系型数据库以表格格式存储数据，并采取严格的措施确保存储数据按照其标准达到最高可能的质量。它们最适合需要确保数据准确性的系统，可能需要为多个实体存储数据。它们通常依赖于一种称为 SQL 的语言来与数据交互，并通过规范化过程，将迫使我们在多个表中分散数据。这样，我们可以避免数据重复，并在其他表中建立对在一个表中找到的记录的引用。

缺点是严格的规则使得按需扩展变得困难，这导致与多个实体相关的数据读取时间变慢。

## 非关系型数据库

非关系数据库也被称为 NoSQL 数据库，因为它们与传统的关系数据库在结构上有所不同。它们在数据存储方面不太严格，允许更大的可伸缩性。它们最适合需要灵活数据存储选项的系统，考虑到快速变化的需求和功能。它们也常作为只读数据库使用，因为它们支持数据被精确地结构化以满足系统的需求。这些类型数据库最流行的实现包括文档数据库（如**MongoDB**或**Azure Cosmos DB**）、键值数据库（如**Redis**）和图数据库（如**Neo4j**）。

每种类型都有其优点和缺点。文档数据库选项最常作为关系数据库的替代品使用，因为它提供了一种更灵活的方式来存储所有数据点，但将它们保存在一个地方。然而，如果管理不当，这可能导致数据重复和整体质量的下降。

在考虑为服务选择最佳数据库选项时，我们必须考虑可维护性、技术成熟度和易用性以及任务的一般适用性。一种解决方案肯定不能适用于所有情况，但我们还必须考虑成本和可行性。我们有几种方法来实现支持我们服务的数据库；每种方法都有其优缺点。

## 所有服务一个数据库

从成本分析和维护角度来看，这是理想的解决方案。数据库引擎功能强大，旨在在重负载下运行，因此多个服务使用相同的数据库并不难实现。团队也不需要多样化的技能集来维护数据库和与该技术合作。

然而，这种方法给所有服务带来了一个故障点。如果这个数据库离线，那么所有服务都会受到影响。我们还放弃了选择最佳数据库技术以支持每个服务最佳实现的技术堆栈的灵活性。虽然大多数技术堆栈都有支持大多数数据库的驱动程序，但事实仍然是，某些语言与某些数据库配合得最好。在选择这种方法时务必非常小心。

## 每个服务一个数据库

这种解决方案为我们每个服务的实现提供了最大的灵活性。在这里，我们可以使用最适合所使用的编程语言和框架以及微服务的数据存储需求的数据库技术。需要表格数据存储结构的服务可以依赖关系数据库。通过扩展，使用 PHP 技术开发的微服务可能会倾向于 MySQL 数据库，而使用 ASP.NET Core 可能会倾向于 Microsoft SQL Server。这将减轻支持数据库的磨损，因为一种语言可能缺乏足够的工具。另一方面，基于 NodeJS 的微服务可能会倾向于 MongoDB，因为其数据不需要那么结构化，并且可能比其他服务更快地发展。

这里明显的缺点是我们需要能够支持多种数据库技术，并且必须具备进行常规维护和保养活动的技能集。我们还因为许可和托管选项而承担额外的成本，因为数据库可能（理想情况下，将会）需要单独的服务器托管安排。

单独来看，每个服务都需要确保其数据尽可能准确和可靠。因此，我们使用一个称为事务的概念来确保数据要么成功更新，要么不更新。这对于数据可能分布在多个表中的关系数据库来说特别有用。通过强制执行这种全有或全无机制，我们减少了部分成功的情况，并确保数据在所有表中保持一致性。

总是选择最适合你正在构建的微服务的技术来解决问题或领域。这种灵活性是拥有松散耦合应用程序的更多公开宣传的好处之一，在这种应用程序中，不同的部分不需要共享资产或功能。

相反，使用支持独立服务的单独数据库可能会导致严重的数据质量问题。回想一下，某些操作需要几个服务的参与，有时，如果一个服务未能更新其数据存储，就真的没有方法来跟踪失败并采取纠正措施。每个服务将处理其事务，但涉及几个独立数据库的操作将面临部分完成的风险，这是不好的。这就是我们可以求助于悲剧模式来帮助我们管理这种风险的地方。

# 在服务之间使用悲剧模式

悲剧模式通常用于协助我们在微服务应用程序中实现全有或全无的概念。每个服务都会为自己做这件事，但我们需要机制来允许服务相互通知其成功或失败，并且，通过扩展，在必要时采取行动。

以我们有一个需要四个服务参与的操作为例，每个服务都会在过程中存储一些数据；我们需要一种方式让服务报告其数据库操作是否成功。如果不成功，我们触发回滚操作。我们可以通过编排或编排来实现我们的悲剧模式。

通过编排，我们实现了一个消息系统（如 RabbitMQ 或 Azure 服务总线），其中服务会相互通知其操作完成或失败。虽然没有中央控制消息流，但每个服务都被配置为在接收到某些消息时采取行动，并根据其内部操作的结果发布消息。这是一个很好的模型，我们希望保持每个服务的自主性，并且没有服务需要了解其他服务。

在理论上，编排看起来很简单，但在需要向叙事添加新服务时实现和扩展可能会很复杂。从长远来看，每次叙事需要修改时，都需要关注几个接触点。这些因素促进了编排方法作为一个可行的替代方案。

使用编排方法，我们可以建立一个中央观察者，该观察者将协调与叙事相关的活动。它将编排对每个服务的每个调用的调用，并根据服务的成功或失败响应决定下一步。在编排器中实现的叙事将按照特定顺序沿着成功轨迹和单独的失败轨迹跟踪特定的服务调用。如果在叙事的中间发生失败，编排器将开始调用之前已报告成功的每个服务的回滚操作。

比较而言，编排方法允许更好地控制和对叙事每个步骤发生情况的监督，但可能更难以在长期内实现和维护。随着叙事的发展，我们将有同样多的接触点需要维护。

您选择的方法应与您的系统需求以及您期望的操作行为相匹配。编排促进服务自治，但可能导致大型叙事的意大利面式实现，我们需要跟踪哪个服务消费了哪个消息。这也使得调试变得非常困难。编排方法迫使我们引入一个中心故障点，因为如果编排器失败，其他什么都不会发生。

然而，这两种方法都取决于服务及其依赖项的整体可用性，以完成操作。我们需要确保我们不将第一次失败视为最终响应，并实现逻辑，在放弃之前尝试操作多次。

# 弹性微服务

构建具有弹性的服务非常重要。这充当了对系统造成破坏并导致糟糕用户体验的暂时性失败的缓冲。没有基础设施是坚不可摧的。每个网络都有故障点，依赖于不完美网络的服务的本质也是不完美的。除了基础设施的不完美之外，我们还需要考虑一般的应用负载以及我们的请求现在可能是一个过多的行为。这并不意味着服务已离线；这只是意味着它压力很大。

并非所有故障原因都在我们的控制之下，但我们可以控制我们的服务如何响应。通过实现重试逻辑，我们可以强制同步调用另一个服务，直到成功调用为止。这有助于我们减少应用程序中的故障数量，并在我们的操作中提供更多积极和准确的结果。典型的重试逻辑包括我们进行初始调用并观察响应。当响应不是预期结果时，我们再次尝试调用。我们继续这样做，直到我们收到可以处理的响应。然而，这种非常简化的重试逻辑存在一些缺陷。

我们应该只重试一段时间，因为我们不确定服务是否正在经历中断。在这种情况下，我们需要实施一个策略，在尝试一定次数后停止重试调用。我们称这种策略为断路器策略。我们还希望考虑在重试尝试之间添加一些时间。

这么复杂的策略可以通过一个名为 Polly 的简单代码实现，这是一个 `NuGet` 包。这个包允许我们声明全局策略，这些策略可以用来管理我们的 `HttpClient` 服务如何进行 API 调用。我们还可以为每个 API 调用定义特定的策略。

重试在很大程度上有助于我们保持应用程序健康的外观。然而，预防胜于治疗，我们更喜欢在故障变得严重之前跟踪和缓解故障。为此，我们需要实施健康检查。

# 健康检查的重要性

正如其名所示，健康检查允许我们跟踪和报告服务的健康状况。每个服务都是应用程序中可能发生故障的点，每个服务都有可能影响其健康状况的依赖项。我们需要一个机制来探测我们服务的整体状态，以便更主动地解决问题。

ASP.NET Core 内置了一种报告服务健康状况的机制，它可以非常简单地告诉我们服务是否健康、退化或不健康。我们可以扩展这个功能，不仅报告服务的健康状况，还要考虑对数据库和缓存等依赖服务的连接健康状况。

我们还可以建立各种端点，用于检查不同的结果，例如一般运行时与启动时的健康状况。当我们想要根据我们使用的工具、现有的监控团队或一般的应用程序启动操作对监控操作进行分类时，这种分类非常有用。

我们可以建立存活性检查，这些检查可以定期进行以报告预期运行的应用程序的整体健康状况。只要出现不健康的结果，我们就会采取行动，这将是我们的日常维护和保养活动的一部分。然而，当分布式应用程序启动时，并且多个服务相互依赖时，我们希望在启动依赖于它的服务之前，准确确定哪个依赖服务是健康和可用的。这类检查被称为就绪性检查。

由于分布式应用中需要跟踪的服务复杂性和数量往往很大，我们尽可能地自动化我们的托管、部署和监控任务。容器化，我们将在稍后讨论，是一种以轻量级和稳定的方式托管我们的应用程序的标准方法，而编排工具如 Kubernetes 使我们能够轻松地对服务和容器进行健康检查，这将告诉我们基础设施的健康状况。最终，我们可以利用几个自动化工具来监控和报告我们的服务和依赖项。

我们花了一些时间探索围绕我们的微服务及其相互关系的细微差别。然而，我们还没有讨论围绕一个或多个需要与多个服务相关联的客户端应用程序的细微差别。

# API 网关和前端后端

基于微服务架构的应用程序将有一个用户界面，该界面将与多个网络服务交互。回想一下，我们的服务已经被设计来统治一个业务领域，并且用户完成的许多操作跨越了多个领域。因此，客户端应用程序需要了解服务以及如何与它们交互以完成一个操作。通过扩展，我们可以在 Web 和移动应用程序中拥有多个客户端。

问题在于，我们需要在客户端应用程序中实现过多的逻辑来支持所有服务调用，这可能导致客户端应用程序变得冗长。随着我们引入的新客户端越来越多，维护工作也会变得更加痛苦。这里的解决方案是将我们的微服务的入口点进行整合。这被称为 API 网关，它将位于服务和客户端应用程序之间。

API 网关允许我们将所有服务集中在一个单一端点地址之后，这使得实现 API 逻辑变得更加容易。在请求发送到中央端点之后，它会被路由到适当的微服务，这些微服务存在于不同的端点。API 网关允许我们为应用中的所有端点地址创建一个中央注册表，并在需要时添加中间操作来处理请求和响应数据。为此操作提供便利的技术包括一个轻量级的 ASP.NET Core 应用程序，称为**Ocelot**。至于云选项，我们可以转向 Azure API 管理。

现在我们有了网关，我们遇到了另一个问题，即我们有多位客户端，每个客户端都有不同的 API 交互需求。例如，移动设备将需要与 Web 和智能设备客户端应用程序不同的缓存和安全权限。在这种情况下，我们可以实现后端为前端模式。这比听起来简单得多，但需要正确实施才能有效，并可能导致额外的托管和维护成本。

这种模式要求我们提供一个专门配置的网关，以满足目标客户端应用程序的需求。如果我们的医疗保健应用程序需要被 Web 和移动客户端访问，我们将实现两个网关。每个网关将公开一个相关的客户端将使用的特定 API 端点。

现在我们正在为各种客户端应用程序和设备提供服务，我们需要考虑便于任何客户端应用程序的安全选项。

# 携带者令牌安全性

安全性是应用开发中需要正确处理的基本部分之一。发布无法控制用户访问和权限的软件，从长远来看可能会产生不利影响，并允许我们的应用程序被利用。

使用 ASP.NET Core，我们可以访问一个名为 `Identity Core` 的身份验证库，它支持多种身份验证方法，并允许我们轻松地将身份验证集成到我们的应用程序和支持数据库中。它为我们在 Web 应用程序中实现的多种身份验证方法和授权规则提供了优化的实现，并允许我们轻松地保护应用程序的某些部分。

通常，我们使用身份验证来识别试图访问我们系统的用户。这通常需要用户输入用户名和密码。如果他们的信息可以验证，我们可以检查他们被授权执行的操作，然后使用他们的基本信息创建一个会话。所有这些操作都是为了简化用户体验，使用户能够根据需要自由地使用应用程序的不同部分，而无需在每一步重新进行身份验证。这个会话也被称为状态。

在 API 开发中，我们没有创建会话或维护状态的便利。因此，我们需要用户对受保护的 API 端点进行每次请求的身份验证。这意味着我们需要一种有效的方法来允许用户在每次请求中传递他们的信息，评估它，然后发送适当的响应。

携带者令牌是当前行业标准的支持这种无状态身份验证需求的方法。携带者令牌在初始身份验证尝试之后生成，此时用户分享他们的用户名和密码。一旦信息得到验证，我们检索关于用户的一些信息，这些信息我们称之为声明，并将它们组合成一个编码的字符串值，我们称之为令牌。然后，这个令牌作为 API 响应返回。

触发初始身份验证调用的应用程序需要存储此令牌以供将来使用。

现在用户已经颁发了一个令牌，任何后续的 API 调用都需要包含这个令牌。当 API 收到后续请求以保护端点时，它将检查 API 请求的头部部分是否存在令牌，然后尝试验证令牌以进行以下操作：

+   **受众**：这是一个表示预期接收令牌的应用程序的值

+   **发行者**：这表明了颁发给令牌的应用程序

+   **过期日期和时间**：令牌有生命周期，因此我们确保令牌仍然可用

+   **用户声明**：这些信息通常包括用户的角色以及他们被授权执行的操作

我们可以在每次带有令牌的请求到来时评估我们希望验证的所有点；验证规则越严格，就越难有人伪造或重复使用令牌在 API 上。

保护一个 API 足够简单，但当这种努力分散到多个 API 上时，例如在基于微服务的应用程序中，这会变得非常繁琐且难以管理。当用户在访问可能使用不同服务来完成任务的程序的不同部分时需要多次进行身份验证，这不是一个好的体验。我们需要一个中央权威机构来颁发和验证令牌，所有服务都可以利用它。本质上，我们需要能够使用一个令牌并在多个服务中验证用户。

面对这一新的挑战，我们需要使用 OAuth 提供商来集中保护我们的服务，并处理我们的用户信息和验证。OAuth 提供商应用程序的配置和启动可能需要一些时间，因此一些公司提供 OAuth 服务作为 SaaS 应用程序。设置和托管您的 OAuth 提供商实例有几种选择，但这将需要更多的维护和配置工作。自托管的好处是您对系统和您实施的安保措施有更多的控制。

Duende IdentityServer 是 OAuth 提供商更著名的自托管选项。它基于 ASP.NET Core，并利用 Identity Core 功能来提供行业标准的安全措施。对于小型组织是免费的，可以部署为一个简单的 Web 服务和我们的微服务的中央安全权威。他们也有托管模式，可以与其他托管选项进行比较，例如 Microsoft Azure AD 和 Auth0 等。

现在我们已经探讨了保护我们的微服务，我们需要找出最佳方式来托管它们以及它们的各种依赖项。我们是使用一组 Web 服务器，还是存在更高效的选项？

# 容器和微服务

我们通常可以在一个服务器上托管一个 Web 应用程序或 API 及其支持数据库。这样做是有道理的，因为所有东西都在一个地方，易于访问和维护。但这个服务器也需要非常强大，并配备多个应用程序和进程来支持应用程序的不同部分。

因此，我们应该考虑将托管考虑因素分开，并将 API 和数据库放置在不同的机器上。这会花费更多，但我们可以更好地维护或托管，并确保我们不会因为不需要的应用程序而给机器或环境带来负担。

当处理微服务时，在尝试为多个服务复制这些托管考虑因素时，我们会遇到一个具有挑战性的情况。我们希望每个微服务在功能和托管方面都是自治的。我们的服务应尽可能少地共享基础设施，因此我们不希望在一个机器上放置超过一个服务。我们也不希望让单个设备负担支持多个托管环境的要求，因为每个微服务可能都有不同的需求。

我们转向容器托管作为一种轻量级的替代方案，以配置多个机器。每个容器代表机器资源的一部分，具有为应用程序运行所需的优化存储和性能资源。将这个概念转化为我们的托管需求，我们可以为每个微服务、数据库和所需的第三方服务创建这些优化环境的切片。

这里的优势是，我们仍然可以为每个服务及其支持数据库创建最佳托管环境，所需机器数量远少于支持这项工作。另一个好处是，每个容器都基于一个镜像，代表容器环境的精确需求。这个镜像是可以重复使用的，因此我们在环境转换和尝试为每个服务配置环境时，要担心的事情更少。这个镜像将始终产生相同的容器，并且在部署过程中不会有惊喜。

容器在开发社区中得到广泛使用和支持。首选的容器托管选项是 Docker，这是一家行业领先的容器技术提供商。Docker 提供了一个广泛的容器镜像库，我们可以利用它来获取从流行的第三方应用程序中提取的安全和可维护的镜像，这些应用程序通常在开发过程中被使用。它也是一个开放的社区，因此我们可以为我们的需求创建容器，并将它们添加到社区存储库中，以便以后访问，无论是公共还是私人用途。

当使用 .NET 时，我们可以生成一个 `Dockerfile`，这是一个包含有关应使用以创建我们希望托管的服务容器的镜像声明的文件。这个 `dockerfile` 使用一种名为 **Yet Another Markup Language** (**YAML**) 的语言编写，概述了一个基础镜像，然后是特殊的构建和部署指令。基础镜像声明我们从现有镜像中借用信息，然后我们声明希望在将现有镜像和此应用程序结合后，将我们的应用程序部署到容器中。

当我们使用容器托管时，为每个服务生成一个 `dockerfile`，我们需要编排它们启动的顺序及其依赖关系。例如，我们可能不希望在支持数据库的容器启动之前启动服务。为此，我们必须使用一个编排器。行业领先的选项包括 `docker-compose` 和 Kubernetes。

`docker-compose` 是容器编排操作简单易懂的选项。`docker-compose` 将引用每个 `dockerfile`，并允许我们概述在执行此 `dockerfile` 时希望包含的任何独特参数。我们还可以概述依赖关系，并为该 `dockerfile` 的执行和生成的容器提供特定的配置值。现在，我们可以使用一条命令编排容器的供应，以支持我们的网络服务、数据库和其他应用程序。我们甚至可以重用 dockerfile 来创建多个容器，并在不同的端口上拥有具有相同服务但可能具有不同配置的多个容器。在实现前端模式的后端时，我们可以看到这在哪里非常有用。

容器托管是平台无关的 - 我们可以利用多种托管选项，包括云托管选项。主要云托管提供商，如微软 Azure 和亚马逊网络服务，提供容器托管和编排支持。

现在我们已经解决了托管问题，我们需要能够跟踪应用程序中发生的事情。每个服务都应该提供其活动的日志，更重要的是，我们需要能够跨各种服务追踪日志。

# 集中日志

日志是部署后和维护操作的重要组成部分。一旦我们的应用程序已经部署，我们需要能够跟踪和追踪应用程序中的错误和瓶颈。当我们只有一个应用程序和一个日志源时，这很容易实现。我们总是可以到一个地方检索已经发生的事情的日志。

.NET 对简单到高级的日志选项提供原生支持。我们可以利用原生的日志操作，并支持与多个日志目标强大的集成，如下所示：

+   **控制台**：在原生控制台窗口中显示日志输出。通常在开发期间使用。

+   **Windows 事件日志**：也称为事件查看器，这是在基于 Windows 的机器上查看多个应用程序日志的便捷方式。

+   **Azure 日志流**：Azure 有一个中央日志服务，支持应用程序的日志记录。

+   **Azure 应用洞察**：由 Microsoft Azure 提供的强大日志聚合服务。

在编写日志时，我们需要决定我们要记录的信息类型。我们希望避免记录敏感信息，例如可能损害用户或系统信息的信息，因为我们希望尽可能保护我们系统的完整性和用户机密。这将与应用程序运行的环境相关。然而，在这个范围界定练习中，我们必须行使责任、智慧和成熟度。我们还希望考虑我们不想在日志中包含太多杂乱无章的内容。拥有冗长的日志可能和没有日志一样糟糕。

我们还希望确保为每条日志消息选择正确的分类。我们可以将日志消息记录为以下任何级别：

+   **信息**：关于操作的通用信息。

+   **调试**：通常用于开发目的。不应在实时环境中可见。

+   **警告**：表示某事可能没有按预期进行，但不是系统错误。

+   **错误**：当操作失败时发生。通常在捕获并/或处理异常时使用。

+   **严重/致命**：用于突出显示操作失败并导致系统故障。

为日志消息选择正确的分类对于帮助操作团队监控和跟踪需要优先处理的消息大有裨益。

我们还可以为每个日志目标添加独特的配置，并微调每个目标将接收的消息类型。如果我们只想将信息性消息记录到 Windows 事件日志，并且所有警告、错误和严重消息都应该在 Azure 日志流和应用洞察中可见，这种能力就变得相关了。.NET Core 允许我们进行这些细粒度的调整。

我们可以通过使用扩展包，如 `Serilog` 来进一步扩展原生日志库的功能。`Serilog` 是在 .NET 应用程序中使用最广泛的日志扩展库。它支持更多的日志目标，例如滚动文本文件、数据库（SQL Server、MySQL、PostgreSQL 等）和云提供商（Microsoft Azure、Amazon Web Services 和 Google Cloud Platform）等。我们可以通过在应用程序中包含此扩展包，将每个日志消息写入多个目标。

个人应用程序的日志记录可以相对快速地设置起来，但当尝试关联日志时，这个概念会变得复杂。当用户在访问某个功能时遇到困难，我们需要检查几个可能的问题点，考虑到我们的微服务应用程序将在多个服务中触发多个操作。我们需要一种有效的方法来汇总每个服务产生的日志，并且通过扩展，能够追踪和关联与单个操作相关的调用。

现在，我们转向日志聚合平台。简单来说，它们充当日志目的地，旨在存储写入它们的所有日志。它们还提供了一个具有高级查询支持的用户界面。这对于分布式应用程序是必要的，因为我们现在可以将聚合器配置为多个应用程序的中心日志目的地，并且我们可以更容易地查询日志以找到可能相关但来自不同来源的日志。我们还可以配置它们在接收到特定分类的日志时进行监控和警报。

日志聚合的流行选项包括**Seq**、**Elasticsearch、Logstash 和 Kibana**（**ELK**）堆栈，以及托管选项，如**Azure Application Insights**和**DataDog**。每个平台都有其优势和劣势，并且可以用于从小型到大型应用程序。Seq 是小型到中型应用程序的流行选择，它具有易于使用的工具并支持强大的查询操作。然而，聚合器有一些限制，这些限制在我们需要正确跟踪来自多个来源的日志时会出现。

从多个来源跟踪日志被称为分布式日志。这涉及到我们在日志消息中使用常见信息，并跟踪相关的标签和跟踪 ID，以将日志关联到单个事件。这要求我们编写包含更多详细信息和大头信息的丰富日志，以便日志跟踪工具可以使用并提供关于最佳可能信息的。支持这一概念的新兴技术是**OpenTelemetry**，它将从我们的各种应用程序中生成更详细和关联的日志。

我们现在可以使用更专业的工具，如**Jaeger**，来筛选丰富的日志并在日志之间执行更复杂的查询。Jaeger 是一个免费、轻量级且开源的工具，可以帮助我们开始这个概念，但我们还可以再次使用 Microsoft Azure Insights 来处理生产工作负载。

# 摘要

在本章中，我们探讨了微服务的各个组成部分以及我们如何利用不同的开发模式来确保我们交付一个稳定且可扩展的解决方案。我们看到了微服务架构在引入每个解决方案时都存在问题，我们需要确保我们了解我们做出的每个决定的全部潜在问题。

最终，我们需要确保我们正确评估和界定我们应用程序的需求，并避免在不必要的情况下引入微服务架构。如果我们最终使用了微服务架构，我们必须确保我们充分利用支持我们应用程序的各种技术和技巧。在以高级架构的名义引入复杂性之前，始终寻求采取最必要的措施来解决一个问题。

我希望您喜欢这次旅程，并且有足够的信息来指导您在开始使用 ASP.NET 开发微服务时将涉及到的决策和开发过程。
