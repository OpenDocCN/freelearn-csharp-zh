["```cs\n#include \"opencv2/objdetect.hpp\"\n#include \"opencv2/highgui.hpp\"\n#include \"opencv2/imgproc.hpp\"\n#include <iostream>\n#include <stdio.h>\nusing namespace std;\nusing namespace cv;\n```", "```cs\nstruct Circle\n{\nCircle(int x, int y, int radius) : X(x), Y(y), Radius(radius) {}\nint X, Y, Radius;\n};\n```", "```cs\nCascadeClassifier _faceCascade;\n```", "```cs\nString _windowName = \"OpenCV\";\n```", "```cs\nVideoCapture _capture;\n```", "```cs\nint _scale = 1;\n```", "```cs\nextern \"C\" int __declspec(dllexport) __stdcall  Init(int& outCameraWidth, int& outCameraHeight)\n{\n```", "```cs\nif (!_faceCascade.load(\"lbpcascade_frontalface.xml\"))\nreturn -1;\n```", "```cs\n_capture.open(0);\n```", "```cs\nif (!_capture.isOpened())\nreturn -2;\n```", "```cs\noutCameraWidth = _capture.get(CAP_PROP_FRAME_WIDTH);\n```", "```cs\noutCameraHeight = _capture.get(CAP_PROP_FRAME_HEIGHT);\nreturn 0;\n}\n```", "```cs\nextern \"C\" void __declspec(dllexport) __stdcall  Close()\n{\n_capture.release();\n}\n```", "```cs\nextern \"C\" void __declspec(dllexport) __stdcall SetScale(int scale)\n{\n_scale = scale;\n}\n```", "```cs\nextern \"C\" void __declspec(dllexport) __stdcall Detect(Circle* outFaces, int maxOutFacesCount, int& outDetectedFacesCount)\n{\nMat frame;\n_capture >> frame;\n```", "```cs\nif (frame.empty())\nreturn;\n```", "```cs\nstd::vector<Rect> faces;\n```", "```cs\nMat grayscaleFrame;\n```", "```cs\ncvtColor(frame, grayscaleFrame, COLOR_BGR2GRAY);\nMat resizedGray;\n```", "```cs\nresize(grayscaleFrame, resizedGray, Size(frame.cols / _scale, frame.rows / _scale));\nequalizeHist(resizedGray, resizedGray);\n```", "```cs\n_faceCascade.detectMultiScale(resizedGray, faces);\n```", "```cs\nfor (size_t i = 0; i < faces.size(); i++)\n{\nPoint center(_scale * (faces[i].x + faces[i].width / 2), _scale * (faces[i].y + faces[i].height / 2));\nellipse(frame, center, Size(_scale * faces[i].width / 2, _scale * faces[i].height / 2), 0, 0, 360, Scalar(0, 0, 255), 4, 8, 0);\n```", "```cs\noutFaces[i] = Circle(faces[i].x, faces[i].y, faces[i].width / 2);\noutDetectedFacesCount++;\n```", "```cs\nif (outDetectedFacesCount == maxOutFacesCount)\nbreak;\n}\n```", "```cs\nimshow(_windowName, frame);\n```", "```cs\nusing System.Runtime.InteropServices;\n```", "```cs\ninternal static class OpenCVWrapper\n{\n```", "```cs\n [DllImport(\"UnityOpenCVSample\")]\n internal static extern int Init(ref int outCameraWidth, ref int outCameraHeight);\n```", "```cs\n[DllImport(\"UnityOpenCVSample\")]\n internal static extern int Close();\n```", "```cs\n[DllImport(\"UnityOpenCVSample\")]\n internal static extern int SetScale(int downscale);\n```", "```cs\n[DllImport(\"UnityOpenCVSample\")]\n internal unsafe static extern void Detect(CvCircle* outFaces, int maxOutFacesCount, ref int outDetectedFacesCount);\n }\n```", "```cs\n [StructLayout(LayoutKind.Sequential, Size = 12)]\n public struct CvCircle\n {\n public int X, Y, Radius;\n }\n```", "```cs\nusing UnityEngine;\nusing System.Collections;\nusing System.Collections.Generic;\n```", "```cs\npublic class OpenCVFaceDetection : MonoBehaviour\n{\n```", "```cs\n public Camera camera;\n public static List<Vector2> NormalizedFacePositions { get; private set; }\n public static Vector2 CameraResolution;\n private const int DetectionDownScale = 1;\n private bool _ready;\n private int _maxFaceDetectCount = 5;\n private CvCircle[] _faces;\n private Quaternion baseRotation;\n private WebCamTexture webCamTexture;\n```", "```cs\nvoid Start()\n {\n int camWidth = 0, camHeight = 0;\n webCamTexture = new WebCamTexture();\n Renderer renderer = GetComponent<Renderer>();\n renderer.material.mainTexture = webCamTexture;\n baseRotation = transform.rotation;\n webCamTexture.Play();\n camWidth = webCamTexture.width;\n camHeight = webCamTexture.height;\nint result = OpenCVWrapper.Init(ref camWidth, ref camHeight);\n if (result < 0)\n {\n if (result == -1)\n {\n Debug.LogWarningFormat(\"[{0}] Failed to find cascades definition.\", GetType());\n }\n else if (result == -2)\n {\n Debug.LogWarningFormat(\"[{0}] Failed to open camera stream.\", GetType());\n }\n return;\n }\nCameraResolution = new Vector2(camWidth, camHeight);\n _faces = new CvCircle[_maxFaceDetectCount];\n NormalizedFacePositions = new List<Vector2>();\n OpenCVWrapper.SetScale(DetectionDownScale);\n _ready = true;\n}\n```", "```cs\nvoid OnApplicationQuit()\n {\n if (_ready)\n {\n OpenCVWrapper.Close();\n }\n }\n```", "```cs\nvoid Update()\n {\n if (!_ready)\n {\n return;\n }\n transform.rotation = baseRotation * Quaternion.AngleAxis(webCamTexture.videoRotationAngle, Vector3.up);\n\nint detectedFaceCount = 0;\n unsafe\n {\n fixed (CvCircle* outFaces = _faces)\n {\n OpenCVWrapper.Detect(outFaces, _maxFaceDetectCount, ref detectedFaceCount);\n }\n }\n\nNormalizedFacePositions.Clear();\n for (int i = 0; i < detectedFaceCount; i++)\n {\n NormalizedFacePositions.Add(new Vector2((_faces[i].X * DetectionDownScale) / CameraResolution.x, 1f - ((_faces[i].Y * DetectionDownScale) / CameraResolution.y)));\n }\n }\n}\n```"]