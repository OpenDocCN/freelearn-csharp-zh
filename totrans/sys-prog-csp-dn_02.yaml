- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The One Where Speed Matters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Writing* *for performance*'
  prefs: []
  type: TYPE_NORMAL
- en: Most users agree that applications can never be fast enough. Anytime you talk
    to people about what annoys them in a piece of software, performance, or lack
    thereof, it is the one thing that gets to the top of the list.
  prefs: []
  type: TYPE_NORMAL
- en: 'And that makes sense: we are all busy, and we certainly don’t want to spend
    time waiting for a piece of machinery to catch up with us. It has to be the other
    way around!'
  prefs: []
  type: TYPE_NORMAL
- en: 'But if you think about it, you’ll realize it is a miracle that computers can
    do anything at all within a reasonable time. If you think you’re busy, just look
    at everything computers need to do! You can do the following experiment:'
  prefs: []
  type: TYPE_NORMAL
- en: Reboot your computer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Start (if you’re using Windows) Task Manager (hint: use the *Ctrl* + *Shift*
    + *Esc* combination).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Look at how much stuff is going on in the section background processes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All of those processes are examples of system programming. They are all there
    to help the system do its job or to help the user-facing software get things done.
    And there are a lot of them. These processes all take up a bit of CPU time, a
    bit of networking, and some memory. Most are dormant and just waiting for something
    interesting to happen, but they are still there. They take away resources from
    the user-facing software.
  prefs: []
  type: TYPE_NORMAL
- en: I guess it is pretty clear that system software needs to be as small and as
    fast as possible so that there are enough resources left for the rest of the system
    – that is, the part the user cares about. The next chapter deals with making it
    small (or as memory-efficient as possible).
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will cover the following topics
  prefs: []
  type: TYPE_NORMAL
- en: Why does speed matter?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the **Common Type** **System** (**CTS**)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the difference between value types and reference types?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What has boxing got to do with performance, and what is it anyway?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to choose the right data structures and algorithms to be as fast as possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do strings work and how can we make them faster?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is unsafe code and how can we deal with it safely?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some compiler flags that help speed things up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To summarize, this chapter will show you how to make your systems as fast as
    possible. So, buckle up; we are about to go fast!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will find all the code in this chapter in the following link: [https://github.com/PacktPublishing/Systems-Programming-with-C-Sharp-and-.NET/tree/main/SystemsProgrammingWithCSharpAndNet/Chapter02](https://github.com/PacktPublishing/Systems-Programming-with-C-Sharp-and-.NET/tree/main/SystemsProgrammingWithCSharpAndNet/Chapter02).'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the stage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we’ve established that we need as much performance as possible to allow
    the other systems to do their things. But there are other reasons you might want
    to optimize your code:'
  prefs: []
  type: TYPE_NORMAL
- en: Accessibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hosting costs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Planned obsolescence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Energy usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s examine these one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Accessibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Whenever I mention accessibility to software developers, they usually think
    about making software useable for people with physical challenges. I like to think
    a bit broader. Not everybody can afford the latest and fastest hardware. Many
    people need to make do with older, slower machines. Suppose your code slows that
    already sluggish machine down. In that case, you might be responsible for these
    people not being able to use the device anymore.
  prefs: []
  type: TYPE_NORMAL
- en: Other people use shared devices. Often found in institutions, more than one
    person uses these devices, and everybody adds their software. If your software
    slows the machine down, it affects everybody.
  prefs: []
  type: TYPE_NORMAL
- en: Hosting costs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More software these days runs in the cloud, in which case you have to pay per
    usage. If your software requires a lot of horsepower to run, it might increase
    costs. When added up, every bit of performance loss impacts the monthly cloud
    provider bill.
  prefs: []
  type: TYPE_NORMAL
- en: Planned obsolescence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Machines have a fiscal lifetime and an economic lifetime. These lifetimes determine
    when the company decides to replace the device. The fiscal lifetime is easy to
    calculate: when the organization buys a machine, the accountants tell you in how
    many years the value is too low to keep it around. They take the purchase price,
    calculate the depreciation for each year, and make notes of that in their spreadsheets.
    I’m oversimplifying things here, but I’m not an accountant.'
  prefs: []
  type: TYPE_NORMAL
- en: The economic lifetime is harder to calculate. This lifetime is usually when
    a machine becomes so unusable that it is no longer worth upgrading or investing
    in. A computer that becomes too slow to be used should be replaced, even if the
    fiscal lifetime hasn’t expired.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your software could lead to that happening. If your performance is too low,
    the organization could write off the machine earlier than desired. And that leads
    to much e-waste: perfectly good computers get replaced simply because the software
    was written less-than-perfectly.'
  prefs: []
  type: TYPE_NORMAL
- en: Energy usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using more CPU power means using more electrical power. You might think it might
    not be such a big difference, but in the end, all those machines use a lot of
    energy worldwide. Writing your code as efficiently as possible saves power usage
    and helps the environment. It’s as simple as that.
  prefs: []
  type: TYPE_NORMAL
- en: Performance can be gained in a lot of places, even in pieces of your code where
    you deal with the humble integer. Let’s discuss that!
  prefs: []
  type: TYPE_NORMAL
- en: Which integer is the fastest?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Choosing the right type of integer to use can have an impact on the performance
    of your system. I wouldn’t worry too much about this: the CLR is pretty good at
    optimizing your code, and the `for` loop that iterates over a piece of code. If
    we have less than 255 iterations, we might be tempted to use a byte. After all,
    a byte is just 1 byte. If you use an integer, it will be 4 bytes. That is more
    memory and probably takes longer to process, right?'
  prefs: []
  type: TYPE_NORMAL
- en: Wrong!
  prefs: []
  type: TYPE_NORMAL
- en: Don’t try to outsmart the compiler. It knows the system a lot better than you
    do.
  prefs: []
  type: TYPE_NORMAL
- en: Let me show you.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the following four lines of C# code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We set four variables to some values. The following table describes the specifics
    of each type:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **C# Type** | **Short Name** | **Description** | **MaxValue (Hexadecimal)**
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| System.Byte | byte | A byte | 0xFF |'
  prefs: []
  type: TYPE_TB
- en: '| System.UInt16 | ushort | Unsigned 16-bit integer | 0xFFFF |'
  prefs: []
  type: TYPE_TB
- en: '| System.UInt32 | uint | Unsigned 32-bit integer | 0xFFFFFFFF |'
  prefs: []
  type: TYPE_TB
- en: '| System.UInt64 | ulong | Unsigned 64-bit integer | 0xFFFFFFFFFFFFFFFF |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.1: Numeric types with their maximum values'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s examine what the compiler makes out of it. If you want to see this for
    yourself, create a new C# console program in Visual Studio (using .NET 7 or .NET
    8), use top-level statements, and copy those four lines. Then, set a breakpoint
    on the first line and run it. As soon as you hit the breakpoint, press *Ctrl*
    + *K*, *G*. Doing that opens the disassembler.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll get something like this (I’ve cut some of the code that isn’t that useful
    to us here):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: I know I promised we wouldn’t be doing assembly programming, but you need to
    know what’s happening if you want your code to run as fast as possible. Let me
    talk you through it.
  prefs: []
  type: TYPE_NORMAL
- en: Lines 1, 3, 5, and 7 are comment lines that show the C# code that resulted in
    this assembly.
  prefs: []
  type: TYPE_NORMAL
- en: On line 2, we can see the code the CPU handles when we want it to set the value
    to a variable. The actual command is MOV, which means move. It then takes two
    parameters. The first is the target of the MOV, and the second is the value. There
    are several types of MOV commands; this particular one moves a DWORD. In Win32,
    DWORD stands for Double Word, which we know as an unsigned 32-bit integer. We
    are moving the hardcoded value, `0FFh` (255 in decimal), to `[rbp+3Ch]`. In case
    you’re wondering, `rbp` is the stack pointer. So, we’re moving our value, `0xFF`,
    to position 3C on our stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Great. We should know that value types go on the stack instead of the heap.
    Don’t worry if you didn’t realize that. The next chapter is all about memory.
    For now, just accept that we have two types of memory: a small but fast stack
    and a slow but huge heap. This byte goes to the stack.'
  prefs: []
  type: TYPE_NORMAL
- en: Line 4 moves `0xFFFF` to `[rbp+38h]`. Again, we are moving a `DWORD` here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Line 6 does more or less the same: we move `0xFFFFFFFF` to the stack. Again,
    it is a `DWORD`.'
  prefs: []
  type: TYPE_NORMAL
- en: When compiled, a byte, a `UInt16`, and a `UInt32` are considered a `DWORD`.
    There is no difference between them. If you look at the assembly code, there’s
    no way of knowing what type the C# intended to use. That means there is no difference
    in performance here when using an 8-bit byte or a 32-bit unsigned integer. And
    in case you’re wondering, the signed 32-bit integer looks the same, with the difference
    that `Int32.MaxValue` is half the value of `UInt32.MaValue`. However, the compiled
    code is the same.
  prefs: []
  type: TYPE_NORMAL
- en: Look at the code to copy the 64-bit integer to the stack. That works quite differently.
    On line 8, we move `0xFFFFFFFF` to a register (a register is a special piece of
    memory inside the CPU that holds temporary variables). Then, we call CDQE. That
    copies whatever is in the EAX register (which can hold 32 bits) into the `RAX`
    register, which can hold 64 bits. Then, on line 10, it copies the first 32 bits
    of the contents to the stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, setting a variable to `Int64.MaxValue` involves a lot more
    work than the other three variants. It is considerably slower: the CPU has to
    do a lot more.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However – and this is important – this might not always be the case. This is
    what happens on my modern, beefy 64-bit Windows 11 machine. Things might be completely
    different on a low-powered Raspberry PI running Linux on an ARM processor. And
    that is one of the challenges of system programming: you must know how types behave
    to have the highest possible performance.'
  prefs: []
  type: TYPE_NORMAL
- en: I think it’s time to discuss the CTS.
  prefs: []
  type: TYPE_NORMAL
- en: The CTS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The CTS is a set of rules describing the types that are used in a .NET program.
    That’s it. Nothing binary is going on; it is just a set of rules – a standard
    that compilers, languages, and the runtime must adhere to.
  prefs: []
  type: TYPE_NORMAL
- en: There are several different languages available on .NET Framework. Microsoft
    has C#, VB.Net, and F#. They also offer J#, a Java variant running on the CLR.
    You can also write .NET programs in C or C++. Other vendors also provide languages
    and tools you can choose from. Think of IronPython or Delphi.NET, for instance.
  prefs: []
  type: TYPE_NORMAL
- en: All these languages must stick to the rules. The compiler must emit IL code
    (again, IL looks like assembly but isn’t). The JIT compiler then takes the IL
    to create machine code the CPU can understand and run.
  prefs: []
  type: TYPE_NORMAL
- en: There is a subset of the rules in the CTS that are called the `[assembly:` `CLSCompliant(true)]`
    attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Our aim here is not to design languages, so we aren’t going to dive deeper into
    this.
  prefs: []
  type: TYPE_NORMAL
- en: All types used in .NET languages must adhere to the CTS rules. This book is
    not about learning to program in .NET. Still, knowing about the inner workings
    is crucial if you’re a system programmer. We will cover just the highlights of
    the CTS here.
  prefs: []
  type: TYPE_NORMAL
- en: Value types and reference types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Later in this chapter, I’ll discuss value and reference types in a lot more
    detail. Here, I will simply say that value types hold their values directly. In
    contrast, reference types are pointers that point to a value somewhere else in
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: Classes and structs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: .NET-based languages are supposed to be object-oriented. From this, it follows
    that the languages should support classes. These classes also have to have specific
    characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Classes** should have visibility. They can be public, internal, protected,
    or private. We all know what those classifiers mean.'
  prefs: []
  type: TYPE_NORMAL
- en: Classes have methods, properties, fields, delegates, and so on. These items
    can be private, protected, or public. You probably already know all of this; I
    don’t have to explain what this all is.
  prefs: []
  type: TYPE_NORMAL
- en: However, a lot of developers struggle with **structs**. To the casual observer,
    they are more or less the same. And yes, they are indeed similar. They can both
    have methods, properties, fields, and so on. They can both implement interfaces.
    And they can both have static members.
  prefs: []
  type: TYPE_NORMAL
- en: The differences between classes and structs are more interesting. First, a class
    instance lives on the heap, and you will get a pointer that you store in the stack.
    However, a struct lives on the stack.
  prefs: []
  type: TYPE_NORMAL
- en: Since the variable that “holds” the class is the pointer to the heap memory
    where the data is stored, that variable can be null. In that case, it points to
    nothing; it is just a placeholder for a future instance of that class.
  prefs: []
  type: TYPE_NORMAL
- en: 'A struct cannot be null. There is an edge case: nullable types such as `MyStruct?`
    can be null, but that is the whole point of nullable types. Structs cannot inherit
    from each other. They can implement interfaces, though, just like classes can.
    That also means you cannot have an “abstract” or “sealed” struct. Those two modifiers
    are meant for classes that must be inherited. Since we cannot inherit from structs,
    this doesn’t make sense.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at this, you might think that a class is a better choice: there are
    only a few downsides and a lot of upsides in using them over structs. And you’re
    not wrong. But structs have one significant advantage over classes: they are initialized
    on the stack, not the heap. And as I said previously, the stack is way faster
    than the heap. Since we aim for maximum performance, structs are used much more
    in our applications than in others.'
  prefs: []
  type: TYPE_NORMAL
- en: Floating-point numbers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We already saw that it doesn’t matter what kind of integer you use for most
    cases. UInt64, Int64, UInt128, and Int128 are generally slower than the other
    types, so only use them when you have thought it through and decided you need
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Things are a bit different for floating-point numbers, however. We have three
    floating-point types in the CLS and, thus, in C#. Please look at the following
    table to see which ones they are:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Type** | **C# Type** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| float | `System.Single` | 32-bit single-precision floating-point |'
  prefs: []
  type: TYPE_TB
- en: '| double | `System.Double` | 64-bit double-precision floating-point |'
  prefs: []
  type: TYPE_TB
- en: '| decimal | `System.Decimal` | The 128-bit decimal type is more precise but
    has a smaller range than a double |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.2: Floating-point types'
  prefs: []
  type: TYPE_NORMAL
- en: Which type you choose depends on your scenarios. You must select a decimal over
    a float if you need more precision. That would be obvious. But things are slightly
    more complicated if you don’t need the 128-bit precision a decimal gives you.
  prefs: []
  type: TYPE_NORMAL
- en: On a 64-bit machine, the double (`System.Double`) is the fastest floating-point
    number. The CPU can understand this natively, so no conversions are needed. Performance-wise,
    this is your best choice. However, a float (`System.Single`) is more memory efficient.
    However, this is only true on a 64-bit machine. If you’re targeting other platforms,
    the results might be different. For instance, if you want to run your code on
    an ARM-based device such as a Raspberry Pi, you will find that the CPU is optimized
    for the float type. So, you would be better off using a single-precision variety
    if you care about performance. Again, if your use case needs a higher precision,
    please use one of the other types. They are here for a reason, after all.
  prefs: []
  type: TYPE_NORMAL
- en: Where types live – the difference between value types and reference types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Types in the CTS can be either a value type or a reference type. It is essential
    to know the difference between these two options. Value types operate on the stack,
    while reference types live on the heap. Stuff residing on the stack is usually
    much faster than what happens on the heap.
  prefs: []
  type: TYPE_NORMAL
- en: From this, you would think using value types on the stack is the best way to
    get your desired sweet performance. Unfortunately, that is not how things work.
    The reference types are there for a reason, and they can give you significant
    performance improvements if used correctly!
  prefs: []
  type: TYPE_NORMAL
- en: The stack and the heap
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before discussing the difference between value types and reference types, we
    need to quickly look at the difference between the stack and the heap. I have
    already mentioned that the stack is faster than the heap but smaller. This is
    true, but there’s a bit more to this.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the differences between the two types of memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Feature** | **Stack** | **Heap** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Allocation/Deallocation | Fast, compile time | Slow, runtime |'
  prefs: []
  type: TYPE_TB
- en: '| Lifespan | Limited to scope | Beyond scope |'
  prefs: []
  type: TYPE_TB
- en: '| Size Limitation | Smaller, fixed-size | Larger, dynamic size |'
  prefs: []
  type: TYPE_TB
- en: '| Data Types | Value types (usually) | Reference types |'
  prefs: []
  type: TYPE_TB
- en: '| Behavior | Deterministic | Non-deterministic |'
  prefs: []
  type: TYPE_TB
- en: '| Fragmentation | No | Possible |'
  prefs: []
  type: TYPE_TB
- en: '| Thread | Thread-specific | Shared between threads |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.3: Differences between stack and heap memory'
  prefs: []
  type: TYPE_NORMAL
- en: The memory allocation for stack variables is done at compile time, and the memory
    is pushed on and popped off the stack. This makes allocation and deallocation
    extremely fast. For heap variables, the memory is allocated dynamically at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: However, the lifespan of variables on the stack is limited to the function’s
    scope or the block of code. Once your code no longer needs that variable, such
    as because you reached the end of a `for` loop, the memory for this variable is
    automatically freed. For the heap, it is up to you or the garbage collector to
    get rid of the memory when it’s unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: The stack is smaller, and you are much more likely to run out of stack memory
    than heap memory. Heap memory can be huge, especially compared to stack memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re wondering how big that stack is, the answer is, “It depends.” You
    can even specify it yourself. Since the stack is tied to a thread, you can set
    the stack size when working with new threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here, we created a new thread and gave it a `1 MB` stack. It’s easy to determine
    this! If you want to limit the amount of memory a thread uses, you can estimate
    how much you need and allocate it that way.
  prefs: []
  type: TYPE_NORMAL
- en: On a side note, most developers know of [https://StackOverflow.com](https://StackOverflow.com).
    Strangely enough, I have met many developers who have no idea where that name
    comes from.
  prefs: []
  type: TYPE_NORMAL
- en: When you create a thread with a given stack size but try to use more memory
    than available, you get a `StackOverflowException` error. That is where that name
    comes from.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me show you. Oh – and don’t use this in production code. This sample is
    just for illustrative purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code calls a recursive function that does one thing: it calls
    itself. When you call a function or a method, the system stores the address to
    return to when the function ends. The system stores this return address on the
    stack. After all, this is short-lived and needs to be fast. You want to continue
    with your regular flow after the function call.'
  prefs: []
  type: TYPE_NORMAL
- en: But this code does nothing except call a function repeatedly and never returns
    from it. Thus, the return address gets added to the stack thousands of times until
    the memory runs out, and you get that famous `StackOverflowException` error.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to experiment with this, run the preceding code in a separate thread
    and give it different stack sizes. Doing this will give you an idea of how significant
    an impact having the correct stack size has.
  prefs: []
  type: TYPE_NORMAL
- en: Boxing and unboxing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, things look pretty straightforward. Value types live in the stack; reference
    types live on the heap. An integer is a value type; thus, you have it on the stack.
    A class you define is on the heap since that is a reference type. If you want
    your class to be faster, you can turn it into a struct and have it available quicker
    since it goes on the stack. You might be thinking this is easy, but you’d be wrong.
    Things can be a lot more complicated than that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at our good friend, the integer. An integer is a whole number, so
    it has no decimal point. As we saw earlier, we have a couple of variations of
    the integer. We have the 16-bit, the 32-bit, the 64-bit, and even a 128-bit version.
    And we have them in signed and unsigned versions. We even have a byte: this is
    technically not an integer, but since it compiles to a DWORD, we can have it in
    the same category. An integer is a value type, so it lives on the stack. However,
    if you look at *Table 2.1*, you’ll see that the official name of an integer is
    `System.Int32`. I don’t know about you, but that looks like a class or a struct
    name.'
  prefs: []
  type: TYPE_NORMAL
- en: A struct still lives on the stack, but it is less performant than you might
    expect compared to a simple integer. Luckily, the compiler helps us with this.
    As we saw earlier, the compiler turns our integers into DWORDs, so there is no
    performance penalty. But sometimes, things work differently. So, we need to talk
    about boxing and unboxing.
  prefs: []
  type: TYPE_NORMAL
- en: 'C# is a genuine object-oriented language. That means everything is an object,
    and all descend from a base class. At the top level, one base class is the ancestor
    of all other classes. That is `System.Object`. Our integer is no different: the
    `System.Int32` struct derives from the `System.ValueType` class, which, in turn,
    is a descendant of `System.Object`. So, we still follow the rules of object orientation.
    Still, there seems to be a mix of classes and structs here. Don’t worry; these
    are semantics, and the compiler deals with them when needed.'
  prefs: []
  type: TYPE_NORMAL
- en: “Dealing with” sometimes means that the runtime converts value types into reference
    types or vice versa. That is what we call boxing and unboxing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Boxing happens when the system converts a value type into a reference type.
    Converting a reference type into a value type is known as unboxing. Think of it
    as putting our value type in a box, in the shape of a class, or getting it out
    again if you go the other way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first line declares a simple 32-bit integer, and we give it a value. We
    saw this previously; this is a relatively simple and fast instruction. In assembly,
    we move a hardcoded value into a DWORD position on the stack.
  prefs: []
  type: TYPE_NORMAL
- en: We want to make a copy of it, but this time, we use an object instead of an
    integer. Since `System.Int32` is derived from `System.Object` (with `System.ValueType`
    in between), you wouldn’t expect this to be that much work. In the end, we still
    have an integer. But things are more complicated. Again, let’s have a look at
    the assembly code. To be clear, you don’t need to know assembly, but it is easier
    to understand how to get the most performance if you know what happens under the
    hood.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, `object o = i` translates to quite a lot of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'I won’t explain everything that’s happening here, but there are a lot of moving
    parts here. Line 3, however, is the important one: `CORINFO_HELP_NEWSFAST` is
    a method in the CLR that allocates memory on the heap. Yes, the heap. Not the
    stack. This is what we call a very expensive operation: it takes a relatively
    long amount of time. After that, much copying occurs, all of which takes time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Compare this with copying that integer variable to another integer without
    going through boxing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This assembly code takes the value of what’s in the `i` variable (in the `[rbp+0x3C]`
    memory location) and moves it to the eax register. Then, it transfers that register
    to `[rbp+0x2C]`, where the new variable, `j`, is.
  prefs: []
  type: TYPE_NORMAL
- en: This was just two quick move calls, from the stack to the register (blazingly
    fast) and from the register back to the stack. That hardly takes time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Going from the heap to the stack seems to be quicker since less coding is going
    on. Here, `int j = (int)o` leads to unboxing. The assembly for that code looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This assembly code doesn’t have that very expensive call to allocate memory.
    This makes sense: the stack doesn’t require this. The stack has a fixed amount
    of memory, so you can use it if needed. If you run out of it, you get the `StackOverflow`
    exception we looked at earlier. The rest is just moving data about. There’s still
    much more code here than what we saw when we copied two integers. Still, it doesn’t
    look that bad, does it?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Don’t be fooled: if we decide to use the `j` variable from now and not use
    `o` anymore, it can be removed from the heap. The garbage collector takes care
    of that, so you don’t have to worry about it. But the garbage collector also comes
    with a lot of performance loss. The garbage collector is the topic of another
    chapter but be assured it can be a huge performance drain. This isn’t obvious
    from this bit of code. There are hidden costs involved.'
  prefs: []
  type: TYPE_NORMAL
- en: Hidden boxing and unboxing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Copying a value type, such as an integer, to a reference type leads to boxing.
    If you can avoid that, you should do so. But sometimes, boxing and unboxing happen
    when you don’t expect it. Look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here, we declare an integer, `i`, in `DoSomething()`. Then, we call `DoSomethingElse()`
    with that integer. The original author of `DoSomethingElse` was trying to write
    the code so it could be reused. So, they decided to accept `System.Object` as
    a parameter. Since everything is, in the end, derived from that, this seems like
    a good idea. But it isn’t. Here, `i` will be boxed before being passed to `DoSomethingElse`,
    along with the performance penalty that happens when boxing.
  prefs: []
  type: TYPE_NORMAL
- en: 'It would be better if the developer wrote the method like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Here, instead of accepting an object, we take a generic type. Since we pass
    it as an integer, the compiler understands that this is a value type and doesn’t
    convert it into an object. No boxing is happening here. This code is a lot faster
    than the previous version.
  prefs: []
  type: TYPE_NORMAL
- en: How about this line of code?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It looks pretty simple. But again, boxing is happening here. Before string concatenation
    can happen, the `i` variable is first boxed to the reference type.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next one is nice as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Value types are part of reference types that usually live on the heap. So, they
    need to be boxed. Getting the values back will then lead to unboxing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving value types to reference types leads to this behavior. Take a look at
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This is safe, right? We aren’t converting; we’re just declaring that we are
    interested in part of the integer that belongs to the `IComparable` interface.
    The `System.Int32` struct implements a lot of interfaces, and this happens to
    be one of them. Still, it is a struct, so all should be good.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s have a quick look at the associated assembly for that simple line of
    C# code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: You should recognize this by now, especially the call to `CORINFO_HELP_NEWSFAST`.
    This is boxing in action. The same happens when using the `IEquatable<int> = 42`
    line. Although we now use a generic, we still get boxing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at one more example. This one is a bit silly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have a string that we appoint to an object, `myString` (that is not
    the silly part). Then, we assign something to `stuff`, depending on `true` being
    true (which it always is; this is the silly part). If `true` is true, we assign
    `42` to stuff. If not, we copy `myString` to `var`. At first glance, you might
    expect `stuff` to be of the `int` type since `true` is always true. But that is
    not how a static-typed language works. It needs to know what type `stuff` is at
    compile time. The conditional operator, `? :`, expects both sides to be equivalent
    types. Thus, it decides that one part is an object and can cast the integer literal
    to an object. Therefore, it boxes that `42` into an object instance, and `stuff`
    here is another object instance. And there you have it: more boxing.'
  prefs: []
  type: TYPE_NORMAL
- en: Boxing and unboxing allow you to mix and match value and reference types. It
    would be tough to write reusable code otherwise. But be aware of this, and be
    mindful of the costs associated with boxing and unboxing. It happens in places
    you might not be aware of. And that results in less-than-stellar performance.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right data structures and algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Object orientation is all about having the data and the operations on that
    data together in a cohesive and loosely coupled structure. That is what classes
    and structs do: they combine the two. This way, you can define your data structures
    in a way that makes sense concerning the system’s functionality.'
  prefs: []
  type: TYPE_NORMAL
- en: But when speaking about performance, other factors come into play. Having static
    classes is usually a code smell that you must avoid. However, they’re fast. You
    don’t need to instantiate something, resulting in that costly call to allocate
    heap memory. And that memory doesn’t need to be cleaned by the garbage collector
    later.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, if you have member variables for that class, you might as well instantiate
    it. Ultimately, all that happens is that those variables end up on the heap (with
    a little bit of housekeeping). The methods themselves are part of your application
    code and are stored differently.
  prefs: []
  type: TYPE_NORMAL
- en: The BCL also has many classes and data structures you can use to store data.
    Some of them are better suited for high performance than others. Which one you
    choose depends on your use case, but I think writing a bit more code is worth
    it if that means you can use a more efficient class.
  prefs: []
  type: TYPE_NORMAL
- en: Arrays, Lists, and LinkedLists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Arrays**, **Lists**, and **LinkedLists** are all structures you can use to
    store data sequentially. That data is stored in the heap as well. Yes, you read
    that correctly. Look at the following two lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The first line is a simple assignment. The system copies the hard-coded value
    of `42` (0x2A in hex) to a DWORD and stores it on the stack. The second line creates
    a new array, allocates memory for that on the heap, initializes the array, and
    then copies `42` into the first position.
  prefs: []
  type: TYPE_NORMAL
- en: Read that again and try to see if you can guess if there’s any boxing going
    on.
  prefs: []
  type: TYPE_NORMAL
- en: You might expect that there is, but there’s no boxing here. The array holds
    a pointer to a place in the heap that contains individual DWORD values. It knows
    how long each value is (32 bits, to be precise), so it can move the values directly
    without changing anything. Also, no unboxing occurs when taking an element from
    the array and storing it in a local variable. The system copies the DWORD value
    and leaves it at that.
  prefs: []
  type: TYPE_NORMAL
- en: 'A list is the same as an array. Internally, the data is stored in an array.
    However, a list offers the option to resize it dynamically. Next to that, it has
    some nice methods such as `Add()`, `Remove()`, and `IndexOf()` that can be very
    helpful. But nothing comes for free: the methods take time to perform, and dynamic
    reallocation is very expensive in terms of performance. You must judge if you
    need those extra methods and dynamic reallocation. If you do, use a list. If you
    can go without, use an array.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is an in-between solution: you can use `List<T>` and initialize it with
    an appropriate size. After all, you must do the same for an array: you need to
    know how big it is. Doing that causes the `List` class to initialize the array
    it uses internally to that exact size, and no reallocations happen – unless, of
    course, you find out you need more room. But that’s great; you don’t run out of
    memory. Yes, you get the performance penalty in that case, but that’s okay. If
    you pre-initialize the `List` class, the performance is almost identical to the
    pure, basic array.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `LinkedList` class has some nice features. It is a double-linked list of
    items, which means each item is accompanied by a pointer to the next and the previous
    object. This means more data is needed to store things: we cannot just store the
    items themselves, but the system must also add those pointers. This results in
    slower behavior: those pointers must also be calculated and copied. So, you might
    think `LinkedList` is wrong when considering performance.'
  prefs: []
  type: TYPE_NORMAL
- en: However, `LinkedList` might be a great choice if your use case requires insertions
    and removals. Inserting an item simply means storing the object and adjusting
    some pointers. In an array or list, inserting would mean moving everything up
    one place in the internal array when you want something to sit in the middle.
  prefs: []
  type: TYPE_NORMAL
- en: Again, use your judgment. If you can, use arrays (or pre-initialized lists),
    go for the uninitialized list, and only then look at `LinkedLists`.
  prefs: []
  type: TYPE_NORMAL
- en: Stacks and queues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Stacks** and **queues** look very similar. They are more or less similar
    performance-wise, with one big difference: a stack is fast if you need to access
    the latest added items, whereas a queue is very fast when you need quick access
    to the items in the order they were entered. In other words, a stack is optimized
    for **last in, first out** (**LIFO**) scenarios, while a queue is better in **first
    in, first out** (**FIFO**) scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: However, your code runs faster if you can think of a way to use a stack instead
    of a queue. A stack is slightly more efficient than a queue in handling its work,
    at least enough to make it worth rewriting your code.
  prefs: []
  type: TYPE_NORMAL
- en: HashSets and lists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A `HashSet`. A `HashSet` can be efficient when you’re adding, removing, or looking
    up items.
  prefs: []
  type: TYPE_NORMAL
- en: 'A `HashSet` has one significant advantage over a list concerning performance:
    a HashSet has a constant-time average complexity for add, delete, and search operations.
    A list, however, has a linear-time search complexity. In everyday English, a HashSet
    always takes the same time to look up items, no matter how many elements it contains.
    A list needs more search time when more items are added to it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But beware: a constant time means the time doesn’t change. This doesn’t imply
    a `HashSet` is faster! Quite the contrary: a `HashSet` can be pretty slow. And
    that makes sense: before an item is added to the `HashSet`, it needs to calculate
    the unique hash for that item. That hash is the key that’s used to store the object’s
    position. And then, it has to check if an object with that hash has already been
    added.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, once this has been done, looking up an item is very quick: it needs
    to have the hash, and then it can find it easily. Also, when you have one of these
    two collections and need to add an item, the HashSet is faster than the list in
    many cases.'
  prefs: []
  type: TYPE_NORMAL
- en: As with most of these cases, look at your requirements and try to do a couple
    of benchmark tests to see what you can use best.
  prefs: []
  type: TYPE_NORMAL
- en: SortedList, SortedDictionary, and Dictionary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`HashSet`, but the big difference is that you can retrieve the items by its
    key in a `Dictionary`. You can retrieve the data in the `HashSet`, but you must
    use a `foreach` statement to get them all or a `Linq` statement such as `Where()`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The keys in the `SortedLis`t, `SortedDictionary`, and `Dictionary` must be
    unique. If your use case allows for that, these collections can do wonders, but
    only if you choose the right one. The following table compares these three types
    in terms of their performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Property** | **Dictionary** **<****TKey, TValue>** | **SortedList** **<****TKey,
    TValue>** | **SortedDictionary <TKey,TValue>** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Underlying data structure | Hash table. | Array for keys, array for values.
    Keys are sorted. | Balanced binary search tree. |'
  prefs: []
  type: TYPE_TB
- en: '| Ordering | No ordering of elements. | Elements are sorted by key. | Elements
    are sorted by key. |'
  prefs: []
  type: TYPE_TB
- en: '| Insertion | *O(1*) average time complexity. | *O(n*) time complexity since
    it might need to shift elements to maintain order. | *O(log n)* time complexity.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Deletion | *O(1)* average time complexity. | *O(n)* time complexity, for
    the same reason as insertion. | *O(log n)* time complexity. |'
  prefs: []
  type: TYPE_TB
- en: '| Lookup | *O(1)* average time complexity. | *O(log n)* time complexity. |
    *O(log n)* time complexity. |'
  prefs: []
  type: TYPE_TB
- en: '| Memory | Generally less memory efficient than SortedList, but better than
    SortedDictionary. | More memory efficient than SortedDictionary since it uses
    arrays for the keys. | Generally less memory-efficient. |'
  prefs: []
  type: TYPE_TB
- en: '| Use-case | When you don’t want ordering but want fast insertions, deletions,
    and lookups. | When you have a relatively small dataset that you want to keep
    sorted and you will be doing lots of lookups. | When you have a larger dataset
    that you want to keep sorted, and you need faster insertions and deletions than
    SortedList offers. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2.4: Key-based collections'
  prefs: []
  type: TYPE_NORMAL
- en: Again, check your requirements and benchmarks to see what works best for you.
  prefs: []
  type: TYPE_NORMAL
- en: Dictionary or last of tuples/objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **List<Tuple>** and a **Dictionary** are different things, but with some rewrites,
    you could use both to achieve your goal.
  prefs: []
  type: TYPE_NORMAL
- en: The lookup speed in the `Dictionary` is very fast. Since you look for the key
    instead of the actual item, you can achieve a much better performance than with
    the list, where you have to iterate through the whole list to find what you need.
    Also, insertion and deletion are fast and constant when using a Dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: However, with a `Dictionary`, the keys need to be unique. With a list, this
    is not necessary. Again, with some rewrites, you might be able to use a `Dictionary`
    instead of a list and benefit from some highly-needed performance gains.
  prefs: []
  type: TYPE_NORMAL
- en: For versus ForEach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**ForEach** is amazing. It helps us write our code so much faster. However,
    it can also slow down our code.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ForEach` is so helpful that the people who built the compiler added all sorts
    of optimizations. ForEach does lots of work: it gets the enumerator and then enumerates
    through the collection using methods such as `MoveNext()`. They all take time,
    and you would think that it is much slower than using a `for` loop. However, these
    optimizations make the difference negligible when using For or ForEach on an array
    or `List<T>`.'
  prefs: []
  type: TYPE_NORMAL
- en: But suppose you use your own collection where you have implemented `IEnumerable<T>`
    and `IEnumerator<T>`. In that case, chances are the C# team did not optimize for
    that in the compiler. That might result in a slower loop than a regular `for`
    loop.
  prefs: []
  type: TYPE_NORMAL
- en: As always, benchmark whether using the much more readable ForEach is better
    than a regular `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: Strings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the old days, strings used to be simple. You identified the length needed
    to store a sentence, allocated memory, and copied each character’s ASCII values
    in a single row. Then, you put a 0 (zero) at the end, and you were done. Easy.
    But then you realized you needed something more dynamic as you were unsure how
    long the string would be. So, you wrote code to change the buffer required to
    store it. You also realized that you needed to have some operations on those characters.
    For instance, you might have wanted to know how long the string was and not have
    to count the characters every time, or maybe you wanted to convert all characters
    into uppercase. So, you wrote code for that as well. At that point, you had some
    data in the form of characters (with the zero at the end) and some methods on
    that data. That is the definition of a class, so in C++, you write a `String`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Things got even more complicated when you realized that other cultures used
    other characters. Luckily, others also realized this, so they created the **Unicode
    standard**. But now, instead of storing a single byte per character, you must
    store a Unicode character. And that can be anything from 8 bits (in UTF-8) to
    4 bytes. Then, you learned that although a single character can take 32 bits,
    that is technically incorrect: that applies to code points. A code point usually
    *is* the character, but sometimes, it isn’t. In those situations, the character
    you want to display has multiple code points in the string. That’s when most people
    give up.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The good news is that you no longer have to worry about that since we have
    the `System.String` class in .NET. It takes care of all of those details, and
    they look deceivingly simple. Assigning a sentence to an instance of that `String`
    class is as simple as the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The first line assigns `"Hello, World!"` to the `someMessage` variable. When
    we do this, the compiler generates all the code necessary to create an instance
    of the `System.String` class and initializes it with the correct text.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following two lines contain the same Unicode characters: a friendly smiley.
    The first uses the Unicode character, while the second uses the actual character.
    Yes, this is valid C#!'
  prefs: []
  type: TYPE_NORMAL
- en: 'Strings are reference types, so they live on the heap. We learned that the
    heap is slower than the stack earlier, but we have no choice in this case. The
    pointer is copied when we copy a reference type to a new variable. This means
    we have two variables pointing to the same data structure. This also happens when
    we copy a string: a new pointer is made and points to that class’s same instance.'
  prefs: []
  type: TYPE_NORMAL
- en: Strings are immutable. You cannot change the contents of a string. If you do
    that, the CLR creates a new string, and the old one is ready to be garbage collected.
    Again, this might lead to unwanted performance issues.
  prefs: []
  type: TYPE_NORMAL
- en: There are some other things we must consider when talking about string performance.
    Let’s go through them.
  prefs: []
  type: TYPE_NORMAL
- en: Use StringBuilder for concatenation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When talking about string performance, this one gets the most attention. And
    for good reason: this simple “trick” can help get your application faster. The
    idea is that when you’re in a loop, do not concatenate strings. Create a `StringBuilder`
    object and use that. The difference in performance is enormous. And that makes
    sense: changing a string is impossible, so each time you add to one, a new one
    is created, the content is copied with the added string on top of it, and the
    old one is discarded.'
  prefs: []
  type: TYPE_NORMAL
- en: Use `StringBuilders` in loops. You can go ahead and just do it.
  prefs: []
  type: TYPE_NORMAL
- en: Interning strings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Strings are interned. If you have a string in your code and the actual text
    is known at compile time, any other string with the same content will point to
    the same class. Have a look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: When you run this code, you will get a message stating that both strings point
    to the same memory location.
  prefs: []
  type: TYPE_NORMAL
- en: But if you read the contents of both strings from the console, use `Console.ReadLine()`.
    If you enter the same string twice, they will not be interned. This is because
    interning happens at compile time.
  prefs: []
  type: TYPE_NORMAL
- en: You could call `String.Intern` yourself. This checks to see if the string you
    wish to intern is already there, and if so, it makes it point to that instead
    of having its own copy. This could save a lot of memory, but it has a performance
    penalty. So, use it wisely.
  prefs: []
  type: TYPE_NORMAL
- en: Use String.Concat or String.Join
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I said that you should use `StringBuilder` when joining strings in a loop. But
    creating a `StringBuilder` object is a bit overkill if you’re outside a loop and
    only want to add to a string once. In that case, you should use `String.Concat`
    or `String.Join`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just to be clear here: if you are looping, use `StringBuilder`. The `StringBuilder`
    object is the fastest way to concatenate strings. But creating an instance of
    a `StringBuilder` class takes time (it is a class, thus on the heap). If you only
    want to add one or two strings to an existing one, `String.Concat` is faster overall
    than having a `StringBuilder` object.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `String.Join` object is another good way to build up strings. You can use
    this one when you want to combine a collection of items into one string. The list
    of items can be anything since the CLR calls `ToString()` on them. Here, `ToString()`
    needs to make sense; otherwise, you’ll get a long list of class names.
  prefs: []
  type: TYPE_NORMAL
- en: 'It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Printing `result` will show `C#,VB.Net,F#,Delphi.Net` on your screen.
  prefs: []
  type: TYPE_NORMAL
- en: Be careful what you use as the list of elements. If those are `ValueTypes`,
    a lot of boxing happens. That negates our performance gain when using the suitable
    string methods.
  prefs: []
  type: TYPE_NORMAL
- en: Comparison
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Chances are that you have to compare strings in your code. There are several
    ways to improve your performance when doing that. For instance, taking into account
    a culture takes a lot longer compared to not doing that. If you don’t need a culture-specific
    check, you should specify that. The same goes for the casing: if you don’t care
    about the casing when comparing, please don’t use one of the comparisons that
    take care of that.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways to compare strings. The most obvious one is the equality
    operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In this case, there’s no comparison at all. Since the compiler interns the strings,
    the pointers point to the same data. The equality checks for that and returns
    `true`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You could also do it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This code does the same thing, with the same caveat concerning the interning.
    Here, `operator == calls Equals()`, so it shouldn’t be surprising that the results
    are the same, with the same performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, look at this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This way of comparing is significantly slower than the previous examples. The
    CLR now has to compare the strings in all their different appearances: in all
    sorts of cultures and all casings.'
  prefs: []
  type: TYPE_NORMAL
- en: This way works brilliantly if you need it, but if you don’t, please omit the
    options!
  prefs: []
  type: TYPE_NORMAL
- en: 'I see many people writing this sort of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This way of comparing is the worst way of doing this. Calling `ToUpper()` doesn’t
    convert a string into all uppercase. Instead, it creates a new string with all
    uppercase characters. Again, strings are immutable, so the runtime creates a new
    one whenever you change something. Here, we are doing that twice so that we can
    compare them.
  prefs: []
  type: TYPE_NORMAL
- en: Using `StringComparison.IgnoreCase` is about five times as fast compared to
    calling `ToUpper()` (or `ToLower()` for that matter).
  prefs: []
  type: TYPE_NORMAL
- en: Preallocating StringBuilder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One final tip: knowing the length of the resulting string when using `StringBuilder`
    helps tremendously if you tell that class about that. Preallocating helps optimize
    the code and reduces many allocations, resulting in better performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Writing unsafe code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A word of warning before we start talking about unsafe code. There is a reason
    it is called “unsafe.” You could be in for much trouble when you leave safe code.
  prefs: []
  type: TYPE_NORMAL
- en: The CLR checks many things for you when you run your code. For instance, it
    ensures type safety and ensures you are not playing around with spaces in memory
    that are not yours to play with.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the “old” days, when using C++ or C in Windows development, this was the
    primary source of program crashes. Developers made a slight mistake in their pointer
    arithmetic and ended up reading or writing memory they had no access to. The operating
    system immediately killed your process, and you got that dreaded `AccessViolationException`
    error. This is the ultimate slap on the wrist: the operating system telling you
    to stay out of someone else’s memory. Sometimes, it would be worse: the operating
    system might not have caught it, and you messed up the operating system or another
    program. That could lead to even worse situations: the whole machine could crash.'
  prefs: []
  type: TYPE_NORMAL
- en: The safe environment of the CLR in .NET has practically removed that completely.
    The CLR governs everything you do and ensures you stay in the areas where you
    are allowed to stay.
  prefs: []
  type: TYPE_NORMAL
- en: You’ve probably realized that this is nice, but checking what’s happening always
    has a performance hit. Nothing comes for free. We give up some performance in
    exchange for a stable system.
  prefs: []
  type: TYPE_NORMAL
- en: If you want that performance back, you could tell the CLR to stay out of your
    way. The CLR will obey and hand over the reins to you. Again, you are on your
    own and responsible for not messing things up. But things run a bit faster now!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider an example.
  prefs: []
  type: TYPE_NORMAL
- en: An array is a pointer to a consecutive list of items. So, `int[1000]` is just
    a pointer to a long list of a thousand integers, all nicely lined up.
  prefs: []
  type: TYPE_NORMAL
- en: You can access these items in the list by giving the array the index of the
    item you want. First, the CLR checks if the array has been initialized and not
    pointing to some weird random place in memory. Then, it checks if your index falls
    in the range that the CLR allocated for the array. If that checks out, it gets
    and returns the item for you. Nice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code example iterates through the array and adds up all the values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This piece of code works nicely, but it can be faster. All those checks take
    time, and we might decide we don’t need them. We tell the CLR to take a break
    and leave it all to us!
  prefs: []
  type: TYPE_NORMAL
- en: 'The following snippet shows how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We declare the block we want to optimize with the `unsafe` keyword. Everything
    in that block is now no longer checked.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we retrieve the pointer to the array. We mark it as `fixed`. This keyword
    means the garbage collector doesn’t move the array until we are done with it.
    It would be disastrous if the garbage collector moved the array to another place
    in memory when we accessed it. The `fixed` keyword prevents that.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we get the pointer to the end of the array in memory so that we know when
    to end. In the `for` loop, we get the pointer to the elements, read the data at
    that memory position, and add the `sum` variable.
  prefs: []
  type: TYPE_NORMAL
- en: This piece of code works fine. It is also faster than the safe version. But
    just for fun, mess around a bit with the pointers. Instead of letting it end at
    the end of the array, let it end at that position plus `0xFFFF`. Now, there is
    no way to tell what’s going to happen. It might continue reading past the end
    of the array, getting all those byes and adding them to `sum`. That would mean
    you are getting the wrong result. It is more likely that you get the `AccessViolationException`
    error, followed by your program being terminated.
  prefs: []
  type: TYPE_NORMAL
- en: We use unsafe code to improve performance, such as in the preceding example,
    but also when we need to interact with native libraries written in C/C++. But
    if you can avoid it without sacrificing performance too much, please do.
  prefs: []
  type: TYPE_NORMAL
- en: Compiler optimizations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I have said it before and will repeat it here: don’t try to outsmart the compiler.
    The C# compiler is a fantastic piece of software that can do tricks we can’t even
    think of. But sometimes, we can help the compiler make choices that affect performance
    in a good way.'
  prefs: []
  type: TYPE_NORMAL
- en: Aggressive optimization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Look at the following method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'I am sure you agree that this is not an exciting method. Calling this, however,
    does take a lot of time: the calling method has to store the return address, move
    all parameters (the integer values, `a` and `b`) to the right place, jump to the
    method, retrieve the parameters, do the actual work, store the return value in
    the right place, retrieve the return address, jump to that return address, and
    assign the result to the variable in the calling method.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The compiler knows this. So, in this particular case, it will probably optimize
    it and “inline” it. But if you think the compiler doesn’t know about this, you
    can instruct it to take a closer look at the code and be a bit more aggressive
    about it. You do that like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This tells the compiler to be aggressive when optimizing the code. This is
    a hint to the compiler: there is no guarantee it will do what you ask. But in
    this case, it will probably honor your request (again, it would likely have done
    it already) and inline the method.'
  prefs: []
  type: TYPE_NORMAL
- en: Inlining means it takes the method’s body and injects it into the calling method
    directly. So, instead of all this copying and moving I described previously, it
    will now execute the code inline, as if it is part of the original method.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is way faster, of course. It also means your original method gets bigger:
    it now contains that extra bit of code, as do all the other methods that use this
    `AddUp()` method. It gets copied all over the place.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is a matter of choice: more performance over less efficient memory usage.'
  prefs: []
  type: TYPE_NORMAL
- en: The optimize flag
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The compiler can optimize your code. But it doesn’t always do that. You can
    add the `optimize` flag to the compiler to force optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several ways to do that. First, you can add it to the command line
    if you use that to build your code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use `MSBuild`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: They both achieve the same result.
  prefs: []
  type: TYPE_NORMAL
- en: 'You could also set it as an option in your `CSProj` file. The best way to do
    that is to add it to the project properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: The project properties showing the Optimize code option](img/B20924_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: The project properties showing the Optimize code option'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, you can set **Optimize code** for **Debug** and **Release**.
  prefs: []
  type: TYPE_NORMAL
- en: 'This will add or change the following setting to your `.``csproj` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: It’s good to know that by default, programs compiled in the **Debug** configuration
    have optimizations turned off. In contrast, programs compiled in the **Release**
    configuration have it turned on.
  prefs: []
  type: TYPE_NORMAL
- en: When debugging, you are better off using non-optimized code. When releasing,
    the opposite applies.
  prefs: []
  type: TYPE_NORMAL
- en: Next steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance – that was what this chapter was all about. We learned why it is
    crucial, especially for system programming, to write software that is as fast
    and efficient as possible.
  prefs: []
  type: TYPE_NORMAL
- en: First, we looked at the BCL and the CLR and saw how the different data types
    can affect performance, but also that things don’t always behave as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we examined the types in the CTS and identified which types give us the
    best-performing systems and what to avoid. We spent quite some time in the `Strings`
    class. We also learned how to rewrite our code so that it uses the best tools
    this class gives us to make it behave faster.
  prefs: []
  type: TYPE_NORMAL
- en: After, we dove into the dark underworld of unsafe types and saw that they could
    give us even more performance but with the downside of the possibility of crashing
    our application, or even our system, in the most spectacular way.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we looked at ways to help the compiler make our systems even faster.
    Here, we learned that the compiler is smart enough to make those changes. It’s
    worth repeating that you shouldn’t try to outsmart the system. You really should
    only use the unsafe code and compiler tricks if benchmarking shows that you have
    an issue. Otherwise, leave those two alone. However, they are good tricks to understand
    if you do need them.
  prefs: []
  type: TYPE_NORMAL
- en: However, better performance often leads to less efficient memory usage. It is
    a trade-off. Sometimes, it is better to have a more memory-efficient system than
    it is to have a fast system. Sometimes, you have to mix and match. In the next
    chapter, we’ll consider memory and cover these aspects in greater detail.
  prefs: []
  type: TYPE_NORMAL
