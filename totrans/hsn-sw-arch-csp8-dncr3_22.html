<html><head></head><body>
        

                            
                    <h1 class="header-title">Deploying Your Application with Azure DevOps</h1>
                
            
            
                
<p>This chapter focuses on so-called <strong>service design thinking</strong>, that is, keeping in mind the software you are designing as a service offered to an organization/part of an organization. The main takeaway of this approach is that the highest priority is the value your software gives to the target organization. Moreover, you are not offering just working code and an agreement to fix bugs, but a solution for all of the needs that your software was conceived for. In other words, your job includes everything it needs to satisfy those needs, such as monitoring users' satisfaction and adapting the software when the user needs change.</p>
<p>Finally, it is easier to monitor the software to reveal issues and new needs and to modify it to adapt it quickly to ever-changing needs.</p>
<p>Service design thinking is strictly tied to the <strong>Software as a Service</strong> (<strong>SaaS</strong>) model, which we discussed in <a href="049a0a4b-74b6-41a1-92db-87a4f8af9fd1.xhtml">Chapter 4</a>, <em>Deciding the Best Cloud-Based Solution</em>. In fact, the simplest way to offer solutions based on web services is to offer the usage of web services as a service instead of selling the software that implements them.</p>
<p>More specifically, this chapter covers the following topics:</p>
<ul>
<li>Understanding SaaS</li>
<li>Preparing a solution for a service scenario</li>
<li>Use case – deploying our package-management application with Azure Pipelines</li>
</ul>
<p>By the end of this chapter, you will be able to design software according to service design thinking principles and use Azure Pipelines to deploy your application.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter requires Visual Studio 2017 or 2019 free Community Edition or better with all database tools installed. It requires a free Azure account. If you have not already created one, the <em>Creating an Azure account</em> subsection of <a href="14b5c5da-4042-439e-9e5a-2e19ba4c4930.xhtml">Chapter 1</a>, <em>Understanding the Importance of Software Architecture</em>, explains how to do so. This chapter uses the same code as <a href="c707cf13-3616-4788-8f39-687bd1cb7c7b.xhtml">Chapter 15</a>, <em>Testing Your Code with Unit Test Cases and TDD</em>, which is available here: <a href="https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8">https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding SaaS</h1>
                
            
            
                
<p>Selling/using software as a service is connected with a wider set of solutions design principles called service design thinking. Service design thinking is not just a software development technique and/or a software deployment approach, but it impacts several business areas, namely, organization and human resources, software development processes, and finally, hardware infrastructures and software architecture.</p>
<p>In the subsections that follow, we will briefly discuss the implications for each of the business areas we listed, and in the last subsection, we will focus specifically on the SaaS deployment model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adapting your organization to a service scenario</h1>
                
            
            
                
<p>The first organizational implication comes from the need to optimize the value of the software for the target organization. This requires a human resource or a team—in charge of planning and monitoring the impact of the software in the target organization—to maximize the value added by the software. This strategic role is not needed just during the initial design stage but during the whole lifetime of the application. In fact, this role is in charge of keeping the software fine-tuned with the ever-changing needs of the target organization.</p>
<p>Another important area of impact is <strong>human resource management</strong>. In fact, since the main priority is the value added by the software and not exploiting existing resources and competences, human resources must be adapted to the project needs. This means acquiring new resources as soon as they are needed and developing the required competencies through new human resources and/or adequate training of existing resources.</p>
<p>The next subsection deals with the implications of all processes involved in software development.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Developing software in a service scenario</h1>
                
            
            
                
<p>The main constraint that impacts software development processes is the need to keep the software fine-tuned with the organization's needs. This need can be satisfied by any agile methodology based on a CI/CD approach. For a short review of CI/CD, please refer to the <em>Organizing your work using Azure DevOps</em> section of <a href="bc26065f-b001-4123-9524-3bbfa87bfadd.xhtml">Chapter 3</a>, <em>Documenting Requirements with Azure DevOps</em>, while for a detailed discussion of CI/CD, please refer to <a href="b444cf5c-311d-4f74-80b0-0e86c0c13307.xhtml">Chapter 17</a>, <em>Deploying Your Application with Azure DevOps,</em> which is completely dedicated to CI/CD. It is worth pointing out that any well-designed CI/CD cycle should include the processing of user feedback and user satisfaction reports.</p>
<p>Moreover, to optimize the value added by the software, it is a good practice to organize stages where the development team (or part of it) is placed in close contact with the system users so that developers can better understand the impact of the software on the target organization.</p>
<p>Finally, the value added by the software must always be kept in mind when writing both functional and non-functional requirements. For this reason, it is useful to annotate <em>user stories</em> with consideration of <em>why</em> and <em>how</em> they contribute to value. The process of collecting requirements is discussed in <a href="a4194162-692d-4ac4-9b8e-a48199e746ab.xhtml">Chapter 2</a>, <em>Functional and Nonfunctional Requirements</em>.</p>
<p class="mce-root">More technical implications are discussed in the next subsection.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical implications of a service scenario</h1>
                
            
            
                
<p>In a service scenario, both the hardware infrastructure and software architecture are constrained by the three main principles mentioned as follows, which are an immediate consequence of the requirement to keep the software fine-tuned with the organization's needs, namely, the following:</p>
<ul>
<li>There's the need to monitor the software to discover any kind of issue that might have been caused by system malfunctions or changes in software usage and/or user needs. This implies extracting health checks and load statistics from all hardware/software components. Good hints for discovering changes in the organization's needs are also given by statistics on the operations performed by the users—more specifically, the average time spent by both the user and the application on each operation instance, and the number of instances of each operation performed per unit of time (day, week, or month).</li>
<li>There's also the need to monitor user satisfaction. Feedback on user satisfaction can be obtained by adding to each application screen a link to an easy-to-fill user-satisfaction report page. </li>
<li>Finally, there's the need to adapt both hardware and software quickly, both to the traffic received by each application module and to the changes in the organization's needs. This means the following:
<ul>
<li>Paying extreme attention to software modularity</li>
<li>Keeping the door open for changes in the database engine and preferring SOA or microservices-based solutions to monolithic software</li>
<li>Keeping the door open to new technologies</li>
</ul>
</li>
</ul>
<p>Making the hardware easy to adapt means allowing hardware scaling, which in turn implies either the adoption of cloud infrastructures, hardware clusters, or both. It is also important to keep the door open to changes in cloud service suppliers, which in turn means encapsulating the dependence on the cloud platform in a small number of software modules.</p>
<p>The maximization of the value added by the software can achieved by choosing the best technology available for the implementation of each module, which in turn means being able to mix different technologies. Here is where container-based technologies, such as Docker, come into play. Docker and related technologies were described in <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>.</p>
<p>Summing up, all of the requirements we have listed converge toward most of the advanced technologies we have described in this book, such as cloud services, scalable web applications, distributed/scalable databases, Docker, SOA, and microservices architectures.</p>
<p>More details on how to prepare your software for a service environment are given in the next section, while the next subsection focuses specifically on the advantages and disadvantages of SaaS applications. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adopting a SaaS solution</h1>
                
            
            
                
<p>The main attraction of SaaS solutions is their flexible payment model, which offers the following advantages: </p>
<ul>
<li>You can avoid abandoning big investments in favor of more affordable monthly payments.</li>
<li>You can start with a cheap system and then move toward more expansive solutions only when the business grows.</li>
</ul>
<p class="mce-root"/>
<p>However, SaaS solutions also offer other advantages, namely, the following:</p>
<ul>
<li>In all cloud solutions, you can easily scale up your solution.</li>
<li>The application is automatically updated.</li>
<li>Since SaaS solutions are delivered over the public internet, they are accessible from any location.</li>
</ul>
<p>Unluckily, SaaS advantages come at a cost, since SaaS also has not negligible disadvantages, namely, the following:</p>
<ul>
<li>Your business is strictly tied to the SaaS provider, which might discontinue the service and/or modify it in a way that is not acceptable to you anymore.</li>
<li>Usually, you can't implement any kind of customization, being limited to the few standard options offered by the SaaS supplier. However, sometimes SaaS suppliers also offer the possibility to add custom modules written either by them or by you.</li>
</ul>
<p>Summing up, SaaS solutions offer interesting advantages but also some disadvantages, so you, as a software architect, must perform a detailed analysis to decide how to adopt them.</p>
<p>The next section explains how to adapt software to be used in a service scenario.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Preparing a solution for a service scenario</h1>
                
            
            
                
<p>First of all, <em>preparing a solution for a service scenario</em> means designing it specifically for the cloud and/or for a distributed environment. In turn, this means designing it with scalability, fault tolerance, and automatic fault recovery in mind.</p>
<p>The main implications of the preceding three points are concerned with the way the <em>state</em> is handled. Stateless module instances are easy to scale and to replace, so you should carefully plan which modules are stateless and which ones have states. Moreover, as explained in <a href="77cdecb5-cef4-4b02-80a1-052ad366b9f3.xhtml">Chapter 7</a>, <em>How to Choose Your Data Storage in the Cloud</em>, you have to keep in mind that write and read operations scale in a completely different way. In particular, read operations are easier to scale with replication, while write operations do not scale well with relational databases and often require NoSQL solutions.</p>
<p class="mce-root"/>
<p>High scalability in a distributed environment prevents the usage of distributed transactions and of synchronous operations, in general. Therefore, data coherence and fault tolerance can be achieved only with more complex techniques based on asynchronous messages, such as the following:</p>
<ul>
<li>One technique is storing all messages to send in a queue so that asynchronous transmissions can be retried in the event of errors or timeouts. Messages can be removed from the queue either when confirmation of reception is received or when the module decides to abort the operation that produced the message.</li>
<li>Another is handling the possibility that the same message is received several times because timeouts caused the same message to be sent several times.</li>
<li>If needed, use techniques such as optimistic concurrency and event sourcing to minimize concurrency problems in databases. Optimistic concurrency is explained in <em>The data layer</em> subsection of the use case at the end of <a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml"/><a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml">Chapter 13</a>, <em>Presenting ASP.NET Core MVC</em>, while event sourcing is described together with other data layer stuff in the <em>Using SOLID principles to map your domains</em> section of <a href="2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml">Chapter 10</a>, <em>Understanding the Different Domains in a Software Solution</em>.</li>
</ul>
<p>The first two points in the preceding list are discussed in detail together with other distributed processing techniques in the <em>How does .NET Core deal with Microservices?</em> section of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>.</p>
<p>Fault tolerance and automatic fault recovery require that software modules implement health check interfaces that the cloud framework might call, to verify whether the module is working properly or whether it needs to be killed and replaced by another instance. ASP.NET Core and all Azure microservices solutions offer off-the-shelf basic health checks, so the developer doesn't need to take care of them. However, more detailed custom health checks can be added by implementing a simple interface.</p>
<p>The difficulty increases if you have the goal of possibly changing the cloud provider of some of the application modules. In this case, the dependency from the cloud platform must be encapsulated in just a few modules, and solutions that are too strictly tied to a specific cloud platform must be discarded. Hence, for instance, you should avoid the use of stateful/stateless native Service Fabric services since their architecture is specific to Azure Service Fabric, so they can't be ported to a different cloud platform.</p>
<p>If your application is conceived for a service scenario, everything must be automated: new versions testing and validation, the creation of the whole cloud infrastructure needed by the application, and the deployment of the application on that infrastructure.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>All cloud platforms offer languages and facilities to automate the whole software CI/CD cycle, that is, building the code, testing it, triggering manual version approvals, hardware infrastructure creation, and application deployment.</p>
<p>Azure Pipelines allows the complete automatization of all of the steps listed. The use case in <a href="c707cf13-3616-4788-8f39-687bd1cb7c7b.xhtml">Chapter 15</a>, <em>Testing Your Code with Unit Test Cases and TDD</em>, shows how to automatize all steps up to and including software testing with Azure Pipelines. The use case in the next section will show how to automatize the application deployment on the Azure web app platform.</p>
<p>Automatization has a more fundamental role in SaaS applications since the whole creation of a new tenant for each new customer must be automatically triggered by the customer subscription. More specifically, multi-tenant SaaS applications can be implemented with three fundamental techniques:</p>
<ul>
<li>All customers share the same hardware infrastructure and data storage. This solution is the easiest to implement since it requires the implementation of a standard web application. However, it is possible just for very simple SaaS services since, for more complex applications, it becomes always more difficult to ensure that storage space and computation time are split equally between users. Moreover, as the database becomes more and more complex, it is always more difficult to keep the data of different users safely isolated. </li>
<li>All customers share the same infrastructure but each customer has its own data storage. This option solves all database problems of the previous solution, and it is quite easy to automatize since the creation of a new tenant requires just the creation of a new database. This solution offers a simple way to define pricing strategies, by linking them to storage consumption. </li>
<li>Each customer has their private infrastructure and data storage. This is the most flexible strategy. From the user's point of view, its only disadvantage is the higher price. Therefore, it is convenient only above a minimum threshold of computational power required by each user. It is more difficult to automate since a whole infrastructure must be created for each new customer and a new instance of the application must be deployed on it.</li>
</ul>
<p>Whichever of the three strategies is chosen, you need the possibility to scale out your cloud resources as your consumers increase.</p>
<p>If you also need the possibility to ensure your infrastructure creation scripts work across several cloud providers, then, on the one hand, you can't use features that are too specific to a single cloud platform, and on the other, you need a unique infrastructure creation language that can be translated into the native languages of the more common cloud platforms. Terraform and Ansible are two very common choices for describing hardware infrastructures.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Use case – deploying our package-management application with Azure Pipelines</h1>
                
            
            
                
<p>In this section, we will configure an automatic deployment to the Azure App Service platform for the DevOps project that we already defined in the use case at the end of <a href="c707cf13-3616-4788-8f39-687bd1cb7c7b.xhtml">Chapter 15</a>, <em>Testing Your Code with Unit Test Cases and TDD</em>. Azure DevOps can also automatically create a new web app, but to prevent configuration errors (which might consume all your free credit), we will create it manually and let Azure DevOps just deploy the application. All of the required steps are organized into various subsections as follows.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating the Azure Web App and the Azure database</h1>
                
            
            
                
<p>An Azure Web App can be defined by following the simple steps that follow:</p>
<ol>
<li>Go to the Azure portal and select App Services, and then click the Add button to create a new Web App. Fill in all data as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/77c50b71-036b-4bab-9652-79586dbe7438.png"/></p>
<ol start="2">
<li>Clearly, you may use a Resource Group you already have, and the most convenient region for you. For Runtime stack, please select the same .NET Core version you used in the Visual Studio solution.</li>
</ol>
<ol start="3">
<li>Now, if you have enough credit, let's create a SQL Server database for the application, and let's call it <kbd>PackagesManagementDatabase</kbd>. If you don't have enough credit, don't worry—you can still test application deployment, but the application will return an error when it tries to access the database. Please refer to the <em>Relational databases</em> subsection of <a href="77cdecb5-cef4-4b02-80a1-052ad366b9f3.xhtml">Chapter 7</a>, <em>How to Choose Your Data Storage in the Cloud</em>, for how to create a SQL Server database.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Configuring your Visual Studio solution</h1>
                
            
            
                
<p>Once you've defined the Azure Web App, you need to configure the application for running in Azure by following these simple steps:</p>
<ol start="1">
<li>If you defined an Azure database, you need two different connection strings in your Visual Studio solution, one of the local databases for development and one of the Azure database for the web app.</li>
<li>Now, open both <kbd>appsettings.Development.json</kbd> and <kbd>appsettings.json</kbd> in your Visual Studio solution, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/093806cf-72b4-4ed2-974c-b0d131f3aa94.png"/></p>
<ol start="3">
<li>Then, copy the whole <kbd>ConnectionStrings</kbd> node of <kbd>appsettings.json</kbd> into <kbd>appsettings.Development.json</kbd>,  as follows:</li>
</ol>
<pre style="padding-left: 60px">"ConnectionStrings": {<br/>        "DefaultConnection": "Server=(localdb)....."<br/>},</pre>
<p style="padding-left: 60px">Now you have the local connection string in the development settings, so you can change <kbd>DefaultConnection</kbd> in <kbd>appsettings.json</kbd> with one of the Azure databases.</p>
<ol start="4">
<li>Go to the database in the Azure portal, copy the connection string, and fill it with the username and password you got when you defined the database server.</li>
<li>Finally, commit your changes locally and then synchronize with the remote repository. Now, your changes are on DevOps Pipelines, which is already processing them to get a new build.</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Configuring Azure Pipelines</h1>
                
            
            
                
<p>Finally, you can configure an Azure Pipeline for the automatic delivery of your application on Azure by following these steps:</p>
<ol start="1">
<li>Connect Visual Studio with your DevOps project by clicking the Manage Connections link in the Connection tab of the Visual Studio Team Server window. Then, click the DevOps link to go to your online project.</li>
<li>Modify the <kbd>PackagesManagementWitTests</kbd> build pipeline by adding a further step after the unit test step. In fact, we need a step that prepares all files to be deployed in a ZIP file.</li>
<li>Click the Edit button of the <kbd>PackagesManagementWitTests</kbd> pipeline, and then go to the end of the file and write the following:</li>
</ol>
<pre style="padding-left: 60px">- task: PublishBuildArtifacts@1</pre>
<ol start="4">
<li>When the Settings link appears above the new task, click it to configure the new task:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/d18768bf-5ff7-4c30-af29-7099052337b2.png" style="width:16.25em;height:16.92em;"/></p>
<ol start="5">
<li>Accept the default Path to publish since it is already synchronized with the path of the task that will deploy the application, and just insert the artifact name, and then select Azure Pipeline as the location. As soon as you save, the pipeline will start, and the newly added task should succeed.</li>
</ol>
<ol start="6">
<li>Deployments and other release artifacts are added to different pipelines called Release Pipelines, to decouple them from build related artifacts. With Release Pipelines, you cannot edit a <kbd>.yaml</kbd> file, but you will work with a graphic interface.</li>
<li>Click the Releases left menu tab to create a new Release Pipeline. As soon as you click add a new pipeline, you will be prompted to add the first task of the first pipeline stage. In fact, the whole release pipeline is composed of different stages, each grouping sequences of tasks. While each stage is just a sequence of tasks, the stages diagram can branch and we can add several branches after each stage. This way, we can deploy to different platforms that each require different tasks. In our simple example, we will use a single stage.</li>
<li>Select the Deploy Azure App Service task. As soon as you add this task, you will be prompted to fill in missing information:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/8ed18539-0b6e-4d06-831e-aa16c837b8f6.png" style="width:14.25em;height:3.83em;"/></p>
<ol start="9">
<li>Click the error link and fill in the missing parameters:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/0ce57687-4bd6-4e9c-b11b-deaf1c0ca177.png" style="width:34.67em;height:21.42em;"/></p>
<ol start="10">
<li>Select your subscription, and then, if an authorization button appears, please click it to authorize Azure Pipelines to access your subscription. Then, select Windows as the deployment platform, and finally, select the App Service you created from the App service name drop-down list. Task settings are automatically saved while you write them, so you need just to click the Save button for the whole pipeline.</li>
<li>Now, we need to connect this pipeline to a source artifact. Click the Add Artifact button and then select Build as the source type, because we need to connect the new release pipeline with the ZIP file created by our build pipeline. A settings window appears:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/d56d9886-b242-4819-9247-cb86d7ba59e0.png" style="width:31.00em;height:28.42em;"/>:</p>
<ol start="12">
<li>Select our previous build pipeline from the drop-down list, and keep Latest as the version. Finally, accept the suggested name in Source alias.</li>
</ol>
<p style="padding-left: 60px">Our release pipeline is ready and can be used as it is. The image of the source artifact you just added contains a trigger icon in its top-right corner, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/545778d2-3408-4a06-8ae9-00ffbe915f1e.png" style="width:11.50em;height:8.25em;"/></p>
<p style="padding-left: 60px">If you click on the trigger icon, you are given the option to automatically trigger the release pipeline as soon as a new build is available:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/75c52940-6e05-41d2-8f18-b10d7a0cc45f.png" style="width:29.42em;height:9.75em;"/></p>
<p class="CDPAlignLeft CDPAlign">Keep it disabled; we can enable it after we have completed and manually tested the release pipeline. In preparation for an automatic trigger, we need to add a human approval task before the application is deployed. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding a manual approval for the release</h1>
                
            
            
                
<p>Since tasks are usually executed by software agents, we need to embed human approval in a manual job. Let's add it with the following steps:</p>
<ol>
<li>Click the three dots on the right of the Stage 1 header:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/97463b10-1754-4141-a811-9aac460bc4ac.png" style="width:14.92em;height:11.17em;"/></p>
<ol start="2">
<li>Then, select Add an agentless job. Once the agentless job has been added, click its add button and add a Manual intervention task. The following screenshot shows the Manual intervention settings:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/79d2f557-6ec8-4678-84d4-24d7c85c41e2.png" style="width:26.25em;height:31.75em;"/></p>
<ol start="3">
<li>Add instructions for the operator and select your account in the Notify users field.</li>
</ol>
<ol start="4">
<li>Now, drag the whole Agentless job with the mouse, to place it before the application deployment task. The final screenshot should be as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/8d9096ac-64a7-46f4-9b9f-492b3051e83a.png" style="width:28.08em;height:22.50em;"/></p>
<ol start="5">
<li>Finished! Click the save button in the top-left to save the pipeline.</li>
</ol>
<p>Now, everything is ready to create our first automatic release.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating a release</h1>
                
            
            
                
<p>Once you have everything in place, a new release can be prepared and deployed as follows:</p>
<ol>
<li>Let's click the Create release button to start the creation of a new release:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/21a6cf8f-2a74-4143-8cc9-dd86229788f5.png" style="width:25.50em;height:39.50em;"/></p>
<ol start="2">
<li>Verify that the Source alias is the last available, add a release description, and then click Create. In a short time, you should receive an email for the release approval. Click the link it contains, and go to the approval page:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/6db8064f-c8ed-4c53-8ccd-bf56055ae639.png" style="width:33.67em;height:6.58em;"/></p>
<ol start="3">
<li>Click the Resume / Reject button and then approve the release. Wait for the deployment to complete. You should have all of the tasks successfully completed, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/70a11166-c5b1-4c65-a402-700d04f035b8.png" style="width:11.08em;height:10.67em;"/></p>
<p>You have run your first successful release pipeline!</p>
<p>In a real-life project, the release pipeline would contain some more tasks. In fact, applications (before being deployed in the actual production environment) are deployed in a staging environment where they are beta-tested. Hence, probably, after this first deployment, there would be some manual tests, manual authorization for the deployment in production, and the final deployment in production.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>We described <em>service design thinking</em> principles and the SaaS software deployment model. Now, you should be able to analyze all of the implications of these approaches for an organization, and you should be able to adapt pre-existing software development processes and hardware/software architectures to take advantage of the opportunities they offer.</p>
<p>We also explained the need for, and the techniques involved in, the automatization of the software cycle, cloud hardware infrastructure configuration, and application deployment.</p>
<p>Once you have implemented the example in the last use case section, you should be able to use Azure Pipelines to automate infrastructure configuration and application deployment.</p>
<p>The next chapter gives more insights into DevOps, which, together with CI/CD, which is discussed in detail in <a href="db7586ff-b06d-4503-a64a-9a6678d09acb.xhtml">Chapter 19</a>, <em>Challenges of Applying CI Scenarios in DevOps</em>, plays a fundamental role in service scenarios and, in particular, the maintenance of SaaS applications.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>What is the main goal of service design thinking?</li>
<li>Is it true that service design thinking requires the optimal usage of all competencies already available in the company?</li>
<li>Why is a complete automatization fundamental in the life cycle of SaaS applications?</li>
<li>Is it possible to define hardware cloud infrastructures with a platform-independent language?</li>
<li>What is the preferred Azure tool for the automatization of the whole application lifecycle?</li>
<li>If two SaaS suppliers offer the same software product, should you prefer the most reliable or the cheapest one?</li>
<li>Is scalability the only important requirement in a service scenario?</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>The main references in this chapter are references to other chapters/sections of this book and have already been given throughout this chapter. Here, we give just the link to the Azure Pipelines documentation: <a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops">https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops</a>, and to the two infrastructure description languages cited in this chapter, Terraform (<a href="https://www.terraform.io/">https://www.terraform.io/</a>) and Ansible (<a href="https://www.ansible.com/">https://www.ansible.com/</a>).</p>


            

            
        
    </body></html>