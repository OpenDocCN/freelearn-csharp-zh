- en: '*Chapter 8*: All You Need to Know about Caching'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Caching is one of the key system design patterns that help in scaling any enterprise
    application along with improving response time. Any web application typically
    involves reading and writing data from and to a data store, which is usually a
    relational database such as SQL Server or a NoSQL database such as Cosmos DB.
    However, reading data from the database for every request is not efficient, especially
    when the data hasn't changed. This is because databases usually persist data to
    disk and it's a costly operation to load the data from disk and send it back to
    the browser client (or device in the case of mobile/desktop applications) or user.
    This is where caching comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: Cache stores can be used as a primary source for retrieving data, falling back
    to the original data store only when the required data is not available in the
    cache, thus giving a faster response to the consuming application. When using
    caches this way, we also need to ensure that the cached data is expired/refreshed
    as and when the data in the original data store is updated.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about various techniques for caching data in
    .NET 6 applications as well as various caching components and the platforms available
    that can be integrated with a .NET 6 application. We will cover the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the components of caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching platforms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing a cache abstraction layer using distributed caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A basic understanding of .NET Core, C#, Azure, and the .NET CLI is required.
    The code for the chapter can be found here: [https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Chapter08](https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Chapter08).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The instructions for the code examples can be found here: [https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application](https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are multiple ways to improve the performance of an application and caching
    is one of the key techniques used in enterprise applications. A **cache** is like
    a temporary data store, with a limited size and limited data, but has much faster
    data access compared to the original data source and usually holds only a subset
    of the data, the most frequently used data that does not change often.
  prefs: []
  type: TYPE_NORMAL
- en: A **cache store** could be as simple as the RAM of the computer that is used
    by the process during execution, or it could be something such as Redis, which
    uses both memory and disks to store data. The key thing here is that it is usually
    on hardware that has a lower access time compared to the original storage layer.
  prefs: []
  type: TYPE_NORMAL
- en: Caching can be implemented at every layer in the architecture so that data can
    be retrieved from the layer closest to the user. For example, in any web application,
    the moment a URL is typed in the browser and we press *Enter*, it goes through
    various web components that are involved in loading the web application, starting
    with the browser, proxies, and DNS, to the web server and database. Caching is
    something that can be applied at all these layers.
  prefs: []
  type: TYPE_NORMAL
- en: If data is cached in the browser, it can be loaded immediately. It can alternatively
    fall back to a higher layer if data is not available in the layer closest to the
    user, thus reducing the load on higher layers that are shared across multiple
    users, such as the application server and database tier.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure depicts this discussion at a high level, where a request
    is flowing through various layers and is moved to a higher layer only when data
    is not available (represented by the dotted line) in the cache:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Cache layers in a request flow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.1_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Cache layers in a request flow
  prefs: []
  type: TYPE_NORMAL
- en: Let's discuss some of these layers in application architecture where data can
    be cached.
  prefs: []
  type: TYPE_NORMAL
- en: Client caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Commonly requested data can be cached on the client side to avoid unnecessary
    round trips to the server. For example, Microsoft's Outlook app downloads the
    most recent emails from the server and keeps a copy of them on the client side,
    and then periodically syncs for new emails. If there is a need to search for an
    email that isn't already downloaded, it goes back to the server.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, browsers can cache various resources and responses from a web application
    based on certain headers, and subsequent requests for the same resource load from
    the browser cache. For example, all JavaScript files, image files, and CSS are
    usually cached on the browser for a certain period. Also, a response from an API
    can be cached by sending appropriate response headers. This is also known as **HTTP
    caching** or **response caching**, which is discussed in detail in a later section.
  prefs: []
  type: TYPE_NORMAL
- en: Content Delivery Network (CDN)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **Content Delivery Network** (**CDN**) is a set of servers that are globally
    distributed and are usually used to serve static content such as HTML, CSS, and
    video. Whenever an application requests a resource, if the CDN is enabled, the
    system will first look to load the resource from the CDN server that is physically
    closest to the user. However, if it is not available on the CDN server, the resource
    is retrieved from the server and is cached in the CDN to serve subsequent requests.
    Netflix is one such great example that heavily relies on its custom-built CDN
    to deliver content to users.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft also comes with Azure CDN, which is primarily used to serve static
    content. Also, Microsoft's CDN gives an option to integrate with Azure Storage,
    which we will be using in our e-commerce application to serve various product
    images. Similarly, AWS has Amazon Cloudfront and Google Cloud offers Cloud CDN
    as part of their respective e-storage offerings.
  prefs: []
  type: TYPE_NORMAL
- en: Web server caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although CDNs are great for static content, they come with additional costs
    and maintenance overhead in terms of refreshing data from application servers.
    To overcome these limitations, applications can use web servers or reverse proxies
    to serve static content. A lightweight NGINX server is one such example that can
    be used to serve static content.
  prefs: []
  type: TYPE_NORMAL
- en: Web servers can also cache dynamic content, such as an API response coming from
    the application server. Web servers such as NGINX or IIS, when configured as a
    reverse proxy, can be further used to cache dynamic content, thereby reducing
    the load on the application server by serving requests from its cache.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: NGINX is an open source solution that is primarily known for its web server
    capabilities; however, it can also be used as a reverse proxy, for load balancing,
    and more. For further reading, please refer to [https://www.nginx.com/](https://www.nginx.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Database caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Increasingly, database servers cache certain components of a query; for example,
    SQL Server usually has cache execution plans and also has a data buffer to cache,
    and MongoDB keeps recently queried data in memory for faster retrieval. So, it
    is good to tweak these settings to improve the performance of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Database caching doesn't guarantee that subsequent execution of the same query
    executes with zero CPU consumption; that is, it is not practically free. The same
    query in subsequent requests executes at a faster pace.
  prefs: []
  type: TYPE_NORMAL
- en: Application caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Application caching can be achieved by caching data retrieved from the storage
    layer within the application server. This is mostly done in the following two
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Stored in the memory of the application server, also known as in-memory caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stored in an external store, such as Redis or Memcached, that has a faster access
    time as compared to the underlying original data store
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application caching usually involves integrating extra code within the application
    logic to cache data. So, whenever a request for data is made, the application
    first looks in the cache. But if it's not available in the cache, the application
    will fall back to the original data store, such as a database. Usually, the size
    of the application cache is limited compared to the original data store, so internally,
    application caching platforms will employ various algorithms such as **Least Recently
    Used** (**LRU**) or **Least Frequently Used** (**LFU**) to clean up the data stored
    in the cache. We will discuss more about caching platforms in the *Caching platforms*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Another important point to consider for application caches is data invalidation,
    which is how frequently data needs to be expired or synced with the original data
    source. So, things such as cache expiry and various strategies to update the cache
    with the original data store (read-through, write-through) need to be considered.
    We will discuss more cache invalidation/refresh strategies in the *Cache access
    patterns* section.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the components of caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we understand the various possible cache stores/platforms available in
    .NET 6 applications, we need to understand the various components of caching that
    are available in .NET 6 and how to use them in enterprise applications. Along
    the way, we will also cover various cache eviction strategies and techniques to
    keep the cache in sync with original data stores.
  prefs: []
  type: TYPE_NORMAL
- en: Response caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Response caching is a caching technique supported by HTTP to cache the response
    to a request made using HTTP or HTTPS either on the client (for example, a browser)
    or an intermediate proxy server. From an implementation standpoint, this is controlled
    by setting the appropriate value for the `Cache-Control` header in both requests
    and responses. A typical `Cache-Control` header will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this case, if the header is present in the response, the server is telling
    the client/proxy (public) that the client can cache the response for 10 seconds
    (`max-age=10`). However, the client can still override it and cache it for a shorter
    duration; that is, if both the request and response set the cache headers, the
    cache duration would be the minimum of both.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with `max-age`, as per the HTTP specification ([https://tools.ietf.org/html/rfc7234#section-5.2](https://tools.ietf.org/html/rfc7234#section-5.2)),
    `Cache-Control` can additionally hold the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Public**: The response can be cached anywhere – client/server/intermediate
    proxy server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Private**: The response can be stored for a specific user but not in a shared
    cache server; for example, it can be stored in the client browser or application
    server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**No-cache**: The response cannot be cached.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other headers that play a role in response caching are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Age**: This is a response header indicating the duration for which an object
    is present in the cache (proxy/browser). The accepted value is an integer and
    represents the duration in seconds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Vary` is set to the `user-agent` value, responses are uniquely cached per
    `user-agent`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows response headers related to the cache for a
    sample request in Postman:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Sample response with Cache-Control and Vary headers'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.2_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Sample response with Cache-Control and Vary headers
  prefs: []
  type: TYPE_NORMAL
- en: 'The following sequence diagram shows a sample API built using ASP.NET Core
    6 that has response caching middleware enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Response cache sequence diagram'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.3_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Response cache sequence diagram
  prefs: []
  type: TYPE_NORMAL
- en: 'After creating a new ASP.NET Core 6 MVC/Web API application, or using an existing
    ASP.NET Core 6 MVC/Web API application, to configure response caching, the following
    code changes are required:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `builder.Services.AddResponseCaching()` to `Program.cs` and add the required
    middleware using `app.UseResponseCaching()`. This middleware holds the required
    logic to cache data. Ensure this middleware is injected before `app.UseEndpoints`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Handle the response to set cache headers either through custom middleware or
    using the `ResponseCache` attribute.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`UseCors` must be called before `UseResponseCaching` when using CORS middleware.
    For further information on this ordering, please refer to [https://github.com/dotnet/AspNetCore.Docs/blob/master/aspnetcore/fundamentals/middleware/index.md](https://github.com/dotnet/AspNetCore.Docs/blob/master/aspnetcore/fundamentals/middleware/index.md).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The `ResponseCache` attribute can be used for the entire controller or specific
    methods in a controller, and it accepts the following key properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Duration`: A numeric value that sets the `max-age` value in the response header'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ResponseCacheLocation`: An enum that takes three values – `Any`, `Client`,
    and `None` – and further sets the `Cache-Control` header to `public`, `private`,
    or `no-store`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`VaryByHeader`: A string that controls cache behavior to cache based on a specific
    header'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`VaryByQueryKeys`: An array of strings that accepts key values on which basis
    data is cached'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A typical method with the `ResponseCache` attribute looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This method would be cached for `500` seconds based on a unique `user-agent`
    header and `Id` value. If any of these values change, a response is served from
    the server, otherwise, it's served from the cache middleware.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see here, we need to prefix the `ResponseCache` attribute to every
    controller/method. So, if the application has many controllers/methods, this could
    be a maintenance overhead since, in order to make any changes to the way data
    is cached (such as changing the `Duration` value), we need to apply the change
    at the controller/method level, and that's where cache profiles come into play.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, instead of setting properties individually, we can group them and give
    them a name in `Program.cs`, and that name can be used in the `ResponseCache`
    attribute. So, for the preceding properties, we can create a cache profile by
    adding the code shown here in `Program.cs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'And on the controller, call this cache profile using `CacheProfileName`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: For an MVC application, `CacheProfile` can be configured in `services.AddControllersWithViews()`.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed caching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As we know, in a distributed system, the data store is split across multiple
    servers. Similarly, distributed caching is an extension of traditional caching
    in which cached data is stored in more than one server in a network. Before we
    get into distributed caching, here''s a quick recap of the **CAP theorem**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**C** stands for consistency, meaning the data is consistent across all the
    nodes and each node has the same copy of the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A** stands for availability, meaning the system is available, and the failure
    of one node doesn''t cause the system to go down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**P** stands for partition-tolerant, meaning the system doesn''t go down even
    if the communication between nodes goes down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As per the CAP theorem, any distributed system can only achieve two of the preceding
    principles, and as distributed systems must be partition-tolerant (P), we can
    only achieve either consistency (C) of data or high availability (A) of data.
  prefs: []
  type: TYPE_NORMAL
- en: So, distributed caching is a cache strategy in which data is stored in multiple
    servers/nodes/shards outside the application server. Since data is distributed
    across multiple servers, if one server goes down, another server can be used as
    a backup to retrieve data.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if our system wanted to cache countries, states, and cities, and
    if there are three caching servers in a distributed caching system, hypothetically
    there is a possibility that one of the cache servers will cache countries, another
    one will cache states, and one will cache cities (of course, in a real-time application,
    data is split in a much more complex way).
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, each server will additionally act as a backup for one or more entities.
    So, on a high level, one type of distributed cache system looks as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Distributed caching high-level representation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.4_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.4 – Distributed caching high-level representation
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, while reading data, it is read from the primary server, and
    if the primary server is not available, the caching system will fall back to the
    secondary server. Similarly, for writes, write operations are not complete until
    data is written to the primary as well as the secondary server. Until this operation
    is completed, read operations can be blocked, hence compromising the availability
    of the system. Another strategy for writes could be background synchronization,
    which will result in the eventual consistency of data, hence compromising the
    consistency of data until synchronization is completed. Going back to the CAP
    theorem, most distributed caching systems fall under the category of CP or AP.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are a few of the distributed caching providers that are integrated
    with .NET 6 applications:'
  prefs: []
  type: TYPE_NORMAL
- en: Redis Cache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memcached
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Couchbase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SQL Server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NCache
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be further extended to any cluster orchestration platform, for example,
    **Terracotta**, which takes care of managing various nodes and can distribute
    data to all nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Although distributed caching has a lot of benefits, one possible disadvantage
    of distributed caching as opposed to single-server caching or in-process caching
    could be the introduced latency due to the possible extra hop and serialization/deserialization.
    So, if applications rely heavily on cached data, the design can consider a combination
    of in-memory cache and distributed cache. However, most scenarios are covered
    by integrating a well-implemented distributed caching system such as Redis, which
    we will cover later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Cache access patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once object data is cached, there needs to be a design in place that takes
    care of refreshing the cache. Multiple cache access patterns can be implemented
    to handle this. A few key patterns are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Cache-aside pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read-through/write-through
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refresh-ahead
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Write-behind
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's discuss each in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Cache-aside pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the name suggests, in the cache-aside pattern, the cache store is kept alongside
    the data store. In this pattern, the application code checks for data availability
    in the cache store. If it's not available in the cache store, the data is retrieved
    from the underlying data store and is updated in the cache. Subsequent requests
    would again query the data in the cache and if the data is available in the cache,
    it will be served from the cache. The cache-aside pattern relies on the concept
    of lazy loading, discussed in [*Chapter 4*](B18507_04_Epub.xhtml#_idTextAnchor205),
    *Threading and Asynchronous Operations*, and populates as and when data is accessed
    for the first time; a subsequent request for the same entity would be loaded from
    cache.
  prefs: []
  type: TYPE_NORMAL
- en: The expiry of data in the cache store should be handled while updating the data
    in the original data store, and then subsequent reads will add the updated data
    to the cache again.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the advantages of this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: Simplified implementation compared to the read-through/write-through patterns
    covered in the next section. As the cache isn't the primary data source in the
    application, we do not need additional classes to synchronize the cache store
    with the data store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As it relies on the lazy loading principle, the cache is populated only when
    any data is accessed at least once.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, there are a few cons associated with this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: It leads to the possibility of a greater number of cache misses. Cache misses
    should always be minimal as they introduce latency in the application due to the
    additional hop.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If cache expiry is missed during data updates, it can lead to stale data in
    the cache. This can occur if data is updated by a background/external process
    that doesn't have information on the caching system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One way to mitigate issues with expiration is to set the **Time to Live** (**TTL**)
    for each entity so that objects are automatically expired after a certain period.
    However, the TTL duration needs to be carefully evaluated after monitoring the
    data refresh rate. Another common practice in the case of the cache-aside pattern
    is to prepopulate the cache store during the startup of the application as this
    helps in reducing the number of cache misses. Most enterprise applications usually
    implement a caching layer using the cache-aside pattern and prepopulate it with
    master data rather than transactional data.
  prefs: []
  type: TYPE_NORMAL
- en: Read-through/write-through
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In read-through/write-through, the application directly reads/writes data from
    the cache store; that is, the application uses it as a primary store and the cache
    layer is responsible for loading the data in the cache and also for writing any
    updates from the cache store back to the original store.
  prefs: []
  type: TYPE_NORMAL
- en: When the application wants to read an entity, it will directly request it from
    the cache store. If that entity is available in the cache, a response is returned.
    However, if it isn't present in the cache, the caching layer requests it from
    the original data store, which is updated in the cache for future use, and then
    the response is returned from the cache layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'When updating an entity, the following steps occur:'
  prefs: []
  type: TYPE_NORMAL
- en: It is first updated in the cache.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The cache layer writes it back to the original data store.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The major advantages of this kind of system are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Significant load reduction on the original data store, which is usually a database,
    as in most enterprise applications, all the calls would be served from the cache
    apart from calls from the cache layer to the data store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplified application code as it only interacts with one store, unlike the
    cache-aside pattern, which interacts with the cache store as well as a data store
    from within the application code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A few disadvantages of this pattern are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An additional mechanism is required to synchronize data between the cache and
    data store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cache updating becomes a bit tricky as it involves additional complexity to
    refresh the cache store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refresh-ahead
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The refresh-ahead strategy allows you to load data into the cache store asynchronously;
    that is, in this design, the application still talks directly to the cache store.
    However, the cache layer periodically refreshes the data before the data in the
    cache expires. The refresh happens asynchronously for the entries that were accessed
    most recently and are refreshed from the original store asynchronously before
    their expiration. This way, there won't be any latency in the application if any
    item cache is expired.
  prefs: []
  type: TYPE_NORMAL
- en: Write-behind
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the write-behind strategy, data is updated into the cache store first and
    asynchronously updated back to the data store, as opposed to the write-through
    strategy in which data is immediately updated to the data store. One of the key
    advantages of this strategy is reduced latency. However, as data is updated asynchronously
    (writing to the data store and cache store are two different transactions) to
    the data store, there should be a rollback mechanism implemented in case there
    is ever a failure.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, this is much more complex to implement as opposed to write-through
    due to the additional handling needed to avoid any data loss during asynchronous
    updates, but it's still a good pattern to integrate if there is a requirement
    to have the cache store as the primary source.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the patterns discussed up to now can be visualized at a high level as shown
    in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Cache patterns'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.5_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Cache patterns
  prefs: []
  type: TYPE_NORMAL
- en: Up to now, we have seen various caching patterns and strategies. In the next
    section, we will discuss various cache providers and their integration with .NET
    6 applications.
  prefs: []
  type: TYPE_NORMAL
- en: Caching platforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '.NET 6 supports multiple caching platforms. A few of the commonly used cache
    platforms are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`w3wp.exe`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distributed cache**: Data is stored across multiple servers. The data stores
    that can be integrated with .NET 6 applications are SQL Server, Redis, and NCache.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-memory cache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To configure memory caching, after creating a new ASP.NET Core 6 MVC/Web API
    application, or for an existing ASP.NET Core 6 MVC/Web API application, the following
    code changes are required:'
  prefs: []
  type: TYPE_NORMAL
- en: Add `builder.Services.AddMemoryCache()` to `Program.cs`. The `MemoryCache` class
    is a built-in implementation of `IMemoryCache` in .NET 6 and would be available
    in any C# class via `IMemoryCache`. It is instantiated using constructor injection.
    Object creation happens using `IMemoryCache` and create an instance of `MemoryCache`
    using constructor injection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`MemoryCache` exposes many methods, but a few important ones are `Get` (to
    get the value of a key), `Set` (to insert a key and its value), and `Remove` (to
    remove a key (cache expiration)).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While creating a cache object (using `Set` or other methods), the memory cache
    can be configured for various parameters using `MemoryCacheEntryOptions`. The
    following properties are supported:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a. `SetAbsoluteExpiration`: The absolute `TimeSpan` or the exact date and time
    (`DateTime`) until which the cache is valid.'
  prefs: []
  type: TYPE_NORMAL
- en: 'b. `SetSlidingExpiration`: The inactive time for the cache after which the
    cache entry is removed from the cache. For example, a sliding expiration value
    of 5 seconds will wait for the cache entry to be inactive for 5 seconds. Sliding
    expiration should always be less than absolute expiration as the cache would expire
    after the absolute expiration duration has been reached irrespective of the sliding
    expiration duration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'c. `SetPriority`: As cache size is limited while performing cache eviction
    (`SetPriority` can be used to set the priority for a cache entry through a `CacheItemPriority`
    enum. Its default value is `CacheItemPriority.Normal`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple Web API controller with memory cache integration as per the preceding
    steps will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, this code is self-explanatory and has an API using an in-memory
    cache.
  prefs: []
  type: TYPE_NORMAL
- en: 'One additional method that is available in `MemoryCache` is the integration
    of a callback method that is available through `RegisterPostEvictionCallback`.
    This is an extension method in `MemoryCacheEntryOptions` that accepts a `PostEvictionDelegate`
    delegate and a callback is triggered during cache entry expiration. The signature
    of `PostEvictionDelegate` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'So, that means the callback that we pass to `RegisterPostEvictionCallback`
    should follow the same signature, and as you can see, all the input parameters
    are self-explanatory. So, let''s add a callback method and update `cacheEntryOptions`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The code map of the weather controller is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Weather controller code map'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.6_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – Weather controller code map
  prefs: []
  type: TYPE_NORMAL
- en: Once we run this code, we can see that any subsequent calls to the controller
    after the absolute expiration of 50 seconds will trigger a callback and log the
    reason as `Expiration`. Once this is deployed to `AppService`, the callback is
    automatically triggered. Only for debugging purposes would we need to make another
    call.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed cache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having discussed in-memory cache, let's move on to the other cache platforms
    that can be configured for distributed caching. Distributed caching, just like
    distributed storage systems, distributes the cache data to multiple servers to
    primarily support scaling. In this section, we will look at the different types
    of distributed cache, starting with SQL.
  prefs: []
  type: TYPE_NORMAL
- en: SQL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Distributed caching can be implemented with various stores, one of them being
    SQL Server. The first step to using SQL Server for distributed caching is to create
    the required SQL table that will store cache entries. The entire setup for SQL
    as a distributed caching store involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a command line in the administrator prompt and run the following command
    to install the `dotnet-sql-cache` package globally:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This is how it appears:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Installing the sql-cache package using the .NET CLI'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.7_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Installing the sql-cache package using the .NET CLI
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the required database (on-premises or using Azure SQL) and run the following
    command to create the table that stores cache data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this command, we are passing the connection string of the database (update
    it accordingly when running it locally) as one parameter and the other is the
    name of the table (`cache` is the name of the table in the preceding snippet).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Creating a SQL table for distributed caching'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.8_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.8 – Creating a SQL table for distributed caching
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the command has run successfully, if we open the SQL server in SSMS, we
    will see a table as shown in the following screenshot that has the columns and
    indexes required for optimization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Cache table in SQL distributed caching from SSMS'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.9_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9 – Cache table in SQL distributed caching from SSMS
  prefs: []
  type: TYPE_NORMAL
- en: Create a Web API application and install NuGet `Microsoft.Extensions.Caching.SqlServer`
    (either through the **Package Manager Console** (**PMC**) or using the .NET CLI).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In `Program.cs`, add the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To insert data into the cache, we need to make use of `IDistributedCache`,
    and the object will be created via constructor injection. So, clean up all the
    code in `WeatherForecastController` (the default controller created during the
    creation of the ASP.NET Core 6 Web API project) and add the following code (a
    Web API controller that has a `Get` method):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following `Get` method, which uses `distributedCache` and saves data
    to the cache store (SQL in this case):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the application and we can see that the cache entry is getting stored in
    the SQL database, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/Figure_8.10_B18507.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Cache table in SQL distributed caching
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the code is very much like the `MemoryCache` code, except that
    we use `IDistributedCache` here to read/write data to cache and `DistributedCacheEntryOptions`
    for setting additional properties during cache entry creation.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few recommendations for using SQL Server as a distributed caching store are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: SQL Server can be picked if the existing application does not support stores
    such as Redis. For example, an on-premises application that only integrates with
    SQL Server can easily extend SQL Server for caching purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cache database should be different from the application database as using
    the same databases can cause bottlenecks and defeats the purpose of using a cache.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The built-in implementation of `IDistributedCache` for SQL Server is `SqlServerCache`
    and does not support serializing a different schema for the caching table. Any
    customization has to be manually overridden by implementing `IDistributedCache`
    in a custom class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Up until now, we have seen in-memory caching and distributed caching using SQL
    Server. In the next section, we will see how to use Redis (one of the recommended
    stores and a widely used store for caching) for distributed caching in .NET 6
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Redis is an in-memory data store that is used for various purposes, such as
    databases, cache stores, and even as a message broker. The core data structure
    that Redis supports is key-value pairs where the value could be something as simple
    as a string, to a custom complex data type (nested classes). Redis works with
    an in-memory dataset and can also persist data to disk on a per-need basis. Redis
    also internally supports replication and automatic partitioning with Redis Cluster.
    With all these features available out of the box, it's an ideal store for distributed
    caching.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure provides a managed instance for Redis servers known as **Azure Cache
    for Redis**, and just like any other PaaS service, it is managed by Microsoft.
    This allows application developers to integrate it as is and leave the infrastructure
    overhead of maintaining, scaling, and upgrading the Redis server to Microsoft.
    Azure Cache for Redis can be used for distributed caching and can be easily integrated
    into .NET 6 applications using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create an instance of Azure Cache for Redis as outlined at [https://docs.microsoft.com/en-in/azure/azure-cache-for-redis/quickstart-create-redis](https://docs.microsoft.com/en-in/azure/azure-cache-for-redis/quickstart-create-redis).
    Navigate to **Access keys** and copy the value under **Primary connection string**,
    as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.11 – Cache key from Azure Cache for Redis'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.11_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.11 – Cache key from Azure Cache for Redis
  prefs: []
  type: TYPE_NORMAL
- en: Create an ASP.NET Core 6 Web API application and install the NuGet `Microsoft.Extensions.Caching.StackExchangeRedis`
    package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In `Program.cs`, add the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Update the default `WeatherForecastController` controller with the same code
    as shown in the previous *SQL* section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the application and we can see that data gets stored in the cache for 10
    seconds. Any calls within 50 seconds to this API will retrieve data from the cache.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Azure Cache for Redis also comes with a console that allows us to query the
    Redis server using Redis CLI commands. The console can be found in the Azure portal
    by navigating to the overview left menu of the Redis instance. Querying it for
    the `Weather` key will give us the results shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Redis console'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_8.12_B18507.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.12 – Redis console
  prefs: []
  type: TYPE_NORMAL
- en: If we go with the Premium tier of Azure Cache for Redis, it also supports multiple
    shards to support higher volumes of data and geo-replication for high availability.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, to add/remove keys from the cache store, there are the `GetAsync`
    and `SetAsync` methods, which can be used to store more complex types or any type
    other than string. However, these methods return/accept `Task<byte[]>`, so the
    application needs to handle serialization/deserialization, which can be seen in
    the reusable caching library.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Redis is the most preferred cache store for enterprise applications, and in
    our e-commerce application, we will use Azure Cache for Redis as our cache store.
    Some additional information about Azure Cache for Redis can be found at [https://docs.microsoft.com/en-in/azure/azure-cache-for-redis/](https://docs.microsoft.com/en-in/azure/azure-cache-for-redis/).
  prefs: []
  type: TYPE_NORMAL
- en: Other providers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As you can see, distributed caching in .NET 6 applications is driven by `IDistributedCache`,
    and whichever store''s implementation is injected in the `Program` class cache
    store is configured accordingly. Additionally, there are two more providers that
    .NET 6 has a built-in implementation for:'
  prefs: []
  type: TYPE_NORMAL
- en: '`IDistributedCache`. NCache can be integrated like Redis or SQL. However, the
    NCache server needs to be configured locally for development and can be configured
    in IaaS using virtual machines or PaaS using app services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AddDistributedMemoryCache`): This is another built-in implementation of `IDistributedCache`
    and can be used similarly. It can be used for unit testing. Since it''s not a
    distributed cache and uses process memory, it is not recommended for multiple
    application server scenarios. The only difference between `AddMemoryCache(IMemoryCache)`
    and `AddDistributedMemoryCache(IDistributedCache)` is that the latter one requires
    serialization to store complex data. So, if there is a type that cannot be serialized
    and needs to be cached, go with `IMemoryCache`, otherwise go with `IDistributedCache`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In enterprise applications, `IDistributedCache` can address all the caching
    layer implementation, and a combination of in-memory cache for a development/testing
    environment and Redis for a production environment would be ideal. If your application
    is hosted on a single server, you can go with an in-memory cache but that's very
    rare for production applications, hence it is most recommended to go with distributed
    caching.
  prefs: []
  type: TYPE_NORMAL
- en: So, based on all the principles and patterns that we've discussed, we will design
    a cache abstraction layer to be used in an e-commerce application, which is discussed
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a cache abstraction layer using distributed caching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In enterprise applications, it's always good to have a wrapper class on top
    of an underlying cache implementation as it abstracts the core logic of caching
    and can also be used as one single class that holds application-wide default cache
    entry options.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be implementing a cache wrapper class with an underlying store as Azure
    Cache for Redis using the `IDistributedCache` implementation. It''s a .NET Standard
    2.1 class library; the source code for this library is available in the `Packt.Ecommerce.Caching`
    project. Any class that wants to cache data should inject `IDistributedCacheService`
    using constructor injection and can call the following various methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`AddOrUpdateCacheAsync<T>`: Adds or updates cache entries of type `T` asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AddOrUpdateCacheStringAsync`: Adds or updates cache entries of the string
    type asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GetCacheAsync<T>`: Gets cache entries of type `T` asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`GetCacheStringAsync`: Gets cache entries of the string type asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RefreshCacheAsync`: Refreshes cache entries asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RemoveCacheAsync`: Removes cache entries asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DistributedCacheService` is the wrapper class that inherits `IDistributedCacheService`
    and implements all the preceding methods. Additionally, `IDistributedCache` and
    `DistributedCacheEntryOptions` are configured in this class to use distributed
    caching.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For serialization and deserialization, we will use `System.Text.Json`, a custom
    `IEntitySerializer` interface, and the `EntitySerializer` class is created with
    the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SerializeEntityAsync<T>`: Serializes the specified object to a byte array
    asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DeserializeEntityAsync<T>`: Deserializes the specified stream asynchronously'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `IEntitySerializer` implementation is injected into the `DistributedCacheService`
    class using constructor injection and is used for serialization and deserialization.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the *Serialization performance comparison* article, which talks
    about benchmarking various serializers. You can find it at [https://maxondev.com/serialization-performance-comparison-c-net-formats-frameworks-xmldatacontractserializer-xmlserializer-binaryformatter-json-newtonsoft-servicestack-text/](https://maxondev.com/serialization-performance-comparison-c-net-formats-frameworks-xmldatacontractserializer-xmlserializer-binaryformatter-json-newtonsoft-servicestack-text/).
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of `DistributedCacheService` and `EntitySerializer` follows
    all the asynchronous principles discussed in [*Chapter 4*](B18507_04_Epub.xhtml#_idTextAnchor205),
    *Threading and Asynchronous Operations*, and the configuration as explained in
    [*Chapter 6*](B18507_06_Epub.xhtml#_idTextAnchor473)*, Configuration in .NET 6*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, in an API/MVC application, perform these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Install the NuGet `Microsoft.Extensions.Caching.StackExchangeRedis` package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Configure caching by adding the following code snippet to `Program.cs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'From a configuration standpoint, two properties are added to `appsettings.json`,
    as shown here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Any class that wants to cache data needs to add a reference to the `Packt.Ecommerce.Caching`
    project and inject `IDistributedCacheService`, and can call the aforementioned
    methods to read/update/insert data in the cache store. The following is a code
    snippet of a method using the cache service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are using the cache-aside pattern and checking for the `Country` key
    in the cache store first. If found, return it from the function, otherwise retrieve
    it from the database and insert it into the cache, and then return from the function.
    We will heavily use the cache service in [*Chapter 10*](B18507_10_Epub.xhtml#_idTextAnchor1040),
    *Creating an ASP.NET Core 6 Web API*.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we have used a few of the patterns that we discussed in earlier
    sections. There are also a few additional considerations discussed in the next
    section, which need to be kept in mind while designing the cache layer in an enterprise
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Caching considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Having a cache layer is critical for improving performance and scalability
    in enterprise applications. Hence, the following are a few factors that need to
    be considered while developing the caching layer:'
  prefs: []
  type: TYPE_NORMAL
- en: If we are building a new application, then Azure Cache for Redis can be the
    starting point using the `IDistributedCache` implementation as it can easily be
    plumbed into the application with a few lines of code. However, this comes at
    a cost that needs to be evaluated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For an existing project, the current infrastructure plays a critical role and
    SQL can be the default choice if SQL Server is already being used as a data store.
    However, it's good to benchmark the performance of SQL against Redis, and a decision
    can be taken accordingly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having a wrapper class on the underlying cache store is a good approach as it
    decouples the application from the cache store and makes the code more flexible
    and easily maintained in case of future changes in the cache store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The methods of `IMemoryCache` and `IDistributedCache` are not thread-safe. For
    example, say a thread queries a key from the cache and finds it isn't there in
    the cache, and falls back to the original data store. While data is retrieved
    from the original store if another thread queries the same key, it won't wait
    for the first thread to finish reading from the database. The second thread will
    also end up falling back to the database. So, thread safety needs to be handled
    explicitly, possibly in the wrapper class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Response caching should be implemented along with application caching for even
    more optimization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`If-None-Match` request header and if there is a match, the server returns
    `304` (no change) and the client can reuse the cached version of the data. For
    ETag, there is no built-in implementation on the server side, so a filter or middleware
    can be used to implement server-side logic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although we used JSON serialization in our implementation, there are other formats,
    such as BSON or protocol buffers, that should be evaluated for serialization and
    deserialization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just like any other component in application development for caching, there
    is no one-size-fits-all solution. So, the preceding points should be evaluated
    and an appropriate caching solution implemented accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about various caching techniques, patterns, and
    their benefits in improving application performance. Furthermore, we learned about
    HTTP caching, how response caching can be integrated into an API response, and
    further various available caching providers and their integration with .NET 6
    applications. We also learned how to implement distributed caching using `IDistributedCache`
    and built a cache abstraction layer that will be used in subsequent chapters for
    caching requirements. Some of the key information and skills that we learned about
    along the way were why and when caching is needed and how to implement caching
    in .NET 6 applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at various data stores and providers in .NET
    6 and their integration with .NET 6 applications.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Which of the following values for the `Cache-Control` header allows the response
    to be stored in any server (client/server/proxy)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. `Private`
  prefs: []
  type: TYPE_NORMAL
- en: b. `Public`
  prefs: []
  type: TYPE_NORMAL
- en: c. `No-cache`
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer: b**'
  prefs: []
  type: TYPE_NORMAL
- en: In a multiple-application server scenario, which of the following caching platforms
    should we choose?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Distributed caching
  prefs: []
  type: TYPE_NORMAL
- en: b. In-memory caching
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer: a**'
  prefs: []
  type: TYPE_NORMAL
- en: 'True or false: In the cache-aside pattern, data is first updated in the cache
    store and then in the underlying data store.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. True
  prefs: []
  type: TYPE_NORMAL
- en: b. False
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer: b**'
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following caches is best suited to store static files and image
    files and supports geo-replication?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. Web server caching
  prefs: []
  type: TYPE_NORMAL
- en: b. Application caching
  prefs: []
  type: TYPE_NORMAL
- en: c. Content Delivery Network (CDN)
  prefs: []
  type: TYPE_NORMAL
- en: '**Answer: c**'
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can read more about caching here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/Alachisoft/NCache](https://github.com/Alachisoft/NCache)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://redis.io/](https://redis.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/redis/](https://aws.amazon.com/redis/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-configure#redis-console](https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-configure#redis-console)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Features (terracotta.org)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
