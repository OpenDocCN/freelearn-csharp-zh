- en: Chapter 9. Functional Programming Techniques for Better State Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While writing concurrent/parallel code, handling state is difficult in an imperative
    program (something that you would have seen by now). Modern languages and platforms
    borrow idioms and practices that enable better state management and facilitate
    strong concurrency models from the functional programming community. In this chapter,
    we will see what those are and try to understand, through code samples, how to
    best leverage some of those features (striving for coverage would stretch this
    chapter to an entire book) to our advantage. We would also see how C# has evolved
    as a language to bring the best of both worlds (imperative and functional), and
    to help you apply functional thinking to model real-world scenarios. This chapter
    will also cover **Language Integrated Query** (**LINQ**) as a mechanism for writing
    compositional code. Through this journey, we will uncover some good design practices,
    leveraging the functional constructs in the language (primarily C#). We hope this
    chapter serves as a starter kit by providing you with some of the techniques and
    tools to tackle programming tasks in a functional way. Some of the ideas covered
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: Being functional
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Referential transparency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First class functions (also higher order functions)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lambda calculus and anonymous functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Currying and partial function application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A brief overview of how LINQ works
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Being functional
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functional programming is a programming paradigm that involves algorithm composition,
    to be dealt on the same lines as mathematical function evaluations. This implies
    that the output of these functions would purely depend on the inputs provided.
    Moreover, any applicable data structures that the algorithm would need to create
    the output would be transient, having a lifetime within the function scope, and
    thus help in avoiding state mutation. It is also a powerful declarative programming
    paradigm, which involves leveraging expressions for readable code in place of
    procedural in-line statements.
  prefs: []
  type: TYPE_NORMAL
- en: Referential transparency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's delve a bit deeper to understand the consequences of being functional,
    as illustrated by the definitions given in the preceding section. Now, when we
    try to relate functions from both these worlds (mathematical and imperative programming),
    we see a strong disparity, as the latter mutates state with commands in the source
    language, thereby bringing in side effects (though desirable from an imperative
    programming standpoint). This violates one of the fundamental pre-requisites of
    functional programming - that of referential transparency, that is, the same expressions
    (when run at different times) yield different values with respect to the executing
    program's state. This affects the predictability of the program, which is definitely
    not desirable. On the other hand, pure functions (say *f*, one without such side
    effects) in the mathematical world would yield the same result *f(x)* each time
    with the same value of *x*, say *sin(x)*. This characteristic is attributed to
    idempotency in software behavior (delivers consistency). Now you understand how
    this characteristic became so fundamental to functional programming.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand the consequence of this by looking at two functions: one
    which is referentially opaque (with side effects), and the other which is referentially
    transparent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The function `AddOneRT` is referentially transparent, which means that `AddOneRT
    (x) = AddOneRT (y)` if `x = y`. However, we can't say any such thing for `AddOneRO`,
    because it uses a global variable (`i`) that it modifies.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now since `AddOneRO (x) <> AddOneRO (y)` if `x = y`, this further implies `AddOneRO
    (x) - AddOneRO (x) <> 0`, thus invalidating the fundamental mathematical identity
    (`x - x = 0`)!
  prefs: []
  type: TYPE_NORMAL
- en: This has major consequences in terms of code robustness and optimization by
    means of memorization (caching intermediate results), common subexpression elimination
    (where the result of a pure expression can be substituted in place of repeated
    evaluations without affecting the program behavior), lazy evaluation, or parallelization.
    So, in order to reap the benefits of these consequences from functional computation,
    one needs to strive to get the functions to be as referentially transparent (that
    is, free from the side effects of memory and I/O) as a mathematical function.
    With this, we come to the next important functional programming feature where
    functions become first-class citizens.
  prefs: []
  type: TYPE_NORMAL
- en: First-class and higher-order functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functions are the fundamental processing units in functional programming, and
    since they can be used like any other value, functions can be stored in variables,
    properties, objects, and collections. The term first-class function was created
    by Christopher Strachey.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Higher-order functions are functions that can either take other functions as
    arguments or return them as results.
  prefs: []
  type: TYPE_NORMAL
- en: C# supports higher-order functions (both named and anonymous), which are treated
    like ordinary variables with a function type.
  prefs: []
  type: TYPE_NORMAL
- en: Function type
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: C# provides the capability to define both generic functions and strongly typed
    delegates. The delegate type carries the method signature of a function prototype,
    and its instances become function pointers. Thus, you can manipulate a function
    variable whose function method signature matches with that of the function prototype.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to generic function types, C# 2.0 introduced anonymous methods/delegates
    and iterators (with the `yield return` statement which lets you create iterator/continuation
    methods that return sequences based on the caller''s demand/pull. That is, you
    get the benefit of deferred execution without incurring storage allocation overheads
    for the input and output sequences), which provided more flexibility and compositional
    capability. We can also use the following three generic function types that C#
    provides:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A function that takes multiple type arguments, and returns result of a particular
    type:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'A procedure that takes multiple type arguments, and performs action/s without
    returning any result:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'A function that takes multiple type arguments, and returns a Boolean result:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the preceding function types in action as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'A client using the anonymous delegate syntax would consume the preceding static
    methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you can see, this deferred execution model makes your algorithms use less
    storage space and compose better than traditional imperative methods. More importantly,
    with functional purity you'll be able to leverage parallelism by assigning different
    operations to different CPU cores, thereby improving throughput.
  prefs: []
  type: TYPE_NORMAL
- en: Now it's time to look at a core functional programming concept which was adopted
    in C# 3.0, that is, lambda expressions that facilitated wide adoption of functional
    programming practices (with little or no knowledge on it's consequences) in the
    imperative world.
  prefs: []
  type: TYPE_NORMAL
- en: Lambda (λ) calculus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: λ-calculus is a mathematical formalism for denoting computation in an abstract
    form using functions. This brings forth a formal notation and transformation rules
    for representation (function abstraction) and manipulation (function application)
    of lambda terms. The key to this formalism is variable binding and substitution.
    **Alonzo Church** created lambda calculus in an attempt to prove mathematical
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The λ-calculus provides a simple semantics for computation using computable
    functions based on **Church-Turing** thesis (readers are urged to take a look
    at the history of lambda calculus, its motivation, and mathematical implications
    at a little deeper level to better appreciate this formalism and its consequences,
    as opposed to just being sheer consumers) by incorporating the following simplifications
    and concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Anonymous functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This involves treating functions as anonymous, without giving them explicit
    names. For example, take this simple `static` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If you rewrite the preceding static method, the equivalent representation as
    an anonymous delegate would be what is highlighted in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the corresponding lambda expression would be the one highlighted in this
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Another lambda expression that follows the same function signature, yet bringing
    in a polymorphic behavior, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now you can see the formal syntax that lambda expressions obey, as stated in
    the definitions given earlier, which denotes that variables `x` and `y` are bound
    to the lambda term `x + y`. You just witnessed the lambda abstraction for the
    function *f(x, y) = x + y*. The function definitions (`AddOperation` and `ConcatOperation`)
    with this lambda abstraction just sets up the function without invocation. An
    application in lambda calculus parlance, with respect to the preceding example,
    would signify applying inputs `x` and `y` to the function *f*.
  prefs: []
  type: TYPE_NORMAL
- en: Function application in lambda calculus is achieved through **beta reduction**
    (a continuous reduction process involving substitution of bound variables to the
    lambda terms till no applications remain for reduction). A function application
    in lambda calculus is analogous to method invocation in the imperative world,
    except that the consequences are totally different, which you would have understood
    by now.
  prefs: []
  type: TYPE_NORMAL
- en: Closures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned earlier, the key to formalism is variable binding and substitution.
    Bound variables are the ones that fall within the scope of an abstraction. The
    remaining variables are said to be free (from the context of that specific abstraction).
    A closed lambda expression is one with no free variables.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Something to note here is that a variable is bound by its nearest abstraction,
    which means that a free variable, with respect to an abstraction, would eventually
    be bound to higher abstractions in the hierarchy. And this free or unbound variable
    (with its associated references and values), which gets captured in the context
    of an abstraction (that is, the lexical Scope), constitutes a closure (again pertaining
    to that abstraction).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code clearly shows a closure in action. Here, the closure object
    (which constitutes of variable `x` and its target method) helps to share data
    between the functions. The use of this higher-order `sum` function (where new
    functions are composed and returned) is illustrated clearly in the following code
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Currying and partial application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Partial application and currying are two distinct techniques, yet loosely depicted.
    It is facilitated by the capability of higher-order functions, wherein their partial
    application (against one or multiple arguments) returns new functions (that accept
    the remaining arguments) with lesser arity (compared to the original function).
  prefs: []
  type: TYPE_NORMAL
- en: Let's now understand the difference between currying and partial application.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Currying is a natural consequence of lambda calculus, where functions employ
    only a single input. This technique primarily involves conversion of a function
    evaluation that accepts multiple arguments (as in any practical function) into
    a series of function evaluations that accept one argument at a time. Currying
    got its name from Haskell Curry, who developed it following the work of Gottlob
    Frege and Moses Schönfinkel.
  prefs: []
  type: TYPE_NORMAL
- en: Without much ado, let's see these in action.
  prefs: []
  type: TYPE_NORMAL
- en: Currying
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s go back to our old example here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now this is a simple and practical function we employ mostly. Let''s see how
    this is deftly curried to generate functions that accept one argument at a time,
    and yet leverage the core function for function application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Any client would leverage the curried function this way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'There''s another interesting way to curry functions; as a matter of fact, we
    can curry any arbitrary function using the function definition (delegate in our
    case). Here we leverage e**xtension methods** (a language feature introduced in
    version 3.0) to provide innate currying capability to a generic function definition:
    `Func<T1, T2, TReturn>`. This means you can apply currying to any function that
    has this method signature. See the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The keyword `this` in the highlighted code enables the extension method magic
    for you (which essentially decorates the generic delegate type `Func<T1, T2, TReturn`)
    with the curry function. **Voila**! We finally have imparted innate currying capability
    to any function that conforms to this definition. Take a look at the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now to replicate the same thing in the polymorphic function below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You could continue (as shown in the next code) to create more curry function
    overloads to support additional function definitions (that has more than two input
    parameters):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Partial application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let's look at partial application which is distinctively different from
    currying, though highly confusing to many programmers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Partial application (or partial function application) is yet another consequence
    of lambda calculus where functions employ a fixed set of inputs. This technique
    primarily involves conversion of a function evaluation that accepts multiple arguments
    (as in any practical function) into a function that accepts a fixed number of
    arguments, which in turn yields yet another function that accepts the remaining
    arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code says it all:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Applying currying and partial application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s see these two in action in a real programming scenario. The scenario
    we would look at is a classic mathematical conundrum - that of determining the
    Pythagorean Triples within a given range. As the name suggests, the Pythagorean
    triple constitutes the set of numbers that satisfy the Pythagorean theorem (*a²
    + b² = c²*). The conventional method to find the triples is shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This preceding code continuously yields the triplets as and when it is discovered.
    Another interesting thing about the brute force approach here is that it returns
    duplicates (for example-[3, 4, 5] and [4, 3, 5], [6, 8, 10] and [8, 6, 10], and
    so on. The filter (highlighted code), in conjunction with the **HashSet**, helps
    eliminate these duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s see the same code leveraging curried functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In this case the curried function is created, based on the formula that proves
    the Pythagorean theorem, which would accept a valid input for `a`, `b`, and `c`
    consecutively, and final evaluation is done when the last argument is received.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s check out partial application usage in this same scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can clearly see the distinction between currying and partial application.
    The result yielded by partial application becomes a closure (gets captured) for
    reuse in place of function captures in the currying approach. This early evaluation
    (*a²* and *b²*) in the case of partial application would give an advantage for
    reuse in subsequent iterations in place of repeated deferred evaluations with
    respect to currying. The real use of currying and partial application is seen
    when inputs are generated asynchronously for consumption by a grand computation
    function. You could capture or partially compute as and when these inputs are
    generated, and trigger the final evaluation on obtaining the last input. Another
    thing to note is that partial application can accept more than one arguments (unlike
    the example shown here where it accepts one as in currying). A typical consumer
    client would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we guess no more confusions on these two concepts from now on! Another
    adventure (if you''re game; yes, we dare you) is to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Optimize this algorithm (now you know there are *range3* iterations and the
    performance impact is huge when you go beyond the range of 1,000).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making the filter operation lazily evaluated as part of the LINQ consumer query
    which would yield duplicates (without the HashSet in the first place). And again,
    nothing actually stops you from figuring out a way to generate triplets without
    duplicates!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure out a way to generate triples forever as they are detected (without the
    limitation of a range, loop, or any computation limits (such as reaching the max
    value for a 64-bit signed integer).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expression trees
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By now you have seen how to create delegates from a lambda expression (anonymous
    function). You can also opt to create expression tree types. Expression trees
    are analogous to **Abstract Syntax Tree** (**AST**) in the compiler construction
    realm, and they embody code in a tree data structure, where each node is represented
    as an expression. Using expression trees, you can compile and run code, thereby
    gaining powerful ability to dynamically modify executable code.
  prefs: []
  type: TYPE_NORMAL
- en: '|   | *Expression trees are also used in the Dynamic Language Runtime (DLR)
    to provide interoperability between dynamic languages and the .NET Framework and
    to enable compiler writers to emit expression trees instead of Microsoft Intermediate
    language (MSIL).* |   |'
  prefs: []
  type: TYPE_TB
- en: '|   | --*MSDN* |'
  prefs: []
  type: TYPE_TB
- en: Expression trees are inherently immutable. All that we need to get the compiler
    emit the code for an expression tree is to assign the lambda expression to a variable
    of type `Expression<TDelegate>`. The .NET framework provides a rich API (expression
    class under **System.Linq.Expressions Namespace**) for parsing, creation, and
    manipulation (of course recreating with appropriate tree visitors). The API supports
    most of the language grammar.
  prefs: []
  type: TYPE_NORMAL
- en: Altogether, this becomes a very powerful construct that can be leveraged for
    code/dependency injection, **Domain-Specific Language** (**DSL**) creation, and
    associated language translations (all you would need to do in such a case is to
    let your dynamic language **lexer** and **parser** to generate the **Abstract
    Syntax Tree** (**AST)**, which in our case is the expression tree itself, and
    DLR would do the rest. Don't think twice before embarking on your next DSL adventure.
    There is inherent platform support!)You finally understand how a lambda expression
    (an anonymous function) can be used to create delegates or expression tree types.
    By using lambda expressions, you can write local functions that can be passed
    as arguments or returned as the value of function calls.
  prefs: []
  type: TYPE_NORMAL
- en: Recursion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Recursions are no alien feature to any programmer worth his salt. Recursions
    are leveraged in functional programming to accomplish iteration/looping. Recursive
    functions invoke themselves, performing an operation repeatedly till the base
    case is reached. Tail call-based recursions are a common phenomenon. Recursion
    typically involves adding stack frames to the call stack, thus growing the stack.
    You can run out of stack space during deep recursions. The compiler does its own
    share of optimizations (predominantly tail call optimization/elimination) to conserve
    stack space and improve throughput. But the functional world (with its first-class
    and higher-order functions) gives us more flexibility to wire such optimizations
    in our recursive functions. Let''s see how this is achieved with the following
    factorial example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Unlike the classical example, you see how recursion is put to work by lambda
    expressions as well, which makes you use these anonymous functions as higher order
    functions (where they are dynamically created or passed as arguments). You can
    also notice the use of a wrapper function (factorial in this case), which is directly
    called, but does not recurse itself, and instead, leverages an auxiliary function
    (`fIterator` in this case) to do the actual recursion.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The wrapper function becomes handy for performing parameter validations, error
    handling, memorization, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to conserve stack space, we can opt for a tail call elimination technique
    known as tail recursion as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In this case, no state, except for the calling function's address, needs to
    be saved either on the stack or on the heap, and the call stack frame for `fIterator`
    is reused for storage of the intermediate results. Another thing to note is the
    addition of an accumulator argument (product in this case).
  prefs: []
  type: TYPE_NORMAL
- en: 'Tail recursion can be achieved by another technique called **trampolining**,
    where functions are called by a `trampoline` function as opposed to functions
    calling each other directly. All the needed payload (function pointer and arguments)
    for the function call is provided to the `trampoline` function, which then places
    the call on the caller''s behalf. This ensures that the stack does not grow and
    iteration can continue indefinitely:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The following image depicts the supporting language constructs that have evolved
    to make these functional programming features available for consumption:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Recursion](img/B05691_09_01-1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Sample programs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have taken a detailed look at the core functional programming constructs,
    it's time to indulge in power play (with code of course). Let's learn to play
    the game with some hardcore sample programs.
  prefs: []
  type: TYPE_NORMAL
- en: Spell checker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This was inspired by Peter Norvig's (former Research Director at Google) technical
    blog on *How to Write a Spelling Corrector*. What is interesting is the way the
    solution has been envisaged. The solution employs the probability theory at its
    core to find all possible corrections for a word of length *n*, by accounting
    for user errors in the form of typos arising because of omissions (deletes), characters
    misplaced (replaces and transposes), and inserted (inserts).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can refer to this technical blog on *How to Write a Spelling Corrector*
     by Peter Norvig for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For a word of length *n*, there will be *n* deletions, *n-1* transpositions,
    *26n* replacements, and *26(n+1)* insertions.
  prefs: []
  type: TYPE_NORMAL
- en: To have fair shot at determining the corrections, we do find all possible corrections
    that are 1 (`edits1` function) and 2 (`edits2` function) distance away. You would
    be able to see the function compositions in the code given next using LINQ queries
    that yield these possible corrections in a breeze. This demonstrates the expressive
    and declarative power of lambda expressions.
  prefs: []
  type: TYPE_NORMAL
- en: What is most important, and to ensure the right filtering of this huge set (for
    meaningful corrections), is to determine what are the known or meaningful words.
    For this a dictionary is either fed or created (in our case) from a corpus of
    free text from Project Gutenberg, and lists of the most frequent words from Wiktionary
    and the British National Corpus. The text is extracted, concatenated, and provided
    in the text file `NSC_Training_Model.txt` (you could also directly obtain this
    from [http://norvig.com/big.txt](http://norvig.com/big.txt)). The `known` function
    does this filtering for you.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to determine the list of corrections in the order of recommendation, we
    employ the probability of occurrence of the known corrections in the dictionary
    created out of the corpus (as it becomes a good indication of common usage). Now
    you know how personalized spelling correctors work on your mobile device! (Yes,
    you guessed it right, it certainly is based on the probability of the list of
    possible corrections in the order of your usage of words).
  prefs: []
  type: TYPE_NORMAL
- en: The authors encourage the readers to visit the site ([http://norvig.com/spell-correct.html](http://norvig.com/spell-correct.html)),
    and take a look at the detailed explanation of the solution. One of the authors
    has his JavaScript implementation published on the site as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The function `NorvigSpellChecker` shown below returns a list of potential corrections
    based on the word and count (maximum items in list) specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'A declarative style of coding with lambda expressions has been employed fluidly
    in realizing this spell checker. You could see how the algorithm is composed using
    LINQ expressions. Closures, concurrency, and parallelism (in the form of PLINQ)
    has been employed in realizing this function. A typical consumer of this spell
    checker would be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We urge interested developers to explore options to further parallelize the
    algorithm/steps, and see the results (at least from a performance standpoint).
    It would be a worthwhile journey to understand that the parallelization constructs
    at your disposal (especially PLINQ and TPL) are not mere silver bullets!
  prefs: []
  type: TYPE_NORMAL
- en: Subset generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This problem has a classical implication on a variety of NP-complete problems
    that we are exposed to in daily life. The procedural and generic serial implementation
    is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: As you see, the preceding algorithm leverages Boolean logic to determine the
    unique sets. The possible *ON (1)* states of the gates determine the sets, and
    we just need to determine the index of the element in the array (that has the
    complete list of elements whose sets need to be determined) that yields a state
    of 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'The declarative equivalent of the preceding implementation has been realized
    with PLINQ as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to take this to the next level, since this has a limit (9,223,372,036,854,775,807
    - max value for a 64-bit signed integer) on the `_mask`, that is, computing the
    total possible combinations, we would have to trade this algorithm for another
    which can continuously generate subsets, that too, forever. This is the power
    of deferred execution and continuation methods (supported by the `yield return`
    keyword). Let''s see this algorithm (again optimized for some amount of parallelism
    which becomes significant for large set generation). This also employs Boolean
    logic but in a different way. It computes 1- bit addition forever, in this case
    using the full adder logic (as the resulting bits directly represent the set):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Subset generation](img/B05691_09_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The parallelization done here is to chunk the binary additions for each `overFlow`
    (as the code indicates). For example, say there are three elements namely, 10,
    20, and 30\. The process of determining the sets (including chunking) would happen
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Bits** | **Chunks** | **Resulting set** |'
  prefs: []
  type: TYPE_TB
- en: '| 0 - 0 - 1 | 1 | [30] |'
  prefs: []
  type: TYPE_TB
- en: '| 0 - 1 - 0 | 2 | [20] |'
  prefs: []
  type: TYPE_TB
- en: '| 0 - 1 - 1 | 2 | [20, 30] |'
  prefs: []
  type: TYPE_TB
- en: '| 1 - 0 - 0 | 3 | [10] |'
  prefs: []
  type: TYPE_TB
- en: '| 1 - 0 - 1 | 3 | [10, 30] |'
  prefs: []
  type: TYPE_TB
- en: '| 1 - 1 - 0 | 3 | [10, 20] |'
  prefs: []
  type: TYPE_TB
- en: '| 1 - 1 - 1 | 3 | [10, 20, 30] |'
  prefs: []
  type: TYPE_TB
- en: 'The initial set of bit (*0-0-0*) which yields an empty set is ignored here.
    The overflows are indicated by the high-lighted rows, and the bits that shift
    are represented as bold. The throughput was observed to be ~three times faster
    than the serial implementation on a quad-Core computer! In case you''re wondering
    why parallelization has been restricted to one level, the authors urge you to
    find out the effect of parallelizing/optimizing further. This is a NP-complete
    problem that would demand *2n* cores for the ultimate parallelization! It would
    be interesting to see how these sets could be applied for packing algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Just in case you are wondering how this could help in solving packing problems
    (of course with smaller sets), see this client given next, which generates the
    various ways in which the following packages (having weights 3, 1, 1, 2, 2, and
    1 kg) could be packed in boxes that can accommodate 5 kg. We believe this opens
    up a window of possibilities for any interested developer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: How does LINQ work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we conclude this chapter, we would like to give you a rough idea about
    how **Language Integrated Query** (**LINQ**) works under the hood, in a schematic
    manner. As we know, LINQ is a declarative language embedded inside a multi-paradigm
    language. The primary advantage of LINQ is the alignment to the rich type system
    of C#. Syntactically, LINQ is very similar to SQL language and the evaluation
    model is very similar to an SQL engine. As an example, let us explore a LINQ query
    which retrieves information regarding a set of employees by querying `Employee`
    and `Department` table. The query returns an anonymous type consisting of employee
    name, department name and location of the employee. We are using the comprehension
    syntax in this particular example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: While evaluating this LINQ statement, even though documentation states about
    outer sequence and inner sequence, schematically speaking, a cartesian product
    (aka cross join in database parlance) will be performed between `Employee` and
    `Department` table. The resulting data set will be filtered based on the join
    clause (on `emp.deptid` equals `dept.nid`), resulting in yet another data set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, a project operation will be performed (`select new { <data> }`) to create
    an instance of new anonymous type, to add into a collection. The anonymous type
    will be synthesized by the C# compiler during the compile time. The above example
    uses comprehension style syntax and it will be transformed into a lambda expression
    syntax by the C# compiler, before generating the code. When we evaluate comprehension
    queries or mixed mode queries, the C# compiler transforms everything to lambda
    syntax before generating the code. The core algorithm for evaluation of LINQ queries
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: Cartesian product (of data sets involved)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restrict or filter (where predicate)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Order by
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Group operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Projection (technical name for selecting subsets of fields, in a result)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To understand more about the query evaluation process, one can consult a book
    which deals with relational database theory, as this topics warrants another book!
    The LINQ was introduced with C# with version 3.0 of the language and the designers
    of language introduced the following features to the language to facilitate the
    implementation of LINQ. They are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lambda expressions and functions**: To facilitate the passing of predicates
    and transformations as parameters to LINQ operator functions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Extension methods**: To avoid the syntactic clutter while nesting LINQ operators
    (transformation of nested queries to fluent interface style)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anonymous types**: To allow developers to project the contents of a data
    set to types which are not declared ahead of time by the developers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Type inference**: This feature was mandated because of the difficulty for
    programmers to identify the type of result from a LINQ operations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try to understand in detail what has been covered in this section. If you are
    able to comprehend what has been dealt here tersely, it can help improve the competence
    as a developer.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Functional programming model and its idioms help a programmer to write better
    code in the many-core architecture of the modern CPUs. C# programming language
    and the .NET platform has incorporated FP constructs into the language to help
    write certain kind of code in a functional manner. The mastery of lambda expressions
    and functions, type inference, expression trees, LINQ, and so on helps structure
    our code better if used judiciously by mixing the OOP and FP codes. Mixing of
    OOP and FP to write code is termed as object/functional programming, and most
    modern day languages like C#, Scala, Java (after version 8), Ruby, and so on support
    this idiom. In the next chapter, we will implement some GoF design patterns using
    object/functional programming, and also pick up some OOP/FP programming idioms
    such as map/reduce.
  prefs: []
  type: TYPE_NORMAL
