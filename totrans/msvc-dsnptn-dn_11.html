<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-157"><a id="_idTextAnchor168"/>11</h1>
<h1 id="_idParaDest-158"><a id="_idTextAnchor169"/>Implementing the API and BFF Gateway Patterns</h1>
<p>When building an application using the microservices architectural approach, we have come to realize that we will need to keep track of several API endpoints. We have effectively gone from one endpoint, which would have been made available through a monolith, to a series of endpoints. Some of these endpoints will be called by other APIs and some will integrate directly into the client applications that interact with the microservices.</p>
<p>This becomes a challenge because we end up conflating the client application with custom logic to cater to integrating with the various services and possibly orchestrating inter-service communications. We want to keep the client application code as simple and extensible as possible, but integrating with each service does not support that notion.</p>
<p>This is where we will consider implementing the API gateway pattern, which introduces a central point of contact between the client and the services. Our API gateway will keep a record of all the endpoints and expose a single API address where the endpoints will map to the various endpoints of the other microservices.</p>
<p>In this chapter, we will look at various scenarios that will make an API gateway a good selection for our application and methods of implementation.</p>
<p>After reading this chapter, we will be able to do the following:</p>
<ul>
<li>Understand API gateways and why they are important</li>
<li>Implement an API gateway using industry-leading technology and methods</li>
<li>Properly implement the <strong class="bold">backend for frontend</strong> (<strong class="bold">BFF</strong>) pattern</li>
</ul>
<h1 id="_idParaDest-159"><a id="_idTextAnchor170"/>Technical requirements</h1>
<p>The code references used in this chapter can be found in this project’s repository, which is hosted on GitHub at <a href="https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch11">https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch11</a>.</p>
<h1 id="_idParaDest-160"><a id="_idTextAnchor171"/>What is the API gateway pattern?</h1>
<p>To understand the API gateway pattern and why we need it, we need to review the fundamentals of the service-oriented <a id="_idIndexMarker512"/>architecture and how we architect such solutions.</p>
<p>The service-oriented architecture includes three main layers to an application:</p>
<ul>
<li><strong class="bold">Client</strong>: Also referred to as the fronted. This client app is what the user sees and is designed to consume its <a id="_idIndexMarker513"/>data from an API. Its functionality is generally limited to functions that the API makes available, and a frontend developer can leverage several techniques to expose functionality to the end user.</li>
<li><strong class="bold">Server</strong>: Also referred to as the backend. This section of the architecture houses the API and the <a id="_idIndexMarker514"/>business logic. The client app is only as intelligent as the backend. The backend can be made up of one or more services, as would be the case with microservices.</li>
<li><strong class="bold">Database</strong>: The database is the anchor of this entire application since it stores all the data being <a id="_idIndexMarker515"/>used by the API backend and is displayed on the frontend.</li>
</ul>
<p>This application layout is popular in monolithic applications, where all the functionality that is needed on the frontend can be found in one API. This is an effective development method that has been at the helm of many successful and powerful applications. We have, however, explored the downsides to a monolithic approach, where the API might become bloated and difficult to maintain in the long run. The main advantage that we would seem to forsake in the pursuit of a microservices approach would be where we have a single point of entry for the client application, as opposed to several services each with requirements.</p>
<p>While the microservices architecture leads us down the path of having an application that is implemented with the service-oriented architecture, we will need to account for the fact that our client will need to keep track of several backends or APIs and be intelligent enough to orchestrate calls for each user request. This is a lot of responsibility for the portion of the application that should be the least intelligent, based on the description provided.</p>
<p><em class="italic">Figure 11.1</em> shows the client and microservices:</p>
<div><div><img alt="Figure 11.1 – The client app needs to be aware of all the endpoints of all the microservices and retain the knowledge of how each one works" src="img/Figure_11.1_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.1 – The client app needs to be aware of all the endpoints of all the microservices and retain the knowledge of how each one works</p>
<p>This is where we introduce<a id="_idIndexMarker516"/> an API gateway. This gateway will sit between our services and the client app and simplify the communication between the two. For the client, it will expose a singular base URL, which the client will gladly interact with and see as one API service; to the microservices, it will act as a conduit, where it will forward requests coming in from the client to the appropriate microservice.</p>
<p>Let us review the advantages of introducing an API gateway.</p>
<h2 id="_idParaDest-161"><a id="_idTextAnchor172"/>Advantages of an API gateway</h2>
<p>When a request comes in <a id="_idIndexMarker517"/>from a client, it is received by the gateway, which interprets the request, transforms the data if necessary, and then forwards it to the appropriate microservice. In fact, for situations where multiple microservices may need to be called, we can implement orchestration and result aggregation and return more accurate representations of the data to the client as needed.</p>
<p>Our API gateway also allows us to centralize the following tasks for our microservices:</p>
<ul>
<li><strong class="bold">Centralized Logging</strong>: From the API gateway, we can centrally log all the traffic to our various endpoints and keep track of the success and error responses from the downstream services. This is advantageous because it spares us the need to implement logging in each service and potentially have a very chatty log. Using an API gateway allows us to centralize our implementation and prioritize what gets written to the log and can help us to better catalog the outcomes of synchronous operations. We can also use the gateway to track and log statistics and response times of calls to the downstream services.</li>
<li><strong class="bold">Caching</strong>: Caching acts as a<a id="_idIndexMarker518"/> temporary data store that comes in handy when the main data source might be offline or when we need to reduce the number of times the services are called. We can use a caching layer in the gateway to stabilize our application and potentially increase the application’s performance. With proper coordination and customization, we can use this caching for high-speed read operations on endpoints that have high volumes of traffic and even use it to handle partial failure, where we use the cached data for a response when a service is unavailable.</li>
<li><strong class="bold">Security</strong>: Securing microservices can be a tedious and technical task. Each service might have unique security requirements and may lead to development overhead when coordinating security measures and implementations. Using an API gateway, we can centralize security measures at the gateway level. This can remove the burden from the microservice to authenticate and authorize access to resources since the gateway will manage most of those requirements. We can also implement IP whitelisting at this level and limit access to an approved list of IP addresses.</li>
<li><strong class="bold">Service Monitoring</strong>: We can configure our API gateway to conduct health probes on the downstream services. As previously discussed, health checks or probes help us to ascertain the status of our services. Since the gateway will need to forward requests, it is important to be able to determine the health of a downstream service before attempting an operation. Since the gateway can determine the health of a service, it can be configured to gracefully handle failures and partial failures.</li>
<li><strong class="bold">Service Discovery</strong>: Our gateway needs to know the addresses of all services and how to transform and forward requests as needed. For this, the gateway needs a register of all the downstream services. The gateway will simply act as a wrapper around the services endpoints and expose a singular address to the client application.</li>
<li><strong class="bold">Rate Limiting</strong>: Sometimes, we want to limit the number of requests that can be sent in quick succession, from the same source, on the suspicion that such activity might <a id="_idIndexMarker519"/>be a <strong class="bold">distributed denial-of-service</strong> (<strong class="bold">DDoS</strong>) attack on a service endpoint. Using the <a id="_idIndexMarker520"/>API gateway, we can implement generic rules that govern how often endpoints can be accessed.</li>
</ul>
<p>Once again, the most important aspect of the gateway’s implementation is that it takes much of the responsibility away from our client, making scaling and diversifying client code much easier.</p>
<p><em class="italic">Figure 11.2</em> shows the client, a gateway, and microservices:</p>
<div><div><img alt="Figure 11.2 – With the gateway introduced, the client app now has one endpoint and doesn’t need to know about the underlying services" src="img/Figure_11.2_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.2 – With the gateway introduced, the client app now has one endpoint and doesn’t need to know about the underlying services</p>
<p>Now that we have seen where the API gateway helps us to centralize access to several API endpoints and make it easier for the client application to integrate API operations, let us review some of the<a id="_idIndexMarker521"/> disadvantages of using this pattern.</p>
<h2 id="_idParaDest-162"><a id="_idTextAnchor173"/>Disadvantages of an API gateway</h2>
<p>While the <a id="_idIndexMarker522"/>advantages are clear and irrefutable, we must also be aware of the downsides of introducing an API gateway. An API gateway may come in the form of another microservice and ironically so. The remedy for dealing with too many services is to build one to rule them all. This then introduces a single point of failure since when this is offline, our client app will have no way to send requests to the various services. Now, additional maintenance is required as our gateway service needs to morph alongside each service it interacts with to ensure the requests and responses are accurately interpreted. We also run the risk of increasing the roundtrip time for requests, since this new layer will need to be performant enough to receive the original request, forward it, and then retrieve and forward the response from the microservice.</p>
<p>While we have obvious advantages that we can reference, we need to ensure that we know, accept, and mitigate the risks involved with implementing a gateway service for our microservices application.</p>
<p>As we have seen, there are several cross-cutting and generic concerns that all APIs share. Implementing these generic requirements in each service can lead to bloat and attempting to build a singular service to implement them can lead to a monolithic application being created. It is easier to use a third-party application that is fortified with the main features that we require of an API gateway.</p>
<p>Now, let us review the ways an API gateway could be implemented.</p>
<h1 id="_idParaDest-163"><a id="_idTextAnchor174"/>Implementing the API gateway pattern</h1>
<p>Certain <a id="_idIndexMarker523"/>guidelines should be followed when implementing an API gateway. Given its description, we might be inclined to develop a new microservice, label it the gateway, and develop and maintain the API integrations ourselves.</p>
<p>Surely, this is a viable approach, and it does give you full control over the implementation, rules, and features that you deem necessary for your application and downstream services. We can also implement specific business logic to govern certain operations by orchestrating requests and responses to the downstream services and aggregating and transforming data accordingly. However, this can lead to having a <em class="italic">thick API gateway</em>. We will discuss this further in the next section.</p>
<h2 id="_idParaDest-164"><a id="_idTextAnchor175"/>Thick API gateways</h2>
<p>The expression <em class="italic">thick API gateway</em> is coined when we realize we are placing too much business operation logic into our API gateway. Our <a id="_idIndexMarker524"/>gateway should act more as an abstraction layer between the client<a id="_idIndexMarker525"/> and the microservices, not the main hub for business logic. We should avoid placing business logic in the gateway, which will increase the complexity of the implementation and increase the maintenance effort required for the gateway.</p>
<p>We can also call this an <em class="italic">overambitious gateway</em> and generally should try to avoid making the API gateway a<a id="_idIndexMarker526"/> central point for how our application behaves. We also risk implementing a monolith and ending up at square one with our microservices application. At the same time, we should not avoid such a gateway implementation entirely, since there are additional patterns that can be leveraged by having a gateway with some business logic.</p>
<p>Earlier in this book, we<a id="_idIndexMarker527"/> reviewed the <em class="italic">Saga pattern</em> and, more specifically, the <em class="italic">orchestration pattern</em>. Recall<a id="_idIndexMarker528"/> that the orchestration pattern hinges on the presence of a central service that has oversight of the downstream services, monitors the service responses, and decides to continue or terminate the saga accordingly. In this situation, a <em class="italic">thick API gateway</em> would be an asset in implementing this kind of behavior.</p>
<p>Ultimately, we all have different needs in our applications, and these are, once again, guidelines that we should abide by in doing our implementations. We should always make the best decision for our application based on our needs.</p>
<p>In a situation where all these factors might not be applicable and we need to minimize the amount of business logic that the gateway implements, we may look to existing tools and services that can help us to accomplish these with much less maintenance and development effort. At this point, we can begin thinking about <em class="italic">Amazon API Gateway</em>, <em class="italic">Microsoft Azure API Management,</em> and open source solutions such as <em class="italic">Ocelot</em>.</p>
<p>In the next section, we will review implementing API gateway functionality using <em class="italic">Microsoft Azure API Management</em>.</p>
<h2 id="_idParaDest-165"><a id="_idTextAnchor176"/>Implementing an API gateway using Azure API Management</h2>
<p>Microsoft Azure API Management is a cloud-based solution that can be found in the Microsoft Azure suite of development tools. It is designed to abstract, protect, accelerate, and observe <a id="_idIndexMarker529"/>backend APIs. While doing this, it securely exposes APIs through service discovery, to internal and external clients, inside and outside of the Azure ecosystem.</p>
<p> It serves several purposes, including the following:</p>
<ul>
<li><strong class="bold">API Gateway</strong>: Allows<a id="_idIndexMarker530"/> controlled access to backend services and allows us to enforce throttling and access control policies. The gateway acts as a façade to the backend services, allowing API providers to reduce the attrition involved in making changes to the ever-evolving suite of services in the backend. The gateway provides consistent and powerful configuration options for security, throttling, monitoring, and even caching.</li>
<li>While this is a cloud-based service, the API gateway can also be deployed in a local environment for customers who wish to self-host their APIs for performance and compliance reasons. This <em class="italic">self-hosted gateway</em> is packaged as a Docker container and is commonly deployed to Kubernetes.</li>
<li><strong class="bold">Developer Portal</strong>: An automatically generated and fully customizable website. Third-party developers can use the developer portal to review API documentation and learn how to integrate it into their applications.</li>
<li><strong class="bold">Management Plane</strong>: This section of Azure API Management allows us to provision and configure the service’s settings. We can define API schemas from several sources and configure support for different protocols and standards such as <em class="italic">OpenAPI specifications</em>, <em class="italic">WebSockets</em>, or <em class="italic">GraphQL</em>.</li>
</ul>
<p>Now, let us explore some of the steps required to set up our first Azure API Management service. For these exercises, you will need an <em class="italic">Azure subscription</em> and if you don’t already have one, you may create a free <em class="italic">Microsoft Azure account</em> before you begin.</p>
<p>Our first action is to sign in to the Azure portal. You can then use the search feature and type in <em class="italic">API Management services</em> and select the matching option in the search results. The resulting page will list all the instances of the <em class="italic">API Management services</em> that you currently have. For this <a id="_idIndexMarker531"/>exercise, you may proceed by clicking <strong class="bold">Create</strong>.</p>
<p><em class="italic">Figure 11.3</em> shows the Azure API Management services search results:</p>
<div><div><img alt="Figure 11.3 – Proceed to create a new API Management service for this exercise" src="img/Figure_11.3_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.3 – Proceed to create a new API Management service for this exercise</p>
<p>On the next screen, we can proceed to fill in the details of our service and select the following options:</p>
<ul>
<li><strong class="bold">Subscription</strong>: The subscription this new service will be provisioned under.</li>
<li><strong class="bold">Resource group</strong>: The logical group of resources associated with the service being provisioned. A new one can be created for this exercise.</li>
<li><strong class="bold">Region</strong>: The best geographical representation of where the bulk of the users of the services will be located.</li>
<li><strong class="bold">Resource name</strong>: A unique name for the instance that you will be provisioning. You will need to modify the name displayed in <em class="italic">Figure 11.4</em> to proceed.</li>
<li><strong class="bold">Organization name</strong>: The name of your organization. This will be the name associated with ownership of the API service.</li>
<li><strong class="bold">Administrator email address</strong>: The email address to be used for all communication and notifications from API Management.</li>
<li><strong class="bold">Pricing tier</strong>: This determines the level of service uptime that we prefer. For this instance, we will use the <em class="italic">Developer</em> tier, which isn’t for production use.</li>
</ul>
<p><em class="italic">Figure 11.4</em> shows the various <a id="_idIndexMarker532"/>Azure API Management options:</p>
<div><div><img alt="Figure 11.4 – Minimum values needed to create the API Management service" src="img/Figure_11.4_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.4 – Minimum values needed to create the API Management service</p>
<p>After creating the API Management service, we can begin importing our microservices into the management portal. Now, our API Management service will act as a façade in front of our services, allowing us to control access and transform data as needed. We can import APIs from any source if their API is discoverable across the internet or network.</p>
<p>The API Management<a id="_idIndexMarker533"/> service will handle all communications between a client and the target service that maps to the requested endpoint, regardless of the technology used to implement the API.</p>
<p><em class="italic">Figure 11.5</em> shows the APIs added to the Azure API Management service:</p>
<div><div><img alt="Figure 11.5 – The API Management service allows you to add APIs and map custom routes, that when called, will reroute the request to the mapped resource" src="img/Figure_11.5_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.5 – The API Management service allows you to add APIs and map custom routes, that when called, will reroute the request to the mapped resource</p>
<p>In <em class="italic">Figure 11.5</em>, we can see where we have mapped our appointments and customer APIs to the API Management service and have defined a base URL based on the primary endpoint now available through the service.</p>
<p>In <em class="italic">Figure 11.6</em>, we can see where we can manage the request types that are allowed, as well as define our policies and transformations for each request type.</p>
<p><em class="italic">Figure 11.6</em> also shows the <a id="_idIndexMarker534"/>various request processing options in the Azure API Management service:</p>
<div><div><img alt="Figure 11.6 – The API Management service allows you to easily manage the request types that are allowed for each API and define transformation policies for requests and responses" src="img/Figure_11.6_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.6 – The API Management service allows you to easily manage the request types that are allowed for each API and define transformation policies for requests and responses</p>
<p>Using Azure API Management, we gain many standard API gateway features out of the box and the further benefit of availability and service uptime guarantees when we have production-grade pricing tiers. If we<a id="_idIndexMarker535"/> choose not to self-host this application, we can take advantage of its <strong class="bold">Software-as-a-Service</strong> (<strong class="bold">SaaS</strong>) model, where we have a greatly reduced responsibility to do any infrastructure work related to getting it up and running.</p>
<p>We may end up in a situation where we need to self-host our gateway and API Management is not an option. In this situation, we can look to provide our own API gateway application. A great candidate for this implementation is <em class="italic">Ocelot</em>, which is a lightweight API gateway package that can be installed directly into a standard ASP.NET Core project. We will discuss this further in the next section.</p>
<h2 id="_idParaDest-166"><a id="_idTextAnchor177"/>Implementing an API gateway using Ocelot</h2>
<p>Ocelot is an open source <a id="_idIndexMarker536"/>API gateway developed on the .NET Core platform. It is a simple implementation of a gateway that unifies the communication to microservices through abstraction, as we have come to expect from a gateway. The Ocelot API gateway transforms incoming HTTP requests and forwards them to the appropriate microservice address based on preset configurations.</p>
<p>It is a popular and widely used API gateway technology and can easily be installed into a .NET Core application using the NuGet package manager. Its configurations can be outlined in JSON format; here, we define <em class="italic">upstream</em> and <em class="italic">downstream</em> routes. <em class="italic">Upstream</em> routes<a id="_idIndexMarker537"/> refer to the service address that is exposed to the client, while <em class="italic">downstream</em> routes are <a id="_idIndexMarker538"/>the real addresses of the mapped microservices. We can also define the allowed protocols for each upstream service route, allowing robust control over the kind of traffic that we are willing to accept on a route.</p>
<p>Let us set up an Ocelot API gateway application together. We will use a simple ASP.NET Web API project template and start by adding the <code>Ocelot</code> package via the NuGet package manager:</p>
<pre class="console">
Install-Package Ocelot</pre>
<p>Now that we have our package installed, we need to begin outlining our routing configurations. We can create a new configuration file and call it <code>ocelot.json</code>. In this JSON file, we will outline all <em class="italic">upstream</em> and <em class="italic">downstream</em> routes. This configuration will look something like this:</p>
<pre class="source-code">
{
     "Routes": [
    {
      "DownstreamPathTemplate": "/api/Patients",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "localhost",
          "Port": 5232
        }
      ],
      "UpstreamPathTemplate": "/Patients",
      "UpstreamHttpMethod": [
        "GET",
        "POST"
      ]
    },
    {
      "DownstreamPathTemplate": "/api/Patients/{id}",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "localhost",
          "Port": 5232
        }
      ],
      "UpstreamPathTemplate": "/Patients/{id}",
      "UpstreamHttpMethod": [
        "GET",
        "PUT"
      ]
    },
    {
      "DownstreamPathTemplate": "/api/Appointments",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "localhost",
          "Port": 5274
        }
      ],
      "UpstreamPathTemplate": "/Appointments",
      "UpstreamHttpMethod": [
        "POST",
        "PUT",
        "GET"
      ]
    }
  ],
  "GlobalConfiguration": {
    "BaseUrl": http://localhost:5245""
  }
}</pre>
<p>This configuration file is<a id="_idIndexMarker539"/> straightforward and once we pick up on the pattern, we can extend it as needed for the rest of our services. The sections are explained here:</p>
<ul>
<li><strong class="bold">Routes</strong>: This is the<a id="_idIndexMarker540"/> parent section of our JSON configuration, where we begin to define the upstream and downstream configurations.</li>
<li><strong class="bold">DownstreamPathTemplate</strong>: This section<a id="_idIndexMarker541"/> outlines the address at which the microservice can be found.</li>
<li><strong class="bold">DownstreamScheme</strong>: This outlines <a id="_idIndexMarker542"/>the protocols that we will use to communicate to<a id="_idIndexMarker543"/> the microservice being defined.</li>
<li><strong class="bold">DownstreamHostAndPorts</strong>: The host <a id="_idIndexMarker544"/>address and port are defined in this section.</li>
<li><strong class="bold">UpstreamPathTemplate</strong>: We outline the path that we expose to the client apps. By calling this defined route, Ocelot <a id="_idIndexMarker545"/>will automatically reroute the request to the service defined in the <strong class="bold">DownstreamPathTemplate</strong>. Notice that in the preceding example, we can rename the route if we need to. The <strong class="bold">Customers</strong> API endpoint originally found in the downstream API can only be reached via a <strong class="bold">Patients</strong> endpoint address.</li>
<li><strong class="bold">UpstreamHttpMethod</strong>: Here, we <a id="_idIndexMarker546"/>define the methods that we will accept as legitimate requests from a client.</li>
<li><strong class="bold">GlobalConfiguration</strong>: We outline the <strong class="bold">BaseUrl</strong> in the configuration, where all request traffic <a id="_idIndexMarker547"/>should be sent<a id="_idIndexMarker548"/> through.</li>
</ul>
<p>Now, let us configure our application to use these configurations and use the Ocelot package. We will start by adding the following lines to the <code>Program.cs</code> file:</p>
<pre class="source-code">
builder.Configuration.AddJsonFile("ocelot.json", optional:
  false, reloadOnChange: true);
builder.Services.AddOcelot(builder.Configuration);</pre>
<p>These lines add the <code>ocelot.json</code> file to our global configuration at application startup and then register Ocelot as a service. Then, we need to add the Ocelot middleware, like this:</p>
<pre class="source-code">
await app.UseOcelot();</pre>
<p>With these few configurations, we can now use the gateway URL as the API URL in our client apps.</p>
<p>Ocelot is well-documented and extendable. It supports other features, such as the following:</p>
<ul>
<li>Built-in cache management</li>
<li>A rate limiter</li>
<li>Support for native .NET Core logging integrations</li>
<li>Support <a id="_idIndexMarker549"/>for <strong class="bold">JSON Web Token</strong> (<strong class="bold">JWT</strong>) authentication</li>
<li>Retry and circuit breaker policies (using <em class="italic">Polly</em>)</li>
<li>Aggregating</li>
<li>Pre- and post-downstream request transformations</li>
</ul>
<p>Now that we <a id="_idIndexMarker550"/>have learned how to set up a simple gateway with Ocelot, let us look into extending this functionality. We will begin by adding cache management.</p>
<h2 id="_idParaDest-167"><a id="_idTextAnchor178"/>Adding cache management</h2>
<p>Caches act as temporary data stores in between requests to a more reliable data store. This means that a<a id="_idIndexMarker551"/> cache will temporarily store data based on the last set of data it was given. Good cache management would suggest that we flush our cache based on an interval and refresh it with a newer version of the data.</p>
<p>Caching comes in handy when we need to reduce the number of trips that are made to the main database, reducing latency and read/write costs that come with database calls. Ocelot has some support for caching, which is good for solving small caching concerns natively in the gateway application.</p>
<p>This can be added with a fair amount of ease. We will begin by using NuGet Package Manager to execute the following command:</p>
<pre class="source-code">
Install-Package Ocelot.Cache.CacheManager</pre>
<p>This package gives us the caching extensions that we need to then introduce an extension method in the <code>Program.cs</code> file. This extension method looks like this:</p>
<pre class="source-code">
builder.Services.AddOcelot()
    .AddCacheManager(x =&gt;
    {
        x.WithDictionaryHandle();
    });</pre>
<p>Finally, we add the following line to our <code>ocelot.json</code> configuration file:</p>
<pre class="source-code">
"FileCacheOptions": {
    "TtlSeconds": 20,
    "Region": "SomeRegionName"
  }</pre>
<p>Now that we have<a id="_idIndexMarker552"/> introduced a configuration to govern how caching should occur in our gateway, we must outline that values should be cached for a maximum of 20 seconds. This will add native caching support for the downstream services that have been defined. Once that cache period has expired, requests will be forwarded as expected and then the new response values will be cached once again, for the defined period.</p>
<p>Caching helps to reduce the amount of pressure that we place on a service, but it reasonably only imposes that limit for a short period. If we extend that period, then we run the risk of returning stale data for too long. Another layer of protection that we will want to implement is rate limiting. Let us explore this next.</p>
<h2 id="_idParaDest-168"><a id="_idTextAnchor179"/>Adding rate limiting</h2>
<p>Rate limiting helps us to defend our application from the effects of DDoS attacks. Essentially, we impose rules on <a id="_idIndexMarker553"/>how frequently our service endpoints can be accessed by the same resource. When the request frequency violates our rules, we reject other incoming requests. This helps to prevent probable service performance degradation. Our service will not be attempting to fulfill all requests, especially those that may look like attacks.</p>
<p>Rate limiting works by recording the IP address of the originating request. For all other requests from the same IP address, we evaluate if it is legal and within the set constraints that govern how often a request should come from the same sender. When a rule violation is detected, we send a failure response and do not forward the request in the service.</p>
<p>Ocelot allows us to configure rate limiting for the configured downstream services. This is good because it allows us to globally manage these rules and we do not need to implement these<a id="_idIndexMarker554"/> rules in each service.</p>
<p>First, let us modify our code to implement rate limiting for a particular downstream service. We can add the following code to the service’s configuration file:</p>
<pre class="source-code">
{
      "DownstreamPathTemplate": "/api/Patients",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "localhost",
          "Port": 5232
        }
      ],
      "UpstreamPathTemplate": "/Patients",
      "UpstreamHttpMethod": [
        "GET",
        "POST"
      ],
      "RateLimitOptions": {
        "ClientWhitelist": [],
        "EnableRateLimiting": true,
        "Period": "5s",
        "PeriodTimespan": 1,
        "Limit": 1
      }
    },</pre>
<p>We have introduced a new section called <code>RateLimitingOptions</code> to the <code>ocelot.json</code> file. More specifically, we have added this new configuration to our patient’s downstream service configuration. This will now impose the following restrictions on how this<a id="_idIndexMarker555"/> downstream service can be accessed:</p>
<ul>
<li><strong class="bold">ClientWhiteList</strong>: List of allowed clients that are not subjected to the rate limiting restrictions.</li>
<li><strong class="bold">EnableRateLimiting</strong>: A flag that indicates whether the rate-limiting restrictions should be enforced or not.</li>
<li><strong class="bold">Period</strong>: This value specifies the amount of time that we use to determine if a client is making a request that violates the limiting options. We can use the following:<ul><li>s for seconds</li><li>m for minutes</li><li>h for hours</li><li>d for days</li></ul></li>
</ul>
<p>The pattern is fairly easy to follow. In our example, we have a 5-second limit on requests.</p>
<ul>
<li><strong class="bold">PeriodTimeSpan</strong>: This is like a cooldown period. For this period, subsequent requests from the client that violated the limiting restrictions will be rejected and the clock will restart. Once this period has elapsed, the client can continue making requests.</li>
<li><strong class="bold">Limit</strong>: The number of requests that a client is allowed to make during the period. Here, we are defining that only one request should come in from the client every 5 seconds.</li>
</ul>
<p>Then, we can define global values that govern how the gateway will handle rate limiting. We can add a similar <code>RateLimitingOptions</code> section to our <code>GlobalConfiguration</code> section:</p>
<pre class="source-code">
"GlobalConfiguration": {
    "BaseUrl": http://localhost:5245"",
    "RateLimitOptions": {
      "DisableRateLimitHeaders": false,
      "QuotaExceededMessage": "Too many requests!!!",
      "HttpStatusCode": 429,
      "ClientIdHeader": "ClientId"
    }
  }</pre>
<p>Now, we have some new options, which are as follows:</p>
<ul>
<li><strong class="bold">DisableRateLimitHeaders</strong>: A flag that determines whether we disable or enable rate-limiting headers. These<a id="_idIndexMarker556"/> header values are generally as follows:<ul><li><strong class="bold">X-Rate-Limit</strong>: Maximum number of requests available within the timespan</li><li><strong class="bold">Retry-After</strong>: Indicates how long the client should wait before making a follow-up request</li></ul></li>
<li><strong class="bold">QuotaExceededMessage</strong>: Allows us to define a custom message to send to the client that has violated the limiting rules.</li>
<li><strong class="bold">HttpStatusCode</strong>: This outlines the response code to be sent when the rules are violated. 429TooManyRequests is the standard response for this situation.</li>
<li><strong class="bold">ClientIdHeader</strong>: Specifies the header that should be used to identify the client making the request.</li>
</ul>
<p>With these minor changes, we have enforced rate limiting on all requests coming into the <code>/patients</code> endpoint. We will respond with a <strong class="bold">429TooManyRequests</strong> HTTP response if two or more requests come in within 5 seconds, from the same client address.</p>
<p>Another consideration we might have when using Ocelot is to aggregate our responses. This allows us to string multiple calls along and reduce the client’s need to orchestrate these calls. We’ll learn how<a id="_idIndexMarker557"/> to add this next.</p>
<h2 id="_idParaDest-169"><a id="_idTextAnchor180"/>Adding response aggregation</h2>
<p>Response <a id="_idIndexMarker558"/>aggregation is a method used for merging responses from multiple downstream services and sending one response accordingly. Essentially, an API gateway can achieve this by accepting a single request from a client and then making distributed parallel requests to several downstream services. Once all the responses are in from the downstream services, it will merge the data into a single object and return it to the client.</p>
<p>Several benefits come with this approach. The most prevalent one is that we can reduce the number of requests that the client needs to make to get data from several services. The API gateway will handle that orchestration automatically. The client also only needs to know one schema. So, several potentially complex requests can be merged into a single request body, which will reduce the number of schemas that the client needs to track. This approach will also speed up the response times involved with calling several services. Since the calls will be made in parallel, we do not have to wait the entire period that would be required when making service calls one after the other.</p>
<p>Ocelot allows us to configure aggregate calls with a fair amount of ease. We will decorate our downstream service configurations with keys that act as a point of reference for our aggregate configuration. If we want to aggregate a call that should return a patient and all the appointments that they have made, we would need to make the following modifications:</p>
<pre class="source-code">
    {
      "DownstreamPathTemplate": "/api/Patients/{id}",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "localhost",
          "Port": 5232
        }
      ],
      "UpstreamPathTemplate": "/Patients/{id}",
      "UpstreamHttpMethod": [
        "GET",
        "PUT"
      ],
      "Key": "get-patient"
    }</pre>
<p>We start by adding a new key to the <code>api/patients/{id}</code> downstream service configuration. This key acts as an alias, which we will use later. We will also add a new downstream service <a id="_idIndexMarker559"/>configuration for appointments and a new endpoint. The configuration looks like this:</p>
<pre class="source-code">
    {
      "DownstreamPathTemplate":
          "/api/user/Appointments/{id}",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "localhost",
          "Port": 5274
        }
      ],
      "UpstreamPathTemplate": "/Appointments/user/{id}",
      "UpstreamHttpMethod": [
        "GET"
      ],
      "Key": "get-patient-appointments"
    }</pre>
<p>The matching endpoint that will be<a id="_idIndexMarker560"/> implemented in the appointments services looks like this:</p>
<pre class="source-code">
// GET: api/Appointments/user/{id}
        [HttpGet("user/{id}")]
        public async Task&lt;ActionResult&lt;List&lt;Appointment&gt;&gt;&gt;
            GetAppointmentsByUser(Guid id)
        {
            var appointments = await _context.Appointments
                .Where(q =&gt; q.PatientId == id)
                .ToListAsync();
            return appointments;
        }</pre>
<p>Now that we have configured the new endpoints and modified the downstream service configurations, we need to add a new configuration for our aggregate orchestration:</p>
<pre class="source-code">
"Aggregates": [
    {
      "RouteKeys": [
        "get-patient",
        "get-patient-appointments"
      ],
      "UpstreamPathTemplate": "/get-patient-details/{id}"
    }
  ],</pre>
<p>Now, we can use the endpoint as defined by the aggregate configuration and execute a single call that will return a patient’s record alongside all the appointments that they have made. This information comes from multiple services almost simultaneously. Our client no longer needs to make multiple calls to get this information.</p>
<p>This simple and powerful technique helps us to better orchestrate API calls and present exactly the information that a client app needs. It promotes a more behavior-driven workflow when retrieving<a id="_idIndexMarker561"/> data and reduces the development overhead that each client application will need.</p>
<p>Now that we have seen how we can implement API gateways using either our API project or Azure API Management, we have overcome a major hurdle in our microservices application. We no longer need to build client apps that need to keep track of all the addresses of our microservices.</p>
<p>This now raises another cause for concern. Unfortunately, different devices might have different requirements for how they interact with our services. Mobile clients might need special security and caching considerations that web applications do not. This adds more complication to how we keep track of configurations in the central gateway, relative to the devices hosting the client apps.</p>
<p>These considerations lead us down the path of implementing a gateway per type of service client. This method of implementation is called the <em class="italic">Backend for Frontend pattern</em>, which we will discuss next.</p>
<h1 id="_idParaDest-170"><a id="_idTextAnchor181"/>Backend for Frontend pattern</h1>
<p>While API <a id="_idIndexMarker562"/>gateways solve several problems, it is not a one size fits all solution. We still end up contending with the possibility of catering to multiple device types and, by extension, client applications. For example, we may need to use additional compression and caching rules with data <a id="_idIndexMarker563"/>being consumed by a mobile client, whereas a website might not need many special considerations. The more devices become capable of interacting with APIs, the more we need to ensure that we can support integrations.</p>
<p><em class="italic">Figure 11.7</em> shows multiple clients with one gateway:</p>
<div><div><img alt="Figure 11.7 – All client devices access the same gateway, leading to inefficient behavior for some devices" src="img/Figure_11.7_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.7 – All client devices access the same gateway, leading to inefficient behavior for some devices</p>
<p>All these considerations make a good case for the <strong class="bold">Backend for Frontend</strong> (<strong class="bold">BFF</strong>) pattern. This pattern allows us to supply a service-per-device API approach. The BFF pattern allows us to <a id="_idIndexMarker564"/>acutely define our API functionality based on the experience that we hope for a user to have on a particular user interface. This makes it easier for us to develop and maintain and adjust our API based on the client’s requirements and simplifies the process of delivering functionality across multiple clients.</p>
<p><em class="italic">Figure 11.8</em> shows a BFF setup:</p>
<div><div><img alt="Figure 11.8 – Each client app has an endpoint to a gateway that is specially configured to optimize API traffic for the target device type" src="img/Figure_11.8_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 11.8 – Each client app has an endpoint to a gateway that is specially configured to optimize API traffic for the target device type</p>
<p>Now, we can optimize each gateway instance to handle traffic for specific devices in the most efficient way possible. For instance, our mobile applications might require additional caching or <a id="_idIndexMarker565"/>compression settings and we may need to rewrite request headers. We might even define additional header information to be provided from our mobile devices as we may need to track the device type and location. In a nutshell, we need to ensure that we are catering to each possible device as much as possible.</p>
<p>Azure API Management has features that allow us to interrogate the incoming request and redirect or modify the request before forwarding it or modifying the response before it is sent to the requesting client. By defining these policies, we can implement a BFF-like mechanism where policies are defined to look for the type of device or, generally, the source of the request and modify it as optimally as possible for forwarding or returning.</p>
<p>Ocelot might require a bit more potentially confusing logic to support policies of this nature. The more recommended way to implement this pattern using Ocelot is to use multiple implementations of Ocelot. In this implementation style, we would create multiple Ocelot projects, each with its specific purpose, such as mobile, web, and public gateways, and add each configuration for the allowed up and downstream services. We would also be able to specify the rate-limiting and caching options per implementation.</p>
<p>Let us review how this <a id="_idIndexMarker566"/>pattern can be implemented using Ocelot.</p>
<h2 id="_idParaDest-171"><a id="_idTextAnchor182"/>BFF pattern using Ocelot</h2>
<p>We have already <a id="_idIndexMarker567"/>seen that we can configure Ocelot to be our API gateway. A simple enough extension to what we have done is to create <a id="_idIndexMarker568"/>additional projects and configure them similarly. We can retain the gateway that we have already and use it exclusively for third-party application access. With the up and downstream services we have defined, we can restrict third parties to only be able to access those endpoints.</p>
<p>We can then create a new Ocelot project and use it specifically for our web client. Let us say that we do not want rate limiting on the web client and can decrease the cache time to 10 seconds instead of 20. Given that this is our web application, we can lift most of these restrictions and allow for less strict interactions.</p>
<p>This configuration file will simply look like this:</p>
<pre class="source-code">
{
  "Routes": [
    {
      "DownstreamPathTemplate": "/api/Patients",
      "DownstreamScheme": "http",
      "DownstreamHostAndPorts": [
        {
          "Host": "localhost",
          "Port": 5232
        }
      ],
      "UpstreamPathTemplate": "/web/Patients",
      "UpstreamHttpMethod": [
        "GET",
        "POST"
      ]
    },
   // omitted for brevity   ],
  "FileCacheOptions": {
    "TtlSeconds": 10,
    "Region": "SomeRegionName"
  },
  "GlobalConfiguration": {
    "BaseUrl": http://localhost:5245""
  }
}</pre>
<p>This looks similar to what we have already done with the previous gateway, but note that now, we have the unique opportunity to define custom paths that match with the web entry point that we are implementing while adding/removing configurations as we deem necessary for the web <a id="_idIndexMarker569"/>client. Also, notice that it will broadcast from a separate address, which will prevent any reference <a id="_idIndexMarker570"/>overlaps between the clients.</p>
<p>We may also want to implement a mobile client that has fewer restrictions similar to what we have outlined in the web gateway, but we may also want to customize the aggregation operation. So, for our mobile client gateway, we can add the following aggregator definition to the Ocelot configuration:</p>
<pre class="source-code">
  "Aggregates": [
    {
      "RouteKeys": [
        "get-patient",
        "get-patient-appointments"
      ],
      "UpstreamPathTemplate": "/get-patient-details/{id}",
      "Aggregator": "PatientAppointmentAggregator"
    }
  ],</pre>
<p> In the <code>Program.cs</code> file, we add the following line to register the aggregator:</p>
<pre class="source-code">
builder.Services.AddOcelot().AddSingletonDefinedAggregator&lt;
  PatientAppointmentAggregator&gt;()</pre>
<p>Now, we need to define a class called <code>PatientAppointmentAggregator</code>, which will implement our custom aggregation logic. This custom aggregator will intercept the responses from the<a id="_idIndexMarker571"/> downstream server and allow <a id="_idIndexMarker572"/>us to interrogate and modify what is returned:</p>
<pre class="source-code">
public class PatientAppointmentAggregator :
  IDefinedAggregator
{
    public async Task&lt;DownstreamResponse&gt;
        Aggregate(List&lt;HttpContext&gt; responses)
    {
        var patient = await responses[0].Items.Downstream
          Response().Content.ReadAsStringAsync();
        var appointments = await responses[1]
          .Items.DownstreamResponse()
            .Content.ReadAsStringAsync();
        var contentBuilder = new StringBuilder();
        contentBuilder.Append(patient);
        contentBuilder.Append(appointments);
        var response = new StringContent
          (contentBuilder.ToString())
        {
            Headers = { ContentType = new
              MediaTypeHeaderValue("application/json") }
        };
        return new DownstreamResponse(response,
          HttpStatusCode.OK, new List&lt;KeyValuePair&lt;string,
            IEnumerable&lt;string&gt;&gt;&gt;(), "OK");
    }
}</pre>
<p>This aggregator code receives a list of responses, where each entry represents the response from the downstream services in the order they were defined in the configuration. We then extract<a id="_idIndexMarker573"/> the response as a string and append it in one string value. We also add a <code>ContentType</code> header to the ultimate response, which is sent with a <code>200OK</code> HTTP response. This is a simple <a id="_idIndexMarker574"/>example, but it shows how easy it is for us to customize the default aggregation behavior and, by extension, for a specific BFF gateway.</p>
<p>The BFF pattern allows us to further diversify our development teams and their efforts in maintaining the various microservices. Teams can now manage their gateways and implement gateway methods and features that are unique to the devices they are catering to.</p>
<p>Now that we understand <a id="_idIndexMarker575"/>API gateways, the BFF pattern, and how we can implement either one of these using industry-standard software, let us review<a id="_idIndexMarker576"/> what we have learned in this chapter.</p>
<h1 id="_idParaDest-172"><a id="_idTextAnchor183"/>Summary</h1>
<p>This chapter has reviewed the need for an API gateway. When building a monolith, we have a single point of entry to our application’s supporting API and this single point of entry can be used for any type of client.</p>
<p>The downside to this is that we might end up with an API that becomes increasingly difficult to improve on and scale as the demands change. We also need to consider the fact that different devices have different needs from the API in terms of caching, compression, and authentication to name a few.</p>
<p>We then attempt to diversify our application’s capabilities into multiple services or microservices and then implement only what is needed per service. This approach simplifies each service’s code base while complicating the code base of the client applications. Where there was one service endpoint, we now have several to keep track of.</p>
<p>API gateways will sit on top of all the microservices and expose a single point of entry and allow us to implement several instances, which can cater to the direct needs of the client applications that will use them. This adjustment is called BFF, and it allows us to curate backend services specifically for the client applications that need them.</p>
<p>The major downside here is that we have reintroduced a single point of failure by providing the gateway layer, which can introduce potential performance issues. The goal, however, is to reduce the need for our client apps to have intimate knowledge of the complex web of services that they need to interact with, and this layer of abstraction also helps us to maintain our services with less effect on the client applications.</p>
<p>We also learned that when attempting to add the BFF pattern, we introduce the need for more services and more code to maintain. Ideally, we would like to have a single implementation that can be provisioned multiple times, all with their specific configurations. This is where technology such as Docker will help, but we will review that later in this book.</p>
<p>Now that we have seen the pros and cons of the API gateway pattern, we need to explore security for our APIs. In the next chapter, we will explore API security using bearer tokens.</p>
</div>
</body></html>