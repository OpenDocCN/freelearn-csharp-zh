- en: Exploring Integrations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll explore integration-testing the Speaker Meet application.
    The React front-end application will be tested and configured to hit the real
    back-end API, and the .NET application will be tested to ensure that it functions
    properly from controller to database.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a real API service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing mocked API calls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: End-to-end integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing a real API service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The time has come to actually receive data from the server. Our current data
    model is still not 100% correct, but the groundwork is there. When we receive
    the correct data structure from the server, we will need to update our views accordingly.
    We will leave that part as an exercise for you.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will look at pulling our mocked API out of the factory that
    we created and replacing it with a real API. In our existing tests, we will use
    Sinon to override the default functionality of our Ajax component with the functionality
    from our mock API.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we will need to create an application configuration object to manage
    the base path for the API to determine the correct path in both dev and prod.
  prefs: []
  type: TYPE_NORMAL
- en: Replacing the mock API with the real API service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To keep things as simple as possible, we will be using the fetch API to get
    data from the server. We will begin by breaking all the tests that are currently
    using the mock API. That is because we are going to create a stub class that implements
    the same interface as the mock API, but it will not be doing anything:'
  prefs: []
  type: TYPE_NORMAL
- en: '`src/services/fetchSpeakerService.js`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, replace the mock service that is created by the factory with the creation
    of the fetch based service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Thankfully, only four tests are failing because of that change. Looking at the
    failed tests, three of them are failing because we did not return a promise. One
    test, however, is failing because we are no longer returning the mock API. We
    are going to ignore the failing tests caused by missing promises by excluding
    them temporarily. Then, we will focus on test checking for a specific instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test that is failing is in the service factory tests. We don''t actually
    want the service factory to return a `MockSpeakerService`. We want it to return
    a `FetchSpeakerService`. Even more accurately, we want any implementation of a
    `SpeakerService`. Let''s create a base class that will behave like an interface
    or abstract class from C#:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/src/services/speakerService.js`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have an abstract base class, we need to inherit from that base class
    in both our existing service classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'And then we need to modify the factory tests to expect an instance of the base
    class instead of the derived class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Using Sinon to mock Ajax responses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, it is time to tackle the three tests that we have ignored. They are expecting
    actual responses from our service. Right now, our service is completely empty.
    Keep in mind, those tests were written to be unit tests and we need to protect
    them from the changes in the response that the real endpoint will experience over
    time. For that reason, we are going to, finally, introduce Sinon.
  prefs: []
  type: TYPE_NORMAL
- en: We will use Sinon to return the results from our mock API instead of the real
    API. This will allow us to continue to use the work we have already put into the
    mock API.
  prefs: []
  type: TYPE_NORMAL
- en: After we have our existing tests covered, we are going to introduce integration
    tests by using Sinon to mock the back-end server. Using Sinon in that way will
    allow us to test-drive our fetch based speaker service.
  prefs: []
  type: TYPE_NORMAL
- en: Fixing existing tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First things first; we must make our existing tests pass. In the `speakerActions.spec.js`
    file, find the first test that we skipped and remove the skip. This will cause
    that test to fail with:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Cannot read property ''then'' of undefined`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Back in the `beforeEach` method, where we are creating the speaker service,
    we need to create a new Sinon stub for a service method. Looking at the test,
    we can see that the first service call we make is to get all speakers. So, let''s
    start there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Looking at this code, what we have done is to create a new Sinon stub and redirect
    calls to the service `getAll` method to the `mockService getAll` method. Lastly,
    we bind the `mockService` call to the `mockService` to preserve access to private
    variables in the `mockService`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the tests again, we get a new error:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Attempted to wrap getAll which is already wrapped`'
  prefs: []
  type: TYPE_NORMAL
- en: 'What this error is telling us is that we have already created a stub for the
    method we are trying to stub. At first, this error may not make any sense. But,
    if you look we are doing this in a `beforeEach`. Sinon is a singleton and we are
    running our mocking commands inside a `beforeEach`, so it already has a `getAll`
    stub registered by the time the second test is preparing to run. What we must
    do is remove that registration before we try to register it again. Another way
    to say this is that we must remove the registration after each test run. Let’s
    add an `afterEach` method and remove the registration there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: That fixes the first failing test that we had, now to fix the other two. The
    process will be largely the same, so let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: Remove the skip from the next test. The test fails. We are calling the `getSpeaker`
    action in this test and if we look at the speaker actions, we can see that it
    uses the `getById` service method. As before we will need to stub this method
    in the `beforeEach`.
  prefs: []
  type: TYPE_NORMAL
- en: '`getById = sinon.stub(service, "getById");`'
  prefs: []
  type: TYPE_NORMAL
- en: '`getById.callsFake(mockService.getById.bind(mockService));`'
  prefs: []
  type: TYPE_NORMAL
- en: 'As before, we are now getting the already wrapped message:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Attempted to wrap getById which is already wrapped`'
  prefs: []
  type: TYPE_NORMAL
- en: We can fix this one the same way we fixed the last one, by removing the stub
    in the `afterEach` function.
  prefs: []
  type: TYPE_NORMAL
- en: '`getById.restore();`'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are back to all passing tests with one skipped. The last test is the exact
    same process. Here are the full `beforeEach` and `afterEach` functions when we
    are done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Don't forget to remove the skip from the last test. When all is said and done
    you should have 42 passing tests and 0 skipped tests.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking the server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have fixed our existing tests, we are ready to start writing tests
    for our real service, the `fetchSpeakerService`. Let's get started by looking
    at the test we used for our mock service. The tests will largely be the same as
    we are trying to achieve the same pattern of functionality.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will want to create the test file `fetchSpeakerService.spec.js.`
    Once the file is created, we can add the standard existence test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Because we stubbed out the fetch speaker service earlier, this test should just
    pass after we add the appropriate import.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the mock speaker service tests, the next test is a construction and
    type verification test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'This test, too, should pass right away, because when we stubbed the fetch service
    we created it as a class. Continuing to follow the progression of the mock service
    tests, we have an `After Initialization` section with a `Create` section inside
    it. The only test in the *Create* section is an exists test for the `Create` method.
    Writing this test, it should pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Because we are copying the flow from the mock service tests, we have already
    extracted the service to a `beforeEach` instantiation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, our tests will start to get interesting and won't just
    pass right away. Before we move on, to verify that the tests are doing what they
    should be doing, it is a good idea to comment out parts of the fetch service and
    see the appropriate tests pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving on to the `Get All` section, still inside the `After Initialization`
    section, we have an existence test checking the `getAll method`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As with the other tests so far, to fail this test you will have to comment
    out the `getAll` method in the fetch service to see it fail. Immediately following
    this test are two more sections: `No Speakers Exist` and `Speaker Listing`. We
    will add them one at a time starting with `No Speakers Exist`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have a failing test. The failure is complaining because it doesn''t
    look like we returned a promise. Let''s begin the proper implementation of the
    fetch service and we will use Sinon in the tests to mock the back-end. In the
    fetch service, add the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This is a very basic fetch call. We are use the HTTP verb, `GET,` so there is
    no reason to call a method on fetch; by default it will use `GET`.
  prefs: []
  type: TYPE_NORMAL
- en: In our tests, we are now getting a meaningful result. `fetch is not defined`.
    This result is because fetch does not exist as part of our testing setup yet.
    We will need to import a new NPM package to handle fetch calls in testing. The
    package we want to import is `fetch-ponyfill`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'After installing the `ponyfill` library, we must modify our test setup file
    `scripts/test.js`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'After those modifications, we must restart our tests for the changes to take
    effect. We are now getting a test failure telling us that only absolute URLs are
    supported. We are getting this message because when we instantiate our fetch service
    we aren''t passing a baseURL. For the tests it doesn''t matter what the URL is
    so let''s just use localhost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'After making this change we have moved the error forward and now we are getting
    a fetch error to the effect that localhost refused a connection. We are now ready
    to replace the back-end with Sinon.  We will start in the `beforeEach` and `afterEach`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In the test, we will need some items from the `fetch-ponyfill` package so let's
    add the import statements while we are close to the top of the file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'And now in the test, we need to configure the response from the server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: That finishes the `No Speakers Exist` scenario. We will refactor the server
    response once we have a better idea about what data will be changing.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready for the speaker listing scenario. As before, we start by copying
    the test from the mock service tests. Remove the arrange from the mock service
    test and copy the arrange from our previous test.
  prefs: []
  type: TYPE_NORMAL
- en: 'After adding the arrange from the no speakers test, we get a message expecting
    a length of 1 instead of 0\. This is an easy fix and for the purposes of this
    test we can simply add an empty object to the body array of the response. Here
    is what the test should look like, once it is passing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we are using basically the same arrange twice, it''s time to refactor
    our tests. The only thing that has really changed is the body. Let''s extract
    an `okResponse` function to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We have placed this helper function at the top of the `After Initialization`
    `describe`. Now in each test, replace the arrange with a call to the function,
    passing in the body that is specific to that test.
  prefs: []
  type: TYPE_NORMAL
- en: The get all speakers functionality is now covered by the tests. Let's move on
    to getting a specific speaker by ID. Copy the tests for `getById` from the mock
    service tests and apply a skip to the describes. Now, remove the skip from the
    outer-most describe. This should enable the existence test, which should pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next test is for when a speaker is not found; removing skip from that test
    results in a message indicating that we are not returning a promise. Let''s go
    into the body of the `getById` function and use fetch to get a speaker:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding fetch to our function should have fixed the error but hasn''t. Remember
    we are mocking the response from fetch so if we don''t set a response then fetch
    won''t return anything at all. Let''s configure the mock response. In this case
    we are expecting a 404 from the server so let’s configure that response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'That makes our test pass, but it''s not for the right reason. Let’s add a `then`
    clause to the assertion to prove the false positive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now our test will fail with expected `''Error not returned''` to equal `''SPEAKER_NOT_FOUND''`.
    Why is this? Shouldn''t a 404 cause a rejection of the promise? With fetch, the
    only thing that will cause a rejected promise is a network connection error. For
    that reason, we didn''t reject when we mocked the server response. What we need
    to do is check for that condition in the service and cause a promise rejection
    on that side. The easiest way to accomplish this is to wrap the fetch call with
    a promise of our own. Once wrapped, we can check for the appropriate condition
    and reject our promise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'That should do it for this test. We are now ready for our last test. Before
    we move on, let''s do a quick refactoring of the arrange in this test to shorten
    the test and have it make a bit more sense to future readers. While we are doing
    that, we will refactor the existing response function to reduce duplication and
    enforce some default values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Use the `notFoundResponse` function in the test just like we used the `okResponse`
    function. Moving on to our last test for the current functionality of the fetch
    service, remove the skip from the next describe and we will begin looking at the
    errors generated and make the necessary changes to make the test pass.
  prefs: []
  type: TYPE_NORMAL
- en: 'This last test is fairly simple after the work we have already done to make
    mock responses easier. We need the fetch call to return an `ok` response with
    the speaker as the body:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are getting a timeout error. That is because our service isn''t actually
    handling the case where the speaker exists. Let''s add that now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Now all our tests are passing and we have verified all the expected behavior
    of the system. There are a few more things we could do and some developers will
    choose to do them. We will discuss some of them but will not be providing examples.
  prefs: []
  type: TYPE_NORMAL
- en: Application configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that all the tests are passing there is still some application configuration
    that must be taken care of before the application can be used.
  prefs: []
  type: TYPE_NORMAL
- en: In the service factory, we must set a base URL for the fetch service to use
    when the application is running. This can be done many different ways and which
    way exactly is up to you. The simplest but least flexible way is to just hard-code
    a string value as the base URL used to construct the service. However, you could
    get as fancy as having a dynamic class that sets the value based on the applications,
    running environment. Again this decision is left to you.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last subject we will discuss in this chapter is end-to-end integration tests.
    These tests involve actually calling the server and checking the real responses.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, what are the benefits from testing the actual client server connection?
    The most valuable benefit is that you know your application will work in the deployed
    environment. Sometimes an application will get deployed and not work because a
    network or database connection was incorrectly configured and that will wreak
    havoc on a deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, this will help to verify the system is working properly. A series
    of smoke tests could be employed after a deployment to ensure the deployment was
    successful.
  prefs: []
  type: TYPE_NORMAL
- en: Detriments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: E2E tests are usually skipped for one of two reasons. The first reason is that
    they are difficult to write. You have a lot of extra setup to get these tests
    to run, including a completely different test runner than what you normally use
    for unit testing. If not a different runner, they at least need to be a separate
    test run and not included in your normal unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: The second issue is that E2E tests are fragile. Any change to the system and
    these tests break. They are not commonly run all the time like a unit test is
    and so the broken code will not be noticed until they are run in the production
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons we generally do not write that many E2E tests, if any at all.
  prefs: []
  type: TYPE_NORMAL
- en: How much end-to-end testing should you do?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you choose to do end-to-end testing, you will want to do as little as possible.
    These are the top tier of tests and should be the least numerous type of test
    in your system. A recommendation is to only write as many tests as you have third-party
    connections to your application, that is, one test for each back-end server that
    you must communicate with. Additionally, use the simplest and most basic case
    which is not anticipated to change.
  prefs: []
  type: TYPE_NORMAL
- en: That completes integration testing from the front-end. There are still some
    things that can be done. We will leave them as an exercise for you. You might
    have noticed that the front-end and back-end are not fully in agreement for the
    model that is being passed back and forth. As an exercise, add or remove and refine
    the model that is being used by both systems so that they agree on the format.
  prefs: []
  type: TYPE_NORMAL
- en: Another task would be to set the base URL for the fetch service and run both
    applications locally to verify interconnectability.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the API project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the React project now configured to hit the real API, it's time to turn
    our attention to the .NET solution. In order to verify that everything is wired
    up correctly, you'll want to write a series of integration tests to ensure that
    the whole system is working properly.
  prefs: []
  type: TYPE_NORMAL
- en: Integration test project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Create a new xUnit Project called `SpeakerMeet.Api.IntegrationTest` within the
    existing solution. This will be where the .NET integration tests will be created.
    You may want to explore separating these out according to your preferences and/or
    team coding standards, but that can wait. For now, a single integration test project
    will do.
  prefs: []
  type: TYPE_NORMAL
- en: For our purposes, we'll be testing whether the system functions from API entry
    all the way to the database, and back. However, it's best to start small test
    individual integration points, and grow from there.
  prefs: []
  type: TYPE_NORMAL
- en: Where to begin?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You could certainly start by creating a test that will call an API endpoint.
    In order to achieve this, an HTTP Request will need to be made to a controller.
    The controller will then call into a service within the business layer, which
    in turn will make a call to the repository, and finally a command is sent to the
    database. That feels like a lot of moving parts. Perhaps there's a better place
    to start.
  prefs: []
  type: TYPE_NORMAL
- en: In order to break down the problem into smaller, more manageable pieces, perhaps
    it's best to start testing closer to the persistence layer of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying the repository calls into the DB context
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good place to start is verifying that the system is fully integrated; let's
    first test that the repository can access the database. Create a folder within
    the integration test project called `RepositoryTests` and create a new test file
    called `GetAll`. This will be where the integration tests for the `GetAll` method
    of the repository will be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'You could create a test that verifies that the repository can be created, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'However, that''s not going to pass. If you run the test you will receive the
    following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '`System.InvalidOperationException: No database provider has been configured
    for this DbContext`.'
  prefs: []
  type: TYPE_NORMAL
- en: This is easily fixed by configuring an appropriate provider.
  prefs: []
  type: TYPE_NORMAL
- en: InMemory database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running tests against a SQL Server is time-consuming, error-prone, and potentially
    costly. Establishing a connection to a database takes time, and remember, you
    want your test suite to be lightning-fast. It might also be a problem to rely
    on data if the database is used by others, whether in a development environment,
    by quality assurance engineers, and so on. You certainly wouldn't want to run
    your integration tests against a production database. Additionally, running tests
    against a database hosted in the cloud (for example, AWS, Azure, and so on) could
    potentially incur a dollar cost in terms of bandwidth and processing.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, it's quite trivial to configure a solution that uses Entity Framework
    to use an `InMemory` database.
  prefs: []
  type: TYPE_NORMAL
- en: First, install a `NuGet` package for the `InMemory` database.
  prefs: []
  type: TYPE_NORMAL
- en: '`Microsoft.EntityFrameworkCore.InMemory`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, modify the test you created before so that the database context is created
    `InMemory`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The test should now pass because the context is now being created `InMemory`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, create a test to verify that a collection of Speaker entities is returned
    when the `GetAll` method is called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, turn your attention to the `Get` method in the repository. Create a new
    test method to verify that a null Speaker entity is returned when a speaker with
    the given ID is not found:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This should pass right away. Now, create a test to verify that a Speaker entity
    is returned when a speaker with the supplied ID exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: This test will not pass quite yet. Regardless of whether or not a Speaker with
    the ID of 1 exists in your development database, the speakers table in the `InMemory`
    database is currently empty. Adding data to the `InMemory` database is quite simple.
  prefs: []
  type: TYPE_NORMAL
- en: Adding speakers to the InMemory database
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to test that the repository will return specific Speaker entities
    when querying the database, you first must add Speakers to the database. In order
    to do this, add a few lines of code to your test file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Feel free to add as many speakers as you want, with as much detail as you feel
    necessary. Your test should now pass. More tests can be created, and should continue
    to be added as the system grows in functionality and complexity. The bulk of the
    logic should be tested already in the unit tests, but verifying that the system
    functions as a whole is equally important.
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the service calls the DB through the repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Moving on to the business layer, you should verify that each service can retrieve
    data from the `InMemory` database through the repository.
  prefs: []
  type: TYPE_NORMAL
- en: First, create a new folder in the integration test project called `ServiceTests.`
    Within that folder, create a folder named `SpeakerServiceTests`. This folder is
    where the tests specific to the `SpeakerService` will be created.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new test file named `GetAll`. Add a test method to verify that the
    service can be created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: ContextFixture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There's a lot of setup code here and quite a bit of duplication from our previous
    tests. Luckily, you can use what's known as a *Test Fixture*.
  prefs: []
  type: TYPE_NORMAL
- en: A Test Fixture is simply some code that is run to configure the system under
    test. For our purposes, create a *ContextFixture* to set up an `InMemory` database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new class named `ContextFixture`, which is where all the `InMemory`
    database creation will happen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, modify the test class to use the new `ContextFixture` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'That''s quite a bit cleaner. Now, create a new test to ensure a collection
    of `SpeakerSummary` objects is returned when the `GetAll` method of the `SpeakerService`
    is called:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, create a new test class for the `Get` method of the `SpeakerService`.
    The first test should validate that an exception is thrown when a speaker does
    not exist with the supplied ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You can reuse the `ContextFixture` that you created earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Verify the API calls into the service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, turn your attention to the web API controllers. As covered in a previous
    chapter, you could simply create a new instance of the controller and call the
    method under test. However, that would not exercise the entire system.
  prefs: []
  type: TYPE_NORMAL
- en: It would be far better to call the method with an HTTP request. Deploying to
    a web server would be prohibitively time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: TestServer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ASP.NET Core has the ability to configure a host for testing purposes. Install
    the `TestServer` from `NuGet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Microsoft.AspNetCore.TestHost`'
  prefs: []
  type: TYPE_NORMAL
- en: There's a little setup involved. First, you’ll add an instance of the `TestServer`.
    Create a new `WebHostBuilder` and use the existing `Startup` class of the web
    API project. This will wire up the Dependency Injection container that was set
    up previously. Now, configure the services to set up a new `InMemory` database.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the test here to see the setup required:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: ServerFixture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to move the setup out of the controller tests, again use a test fixture.
    This time, create a new class named `ServerFixture`. This will be where the setup
    will live for the controller tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, return to the previous test. Modify the test class to use the `ServerFixture`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, verify that the response returns an `OK` status code by creating a new
    test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, ensure that the proper speaker is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember, you want to make sure your test suite is clean and well maintained.
    To clean this test up a bit, you might want to consider creating a `ReadAsJsonAsync`
    extension. Here''s what that might look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, modify the test to use the new extension method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: That's much better. Now this extension can be used and reused over and over,
    and its first use has now been documented in the `ItShouldReturnSpeakers` test.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, move on to testing that the single speaker endpoint can be called. Create
    a test named `ItShouldCallGetSpeaker` and ensure that a response is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, test that the proper response code is returned if a Speaker with the given
    ID does not exist:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now validate that an `OK` status code is returned when a speaker with the supplied
    ID exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, confirm that the speaker returned is the one that is expected.
    Note that the `ReadAsJsonAsync` can be used here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Only the `Get` and `GetAll` methods for speakers have been tested in the preceding
    pages. Feel free to add tests for the `Search` methods to grow your integration
    test suite.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You should now have a firm grasp of integration testing, its benefits, and detriments.
    The mock API calls have been removed and the real API service has been implemented.
    Integration tests have been created and now ensure separate parts of the application
    are working well together.
  prefs: []
  type: TYPE_NORMAL
- en: Change is inevitable, especially in software development. In the next chapter,
    we'll be discussing how to handle a change in requirements. Whether these changes
    include new features, resolve defects, or change existing logic, through TDD these
    can be easily managed.
  prefs: []
  type: TYPE_NORMAL
