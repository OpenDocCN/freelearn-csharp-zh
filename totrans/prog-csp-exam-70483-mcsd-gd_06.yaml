- en: Managing and Implementing Multithreading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What happens when a long-running program starts executing on a client's computer?
    How do operating systems handle such long-running processes? Does the operating
    system notify the user about their progress? How does the operating system let
    the user know when it has finished with these processes? Threading is the way
    in which the operating system handles the responsiveness of your program while
    managing other system resources. This is achieved using multiple threads of execution,
    which is one of the most powerful ways to keep your application responsive while
    using the processor for other events.
  prefs: []
  type: TYPE_NORMAL
- en: An operating system organizes each running application as a process. Each process
    may contain one or more threads. A thread allows the operating system to allocate
    processor time as required. Each thread holds scheduling priority and a set of
    structures that are used by the system to pause or execute the thread. This is
    called **thread context**. In other words, the thread context holds all the information
    that's required by the system to seamlessly resume execution. As we've already
    mentioned, a process can contain multiple threads, all of which share the same
    virtual address space of the process.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will focus on creating and managing threads, synchronizing
    data across threads, and multithreading. We'll also look at how the operating
    system uses this concept to keep the responsiveness of the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding threads and the threading process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronizing data in multithreading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multithreading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The exercises in this chapter can be practiced using Visual Studio 2012 or above
    with .NET Framework 2.0 or above. However, any new C# features from C# 7.0 and
    above require that you have Visual Studio 2017 installed.
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have a license for any of the aforementioned products, you can
    download the community version of Visual Studio 2017 from [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/).
  prefs: []
  type: TYPE_NORMAL
- en: The sample code for this chapter can be found on GitHub at [https://github.com/PacktPublishing/Programming-in-C-sharp-Exam-70-483-MCSD-Guide/tree/master/Chapter06](https://github.com/PacktPublishing/Programming-in-C-sharp-Exam-70-483-MCSD-Guide/tree/master/Chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding threads and the threading process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A primary thread is started whenever a .NET program is started. Additional threads
    are created by this primary thread to execute the application login either concurrently
    or in parallel. These threads are called **worker threads**. These threads can
    execute any part of the program code, which may include parts that are executed
    by another thread. As these threads are free to cross application boundaries,
    .NET Framework provides a way to isolate these threads within a process using
    application domains (not available in .NET Core).
  prefs: []
  type: TYPE_NORMAL
- en: If our program can perform multiple operations in parallel, it will drastically
    decrease the total execution time. This can be achieved by utilizing multiple
    threads with multiprocessors or the multicore environment. The Windows operating
    system, when used alongside .NET Framework, ensures that these threads complete
    their respective tasks. Managing these tasks does have overhead, however. The
    OS allocates each thread a certain period of CPU time so that they can execute.
    After this period, a thread switch happens, which is called context switching.
    This context is saved and restored for each switch. To do this, Windows uses CPU
    registers and state data.
  prefs: []
  type: TYPE_NORMAL
- en: In an environment where multiple processors and multicore systems are available,
    we can take advantage of these resources and increase the throughput of the application.
    Consider a Windows application in which one thread (the primary thread) is handling
    the user interface by responding to user actions and other threads (worker threads)
    perform operations that require more time and processing. If the primary thread
    completes all of these operations, the user interfaces won't be responsive.
  prefs: []
  type: TYPE_NORMAL
- en: Because of this overhead, we need to carefully determine when to use multithreading.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming sections, we will focus on how we can create and manage threads,
    understand different thread properties, how we can create and pass parameters
    to threads, the difference between foreground and background threads, how to destroy
    threads, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Managing threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Threads can be created by creating a new instance of the `System.Threading`
    thread class and providing the name of the method that you want to execute on
    a new thread to the constructor. Using this class gives us more control and configuration
    of the program; for example, you can set the priority of the thread and whether
    it is a long-running thread, abort it, put it to sleep, and implement advanced
    configuration options. The `Thread.Start` method is used to create a thread call,
    while the `Thread.Abort` method is used to terminate the execution of a thread.
    The abort method raises `ThreadAbortException` when invoked. `Thread.Sleep` can
    be used to pause the execution of the thread for a certain amount of time. Finally,
    the `Thread.Interrupt` method is used to interrupt a blocked thread.
  prefs: []
  type: TYPE_NORMAL
- en: Let's understand these concepts by looking at a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code, `ThreadSample` is the primary thread, which starts the
    worker thread. The worker thread loops 10 times and writes to the console, letting
    the process know it has completed. After starting the worker thread, the primary
    thread loops four times. Note that the output depends on the environment you are
    running this program on. Try to change the seconds in the `thread.sleep` statement
    and observe the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the output of our program. `ThreadOne` starts its execution first
    and initiates 10 different worker threads and then the primary thread is executed.
    If you delay the execution of `ThreadOne` by using sleep, you will see the primary
    thread wait until `ThreadOne` returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fca1f269-d3ff-4f46-8c44-8455d1ac33a3.png)'
  prefs: []
  type: TYPE_IMG
- en: When the program is executed, a foreground thread is created automatically to
    execute the code. This primary thread then creates worker threads as required
    to execute the sections of the code from the same process. As you can see, the
    thread takes a delegate in its constructor.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding program, we used `thread.join`, which lets the primary thread
    wait until all the worker threads have completed their execution. Also, `Thread.Sleep(0)`
    tells Windows that the current thread has finished its execution so that a context
    switch can happen instead of Windows having to wait for the allocated time.
  prefs: []
  type: TYPE_NORMAL
- en: Thread properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each thread carries certain properties. The following table details each of
    them:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `IsAlive` | Returns `true` if the thread is in a started state. |'
  prefs: []
  type: TYPE_TB
- en: '| `IsBackground` | Gets or sets this property to let the system know how to
    execute the thread. |'
  prefs: []
  type: TYPE_TB
- en: '| `Name` | Name of the thread. |'
  prefs: []
  type: TYPE_TB
- en: '| `Priority` | Gets or sets thread priority. The default is `Normal`. |'
  prefs: []
  type: TYPE_TB
- en: '| `ThreadState` | Gets the thread''s current state. |'
  prefs: []
  type: TYPE_TB
- en: 'In the following code sample, we will call a method that will display information
    about some thread properties. We will also understand how we can pause a thread
    and terminate it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'When you execute the program, you will see the properties of each thread. You
    will also observe that although the primary thread has completed, the worker threads
    are still executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aca30cc8-553f-4a9a-8a8f-e5bc29f52fa6.png)'
  prefs: []
  type: TYPE_IMG
- en: You might have observed that only one thread is writing to the console at a
    time. This is known as **synchronization**. In this case, it is handled by the
    console class for us. Synchronization allows no two threads to execute the same
    code block at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Parameterized threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here, we will look at how we can pass arguments to the `ThreadStart` method.
    To achieve this, we will be using the `ParameterizedThreadStart` delegate on the
    constructor. The signature of this delegate is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'When you pass a parameter as an object to the `ThreadStart` method, it will
    cast the parameter to the appropriate type. The following sample program uses
    the same logic that we used previously, except that we pass the interval as an
    argument via the `ThreadStart` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f28de47d-495f-4785-a190-8d100e291557.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, let's look at foreground and background threads.
  prefs: []
  type: TYPE_NORMAL
- en: Foreground and background threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, when a thread is created, it is created as a foreground thread.
    You can use the `IsBackground` property to make a thread a background thread.
    The main difference between foreground and background threads is that a background
    thread does not run if all the foreground threads are terminated. The runtime
    aborts all the background threads when foreground threads are stopped. If a thread
    is created using a thread pool, then these threads are executed as background
    threads. Note that when an unmanaged thread enters the managed execution environment,
    it is executed as a background thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s jump into an example to understand the difference between foreground
    and background threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67377582-684b-4fc3-ac09-29a9b7eb8ac8.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the primary thread was created as a foreground thread while
    the worker thread was created as a background thread. When we stopped the primary
    thread, it stopped the background thread. This is why the elapsed time statement
    was not displayed through the loop, which is running for 5 seconds (`while(sw.ElapsedMilliseconds
    <=5000)`).
  prefs: []
  type: TYPE_NORMAL
- en: Thread states
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When a thread is created, it will be in an **Unstarted** state until the **Start**
    method is invoked. A thread is always in at least one state and sometimes it may
    be in multiple states at the same time. In the following diagram, each oval represents
    a state. The text on each line represents the action that is performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/575bba21-2b4f-4c23-8c09-30d501edae13.png)'
  prefs: []
  type: TYPE_IMG
- en: A thread can be in two different states at the same time. For example, if a
    thread is in a waiting state and another thread aborts, it can be in both the
    **Wait/Join Sleep** and **Abort Requested** states. When the thread returns to
    the wait call, it will receive a `ThreadAbortException`.
  prefs: []
  type: TYPE_NORMAL
- en: Destroying threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `Thread.Abort` method is used to stop a thread. Once aborted, it cannot
    be restarted. However, when you invoke `Thread.Abort`, it doesn't terminate the
    thread immediately since the `Thread.Abort` statement throws a `ThreadAbortException`,
    which needs to be caught. Then, the cleanup code should be executed. If you call
    the `Thread.Join` method, this will make sure the thread waits until the other
    thread's execution is completed. The `join` method depends on the timeout interval,
    so if it's not specified, then the wait is not guaranteed.
  prefs: []
  type: TYPE_NORMAL
- en: When your own code aborts a thread and you don't want to rethrow it, use the
    `ResetAbort` method. You will learn more about how to rethrow exceptions in [Chapter
    7](7c2b2a82-6a5c-4c96-a877-04d8a6e26ef0.xhtml), *Implementing Exception Handling*.
  prefs: []
  type: TYPE_NORMAL
- en: Thread pools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A thread pool provides a pool of threads that can be used as worker threads
    and are managed by the system. This allows us to focus on application logic instead
    of managing threads. This is an easy way for us to use multiple threads. From
    .NET Framework 4 onward, it became easy to use thread pools as they allowed us
    to create tasks and perform asynchronous tasks. The **Task Parallel Library**
    (**TPL**) and asynchronous method calls are mainly dependent on the thread pool.
  prefs: []
  type: TYPE_NORMAL
- en: Threads that are created from a thread pool are background threads. Each thread
    uses default properties. When a thread completes its task, it is returned to a
    queue of waiting threads so that they can be reused. In turn, this reduces the
    cost of creating new threads for every task. You can have one thread pool per
    process.
  prefs: []
  type: TYPE_NORMAL
- en: .NET Framework allows us to set and get `MaxThread` for a thread pool, though
    the number of threads that can be queued is limited by available memory. Once
    the thread pool threads are busy, other tasks are queued until the threads are
    available.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that any unhandled exception in a thread pool
    will terminate this process. More information on thread pools can be found at
    [https://docs.microsoft.com/en-us/dotnet/standard/threading/the-managed-thread-pool](https://docs.microsoft.com/en-us/dotnet/standard/threading/the-managed-thread-pool).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows how we can create multiple threads using a thread
    pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of running the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/edce518e-f26b-4179-8b24-7f39e97f9179.png)'
  prefs: []
  type: TYPE_IMG
- en: Her, we created five worked threads using the thread pool. If you uncomment
    `Thread.CurrentThread.Join` in the preceding code, the primary thread won't exit
    until all of the threads have been processed.
  prefs: []
  type: TYPE_NORMAL
- en: Thread storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thread-relative static fields and data slots are the two ways in which we can
    store data that is unique to the thread and application domain. Thread-relative
    static fields are defined at compile time and provide the best performance. Another
    benefit is that they do compile-time type checking. These fields are used when
    the requirement about what kind of data to be stored is clear beforehand.
  prefs: []
  type: TYPE_NORMAL
- en: Thread-relative static fields can be created using `ThreadStaticAttribute`.
  prefs: []
  type: TYPE_NORMAL
- en: There are scenarios where these storage requirements may arise at runtime. In
    such scenarios, we can opt for data slots. These are a bit slower than static
    fields. Since these are created at runtime, they store information as an object
    type. It is important for us to convert these objects into their respective types
    before using them.
  prefs: []
  type: TYPE_NORMAL
- en: '.NET Framework allows us to create two types of data slots: named data slots
    and unnamed data slots. Named data slots use the `GetNamedDataSlot` method so
    that we can retrieve it as and when required. However, one disadvantage of `NamedDataslot`
    is when two threads from the same application domain use the same data slot in
    two different components of code and execute them at the same time. When this
    happens, they can corrupt each other''s data.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ThreadLocal<T>` can be used to create local data storage.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These two ways of storing data can be referred to as **thread-local storage**
    (**TLS**). A couple of the benefits of managed TLS are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Within an application domain, one thread cannot modify data from another thread,
    even when both threads use the same field or slot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a thread accesses the same field or slot from multiple application domains,
    a separate value is maintained in each application domain
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we will jump into an example and look at how the `ThreadStatic` attribute
    can be used. In the following example, a static variable is being defined and
    decorated with the `ThreadStatic` attribute. This ensures that each thread has
    its own copy of the variable. When you execute the following program, you will
    observe that `_intvariable` goes up to 6 for each thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of running the preceding program.
    Comment the `ThreadStatic` attribute and run the program again—you will find that
    the `_intvariable` value goes up to 18 as each thread updates its value:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f843c56b-b2b7-4ab2-9fd3-998b1398a21c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s see how we can use `ThreadLocal<T>` to create local storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8d01b785-5fbc-4c3a-a685-ca0dcaeb507e.png)'
  prefs: []
  type: TYPE_IMG
- en: Now that we've understood how to manage threads, let's look at how to synchronize
    data in multithreading.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing data in multithreading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multiple threads can invoke the methods or properties of an object, which can
    make the state of an object invalid. It is possible to make conflicting changes
    regarding two or more threads on the same object. This makes it important to synchronize
    these calls, which will allow us to avoid such issues. When the members of a class
    are protected from conflicting changes, they are known to be **thread-safe**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CLR provides multiple ways in which we can synchronize access to the object
    instance and static members:'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronize code regions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual synchronization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronize context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thread-safe collection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, there is no synchronization for objects, which means any thread
    can access methods and properties at any time.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing code regions allows us to synchronize blocks of code, methods,
    and static methods. However, synchronizing static fields is not supported. Synchronizing
    is possible if we use a `Monitor` class or a keyword. C# supports the `lock` keyword,
    which can be used to mark blocks of code for synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: When applied, the threads attempt to acquire the lock while executing the code.
    If another thread has already been acquired by the lock on this block, then the
    thread blocks until the lock is available. The lock is released when the thread
    has executed the code block or exits in any other way.
  prefs: []
  type: TYPE_NORMAL
- en: '`MethodImplAttribute` and `MethodImplOptions.Synchronized` give us the same
    results as using `Monitor` or keywords to lock the code block.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at an example to understand lock statements with tasks. We will learn
    more about tasks in the upcoming sections.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the purpose of this example, we created an `Account` class that synchronizes
    its private field balance amount by locking it to an instance. This ensures that
    no two threads update this field at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `TestLockStatements(``)` method looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We are creating two tasks, and each task invokes `UpdateMethod`. This method
    loops 10 times and updates the account balance using either credit or debit methods.
    Because we are using the `lock(obj)` field at the instance level, the balance
    amount field won't be updated at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows the desired output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Accessing shared variables across multiple threads may cause data integrity
    issues. Such issues can be addressed by using a synchronization primitive. These
    are derived by the `System.Threading.WaitHandle` class. While performing manual
    synchronization, a primitive can protect access to shared resources. Different
    synchronization primitive instances are used to protect access to a resource or
    some parts of code access, which allows multiple threads to access a resource
    concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about synchronization primitives at [https://docs.microsoft.com/en-us/dotnet/standard/threading/overview-of-synchronization-primitives](https://docs.microsoft.com/en-us/dotnet/standard/threading/overview-of-synchronization-primitives).
  prefs: []
  type: TYPE_NORMAL
- en: The `System.Collections.Concurrent` namespace was introduced by .NET Framework
    and can be used without additional synchronization in the user code. This namespace
    includes several collection classes that are both thread-safe and scalable. This
    allows multiple threads to add or remove items from these collections.
  prefs: []
  type: TYPE_NORMAL
- en: More information on these thread-safe collections can be found at [https://docs.microsoft.com/en-us/dotnet/standard/collections/thread-safe/index](https://docs.microsoft.com/en-us/dotnet/standard/collections/thread-safe/index).
  prefs: []
  type: TYPE_NORMAL
- en: Multithreading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Developers are allowed to create multiple threads within a process and manage
    them throughout the program''s execution. This allows us to focus on the application
    logic instead of managing threads. However, starting with .NET Framework 4, we
    can create multithreaded programs using the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: TPL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parallel Language-Integrated Query**(**PLINQ**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand both of these features, we need to talk about parallel programming.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel programming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Parallel programming** helps the developer take advantage of the hardware
    on workstations where multiple CPU cores are available. They allow multiple threads
    to be executed in parallel.'
  prefs: []
  type: TYPE_NORMAL
- en: In previous versions, parallelization required low-level manipulation of threads
    and locks. From .NET Framework 4 onward, enhanced support for parallel programming
    was provided in the form of the runtime, class library types, and diagnostic tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the high-level architecture of parallel programming:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/955ad58e-8fd8-4cce-9825-93e9914c6db6.png)'
  prefs: []
  type: TYPE_IMG
- en: In the upcoming sections, we will talk about some of the components listed in
    the preceding architecture diagram.
  prefs: []
  type: TYPE_NORMAL
- en: TPL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TPL makes developers more productive by creating parallel and concurrent applications.
    These are available as public types in the `System.Threading` and `System.Threading.Tasks`
    namespaces. TPL allows us to maximize code performance while focusing on program
    work. TPL is based on tasks, which represent a thread or thread pool. When one
    or more tasks are run concurrently, this is known as task parallelism. A task
    has a couple of benefits: being scalable and efficient, and having more programmatic
    control than threads.'
  prefs: []
  type: TYPE_NORMAL
- en: Because TPL handles the partitioning of the work, scheduling, cancellation,
    state, and other low-level details, it can scale the degree of concurrency dynamically
    and use the system resources or processors that are available.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to be aware of when to apply parallel programming, otherwise
    the overhead of parallelization decreases the speed of code execution. A basic
    understanding of threading concepts such as locks and deadlocks is important so
    that we can use TPL effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Data parallelism
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When an operation can be performed concurrently on source collection elements,
    it is referred to as data parallelism. In this process, the source collection
    is partitioned into multiple threads and executed in parallel. .NET Framework
    supports data parallelism via the `System.Threading.Tasks.Parallel` class. Methods
    such as `Parallel.For` and `Parallel.ForEach` are defined in this class. When
    you use these methods, the framework manages all the low-level work for us.
  prefs: []
  type: TYPE_NORMAL
- en: A task represents an asynchronous operation and does not return a value. These
    are defined in the `System.Threading.Tasks` class.
  prefs: []
  type: TYPE_NORMAL
- en: Using tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A task represents an operation that may or may not return a value and executes
    asynchronously. Since they are executed asynchronously, they are executed as worker
    threads from the thread pool rather than the primary thread. This allows us to
    use the `isCanceled` and `IsCompleted` properties to understand the state of the
    task. You can also make a task run synchronously, which will be executed on the
    main or primary thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'A task can implement the `IAsyncResult` and `IDisposable` interfaces like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at an example so that we can understand how we can create and initiate
    a task in different ways. In this example, we will use an action delegate that
    takes an argument of the `object` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here, we create four different tasks. For the first task, we used start methods,
    while for the second task, we used a task `factory.startnew` method. The third
    task was started using the `run(Action)` method, while the fourth task was executed
    synchronously on the main thread using the run synchronously method. Here, tasks
    1, 2, and 3 are worker threads that are using a thread pool, while task 4 is executing
    on the primary thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the output of running the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2796ffa5-1d98-4b42-b575-49621395d9e5.png)'
  prefs: []
  type: TYPE_IMG
- en: The `Wait` method is similar to `Thread.Join`, which waits until the task completes.
    This is useful when synchronizing the execution of calling threads and asynchronous
    tasks since we can wait for one or more threads to complete. The `Wait` method
    also accepts certain parameters that allow us to conditionally wait for a task
    to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the different options that are available for a thread
    when it comes to waiting:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `Wait` | Waits for the task''s execution to complete. |'
  prefs: []
  type: TYPE_TB
- en: '| `Wait(int32)` | Makes the tasks wait for a specified number of milliseconds
    before executing. |'
  prefs: []
  type: TYPE_TB
- en: '| `Wait(Timespan)` | Waits for the task''s execution to complete within a specified
    time interval. |'
  prefs: []
  type: TYPE_TB
- en: '| `Wait(CancellationToken)` | Waits for the task''s execution to complete.
    The wait is terminated if `cancellationToken` is issued before the task''s execution
    is completed. |'
  prefs: []
  type: TYPE_TB
- en: '| `Wait(Int32, CancellationToken)` | Waits for the task''s execution to complete.
    The wait terminates on timeout or when a cancellation token is issued before the
    task completes. |'
  prefs: []
  type: TYPE_TB
- en: '| `WaitAll` | Waits for all the provided tasks to complete their execution.
    Similar to the `Wait` method, `WaitAll` tasks multiple parameters and performs
    them accordingly. |'
  prefs: []
  type: TYPE_TB
- en: '| `WaitAny` | Waits for the provided task to complete its execution. Similar
    to the `Wait` method, `WaitAll` tasks multiple parameters and performs them accordingly.
    |'
  prefs: []
  type: TYPE_TB
- en: 'Tasks support two other methods: `WhenAll` and `WhenAny`. Now, `WhenAll` is
    used to create a task that will complete its execution when all the provided tasks
    have been completed. Similarly, `WhenAny` creates tasks and completes when the
    provided task completes its execution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A task can also return a value. However, reading the result of a task means
    waiting until its execution has completed. Without completing its execution, it
    isn''t possible to use the result object. The following is an example of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'By executing the preceding code, you will see that the main thread waits until
    the task returns a value. Then, it displays a `Press any key to exit` message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s also possible to add a continuation task. .NET Framework provides a keyword
    called `ContinueWith`, which allows you to create a new task and execute it once
    the previous tasks have finished executing. In the following code, we are instructing
    the task to continue with the result from the parent task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'When task `t` has completed its execution, the result is used in the second
    task, `t1`, and the final result is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '`ContinueWith` has a couple of overload methods that allow us to configure
    when the continuation task should execute, such as when a task is canceled or
    completed successfully. To make this configuration work, we will use `TaskContinuationOptions`.
    You can find more of the options that are available at [https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskcontinuationoptions?view=netframework-4.7.2](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskcontinuationoptions?view=netframework-4.7.2).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block shows how we can use `continuationOptions`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '`TaskFactory` supports creating and scheduling tasks. It also allows us to
    do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a task and start it immediately using the `StartNew` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a task that starts when any one of the tasks in an array has completed
    by calling the `ContinueWhenAny` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a task that starts when all the tasks in an array have completed by calling
    the `ContinueWhenAll` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading on `TaskFactory` can be found at [https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskfactory?view=netframework-4.7.2](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskfactory?view=netframework-4.7.2).
  prefs: []
  type: TYPE_NORMAL
- en: Using the Parallel class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The `System.Threading` class has another class named `Parallel`. This class
    provides parallel implementations for `For` and `ForEach` loops. Their implementation
    is similar to the sequential loop. When you use `ParallelFor` or `ParallelForEach`,
    the system automatically splits the process into multiple tasks and acquires locks
    if required. All of this low-level work is handled by TPL.
  prefs: []
  type: TYPE_NORMAL
- en: 'A sequential loop may look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The same loop can be represented using `Parallel` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: TPL manages the data source and creates partitions so that the loop can operate
    on multiple parts in parallel. Each task will be partitioned by the task scheduler
    as per system resources and workload. Then, if the workload becomes unbalanced,
    the work will be redistributed into multiple threads and processes by the task
    scheduler.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel programming can increase performance when you have a lot of work to
    be done in parallel. If this isn't the case, it can become a costly affair.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand how parallelism works in a scenario given. In
    the following example, we'll look at how we can use `Parallel.For` and make a
    time comparison between sequential and parallel loops.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we are defining an array of integers and calculating the sum and product
    of each element of the array. In the main program, we invoke this method using
    sequential and parallel loops and calculate how much time each loop takes to complete
    the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, we executed two loops: one using a parallel loop and
    the other using a sequential loop. The results show the time each operation took:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2683561f-3fd8-40d0-855f-e7275065851f.png)'
  prefs: []
  type: TYPE_IMG
- en: '`System.Threading.Tasks.Parallel` comes with multiple helper classes, such
    as `ParallelLoopResult`, `ParallelLoopState`, and `ParallelOptions`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ParallelLoopResult` provides the completion status of the parallel loop, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '`ParallelLoopState` allows iterations of parallel loops to interact with other
    iterations. Finally, `LoopState` allows you to identify any exceptions in iterations,
    break from an iteration, stop an iteration, identify if any iteration has invoked
    break or stop, and break long-running iterations.'
  prefs: []
  type: TYPE_NORMAL
- en: PLINQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Language-Integrated Query** (**LINQ**) was introduced in .NET Framework 3.5\.
    It allows us to query in-memory collections such as `List<T>`. You will learn
    more about LINQ in [Chapter 15](75481977-f6a3-41af-ab1e-e3b112dd9aad.xhtml), *Using
    LINQ Queries*. However, if you want to find out more sooner, more information
    can be found at [https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/index](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/index).'
  prefs: []
  type: TYPE_NORMAL
- en: PLINQ is the parallel implementation of the LINQ pattern. They resemble LINQ
    queries and operate on any in-memory collections but differ in terms of execution.
    PLINQ uses all the available processors in the system. However, the processors
    are limited to 64 bits. This is achieved by partitioning the data source into
    smaller tasks and executing each task on separate worker threads on multiple processors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the standard query operators are implemented in the `System.Linq.ParallelEnumerable`
    class. The following table lists the various parallel execution-specific methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `AsParallel` | When you want a system to perform parallel execution on an
    enumerable collection, the `AsParallel` instruction can be provided to the system.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `AsSequential` | Instructing the system to run sequentially can be achieved
    by using `AsSequential`. |'
  prefs: []
  type: TYPE_TB
- en: '| `AsOrdered` | To maintain the order on the result set, use `AsOrdered`. |'
  prefs: []
  type: TYPE_TB
- en: '| `AsUnordered` | To not maintain the order on the result set, use `AsUnordered`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `WithCancellation` | A cancellation token carries the user''s request to
    cancel the execution. This has to be monitored so that execution can be canceled
    at any time. |'
  prefs: []
  type: TYPE_TB
- en: '| `WithDegreeofParallelism` | Controls the number of processors to be used
    in a parallel query. |'
  prefs: []
  type: TYPE_TB
- en: '| `WithMergeOptions` | Provides options so that we can merge results to the
    parent task/thread/result set. |'
  prefs: []
  type: TYPE_TB
- en: '| `WithExecutionMode` | Forces the runtime to use either parallel or sequential
    modes. |'
  prefs: []
  type: TYPE_TB
- en: '| `ForAll` | Allows results to be processed in parallel by not merging to the
    parent thread. |'
  prefs: []
  type: TYPE_TB
- en: '| `Aggregate` | A unique PLINQ overload to enable intermediate aggregation
    over thread-local partitions. Also allows us to merge the final aggregation to
    combine the results of all partitions. |'
  prefs: []
  type: TYPE_TB
- en: 'Let''s try to use some of these methods so that we can understand them in more
    detail. The `AsParallel` extension method binds query operators such as `where`
    and `select` to the `parallelEnumerable` implementation. By simply specifying
    `AsParallel`, we tell the compiler to execute the query in parallel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'When executed, the preceding code block identifies all even numbers and prints
    them on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac50e5c7-f5b7-4416-9ae0-d113a7fa112a.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the even numbers weren't printed in order. One thing to remember
    regarding parallel processing is that it does not guarantee any particular order.
    Try executing the code block multiple times and observe the output. It will differ
    each time since it is based on the number of processors that are available at
    the time of execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'By using the `AsOrdered` operator, the code block accepts a range of numbers
    between 1 and 20\. However, using `AsOrdered` will order the numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This example shows how we can maintain the order of the result set when using
    `Parallel`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: When you execute a code block using PLINQ, the runtime analyzes whether it is
    safe to parallelize the query. If it is, it partitions the query into tasks and
    then runs them concurrently. If it isn't safe to parallelize the query, it executes
    the query in a sequential pattern. In terms of performance, using a sequential
    algorithm is better than using a parallel algorithm, so by default, PLINQ selects
    the sequential algorithm. Using `ExecutionMode` will allow us to instruct PLINQ
    to select the parallel algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The following code block shows how we can use `ExecutionMode`**:**
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'As we mentioned previously, PLINQ uses all the processors by default. However,
    by using the `WihtDegreeofParallelism` method, we can control the number of processors
    to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Execute the preceding code block by changing the number of processors and observe
    the output. In the first scenario, we left the system to use the available cores/processors,
    but in the second one, we instructed the system to use three cores. You will see
    that the difference in performance is based on your system's configuration.
  prefs: []
  type: TYPE_NORMAL
- en: PLINQ also comes with a method called `AsSequential`. This is used to instruct
    PLINQ to execute queries sequentially until `AsParallel` is called.
  prefs: []
  type: TYPE_NORMAL
- en: '`forEach` can be used to iterate through all the results of a PLINQ query and
    merges the output from each task to the parent thread. In the preceding examples,
    we used `forEach` to display even numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: '`forEach` can be used to preserve the order of the PLINQ query results. So,
    when order preservation is not required and we want to achieve faster query execution,
    we can use the `ForAll` method. `ForAll` does not perform the final merge step;
    instead, it parallelizes the processing of results. The following code block is
    using `ForAll` to print output to the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In this scenario, the I/O is being used by multiple tasks, so the numbers will
    appear in a random order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5d0ec129-6fe0-48d5-a435-dd2e500666d9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When PLINQ executes in multiple threads, as the code runs, the application
    logic may fail in one or more threads. PLINQ uses the `Aggregate` exception to
    encapsulate all the exceptions that are thrown by a query and sends them back
    to the calling thread. When doing this, you need to have one `try..catch` block
    on the calling thread. When you get the results from the query, the developer
    can traverse through all the exceptions encapsulated in `AggregatedException`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code block is writing all the details from an exception that
    was thrown in a PLINQ. Here, we are traversing and showcasing all six exceptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a0f88c43-4592-4dbc-9f2e-836dd9016e98.png)'
  prefs: []
  type: TYPE_IMG
- en: You can loop through the `InnerExceptions` property and take necessary actions.
    We will look at inner exceptions in more detail in [Chapter 7](7c2b2a82-6a5c-4c96-a877-04d8a6e26ef0.xhtml),
    *Implementing Exception Handling*. However, in this case, when a PLINQ is executed,
    instead of terminating the execution on an exception, it will run through all
    the iterations and provide the final results.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous programming with async and await
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Asynchronous programming** can help you enhance the responsiveness and performance
    of an application. In a traditional approach, it is difficult to write and maintain
    asynchronous code. However, C# 5 introduced two new keywords that simplify asynchronous
    programming: `async` and `await`. When encountered, the C# compiler does all the
    difficult work for you. It resembles synchronous code. `Task` and `Task<T>` are
    at the core of asynchronous programming.'
  prefs: []
  type: TYPE_NORMAL
- en: Any I/O-bound or CPU-bound code can utilize asynchronous programming. In the
    case of IO-bound code, when you want to return a task from an `async` method,
    we use the `await` operation, whereas in CPU-bound code we wait for the operation
    that started a background thread using `Task.Run`.
  prefs: []
  type: TYPE_NORMAL
- en: When the `await` keyword is used, it returns control to the calling methods,
    thus allowing the UI to be responsive.
  prefs: []
  type: TYPE_NORMAL
- en: 'Internally, when the compiler encounters the `async` keyword, it splits the
    method into tasks, and each task is marked with the `await` keyword. The `await`
    keyword generates code that will check whether the asynchronous operation has
    already completed; that is, the C# compiler transforms the code into a state machine
    that keeps track of the metadata related to each task/thread so that it can resume
    execution when the background task has finished executing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code block, we are trying to find how many times a specific
    word has been used on a website. The output of the previous code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Here, we used the `async` keyword on the `GetDotnetCountAsync` method. Although
    the method is executed synchronously, the `await` keyword allows us to return
    to the calling method and wait until the `async` method has finished executing,
    which is when it returns the result.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to understand that an `async` method body should always have
    an `await`, otherwise this method will never yield. No error is raised by the
    compiler either.
  prefs: []
  type: TYPE_NORMAL
- en: When writing asynchronous methods, you should always use `async` as the suffix.
    Note that `async` must be used for event handlers. This is the only method that
    allows `async` events handlers to work as events do not have return types.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about the **Task-Based Asynchronous Pattern** (**TAP**) from
    MSDN at [https://docs.microsoft.com/en-us/dotnet/standard/asynchronous-programming-patterns/task-based-asynchronous-pattern-tap](https://docs.microsoft.com/en-us/dotnet/standard/asynchronous-programming-patterns/task-based-asynchronous-pattern-tap).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at threads, their properties, how we can use parameterized
    threads, and the difference between foreground and background threads with detailed
    examples. We also learned about thread states and how threads store and share
    data across multiple threads. This is where we discussed different synchronization
    methods. We focused on parallel programming, tasks and asynchronous programming
    using tasks, how to use parallel classes, and PLINQ.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore exception handling in C#. Exception handling
    helps us deal with any unexpected or exceptional situations that occur during
    program execution. Exception handling uses the `try`, `catch`, and `finally` blocks.
    These help developers try out actions that may or may not succeed, handle failures
    if they occur, and clean up unwanted resources, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, the main method of your code block runs as which of the following?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Worker thread
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Primary thread
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Background thread
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: None of the above
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What action needs to be performed to move a thread to the run state when suspended?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Interrupt
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Resume
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Abort
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Suspended
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the correct keyword to use while working on synchronization code regions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lock
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Release
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Getlock
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Unlock
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A task may or may not return a value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When working with PLINQ, the results are returned in order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Primary thread**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Resume**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Lock**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**True**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**False**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we talked about many features that .NET Framework offers that
    we can use in our applications. However, we didn''t cover this topic in detail.
    Therefore, it may be useful for you to go through a couple of MSDN articles so
    that you can understand more about these concepts. Take a look at the following
    links:'
  prefs: []
  type: TYPE_NORMAL
- en: More on application domains can be found at [https://docs.microsoft.com/en-us/dotnet/framework/app-domains/application-domains#application-domains-and-threads](https://docs.microsoft.com/en-us/dotnet/framework/app-domains/application-domains#application-domains-and-threads).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More on threads and processes can be found at [https://docs.microsoft.com/en-us/windows/desktop/procthread/processes-and-threads](https://docs.microsoft.com/en-us/windows/desktop/procthread/processes-and-threads).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following documentation on parallel programming will help you understand
    some of the topics that we didn''t cover in this chapter: [https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/for-further-reading-parallel-programming](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/for-further-reading-parallel-programming).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One of the concepts that you''ll need to understand while working with tasks
    is task schedulers: [https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskscheduler?view=netframework-4.7.2](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskscheduler?view=netframework-4.7.2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following article about async provides more information about all the moving
    pieces that are used when asynchronous operations are performed: [https://docs.microsoft.com/en-us/dotnet/standard/async-in-depth](https://docs.microsoft.com/en-us/dotnet/standard/async-in-depth).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
