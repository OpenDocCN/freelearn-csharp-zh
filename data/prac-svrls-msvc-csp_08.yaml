- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Practical Microservices Organization with Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 实践微服务组织
- en: 'This chapter is dedicated to a fundamental building block of microservice applications:
    orchestrators! The focus is on **Kubernetes**, but the concepts learned here are
    fundamental for understanding other orchestration options. In particular, **Azure
    Container Apps** is a serverless alternative to Kubernetes, implemented with Kubernetes
    itself, and uses simplified configuration options, but the objects to configure
    and concepts involved are exactly the same. Azure Container Apps is described
    in [*Chapter 9*](Chapter_9.xhtml#_idTextAnchor261)*, Simplifying Containers and
    Kubernetes: Azure Container Apps* *and other Tools*.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章致力于微服务应用程序的基本构建块：编排器！重点是 **Kubernetes**，但在这里学到的概念对于理解其他编排选项也是基本的。特别是，**Azure
    Container Apps** 是 Kubernetes 的无服务器替代方案，它本身是用 Kubernetes 实现的，并使用简化的配置选项，但配置的对象和涉及的概念完全相同。Azure
    Container Apps 在 [*第 9 章*](Chapter_9.xhtml#_idTextAnchor261) *简化容器和 Kubernetes：Azure
    Container Apps* *和其他工具* 中进行描述。
- en: All concepts will be exemplified with small examples and with the car-sharing
    book case study application. After a general description of orchestrators’ role
    and functionalities, we will describe how to configure and interact in practice
    with a Kubernetes cluster. We will use **Minikube**, which is a local simulator
    of a Kubernetes cluster, throughout the chapter. However, we will also explain
    how to create and use a Kubernetes Azure cluster.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所有概念将通过小型示例和汽车共享案例研究应用程序进行说明。在一般描述编排器的角色和功能之后，我们将描述如何在实际中配置和与 Kubernetes 集群交互。本章将使用
    **Minikube**，这是一个 Kubernetes 集群的本地模拟器。然而，我们也会解释如何创建和使用 Kubernetes Azure 集群。
- en: We will also describe how to test and debug the interaction of some microservices
    during development with **Docker** first, and then the complete application running
    in a Kubernetes cluster. A .NET-specific alternative for testing a microservices
    application in the development stage is **.NET Aspire**, which will be described
    in [*Chapter 12*](Chapter_12.xhtml#_idTextAnchor345)*, Simplifying Microservices
    with .NET Aspire*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先描述如何在开发过程中使用 **Docker** 测试和调试一些微服务的交互，然后是运行在 Kubernetes 集群中的完整应用程序。在开发阶段测试微服务应用程序的
    .NET 特定替代方案是 **.NET Aspire**，它将在 [*第 12 章*](Chapter_12.xhtml#_idTextAnchor345)
    *使用 .NET Aspire 简化微服务* 中进行描述。
- en: 'More specifically, this chapter covers:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，本章涵盖：
- en: Introduction to orchestrators and their configuration
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编排器及其配置的介绍
- en: Kubernetes basics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 基础
- en: 'Interacting with Kubernetes: Kubectl and Minikube'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 Kubernetes 交互：Kubectl 和 Minikube
- en: Configuring your application in Kubernetes
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中配置您的应用程序
- en: Running your microservices on Kubernetes
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上运行您的微服务
- en: Advanced Kubernetes configuration
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级 Kubernetes 配置
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要：
- en: At least the Visual Studio 2022 free *community edition*.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 至少 Visual Studio 2022 的免费 *社区版*。
- en: An SQL instance accepting TCP/IP requests and user/password authentication,
    and **Docker Desktop** for Windows, the installation for which was explained in
    the *Technical requirements* section of [*Chapter 7*](Chapter_7.xhtml#_idTextAnchor151)*,
    Microservices in Practice*.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个接受 TCP/IP 请求和用户/密码认证的 SQL 实例，以及 Windows 的 **Docker Desktop**，其安装已在 [*第 7 章*](Chapter_7.xhtml#_idTextAnchor151)
    *实践中的微服务* 的 *技术要求* 部分中解释。
- en: '**If you would like to interact with a Kubernetes cluster on Azure, you need
    Azure CLI. The page at** [https://learn.microsoft.com/bs-latn-ba/cli/azure/install-azure-cli-windows?tabs=azure-cli](https://learn.microsoft.com/bs-latn-ba/cli/azure/install-azure-cli-windows?tabs=azure-cli)
    **contains the links to both the 32-bit and 64-bit Windows installers.**'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**如果您想与 Azure 上的 Kubernetes 集群交互，则需要 Azure CLI。以下页面包含 32 位和 64 位 Windows 安装程序的链接**：[https://learn.microsoft.com/bs-latn-ba/cli/azure/install-azure-cli-windows?tabs=azure-cli](https://learn.microsoft.com/bs-latn-ba/cli/azure/install-azure-cli-windows?tabs=azure-cli)。'
- en: '**Minikube**: The easiest way to install Minikube is by using the Windows installer
    you can find on the official installation page: [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/).
    During the installation, you will be prompted on the kind of virtualization tool
    to use – please specify Docker. The previous link also gives a PowerShell command
    for adding `minicube.exe` to the Windows path.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Minikube**：安装Minikube的最简单方法是使用您可以在官方安装页面找到的Windows安装程序：[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)。在安装过程中，您将收到提示选择要使用的虚拟化工具
    – 请指定Docker。前面的链接还提供了一个将`minicube.exe`添加到Windows路径的PowerShell命令。'
- en: '**Kubectl**: First of all, verify if it is already installed by opening a Windows
    console and issuing this command: `Kubectl -h`. If the response is the list of
    all Kubectl commands, it is already installed. Otherwise, the simplest way to
    install it is through the **Chocolatey** package installer:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Kubectl**：首先，通过打开Windows控制台并执行此命令来验证它是否已安装：`Kubectl -h`。如果响应是所有Kubectl命令的列表，则已安装。否则，安装它的最简单方法是通过**Chocolatey**包安装程序：'
- en: '[PRE0]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If Chocolatey is not already installed, you can install it by launching **PowerShell**
    in administrative mode and then issuing the PowerShell command suggested on the
    official Chocolatey page: [https://chocolatey.org/install#individual](https://chocolatey.org/install#individual).
    You can launch PowerShellin administrative mode as follows:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果Chocolatey尚未安装，您可以通过以管理员模式启动**PowerShell**并执行官方Chocolatey页面上的建议命令来安装它：[https://chocolatey.org/install#individual](https://chocolatey.org/install#individual)。您可以通过以下方式以管理员模式启动PowerShell：
- en: Search **PowerShell** in the Windows search box.
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Windows搜索框中搜索**PowerShell**。
- en: Right-click on the **PowerShell** link and select to execute it as an administrator.
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击**PowerShell**链接，并选择以管理员身份执行。
- en: You can find the sample code for this chapter at [https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp)找到本章的示例代码。
- en: Introduction to orchestrators and their configuration
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编排器和它们的配置简介
- en: Orchestrators were mainly conceived for balancing microservices’ load. Therefore,
    one might ask if they are necessary for all applications. I can’t say they are
    necessary, but, for sure, renouncing them doesn’t mean just manually configuring
    where to place each replica of each microservice. We should also find efficacious
    solutions for dynamically reconfiguring the number of replicas and their locations,
    for balancing the load among several replicas allocated on different servers,
    and for balancing the traffic among the various replicas of each microservice.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 编排器主要是为了平衡微服务的负载而设计的。因此，有人可能会问，它们对所有应用程序都是必要的吗？我无法说它们是必要的，但肯定的是，放弃它们并不意味着只是手动配置每个微服务的每个副本的位置。我们还应该找到有效的解决方案来动态重新配置副本的数量和位置，以平衡分配在不同服务器上的多个副本之间的负载，以及平衡每个微服务的各个副本之间的流量。
- en: 'The above simple considerations show that an efficacious orchestrator should
    offer at least the following services:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 上述简单考虑表明，一个有效的编排器至少应提供以下服务：
- en: Accepting high-level specifications and translating them into actual allocations
    of microservice replicas on different servers of a given cluster.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接受高级规格并将其转换为在给定集群的不同服务器上实际分配微服务副本。
- en: Providing a unique virtual address for all replicas of the same microservices
    and automatically splitting the traffic among them. This way, the code of each
    microservice can reference just this unique virtual address without caring where
    each replica is.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为同一微服务的所有副本提供一个唯一的虚拟地址，并自动在它们之间分配流量。这样，每个微服务的代码只需引用这个唯一的虚拟地址，而无需关心每个副本的位置。
- en: Recognizing faulty replicas, killing them, and replacing them with newly created
    replicas.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别故障副本，终止它们，并用新创建的副本替换它们。
- en: Downloading microservices container images from container registries.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从容器注册表中下载微服务容器镜像。
- en: 'Moreover, since microservice replicas are ephemeral and can be destroyed and
    moved from one server to another, they can’t use the disk storage of the servers
    that host them. Instead, they must use network storage. Orchestrators must also
    provide simple ways to allocate disk storage and mount it inside the containers
    where the microservices run. In general, they must provide easy ways of projecting
    everything that can be projected inside a container, namely:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于微服务副本是短暂的，可以被销毁并从一个服务器移动到另一个服务器，因此它们不能使用托管它们的服务器的磁盘存储。相反，它们必须使用网络存储。编排器还必须提供简单的方法来分配磁盘存储并在运行微服务的容器内挂载它。一般来说，它们必须提供简单的方法来投影容器内可以投影的所有内容，即：
- en: Disk storage
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 磁盘存储
- en: Environment variables
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 环境变量
- en: Communication ports
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通信端口
- en: As a matter of fact, each orchestrator also offers other services, but the seven
    services listed above are the starting point for learning and assessing any orchestrator.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，每个编排器还提供其他服务，但上面列出的七个服务是学习和评估任何编排器的起点。
- en: 'The behavior of an orchestrator is controlled with tree-like settings coming
    from various sources: configuration files, command arguments, and so on. Behind
    the curtain, all sources are packaged by a client that communicates with an orchestrator
    web API.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 编排器的行为由来自各种来源的树形设置控制：配置文件、命令参数等。在幕后，所有来源都由一个与编排器 Web API 通信的客户端打包。
- en: All possible orchestrator settings are organized like .NET configuration settings
    in a tree data structure. Therefore, analogously to .NET settings, they can be
    provided in JSON format or other equivalent formats. As a matter of fact, all
    orchestrators accept settings either in JSON or in another equivalent format called
    `.yaml`. Some orchestrators accept both formats; others might accept just one
    of them. The `.yaml` format is described in the next subsection.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可能的编排器设置都像 .NET 配置设置一样组织在树形数据结构中。因此，类似于 .NET 设置，它们可以以 JSON 格式或其他等效格式提供。实际上，所有编排器都接受
    JSON 或另一种称为 `.yaml` 的等效格式的设置。一些编排器接受这两种格式；其他可能只接受其中之一。`.yaml` 格式将在下一小节中描述。
- en: .yaml files
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: .yaml 文件
- en: '`.yaml` files, like JSON files, can be used to describe nested objects and
    collections in a human-readable way, but they do it with a different syntax. You
    have objects and lists, but object properties are not surrounded by `{}`, and
    lists are not surrounded by `[]`. Instead, nested objects are declared by simply
    indenting their content with spaces. The number of spaces can be freely chosen,
    but once they’ve been chosen, they must be used consistently.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与 JSON 文件一样，`.yaml` 文件可以用来以可读的方式描述嵌套对象和集合，但它们使用不同的语法。您有对象和列表，但对象属性不被 `{}` 包围，列表也不被
    `[]` 包围。相反，通过简单地使用空格缩进其内容来声明嵌套对象。空格的数量可以自由选择，但一旦选择，就必须始终一致地使用。
- en: 'List items can be distinguished from object properties by preceding them with
    a hyphen (-). Below, there is an example involving nested objects and collections:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 列表项可以通过在它们前面加上破折号 (-) 来与对象属性区分开来。下面是一个涉及嵌套对象和集合的示例：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In each line, all characters following a `#` character are considered comments.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一行中，所有跟随 `#` 字符的字符都被认为是注释。
- en: 'The previous `Person` object has a `Spouse` nested object and a nested collection
    of addresses. The same example in JSON would be:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的 `Person` 对象有一个嵌套的 `Spouse` 对象和一个嵌套的地址集合。在 JSON 中的相同示例将是：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As you can see, the `.yaml` syntax is more readable, since it avoids the overhead
    of parentheses.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`.yaml` 语法更易读，因为它避免了括号的冗余。
- en: '`.yaml` files can contain several sections, each defining a different object,
    that are separated by a line containing the `---` string. Comments are preceded
    by a # symbol, which must be repeated on each comment line.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`.yaml` 文件可以包含多个部分，每个部分定义不同的对象，它们通过包含 `---` 字符串的行进行分隔。注释由 # 符号开头，每个注释行都必须重复该符号。'
- en: Since spaces/tabs contribute to object semantics, YAML is space/tabs sensitive,
    so attention must be paid to add the right number of spaces.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 由于空格/制表符有助于对象语义，YAML 对空格/制表符敏感，因此必须注意添加正确数量的空格。
- en: Small collections or small objects can also be specified in-line with the usual
    `[]` and `{}` syntax, that is, after the colon in the same line of the property
    they are the value of.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 小集合或小对象也可以使用通常的 `[]` 和 `{}` 语法内联指定，即在属性值的同一行的冒号之后。
- en: 'With the basics of orchestrators and `.yaml` files, we are ready to learn about
    the most widespread orchestrator: **Kubernetes**. At the moment, it is also the
    most complete. So, once you’ve learned about it, learning about other orchestrators
    should be very easy.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了编排器和`.yaml`文件的基础知识后，我们就可以学习最广泛使用的编排器：**Kubernetes**。目前，它也是最完整的。因此，一旦你了解了它，学习其他编排器应该非常容易。
- en: Kubernetes basics
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes基础知识
- en: The Kubernetes orchestrator is distributed software that must be installed on
    all virtual servers of a network. Most of the Kubernetes software is installed
    on just some machines that are called **master nodes**, while all other machines
    run just interface software called **Kubelet** that connects with the software
    running on the master nodes and locally executes tasks decided on by the master
    nodes. All machines in a Kubernetes cluster are called **nodes**.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes编排器是分布式软件，必须在网络的每个虚拟服务器上安装。大多数Kubernetes软件仅安装在称为**主节点**的一些机器上，而所有其他机器仅运行称为**Kubelet**的接口软件，该软件与主节点上的软件连接，并在本地执行由主节点决定的任务。Kubernetes集群中的所有机器都称为**节点**。
- en: Actually, all nodes must also run a container runtime in order to be able to
    run containers. As we will see later on, all nodes also run software that handles
    virtual addressing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，所有节点还必须运行容器运行时，以便能够运行容器。正如我们稍后将会看到的，所有节点还运行处理虚拟地址的软件。
- en: Kubernetes configuration units are abstract objects with properties, subparts,
    and references to other objects. They are referred to as **Kubernetes resources**.
    We have resources that describe a single microservice replica and other resources
    that describe a set of replicas. Resources describe communication settings, disk
    storage, users, roles, and various kinds of security constraints.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes配置单元是具有属性、子部分和其他对象引用的抽象对象。它们被称为**Kubernetes资源**。我们有描述单个微服务副本的资源，以及其他描述一组副本的资源。资源描述通信设置、磁盘存储、用户、角色以及各种安全约束。
- en: 'Cluster nodes and all resources they host are managed by master nodes that
    communicate with human cluster administrators through an API server, as shown
    in the following diagram:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 集群节点以及它们所承载的所有资源都由主节点管理，主节点通过API服务器与人类集群管理员进行通信，如下所示：
- en: '![Figure 8.1: Kubernetes cluster](img/B31916_08_1.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1：Kubernetes集群](img/B31916_08_1.png)'
- en: 'Figure 8.1: Kubernetes cluster'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1：Kubernetes集群
- en: Kubectl is the client typically used to send commands and configuration data
    to the API server. The scheduler allocates resources to nodes according to the
    administrator constraints, while the controller manager groups several daemons
    that monitor the cluster’s actual state and try to move it toward the desired
    state declared through the API server. There are controllers for several Kubernetes
    resources, from Microservices replicas to communication facilities. In fact, each
    resource has some target objectives to be maintained while the application runs,
    and the controller verifies these objectives are actually achieved, possibly triggering
    corrective actions, such as moving some pods running too slowly onto less crowded
    nodes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Kubectl是通常用于向API服务器发送命令和配置数据的客户端。调度器根据管理员的约束将资源分配给节点，而控制器管理器将多个守护进程分组，这些守护进程监控集群的实际状态，并尝试将其移动到通过API服务器声明的期望状态。有几个控制器用于Kubernetes资源，从微服务副本到通信设施。实际上，每个资源在应用程序运行期间都有一些需要保持的目标目标，控制器会验证这些目标是否真正实现，可能触发纠正操作，例如将运行速度过慢的一些Pod移动到更少拥挤的节点上。
- en: The deployment unit, that is, the unit that can be deployed on a server, started,
    killed, and/or moved to another server, is not a single container, but a set of
    containers called a **Pod**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 部署单元，即可以部署在服务器上、启动、终止和/或移动到另一个服务器的单元，不是一个单独的容器，而是一组称为**Pod**的容器。
- en: A Pod is a set of containers that are constrained to run all together on the
    same server..
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Pod是一组被限制在同一个服务器上一起运行的容器。
- en: The concept of the Pod is fundamental since it enables very useful, strong cooperation
    patterns. For instance, we may attach another container to our main container
    whose unique purpose is to read the log files created by the main container and
    send them to a centralized log service.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Pod的概念是基本的，因为它能够实现非常有用且强大的协作模式。例如，我们可能将另一个容器附加到我们的主容器上，该容器的唯一目的是读取主容器创建的日志文件并将它们发送到集中的日志服务。
- en: The **Sidecar** pattern consists of enhancing a main container with a secondary
    container deployed on the same Pod and whose only purpose is to offer some services
    to the main container.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**侧边栏**模式由增强主容器并在同一Pod上部署的次要容器组成，其唯一目的是为主容器提供一些服务。'
- en: In general, we put several containers together inside the same Pod when we need
    them to communicate through their node file system, or when we need each container
    replica to be somehow associated with a specific replica of other containers.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们需要容器通过它们的节点文件系统进行通信，或者需要每个容器副本与特定副本的其他容器相关联时，我们会将多个容器放在一起同一个Pod中。
- en: In Kubernetes, communication between **Pods** is handled by resources called
    **Services** that are assigned virtual addresses by the Kubernetes infrastructure
    and that forward their communications to sets of pods that satisfy some constraints.
    In short, Services are Kubernetes’ way to assign constant virtual addresses to
    sets of **Pods**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，**Pod**之间的通信由称为**服务**的资源处理，这些服务由Kubernetes基础设施分配虚拟地址，并将它们的通信转发到满足某些约束的一组Pod。简而言之，服务是Kubernetes为Pod集合分配固定虚拟地址的方式。
- en: All Kubernetes resources may be assigned name-value pairs called **labels**
    that are used to reference them through a pattern-matching mechanism. Thus, for
    instance, all **Pods** that receive traffic from the same **Service** are selected
    by specifying labels that they must have in the **Service** definition.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 所有Kubernetes资源都可以分配名为**标签**的键值对，这些标签用于通过模式匹配机制引用它们。因此，例如，所有从同一**服务**接收流量的**Pod**都可以通过指定它们必须在**服务**定义中具有的标签来选择。
- en: Kubernetes clusters can be on-premises, that is, Kubernetes may be installed
    on any private network. But, more often, they are offered as cloud services. For
    instance, Azure offers **Azure Kubernetes Service (AKS)**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes集群可以是本地部署的，也就是说，Kubernetes可以安装在任何私有网络上。但更常见的是，它们作为云服务提供。例如，Azure提供**Azure
    Kubernetes Service (AKS)**。
- en: In the remainder of the book, we will use the **Minikube** Kubernetes simulator
    running on your development machine, since an actual AKS service might quickly
    exhaust all your Azure free credits. However, all operations in our examples can
    be replicated on an actual cluster, and whenever there are differences, we will
    also describe how to perform operations on AKS.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的剩余部分，我们将使用运行在您的开发机器上的**Minikube** Kubernetes模拟器，因为实际的AKS服务可能会迅速耗尽您的所有Azure免费额度。然而，我们示例中的所有操作都可以在实际集群上复制，并且当存在差异时，我们还将描述如何在AKS上执行操作。
- en: Let’s start by interacting with a Kubernetes cluster.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从与Kubernetes集群交互开始。
- en: 'Interacting with Kubernetes: Kubectl, Minikube, and AKS'
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与Kubernetes交互：kubectl，Minikube，和AKS
- en: Before interacting with a Kubernetes cluster with the Kubectl client, we must
    configure Kubectl and furnish it with both the cluster URL and the necessary credentials.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Kubectl客户端与Kubernetes集群交互之前，我们必须配置Kubectl并向其提供集群URL和必要的凭据。
- en: Once installed, Kubectl creates a different JSON configuration file for each
    computer user, which will contain configuration info for all Kubernetes clusters
    and their users. Kubectl has commands for inserting new Kubernetes cluster configurations
    and for making a cluster configuration the current one.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，kubectl将为每个计算机用户创建不同的JSON配置文件，其中将包含所有Kubernetes集群及其用户的配置信息。kubectl有命令用于插入新的Kubernetes集群配置，以及将集群配置设置为当前配置。
- en: 'Each pair made of a Kubernetes cluster API URL plus a user credential is called
    a **context**. Contexts, credentials, and cluster connections can be defined with
    various `kubectl config` subcommands. Below are the most useful ones:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由Kubernetes集群API URL和用户凭据组成的每一对称为**上下文**。上下文、凭据和集群连接可以使用各种`kubectl config`子命令定义。以下是最有用的几个：
- en: 'Viewing the overall configuration file:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看整体配置文件：
- en: '[PRE3]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Adding a new Kubernetes cluster:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加新的Kubernetes集群：
- en: '[PRE4]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'User credentials are based on client certificates. A valid certificate can
    be obtained by creating a certificate request and submitting it to the Kubernetes
    cluster, which will create an approved certificate. The detailed procedure will
    be shown in [*Chapter 10*](Chapter_10.xhtml#_idTextAnchor297)*, Security and Observability
    for Serverless and Microservices Applications*. Once you get an approved certificate,
    the user can be created with:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户凭据基于客户端证书。可以通过创建证书请求并将其提交到Kubernetes集群来获得有效的证书，Kubernetes集群将创建一个批准的证书。详细步骤将在[*第10章*](Chapter_10.xhtml#_idTextAnchor297)*，无服务器和微服务应用程序的安全性和可观察性*中展示。一旦获得批准的证书，就可以使用以下方式创建用户：
- en: '[PRE5]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Where `newusername.key` is the complete path to the private key you used to
    create the certificate request, and `newusername.crt` is the complete path of
    the approved certificate file.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 `newusername.key` 是你用于创建证书请求的私钥的完整路径，而 `newusername.crt` 是已批准的证书文件的完整路径。
- en: 'Once you have both a server and a user, you can create a context for the connection
    of that user to that server, with:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你有了服务器和用户，你可以使用以下命令为该用户到该服务器的连接创建一个上下文：
- en: '[PRE6]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Once all the contexts you need have been properly defined, you can switch to
    a given context with:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有需要的上下文都已被正确定义，你可以使用以下命令切换到指定的上下文：
- en: '[PRE7]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: After having set a new current context, all Kubectl commands will use both the
    cluster and the user defined in that context.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置了新的当前上下文后，所有 Kubectl 命令都将使用在该上下文中定义的集群和用户。
- en: 'If you are the cluster administrator, your user already exists in the system,
    so you don’t need to create it. However, you need to get the administrator user
    credentials and add them to your configuration file. Each cloud service has a
    login procedure that does this job. For instance, in the case of AKS, the procedure
    is:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经是集群管理员，你的用户已经在系统中存在，因此你不需要创建它。然而，你需要获取管理员用户凭据并将它们添加到配置文件中。每个云服务都有一个登录过程来完成这项工作。例如，在
    AKS 的情况下，过程如下：
- en: 'Log in to Azure with Azure CLI:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Azure CLI 登录到 Azure：
- en: '[PRE8]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The default browser should open, and you should be prompted for your Azure credentials.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认浏览器应该会打开，并提示你输入你的 Azure 凭据。
- en: 'If not already installed, install the package for interacting with AKS:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未安装，请安装用于与 AKS 交互的包：
- en: '[PRE9]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Ask to add your AKS credentials to your Kubectl configuration file:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求将你的 AKS 凭据添加到你的 Kubectl 配置文件中：
- en: '[PRE10]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If the command is successful, a new cluster, new user, and new context will
    be added to your Kubectl configuration, and the new context will be made the current
    one. Please run `kubectl config view` to see all configuration file modifications.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果命令成功，新的集群、新的用户和新的上下文将被添加到你的 Kubectl 配置中，并且新的上下文将成为当前上下文。请运行 `kubectl config
    view` 来查看所有配置文件修改。
- en: Minikube comes with a default user, a default cluster name, and a default context,
    which are all called `minikube`. When you start your Minikube cluster with `minikube
    start`, if not already defined, all the above entities will be added to your Kubectl
    configuration file. Moreover, the `minikube` context will be automatically made
    the current one, so no extra actions are needed after you start your cluster.
    Of course, you may define other users and other contexts.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube 默认包含一个用户、一个默认集群名称和一个默认上下文，它们都被称为 `minikube`。当你使用 `minikube start` 启动你的
    Minikube 集群时，如果尚未定义，上述所有实体都将添加到你的 Kubectl 配置文件中。此外，`minikube` 上下文将自动成为当前上下文，因此启动集群后无需额外操作。当然，你也可以定义其他用户和其他上下文。
- en: Minikube can be stopped with `minikube stop`, and paused with `minikube pause`.
    Both stopping and pausing do not delete the cluster data and configuration. Other
    useful commands will be shown later on while using Minikube in our examples.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用 `minikube stop` 停止 Minikube，使用 `minikube pause` 暂停。停止和暂停都不会删除集群数据和配置。其他有用的命令将在使用
    Minikube 的示例中稍后展示。
- en: 'Let’s try some Kubectl commands on Minikube (ensure Minikube has been started):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 Minikube 上尝试一些 Kubectl 命令（确保 Minikube 已经启动）：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It should show all virtual network Kubernetes nodes. As the default, Minikube
    creates a cluster with a single node called `minikube`, so you should see something
    like:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该显示所有虚拟网络 Kubernetes 节点。默认情况下，Minikube 创建一个名为 `minikube` 的单节点集群，因此你应该看到类似以下内容：
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Since we specified Docker as the virtualization tool, the whole cluster will
    be embedded in a Docker container, as you can verify by listing all running containers
    with `docker ps` (remember that all Docker commands must be issued in a Linux
    shell).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们指定了 Docker 作为虚拟化工具，整个集群都将嵌入到一个 Docker 容器中，你可以通过使用 `docker ps` 列出所有正在运行的容器来验证（记住，所有
    Docker 命令都必须在 Linux shell 中执行）。
- en: 'As the default, this unique node contains 2 CPUs and 4 gigabytes of RAM, but
    we can modify all these parameters, and we can also create clusters with several
    nodes by passing some options to `minikube start`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，这个独特的节点包含 2 个 CPU 和 4 GB 的 RAM，但我们可以修改所有这些参数，我们也可以通过传递一些选项给 `minikube
    start` 来创建具有多个节点的集群：
- en: '`--nodes <n>`: Specifies the number of nodes in the cluster. Please consider
    that nodes are virtual machines that will run simultaneously, so a large number
    of nodes can be set only on a powerful workstation with several cores and say
    32-64 gigabytes of RAM. The default is 1.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--nodes <n>`: 指定集群中的节点数量。请考虑节点是同时运行的虚拟机，因此只有具有多个核心和 32-64 GB RAM 的强大工作站才能设置大量节点。默认为
    1。'
- en: '`--cpus <n or no-limits>`: The number of CPUs allocated to Kubernetes, or `no-limits`,
    to let Minikube allocate as many CPUs as needed. The default is 2.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--cpus <n or no-limits>`: 分配给 Kubernetes 的 CPU 数量，或 `no-limits` 以让 Minikube
    分配所需的 CPU 数量。默认为 2。'
- en: '`--memory <string>`: The amount of RAM to be allocated to Kubernetes (format:
    <number>[<unit>], where unit = b, k, m, or g). Use “max” to use the maximum amount
    of memory. Use “no-limit” to not specify a limit.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--memory <string>`: 分配给 Kubernetes 的 RAM 量（格式：<number>[<unit>]，其中 unit = b,
    k, m 或 g）。使用“max”以使用最大内存量。使用“no-limit”以不指定限制。'
- en: '`--profile <string>`: The name of the Minikube virtual machine (defaults to
    `minikube`). Useful for having more than one Minikube virtual machine – for instance,
    one with one node and another with two nodes.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--profile <string>`: Minikube 虚拟机的名称（默认为 `minikube`）。对于拥有多个 Minikube 虚拟机很有用——例如，一个节点和一个有两个节点的另一个。'
- en: '`--disk-size <string>`: The disk size allocated to the Minikube VM (format:
    <number>[<unit>], where unit = b, k, m, or g). The default is “20000mb”.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--disk-size <string>`: 分配给 Minikube VM 的磁盘大小（格式：<number>[<unit>]，其中 unit =
    b, k, m 或 g）。默认为“20000mb”。'
- en: If you want to change one of the above settings after having created the Minikube
    container with your first `minikube start`, you need either to delete the previous
    container with `minikube delete` or create a new Minikube container with a custom
    name with the `--profile` option.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在创建 Minikube 容器后（使用第一个 `minikube start`）想要更改上述设置之一，您需要使用 `minikube delete`
    删除之前的容器，或者使用 `--profile` 选项创建一个具有自定义名称的新 Minikube 容器。
- en: 'After this short parenthesis, let’s return to Kubectl! Let’s type:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简短的括号之后，让我们回到 Kubectl！让我们输入：
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'It lists all Kubernetes resources. If you have not created any resources, the
    cluster should contain just a single resource of type ClusterIP, as shown below:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 它列出了所有 Kubernetes 资源。如果您尚未创建任何资源，则集群应仅包含一个类型为 ClusterIP 的单个资源，如下所示：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: It is part of the Kubernetes infrastructure.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 它是 Kubernetes 基础设施的一部分。
- en: In general, `kubectl get <resource type>` lists all resources of a given type.
    Thus, for instance, `kubectl get pods` lists all Pods, and `kubectl get services`
    lists all services.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，`kubectl get <resource type>` 列出给定类型的所有资源。例如，`kubectl get pods` 列出所有 Pod，`kubectl
    get services` 列出所有服务。
- en: 'If, instead, we need more detailed information on a given object, we may use
    `kubectl describe <object type> <object name>`. Thus, for instance, if we need
    more information on the Minikube single node called `minikube`, we may issue the
    command below:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要有关特定对象的更详细信息，我们可以使用 `kubectl describe <object type> <object name>`。例如，如果我们需要有关名为
    `minikube` 的 Minikube 单节点更多信息，我们可以执行以下命令：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Please try it!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请尝试一下！
- en: You will see other Kubectl commands when learning how to define Pods, Services,
    and other Kubernetes resources in other sections of this chapter. The next subsection
    explains how to create an Azure Kubernetes cluster, so if at the moment you don’t
    plan to use Azure Kubernetes, feel free to skip it. You can return to it when
    you need to create one.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习如何在本章的其他部分定义 Pod、服务和其他 Kubernetes 资源时，您将看到其他 Kubectl 命令。下一个小节解释了如何创建 Azure
    Kubernetes 集群，所以如果您目前不打算使用 Azure Kubernetes，请随意跳过。当您需要创建一个时，您可以返回。
- en: Creating an Azure Kubernetes cluster
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 Azure Kubernetes 集群
- en: 'To create an AKS cluster, do the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 AKS 集群，请执行以下操作：
- en: Type `AKS` into the Azure search box.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Azure 搜索框中输入 `AKS`。
- en: Select **Kubernetes services**.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **Kubernetes 服务**。
- en: Then click the **Create** button.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后点击 **创建** 按钮。
- en: Select **Kubernetes Cluster**.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择 **Kubernetes 集群**。
- en: 'After that, the following form will appear:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，将出现以下形式：
- en: '![Figure 8.2: AKS creation first form](img/B31916_08_2.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2：AKS 创建第一个表单](img/B31916_08_2.png)'
- en: 'Figure 8.2: AKS creation first form'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2：AKS 创建第一个表单
- en: 'Here, as usual, you can select one of your Azure subscriptions, an existing
    resource group, or you can create a new one. Let’s move on to the AKS-specific
    configuration:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，像往常一样，您可以选择您的 Azure 订阅、现有的资源组，或者您可以创建一个新的。让我们继续到 AKS 特定配置：
- en: '**Cluster preset configuration**: Here, you can choose among various preconfigured
    settings that are a good starting point for various situations. In the preceding
    screenshot, I have chosen **Dev/Test**, which is specific for development and
    learning, so it proposes the cheapest options. However, you can also select a
    standard production or an economic production initial setting.'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**集群预设配置**：在这里，您可以从各种预配置设置中选择，这些设置是各种情况的良好起点。在前面的屏幕截图中，我选择了**开发/测试**，这是专门针对开发和学习的，因此它提出了最经济的选项。然而，您也可以选择标准生产或经济生产初始设置。'
- en: '**Kubernetes cluster name**: Here, you must select a unique name for your cluster.'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Kubernetes集群名称**：在这里，您必须为您的集群选择一个唯一的名称。'
- en: For all other settings, you can choose the proposed defaults. In particular,
    the **Region** field should propose the most adequate region for you. **AKS pricing
    tier** should be set to **Free**, meaning you will pay just for the virtual machines
    that make up the cluster. However, you can also select paying options that include
    support and super-big clusters with up to 5,000 nodes. The **Availability zones**
    field enables geographic redundancy in up to 3 different geographic zones.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于所有其他设置，您可以选择建议的默认值。特别是，**区域**字段应建议最适合您的区域。**AKS定价层**应设置为**免费**，这意味着您只需为构成集群的虚拟机付费。然而，您也可以选择包括支持和超级大集群（最多5,000个节点）在内的付费选项。**可用区**字段可在最多3个不同的地理区域中启用地理冗余。
- en: 'If you selected **Dev/Test**, the cluster will include from 2 to 5 nodes with
    automatic scaling. That is, the number of starting nodes is 2, but it can automatically
    increase up to 5 if the workload increases. Let’s go to the **node pools** tab
    to customize both the node number and type:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择了**开发/测试**，则集群将包括2到5个节点，并具有自动扩展功能。也就是说，起始节点数为2，但如果工作负载增加，它可以自动增加到5。让我们转到**节点池**选项卡来自定义节点数量和类型：
- en: '![Figure 8.3: AKS node pool configuration](img/B31916_08_3.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3：AKS节点池配置](img/B31916_08_3.png)'
- en: 'Figure 8.3: AKS node pool configuration'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3：AKS节点池配置
- en: If you selected **Dev/Test**, there should be a unique node pool that will be
    used for both Kubernetes master nodes and standard nodes. Pay attention that the
    **Dev/Test** server type (D4ds-v5) has a high monthly price, so please use the
    price calculator ([https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/#pricing](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/#pricing))
    to verify the cost of a machine before choosing it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择了**开发/测试**，则应该有一个独特的节点池，它将用于Kubernetes主节点和标准节点。请注意，**开发/测试**服务器类型（D4ds-v5）的月费用很高，因此在选择之前，请使用价格计算器（[https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/#pricing](https://azure.microsoft.com/en-us/pricing/details/virtual-machines/linux/#pricing)）验证机器的成本。
- en: The standard production selection, instead, would create two node pools – one
    for master nodes and the other for standard nodes.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，标准生产选择将创建两个节点池——一个用于主节点，另一个用于标准节点。
- en: Anyway, you can change the node pools and edit each of them. In the case of
    the preceding screenshot, let’s click on **agentpool**. A new form will open.
    Here, you can change both the machine type and the maximum number of nodes. A
    good option for experimenting without wasting too much credit is choosing 3 nodes
    and an `A` family machine. When you have done either, click on update or on cancel
    to return to the previous form.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，您都可以更改节点池并编辑每个节点池。在前面屏幕截图中，让我们点击**agentpool**。将打开一个新的表单。在这里，您可以更改机器类型和最大节点数。在没有浪费太多信用的情况下进行实验的好选项是选择3个节点和一个`A`系列机器。当您完成这些操作之一后，请点击更新或取消以返回到上一个表单。
- en: 'Finally, you can associate Azure Container Registry with the cluster by going
    to the **Integrations** tab:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以通过转到**集成**选项卡将Azure容器注册表与集群关联：
- en: '![Figure 8.4: Connect your cluster to ACR](img/B31916_08_4.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图8.4：将您的集群连接到ACR](img/B31916_08_4.png)'
- en: 'Figure 8.4: Connect your cluster to ACR'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4：将您的集群连接到ACR
- en: 'If you already defined an Azure Container Registry for experimenting in the
    *A few more Docker commands and options* subsection of [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067)*,
    Setup and Theory: Docker and Onion Architecture*, select that registry; otherwise,
    you can create a new one in a new browser window and select it, or you can associate
    a registry to your cluster at a later time.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经在[*第3章*](Chapter_3.xhtml#_idTextAnchor067)*的*一些更多Docker命令和选项*子节中为实验定义了Azure容器注册表，请选择该注册表；否则，您可以在新浏览器窗口中创建一个新的注册表并选择它，或者您可以在稍后时间将注册表与您的集群关联。
- en: When you associate a registry to your cluster, you enable the cluster to access
    and download all its Docker images.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将注册表关联到你的集群时，你使集群能够访问和下载所有其 Docker 镜像。
- en: When you’ve finished, select **Review + Create**.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成时，选择 **Review + Create**。
- en: Once you’ve created your cluster, you can connect to it with the login procedure
    we explained earlier in this section.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你创建了你的集群，你可以使用本节之前解释的登录程序连接到它。
- en: Now that you have learned how to connect with both Minikube and AKS, let’s move
    on to experimenting with Kubernetes resources.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何连接到 Minikube 和 AKS，让我们继续实验 Kubernetes 资源。
- en: Configuring your application in Kubernetes
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中配置你的应用程序
- en: As already mentioned, the simplest Kubernetes resource is the Pod. We will never
    create a single Pod since we will always create several replicas of each microservice,
    but being able to configure a Pod is also fundamental for creating more complex
    resources, so let’s start creating a single Pod.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，最简单的 Kubernetes 资源是 Pod。我们不会创建单个 Pod，因为我们总是要为每个微服务创建多个副本，但能够配置 Pod 对于创建更复杂的资源也是基础性的，所以让我们开始创建一个单个
    Pod。
- en: 'A Pod can be defined through a `.yaml` file with the content below:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 可以通过以下内容的 `.yaml` 文件进行定义：
- en: '[PRE16]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: All Kubernetes configuration files start with the name of the API where the
    resources being configured are defined, and its version. In the case of Pods,
    we have just the version since they are defined in the **core API**. Then, `kind`
    defines the type of resource to be configured – in our case, a Pod.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 Kubernetes 配置文件都以配置的资源定义的 API 名称及其版本开头。对于 Pod 来说，我们只有版本，因为它们是在 **核心 API**
    中定义的。然后，`kind` 定义了要配置的资源类型 – 在我们的例子中，是一个 Pod。
- en: Like types in C#, Kubernetes resources are also organized in namespaces. Therefore,
    together with any resource name, we must also specify a namespace. If no namespace
    is specified, a namespace called `default` is assumed.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 与 C# 中的类型一样，Kubernetes 资源也是按命名空间组织的。因此，除了任何资源名称外，我们还必须指定一个命名空间。如果没有指定命名空间，则假定命名空间为
    `default`。
- en: Pay attention! While the intent of Kubernetes and C# namespaces is the same,
    there are substantial differences between them. Namely, C# namespaces are hierarchical,
    while Kubernetes namespaces are not. Moreover, namespaces are not applicable to
    all Kubernetes resources since there are cluster-wide resources that belong to
    no specific namespace.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！虽然 Kubernetes 和 C# 命名空间的目的相同，但它们之间存在重大差异。具体来说，C# 命名空间是分层的，而 Kubernetes 命名空间不是。此外，命名空间并不适用于所有
    Kubernetes 资源，因为有一些集群范围内的资源不属于任何特定的命名空间。
- en: 'If the namespace used in a resource definition doesn’t exist yet, it must be
    defined with the snippet below:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在资源定义中使用的命名空间尚不存在，则必须使用以下片段进行定义：
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Name and namespace are specified as sub-properties of `metadata`, together with
    optional l`abels`. Labels are free name-value pairs we can use to classify the
    object. Typically, they specify information such as the role of the resource in
    the application and the tier or module it belongs to.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 名称和命名空间作为 `metadata` 的子属性指定，以及可选的标签。标签是我们可以用来自分类对象的自由名称值对。通常，它们指定有关资源在应用程序中的作用以及它所属的层或模块的信息。
- en: As already mentioned in the previous section, other resources can use labels
    to select a set of resources.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在上一节中，其他资源可以使用标签来选择一组资源。
- en: 'The `spec` property specifies the actual content of the Pod, that is, its containers
    and its restart policy (`restartPolicy`). The restart policy specifies when to
    restart a Pod:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`spec` 属性指定了 Pod 的实际内容，即其容器及其重启策略 (`restartPolicy`)。重启策略指定何时重启 Pod：'
- en: '`restartPolicy: Always`: This is the default. The Pod is restarted whenever
    all containers terminate or a container terminates with a failure.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`restartPolicy: Always`：这是默认值。当所有容器终止或容器以失败状态终止时，Pod 将被重启。'
- en: '`restartPolicy: OnFailure`: The Pod is restarted when at least one container
    exits with a failure'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`restartPolicy: OnFailure`：当至少有一个容器以失败状态退出时，Pod 将被重启。'
- en: '`restartPolicy: Never`: The Pod is never restarted.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`restartPolicy: Never`：Pod 从不会被重启。'
- en: 'Containers are split into two lists: `containers` and `initContainers`. The
    containers in the `containers` list are started only after all containers in `initContainers`
    are **successful**, and each container in the `initContainers` list is started
    only after the previous container is **successful**. In turn, a container in the
    `initContainers` list is considered **successful** in the two circumstances:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 容器被分为两个列表：`containers` 和 `initContainers`。`containers` 列表中的容器仅在 `initContainers`
    列表中的所有容器都 **成功** 后启动，并且 `initContainers` 列表中的每个容器仅在之前的容器 **成功** 后启动。反过来，`initContainers`
    列表中的容器在以下两种情况下被认为是 **成功** 的：
- en: If a container configuration has the `restartPolicy` property set to `Always`,
    then the container is considered successful if it has been successfully started.
    This option is useful for implementing **sidecar** containers. This way, we ensure
    that **sidecars** are ready before the containers they enhance are started. Please
    refer to the Pod definition at the beginning of the *Kubernetes basics* section
    for an explanation of what a **sidecar** is.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果容器配置的 `restartPolicy` 属性设置为 `Always`，则容器被认为是成功的，如果它已成功启动。此选项对于实现 **sidecar**
    容器很有用。这样，我们确保在增强容器的容器启动之前，**sidecars** 已经就绪。请参阅 *Kubernetes基础知识* 部分开头的 Pod 定义，以了解
    **sidecar** 是什么。
- en: If a container configuration doesn’t have the `restartPolicy` property set to
    `Always`, then the container is considered successful if it is successfully terminated.
    This option is useful for performing some startup initialization – for instance,
    for waiting for a database or a message broker to be ready. In a similar situation,
    the container code is a loop that continuously tries a connection with the database/message
    broker, and terminates as soon as it succeeds.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果容器配置没有将 `restartPolicy` 属性设置为 `Always`，则容器被认为是成功的，如果它已成功终止。此选项对于执行一些启动初始化很有用——例如，等待数据库或消息代理就绪。在类似的情况下，容器代码是一个循环，持续尝试与数据库/消息代理建立连接，并在成功后终止。
- en: A failed `initContainers` doesn’t cause a whole Pod restart. Instead, it is
    retried with an exponential retry several times before causing a whole Pod failure.
    For this reason, they should be designed as idempotent since their actions might
    be executed more than once.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 失败的 `initContainers` 不会导致整个 Pod 重新启动。相反，它会在导致整个 Pod 失败之前进行指数重试几次。因此，它们应该设计为幂等的，因为它们的行为可能会执行多次。
- en: 'Each container in any of the two above lists is something like:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 上述两个列表中的每个容器都类似于：
- en: '[PRE18]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We specify both a name for the container and the URL of its image in a container
    registry, which accounts for point 4 of the minimal services any orchestrator
    should offer (see the beginning of the *Introduction to orchestrators and their
    configuration* section). These two properties are obligatory, while all other
    properties are optional. The `command` property, when provided, overwrites the
    `CMD` instruction of the image Docker file.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在容器注册库中指定容器的名称和其镜像的 URL，这符合任何编排器应提供的最小服务中的第 4 点（参见 *编排器和其配置简介* 部分的开头）。这两个属性是必需的，而所有其他属性都是可选的。当提供
    `command` 属性时，它将覆盖 Docker 文件中的 `CMD` 指令。
- en: 'Then, we also account for points 5, 6, and 7 of the minimal services any orchestrator
    should offer, that is, disk storage, environment variables, and communication
    ports. More specifically, we have:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们还考虑了任何编排器应提供的最小服务中的第 5、6 和 7 点，即磁盘存储、环境变量和通信端口。更具体地说，我们有：
- en: '`volumeMount` specifies how a virtual storage volume specified by `name` is
    mapped to the path specified by `mountPath` in the container file system. If the
    optional `subPath` is provided, just that `subpath` of the volume specified by
    `name` is mounted. Virtual storage volumes are described later on in this chapter
    (in the *Dynamic provisioning of permanent disk space* subsection), together with
    other `volumeMounts` properties.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`volumeMount` 指定由 `name` 指定的虚拟存储卷如何映射到容器文件系统中由 `mountPath` 指定的路径。如果提供了可选的 `subPath`，则仅挂载由
    `name` 指定的卷的该 `subpath`。虚拟存储卷将在本章后面的部分（在 *永久磁盘空间的动态分配* 子部分中）进行描述，以及其他 `volumeMounts`
    属性。'
- en: '`env` specifies all container’s environment variables as a list of `name-value`
    pairs.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`env` 指定所有容器的环境变量，以 `name-value` 对的形式列出。'
- en: '`ports` specifies the list of all ports exposed by the container we would like
    to use in our application. These ports may be mapped to other ports in the actual
    communication between Pods. However, the port mapping is specified in other resources
    called `services` that provide virtual Pod addresses and other communication-related
    options.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ports`指定了我们希望在应用程序中使用的容器暴露的所有端口的列表。这些端口可能映射到Pod之间实际通信中的其他端口。然而，端口映射是在其他资源中指定的，这些资源被称为`services`，它们提供虚拟Pod地址和其他通信相关选项。'
- en: Finally, the `resource`s section specifies both the minimal computational resources
    needed for starting the container (`requests`) and the maximum computational resources
    it can waste (`limits`).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`resource`s部分指定了启动容器所需的最低计算资源（`requests`）以及它可以浪费的最高计算资源（`limits`）。
- en: 'The constraints in the `requests` property are used to choose the virtual machine
    to place a Pod. `limits`, instead, are enforced by the operating system kernel
    as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`requests`属性中的约束用于选择放置Pod的虚拟机。相反，`limits`是由操作系统内核强制执行的，如下所示：'
- en: CPU limits are enforced with throttling. That is, containers exceeding the CPU
    limit are delayed, putting them in sleeping mode for enough time.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU限制通过节流来强制执行。也就是说，超过CPU限制的容器会被延迟，使它们进入睡眠模式足够长的时间。
- en: Memory limits are enforced by throwing an exception when they are exceeded.
    In turn, the exception causes the application of the Pod restart policy, which
    usually causes a Pod restart.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当内存限制被超过时，会抛出一个异常来强制执行内存限制。反过来，这个异常会导致Pod的重启策略被应用，这通常会导致Pod重启。
- en: With regard to units of measure, typical memory units of measure are `Ti` (terabytes),
    `Gi` (gigabytes), `Mi` (megabytes), and `Ki` (kilobytes). CPU time, instead, can
    be measured either in millicores (`mi`) or as a fractional number of cores (no
    unit of measure after the value).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 关于度量单位，典型的内存度量单位是`Ti`（千兆字节）、`Gi`（兆字节）、`Mi`（兆字节）和`Ki`（千字节）。而CPU时间，则可以以毫核（`mi`）或作为核心数的分数（值后没有单位）来衡量。
- en: Let’s try a Pod with a sidecar container, which shows both the practical usage
    of the described syntax and how a sidecar can help in building application-level
    monitoring. The main container will be a fake microservice based on the Alpine
    Linux distribution Docker image, which just puts log messages in a file located
    in a directory shared with the sidecar. In an actual application, the log would
    be organized in several files (for instance, one for each day), and old files
    would be periodically deleted. Moreover, the sidecar would read these files and
    send their content to a log API. Our didactical sidecar, instead, will just periodically
    read the last 10 rows of the file and will display them in its console.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一个带有侧边容器Pod的例子，这展示了描述的语法的实际用法以及侧边容器如何帮助构建应用级监控。主容器将是一个基于Alpine Linux发行版Docker镜像的虚构微服务，它只是将日志消息放入与侧边容器共享的目录中的文件。在实际应用中，日志会被组织在几个文件中（例如，每个文件对应一天），旧文件会定期删除。此外，侧边容器会读取这些文件并将它们的内容发送到日志API。我们的教学侧边容器，相反，只是定期读取文件的最后10行，并在其控制台中显示它们。
- en: 'The code is quite simple. First of all, we define a namespace that encloses
    our example:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相当简单。首先，我们定义一个命名空间来包围我们的示例：
- en: '[PRE19]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then, after a `---` row, we place the actual Pod definition:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在`---`行之后，我们放置实际的Pod定义：
- en: '[PRE20]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Both containers use a simple Alpine Linux distribution Docker image and confine
    the application-specific code in the `command`, which is a Linux script. This
    technique is used for adapting preexisting images or for very simple tasks such
    as the ones often performed by a sidecar. We also used the same technique for
    the main container because the main container does nothing and has a purely didactical
    purpose.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 两个容器都使用简单的Alpine Linux发行版的Docker镜像，并将应用程序特定的代码限制在`command`中，这是一个Linux脚本。这种技术用于适应现有的镜像或执行非常简单的任务，例如侧边容器经常执行的任务。我们也为主要的容器使用了同样的技术，因为主要的容器什么都不做，具有纯粹的教学目的。
- en: 'Accordingly, with the previously exposed syntax, the sidecar is defined in
    the `initContaines` list with `restartPolicy: Always`.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，使用之前暴露的语法，侧边容器在`initContainers`列表中定义为`restartPolicy: Always`。'
- en: The main container command executes an endless loop where it just writes the
    current date and time in the `/opt/logs.txt` file and then sleeps for one second.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 主容器命令执行一个无限循环，它只是在`/opt/logs.txt`文件中写入当前日期和时间，然后休眠一秒钟。
- en: The sidecar container command uses `sh -c` to execute a single shell command,
    the `tail` command with the `-f` option on the `/opt/logs.txt` file. This command
    shows the last 10 rows of the file in the container console and updates them whenever
    new rows are added, so that the console always contains the current last 10 rows
    of the file.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 边车容器命令使用 `sh -c` 来执行单个 shell 命令，即带有 `-f` 选项的 `tail` 命令，针对 `/opt/logs.txt` 文件。此命令显示容器控制台中文件的最后
    10 行，并在添加新行时更新它们，因此控制台始终包含文件的当前最后 10 行。
- en: 'The file processed by both containers is the same because both containers mount
    the same data volume in the same `/opt` directory on their filesystems with:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 两个容器处理的是相同的文件，因为两个容器都在它们的文件系统上的相同 `/opt` 目录中挂载了相同的数据卷：
- en: '[PRE21]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The data volume is defined in a `volumes` list that is a direct descendant
    of the `spec` property, as:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 数据卷是在 `volumes` 列表中定义的，它是 `spec` 属性的直接后代，如下所示：
- en: '[PRE22]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`emptyDir` defines and allocates a volume that is specific to the Pod where
    it is defined. This means that it can’t be accessed by any other Pod. The volume
    is implemented with the disk memory of the node that hosts the Pod. This means
    that if the Pod is deleted or moved to a different node, the volume is destroyed
    and its content is lost. `EmptyDir` is the preferred way to provide temporary
    disk storage that’s used somehow in the Pod computations. It has an optional `sizeLimit`
    property that specifies a maximum disk space the Pod can use. For instance, we
    can set `sizeLimit: 500Mi` to specify 500 mega of maximum disk space.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`emptyDir` 定义并分配了一个特定于其定义的 Pod 的卷。这意味着它不能被任何其他 Pod 访问。该卷使用托管 Pod 的节点的磁盘内存实现。这意味着如果
    Pod 被删除或移动到不同的节点，该卷将被销毁，其内容将丢失。`EmptyDir` 是提供用于 Pod 计算中某种方式使用的临时磁盘存储的首选方式。它有一个可选的
    `sizeLimit` 属性，用于指定 Pod 可以使用的最大磁盘空间。例如，我们可以设置 `sizeLimit: 500Mi` 以指定 500 兆的最大磁盘空间。'
- en: Since we have not specified any size limit, the `emptyDir` object has no properties,
    so we are forced to add the empty object value `{}` to get a correct `.yaml` syntax
    (we can’t have a colon followed by nothing).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有指定任何大小限制，`emptyDir` 对象没有属性，因此我们被迫添加空对象值 `{}` 以获得正确的 `.yaml` 语法（我们不能有冒号后跟空格）。
- en: Let’s create a folder for experimenting with `.yaml` files in Minikube, and
    let’s place the whole example code in a file called `SimplePOD.yaml` inside that
    folder. This file is also available in the `ch08` folder of the book’s GitHub
    repository.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 Minikube 中创建一个用于实验 `.yaml` 文件的文件夹，并将整个示例代码放在该文件夹中名为 `SimplePOD.yaml` 的文件中。此文件也位于书籍
    GitHub 存储库的 `ch08` 文件夹中。
- en: 'Now, right-click on the newly created folder and open a Windows console in
    that directory. After having verified that Minikube is started by issuing a `kubectl
    get all` command, we can apply all our definitions with the `kubectl apply` command:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，右键单击新创建的文件夹，在该目录中打开一个 Windows 控制台。在通过执行 `kubectl get all` 命令确认 Minikube 已启动后，我们可以使用
    `kubectl apply` 命令应用所有定义：
- en: '[PRE23]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, if we issue the `kubectl get pods` command, we don’t see a new Pod! This
    is right because that command just lists resources defined in the `default` namespace,
    while our Pod has been defined in a new namespace called `basic-examples`, so
    if we would like to operate on a resource in this namespace, we must add the `-n
    basic-examples` option to our commands:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们执行 `kubectl get pods` 命令，我们看不到新的 Pod！这是正确的，因为该命令仅列出 `default` 命名空间中定义的资源，而我们的
    Pod 已定义在名为 `basic-examples` 的新命名空间中，因此如果我们想操作该命名空间中的资源，我们必须在我们的命令中添加 `-n basic-examples`
    选项：
- en: '[PRE24]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In order to access our sidecar console, we can use the Kubectl `logs` command.
    In fact, all console output of all container Pods is automatically collected by
    Kubernetes and can be inspected with this command. The command needs the Pod name
    and its namespace if different from `default`. Moreover, if the Pod contains several
    containers, it also needs the name of the container we would like to inspect,
    which can be provided with the `-c` option. Summing up, our command is:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 为了访问我们的边车控制台，我们可以使用 Kubectl 的 `logs` 命令。实际上，所有容器 Pod 的控制台输出都会自动由 Kubernetes
    收集，并可以使用此命令进行检查。该命令需要 Pod 名称以及如果不同于 `default` 的命名空间。此外，如果 Pod 包含多个容器，还需要我们想要检查的容器的名称，这可以通过
    `-c` 选项提供。总结起来，我们的命令是：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The command above will show just the current console content and then it will
    exit. If we would like the content to update automatically as the console content
    changes, we must add the `-f` option:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将仅显示当前控制台内容，然后退出。如果我们希望内容自动更新，以匹配控制台内容的变化，我们必须添加 `-f` 选项：
- en: '[PRE26]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: This way, our window freezes on the command and automatically updates. The command
    can be exited with `ctrl-c`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们的窗口会冻结在命令上并自动更新。可以使用 `ctrl-c` 退出命令。
- en: 'We can also have a console into the `logshipper` container with the Kubectl
    `exec` command. It needs namespace, Pod, and container names, and after the `–`
    characters, the Linux command to execute in the container file system. If you
    need a console, the Linux command is `sh`, and if we would like to interact with
    that console, we need to also specify the `-it` options that stand for “interactive
    tty.” Summing up, we have:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 Kubectl 的 `exec` 命令进入 `logshipper` 容器的控制台。这需要指定命名空间、Pod 和容器名称，并在 `–`
    字符之后，指定在容器文件系统中要执行的 Linux 命令。如果您需要一个控制台，Linux 命令是 `sh`，如果我们想与该控制台交互，我们还需要指定 `-it`
    选项，代表“交互式 tty”。总结一下，我们有：
- en: '[PRE27]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Once in the container, we can move into the `/opt` directory with `cd /opt`,
    and verify if the `logs.txt` file is there, with `ls`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 进入容器后，我们可以使用 `cd /opt` 命令进入 `/opt` 目录，并使用 `ls` 命令验证 `logs.txt` 文件是否存在。
- en: Once finished, you can exit the container console by issuing the `exit` command.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您可以通过发出 `exit` 命令退出容器控制台。
- en: The `kubectl exec` command is very useful for debugging applications, especially
    when they are already in production or staging.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl exec` 命令对于调试应用程序非常有用，尤其是在它们已经处于生产或预发布阶段时。'
- en: 'When you have finished with all resources created by a `.yaml` file, you can
    delete all of them with `kubectl deleted <file name>.yaml`. Thus, in our case,
    we can destroy all our example entities with:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当您完成所有由 `.yaml` 文件创建的资源后，可以使用 `kubectl deleted <file name>.yaml` 删除所有这些资源。因此，在我们的例子中，我们可以销毁所有示例实体：
- en: '[PRE28]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`kubectl apply` can also be used for modifying previously created resources.
    It is enough to edit the `.yaml` file used to create the resources and then repeat
    the `apply` command on it.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl apply` 也可以用来修改之前创建的资源。只需编辑创建资源时使用的 `.yaml` 文件，然后重复对该文件执行 `apply` 命令即可。'
- en: We have seen how to create temporary disk space with `emptyDir`. Now let’s see
    the typical way of allocating permanent network disk space and sharing it between
    various Pods.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何使用 `emptyDir` 创建临时磁盘空间。现在让我们看看分配永久网络磁盘空间并在各种 Pods 之间共享的典型方法。
- en: Dynamic provisioning of permanent disk space
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 永久磁盘空间的动态分配
- en: Volume definitions similar to `emptyDir` are called in-tree definitions because
    the instruction that creates the volume is inserted directly into the Pod definition.
    There is no way to share an in-tree definition with other Pod definitions, so
    it is not easy to share in-tree volumes between different Pods.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 `emptyDir` 的卷定义称为树内定义，因为创建卷的指令直接插入到 Pod 定义中。无法将树内定义与其他 Pod 定义共享，因此在不同 Pods
    之间共享树内卷并不容易。
- en: 'Actually, disk space sharing can also be achieved with in-tree definitions
    by adequately configuring the device that provides the disk space. For instance,
    suppose we are using an NFS server connected to our Kubernetes cluster to furnish
    network disk space. We can connect a Pod with it with the instruction below:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，通过适当配置提供磁盘空间的设备，也可以使用树内定义来实现磁盘空间共享。例如，假设我们正在使用连接到我们的 Kubernetes 集群的 NFS
    服务器来提供网络磁盘空间。我们可以使用以下指令将 Pod 连接到它：
- en: '[PRE29]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Where `server` is a server name or an IP address, and path is the directory
    to share. In order to share the same disk space between PodS, it is enough that
    they specify the same server and path.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 `server` 是服务器名称或 IP 地址，path 是要共享的目录。为了在 Pods 之间共享相同的磁盘空间，它们只需指定相同的服务器和路径即可。
- en: 'However, this technique has two cons:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种技术有两个缺点：
- en: The share is not explicitly declared, but it is indirect, thus it undermines
    code maintainability and readability.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共享并未明确声明，但它是间接的，因此它损害了代码的可维护性和可读性。
- en: Kubernetes is not informed about the Pods that are using a share, so it can’t
    be instructed to release the share when it is not needed anymore.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 并不知道使用共享的 Pods，因此无法指示在不再需要时释放共享。
- en: 'Therefore, in-tree definitions are more adequate for temporary disk space that
    is not shared among Pods. Luckily, the problem is not the NFS protocol itself,
    but just the in-tree syntax. For this reason, Kubernetes also offers an out-of-tree
    syntax based on two separate objects: **Persistent Volume Claims** (**PVCs**),
    which represent disk space needs, and **Persistent Volumes** (**PVs**), which
    represent actual disk space.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于不共享Pod的临时磁盘空间，树内定义更为合适。幸运的是，问题不在于NFS协议本身，而只是树内语法。因此，Kubernetes还提供了一个基于两个独立对象的树外语法：**持久卷声明**（**PVC**），它代表磁盘空间需求，以及**持久卷**（**PV**），它代表实际的磁盘空间。
- en: 'The whole technique works this way:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 整个技术工作方式如下：
- en: We define the disk space specification in a PVC.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在PVC中定义磁盘空间规范。
- en: All Pods that need to share the same disk space reference the same PVC.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有需要共享相同磁盘空间的Pod都引用相同的PVC。
- en: Kubernetes, somehow, tries to satisfy each PVC with a compatible PV that is
    then mounted on all Pods sharing that PVC.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes，不知何故，试图为每个PVC提供一个兼容的PV，然后将其挂载在所有共享该PVC的Pod上。
- en: When all Pods that share the same PV are destroyed, we can instruct Kubernetes
    to keep the allocated disk space or delete it.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有共享相同PV的Pod都被销毁时，我们可以指示Kubernetes保留分配的磁盘空间或删除它。
- en: The way a PVC catches the needed disk and returns a PV depends on the driver
    used to serve the PVC. Drivers must be installed in the Kubernetes cluster, but
    all cloud providers furnish predefined drivers.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: PVC获取所需磁盘并返回PV的方式取决于为PVC提供服务的驱动程序。驱动程序必须安装在Kubernetes集群中，但所有云提供商都提供预定义的驱动程序。
- en: 'Driver names and related settings are organized in resources called **Storage
    Classes** (`kind: StorageClass`). Together with predefined drivers, all cloud
    providers also offer predefined storage classes based on those drivers. However,
    you can define new storage classes based on the same driver but with different
    settings.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '驱动程序名称和相关设置组织在称为**存储类**的资源中（`kind: StorageClass`）。与预定义的驱动程序一起，所有云提供商也提供基于这些驱动程序的预定义存储类。然而，您可以根据相同的驱动程序定义新的存储类，但具有不同的设置。'
- en: You can also install drivers and storage classes based on those drivers on on-premises
    Kubernetes clusters (there are a lot of open-source drivers). Minikube has addons
    that install various storage drivers and related storage classes, too.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在本地Kubernetes集群上安装基于这些驱动程序的驱动程序和存储类（有许多开源驱动程序）。Minikube也有安装各种存储驱动程序和相关存储类的插件。
- en: Drivers that simply match PVCs with PVs that are manually predefined by the
    user are called static. While drivers that dynamically create PV resources, taking
    the needed disk space from a common pool of available disk space, are called dynamic.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 仅将PVC与用户手动预定义的PV匹配的驱动程序称为静态。而动态创建PV资源，从可用的磁盘空间池中获取所需磁盘空间的驱动程序称为动态。
- en: 'In this section, we will focus just on dynamic storage allocation since it
    is the most relevant in actual microservices applications. You may find more details
    on storage classes and how to define them in the official Kubernetes documentation:
    [https://kubernetes.io/docs/concepts/storage/storage-classes/](https://kubernetes.io/docs/concepts/storage/storage-classes/).'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将仅关注动态存储分配，因为它在实际微服务应用中最为相关。您可以在官方Kubernetes文档中找到有关存储类及其定义的更多详细信息：[https://kubernetes.io/docs/concepts/storage/storage-classes/](https://kubernetes.io/docs/concepts/storage/storage-classes/)。
- en: 'The first step in creating a PVC is the verification of the available storage
    classes:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 创建PVC的第一步是验证可用的存储类：
- en: '[PRE30]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then the details of a specific class can be obtained with `kubectl describe`.
    In Minikube, we obtain:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以使用`kubectl describe`获取特定类的详细信息。在Minikube中，我们得到：
- en: '[PRE31]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The “default” after the class name informs us that the `standard` class is the
    default storage class, that is, the one used when no storage class is specified.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 类名后面的“默认”告诉我们`standard`类是默认存储类，即在未指定存储类时使用的类。
- en: 'When using dynamic provisioning, a PVC needs to specify just:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用动态预配时，PVC只需指定：
- en: The storage needed
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所需的存储
- en: The storage class
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储类
- en: 'The access modality: `ReadWriteOnce` (only a single node can read and write
    on the storage), `ReadOnlyMany` (several nodes can read), `ReadWriteMany` (several
    nodes can both read and write), `ReadWriteOncePod` (only a single Pod can read
    and write on the storage)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问模式：`ReadWriteOnce`（只有单个节点可以在存储上读写），`ReadOnlyMany`（多个节点可以读取），`ReadWriteMany`（多个节点可以读写），`ReadWriteOncePod`（只有单个Pod可以在存储上读写）
- en: In fact, all the information needed to get a PV is contained in the storage
    class. Since a PVC describes a Pod need and not a specific PV, the provisioned
    storage will provide at least the required access mode, but it can support more
    accesses, too.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，获取 PV 所需的所有信息都包含在存储类中。由于 PVC 描述的是 Pod 需求而不是特定的 PV，因此预配的存储将提供至少所需的访问模式，但也可能支持更多的访问。
- en: If the driver used by the storage class doesn’t support the required modality,
    the operation fails. Therefore, before using a storage class, you must verify
    the operations supported by its driver. `ReadOnlyMany` doesn’t make sense with
    dynamic provisioning, since allocated storage always comes clean, so there is
    nothing to read.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存储类使用的驱动程序不支持所需的模式，操作将失败。因此，在使用存储类之前，您必须验证其驱动程序支持的操作。`ReadOnlyMany` 与动态预配不搭配，因为分配的存储总是干净的，所以没有东西可以读取。
- en: In practice, drivers that support dynamic provisioning always support `ReadWriteOnce`,
    and some of them also support `ReadWriteMany`. Therefore, if you need a volume
    that is shared among several Pods, you must verify that the chosen driver supports
    `ReadWriteMany`; otherwise, all Pods that share the volume will be allocated on
    the same node to ensure that all of them can access the claimed `ReadWriteOnce`
    storage.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，支持动态预配的驱动程序总是支持 `ReadWriteOnce`，其中一些也支持 `ReadWriteMany`。因此，如果您需要一个在多个 Pod
    之间共享的卷，您必须验证所选驱动程序是否支持 `ReadWriteMany`；否则，所有共享该卷的 Pod 都将分配在同一个节点上，以确保它们都能访问所声明的
    `ReadWriteOnce` 存储空间。
- en: 'A PVC is defined as shown below:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: PVC 的定义如下：
- en: '[PRE32]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The needed storage is specified with the same syntax as the RAM required by
    a container. If the storage class is not provided, Kubernetes uses a storage class
    that has been marked as the default storage class, if any.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 需要的存储使用与容器所需的 RAM 相同的语法指定。如果没有提供存储类，Kubernetes 将使用标记为默认存储类的存储类（如果有的话）。
- en: 'Once you’ve defined a PVC, the volume property of the Pod needs to reference
    it:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了 PVC，Pod 的卷属性需要引用它：
- en: '[PRE33]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: However, the PVC and Pod must belong to the same namespace; otherwise, the operation
    fails.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，PVC 和 Pod 必须属于同一个命名空间；否则，操作将失败。
- en: Now that we have all the building blocks, we can move on to more complex resources
    built on top of these blocks. Single Pods are not useful since we always need
    several replicas of each microservice, but luckily, Kubernetes already has built-in
    resources for handling both undistinguishable replicas and indexed replicas useful
    for implementing sharding strategies.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了所有构建块，我们可以继续构建更复杂的资源，这些资源建立在这些块之上。单个 Pod 没有用，因为我们总是需要每个微服务的多个副本，但幸运的是，Kubernetes
    已经内置了处理不可区分副本和索引副本的资源，后者对于实现分片策略非常有用。
- en: ReplicaSets, Deployments, and their services
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReplicaSets、Deployments 及其服务
- en: '**ReplicaSets** are resources that automatically create N replicas of a Pod.
    However, they are rarely used because it is more convenient to use **Deployments**,
    which are built on top of ReplicaSets and automatically handle a smooth transition
    when the number of replicas or other parameters are modified.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '**ReplicaSets** 是一种资源，它会自动创建 Pod 的 N 个副本。然而，它们很少被使用，因为使用 **Deployments** 更方便，Deployments
    是建立在 ReplicaSets 之上的，并且可以自动处理副本数量或其他参数修改时的平滑过渡。'
- en: 'The definition of a Deployment is:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment 的定义如下：
- en: '[PRE34]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Deployments are not contained in the API core, so their API name (`apps`) must
    be specified. The metadata section is identical to that of a Pod. The `spec` section
    contains the desired number of replicas (`replicas`) and a selector that specifies
    a condition for a Pod to belong to the deployment: it must have all labels with
    the specified values.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Deployments 不包含在 API 核心中，因此必须指定它们的 API 名称（`apps`）。元数据部分与 Pod 的元数据部分相同。`spec`
    部分包含所需的副本数量（`replicas`）和一个选择器，该选择器指定了 Pod 属于部署的条件：它必须具有所有指定的标签值。
- en: '`template` specifies how to create a Pod for the Deployment. If the cluster
    already contains some Pods that satisfy the selector conditions, then the template
    is used to create just the Pods needed to reach the `replicas` target number.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '`template` 指定了为 Deployment 创建 Pod 的方式。如果集群已经包含一些满足选择器条件的 Pod，那么模板将用于创建达到 `replicas`
    目标数量所需的 Pod。'
- en: 'The template is a complete Pod definition whose syntax is identical to the
    one we use for specifying a single Pod. The only differences being:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 模板是一个完整的 Pod 定义，其语法与我们用于指定单个 Pod 的语法相同。唯一的区别是：
- en: The Pod definition is not preceded by any API specification
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod 定义没有先前的任何 API 规范
- en: The Pod metadata section doesn’t contain a Pod name, since we are providing
    a template for creating `replica` Pods. Pod names are automatically created by
    the Deployment.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod元数据部分不包含Pod名称，因为我们提供的是一个用于创建`replica` Pod的模板。Pod名称由Deployment自动创建。
- en: The Pod metadata section doesn’t contain a Pod namespace since Pods inherit
    the same namespace as the Deployment.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod元数据部分不包含Pod命名空间，因为Pod继承与Deployment相同的命名空间。
- en: 'Needless to say, the Pod template must specify labels that match the selector
    `conditions`. Below is a complete example:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 不言而喻，Pod模板必须指定与`selector`条件匹配的标签。下面是一个完整的示例：
- en: '[PRE35]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The Deployment creates two replicas of an **nginx** web server that share a
    common disk space. More specifically, they share the `/usr/share/nginx/html` path
    that is mapped to a common PVC. `/usr/share/nginx/html` is the folder where **nginx**
    looks for static web content, so if we place an `index.html` file there, it should
    be accessible by both web servers.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment创建了两个**nginx**网络服务器的副本，它们共享一个共同的磁盘空间。更具体地说，它们共享映射到共同PVC的`/usr/share/nginx/html`路径。`/usr/share/nginx/html`是**nginx**查找静态Web内容的文件夹，因此如果我们将其中的`index.html`文件放置在那里，它应该可以通过两个Web服务器访问。
- en: The code above implements two load-balanced web servers that serve the same
    content. Let’s place the Deployment in a `WebServers.yaml` file. We will use it
    in a short while, after having added the missing code, that is, the PVC definition
    and a Service that forwards traffic from outside of the Kubernetes cluster and
    load-balances it among the replicas.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码实现了两个负载均衡的Web服务器，它们提供相同的内容。让我们将Deployment放在一个`WebServers.yaml`文件中。我们将在添加了缺失的代码（即PVC定义和将流量从Kubernetes集群外部转发并负载均衡到副本的服务）之后不久使用它。
- en: 'Deployments can be connected to three kinds of services:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment可以连接到三种类型的服务：
- en: '**ClusterIP**, which forwards traffic from inside the network to the Deployment'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ClusterIP**，它将网络内部的流量转发到Deployment'
- en: '**LoadBalancer**, which forwards traffic from outside of the cluster to the
    Deployment'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LoadBalancer**，它将集群外部的流量转发到Deployment'
- en: '**NodePort,** which is not fundamental for application developers and will
    not be described'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NodePort**，对于应用程序开发者不是基本的，因此将不会进行描述'
- en: 'The definition of a **ClusterIP** is:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**ClusterIP**的定义是：'
- en: '[PRE36]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '`selector` defines the Pods that will receive the traffic from the service.
    The Pods must belong to the same namespace as the service. The `ports` list defines
    the mapping from external ports (`port`) to the ports inside the Pod containers
    (`targetPort`). Each map can also specify an optional name and an optional protocol.
    If no protocol is specified, all protocols will be forwarded to the Pods.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '`selector`定义了将接收服务流量的Pod。Pod必须属于与服务相同的命名空间。`ports`列表定义了从外部端口（`port`）到Pod容器内部端口（`targetPort`）的映射。每个映射还可以指定一个可选的名称和一个可选的协议。如果没有指定协议，所有协议都将转发到Pod。'
- en: A **ClusterIP** service is assigned the `<service name>.<namespace>.svc.cluster.local`
    domain name, but it can also be accessed with `<service name>.<namespace>` (or
    simply `<service name>` if the namespace is `default`).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 被分配了`<service name>.<namespace>.svc.cluster.local`域名的一个**ClusterIP**服务，但它也可以通过`<service
    name>.<namespace>`（如果命名空间是`default`，则可以简单地使用`<service name>`）访问。
- en: Summing up, all traffic sent to either `<service name>.<namespace>.svc.cluster.local`
    or to `<service name>.<namespace>` is forwarded to the Pods selected by the `selector`.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，所有发送到`<service name>.<namespace>.svc.cluster.local`或`<service name>.<namespace>`的流量都将转发到由`selector`选择的Pod。
- en: 'A **LoadBalance**r service is completely analogous, the only difference being
    the two sub-properties of `spec` below:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '**LoadBalance**服务与它完全类似，唯一的区别是下面`spec`的两个子属性：'
- en: '[PRE37]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If you specify an IP address, that IP address must be a static IP address you
    bought somehow; otherwise, in the case of cloud Kubernetes clusters, you can omit
    the `loadBalancerIP` property and a dynamic IP address is automatically assigned
    to the service by the infrastructure. In AKS, you must also specify the resource
    group where the IP address has been allocated in an annotation:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你指定了一个IP地址，那么这个IP地址必须是某种方式购买的静态IP地址；否则，在云Kubernetes集群的情况下，你可以省略`loadBalancerIP`属性，服务将由基础设施自动分配一个动态IP地址。在AKS中，你还必须在注释中指定IP地址已分配的资源组：
- en: '[PRE38]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Moreover, you must give the “Network Contributor” role on the resource group
    where you defined the static IP address to the managed identity associated to
    the AKS cluster (as a default, a managed identity is automatically assigned to
    any newly created AKS cluster). See the detailed procedure for performing this
    operation here: [https://learn.microsoft.com/en-us/azure/aks/static-ip](https://learn.microsoft.com/en-us/azure/aks/static-ip).'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您必须将“网络贡献者”角色分配给您定义静态 IP 地址的资源组，并将其分配给与 AKS 集群关联的管理身份（默认情况下，任何新创建的 AKS 集群都会自动分配一个管理身份）。有关执行此操作的详细步骤，请参阅此处：[https://learn.microsoft.com/en-us/azure/aks/static-ip](https://learn.microsoft.com/en-us/azure/aks/static-ip)。
- en: 'You can also specify an annotation with a label:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用标签指定注释：
- en: '[PRE39]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: In which case, Azure will automatically associate the `<label>.<location>.cloudapp.azure.com`
    domain name to the LoadBalancer.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Azure 将自动将 `<label>.<location>.cloudapp.azure.com` 域名与 LoadBalancer 关联。
- en: If you want to publish the service on a custom domain name, you need to buy
    a domain name, and then you need to create an Azure DNS zone with appropriate
    DNS records. However, in this case, it is better to use an Ingress instead of
    a simple LoadBalancer (see the *Ingresses* subsection).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在一个自定义域名上发布服务，您需要购买一个域名，然后您需要创建一个带有适当 DNS 记录的 Azure DNS 区域。然而，在这种情况下，使用
    Ingress 而不是简单的 LoadBalancer 会更好（见 *Ingresses* 子节）。
- en: 'The loadBalancerIP property has been declared obsolete and will be removed
    in future Kubernetes versions. It should be replaced by a platform-dependent annotation.
    In the case of AKS, the annotation is: `service.beta.kubernetes.io/azure-pip-name:
    <your static IP address>`'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '`loadBalancerIP` 属性已被弃用，将在未来的 Kubernetes 版本中删除。它应该由平台相关的注释替换。在 AKS 的情况下，注释是：`service.beta.kubernetes.io/azure-pip-name:
    <your static IP address>`'
- en: 'Let’s go back to our nginx example and let’s create a LoadBalancer Service
    to expose our load-balanced web servers on the internet:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的 nginx 示例，并创建一个 LoadBalancer 服务来在互联网上公开我们的负载均衡的 Web 服务器：
- en: '[PRE40]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We don’t specify an IP address since we are going to test the example in Minikube,
    a simulator that uses a particular procedure to expose LoadBalancer Services.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有指定 IP 地址，因为我们将在 Minikube 中测试此示例，Minikube 是一个模拟器，它使用特定的程序来公开 LoadBalancer
    服务。
- en: Let’s place the Service definition in a file named `WebServersService.yaml`.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将服务定义放置在名为 `WebServersService.yaml` 的文件中。
- en: 'In a `WebServersPVC.yaml` file, let’s also place the missing PVC:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `WebServersPVC.yaml` 文件中，我们也要放置缺失的 PVC：
- en: '[PRE41]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: We have not specified a storage class because we will use the default one.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有指定存储类，因为我们将使用默认的存储类。
- en: 'Let’s also create a `BasicExamples.yaml` file for defining the `basic-examples`
    namespace:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再创建一个 `BasicExamples.yaml` 文件来定义 `basic-examples` 命名空间：
- en: '[PRE42]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Now let’s copy the `index.html` file contained in the `ch08` folder of the book’s
    GitHub repository, or any other self-contained HTML page with no external references
    to other images/content, in the same folder containing all the above `.yaml` files.
    We will use that page as experimental content to be shown by the web servers.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们复制书籍 GitHub 存储库中 `ch08` 文件夹中包含的 `index.html` 文件，或者任何其他在同一文件夹中包含所有上述 `.yaml`
    文件的独立 HTML 页面，没有对其他图像/内容的引用。我们将使用该页面作为实验内容，由 Web 服务器显示。
- en: 'Let’s start our experiment:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始我们的实验：
- en: Open a console on the folder containing all `.yaml` files (right-click on the
    folder and select the console option).
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在包含所有 `.yaml` 文件的文件夹上打开控制台（右键单击文件夹并选择控制台选项）。
- en: Ensure Minikube is running, and if not, start it with `minikube start`.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保 Minikube 正在运行，如果不是，请使用 `minikube start` 启动它。
- en: Deploy all files in the right sequence, that is, ensuring that all resources
    referenced in a file have already been created.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按正确的顺序部署所有文件，即确保文件中引用的所有资源都已创建。
- en: '[PRE43]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now we need to copy the `index.html` files in the `/usr/share/nginx/html` folder
    of either of the two created Pods. It will also be seen by the other Pod, since
    they share the same disk storage. For this operation, we need a Pod name. Let’s
    get it with:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要复制两个创建的 Pod 中的任意一个的 `/usr/share/nginx/html` 文件夹中的 `index.html` 文件。由于它们共享相同的磁盘存储，它也将被另一个
    Pod 所见。为此操作，我们需要一个 Pod 名称。让我们用以下命令获取它：
- en: '[PRE44]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'A file can be copied in a Kubernetes Pod with the `kubectl cp` command:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用 `kubectl cp` 命令在 Kubernetes Pod 中复制文件：
- en: '[PRE45]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In our case, the `cp` command becomes:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的情况下，`cp` 命令变为：
- en: '[PRE46]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In Minikube, you can access the cluster through a LoadBalancer service by creating
    a tunnel. Do the following:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Minikube 中，您可以通过创建隧道来通过 LoadBalancer 服务访问集群。请执行以下操作：
- en: Open a new console window
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的控制台窗口
- en: In this new window, issue the `minikube tunnel` command
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个新窗口中，执行`minikube tunnel`命令
- en: The window will freeze on the command. As long as the window remains open, the
    `LoadBalancer` is accessible through `localhost`. Anyway, you can verify the external
    IP assigned to the LoadBalancer by issuing `kubectl get services -n Basic-Examples`
    in the previous window.
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 窗口会在命令执行时冻结。只要窗口保持打开状态，`LoadBalancer`就可通过`localhost`访问。无论如何，你可以在上一个窗口中通过执行`kubectl
    get services -n Basic-Examples`来验证分配给`LoadBalancer`的外部IP。
- en: Open your favourite browser and go to `http://localhost`. You should see the
    content of the `index.html` page.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开你喜欢的浏览器并访问`http://localhost`。你应该能看到`index.html`页面的内容。
- en: 'Once you’ve finished experimenting, let’s destroy all resources in reverse
    order (the opposite order in which you created them):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成实验，让我们按相反的顺序（与创建它们的顺序相反）销毁所有资源：
- en: '[PRE47]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: You can keep the namespace definition since we will use it in the next example.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以保留命名空间定义，因为我们将在下一个示例中使用它。
- en: All Deployment replicas are identical; they have no identity, so there is no
    way to refer to a specific replica from your code. If a replica goes down, for
    instance, because of a node crash, the system might have a small performance issue,
    but will continue working properly since replicas are just a way to improve performance,
    so no replica is indispensable.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的Deployment副本都是相同的；它们没有身份，因此无法从你的代码中引用特定的副本。例如，如果一个副本因为节点崩溃而宕机，系统可能会出现轻微的性能问题，但由于副本只是提高性能的一种方式，所以没有副本是不可或缺的。
- en: It is worth pointing out that as soon as Kubernetes detects a node fault, it
    recreates all Pods hosted on that node elsewhere. However, this operation might
    take time since the fault might not be detected as soon as it takes place. In
    the meantime, applications might have malfunctions if a Pod hosted by the faulty
    node is indispensable, which is why Deployments must be preferred whenever possible.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，一旦Kubernetes检测到节点故障，它就会在其他地方重新创建该节点上托管的所有Pod。然而，由于故障可能不会立即被检测到，此操作可能需要一些时间。在此期间，如果由故障节点托管的Pod是不可或缺的，应用程序可能会出现故障，这就是为什么在可能的情况下应优先选择Deployments。
- en: Unfortunately, there are situations where identical copies can’t achieve the
    needed parallelism, but we need non-identical sharded copies. If you don’t remember
    what sharding is and why it is necessary in some situations, please refer to the
    *Ensuring that messages are processed in proper order* section of [*Chapter 7*](Chapter_7.xhtml#_idTextAnchor151)*,
    Microservices in Practice*. **StatefulSets** furnish the kind of replication needed
    for sharding.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在某些情况下，相同的副本无法达到所需的并行度，但我们需要非相同的分片副本。如果你不记得什么是分片以及为什么在某些情况下它是必要的，请参阅[*第7章*](Chapter_7.xhtml#_idTextAnchor151)*，实践中的微服务*中的*确保消息按正确顺序处理*部分。**StatefulSets**提供了进行分片所需的复制类型。
- en: StatefulSets and Headless Services
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有状态集和Headless服务
- en: 'All replicas of a `StatefulSet` are assigned indexes that go from 0 to N-1,
    where N is the number of replicas. Their Pod names are predictable, too, since
    they are built as `<StatefulSet name>-<replica index>`. Their domain names also
    contain the Pod names, so that each Pod has its own domain name: `<POD name>.<service
    name>.<namespace>.svc.cluster.local`, or simply `<POD name>.<service name>.<namespace>`.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 一个`StatefulSet`的所有副本都被分配了从0到N-1的索引，其中N是副本的数量。它们的Pod名称也是可预测的，因为它们被构建为`<StatefulSet
    name>-<replica index>`。它们的域名也包含Pod名称，这样每个Pod都有自己的域名：`<POD name>.<service name>.<namespace>.svc.cluster.local`，或者简单地`<POD
    name>.<service name>.<namespace>`。
- en: When a StatefulSet is created, all replicas are created in order of increasing
    index; while when it is destroyed, all replicas are destroyed in decreasing index
    order. The same happens when the number of replicas is changed.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建一个有状态集（StatefulSet）时，所有副本会按照递增的索引顺序创建；而当它被销毁时，所有副本会按照递减的索引顺序销毁。当副本数量发生变化时，情况也是如此。
- en: Each `StatefulSet` must have an associated Service that must be declared in
    the `serviceName` property of the `StatefulSet`. The definition of a `StatefulSet`
    is almost identical to that of a `Deployment`; the only difference being that
    `kind` is `StatefulSet` and there is the `serviceName:”<service name>“` property
    immediately under the `spec` section.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`StatefulSet`都必须有一个关联的服务，该服务必须在`StatefulSet`的`serviceName`属性中声明。`StatefulSet`的定义几乎与`Deployment`相同；唯一的区别是`kind`是`StatefulSet`，并且在`spec`部分下面立即有`serviceName:”<service
    name>“`属性。
- en: 'The service associated to `StatefulSet` must be a so-called `Headless` service,
    which is defined as a ClusterIP service but with a `ClusterIP: None` property
    under `spec`:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '与 `StatefulSet` 关联的服务必须是一个所谓的 `Headless` 服务，它被定义为 ClusterIP 服务，但在 `spec` 下具有
    `ClusterIP: None` 属性：'
- en: '[PRE48]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'It is also worth pointing out that, typically, each replica has its own private
    storage, so, usually, StatefulSet definitions do not have a reference to a PVC,
    but instead use a PVC template that attaches a different PVC to each created Pod:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，通常每个副本都有自己的私有存储，因此通常 StatefulSet 定义不引用 PVC，而是使用 PVC 模板，将不同的 PVC 绑定到每个创建的
    Pod：
- en: '[PRE49]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Where both the `metadata` and `spec` properties are identical to those of a
    PVC resource.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 `metadata` 和 `spec` 属性与 PVC 资源中的属性相同。
- en: 'Below is an example of a StatefulSet with its associated Headless Service.
    The Pod name is passed to each container through an environment variable, so that
    the code is aware of its index and its possible role in a sharding algorithm:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个带有其关联的无头服务的 StatefulSet 的示例。Pod 名称通过环境变量传递给每个容器，这样代码就能知道其索引及其在分片算法中可能的角色：
- en: '[PRE50]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Each Pod contains just the Alpine Linux distribution, and the actual code is
    provided in `command`, which just prints the `MY_POD_NAME` environment variable
    in an endless loop. In turn, the `MY_POD_NAME` environment variable is set with:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Pod 只包含 Alpine Linux 发行版，实际的代码在 `command` 中提供，它只是无限循环地打印 `MY_POD_NAME` 环境变量。反过来，`MY_POD_NAME`
    环境变量设置为：
- en: '[PRE51]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This code takes the value from the `metadata.name` field of the Pod. In fact,
    if we did not specify a name in the Pod template metadata section, a name would
    automatically be created by the StatefulSet and added to the resource internal
    representation of the Pod. The Kubernetes component that makes the Pod fields
    available to environment variables definition is called the **downward API**.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码从 Pod 的 `metadata.name` 字段获取值。实际上，如果我们没有在 Pod 模板元数据部分指定名称，StatefulSet 会自动创建一个名称并将其添加到
    Pod 资源内部表示中。使 Pod 字段可用于环境变量定义的 Kubernetes 组件称为 **向下 API**。
- en: The above StatefulSet does nothing useful but just shows how to pass the Pod
    name to your containers.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的 StatefulSet 没有做任何有用的事情，只是展示了如何将 Pod 名称传递给容器。
- en: Put the above code in a `StateFulSetExample.yaml` file and apply it!
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 将上述代码放入 `StateFulSetExample.yaml` 文件并应用它！
- en: 'If you issue the `kubectl get pods -n basic-examples` command, you can verify
    that all 3 replicas were created with the right names based on the StatefulSet
    name and on your indexes. Now let’s verify that `podname-1` correctly received
    its name, by displaying its log:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发出 `kubectl get pods -n basic-examples` 命令，你可以验证所有 3 个副本都是根据 StatefulSet
    名称和你的索引创建的正确的名称。现在让我们通过显示其日志来验证 `podname-1` 是否正确接收到了其名称：
- en: '[PRE52]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: You should see several lines with the right Pod name. Great!
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会看到几行带有正确 Pod 名称的行。太棒了！
- en: 'Now let’s verify that our code created 3 different PVCs:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们验证我们的代码创建了 3 个不同的 PVC：
- en: '[PRE53]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: You should see three different claims.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会看到三个不同的声明。
- en: 'When you finish experimenting with the example, you can delete everything with
    `kubectl delete -f StateFulSetExample.yaml`. Unluckily, deleting everything does
    not also delete the PVC created by templates, as you can verify at this point.
    The simplest way to delete them is by deleting the `basic-examples` namespace
    with:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成对示例的实验后，你可以使用 `kubectl delete -f StateFulSetExample.yaml` 删除所有内容。不幸的是，删除所有内容并不会删除由模板创建的
    PVC，正如你现在可以验证的那样。删除它们的最简单方法是删除 `basic-examples` 命名空间：
- en: '[PRE54]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Then, if you want, you can recreate it with:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果你想，你可以通过以下方式重新创建它：
- en: '[PRE55]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Statefulsets are used to deploy RabbitMQ clusters and database clusters in Kubernetes.
    If a master node is needed, then one with a specific index (usually 0) elects
    itself as a master. Each replica uses its own disk storage so that both data sharding
    and data replication strategies can be enforced. It’s likely that you won’t need
    to do this yourself, since the code for deploying clusters of the most famous
    message-broker and database clusters is already available on the web.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: Statefulsets 用于在 Kubernetes 中部署 RabbitMQ 集群和数据库集群。如果需要主节点，则具有特定索引（通常是 0）的节点会选举自己为主节点。每个副本使用自己的磁盘存储，以便可以强制执行数据分片和数据复制策略。你可能不需要自己这样做，因为最著名的消息代理和数据库集群的集群部署代码已经在网上可用。
- en: Having learned how to create and maintain several replicas of a microservice,
    we have to learn how to set and update the number of replicas, that is, how to
    scale our microservices.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习了如何创建和维护微服务的多个副本之后，我们必须学习如何设置和更新副本数量，即如何扩展我们的微服务。
- en: Scaling and autoscaling
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展和自动扩展
- en: Scaling is fundamental for application performance tuning. We must distinguish
    between scaling the number of replicas of each microservice and scaling the number
    of nodes of the whole Kubernetes cluster.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展对于应用程序性能调整是基本的。我们必须区分扩展每个微服务的副本数量和扩展整个Kubernetes集群的节点数量。
- en: The number of nodes is usually tuned according to the average CPU busy percentage.
    For instance, one might start with a 50% percentage when the initial application
    traffic is low. Then, as the application traffic increases, we maintain the same
    number of nodes till we are able to keep a good response time, possibly tuning
    the number of microservice replicas. Suppose that performance starts to decrease
    when the CPU busy percentage is 80%. Then, we can target, say, a 75% CPU busy
    time.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 节点数量通常根据平均CPU繁忙百分比进行调整。例如，当初始应用程序流量较低时，可能从50%的百分比开始。然后，随着应用程序流量的增加，我们保持相同的节点数量，直到我们能够保持良好的响应时间，可能调整微服务副本的数量。假设当CPU繁忙百分比为80%时性能开始下降。然后，我们可以将目标设置为75%的CPU繁忙时间。
- en: Automatic cluster scaling is possible just with cloud clusters, and each cloud
    provider offers some kind of autoscaling.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用云集群即可实现自动集群扩展，每个云服务提供商都提供某种形式的自动扩展。
- en: With regard to AKS, in the *Creating an Azure Kubernetes cluster* section, we
    saw that we can specify both a minimum and a maximum number of nodes, and AKS
    tries to optimize performance for us. You can also fine-tune how AKS decides the
    number of nodes. More details on this customization are given in the references
    in the *Further reading* section.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 关于AKS，在*创建Azure Kubernetes集群*部分，我们看到了我们可以指定最小和最大节点数，并且AKS试图为我们优化性能。你还可以微调AKS如何决定节点数量。更多关于这种定制的详细信息可以在*进一步阅读*部分的参考中找到。
- en: There are also automatic auto-scalers that integrate with various cloud providers
    ([https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/](https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/)).
    As a default, auto-scalers increase the number of nodes when Kubernetes is not
    able to satisfy the resources required by a Pod, which is the sum of the `resource->request`
    fields of all Pod containers.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有与各种云提供商集成的自动自动扩展器([https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/](https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/))。默认情况下，自动扩展器在Kubernetes无法满足Pod所需资源时增加节点数量，这是所有Pod容器`resource->request`字段的总和。
- en: 'Scaling microservice replicas, instead, is a more difficult task. You may calculate
    it by measuring the average replica response time and then calculating:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，扩展微服务副本是一个更困难的任务。你可以通过测量平均副本响应时间然后计算：
- en: '[PRE56]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Where the target throughput should be a raw estimate calculated with simple
    calculations. For frontend microservices, it is just the number of requests you
    expect your application will receive for each API call. For Worker services, it
    can depend on the number of requests expected on several frontend services, but
    there is no standard way to compute it. Instead, you need to reason about how
    the application works and how the requests directed to that Worker microservice
    are created.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 目标吞吐量应该是一个通过简单计算得出的粗略估计。对于前端微服务，它只是你期望应用程序为每个API调用接收的请求数量。对于Worker服务，它可能取决于预期在几个前端服务上的请求数量，但没有标准的方式来计算它。相反，你需要推理应用程序的工作方式以及指向该Worker微服务的请求是如何创建的。
- en: 'Then, you should monitor the system performance, looking for bottlenecks, according
    to the following procedure:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你应该根据以下程序监控系统性能，寻找瓶颈：
- en: Look for a microservice that is a bottleneck
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 寻找瓶颈微服务
- en: Increase its number of replicas till it stops being a bottleneck
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其副本数量增加到它不再成为瓶颈
- en: Repeat point 1 till there are no evident bottlenecks
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复第1点，直到没有明显的瓶颈
- en: Then optimize the number of cluster nodes to achieve good performance
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后优化集群节点数量以实现良好的性能
- en: Store the average CPU utilization memory occupation of all Deployments and StatefulSets,
    and the average number of requests reaching the whole application. You may use
    this data for setting auto-scalers.
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储所有Deployments和StatefulSets的平均CPU利用率内存占用，以及整个应用程序接收到的平均请求数量。你可以使用这些数据来设置自动扩展器。
- en: While StatefulSets are difficult to scale automatically, Deployments can be
    automatically scaled without causing problems. Therefore, you may use a Kubernetes
    Pod auto-scaler to scale them automatically.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然StatefulSets难以自动扩展，但Deployments可以自动扩展而不会引起问题。因此，您可以使用Kubernetes Pod自动扩展器自动扩展它们。
- en: Pod auto-scaler targets are either average per Pod resource consumption or metrics
    somehow connected with the traffic. In the first case, the auto-scaler chooses
    the number of replicas that makes the resource consumption closest to a specified
    target. In the second case, the number of replicas is set to the actual value
    of the traffic metric divided by the target value of the metric, that is, the
    traffic target is interpreted as the target traffic sustained by each Deployment
    Pod.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: Pod自动扩展目标可以是每个Pod的平均资源消耗或与流量相关的度量指标。在第一种情况下，自动扩展器选择使资源消耗最接近指定目标的副本数量。在第二种情况下，副本数量设置为流量度量指标的实际值除以度量指标的目标值，即流量目标被解释为每个Deployment
    Pod持续的目标流量。
- en: If several target types are specified, the maximum number of replicas proposed
    by each of them is taken.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 如果指定了多个目标类型，则取每个目标类型提出的最大副本数量。
- en: 'An auto-scaler can be defined as follows:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展器可以定义如下：
- en: '[PRE57]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: We specify the type of resource to control and the API where it is defined,
    and its name. Both the controlled resource and the auto-scaler must be defined
    in the same namespace. You can set `scaleTargetRef->kind` also to `StatefulSet`,
    but you need to verify that the change in the number of replicas doesn’t break
    your sharding algorithm, both in the long run and during transitions between different
    numbers of replicas.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定要控制的资源类型及其定义的API，以及其名称。受控资源和自动扩展器必须在同一命名空间中定义。您还可以将`scaleTargetRef->kind`设置为`StatefulSet`，但您需要验证副本数量的变化不会破坏您的分片算法，无论是长期还是在不同副本数量之间的转换过程中。
- en: Then, we specify the maximum and minimum number of replicas. If the computed
    number of replicas exceeds this interval, it is cut to either `minReplicas` or
    `maxReplicas`.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们指定副本的最大和最小数量。如果计算出的副本数量超出此范围，则将其裁剪为`minReplicas`或`maxReplicas`。
- en: 'Finally, we have the list of criteria, where each criterion may refer to three
    types of **metrics**: `resource`, `pod`, or `object`. We will describe each of
    them in a separate subsection.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有标准列表，其中每个标准可能涉及三种类型的**度量指标**：`resource`、`pod`或`object`。我们将在单独的小节中描述每个标准。
- en: Resource metrics
  id: totrans-363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 资源度量指标
- en: 'Resource metrics are based on the average memory and CPU resources wasted by
    each Pod. The target consumption may be an absolute value such as 100Mb, or 20mi
    (millicores), in which case the number of replicas is computed as `<actual average
    consumption>/<target consumption>`. Resource metrics based on absolute values
    are declared as:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 资源度量指标基于每个Pod浪费的平均内存和CPU资源。目标消耗可能是一个绝对值，例如100Mb或20mi（毫核），在这种情况下，副本数量的计算方式为`<实际平均消耗>/<目标消耗>`。基于绝对值的资源度量指标声明如下：
- en: '[PRE58]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The target can also be specified as a percentage of the total Pod `resource->request`
    declared (sum of all Pod containers). In this case, Kubernetes first computes:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 目标也可以指定为总Pod `resource->request`声明的百分比（所有Pod容器的总和）。在这种情况下，Kubernetes首先计算：
- en: '[PRE59]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Then, the number of replicas is computed as `<utilization>/<target utilization>`.
    For instance, if the target CPU utilization is 50 on average, each Pod must waste
    50% of the CPU millicores declared in the request. Therefore, if the average CPU
    wasted by all Pods of a Deployment is 30Mi, while the CPU required by each Pod
    is 20mi, we compute the utilization as 100*30/20= 150\. So, the number of replicas
    is 150/50 = 3.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，副本数量计算为`<利用率>/<目标利用率>`。例如，如果目标CPU利用率平均为50%，则每个Pod必须浪费请求中声明的CPU毫核的50%。因此，如果Deployment中所有Pod的平均CPU浪费为30Mi，而每个Pod所需的CPU为20mi，我们计算利用率为100*30/20=
    150。因此，副本数量为150/50 = 3。
- en: 'In this case, the code is:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，代码如下：
- en: '[PRE60]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Pod metrics
  id: totrans-371
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pod度量指标
- en: 'Pod metrics are not standard but depend on the metrics actually computed by
    each specific cloud platform or on-premise installation. Pod metric constraints
    are declared as:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: Pod度量指标并非标准化，而是依赖于每个特定云平台或本地安装实际计算的度量指标。Pod度量指标约束声明如下：
- en: '[PRE61]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Where we suppose that the `packets-per-second` metric exists in the platform
    and computes the average communication packets received per second by a Pod. The
    calculation of the number of replicas is done as in the case of `averageValue`
    for resource metrics.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 假设平台中存在 `packets-per-second` 指标，并计算每个 Pod 每秒接收的平均通信数据包。副本数量的计算与资源指标中的 `averageValue`
    情况相同。
- en: Object metrics
  id: totrans-375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对象指标
- en: Object metrics refer to metrics computed on objects outside of the controlled
    Pods but inside the Kubernetes cluster. Like Pod metrics, object metrics are also
    not standard but depend on the metrics actually computed by each specific platform.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 对象指标是指计算在受控 Pod 外部但位于 Kubernetes 集群内部的对象上的指标。像 Pod 指标一样，对象指标也不是标准的，而是取决于每个特定平台实际计算的指标。
- en: 'In the *Advanced Kubernetes configuration* section, we will describe Kubernetes
    resources called **Ingresses** that interface the Kubernetes cluster with the
    external world. Typically, all Kubernetes input traffic transits through a single
    Ingress, so we can measure the total input traffic by measuring the traffic inside
    that Ingress. Once a cluster has been empirically optimized, and we need to just
    adapt it to temporary peaks, the easiest way to do it is by connecting the number
    of replicas of each frontend microservice and also of some Worker microservice
    to the total application input traffic. This can be done with Object metric constraints
    that reference the unique application Ingress:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *高级 Kubernetes 配置* 部分，我们将描述称为 **Ingress** 的 Kubernetes 资源，它们将 Kubernetes 集群与外部世界接口。通常，所有
    Kubernetes 输入流量都通过单个 Ingress 转移，因此我们可以通过测量该 Ingress 内部的流量来测量总输入流量。一旦集群经过经验优化，并且我们只需要适应临时峰值，最简单的方法是将每个前端微服务和一些
    Worker 微服务的副本数量与总应用程序输入流量连接起来。这可以通过引用唯一应用程序 Ingress 的对象指标约束来实现：
- en: '[PRE62]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: In this case, we have a `value` since we don’t average on several objects, but
    the number of replicas is computed as for the Pod metrics. Moreover, in this case,
    we must be sure that the `requests-per-second` metric is actually computed by
    the infrastructure on all Ingresses.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们有一个 `value`，因为我们不是在多个对象上取平均值，但副本数量是按照 Pod 指标的方式计算的。此外，在这种情况下，我们必须确保
    `requests-per-second` 指标实际上是由基础设施在所有 Ingress 上计算的。
- en: Personally, I always use CPU and memory metrics since they are available on
    all platforms, and since using the procedure sketched in this subsection, it is
    reasonably easy to find good target values for them.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 个人来说，我总是使用 CPU 和内存指标，因为它们在所有平台上都可用，并且自从使用本小节中概述的流程以来，找到它们的良好目标值相对容易。
- en: Though all cloud providers offer useful Kubernetes metrics, there are open-source
    metric servers that can also be installed on on-premises Kubernetes clusters through
    `.yaml` files. See the *Further reading* section for an example.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然所有云服务提供商都提供了有用的 Kubernetes 指标，但也有一些开源的指标服务器可以通过 `.yaml` 文件安装到本地 Kubernetes
    集群中。请参阅 *进一步阅读* 部分，以获取示例。
- en: Minikube has a metrics-server addon that can be installed with `minikube addons
    enable metrics-server`. You also need it to use standard resource metrics like
    CPU and memory.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube 有一个名为 metrics-server 的指标服务器插件，可以通过 `minikube addons enable metrics-server`
    安装。您还需要它来使用标准资源指标，如 CPU 和内存。
- en: In the next section, we will analyze how to test and deploy a microservice application
    and will put these concepts into practice by running and debugging the Worker
    microservice we implemented in [*Chapter 7*](Chapter_7.xhtml#_idTextAnchor151)*,
    Microservices in Practice*, on Minikube.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将分析如何测试和部署微服务应用程序，并通过在 Minikube 上运行和调试我们在 [*第 7 章*](Chapter_7.xhtml#_idTextAnchor151)*，实践中的微服务*
    中实现的 Worker 微服务来将这些概念付诸实践。
- en: Running your microservices on Kubernetes
  id: totrans-384
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上运行微服务
- en: 'In this section, we will test the routes-matching worker microservice in Minikube,
    but we will also describe how to organize the various environments your microservices
    application will be deployed to: development, staging, and production. Each environment
    has its own peculiarities, such as an easy way to test each change in development
    and maximizing performance in production.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将测试 Minikube 中的 routes-matching 工作微服务，但也会描述如何组织微服务应用程序将要部署的各种环境：开发、测试和生产。每个环境都有其独特的特点，例如在开发中轻松测试每个更改，以及在生产中最大化性能。
- en: Organizing all deployment environments
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组织所有部署环境
- en: It is also worth pointing out that the simplest test in Minikube requires a
    not-negligible setup time. Therefore, most development simply uses Docker, that
    is, a few containerized microservices organized into a unique Visual Studio solution
    that starts all of them when you launch the solution.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，Minikube中最简单的测试也需要相当长的设置时间。因此，大多数开发工作简单地使用Docker，即几个容器化的微服务组织成一个独特的Visual
    Studio解决方案，当您启动解决方案时，它会启动所有这些服务。
- en: At this stage, we don’t test the whole application but just a few tightly interacting
    microservices, possibly simulating the remainder of the application with stubs.
    If communication is handled through a message broker, it is enough to launch all
    microservices and the message broker to test everything; otherwise, if we rely
    on direct communication between microservices, we must connect all microservices
    in a virtual network.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们不会测试整个应用程序，而只是测试几个紧密交互的微服务，可能使用存根模拟应用程序的其余部分。如果通信是通过消息代理处理的，那么启动所有微服务和消息代理来测试一切就足够了；否则，如果我们依赖于微服务之间的直接通信，我们必须在虚拟网络中连接所有微服务。
- en: Docker offers the possibility to both create a virtual network and connect running
    containers to it. The virtual network created by Docker also includes your development
    machine, which gets the **host.docker.internal** hostname. Therefore, all microservices
    can use various services running on the development machine, such as RabbitMQ,
    SQL Server, and Redis.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: Docker提供了创建虚拟网络并将运行中的容器连接到它的可能性。Docker创建的虚拟网络也包括您的开发机器，该机器获得**host.docker.internal**主机名。因此，所有微服务都可以使用开发机上运行的各种服务，例如RabbitMQ、SQL
    Server和Redis。
- en: 'You can create a test virtual network in Docker with:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令在Docker中创建一个测试虚拟网络：
- en: '[PRE63]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Then, attaching all running microservices to this network is super easy. It
    is enough to modify their project files as follows:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将所有运行的微服务附加到这个网络非常简单。只需修改它们的项目文件如下：
- en: '[PRE64]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Then, you can also add other `docker run` arguments, such as a volume mount.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您还可以添加其他`docker run`参数，例如卷挂载。
- en: Testing on Minikube can be performed at the end of the working day or simply
    after the complete implementation of a feature.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在工作日的末尾或简单地在一个功能的完整实现之后在Minikube上进行测试。
- en: 'In the next subsections, we will compare all deployment environments on the
    following axes:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将从以下轴向上比较所有部署环境：
- en: Database engine and database installation
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库引擎和数据库安装
- en: Container registries
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器注册库
- en: Message broker installation
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 消息代理安装
- en: Debugging techniques
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调试技术
- en: Database engine and database installation
  id: totrans-401
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据库引擎和数据库安装
- en: Development tests with Docker or Minikube may all use a database engine running
    directly on the development machine. You may use either an actual installation
    or an engine running as a Docker container. The advantage is that the database
    is also accessible from Visual Studio, so you can pass all migrations while you
    develop them.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker或Minikube进行开发测试可能都会使用直接在开发机上运行的数据库引擎。您可以使用实际安装或作为Docker容器运行的引擎。其优势在于数据库也可以从Visual
    Studio访问，因此您可以在开发它们的同时传递所有迁移。
- en: You can also use fresh Docker containers running the database engine to start
    databases from scratch and perform unit tests, or to test the overall migration
    set.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用运行数据库引擎的新鲜Docker容器从头开始启动数据库并执行单元测试，或者测试整体迁移集。
- en: If you installed Minikube with the Docker driver, a database running on your
    development machine can be reached from inside your Minikube containers by using
    either the **host.minikube.internal** or **host.docker.internal** hostnames. Therefore,
    if you use **host.docker.internal**, you will be able to reach your host machine
    from both Minikube and from your containerized applications directly launched
    by Visual Studio.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用Docker驱动程序安装了Minikube，您可以通过使用**host.minikube.internal**或**host.docker.internal**主机名从您的Minikube容器内部访问开发机上的数据库。因此，如果您使用**host.docker.internal**，您将能够从Minikube以及直接由Visual
    Studio启动的容器化应用程序直接访问主机机。
- en: On both staging and production, you can use database cloud services that ensure
    good performance, are scalable, and offer clustering, replication, geographic
    redundancy, and so on. It’s also possible to deploy the database inside your Kubernetes
    cluster, but in this case, you must buy a license, you should dedicate ad hoc
    Kubernetes nodes for the database (virtual machines that ensure optimal database
    performance), and you should fine-tune the database configuration. Therefore,
    if there are no compelling reasons for a different choice, it is more convenient
    to opt for cloud services.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 在 staging 和 production 上，您可以使用确保良好性能、可扩展性，并提供集群、复制、地理冗余等功能的数据库云服务。也有可能将数据库部署在您的
    Kubernetes 集群内部，但在此情况下，您必须购买许可证，您应该为数据库分配专用的 Kubernetes 节点（确保最佳数据库性能的虚拟机），并且您应该微调数据库配置。因此，如果没有充分的理由选择不同的方案，选择云服务会更方便。
- en: Moreover, both in production and staging, you can’t configure your Deployments
    to automatically apply migrations when they start; otherwise, all replicas will
    attempt to apply them. It’s better to extract a database script from your migrations
    and apply it with a database DBO user privilege, while leaving the microservice
    replicas with a less privileged database user.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，无论是在生产还是在 staging，您都不能配置您的 Deployments 在启动时自动应用迁移；否则，所有副本都将尝试应用它们。更好的做法是从您的迁移中提取数据库脚本，并使用数据库
    DBO 用户权限应用它，同时让微服务副本拥有更低的数据库用户权限。
- en: 'A database script can be extracted from all migrations with the migration command
    below:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下迁移命令从所有迁移中提取数据库脚本：
- en: '[PRE65]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Let’s move on to container registries.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论容器注册库。
- en: Container registries
  id: totrans-410
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器注册库
- en: As far as staging and production are concerned, they can both use the same container
    registry since containers are versioned. So, for instance, production can use
    `v1.0`, while staging can use `v2.0-beta1`. It is better if registries belong
    to the same cloud subscription of the Kubernetes cluster to simplify credential
    handling. For instance, in the case of AKS, it is enough to associate a registry
    to an AKS cluster once and for all to grant access to the cluster to the registry
    (see the *Creating an Azure Kubernetes cluster* subsection of this chapter).
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 就 staging 和 production 而言，它们都可以使用相同的容器注册库，因为容器是分版本的。例如，生产可以使用 `v1.0`，而 staging
    可以使用 `v2.0-beta1`。如果注册库属于 Kubernetes 集群的同一云订阅，则可以简化凭证处理。例如，在 AKS 的情况下，只需将注册库与
    AKS 集群关联一次，即可授予注册库对集群的访问权限（参见本章的 *创建 Azure Kubernetes 集群* 小节）。
- en: 'As far as development is concerned, each developer can use the same registry
    used by the staging environment for the containers they are not working on, but
    each developer should have a private registry for the containers they are working
    on, so they can experiment with no risk of dirtying the “official image” registries.
    Therefore, the simplest solution is to install a local registry in your Docker
    Desktop. You can do this with:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 就开发而言，每个开发者可以使用 staging 环境中用于他们不工作的容器的相同注册库，但每个开发者应该有一个私有注册库用于他们正在工作的容器，这样他们就可以无风险地实验，而不会污染“官方镜像”注册库。因此，最简单的解决方案是在您的
    Docker Desktop 中安装一个本地注册库。您可以使用以下方法完成此操作：
- en: '[PRE66]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Once the container has been created with the instruction above, you can stop
    and restart it from the Docker Desktop graphical user interface.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用上述指令创建了容器，您就可以从 Docker Desktop 图形用户界面停止和重新启动它。
- en: Unluckily, as a default, both Docker and Minikube do not accept interacting
    with insecure registries, that is, with registries that do not support HTTPS with
    a certificate signed by a public authority, so we must instruct both Docker and
    Minikube to accept insecure interaction with the local registry.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，默认情况下，Docker 和 Minikube 都不接受与不安全的注册库交互，也就是说，与不支持由公共机构签发的证书的 HTTPS 的注册库交互，因此我们必须指导
    Docker 和 Minikube 接受与本地注册库的不安全交互。
- en: 'Let’s open the Docker Desktop graphical user interface and click on the settings
    image in the top-right corner:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开 Docker Desktop 的图形用户界面，并点击右上角的设置图标：
- en: '![Figure 8.5: Docker settings](img/B31916_08_5.png)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5：Docker 设置](img/B31916_08_5.png)'
- en: 'Figure 8.5: Docker settings'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5：Docker 设置
- en: 'Then, select **Docker Engine** from the left menu, and edit the big text box
    that contains Docker configuration information, and add the entry shown below
    to the existing JSON content:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，从左侧菜单中选择 **Docker Engine**，并编辑包含 Docker 配置信息的文本框，并将以下条目添加到现有的 JSON 内容中：
- en: '[PRE67]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The above settings add the 5000 ports of both hostnames that point to your
    host computer to the allowed insecure registries. The result should be something
    like:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 上述设置将指向你的主机计算机的 5000 个端口的两个主机名添加到允许的不安全注册表中。结果应该类似于：
- en: '![Figure 8.6: Adding a local registry to Docker allowed insecure registries](img/B31916_08_6.png)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6：将本地注册表添加到 Docker 允许不安全的注册表](img/B31916_08_6.png)'
- en: 'Figure 8.6: Adding a local registry to Docker allowed insecure registries'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6：将本地注册表添加到 Docker 允许不安全的注册表
- en: 'As far as Minikube is concerned, you have to destroy your current Minikube
    VM with:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 就 Minikube 而言，你必须使用以下命令销毁当前的 Minikube VM：
- en: '[PRE68]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Then, you need to create a new VM image with the right insecure registry settings:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要创建一个新的 VM 镜像，并带有正确的非安全注册表设置：
- en: '[PRE69]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Please execute all the above steps because we will need a local registry for
    testing the route-planning microservice.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 请执行所有上述步骤，因为我们需要本地注册表来测试路由规划微服务。
- en: 'If Minikube also needs to access other password-protected registries, you must
    configure and enable the **registry-creds** addon:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Minikube 还需要访问其他受密码保护的注册表，你必须配置并启用 **registry-creds** 插件：
- en: '[PRE70]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Once you issue the above command, you will be asked to configure Google, AWS,
    Azure, or Docker private registries and enter your credentials.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦执行上述命令，系统将要求你配置 Google、AWS、Azure 或 Docker 私有注册表并输入你的凭证。
- en: 'After a successful configuration, you can enable the credential usage with:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功配置之后，你可以通过以下方式启用凭证使用：
- en: '[PRE71]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Let’s move on to the message broker.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续到消息代理部分。
- en: Message broker installation
  id: totrans-435
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 消息代理安装
- en: RabbitMQ can be installed both locally and in the cloud, and works on all clouds,
    so it really is a good option. You can run a single RabbitMQ server or a server
    cluster. A RabbitMQ cluster can also be installed on the Kubernetes cluster itself.
    During development, you may install it on Minikube, but it is more convenient
    to run it outside of Minikube, so it can also be easily reached by applications
    running outside of Minikube, which, in turn, facilitates application debugging,
    as we will see in the next subsection.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ 可以在本地和云端安装，并且支持所有云平台，因此它确实是一个不错的选择。你可以运行单个 RabbitMQ 服务器或服务器集群。RabbitMQ
    集群也可以安装在 Kubernetes 集群本身上。在开发过程中，你可能需要在 Minikube 上安装它，但将其运行在 Minikube 之外更为方便，这样它也可以被
    Minikube 之外运行的应用程序轻松访问，从而便于应用程序调试，正如我们将在下一小节中看到的。
- en: 'In staging and production, the simplest way to install a RabbitMQ cluster is
    by installing the so-called **RabbitMQ Cluster Operator** with:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试和生成环境中，安装 RabbitMQ 集群最简单的方法是使用所谓的 **RabbitMQ Cluster Operator** 进行安装：
- en: '[PRE72]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The RabbitMQ operator defines the **RabbitmqCluster** custom resource that
    represents a RabbitMQ Cluster. You can create and configure **RabbitmqCluster**
    as you configure any other Kubernetes resource:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ 操作符定义了一个代表 RabbitMQ 集群的 **RabbitmqCluster** 自定义资源。你可以像配置任何其他 Kubernetes
    资源一样创建和配置 **RabbitmqCluster**：
- en: '[PRE73]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The persistence section specifies the options for persisting queues on persistent
    storage. If you omit it, all default values will be taken. If you omit the number
    of replicas, a cluster with a single server will be created. More options are
    available in the official documentation: [https://www.rabbitmq.com/kubernetes/operator/using-operator](https://www.rabbitmq.com/kubernetes/operator/using-operator).'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 持久化部分指定了在持久存储上持久化队列的选项。如果你省略它，将采用所有默认值。如果你省略副本数量，将创建一个包含单个服务器的集群。更多选项可以在官方文档中找到：[https://www.rabbitmq.com/kubernetes/operator/using-operator](https://www.rabbitmq.com/kubernetes/operator/using-operator)。
- en: 'You can get the username and password of your RabbitMQ cluster default user
    by printing the `<cluster name>-default-user` secret where they are stored, as
    shown below:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过打印存储它们的 `<cluster name>-default-user` 机密来获取 RabbitMQ 集群默认用户的用户名和密码，如下所示：
- en: '[PRE74]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Both username and password are base-64 encoded. The simplest way to decode
    them is by copying each of them from the console output, opening a Linux console,
    and using the `base64` command:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 用户名和密码都是 base64 编码的。最简单的方法是将它们从控制台输出中复制出来，打开 Linux 控制台，并使用 `base64` 命令进行解码：
- en: '[PRE75]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: If you want, you may also install the RabbitMQ cluster operator in Minikube,
    but in this case, it is better to start Minikube with at least 4 CPUs and 6-8
    gigabytes of run.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你愿意，你还可以在 Minikube 中安装 RabbitMQ 集群操作符，但在此情况下，最好以至少 4 个 CPU 和 6-8 GB 的运行内存启动
    Minikube。
- en: 'If you need to connect to the RabbitMQ cluster from outside of the Kubernetes
    cluster for debugging purposes, you can use the `kubectl port-forward` command:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要从 Kubernetes 集群外部连接到 RabbitMQ 集群进行调试，可以使用 `kubectl port-forward` 命令：
- en: '[PRE76]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: The above instruction freezes the console and forwards port 5672 of the `service/<cluster
    name>` ClusterIP service that is part of the RabbitMQ cluster to port 5672 of
    localhost. The port-forwarding remains active while the console window is open
    or `ctrl-c` is issued to abort the instruction.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 上述指令冻结了控制台并将 RabbitMQ 集群中 `service/<cluster name>` ClusterIP 服务的 5672 端口转发到
    localhost 的 5672 端口。端口转发在控制台窗口打开或发出 `ctrl-c` 以中止指令时保持活动状态。
- en: 'The general `kubectl port-forward` syntax is:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 通用 `kubectl port-forward` 语法是：
- en: '[PRE77]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: In our case, the service name is equal to the cluster name.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，服务名称等于集群名称。
- en: The service <cluster name> is the ClusterIP service you must use to access the
    RabbitMQ cluster from inside the Kubernetes cluster. Therefore, the RabbitMQ hostname
    to specify in the connection is `<cluster name>.<cluster namespace>`.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 服务 `<cluster name>` 是您必须使用的 ClusterIP 服务，以便从 Kubernetes 集群内部访问 RabbitMQ 集群。因此，在连接中指定的
    RabbitMQ 主机名为 `<cluster name>.<cluster namespace>`。
- en: 'You can also access the RabbitMQ management UI with your browser by forwarding
    the 15672 port:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过转发 15672 端口使用浏览器访问 RabbitMQ 管理界面：
- en: '[PRE78]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Then, the UI will be available at `localhost:15672`. There, you must use the
    credentials you previously extracted from the `cluster name>-default-user` secret.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，UI 将在 `localhost:15672` 上可用。在那里，您必须使用您之前从 `cluster name>-default-user` 机密中提取的凭据。
- en: The port forwarding is safe and doesn’t expose RabbitMQ to the outside world
    since the connection between localhost and the service is mediated by the Kubernetes
    API server. It can be safely used to connect test code running on the development
    machine with the RabbitMQ cluster, as we will see in more detail in the next subsection.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 端口转发是安全的，并且不会将 RabbitMQ 暴露给外部世界，因为 localhost 和服务之间的连接由 Kubernetes API 服务器介导。它可以安全地用于将运行在开发机器上的测试代码与
    RabbitMQ 集群连接起来，我们将在下一小节中更详细地看到这一点。
- en: Debugging techniques
  id: totrans-458
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调试技术
- en: When you launch all containers from Visual Studio, you can debug your code without
    performing any further configuration. However, if you need to debug some microservices
    running either in Minikube, in staging, or in production, you need some supplementary
    configuration.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 当您从 Visual Studio 启动所有容器时，您可以在不进行任何进一步配置的情况下调试您的代码。但是，如果您需要调试在 Minikube、预发布或生产环境中运行的某些微服务，您需要一些补充配置。
- en: 'Instead of trying to attach the debugger inside of your Kubernetes cluster,
    a simpler approach is to use the so-called bridge: you select a specific microservice
    to debug, and instead of debugging it in Kubernetes, you redirect its traffic
    to a replica of your microservice running in Visual Studio, then you redirect
    all local microservice output traffic again inside the cluster. This way, you
    debug just a local copy that has been compiled in debug mode, overcoming both
    the need to replace the release code with debug code, and the difficulty of attaching
    a debugger inside of your Kubernetes cluster.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是尝试在您的 Kubernetes 集群内部附加调试器，一个更简单的方法是使用所谓的桥接：您选择一个特定的微服务进行调试，而不是在 Kubernetes
    中调试它，而是将其流量重定向到在 Visual Studio 中运行的微服务副本，然后再次在集群内部重定向所有本地微服务输出流量。这样，您只需调试一个已编译为调试模式的本地副本，从而克服了需要用调试代码替换发布代码的需求，以及在内部
    Kubernetes 集群中附加调试器的困难。
- en: 'The image below exemplifies the bridge idea:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像展示了桥接的概念：
- en: '![Figure 8.7: Bridging](img/B31916_08_7.png)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7：桥接](img/B31916_08_7.png)'
- en: 'Figure 8.7: Bridging'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7：桥接
- en: 'If both inputs and outputs are handled by a message broker, bridging is easy:
    it is enough to connect the local copy to the same RabbitMQ queues of the in-cluster
    replicas. This way, part of the traffic will be automatically forwarded to the
    local copy. If the RabbitMQ cluster runs inside the Kubernetes cluster, you need
    to forward its ports on localhost as explained in the previous section.'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输入和输出都由消息代理处理，桥接就很简单了：只需将本地副本连接到集群内副本相同的 RabbitMQ 队列即可。这样，部分流量将自动转发到本地副本。如果
    RabbitMQ 集群运行在 Kubernetes 集群内部，您需要按照前一个部分所述转发其 localhost 上的端口。
- en: Moreover, if the microservice is connected to a database, we must also connect
    the local copy to the same database. If you are in production, this might require
    the definition of a firewall rule to enable access of your development machine
    to the database.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果微服务连接到数据库，我们还必须将本地副本连接到相同的数据库。如果您在生产环境中，这可能需要定义防火墙规则以允许您的开发机器访问数据库。
- en: If some input and output are handled by services instead of message brokers,
    bridging becomes more complex. More specifically, forwarding the output to a service
    inside the Kubernetes cluster is quite easy since it requires just port-forwarding
    the target service on localhost with `kubectl port-forward`. However, forwarding
    traffic from a service to the local microservice copy requires some kind of hack
    on the service.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某些输入和输出由服务而不是消息代理处理，则桥接变得更加复杂。更具体地说，将输出转发到Kubernetes集群内的服务相当简单，因为它只需要在本地主机上使用`kubectl
    port-forward`将目标服务端口转发。然而，将流量从服务转发到本地微服务副本需要对该服务进行某种形式的黑客攻击。
- en: Services compute the Pods they must route the traffic to and then create resources
    called `EndpointSlice` containing the IP addresses where they must route the traffic.
    Therefore, in order to route all service traffic to your local machine, you need
    to override the `EndpointSlices` of that service. This can be done by removing
    the selector of the target service so that all `EndpointSlices` will be deleted,
    and then manually adding an `EndpointSlice` that points to your development machine.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 服务计算它们必须路由流量的Pods，然后创建名为`EndpointSlice`的资源，其中包含它们必须路由流量的IP地址。因此，为了将所有服务流量路由到您的本地机器，您需要覆盖该服务的`EndpointSlices`。这可以通过移除目标服务的选择器来实现，这样所有`EndpointSlices`都将被删除，然后手动添加一个指向您的开发机器的`EndpointSlice`。
- en: 'You can do this as follows:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按照以下步骤操作：
- en: 'Get the target service definition with:'
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令获取目标服务定义：
- en: '[PRE79]'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Remove the selector, and apply the new definition.
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除选择器，并应用新的定义。
- en: 'If you are working on a remote cluster, add the `EndpointSlice` below:'
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您在一个远程集群上工作，请添加以下`EndpointSlice`：
- en: '[PRE80]'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'If, instead, you are working on a Minikube local cluster, add the `EndpointSlice`
    below:'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您在一个Minikube本地集群上工作，请添加以下`EndpointSlice`：
- en: '[PRE81]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: When you finish debugging, reapply the original service definition. Your custom
    `EndpointSlice` will be automatically destroyed.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当您完成调试后，重新应用原始服务定义。您的自定义`EndpointSlice`将被自动销毁。
- en: As you can see, using message brokers simplifies a lot of the debugging. It
    is the advised option when implementing applications. Services are a better option
    when implementing tools, such as database clusters, or message brokers that run
    inside your cluster.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，使用消息代理简化了大量的调试工作。在实现应用程序时，这是建议的选项。当实现工具时，例如数据库集群或运行在您集群内的消息代理，服务是一个更好的选择。
- en: There are tools that automatically handle all needed service hacking, such as
    **Bridge to Kubernetes** ([https://learn.microsoft.com/en-us/visualstudio/bridge/bridge-to-kubernetes-vs](https://learn.microsoft.com/en-us/visualstudio/bridge/bridge-to-kubernetes-vs)),
    but unluckily, Microsoft announced that it will stop supporting it. Microsoft
    will advise a valid alternative.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些工具可以自动处理所有需要的服务黑客攻击，例如**桥接到Kubernetes** ([https://learn.microsoft.com/en-us/visualstudio/bridge/bridge-to-kubernetes-vs](https://learn.microsoft.com/en-us/visualstudio/bridge/bridge-to-kubernetes-vs))，但不幸的是，微软宣布将停止支持它。微软将建议一个有效的替代方案。
- en: Now we are finally ready to test an actual Microservice on Minikube.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们终于准备好在Minikube上测试实际的微服务了。
- en: Testing the route-matching worker microservice
  id: totrans-480
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试路由匹配工作微服务
- en: We will test the route-matching worker microservice implemented in [*Chapter
    7*](Chapter_7.xhtml#_idTextAnchor151)*, Microservices in Practice*, together with
    two stub microservices. The first one will send test input to it, while the other
    will collect all its output and will write it in its console, so that we may access
    this output with the `kubectl logs` command. This is a typical way to perform
    a preliminary test. Then, more complex tests may also involve other application
    services.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测试在[*第7章*](Chapter_7.xhtml#_idTextAnchor151)*实践中的微服务*中实现的路线匹配工作微服务，以及两个存根微服务。第一个将发送测试输入给它，而另一个将收集所有输出并将其写入其控制台，这样我们就可以使用`kubectl
    logs`命令访问这些输出。这是一种典型的初步测试方法。然后，更复杂的测试也可能涉及其他应用服务。
- en: 'Let’s create a copy of our route-matching worker microservice solution, then
    add two more **Worker service** projects, and call them respectively `FakeSource`
    and `FakeDestination`. For each of them, enable container support for Linux as
    shown in the following screenshot:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建我们路线匹配工作微服务解决方案的副本，然后添加两个额外的**工作服务**项目，分别命名为`FakeSource`和`FakeDestination`。对于每个项目，如图所示启用Linux容器支持：
- en: '![Figure 8.8: Worker services project settings](img/B31916_08_8.png)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
  zh: '![图8.8：工作服务项目设置](img/B31916_08_8.png)'
- en: 'Figure 8.8: Worker services project settings'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8：工作服务项目设置
- en: 'Then, let’s also add all needed EasyNetQ packages to enable both services to
    interact with a RabbitMQ cluster:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们也添加所有需要的 EasyNetQ 包，以便两个服务能够与 RabbitMQ 集群交互：
- en: '`EasyNetQ`'
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`EasyNetQ`'
- en: '`EasyNetQ.Serialization.NewtonsoftJson`'
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`EasyNetQ.Serialization.NewtonsoftJson`'
- en: '`EasyNetQ.Serialization.SystemTextJson`'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`EasyNetQ.Serialization.SystemTextJson`'
- en: Select at least version 8, also if it is still a prerelease.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 选择至少版本 8，即使它仍然是预发布版本。
- en: 'Then you must add RabbitMQ to the services in the `Program.cs` of both projects:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你必须将 RabbitMQ 添加到两个项目的 `Program.cs` 文件中的服务列表中：
- en: '[PRE82]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The RabbitMQ connection string must be added in the environment variables defined
    in `Properties->launchSettings.json`, as shown below:'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ 连接字符串必须添加到在 `Properties->launchSettings.json` 中定义的环境变量中，如下所示：
- en: '[PRE83]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: Finally, refer to the `SharedMessages` project from both `FakeSource` and `FakeDestination`,
    so they can use all application communication messages.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从 `FakeSource` 和 `FakeDestination` 两个项目中引用 `SharedMessages` 项目，这样它们就可以使用所有应用程序通信消息。
- en: 'At this point, we are ready to code our stub services. In the `Worker.cs` file
    scaffolded by Visual Studio in the `FakeDestination` project, replace the existing
    class with:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经准备好编写我们的存根服务。在 `FakeDestination` 项目中由 Visual Studio 生成的 `Worker.cs`
    文件中，用以下内容替换现有的类：
- en: '[PRE84]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: The hosted service adds a subscription named `FakeDestination` to the `RouteExtensionProposalsMessage`
    event. This way, it receives all matching proposals between an existing route
    and some requests. Once the subscription handler receives a proposal, it just
    logs the message in JSON format, so we can verify that the right match proposal
    events are generated by exploring the `FakeDestination` logs.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 托管服务向 `RouteExtensionProposalsMessage` 事件添加了一个名为 `FakeDestination` 的订阅。这样，它接收所有现有路线和某些请求之间的匹配提案。一旦订阅处理程序收到一个提案，它只是以
    JSON 格式记录消息，这样我们就可以通过检查 `FakeDestination` 的日志来验证是否生成了正确的匹配提案事件。
- en: 'In the `Worker.cs` file scaffolded by Visual Studio in the FakeSource project,
    we will replace the existing class with simple code that does the following:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `FakeSource` 项目中由 Visual Studio 生成的 `Worker.cs` 文件中，我们将用以下简单代码替换现有的类，执行以下操作：
- en: 'Creates three town messages: Phoenix, Santa Fe, and Cheyenne.'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建三个城镇消息：凤凰城、圣菲和切伊恩。
- en: Sends a request going from Phoenix to Santa Fe.
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从凤凰城发送到圣菲的请求。
- en: Sends a route offer passing from Phoenix, Santa Fe, and Cheyenne. As soon as
    this message is received by the route planning worker microservice, it should
    create a proposal to match this offer with the previous request. This proposal
    should be received by `FakeDestination` and logged.
  id: totrans-501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从凤凰城、圣菲和切伊恩发送一条路线出价。一旦这个消息被路线规划工作微服务接收，它应该创建一个提案来匹配这个出价与之前的请求。这个提案应该被 `FakeDestination`
    接收并记录。
- en: Sends a request going from Santa Fe to Cheyenne. As soon as this message is
    received by the routes planning worker microservice, it should create a proposal
    to match this request with the previous offer. This proposal should be received
    by `FakeDestination` and logged.
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从圣菲发送到切伊恩的请求。一旦这个消息被路线规划工作微服务接收，它应该创建一个提案来匹配这个请求与之前的出价。这个提案应该被 `FakeDestination`
    接收并记录。
- en: After 10 seconds, it simulates that both previous proposals have been accepted
    and creates a route extension event based on the previous offer and containing
    both the matched requests. As soon as this message is received by the route planning
    worker microservice, it should both update the offer and should add the two requests
    to the offer. As a result, the `RouteId` field of both requests should point to
    the offer `Id`.
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 10秒后，它模拟前两个提案已被接受，并基于之前的出价创建一个路线扩展事件，包含两个匹配的请求。一旦这个消息被路线规划工作微服务接收，它应该更新出价，并将两个请求添加到出价中。结果，两个请求的
    `RouteId` 字段都应该指向出价的 `Id`。
- en: 'The code of the `Worker.cs` class is:'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '`Worker.cs` 类的代码如下：'
- en: '[PRE85]'
  id: totrans-505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: The code that defines all messages has been omitted. You can find the full code
    in the `ch08->CarSharing->FakeSource->Worker.cs` file of the GitHub repository
    associated with the book.
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 定义所有消息的代码已被省略。你可以在与本书相关的 GitHub 仓库中的 `ch08->CarSharing->FakeSource->Worker.cs`
    文件中找到完整的代码。
- en: 'Now let’s prepare to execute all microservices in Docker by performing the
    following steps:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过执行以下步骤来准备在 Docker 中执行所有微服务：
- en: Right-click on the solution line in Visual Studio Solution Explorer and select
    **Configure Startup Projects…**.
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Visual Studio 解决方案资源管理器中的解决方案行上右键单击，并选择 **配置启动项目…**。
- en: Then select **Multiple startup projects**, and change the name of the launch
    option to **AllMicroservices**.
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后选择 **多个启动项目**，并将启动选项的名称更改为 **AllMicroservices**。
- en: 'Then, select all three `FakeDestination`, `FakeSource`, and `RoutesPlanning`
    projects, and for each of them, choose **Start** for **Action** and **Container
    (Docker file)** for **Debug Target**, as shown below:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，选择所有三个 `FakeDestination`、`FakeSource` 和 `RoutesPlanning` 项目，并为每个项目选择 **操作**
    下的 **启动** 和 **容器（Docker 文件）** 作为 **调试目标**，如下所示：
- en: '![Figure 8.9: Launch settings](img/B31916_08_9.png)'
  id: totrans-511
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.9：启动设置](img/B31916_08_9.png)'
- en: 'Figure 8.9: Launch settings'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9：启动设置
- en: Now you can launch all projects simultaneously by choosing **AllMicroservices**
    in Visual Studio Debug Launcher.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过在 Visual Studio 调试启动器中选择 **AllMicroservices** 来同时启动所有项目。
- en: Ensure that both the application’s SQL Server and the RabbitMQ server are running.
    Then, build the project and launch it.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 确保应用程序的 SQL Server 和 RabbitMQ 服务器都在运行。然后，构建项目并启动它。
- en: 'In the Containers tab that appears, select `FakeDestination`, so you can inspect
    its logs. After a few seconds, you should see the two match proposal messages,
    as shown below:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 在出现的容器选项卡中，选择 `FakeDestination`，这样你就可以检查其日志。几秒钟后，你应该看到以下所示的两个匹配提案消息：
- en: '![Figure 8.10: FakeDestination logs](img/B31916_08_10.png)'
  id: totrans-516
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.10：FakeDestination 日志](img/B31916_08_10.png)'
- en: 'Figure 8.10: FakeDestination logs'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10：FakeDestination 日志
- en: 'Then, in the SQL Server Object Explorer pane, select the application database,
    if already there; otherwise, connect to it, and then show its tables:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 SQL Server 对象资源管理器窗格中，选择应用程序数据库，如果已经存在，否则连接到它，然后显示其表：
- en: '![Figure 8.11: Application database](img/B31916_08_11.png)'
  id: totrans-519
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.11：应用程序数据库](img/B31916_08_11.png)'
- en: 'Figure 8.11: Application database'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11：应用程序数据库
- en: 'Right-click on both **dbo.RouteOffers** and **dbo.RouteRequests** and select
    **View Data** to see all their data. You should see that the offer’s `Timestamp`
    changed to 2 because the offer was updated once the two matching proposals were
    accepted:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 右键单击 **dbo.RouteOffers** 和 **dbo.RouteRequests**，然后选择 **查看数据** 以查看它们的所有数据。你应该看到出价的
    `Timestamp` 已更改为 2，因为一旦接受两个匹配的提案，出价就被更新了一次：
- en: '![Figure 8.12: Updated offer](img/B31916_08_12.png)'
  id: totrans-522
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.12：更新后的出价](img/B31916_08_12.png)'
- en: 'Figure 8.12: Updated offer'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.12：更新后的出价
- en: 'Moreover, you should see that the two requests have been associated with the
    offer:'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你应该看到这两个请求已经与出价相关联：
- en: '![Figure 8.13: Updated requests](img/B31916_08_13.png)'
  id: totrans-525
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.13：更新后的请求](img/B31916_08_13.png)'
- en: 'Figure 8.13: Updated requests'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.13：更新后的请求
- en: Now let’s stop debugging and delete all records in the **dbo.RouteOffers** and
    **dbo.RouteRequests** tables.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们停止调试并删除 **dbo.RouteOffers** 和 **dbo.RouteRequests** 表中的所有记录。
- en: It’s time to deploy our Microservices in Minikube!
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候在 Minikube 中部署我们的微服务了！
- en: 'We will use the same RabbitMQ and SQL Servers running on the development machine.
    However, there are some preliminary steps to perform before we start deploying
    our `.yaml` files in Minikube:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在开发机上使用相同的 RabbitMQ 和 SQL 服务器。然而，在我们开始在 Minikube 中部署 `.yaml` 文件之前，有一些初步步骤需要执行：
- en: We must create adequate Docker images, since the debug images created by Visual
    Studio can’t run outside of Visual Studio. They all have a `dev` version. Go to
    the Docker files of the three `FakeDestination`, `FakeSource`, and `RoutesPlanning`
    projects in Visual Studio Explorer, right-click on them, and select **Build Docker
    Image**. These actions will create three Docker images with the latest version.
  id: totrans-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们必须创建足够的 Docker 映像，因为 Visual Studio 创建的调试映像不能在 Visual Studio 之外运行。它们都有 `dev`
    版本。转到 Visual Studio 探索器中三个 `FakeDestination`、`FakeSource` 和 `RoutesPlanning` 项目的
    Docker 文件，右键单击它们，然后选择 **构建 Docker 映像**。这些操作将创建三个具有最新版本的 Docker 映像。
- en: Launch the local registry container from inside the Docker UI. If you have not
    yet created a registry container, please refer to the *Container registries* subsection
    for installation instructions.
  id: totrans-531
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Docker UI 内启动本地注册表容器。如果你还没有创建注册表容器，请参阅 *容器注册表* 子部分以获取安装说明。
- en: 'Push our newly created images in this registry so they can be downloaded by
    Minikube (remember that you need a Linux console to issue the commands below):'
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将我们在此注册表中创建的新映像推送到 Minikube，以便 Minikube 可以下载它们（记住，你需要一个 Linux 控制台来执行以下命令）：
- en: '[PRE86]'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: We need to create 3 deployments, one for each of our three microservices. Let’s
    create a `Kubernetes` folder in the `CarSharing` solution folder. We will place
    our deployment definitions there.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为我们的三个微服务中的每一个创建 3 个部署。让我们在 `CarSharing` 解决方案文件夹中创建一个 `Kubernetes` 文件夹。我们将把我们的部署定义放在那里。
- en: 'Below `FakeSource.yaml`:'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `FakeSource.yaml` 下方：
- en: '[PRE87]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: It contains just a single environment variable for the RabbitMQ connection string
    – the same one we defined in `launchSettings.json`. The resource request is minimal.
    Labels are a documentation tool, too. Therefore, they define both the application
    name, the role in the application, and the fact that this microservice is a stub.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 它只包含一个用于 RabbitMQ 连接字符串的环境变量——与我们在 `launchSettings.json` 中定义的相同。资源请求是最小的。标签也是一个文档工具，因此它们定义了应用程序名称、应用程序中的角色以及这个微服务是一个占位符的事实。
- en: We designed the `car-sharing` namespace to host the whole application.
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了 `car-sharing` 命名空间来托管整个应用程序。
- en: '`host.docker.internal:5000` is the hostname of our local registry as seen from
    inside Minikube.'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: '`host.docker.internal:5000` 是从 Minikube 内部看到的本地仓库的主机名。'
- en: Our deployments don’t need services since they communicate through RabbitMQ.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的部署不需要服务，因为它们通过 RabbitMQ 进行通信。
- en: '`FakeDestination.yaml` is completely analogous:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '`FakeDestination.yaml` 完全类似：'
- en: '[PRE88]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '`RoutesPlanning.yaml` differs from the other just because it contains a lot
    more environment variables and because it exposes the `8080` port, which we might
    exploit to check the service’s health state (see the *Readiness, liveness, and
    startup probes* subsection in the next section).'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: '`RoutesPlanning.yaml` 与其他文件的不同之处在于它包含更多的环境变量，并且它暴露了 `8080` 端口，我们可以利用这个端口来检查服务的健康状态（参见下一节中的
    *就绪性、活跃性和启动探针* 子节）。'
- en: '[PRE89]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Let’s open a Windows console on the `Kubernetes` folder, and start deploying
    our application:'
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 `Kubernetes` 文件夹上打开一个 Windows 控制台，并开始部署我们的应用程序：
- en: Let’s start Minikube with `minikube start`.
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们启动 Minikube：`minikube start`。
- en: Let’s create the `car-sharing` namespace with `kubectl create namespace car-sharing`.
  id: totrans-547
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 `kubectl create namespace car-sharing` 创建 `car-sharing` 命名空间。
- en: 'Let’s deploy `FakeDestination.yaml` first: `kubectl apply -f FakeDestination.yaml`.'
  id: totrans-548
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们先部署 `FakeDestination.yaml`：`kubectl apply -f FakeDestination.yaml`。
- en: Now let’s verify all Pods are okay and ready with `kubectl get all -n car-sharing`.
    If they’re not ready, please repeat the command until they are ready.
  id: totrans-549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `kubectl get all -n car-sharing` 验证所有 Pod 都正常且已就绪。如果它们没有就绪，请重复该命令，直到它们就绪。
- en: Let’s copy the name of the created Pod. We need it to access its logs.
  id: totrans-550
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们复制创建的 Pod 的名称。我们需要它来访问其日志。
- en: 'Then, let’s deploy `RoutesPlanning.yaml`: `kubectl apply -f RoutesPlanning.yaml`.'
  id: totrans-551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，让我们部署 `RoutesPlanning.yaml`：`kubectl apply -f RoutesPlanning.yaml`。
- en: Again, let’s verify all Pods are okay and ready with `kubectl get all -n car-sharing`.
  id: totrans-552
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，让我们使用 `kubectl get all -n car-sharing` 验证所有 Pod 都正常且已就绪。
- en: 'Then, let’s deploy `FakeSource.yaml`: `kubectl apply -f FakeSource.yaml`.'
  id: totrans-553
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，让我们部署 `FakeSource.yaml`：`kubectl apply -f FakeSource.yaml`。
- en: Again, let’s verify all Pods are okay and ready with `kubectl get all -n car-sharing`.
  id: totrans-554
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，让我们使用 `kubectl get all -n car-sharing` 验证所有 Pod 都正常且已就绪。
- en: 'Now let’s check the `FakeDestination` logs to verify it received the match
    proposals with: `kubectl logs <FakeDestination POD name> -n car-sharing`. Where
    `<FakeDestination POD name>` is the name that we got in *step5.*'
  id: totrans-555
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们检查 `FakeDestination` 的日志以验证它是否收到了匹配建议：`kubectl logs <FakeDestination POD
    name> -n car-sharing`。其中 `<FakeDestination POD name>` 是我们在 *步骤 5* 中获得的名称。
- en: Also check the database table to verify that the applications work properly.
  id: totrans-556
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还需检查数据库表以验证应用程序是否正常工作。
- en: 'When you’ve finished experimenting, delete everything by simply deleting the
    `car-sharing` namespace: `kubectl delete namespace car-sharing`.'
  id: totrans-557
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你完成实验后，只需删除 `car-sharing` 命名空间即可删除所有内容：`kubectl delete namespace car-sharing`。
- en: Also delete the records in the **dbo.RouteOffers** and **dbo.RouteRequests**
    database tables.
  id: totrans-558
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还需删除 **dbo.RouteOffers** 和 **dbo.RouteRequests** 数据库表中的记录。
- en: 'Stop Minikube with: `minikube stop`.'
  id: totrans-559
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令停止 Minikube：`minikube stop`。
- en: Now, if you would like to experiment with debugging with the bridge technique,
    repeat the above steps, but replace points 6 and 7, which deploy the `RoutePlanning`
    microservice with the launch of the single `RoutePlanning` project inside of Visual
    Studio (just replace `AllMicroservices` with `RoutePlanning` in the Visual Studio
    debug widget, and then start the debugger).
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你想使用网桥技术进行调试实验，重复上述步骤，但将第 6 和第 7 点中部署 `RoutePlanning` 微服务的步骤替换为在 Visual
    Studio 中启动单个 `RoutePlanning` 项目（只需在 Visual Studio 调试窗口中将 `AllMicroservices` 替换为
    `RoutePlanning`，然后启动调试器）。
- en: Since all containers are attached to the same RabbitMQ server, the container
    running in Visual Studio will receive all input messages created from within Minikube,
    and all its output messages will be routed inside of Minikube. Let’s place a breakpoint
    wherever you would like to analyze the code before continuing the Kubernetes deployment.
    A few seconds after the deployment of the `FakeSource.yaml` file, the breakpoint
    should be hit!
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有容器都连接到同一个RabbitMQ服务器，因此在Visual Studio中运行的容器将接收来自Minikube内部创建的所有输入消息，并且所有输出消息都将路由在Minikube内部。让我们在继续Kubernetes部署之前，在任何您想要分析代码的地方放置一个断点。在部署`FakeSource.yaml`文件几秒钟后，应该会触发断点！
- en: Advanced Kubernetes configuration
  id: totrans-562
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级Kubernetes配置
- en: This section describes advanced Kubernetes resources that play a fundamental
    role in application design. Other advanced resources and configurations related
    specifically to security and observability will be described in [*Chapter 10*](Chapter_10.xhtml#_idTextAnchor297)*,
    Security and Observability for Serverless and Microservices Applications*.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了在应用程序设计中起基本作用的高级Kubernetes资源。其他与安全和可观察性相关的特定高级资源和配置将在[*第10章*](Chapter_10.xhtml#_idTextAnchor297)*，无服务器和微服务应用的安全和可观察性*中描述。
- en: Let’s start with secrets.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从Secrets开始。
- en: Secrets
  id: totrans-565
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Secrets
- en: Kubernetes allows various kinds of Secrets. Here, we will describe just `generic`
    and `tls` secrets, which are the ones used in the practical development of applications
    based on microservices.
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes允许各种类型的Secret。在这里，我们将仅描述`generic`和`tls`类型的Secret，这些是在基于微服务应用的实际开发中使用的。
- en: Each generic Secret contains a collection of entry-name/entry-value pairs. Secrets
    can be defined with .`yaml` files, but since it is not prudent to mix sensitive
    information with code, they are usually defined with `kubectl` commands.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 每个通用的Secret包含一组条目名称/条目值对。Secret可以用`.yaml`文件定义，但由于将敏感信息与代码混合并不谨慎，它们通常使用`kubectl`命令定义。
- en: 'Below is how to define a Secret, taking the entry values from file contents:'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何定义Secret，从文件内容中获取条目值：
- en: '[PRE90]'
  id: totrans-569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: The file names become entry names (just the file name with its extension – the
    path information is removed), while file contents become the associated entry
    values. Each entry is defined with a different `--from-file=…` option.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 文件名成为条目名称（只是文件名及其扩展名——路径信息被移除），而文件内容成为相关的条目值。每个条目使用不同的`--from-file=…`选项定义。
- en: 'Creates two files with the above names in a directory, put some content in
    them, then open a console on that directory, and finally try the above command.
    Once created, you can see it in `.yaml` format with:'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 在目录中创建两个具有上述名称的文件，向其中添加一些内容，然后在该目录上打开控制台，最后尝试上述命令。一旦创建，您可以用以下方式看到它以`.yaml`格式：
- en: '[PRE91]'
  id: totrans-572
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: In the data section, you will see the two entries, but the entry values appear
    encrypted. Actually, they are not encrypted but just base64-encoded. Needless
    to say, you can prevent some Kubernetes users from accessing Secret resources.
    We will see how in [*Chapter 10*](Chapter_10.xhtml#_idTextAnchor297)*, Security
    and Observability for Serverless and Microservices Applications*.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据部分，您将看到两个条目，但条目值看起来是加密的。实际上，它们并没有加密，只是进行了base64编码。不用说，您可以通过某些方式防止一些Kubernetes用户访问Secret资源。我们将在[*第10章*](Chapter_10.xhtml#_idTextAnchor297)*，无服务器和微服务应用的安全和可观察性*中看到如何做。
- en: 'A Secret can be deleted with:'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下方式删除Secret：
- en: '[PRE92]'
  id: totrans-575
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Instead of using files, one can specify the entry values in line:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 代替使用文件，可以在一行中指定条目值：
- en: '[PRE93]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: As usual, we can specify the Secret namespace with the `-n` option.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我们可以使用`-n`选项指定Secret命名空间。
- en: 'Once defined, generic Secrets can be mounted as volumes on Pods:'
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义，通用的Secret可以作为卷挂载在Pod上：
- en: '[PRE94]'
  id: totrans-580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Each entry is seen as a file whose name is the entry name and whose content
    is the entry value.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 每个条目被视为一个文件，其名称是条目名称，其内容是条目值。
- en: Do not forget that entry values are base64-encoded, so they must be decoded
    before usage.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记条目值是base64编码的，因此在使用之前必须解码。
- en: 'Secrets can also be passed as environment variables:'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: Secrets也可以作为环境变量传递：
- en: 'env:'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 'env:'
- en: '[PRE95]'
  id: totrans-585
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: In this case, Secret values are automatically base64-decoded before passing
    them as environment variables.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Secret值在作为环境变量传递之前会自动进行base64解码。
- en: '`Let’s try Secrets on the routes-matching worker microservices. Let’s create
    a Kubernetes Secret that contains the RabbitMQ connection string and correct FakeDestination.yaml,
    FakeSource.yaml, and RoutesPlanning.yaml, to use this Secret.`'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: '`让我们尝试在路由匹配工作微服务上使用Secrets。让我们创建一个包含RabbitMQ连接字符串以及正确的FakeDestination.yaml、FakeSource.yaml和RoutesPlanning.yaml的Kubernetes
    Secret，以便使用此Secret。`'
- en: '`tls` Secrets are designed for storing web servers’ certificates. We will see
    how to use them in the *Ingresses* subsection. `tls` secrets take as input both
    the private key certificate (.key) and the public key approved certificate (.crt):'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: '`tls` Secrets是为存储Web服务器的证书而设计的。我们将在*Ingresses*子节中看到如何使用它们。`tls` secrets接受输入私钥证书（.key）和经过批准的公钥证书（.crt）：'
- en: '[PRE96]'
  id: totrans-589
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: The next important topic concerns how our container code may help Kubernetes
    verify both whether each container is ready to interact with the remainder of
    the application and if it is in good health.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个重要的话题是，我们的容器代码如何帮助Kubernetes验证每个容器是否准备好与应用程序的其余部分交互，以及它是否处于良好状态。
- en: Readiness, liveness, and startup probes
  id: totrans-591
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 就绪、存活和启动探测
- en: Liveness probes inform Kubernetes when containers are in an unrecoverable faulty
    state, so Kubernetes must kill and restart them. If a container has no liveness
    probe defined for it, Kubernetes restarts it just in case it crashes due to some
    unpredictable exception or because it exceeded its memory limits. Liveness probes
    must be carefully designed to detect actual unrecoverable error situations; otherwise,
    the container might end up in an endless loop of restarts.
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 存活探测通知Kubernetes容器处于不可恢复的故障状态，因此Kubernetes必须杀死并重新启动它们。如果一个容器没有为其定义存活探测，Kubernetes会重新启动它，以防它因某些不可预测的异常或超出其内存限制而崩溃。存活探测必须精心设计，以便检测实际不可恢复的错误情况；否则，容器可能会陷入无限重启的循环。
- en: Temporary failures, instead, are connected to readiness probes. When a readiness
    probe fails, it informs Kubernetes that the container is not able to receive traffic.
    Accordingly, Kubernetes removes the failed container from all the lists of matching
    services that could send traffic to it. This way, traffic is split only among
    the ready containers. The faulty container is not restarted and is reinserted
    in the services list as soon as the readiness probe succeeds again.
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，临时故障与就绪探测相关联。当就绪探测失败时，它通知Kubernetes容器无法接收流量。相应地，Kubernetes将失败的容器从所有可能向其发送流量的匹配服务列表中移除。这样，流量只分配给就绪的容器。故障容器不会被重新启动，一旦就绪探测再次成功，它就会被重新插入服务列表。
- en: Finally, a startup probe informs Kubernetes that the container has completed
    its startup procedure. Its only purpose is avoiding Kubernetes killing and restarting
    the container during startup because of liveness probe failures. In fact, similar
    occurrences might move the container into an endless loop of restarts.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一个启动探测通知Kubernetes容器已完成其启动过程。它的唯一目的是避免在启动期间由于存活探测失败而导致Kubernetes杀死并重新启动容器。实际上，类似的情况可能会使容器陷入无限重启的循环。
- en: Put simply, Kubernetes starts liveness and readiness probes only after the startup
    probe succeeds. Since both liveness and readiness probes already have initial
    delays, startup probes are necessary only in case of very long startup procedures.
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Kubernetes仅在启动探测成功后才会启动存活和就绪探测。由于存活和就绪探测已经具有初始延迟，因此启动探测仅在启动过程非常长的情况下才是必要的。
- en: 'All probes have a **probe operation** that may either fail or succeed, with
    the following parameters:'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 所有探测都有一个**探测操作**，它可能失败或成功，以下参数：
- en: '`failureThreshold`: The number of consecutive times the probe operation must
    fail to consider the probe as failed. If not provided, it defaults to 3.'
  id: totrans-597
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`failureThreshold`: 探测操作必须连续失败多少次才被视为失败。如果没有提供，则默认为3。'
- en: '`successThreshold`: Used only for readiness probes. This is the minimum number
    of consecutive successes for the probe to be considered successful after having
    failed. It defaults to 1.'
  id: totrans-598
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`successThreshold`: 仅用于就绪探测。这是探测在失败后被认为是成功的最小连续成功次数。默认值是1。'
- en: '`initialDelaySeconds`: The time in seconds Kubernetes must wait after the container
    starts before trying the first probe. The default value is 0.'
  id: totrans-599
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`initialDelaySeconds`: Kubernetes在尝试第一次探测之前必须等待容器启动后的时间（以秒为单位）。默认值是0。'
- en: '`periodSeconds`: The time in seconds between two successive probes. The default
    is 10 seconds.'
  id: totrans-600
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`periodSeconds`: 两次连续探测之间的时间（以秒为单位）。默认值为10秒。'
- en: '`timeoutSeconds`: The number of seconds after which the probe times out. The
    default is 1 second.'
  id: totrans-601
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`timeoutSeconds`: 探测超时的秒数。默认是1秒。'
- en: Often, liveness and readiness probes are implemented with the same probe operation,
    but the liveness probe has a greater failure threshold.
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，存活和就绪探测使用相同的探测操作，但存活探测有更高的失败阈值。
- en: Probes are container-level properties, that is, they are on the same level as
    container ports, and `name`.
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 探针是容器级别的属性，即它们与容器端口和 `name` 处于同一级别。
- en: Probe operations may be based on shell commands, HTTP requests, or TCP/IP connection
    attempts.
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 探针操作可能基于 shell 命令、HTTP 请求或 TCP/IP 连接尝试。
- en: 'Probes based on shell commands are defined as:'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 shell 命令的探针定义为：
- en: '[PRE97]'
  id: totrans-606
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: The `command` list contains the command and all its arguments. The operation
    succeeds if it is completed with a `0` status code, that is, if the command completes
    with no errors. In the example above, the command succeeds if the `/tmp/healthy`
    file exists.
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '`command` 列表包含命令及其所有参数。如果操作以 `0` 状态码完成，即命令无错误完成，则操作成功。在上面的例子中，如果 `/tmp/healthy`
    文件存在，则命令成功。'
- en: 'Probes based on TCP/IP connections are defined as:'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 TCP/IP 连接的探针定义为：
- en: '[PRE98]'
  id: totrans-609
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: The operation succeeds if a TCP/connection is successfully established.
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 如果成功建立 TCP 连接，则操作成功。
- en: 'Finally, probes based on HTTP requests are defined as:'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，基于 HTTP 请求的探针定义为：
- en: '[PRE99]'
  id: totrans-612
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '`path` and `port` specify the endpoint path and port. The optional `httpHeaders`
    section lists all HTTP headers that Kubernetes must provide in its request. The
    operation succeeds if the response returns a status code satisfying: `200<=status<400`.'
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: '`path` 和 `port` 指定了端点路径和端口。可选的 `httpHeaders` 部分列出了 Kubernetes 在其请求中必须提供的所有
    HTTP 头。如果响应返回的状态码满足：`200<=status<400`，则操作成功。'
- en: Let’s add a liveness probe to the `RoutesPlanning.yaml` deployment of the *Testing
    the route-matching worker microservice* section. We don’t need a readiness probe,
    since readiness probes only affect services, and we don’t use services since all
    communications are handled by RabbitMQ.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 *测试路由匹配工作微服务* 部分的 `RoutesPlanning.yaml` 部署中添加一个存活探针。我们不需要就绪探针，因为就绪探针仅影响服务，而我们不使用服务，因为所有通信都由
    RabbitMQ 处理。
- en: 'First of all, let’s define the following API in the `Program.cs` file of the
    `RoutesPlanning` project:'
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们在 `RoutesPlanning` 项目的 `Program.cs` 文件中定义以下 API：
- en: '[PRE100]'
  id: totrans-616
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: The code returns an error status if there were at least 6 consecutive failed
    attempts to communicate with RabbitMQ.
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: 如果至少有 6 次连续尝试与 RabbitMQ 通信失败，则代码返回错误状态。
- en: 'In the `RoutesPlanning.yaml` deployment, we must add the code below:'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `RoutesPlanning.yaml` 部署中，我们必须添加以下代码：
- en: '[PRE101]'
  id: totrans-619
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: After this change, if you want, you can retry the whole Minikube test from the
    *Testing the route-matching worker microservice* section.
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 在此更改之后，如果您愿意，可以从 *测试路由匹配工作微服务* 部分重新尝试整个 Minikube 测试。
- en: The next section describes a structured, modular, and efficient way to handle
    the interaction between our cluster and the external world.
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分描述了一种结构化、模块化和高效的方式来处理我们的集群与外部世界的交互。
- en: Ingresses
  id: totrans-622
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 入口
- en: Most microservices applications have several frontend microservices, so exposing
    them with LoadBalancer services would require a different IP address for each
    of them. Moreover, inside of our Kubernetes cluster, we don’t need the burden
    of HTTPS and certificates for each microservice, so the best solution is a unique
    entry point for the whole cluster with a unique IP address that takes care of
    HTTPS communication with the external world while forwarding HTTP communication
    to the services inside of the cluster. Both functionalities are typical of web
    servers.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数微服务应用程序都有几个前端微服务，因此使用 LoadBalancer 服务公开它们将需要为每个微服务分配不同的 IP 地址。此外，在我们的 Kubernetes
    集群内部，我们不需要为每个微服务承担 HTTPS 和证书的负担，因此最佳解决方案是整个集群具有唯一入口点和一个唯一 IP 地址，该地址负责与外部世界的 HTTPS
    通信，同时将 HTTP 通信转发到集群内部的服务。这两种功能都是 Web 服务器的典型特性。
- en: Typically, each IP address has several domain names attached, and a web server
    splits the traffic between several applications according to both the domain name
    and the request path inside each domain. This web server functionality is called
    **virtual hosting**.
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，每个 IP 地址都附有几个域名，并且 Web 服务器根据每个域内的域名和请求路径将流量分配给几个应用程序。这种 Web 服务器功能称为 **虚拟主机**。
- en: The translation between HTTPS and HTTP is a peculiarity of web servers, too.
    It is called **HTTPS termination**.
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: HTTPS 和 HTTP 之间的转换也是 Web 服务器的特性之一。这被称为 **HTTPS 终止**。
- en: Finally, web servers furnish further services, such as request filtering to
    prevent various kinds of attacks. More generally, they understand the HTTP protocol
    and offer HTTP-related services such as access to static files, and various kinds
    of protocol and content negotiations with the client.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Web 服务器提供进一步的服务，例如请求过滤以防止各种类型的攻击。更普遍地说，它们理解 HTTP 协议，并提供与 HTTP 相关的服务，例如对静态文件的访问，以及与客户端的各种协议和内容协商。
- en: On the other hand, LoadBalancer services just handle the lower-level TCP/IP
    protocol and perform some load balancing. Therefore, it would be great to use
    an actual web server to interface our Kubernetes cluster with the external world
    instead of several LoadBalancer services.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，LoadBalancer 服务仅处理底层的 TCP/IP 协议并执行一些负载均衡。因此，使用实际的 Web 服务器来将我们的 Kubernetes
    集群与外部世界接口，而不是使用多个 LoadBalancer 服务，将是非常好的。
- en: Kubernetes offers the possibility to run actual web servers inside of resources
    called **Ingresses**. Ingresses act as interfaces between an actual web server
    and the Kubernetes API, and enable us to configure most web server services with
    a common interface that doesn’t depend on the specific web server that is behind
    the Ingress.
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了在名为 **Ingress** 的资源中运行实际 Web 服务器的可能性。Ingress 作为实际 Web 服务器和 Kubernetes
    API 之间的接口，并允许我们使用一个通用的接口来配置大多数 Web 服务器服务，该接口不依赖于 Ingress 后面的特定 Web 服务器。
- en: 'The following diagram exemplifies how an Ingress splits traffic among all frontend
    microservices inside a Kubernetes cluster:'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图例说明了 Ingress 如何在 Kubernetes 集群内部的所有前端微服务之间分割流量：
- en: '![Figure 8.14: Ingress](img/B31916_08_14.png)'
  id: totrans-630
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.14：Ingress](img/B31916_08_14.png)'
- en: 'Figure 8.14: Ingress'
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14：Ingress
- en: Ingresses can be created in a cluster only after an **Ingress controller** has
    been installed in the cluster. Each Ingress controller installation supplies both
    a specific web server, such as NGINX, and the code that interfaces it with the
    Kubernetes API.
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在集群中安装了 **Ingress 控制器** 之后，才能在集群中创建 Ingress。每个 Ingress 控制器安装都提供特定的 Web 服务器，例如
    NGINX，以及与 Kubernetes API 交互的代码。
- en: The information about the Ingress controller and its settings is provided in
    a resource called `IngressClass`, which is referenced in the actual Ingress definition.
    However, often, Ingress controller installations already define a default `IngressClass`
    class, so there is no need to specify its name inside the ingress definition.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress 控制器和其设置的详细信息包含在一个名为 `IngressClass` 的资源中，该资源在实际的 Ingress 定义中被引用。然而，通常情况下，Ingress
    控制器安装已经定义了一个默认的 `IngressClass` 类，因此无需在 ingress 定义内部指定其名称。
- en: 'Below is how to define an IngressClass:'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何定义 IngressClass：
- en: '[PRE102]'
  id: totrans-635
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: Each class specifies just the controller’s name (`controller`), if it is the
    default class (`…/is-default-class` annotation), and some optional parameters
    that depend on the specific controller.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 每个类仅指定控制器的名称（`controller`），如果是默认类（`…/is-default-class` 注解），以及一些依赖于特定控制器的可选参数。
- en: 'Below is how to define an Ingress:'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何定义一个 Ingress：
- en: '[PRE103]'
  id: totrans-638
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: Some controllers, such as the NGINX-based controller, use annotations placed
    in the metadata section to configure the web server.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 一些控制器，如基于 NGINX 的控制器，使用放置在元数据部分的注解来配置 Web 服务器。
- en: 'HTTPS termination rules (`tls`) are pairs made of a collection of domain names
    and an HTTPS certificate associated to them, where each certificate must be packaged
    as a `tls` secret (see the *Secrets* subsection):'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: HTTPS 终止规则（`tls`）是由域名集合和与其关联的 HTTPS 证书组成的对，其中每个证书都必须打包为一个 `tls` 机密（见 *Secrets*
    子节）：
- en: '[PRE104]'
  id: totrans-641
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: In the example above, each certificate applies just to a single domain, but
    if that domain has subdomains that are secured by the same certificate, we may
    add them to the same certificate list.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，每个证书仅适用于单个域名，但如果该域名有由相同证书保护的所有子域名，我们可能可以将它们添加到同一个证书列表中。
- en: 'There is a virtual hosting rule for each domain, and each of these rules has
    subrules for various paths:'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: 每个域名都有一个虚拟主机规则，每个规则都有针对各种路径的子规则：
- en: '[PRE105]'
  id: totrans-644
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: Domain segments may be replaced by wildcards (`*`). Each `path` subrule specifies
    a service name, and all traffic matching that rule will be sent to that service,
    at the port specified in the rule. The service, in turn, forwards the traffic
    to all matching Pods.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 域段可以用通配符（`*`）替换。每个 `path` 子规则指定一个服务名称，所有匹配该规则的流量都将被发送到该服务，在规则中指定的端口。该服务反过来将流量转发到所有匹配的
    Pods。
- en: If `pathType` is prefix, it will match all request paths that have the specified
    path as a subsegment. Otherwise, a perfect match is required. In the example above,
    the first rule matches all paths since all paths have the empty segment`/`as subsegment.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`pathType`是前缀，则它将匹配所有具有指定路径作为子段的路由请求。否则，需要完全匹配。在上面的例子中，第一个规则匹配所有路径，因为所有路径都有空段`/`作为子段。
- en: If an input request matches more paths, the more specific one (the one containing
    more segments) is preferred.
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个输入请求匹配多个路径，则更具体的路径（包含更多段落的路径）会被优先考虑。
- en: In the next subsection, we will put into practice what we have learned about
    Ingresses with a very simple example in Minikube.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个子节中，我们将通过Minikube中的一个非常简单的示例来实践我们关于Ingress的知识。
- en: Testing Ingresses with Minikube
  id: totrans-649
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Minikube测试Ingress
- en: 'The easiest way to install an NGINX-based Ingress controller in Minikube is
    to enable the `ingress` addon. Therefore, after having started Minikube, let’s
    enable this addon:'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 在Minikube中安装基于NGINX的Ingress控制器最简单的方法是启用`ingress`插件。因此，在启动Minikube之后，让我们启用这个插件：
- en: '[PRE106]'
  id: totrans-651
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: As a result, some Pods are created in the `ingress-nginx` namespace. Let’s check
    it with `kubectl get pods -n ingress-nginx`!
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在`ingress-nginx`命名空间中创建了一些Pod。让我们使用`kubectl get pods -n ingress-nginx`来检查它！
- en: 'The addon installs the same NGINX-based ingress controller used by most Kubernetes
    environments ([https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file](https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file)).
    The installation also automatically creates an `IngressClass` called `nginx`.
    The annotations supported by this controller are listed here: [https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/).'
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 该插件安装了大多数Kubernetes环境使用的相同基于NGINX的Ingress控制器（[https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file](https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file)）。安装还会自动创建一个名为`nginx`的`IngressClass`。此控制器支持的注释在此列出：[https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/)。
- en: The `ch08` folder of the GitHub book repository contains `IngressExampleDeployment.yaml`
    and the `IngressExampleDeployment2.yaml` files. They define two Deployments with
    their associated ClusterIP services. They deploy two different versions of a very
    simple web application that creates a simple HTML page.
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub书籍仓库的`ch08`文件夹包含`IngressExampleDeployment.yaml`和`IngressExampleDeployment2.yaml`文件。它们定义了两个部署及其关联的ClusterIP服务。它们部署了两个不同版本的非常简单的Web应用程序，该应用程序创建了一个简单的HTML页面。
- en: 'As usual, let’s copy the two `.yaml` files in a folder and open a console on
    that folder. As the first step, let’s apply these files:'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，让我们将两个`.yaml`文件复制到一个文件夹中，并在该文件夹上打开一个控制台。作为第一步，让我们应用这些文件：
- en: '[PRE107]'
  id: totrans-656
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Now we will create an ingress that connects the first version of the application
    to `/` and the second version of the application to `/v2`. The names of the ClusterIP
    services of the two deployments are `helloworldingress-service` and `helloworldingress2-service`,
    and both receive on the `8080` port. Therefore, we need to bind the `helloworldingress-service`
    `8080` port to `/` and the `helloworldingress2-service` `8080` port to `/v2`:'
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建一个Ingress，将应用程序的第一个版本连接到`/`，第二个版本连接到`/v2`。两个部署的ClusterIP服务的名称分别是`helloworldingress-service`和`helloworldingress2-service`，并且它们都监听在`8080`端口。因此，我们需要将`helloworldingress-service`的`8080`端口绑定到`/`，将`helloworldingress2-service`的`8080`端口绑定到`/v2`：
- en: '[PRE108]'
  id: totrans-658
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: It is worth pointing out that the host property is empty, so the Ingress doesn’t
    perform any selection based on the domain name, but the microservice selection
    is based just on the path. This was a forced choice since we are experimenting
    on an isolated development machine without the support of a DNS, so we can’t associate
    domain names to IP addresses.
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，主机属性为空，因此Ingress不会根据域名进行任何选择，但微服务选择仅基于路径。这是一个强制选择，因为我们在一个没有DNS支持的隔离开发机器上进行实验，所以我们不能将域名关联到IP地址。
- en: 'Let’s put the above code in a file named `IngressConfiguration.yaml` and let’s
    apply it:'
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将上面的代码放入一个名为`IngressConfiguration.yaml`的文件中，并应用它：
- en: '[PRE109]'
  id: totrans-661
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: In order to connect with the Ingress, we need to open a tunnel with the Minikube
    virtual machine. As usual, open another console and issue the `minikube tunnel`
    command in it. Remember that the tunnel works as long as this window remains open.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与Ingress连接，我们需要通过Minikube虚拟机打开一个隧道。像往常一样，打开另一个控制台并在其中运行`minikube tunnel`命令。记住，只要这个窗口保持打开，隧道就会工作。
- en: 'Now open the browser and go to `http://localhost`. You should see something
    like:'
  id: totrans-663
  prefs: []
  type: TYPE_NORMAL
  zh: 现在打开浏览器并访问`http://localhost`。你应该会看到类似的内容：
- en: '**Hello, world!**'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: '**你好，世界！**'
- en: '**Version: 1.0.0**'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: '**版本：1.0.0**'
- en: '**Hostname: ……**'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: '**主机名：……**'
- en: 'Then go to `http://localhost/v2`. You should see something like:'
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 然后转到`http://localhost/v2`。你应该会看到类似的内容：
- en: '**Hello, world!**'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: '**你好，世界！**'
- en: '**Version: 2.0.0**'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '**版本：2.0.0**'
- en: '**Hostname: ……**'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '**主机名：……**'
- en: We were able to split the traffic between the two applications according to
    the request path!
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够根据请求路径在两个应用程序之间分割流量！
- en: 'When you have finished experimenting, let’s clean up the environment with:'
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成实验后，让我们用以下命令清理环境：
- en: '[PRE110]'
  id: totrans-673
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Finally, let’s stop Minikube with: `minikube stop`.'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们用以下命令停止Minikube：`minikube stop`。
- en: The next subsection explains how to install the same Ingress controller on AKS.
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个子节将解释如何在AKS上安装相同的Ingress控制器。
- en: Using an NGNIX-based Ingress in AKS
  id: totrans-676
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在AKS中使用基于NGNIX的Ingress
- en: 'You can manually install the NGNIX-based Ingress on AKS either with a .`yaml`
    file or with a package manager called Helm. However, then, you should handle complex
    permissions-related configurations to associate a static IP and an Azure DNS zone
    to your AKS cluster. The interested reader can find the complete procedure here:
    [https://medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingress-cert-manager-and-9b4028d762ed](https://medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingress-cert-manager-and-9b4028d762ed).'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在AKS上手动安装基于NGNIX的Ingress，使用`.yaml`文件或使用名为Helm的包管理器。然而，然后，你应该处理与权限相关的复杂配置，将静态IP和Azure
    DNS区域关联到你的AKS集群。感兴趣的读者可以在此处找到完整步骤：[https://medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingress-cert-manager-and-9b4028d762ed](https://medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingress-cert-manager-and-9b4028d762ed)。
- en: 'Luckily, you can let Azure do all of this job for you, because Azure has an
    AKS application routing addon that automatically installs the Ingress for you
    and facilitates all permission configuration. This addon can be enabled on an
    existing cluster with:'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，你可以让Azure为你完成所有这些工作，因为Azure有一个AKS应用程序路由插件，它会自动为你安装Ingress，并简化所有权限配置。此插件可以在现有集群上启用：
- en: '[PRE111]'
  id: totrans-679
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: The addon creates `webapprouting.kubernetes.azure.com` `IngressClass`, which
    you must reference in all your Ingresses.
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 该插件创建`webapprouting.kubernetes.azure.com` `IngressClass`，你必须在所有Ingress中引用它。
- en: An IP address is created whenever you create a new Ingress and remains allocated
    for the lifetime of the Ingress. Moreover, if you create an Azure DNS zone and
    associate it to the addon, the addon will automatically add all needed records
    for all domains defined in the rules of your Ingresses.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: 每次创建新的Ingress时，都会创建一个IP地址，并且在整个Ingress生命周期内保持分配。此外，如果你创建一个Azure DNS区域并将其关联到插件，该插件将自动添加所有需要的记录，以覆盖你的Ingress规则中定义的所有域名。
- en: 'You just need to create an Azure DNS zone with:'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要创建一个Azure DNS区域，使用以下命令：
- en: '[PRE112]'
  id: totrans-683
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'In order to associate this zone to the addon, you need the zone’s unique ID,
    which you can get with:'
  id: totrans-684
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将此区域与插件关联，你需要该区域的唯一ID，你可以通过以下方式获取：
- en: '[PRE113]'
  id: totrans-685
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Now you can attach the zone with:'
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以使用以下命令将区域附加上：
- en: '[PRE114]'
  id: totrans-687
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: After this command, all domain names used in your Ingress’s rules will be automatically
    added to the zone with adequate records. Obviously, you must update your domain
    data in the provider where you bought your domain names. More specifically, you
    must force them to point to the names of the Azure DNS servers that handle your
    zone. You can easily get these DNS server names by going to the newly created
    DNS zone in the Azure portal.
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此命令后，你Ingress规则中使用的所有域名将自动添加到区域中，并带有足够的记录。显然，你必须更新你在购买域名时购买的域名提供商中的域名数据。更具体地说，你必须强制它们指向处理你的区域的Azure
    DNS服务器名称。你可以在Azure门户中访问新创建的DNS区域，轻松获取这些DNS服务器名称。
- en: We have finished our amazing Kubernetes trip. We will return to most of the
    concepts learned about here in most of the remaining chapters, and in particular
    in [*Chapter 11*](Chapter_11.xhtml#_idTextAnchor332)*,* *The Car Sharing App*.
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了我们精彩的Kubernetes之旅。我们将在剩余的大部分章节中回顾在这里学到的许多概念，特别是在[*第11章*](Chapter_11.xhtml#_idTextAnchor332)*，*共享汽车应用程序*。
- en: The next chapter shows how to start a new microservices application smoothly
    and with low costs with the help of Azure Container Apps.
  id: totrans-690
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将展示如何借助Azure Container Apps以低廉的成本顺利启动新的微服务应用程序。
- en: Summary
  id: totrans-691
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about the basics of orchestrators and then learned
    how to install and configure a Kubernetes cluster. More specifically, you learned
    how to interact with a Kubernetes cluster through Kubectl and Kubectl’s main commands.
    Then you learned how to deploy and maintain a microservices application, and how
    to test it locally with the help of Docker and Minikube.
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了编排器的基础知识，然后学习了如何安装和配置 Kubernetes 集群。更具体地说，你学习了如何通过 Kubectl 和 Kubectl
    的主要命令与 Kubernetes 集群交互。然后你学习了如何部署和维护微服务应用程序，以及如何借助 Docker 和 Minikube 在本地进行测试。
- en: You also learned how to interface your Kubernetes cluster with a LoadBalancer
    and with an Ingress, and how to fine-tune it to optimize performance.
  id: totrans-693
  prefs: []
  type: TYPE_NORMAL
  zh: 你还学习了如何将你的 Kubernetes 集群与 LoadBalancer 和 Ingress 进行接口，以及如何微调以优化性能。
- en: All concepts were put into practice with both simple examples and with a more
    complete example taken from the car-sharing case study.
  id: totrans-694
  prefs: []
  type: TYPE_NORMAL
  zh: 所有概念都通过简单的示例和从汽车共享案例研究中取出的更完整的示例进行了实践。
- en: Questions
  id: totrans-695
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why do Kubernetes applications need network disk storage?
  id: totrans-696
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么 Kubernetes 应用需要网络磁盘存储？
- en: Because PODs can’t rely on the disk storage of the nodes where they run, since
    they might be moved to different nodes.
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 POD 不能依赖于它们运行的节点上的磁盘存储，因为它们可能会被移动到不同的节点。
- en: Is it true that if a node containing a Pod of a Deployment with 10 replicas
    crashes, your application will continue running properly?
  id: totrans-698
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一个包含 10 个副本的 Deployment 的 Pod 所在的节点崩溃，你的应用程序是否会继续正常运行？
- en: Yes.
  id: totrans-699
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。
- en: Is it true that if a node containing a Pod of a StatefulSet with 10 replicas
    crashes, your application will continue running properly?
  id: totrans-700
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一个包含 10 个副本的 StatefulSet 的 Pod 所在的节点崩溃，你的应用程序是否会继续正常运行？
- en: Not necessarily.
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 不一定。
- en: Is it true that if a Pod crashes, it is always automatically restarted?
  id: totrans-702
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 Pod 崩溃，它是否总是自动重启？
- en: Yes.
  id: totrans-703
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。
- en: Why do StatefulSets need persistent volume claim templates instead of persistent
    volume claims?
  id: totrans-704
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么 StatefulSet 需要持久卷声明模板而不是持久卷声明？
- en: Because each POD of the StatefulSet needs a different volume.
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 因为每个 StatefulSet 的 POD 需要不同的卷。
- en: What is the utility of persistent volume claims?
  id: totrans-706
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 持久卷声明的效用是什么？
- en: They enable Kubernetes users to request and manage storage resources dynamically,
    decoupling storage provisioning from application deployment.
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 它们使 Kubernetes 用户能够动态地请求和管理存储资源，将存储配置与应用程序部署解耦。
- en: What is more adequate for interfacing an application with three different frontend
    services, a LoadBalancer or an ingress?
  id: totrans-708
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于与三个不同的前端服务接口的应用程序，LoadBalancer 或 Ingress 哪个更合适？
- en: An Ingress. LoadBalancers are adequate just when there is an unique Frontend
    service.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Ingress。当只有一个唯一的 Frontend 服务时，LoadBalancers 是足够的。
- en: What is the most adequate way of passing a connection string to a container
    running in a Pod of a Kubernetes cluster?
  id: totrans-710
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将连接字符串传递给在 Kubernetes 集群的 Pod 中运行的容器的最合适方式是什么？
- en: By using a Kubernetes Secret since it contains sensitive information.
  id: totrans-711
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 Kubernetes Secret，因为它包含敏感信息。
- en: How are HTTPS certificates installed in Ingresses?
  id: totrans-712
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HTTPS 证书是如何安装在 Ingress 中的？
- en: Through a specific type of secret.
  id: totrans-713
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一种特定的秘密类型。
- en: Does standard Kubernetes syntax allow the installation of an HTTPS certificate
    on a LoadBalancer service?
  id: totrans-714
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标准的 Kubernetes 语法是否允许在 LoadBalancer 服务上安装 HTTPS 证书？
- en: No.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 不。
- en: Further reading
  id: totrans-716
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Kubernetes official documentation: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/).'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 官方文档：[https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/).
- en: 'AKS official documentation: [https://learn.microsoft.com/en-us/azure/aks/](https://learn.microsoft.com/en-us/azure/aks/).'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AKS 官方文档：[https://learn.microsoft.com/en-us/azure/aks/](https://learn.microsoft.com/en-us/azure/aks/).
- en: 'Minikube official documentation: [https://minikube.sigs.k8s.io/docs/](https://minikube.sigs.k8s.io/docs/).'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Minikube 官方文档：[https://minikube.sigs.k8s.io/docs/](https://minikube.sigs.k8s.io/docs/).
- en: 'AKS autoscaling: [https://learn.microsoft.com/en-us/azure/aks/cluster-autoscaler?tabs=azure-cli](https://learn.microsoft.com/en-us/azure/aks/cluster-autoscaler?tabs=azure-cli
    )'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AKS 自动扩展：[https://learn.microsoft.com/en-us/azure/aks/cluster-autoscaler?tabs=azure-cli](https://learn.microsoft.com/en-us/azure/aks/cluster-autoscaler?tabs=azure-cli
    )
- en: 'Cloud-independent cluster auto-scalers: [https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/](https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/)'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云无关的集群自动扩展器：[https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/](https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/)
- en: 'Storage classes: [https://kubernetes.io/docs/concepts/storage/storage-classes/](https://kubernetes.io/docs/concepts/storage/storage-classes/).'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '存储类: [https://kubernetes.io/docs/concepts/storage/storage-classes/](https://kubernetes.io/docs/concepts/storage/storage-classes/).'
- en: 'Assigning a static Azure IP address to a LoadBalancer: [https://learn.microsoft.com/en-us/azure/aks/static-ip](https://learn.microsoft.com/en-us/azure/aks/static-ip)'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '将静态 Azure IP 地址分配给 LoadBalancer: [https://learn.microsoft.com/en-us/azure/aks/static-ip](https://learn.microsoft.com/en-us/azure/aks/static-ip)'
- en: 'Example metrics server: [https://github.com/kubernetes-sigs/metrics-server](https://github.com/kubernetes-sigs/metrics-server).'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '示例指标服务器: [https://github.com/kubernetes-sigs/metrics-server](https://github.com/kubernetes-sigs/metrics-server).'
- en: 'NGINX-based Ingress controller: [https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file](https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file)
    .'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '基于 NGINX 的 Ingress 控制器: [https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file](https://github.com/kubernetes/ingress-nginx?tab=readme-ov-file)
    .'
- en: 'Manual installation of NGINX-based Ingress of AKS: [https://medium.com/@anilbidary/](https://www.medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingresscert-manager-and-9b4028d762ed)'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '手动安装基于 NGINX 的 AKS Ingress: [https://medium.com/@anilbidary/](https://www.medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingresscert-manager-and-9b4028d762ed)'
- en: '[domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingresscert-manager-and-9b4028d762ed](https://www.medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingresscert-manager-and-9b4028d762ed)'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基于域名路由的 AKS Azure Kubernetes 服务使用 ingresscert-manager 和 9b4028d762ed](https://www.medium.com/@anilbidary/domain-name-based-routing-on-aks-azure-kubernetes-service-using-ingresscert-manager-and-9b4028d762ed)'
- en: 'Using RabbitMQ Cluster operator: [https://www.rabbitmq.com/kubernetes/operator/using-operator](https://www.rabbitmq.com/kubernetes/operator/using-operator)'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用 RabbitMQ 集群操作符: [https://www.rabbitmq.com/kubernetes/operator/using-operator](https://www.rabbitmq.com/kubernetes/operator/using-operator)'
- en: 'Installing a RabbitMQ Cluster on Kubernetes: [https://www.rabbitmq.com/kubernetes/operator/install-operator](https://www.rabbitmq.com/kubernetes/operator/install-operator).'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在 Kubernetes 上安装 RabbitMQ 集群: [https://www.rabbitmq.com/kubernetes/operator/install-operator](https://www.rabbitmq.com/kubernetes/operator/install-operator).'
- en: Join our community on Discord
  id: totrans-730
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/PSMCSharp](https://packt.link/PSMCSharp)'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/PSMCSharp](https://packt.link/PSMCSharp)'
- en: '![A qr code with black squares  AI-generated content may be incorrect.](img/B31916_Discord-QR-Code.png)'
  id: totrans-733
  prefs: []
  type: TYPE_IMG
  zh: '![带有黑色方块的二维码 AI 生成的内容可能不正确。](img/B31916_Discord-QR-Code.png)'
