<html><head></head><body>
<div id="_idContainer142">
<h1 class="chapter-number" id="_idParaDest-207"><a id="_idTextAnchor206"/><span class="koboSpan" id="kobo.1.1">13</span></h1>
<h1 id="_idParaDest-208"><a id="_idTextAnchor207"/><span class="koboSpan" id="kobo.2.1">Driving Change</span></h1>
<p><span class="koboSpan" id="kobo.3.1">Throughout the book, we have talked about the technical side of observability and discussed how to trace calls, record metrics, report events, or use auto-collected telemetry provided by platforms and libraries. </span><span class="koboSpan" id="kobo.3.2">Here, we’re going to talk about the organizational aspects of implementing </span><span class="No-Break"><span class="koboSpan" id="kobo.4.1">observability solutions.</span></span></p>
<p><span class="koboSpan" id="kobo.5.1">First, we’ll look into the benefits of and reasons for changing your existing solution and discuss associated costs. </span><span class="koboSpan" id="kobo.5.2">Then, we’ll go through the implementation stages and come up with a brief. </span><span class="koboSpan" id="kobo.5.3">Finally, we’ll see how to leverage observability to drive and improve the </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">development process.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">in this chapter, you’ll learn how to do </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.9.1">Decide whether you need a better observability solution and which level is right </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">for you</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Develop an onboarding plan and start </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">implementing it</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Use observability to help with daily </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">development tasks</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.15.1">By the end of this chapter, you should be ready to propose an observability solution and onboarding plan for </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">your organization.</span></span></p>
<h1 id="_idParaDest-209"><a id="_idTextAnchor208"/><span class="koboSpan" id="kobo.17.1">Understanding the importance of observability</span></h1>
<p><span class="koboSpan" id="kobo.18.1">If you’re reading this book, you’re probably</span><a id="_idIndexMarker669"/><span class="koboSpan" id="kobo.19.1"> at least entertaining the idea of improving the observability story of your application. </span><span class="koboSpan" id="kobo.19.2">Maybe it’s hard to understand how customers use your system or it takes a lot of time to understand what exactly went wrong when someone reports an issue. </span><span class="koboSpan" id="kobo.19.3">In the worst case, it takes a lot of time to just notice that the system is unhealthy and users are affected. </span><span class="koboSpan" id="kobo.19.4">Or, maybe you want to minimize such risks in your </span><span class="No-Break"><span class="koboSpan" id="kobo.20.1">future projects.</span></span></p>
<p><span class="koboSpan" id="kobo.21.1">In any case, these pain points brought you here and they should guide you further to find the right observability level and approach for </span><span class="No-Break"><span class="koboSpan" id="kobo.22.1">your system.</span></span></p>
<p><span class="koboSpan" id="kobo.23.1">Even if we clearly see the problem and how it can be solved with better observability, we usually still need to get other people working on the system onboard with this vision. </span><span class="koboSpan" id="kobo.23.2">Astoundingly, they might have quite different feelings about the same problems and might not consider them worthy </span><span class="No-Break"><span class="koboSpan" id="kobo.24.1">of solving.</span></span></p>
<p><span class="koboSpan" id="kobo.25.1">Let me share a few common points I have heard arguing that a problem is </span><span class="No-Break"><span class="koboSpan" id="kobo.26.1">not important:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.27.1">When a customer reports an issue, we can ask for a timestamp and find operations at that time by customer identifier. </span><span class="koboSpan" id="kobo.27.2">Then we can find any suspicious logs, get the request ID, and then find correlated logs on </span><span class="No-Break"><span class="koboSpan" id="kobo.28.1">other services.</span></span></li>
<li><span class="koboSpan" id="kobo.29.1">When we see an issue in production, we open related dashboards and start visually correlating metrics until we can guess what’s broken and then mitigate it. </span><span class="koboSpan" id="kobo.29.2">We have experts and an excellent set of runbooks for </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">typical issues.</span></span></li>
<li><span class="koboSpan" id="kobo.31.1">We can do a user study or customer research to get extensive information on how people use </span><span class="No-Break"><span class="koboSpan" id="kobo.32.1">the system.</span></span></li>
<li><span class="koboSpan" id="kobo.33.1">We ask customers to enable verbose logs and reproduce the problem, then send us logs that we’ll parse based on our expert knowledge of </span><span class="No-Break"><span class="koboSpan" id="kobo.34.1">the system.</span></span></li>
</ul>
<p class="callout-heading"><span class="koboSpan" id="kobo.35.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.36.1">Each of these approaches is totally valid. </span><span class="koboSpan" id="kobo.36.2">They </span><em class="italic"><span class="koboSpan" id="kobo.37.1">already</span></em><span class="koboSpan" id="kobo.38.1"> solve the problem, your team </span><em class="italic"><span class="koboSpan" id="kobo.39.1">already</span></em><span class="koboSpan" id="kobo.40.1"> knows how to use them, and some of them are still necessary and quite useful even with perfect observability solutions </span><span class="No-Break"><span class="koboSpan" id="kobo.41.1">in place.</span></span></p>
<p><span class="koboSpan" id="kobo.42.1">So, essentially, when we consider</span><a id="_idIndexMarker670"/><span class="koboSpan" id="kobo.43.1"> the approach to observability, we need to break the status quo and convince ourselves and our organization that it’s worth it. </span><span class="koboSpan" id="kobo.43.2">To achieve this, we first need to clearly outline the pain points and understand the cost of keeping things as </span><span class="No-Break"><span class="koboSpan" id="kobo.44.1">they are.</span></span></p>
<h2 id="_idParaDest-210"><a id="_idTextAnchor209"/><span class="koboSpan" id="kobo.45.1">The cost of insufficient observability</span></h2>
<p><span class="koboSpan" id="kobo.46.1">Your</span><a id="_idIndexMarker671"/><span class="koboSpan" id="kobo.47.1"> organization</span><a id="_idIndexMarker672"/><span class="koboSpan" id="kobo.48.1"> might already</span><a id="_idIndexMarker673"/><span class="koboSpan" id="kobo.49.1"> have some common</span><a id="_idIndexMarker674"/><span class="koboSpan" id="kobo.50.1"> incident metrics</span><a id="_idIndexMarker675"/><span class="koboSpan" id="kobo.51.1"> in place that we can rely on, such as </span><strong class="bold"><span class="koboSpan" id="kobo.52.1">MTTM</span></strong><span class="koboSpan" id="kobo.53.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.54.1">mean time to mitigate</span></strong><span class="koboSpan" id="kobo.55.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.56.1">MTTR</span></strong><span class="koboSpan" id="kobo.57.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.58.1">mean time to recover</span></strong><span class="koboSpan" id="kobo.59.1">), </span><strong class="bold"><span class="koboSpan" id="kobo.60.1">MTBF</span></strong><span class="koboSpan" id="kobo.61.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.62.1">mean time between failures</span></strong><span class="koboSpan" id="kobo.63.1">), or others. </span><span class="koboSpan" id="kobo.63.2">They are somewhat subjective and depend on what qualifies as an incident, or what recovery means, but roughly show how fast we can investigate incidents and how frequently </span><span class="No-Break"><span class="koboSpan" id="kobo.64.1">they happen.</span></span></p>
<p><span class="koboSpan" id="kobo.65.1">If incidents take a lot of time to resolve and happen frequently, it’s likely that our organization cares deeply about them and would be interested in improving </span><span class="No-Break"><span class="koboSpan" id="kobo.66.1">the situation.</span></span></p>
<p><span class="koboSpan" id="kobo.67.1">Ironically, we need at least some level of observability to notice there is an incident and to measure how long it takes to resolve. </span><span class="koboSpan" id="kobo.67.2">If we don’t have even this in place, we can start to manually track when things get broken and how long it takes us to discover and resolve issues. </span><span class="koboSpan" id="kobo.67.3">However subjective it is, it’s better </span><span class="No-Break"><span class="koboSpan" id="kobo.68.1">than nothing.</span></span></p>
<p><span class="koboSpan" id="kobo.69.1">Some things rarely appear in such metrics directly: how bad is your on-call experience? </span><span class="koboSpan" id="kobo.69.2">How much time does onboarding take before someone can be on-call independently? </span><span class="koboSpan" id="kobo.69.3">How many issues end up closed with something such as “cannot reproduce,” “not enough information,” “probably a network or hardware error”; get lost in ping-pong between teams; or get moved to backlogs and </span><span class="No-Break"><span class="koboSpan" id="kobo.70.1">never resolved?</span></span></p>
<p><span class="koboSpan" id="kobo.71.1">It should be feasible</span><a id="_idIndexMarker676"/><span class="koboSpan" id="kobo.72.1"> to measure some of such things. </span><span class="koboSpan" id="kobo.72.2">For example, we can label issues</span><a id="_idIndexMarker677"/><span class="koboSpan" id="kobo.73.1"> that can’t be investigated further due to a lack of telemetry. </span><span class="koboSpan" id="kobo.73.2">If they represent a significant portion of your bugs, it’s something </span><span class="No-Break"><span class="koboSpan" id="kobo.74.1">worth improving.</span></span></p>
<p><span class="koboSpan" id="kobo.75.1">As a team, you can also do an experiment for a week or two to roughly measure the time spent investigating issues. </span><span class="koboSpan" id="kobo.75.2">How much time does it take to investigate when there is enough data? </span><span class="koboSpan" id="kobo.75.3">Or, how much time is wasted investigating issues and meeting a dead end due to a lack of telemetry or finding a trivial transient </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">network issue?</span></span></p>
<p><span class="koboSpan" id="kobo.77.1">By minimizing the time necessary to find the root cause of an issue, we improve the user experience. </span><span class="koboSpan" id="kobo.77.2">We notice incidents earlier and resolve them faster. </span><span class="koboSpan" id="kobo.77.3">We also improve our work-life balance and focus on creative work instead of grepping megabytes </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">of logs.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.79.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.80.1">There could be other data, such as business analytics, support stats, public reviews, or anything else, showing that a noticeable number of users are leaving us because of unresolved technical issues. </span><span class="koboSpan" id="kobo.80.2">If you need to convince your organization to invest in observability, finding such data and showing how a better observability story can improve things could be a good way to </span><span class="No-Break"><span class="koboSpan" id="kobo.81.1">approach it.</span></span></p>
<p><span class="koboSpan" id="kobo.82.1">So, the first step is to understand whether current tools and processes are effective and have a rough understanding of how better</span><a id="_idIndexMarker678"/><span class="koboSpan" id="kobo.83.1"> observability could improve things. </span><span class="koboSpan" id="kobo.83.2">The next step is to understand</span><a id="_idIndexMarker679"/><span class="koboSpan" id="kobo.84.1"> the cost of </span><span class="No-Break"><span class="koboSpan" id="kobo.85.1">the solution.</span></span></p>
<h2 id="_idParaDest-211"><a id="_idTextAnchor210"/><span class="koboSpan" id="kobo.86.1">The cost of an observability solution</span></h2>
<p><span class="koboSpan" id="kobo.87.1">We can roughly break down</span><a id="_idIndexMarker680"/><span class="koboSpan" id="kobo.88.1"> the costs into two groups: implementation</span><a id="_idIndexMarker681"/><span class="koboSpan" id="kobo.89.1"> and telemetry </span><span class="No-Break"><span class="koboSpan" id="kobo.90.1">backend costs.</span></span></p>
<p><span class="koboSpan" id="kobo.91.1">We need to add instrumentation, tune and customize telemetry collection, learn how to use new tools, create alerts and dashboards, and build new processes around them. </span><span class="koboSpan" id="kobo.91.2">When onboarding a mature and stable system, we should also consider risks – we might break something and temporarily make it </span><span class="No-Break"><span class="koboSpan" id="kobo.92.1">less reliable.</span></span></p>
<p><span class="koboSpan" id="kobo.93.1">As we discussed in </span><a href="B19423_09.xhtml#_idTextAnchor148"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.94.1">Chapter 9</span></em></span></a><span class="koboSpan" id="kobo.95.1">, </span><em class="italic"><span class="koboSpan" id="kobo.96.1">Best Practices</span></em><span class="koboSpan" id="kobo.97.1">, we can always choose the level of detail and amount of customization to help us keep the costs within the </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">given budget.</span></span></p>
<p><span class="koboSpan" id="kobo.99.1">The minimalistic approach would be to start with network-level auto-instrumentation for actively developed services and then add context, customizations, and manual instrumentation as </span><span class="No-Break"><span class="koboSpan" id="kobo.100.1">we go.</span></span></p>
<p><span class="koboSpan" id="kobo.101.1">By using OpenTelemetry and shared instrumentation libraries, we can also rely on vendors to provide common visualizations, alerts, dashboards, queries, and analysis for typical technologies. </span><span class="koboSpan" id="kobo.101.2">As a result, it’s almost free to </span><span class="No-Break"><span class="koboSpan" id="kobo.102.1">get started.</span></span></p>
<h3><span class="koboSpan" id="kobo.103.1">Telemetry backend</span></h3>
<p><span class="koboSpan" id="kobo.104.1">We can host the observability</span><a id="_idIndexMarker682"/><span class="koboSpan" id="kobo.105.1"> stack ourselves or use one of the available platforms. </span><span class="koboSpan" id="kobo.105.2">Either way, there will be recurring costs associated with using </span><span class="No-Break"><span class="koboSpan" id="kobo.106.1">the solution.</span></span></p>
<p><span class="koboSpan" id="kobo.107.1">These costs depend on telemetry volume, retention period, the number of services and instances, and many other factors, including the </span><span class="No-Break"><span class="koboSpan" id="kobo.108.1">support plan.</span></span></p>
<p><span class="koboSpan" id="kobo.109.1">Throughout the book, we have discussed how to optimize telemetry collection while keeping the system observable enough for our needs: traces can be sampled, metrics should have low cardinality, and events and logs can be sampled too or kept in cold but </span><span class="No-Break"><span class="koboSpan" id="kobo.110.1">indexed storage.</span></span></p>
<p><span class="koboSpan" id="kobo.111.1">It’s a good idea to try a few different backends – luckily, many platforms have a free tier or trial period and, most importantly, you can instrument the system once with OpenTelemetry and pump data into multiple backends to compare the experience and get an idea of what the cost of using them would look like. </span><span class="koboSpan" id="kobo.111.2">Once you start relying on a specific backend for alerts or daily tasks, it will be more difficult to switch </span><span class="No-Break"><span class="koboSpan" id="kobo.112.1">between vendors.</span></span></p>
<p><span class="koboSpan" id="kobo.113.1">During this experiment, you will also get a better understanding of the necessary data retention period, sampling rate, and other parameters, and will be able to pick them along with </span><span class="No-Break"><span class="koboSpan" id="kobo.114.1">the vendor.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.115.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.116.1">When running a modern cloud application under scale, it’s not possible to operate it without an observability solution, so it’s not a question of whether you need one but rather how many details you need to collect and which observability vendor out there works best for your system </span><span class="No-Break"><span class="koboSpan" id="kobo.117.1">and budget.</span></span></p>
<p><span class="koboSpan" id="kobo.118.1">Essentially, we can start small and incrementally tune collection to add or remove details, while keeping it within a </span><span class="No-Break"><span class="koboSpan" id="kobo.119.1">reasonable budget.</span></span></p>
<p><span class="koboSpan" id="kobo.120.1">We should also define</span><a id="_idIndexMarker683"/><span class="koboSpan" id="kobo.121.1"> what success means – it could be an MTTR improvement, subjective user experience, on-call engineer happiness, anything else that matters for your organization, or any combination </span><span class="No-Break"><span class="koboSpan" id="kobo.122.1">of these.</span></span></p>
<p><span class="koboSpan" id="kobo.123.1">Let’s now talk more about the implementation details and try to make this journey </span><span class="No-Break"><span class="koboSpan" id="kobo.124.1">less painful.</span></span></p>
<h1 id="_idParaDest-212"><a id="_idTextAnchor211"/><span class="koboSpan" id="kobo.125.1">The onboarding process</span></h1>
<p><span class="koboSpan" id="kobo.126.1">The need for distributed tracing</span><a id="_idIndexMarker684"/><span class="koboSpan" id="kobo.127.1"> and visibility of all parts of the system comes from the complexity of modern applications. </span><span class="koboSpan" id="kobo.127.2">For example, we need to know how a serverless environment interacts with cloud storage to debug configuration issues or optimize performance. </span><span class="koboSpan" id="kobo.127.3">Or, maybe we want to know why certain requests fail in the downstream service without asking someone </span><span class="No-Break"><span class="koboSpan" id="kobo.128.1">to help.</span></span></p>
<p><span class="koboSpan" id="kobo.129.1">To make the most of distributed tracing, we have to onboard the whole system (or at least a significant part of it), making sure all services create correlated and coherent telemetry, write it to a place where different teams can access it, and reuse the same tooling to </span><span class="No-Break"><span class="koboSpan" id="kobo.130.1">do analysis.</span></span></p>
<p><span class="koboSpan" id="kobo.131.1">So, implementing an observability</span><a id="_idIndexMarker685"/><span class="koboSpan" id="kobo.132.1"> solution is an organization-wide effort, and it makes sense to start with a pilot project instrumenting a small part of the system. </span><span class="koboSpan" id="kobo.132.2">Let’s outline its scope </span><span class="No-Break"><span class="koboSpan" id="kobo.133.1">and goals.</span></span></p>
<h2 id="_idParaDest-213"><a id="_idTextAnchor212"/><span class="koboSpan" id="kobo.134.1">The pilot phase</span></h2>
<p><span class="koboSpan" id="kobo.135.1">The goal of this project</span><a id="_idIndexMarker686"/><span class="koboSpan" id="kobo.136.1"> is to get hands-on experience</span><a id="_idIndexMarker687"/><span class="koboSpan" id="kobo.137.1"> with observability, discover any significant technical or process issues early, and better understand the scope and effort needed for the rest of </span><span class="No-Break"><span class="koboSpan" id="kobo.138.1">the system.</span></span></p>
<p><span class="koboSpan" id="kobo.139.1">We’ll need a few (at least two) services</span><a id="_idIndexMarker688"/><span class="koboSpan" id="kobo.140.1"> to </span><span class="No-Break"><span class="koboSpan" id="kobo.141.1">start instrumenting:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.142.1">That are in </span><span class="No-Break"><span class="koboSpan" id="kobo.143.1">active development</span></span></li>
<li><span class="koboSpan" id="kobo.144.1">That interact with </span><span class="No-Break"><span class="koboSpan" id="kobo.145.1">each other</span></span></li>
<li><span class="koboSpan" id="kobo.146.1">That have no (or few) internal dependencies except on </span><span class="No-Break"><span class="koboSpan" id="kobo.147.1">each other</span></span></li>
<li><span class="koboSpan" id="kobo.148.1">That have teams working on them in </span><span class="No-Break"><span class="koboSpan" id="kobo.149.1">close contact</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.150.1">From the technical side, we’ll use this phase to make the </span><span class="No-Break"><span class="koboSpan" id="kobo.151.1">following decisions:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.152.1">Instrumentation SDKs</span></strong><span class="koboSpan" id="kobo.153.1">: I hope I convinced you to use .NET platform</span><a id="_idIndexMarker689"/><span class="koboSpan" id="kobo.154.1"> capabilities and OpenTelemetry, but you probably need to decide what to do with existing instrumentation code </span><span class="No-Break"><span class="koboSpan" id="kobo.155.1">and tooling.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.156.1">Context propagation standards</span></strong><span class="koboSpan" id="kobo.157.1">: Using W3C Trace Context would be a good start. </span><span class="koboSpan" id="kobo.157.2">We may also need to decide whether and how to propagate baggage, or how to pass context over </span><span class="No-Break"><span class="koboSpan" id="kobo.158.1">non-HTTP/proprietary protocols.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.159.1">Sampling strategy</span></strong><span class="koboSpan" id="kobo.160.1">: Rate-based, percentage-based, parent-based, tail-based – these are good things</span><a id="_idIndexMarker690"/><span class="koboSpan" id="kobo.161.1"> to decide early on and identify whether you need an OpenTelemetry collector or can rely on an </span><span class="No-Break"><span class="koboSpan" id="kobo.162.1">observability vendor.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.163.1">Which vendor to use and a migration plan from your current one</span></strong><span class="koboSpan" id="kobo.164.1">: We’ll discuss technical aspects and trade-offs when instrumenting existing systems in </span><a href="B19423_15.xhtml#_idTextAnchor233"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.165.1">Chapter 15</span></em></span></a><span class="koboSpan" id="kobo.166.1">, </span><em class="italic"><span class="koboSpan" id="kobo.167.1">Instrumenting </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.168.1">Brownfield Applications</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.169.1">.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.170.1">By the end of the pilot phase, we should have a clear understanding of what onboarding takes, what the challenges are, and how we will </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">solve them.</span></span></p>
<p><span class="koboSpan" id="kobo.172.1">We will also have</span><a id="_idIndexMarker691"/><span class="koboSpan" id="kobo.173.1"> a small part of the system instrumented – it’s a good time to check whether we see </span><span class="No-Break"><span class="koboSpan" id="kobo.174.1">any improvement.</span></span></p>
<h3><span class="koboSpan" id="kobo.175.1">Tracking progress</span></h3>
<p><span class="koboSpan" id="kobo.176.1">In the perfect world, after instrumentation</span><a id="_idIndexMarker692"/><span class="koboSpan" id="kobo.177.1"> is deployed, we’d be able to resolve all incidents in no time and investigate all the tricky bugs we’ve hunted down for months. </span><span class="koboSpan" id="kobo.177.2">I wish that was </span><span class="No-Break"><span class="koboSpan" id="kobo.178.1">the case.</span></span></p>
<p><span class="koboSpan" id="kobo.179.1">There are at least several challenges along </span><span class="No-Break"><span class="koboSpan" id="kobo.180.1">the way:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.181.1">Change is hard</span></strong><span class="koboSpan" id="kobo.182.1">: People prefer to use tools they know well, especially when they’re dealing with incidents in production. </span><span class="koboSpan" id="kobo.182.2">It would be a good exercise to do the same investigation with the new observability solution after the incident is resolved and compare </span><span class="No-Break"><span class="koboSpan" id="kobo.183.1">the experiences.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.184.1">It’s best to start playing with new tools at development time or when investigating low-priority failures. </span><span class="koboSpan" id="kobo.184.2">In any case, it takes time and practice to learn about and trust </span><span class="No-Break"><span class="koboSpan" id="kobo.185.1">new tools.</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.186.1">You’ll discover new issues</span></strong><span class="koboSpan" id="kobo.187.1">: Looking at traces or a service map for the first time, I always learn something new about my code. </span><span class="koboSpan" id="kobo.187.2">It’s common to discover calls to external systems you didn’t expect (for example, auth calls made under the hood), unnecessary network calls, wrong retry logic, calls that should run in parallel but run sequentially, and </span><span class="No-Break"><span class="koboSpan" id="kobo.188.1">so on.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.189.1">Basic auto-instrumentation is not sufficient</span></strong><span class="koboSpan" id="kobo.190.1">: Without application context or manual instrumentation for certain libraries and scenarios, our ability to find, understand, and aggregate related telemetry </span><span class="No-Break"><span class="koboSpan" id="kobo.191.1">is limited.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.192.1">It will take a few iterations to see an improvement – make sure to collect feedback and understand what’s working and </span><span class="No-Break"><span class="koboSpan" id="kobo.193.1">what’s not.</span></span></p>
<p><span class="koboSpan" id="kobo.194.1">It also takes time and dedication</span><a id="_idIndexMarker693"/><span class="koboSpan" id="kobo.195.1">. </span><span class="koboSpan" id="kobo.195.2">Demos, success stories, shared case studies, and documentation on how to get started should create awareness and help people get curious and </span><span class="No-Break"><span class="koboSpan" id="kobo.196.1">learn faster.</span></span></p>
<h3><span class="koboSpan" id="kobo.197.1">Iterating</span></h3>
<p><span class="koboSpan" id="kobo.198.1">So, after the initial instrumentation, we’re not quite</span><a id="_idIndexMarker694"/><span class="koboSpan" id="kobo.199.1"> ready to roll it out to the rest of the system. </span><span class="koboSpan" id="kobo.199.2">Here’re a few things to </span><span class="No-Break"><span class="koboSpan" id="kobo.200.1">do first:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.201.1">Tune instrumentation libraries</span></strong><span class="koboSpan" id="kobo.202.1">: Remove verbose and noisy signals or enable useful attributes that are off by default. </span><span class="koboSpan" id="kobo.202.2">If some parts of your stack don’t have auto-instrumentation available, start writing </span><span class="No-Break"><span class="koboSpan" id="kobo.203.1">your own.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.204.1">Add essential application context</span></strong><span class="koboSpan" id="kobo.205.1">: Finding common properties and standardizing attribute names or baggage keys across your organization will have a huge impact down the road. </span><span class="koboSpan" id="kobo.205.2">We’ll talk more about it in </span><a href="B19423_14.xhtml#_idTextAnchor220"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.206.1">Chapter 14</span></em></span></a><span class="koboSpan" id="kobo.207.1">, </span><em class="italic"><span class="koboSpan" id="kobo.208.1">Creating Your </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.209.1">Own Conventions</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.210.1">.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.211.1">Start building backend-specific tooling</span></strong><span class="koboSpan" id="kobo.212.1">: Alerts, dashboards, and workbooks will help us validate whether we have enough context and telemetry to run our system and migrate to the </span><span class="No-Break"><span class="koboSpan" id="kobo.213.1">new solution.</span></span></li>
</ul>
<p class="callout-heading"><span class="koboSpan" id="kobo.214.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.215.1">By the end of this stage, you should be able to see positive outcomes. </span><span class="koboSpan" id="kobo.215.2">It probably will not yet have moved the needle for the whole system, and there might not be enough data for the services involved in the experiment, but you should at least see some success stories and be able to show examples of where the new </span><span class="No-Break"><span class="koboSpan" id="kobo.216.1">solution shone.</span></span></p>
<p><span class="koboSpan" id="kobo.217.1">If you see cases where the new observability story should have helped but has not, it is a good idea to investigate why and tune instrumentation further. </span><span class="koboSpan" id="kobo.217.2">While iterating, it’s also worth paying attention to backend costs and optimizing telemetry collection if you see the potential for a significant reduction without </span><span class="No-Break"><span class="koboSpan" id="kobo.218.1">noticeable impact.</span></span></p>
<p><span class="koboSpan" id="kobo.219.1">The goal here is to create a good enough instrumentation approach and any necessary tooling around it. </span><span class="koboSpan" id="kobo.219.2">We iterate fast and keep the number of participating services small so we can still change direction and make </span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">breaking changes.</span></span></p>
<p><span class="koboSpan" id="kobo.221.1">Once we have finalized all the decisions</span><a id="_idIndexMarker695"/><span class="koboSpan" id="kobo.222.1"> and implemented and validated them on a small part of the system, we should be able to rely on new observability solutions for most of the monitoring and debugging needs. </span><span class="koboSpan" id="kobo.222.2">Before we roll them out, we still need to document them and create </span><span class="No-Break"><span class="koboSpan" id="kobo.223.1">reusable artifacts.</span></span></p>
<h3><span class="koboSpan" id="kobo.224.1">Documenting and standardizing</span></h3>
<p><span class="koboSpan" id="kobo.225.1">The main outcome</span><a id="_idIndexMarker696"/><span class="koboSpan" id="kobo.226.1"> of the pilot phase</span><a id="_idIndexMarker697"/><span class="koboSpan" id="kobo.227.1"> is clarity on how to make the rest of the system observable and the specific benefits it </span><span class="No-Break"><span class="koboSpan" id="kobo.228.1">will bring.</span></span></p>
<p><span class="koboSpan" id="kobo.229.1">To maximize the impact of this phase, we need to make it easier for other services to be onboarded. </span><span class="koboSpan" id="kobo.229.2">We can help them by doing </span><span class="No-Break"><span class="koboSpan" id="kobo.230.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.231.1">Documenting new solutions </span><span class="No-Break"><span class="koboSpan" id="kobo.232.1">and processes</span></span></li>
<li><span class="koboSpan" id="kobo.233.1">Providing demos and starters showing how to use backends and configure them, and add alerts </span><span class="No-Break"><span class="koboSpan" id="kobo.234.1">and dashboards</span></span></li>
<li><span class="koboSpan" id="kobo.235.1">Producing common artifacts that include </span><span class="No-Break"><span class="koboSpan" id="kobo.236.1">any customizations:</span></span><ul><li><span class="koboSpan" id="kobo.237.1">Context propagators, samplers, </span><span class="No-Break"><span class="koboSpan" id="kobo.238.1">or instrumentations</span></span></li><li><span class="koboSpan" id="kobo.239.1">Attribute names or helpers that efficiently </span><span class="No-Break"><span class="koboSpan" id="kobo.240.1">populate them</span></span></li><li><span class="koboSpan" id="kobo.241.1">Starter packs that bring all OpenTelemetry dependencies and enable telemetry collection in a </span><span class="No-Break"><span class="koboSpan" id="kobo.242.1">uniform manner</span></span></li><li><span class="koboSpan" id="kobo.243.1">Common </span><span class="No-Break"><span class="koboSpan" id="kobo.244.1">configuration options</span></span></li></ul></li>
</ul>
<p><span class="koboSpan" id="kobo.245.1">Finally, we’re ready to instrument and onboard the rest of the system. </span><span class="koboSpan" id="kobo.245.2">It will probably take some time to align attribute names, configuration, or backend plans. </span><span class="koboSpan" id="kobo.245.3">We also need to keep tracking progress toward original goals and apply necessary changes when things don’t work. </span><span class="koboSpan" id="kobo.245.4">Let’s talk about a few things that can slow </span><span class="No-Break"><span class="koboSpan" id="kobo.246.1">us down.</span></span></p>
<h2 id="_idParaDest-214"><a id="_idTextAnchor213"/><span class="koboSpan" id="kobo.247.1">Avoiding pitfalls</span></h2>
<p><span class="koboSpan" id="kobo.248.1">The challenge with distributed tracing</span><a id="_idIndexMarker698"/><span class="koboSpan" id="kobo.249.1"> and observability is that they’re most effective when a distributed application produces coherent signals: trace context is propagated, sampling algorithms are aligned to produce full traces, all signals use the same attribute names, and </span><span class="No-Break"><span class="koboSpan" id="kobo.250.1">so on.</span></span></p>
<p><span class="koboSpan" id="kobo.251.1">While OpenTelemetry solves most of these concerns, it still relies on the application to bring all the pieces together and use coherent signals. </span><span class="koboSpan" id="kobo.251.2">It becomes a problem for huge organizations where one service deviating from the standard breaks the correlation for the rest of </span><span class="No-Break"><span class="koboSpan" id="kobo.252.1">the system.</span></span></p>
<p><span class="koboSpan" id="kobo.253.1">Here are a few things to avoid when onboarding </span><span class="No-Break"><span class="koboSpan" id="kobo.254.1">your system:</span></span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.255.1">Starting too big</span></strong><span class="koboSpan" id="kobo.256.1">: If multiple teams work on instrumentation independently, they will inevitably develop different solutions optimized for their services. </span><span class="koboSpan" id="kobo.256.2">Aligning these solutions after onboarding is finalized would be a difficult project on its own. </span><span class="koboSpan" id="kobo.256.3">Each team would have an impression that things work for them, but end-to-end customer issues would still take months </span><span class="No-Break"><span class="koboSpan" id="kobo.257.1">to resolve.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.258.1">Not sharing telemetry across the system</span></strong><span class="koboSpan" id="kobo.259.1">: When investigating issues or analyzing performance and usage, it’s beneficial to be able to see how other services process requests. </span><span class="koboSpan" id="kobo.259.2">Without doing so, we will end up in the same place where each cross-service problem involves some amount of ping-pong and problems are not resolved </span><span class="No-Break"><span class="koboSpan" id="kobo.260.1">fast enough.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.261.1">Not enforcing standards</span></strong><span class="koboSpan" id="kobo.262.1">: Inconsistent telemetry would make us come back to grepping logs and make customers and </span><span class="No-Break"><span class="koboSpan" id="kobo.263.1">ourselves unhappy.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.264.1">Not using new tools and capabilities</span></strong><span class="koboSpan" id="kobo.265.1">: We talked about how migrating from familiar tooling is hard. </span><span class="koboSpan" id="kobo.265.2">We need to put enough effort into advocating, promoting, explaining, documenting, and improving things to make sure people use them. </span><span class="koboSpan" id="kobo.265.3">Sunsetting old tools, once new ones are more capable and fast, is one (sometimes unpopular) way to make sure </span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">everyone switches.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.267.1">Not using the observability stack at development or test time</span></strong><span class="koboSpan" id="kobo.268.1">: Investigating flaky tests is one of the cheapest ways to debug tricky issues. </span><span class="koboSpan" id="kobo.268.2">Traces can help a lot, so make sure tests send traces and logs by default and it’s super easy to enable tracing on </span><span class="No-Break"><span class="koboSpan" id="kobo.269.1">dev machines.</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.270.1">Building things that are hard to use or not reliable</span></strong><span class="koboSpan" id="kobo.271.1">: While some friction is expected, we should make sure most of it happens during the pilot phase. </span><span class="koboSpan" id="kobo.271.2">If you decide to build your own observability stack based on OSS solutions, you should expect that certain things such as navigating across tools will be difficult and you’ll need to put a decent amount of effort into making them usable. </span><span class="koboSpan" id="kobo.271.3">Another big investment is building and maintaining reliable </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">telemetry pipelines.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.273.1">Hopefully, we can avoid most of these issues and onboard a significant part of the system onto our new </span><span class="No-Break"><span class="koboSpan" id="kobo.274.1">observability stack.</span></span></p>
<p><span class="koboSpan" id="kobo.275.1">As we continue onboarding, we should see improvement toward our initial goals and may need to adjust them. </span><span class="koboSpan" id="kobo.275.2">During the process, we probably learned a lot about our system and are now dealing with new challenges we could not see before due to a lack </span><span class="No-Break"><span class="koboSpan" id="kobo.276.1">of observability.</span></span></p>
<p><span class="koboSpan" id="kobo.277.1">The journey does</span><a id="_idIndexMarker699"/><span class="koboSpan" id="kobo.278.1"> not end here. </span><span class="koboSpan" id="kobo.278.2">In the same way that we never stop writing tests, we should incorporate and leverage observability in </span><span class="No-Break"><span class="koboSpan" id="kobo.279.1">day-to-day tasks.</span></span></p>
<h1 id="_idParaDest-215"><a id="_idTextAnchor214"/><span class="koboSpan" id="kobo.280.1">Continuous observability</span></h1>
<p><span class="koboSpan" id="kobo.281.1">Observability should not be added as an afterthought</span><a id="_idIndexMarker700"/><span class="koboSpan" id="kobo.282.1"> when service or feature development is over. </span><span class="koboSpan" id="kobo.282.2">When implementing a complex feature across several services or just adding a new external dependency, we can’t rely on users telling us when it’s broken. </span><span class="koboSpan" id="kobo.282.3">Tests usually don’t cover every aspect and don’t represent </span><span class="No-Break"><span class="koboSpan" id="kobo.283.1">user behavior.</span></span></p>
<p><span class="koboSpan" id="kobo.284.1">If we don’t have a reliable telemetry signal, we can’t say whether the feature works or whether customers </span><span class="No-Break"><span class="koboSpan" id="kobo.285.1">use it.</span></span></p>
<h2 id="_idParaDest-216"><a id="_idTextAnchor215"/><span class="koboSpan" id="kobo.286.1">Incorporating observability into the design process</span></h2>
<p><span class="koboSpan" id="kobo.287.1">Making sure we have telemetry</span><a id="_idIndexMarker701"/><span class="koboSpan" id="kobo.288.1"> in place is part of feature</span><a id="_idIndexMarker702"/><span class="koboSpan" id="kobo.289.1"> design work. </span><span class="koboSpan" id="kobo.289.2">The main questions the telemetry should answer are </span><span class="No-Break"><span class="koboSpan" id="kobo.290.1">the following:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.291.1">Who uses this feature and </span><span class="No-Break"><span class="koboSpan" id="kobo.292.1">how much?</span></span></li>
<li><span class="koboSpan" id="kobo.293.1">Does it work? </span><span class="koboSpan" id="kobo.293.2">Does it break </span><span class="No-Break"><span class="koboSpan" id="kobo.294.1">something else?</span></span></li>
<li><span class="koboSpan" id="kobo.295.1">Does it work as expected? </span><span class="koboSpan" id="kobo.295.2">Does it improve things </span><span class="No-Break"><span class="koboSpan" id="kobo.296.1">as expected?</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.297.1">If we can rely on the existing telemetry to answer these questions, awesome! </span></p>
<p><span class="koboSpan" id="kobo.298.1">We should design instrumentation in a way that covers multiple things at once. </span><span class="koboSpan" id="kobo.298.2">For example, when we switch from one external HTTP dependency to a new one, we can leverage existing auto-collected traces and metrics. </span><span class="koboSpan" id="kobo.298.3">A common processor that stamps application context on all spans will take care of traces from the new dependency </span><span class="No-Break"><span class="koboSpan" id="kobo.299.1">as well.</span></span></p>
<p><span class="koboSpan" id="kobo.300.1">If we use feature flags, we should make sure we record them on telemetry for operations that participate in an experiment. </span><span class="koboSpan" id="kobo.300.2">We can record them on events or spans, for example, following OpenTelemetry semantic conventions for feature flags available </span><span class="No-Break"><span class="koboSpan" id="kobo.301.1">at </span></span><a href="https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/semantic_conventions/feature-flags.md"><span class="No-Break"><span class="koboSpan" id="kobo.302.1">https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/semantic_conventions/feature-flags.md</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.303.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.304.1">In some cases, default telemetry is not sufficient and we need to add custom events, traces, metrics, or at least extra attributes. </span><span class="koboSpan" id="kobo.304.2">It’s rarely a good idea to limit instrumentation to a new log record unless we write it in a structured and </span><span class="No-Break"><span class="koboSpan" id="kobo.305.1">aggregable way.</span></span></p>
<p><span class="koboSpan" id="kobo.306.1">Once a feature is proven useful and fully rolled</span><a id="_idIndexMarker703"/><span class="koboSpan" id="kobo.307.1"> out, we might want to remove</span><a id="_idIndexMarker704"/><span class="koboSpan" id="kobo.308.1"> this additional telemetry along with the feature flag. </span><span class="koboSpan" id="kobo.308.2">It’s a great approach if we’re sure it’s not necessary anymore. </span><span class="koboSpan" id="kobo.308.3">Cleaning up and iterating on instrumentation is another </span><span class="No-Break"><span class="koboSpan" id="kobo.309.1">important aspect.</span></span></p>
<h2 id="_idParaDest-217"><a id="_idTextAnchor216"/><span class="koboSpan" id="kobo.310.1">Housekeeping</span></h2>
<p><span class="koboSpan" id="kobo.311.1">As with any other code, instrumentation code degrades and becomes less useful </span><span class="No-Break"><span class="koboSpan" id="kobo.312.1">when neglected.</span></span></p>
<p><span class="koboSpan" id="kobo.313.1">Similar to the test code, any observability code</span><a id="_idIndexMarker705"/><span class="koboSpan" id="kobo.314.1"> we write is less reliable than application code – it’s also hard to notice when it reports something incorrect as there is no functional issue. </span><span class="koboSpan" id="kobo.314.2">So, validating it with testing or manual checks and fixing it in a timely manner </span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">is important.</span></span></p>
<p><span class="koboSpan" id="kobo.316.1">This is one of the reasons to use popular</span><a id="_idIndexMarker706"/><span class="koboSpan" id="kobo.317.1"> instrumentation libraries – they have been through excessive testing by other people. </span><span class="koboSpan" id="kobo.317.2">Keeping your instrumentation libraries up to date and sharing custom ones across the company (or open sourcing them) will result in better </span><span class="No-Break"><span class="koboSpan" id="kobo.318.1">instrumentation quality.</span></span></p>
<p><span class="koboSpan" id="kobo.319.1">Another important part is to make small improvements as you notice issues: add missing events, spans, and attributes (don’t forget to check if there is a common one), structure and optimize logs, and adjust </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">their verbosity.</span></span></p>
<p><span class="koboSpan" id="kobo.321.1">These changes might be risky. </span><span class="koboSpan" id="kobo.321.2">We might remove something that people rely on for alerting or analysis. </span><span class="koboSpan" id="kobo.321.3">There could be some additional guards in place that prevent it – code reviews, documentation, and tests, but it is rarely possible to account for everything, so be cautious when removing or </span><span class="No-Break"><span class="koboSpan" id="kobo.322.1">renaming things.</span></span></p>
<p><span class="koboSpan" id="kobo.323.1">Another risk is adding something expensive or verbose that would either impact application availability, overwhelm telemetry pipelines, or significantly increase your observability bill. </span><span class="koboSpan" id="kobo.323.2">Paying attention to the dev and test telemetry and knowing what’s on the hot path should prevent </span><span class="No-Break"><span class="koboSpan" id="kobo.324.1">obvious mistakes.</span></span></p>
<p><span class="koboSpan" id="kobo.325.1">Building reliable telemetry pipelines with rate-limiting should decrease the severity of such incidents when they make it </span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">to production.</span></span></p>
<p><span class="koboSpan" id="kobo.327.1">As you can see, observability code</span><a id="_idIndexMarker707"/><span class="koboSpan" id="kobo.328.1"> is not very different from any other piece of infrastructure. </span><span class="koboSpan" id="kobo.328.2">Implementing it starts with some research and experiments and works best when we tune and improve it along with </span><span class="No-Break"><span class="koboSpan" id="kobo.329.1">our application.</span></span></p>
<h1 id="_idParaDest-218"><a id="_idTextAnchor217"/><span class="koboSpan" id="kobo.330.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.331.1">In this chapter, we discussed how to implement and roll out observability solutions in your organization. </span><span class="koboSpan" id="kobo.331.2">These efforts can be motivated and justified by the current monitoring infrastructure not being efficient in investigating and resolving </span><span class="No-Break"><span class="koboSpan" id="kobo.332.1">customer issues.</span></span></p>
<p><span class="koboSpan" id="kobo.333.1">We discussed how we can rely on existing metrics or data to understand whether there is room for improvement and estimate the cost of inaction. </span><span class="koboSpan" id="kobo.333.2">Then we looked into common costs associated with implementing and running a modern observability solution – the easiest way to find out is to run a small experiment and compare </span><span class="No-Break"><span class="koboSpan" id="kobo.334.1">different vendors.</span></span></p>
<p><span class="koboSpan" id="kobo.335.1">We explored how we can approach onboarding by starting with a pilot project on a small part of the system and iterating and validating results before we roll it out to the rest of the system. </span><span class="koboSpan" id="kobo.335.2">Finally, we discussed the importance of incorporating observability into daily tasks and evolving it along with </span><span class="No-Break"><span class="koboSpan" id="kobo.336.1">the code.</span></span></p>
<p><span class="koboSpan" id="kobo.337.1">This chapter should help you justify initial observability investments and gradually implement the solution across the system. </span><span class="koboSpan" id="kobo.337.2">In the next chapter, we’ll talk more about unifying telemetry collection and introducing your </span><span class="No-Break"><span class="koboSpan" id="kobo.338.1">own standards.</span></span></p>
<h1 id="_idParaDest-219"><a id="_idTextAnchor218"/><span class="koboSpan" id="kobo.339.1">Questions</span></h1>
<ol>
<li><span class="koboSpan" id="kobo.340.1">Should we look for a single backend for all telemetry signals or a combination of them optimized for individual </span><span class="No-Break"><span class="koboSpan" id="kobo.341.1">telemetry signals?</span></span></li>
<li><span class="koboSpan" id="kobo.342.1">How would you approach standardizing baggage propagation and usage in </span><span class="No-Break"><span class="koboSpan" id="kobo.343.1">your system?</span></span></li>
<li><span class="koboSpan" id="kobo.344.1">You’re adding a cache to the service. </span><span class="koboSpan" id="kobo.344.2">When would you add instrumentation? </span><span class="koboSpan" id="kobo.344.3">How would you </span><span class="No-Break"><span class="koboSpan" id="kobo.345.1">approach it?</span></span></li>
</ol>
<h1 id="_idParaDest-220"><a id="_idTextAnchor219"/><span class="koboSpan" id="kobo.346.1">Further reading</span></h1>
<ul>
<li><em class="italic"><span class="koboSpan" id="kobo.347.1">Becoming a Rockstar SRE</span></em><span class="koboSpan" id="kobo.348.1"> by Jeremy Proffitt and </span><span class="No-Break"><span class="koboSpan" id="kobo.349.1">Rod Anami</span></span></li>
</ul>
</div>
</body></html>