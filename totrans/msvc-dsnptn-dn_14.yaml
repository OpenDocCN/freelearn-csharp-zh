- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Implementing Centralized Logging for Microservices
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施微服务的集中式日志记录
- en: One of the biggest challenges with APIs is the fact that we rarely get actual
    feedback on what is happening in our service. We do our best to design our services
    in a way that our HTTP responses indicate the success or failure of each operation,
    but this is not always enough. The most concerning types of responses are those
    in the 5xx range, without any useful information behind them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 与API相关的一个最大挑战是我们很少得到关于服务中实际发生情况的反馈。我们尽最大努力设计我们的服务，使HTTP响应指示每个操作的成败，但这并不总是足够。最令人担忧的是5xx范围内的响应，它们后面没有任何有用的信息。
- en: For this reason, we need to employ logging in our microservices application.
    Logging produces real-time information on the operations and events occurring
    in the service. Each log message helps us to understand the behavior of the application
    and aids with our investigations when things go wrong. So, the logs are the first
    line of defense against the ambiguous 5xx HTTP responses.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要在我们的微服务应用程序中采用日志记录。日志记录提供了关于服务中发生的操作和事件的实时信息。每条日志消息都帮助我们理解应用程序的行为，并在出现问题时协助我们的调查。因此，日志是应对模糊的5xx
    HTTP响应的第一道防线。
- en: During development, logs help us to contextualize some of the issues that we
    face and give us, when implemented well, a play-by-play sequence of the functions
    being called and their output. This will help us to more easily discern where
    our code might be breaking or why a function’s output is less than desired.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中，日志帮助我们理解我们面临的一些问题，并且当实施得当，可以提供被调用函数及其输出的逐点记录。这将帮助我们更容易地发现代码可能出错的地方，或者为什么函数的输出不符合预期。
- en: In the case of a distributed application, we need to implement special measures
    that help us to centralize the logs being produced by the individual services.
    Yes, we are promoting autonomy in this kind of architecture, but all the components
    still combine to produce one application. This makes the point of failure more
    difficult to find if we need to sift through several log files and sources.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式应用程序的情况下，我们需要实施特殊措施，帮助我们集中管理由各个服务产生的日志。是的，我们在这种架构中推广自主性，但所有组件仍然组合在一起形成一个应用程序。这使得当需要筛选多个日志文件和来源时，故障点更难找到。
- en: 'After reading this chapter, we will be able to do the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章之后，我们将能够做到以下几点：
- en: Understand the use of log aggregation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解日志聚合的使用
- en: Know how to implement performance monitoring
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解如何实现性能监控
- en: Know how to implement distributed tracing
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解如何实现分布式跟踪
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code references used in this chapter can be found in this project’s repository,
    which is hosted on GitHub at [https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch14](https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch14).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的代码示例可以在本项目的GitHub仓库中找到，该仓库托管在[https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch14](https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch14)。
- en: Logging and its importance
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志及其重要性
- en: Logs are blocks of text that most applications produce during runtime. They
    are designed to be human-readable mini-reports about what is happening in the
    application, and they should allow us to be able to track and trace errors that
    occur in our applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 日志是大多数应用程序在运行时产生的文本块。它们被设计成关于应用程序中发生情况的易于阅读的迷你报告，并且应该允许我们跟踪和追踪应用程序中发生的错误。
- en: In a monolithic application, we typically write logs to a log file or a database.
    In fact, in .NET Core, we have access to powerful logging providers and third-party
    libraries that allow us to integrate with several log output destinations. There
    is no real best destination and while some work better than ours, it is a matter
    of project preference and overall comfort. Our monolithic logs contain information
    about everything happening in one application.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在单体应用程序中，我们通常将日志写入日志文件或数据库。实际上，在.NET Core中，我们有访问强大的日志提供程序和第三方库的权限，允许我们与多个日志输出目标集成。没有真正的最佳目标，尽管有些比我们的更好，但这取决于项目偏好和整体舒适度。我们的单体日志包含有关一个应用程序中发生的一切信息。
- en: In a distributed system, this becomes more complex since we have activities
    happening across several applications. The first inclination is to create logs
    per service, which might result in several log files, each containing bits of
    the overall information that we need to see for the application. Imagine needing
    to visit several log files to investigate a failure that occurred at 5:00 P.M.
    To understand this failure, we will need to review several sources to piece together
    anything sensible, which can be a difficult task.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统中，这变得更加复杂，因为我们有多个应用中发生活动。第一个倾向是按服务创建日志，这可能会导致多个日志文件，每个文件都包含我们需要查看的整体信息的一部分。想象一下，需要访问多个日志文件来调查下午5点发生的一个故障。为了理解这个故障，我们需要审查多个来源来拼凑出任何有意义的线索，这可能是一项艰巨的任务。
- en: This investigation gets even more difficult if our logs are too verbose. A verbose
    log reports everything that occurs in the application. Even if we don’t report
    everything, we need to be pointed with what we log to reduce the noise and better
    highlight the key events that need to be captured.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的日志过于冗长，这项调查将变得更加困难。冗长的日志会报告应用中发生的所有事件。即使我们不报告所有内容，我们也需要明确我们记录的内容，以减少噪音并更好地突出需要捕获的关键事件。
- en: We will then need a clean way to centralize the logs that are generated across
    the services. A centralized database may seem like a good idea, but it may lead
    to resource and table locking if several services are attempting to write logs
    frequently. We will review the best centralization techniques later. For now,
    let us focus on deciding what are the best bits of information to log and how
    that can be achieved in .NET Core.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一种干净的方式来集中管理跨服务生成的日志。集中式数据库可能看起来是个好主意，但如果多个服务频繁地写入日志，可能会导致资源和表锁定。我们将在稍后审查最佳集中化技术。现在，让我们专注于决定最佳的信息记录内容以及如何在.NET
    Core中实现这一点。
- en: Choosing what to log
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择记录的内容
- en: An important decision while implementing logging is what we want to log. Do
    we want to log a play-by-play sequence of everything that happens in our application,
    or do we only want to make note of the errors? Different systems have different
    requirements, and the correct choices depend on how crucial the service is to
    the overall running of the application.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施日志记录时做出的重要决定是我们想要记录什么。我们是否想要记录应用中发生的所有事情的逐字记录，还是我们只想记录错误？不同的系统有不同的要求，正确的选择取决于该服务对应用整体运行的重要性。
- en: Now that we have determined the most essential services that need to be monitored
    more through logs, we need to determine what information will be logged. Recall
    that we don’t want our logs to be too chatty, but we don’t want to neglect to
    place pertinent information in the logs. Too much information can lead to large
    useless logs and high storage costs, and too little information will give us useless
    files.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了需要通过日志进行更多监控的最关键服务，我们需要确定将记录哪些信息。回想一下，我们不想让日志过于冗长，但我们也不想在日志中遗漏相关信息。过多的信息可能导致大量无用的日志和高存储成本，而信息过少将使我们得到无用的文件。
- en: 'Useful information would include, but is not limited to the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有用的信息包括但不限于以下内容：
- en: The ID of a resource that is being accessed through an API request
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过API请求访问的资源ID
- en: The different functions being invoked during a request cycle
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求周期中调用的不同功能
- en: 'What we want to avoid is logging sensitive information. We do not want to log
    the following, for example:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要避免记录敏感信息。我们不想记录以下内容，例如：
- en: User credentials during an authentication flow
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 认证流程中的用户凭据
- en: Payment information
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支付信息
- en: Personally identifiable information
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个人可识别信息
- en: Despite our best security efforts, logs remain a source of truth about our system,
    and a security breach on log files that contain sensitive information could prove
    to be a detrimental event. There are legislations and data protection laws that
    govern how we should store and secure our logs. Therefore, it is better to log
    just IDs that can be looked up on demand, without giving any information away
    upfront.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们尽了最大的安全努力，日志仍然是关于我们系统的事实来源，对包含敏感信息的日志文件的安全漏洞可能证明是一个有害的事件。有一些法规和数据保护法规定了我们应该如何存储和保障我们的日志。因此，最好只记录可以按需查询的ID，而不提前泄露任何信息。
- en: 'We also have the concept of *log levels*, which are a categorization of the
    severity of a log message. These levels are split into *information*, *debug*,
    *warning*, *error*, and *critical*. There might be other categories in between,
    but these are the most used ones. This is what they stand for:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有 *日志级别* 的概念，它是日志消息严重性的分类。这些级别分为 *信息*、*调试*、*警告*、*错误* 和 *关键*。中间可能还有其他类别，但这些都是最常用的。它们代表以下含义：
- en: '**Information**: A standard log level that is used when something has happened
    as expected. They are generally used to share information about an operation and
    can be useful in helping to trace the sequence of operations that might have led
    to an error.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息**：这是一个标准的日志级别，当发生预期的事情时使用。它们通常用于分享有关操作的信息，并有助于追踪可能导致错误的操作序列。'
- en: '**Debug**: A very informational log level that is more than we might need for
    everyday use. It is mostly useful for development and helps us to track more intricate
    operations in the code. Production systems generally do not produce debug logs.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调试**：这是一个非常信息的日志级别，比我们日常使用所需的要多。它主要用于开发，帮助我们跟踪代码中的更复杂操作。生产系统通常不会产生调试日志。'
- en: '**Warning**: This log level indicates that something has happened that isn’t
    an error but isn’t normal. Think of it as an amber light that suggests that some
    attention should be given to a situation, but it might not be mission critical.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警告**：这种日志级别表示发生了不是错误但也不正常的事情。把它想象成黄灯，表明应该关注某种情况，但它可能不是任务关键。'
- en: '**Error**: An error is an error. This type of log entry is usually created
    when an exception is encountered. This can be paired with the exception and stack
    trace and proves to be a critical type of log to have when debugging issues.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误**：错误就是错误。这种类型的日志条目通常在遇到异常时创建。它可以与异常和堆栈跟踪一起使用，并在调试问题时证明是一种关键的日志类型。'
- en: '**Critical**: This indicates that we encountered an error that we cannot recover
    from. This kind of log entry can be used when the application fails to start or
    fails to connect to a critical data source or dependency.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键**：这表示我们遇到了一个无法恢复的错误。这种日志条目可以在应用程序启动失败或无法连接到关键数据源或依赖项时使用。'
- en: Log levels are a universal language, and we should ensure that we accurately
    represent the situation being logged with the appropriate log level. We also want
    to avoid misclassifying our events and logging misleading information about what
    has happened in our system.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 日志级别是一种通用语言，我们应该确保我们使用适当的日志级别准确地表示正在记录的情况。我们还希望避免错误分类我们的事件，并记录关于我们系统中发生的事情的误导性信息。
- en: Once again, the ultimate decision on what is logged is relative to the application,
    developer’s, and organization’s needs and we need to ensure that we are thorough
    enough to capture the essential bits about the application’s runtime. Now, let
    us review how we implement logging in to a .NET Core application.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，关于记录什么内容，最终的决定取决于应用程序、开发人员和组织的需要，我们需要确保我们足够彻底，能够捕捉到关于应用程序运行时基本信息的要点。现在，让我们回顾一下如何在
    .NET Core 应用程序中实现日志记录。
- en: Using the .NET logging API
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 .NET 日志 API
- en: .NET has a built-in logging mechanism that is baked into our application startup
    operation. We get an out-of-the-box logging library that produces logs on all
    the happenings of our application as soon as it is started. This mechanism works
    with several third-party logging providers, making it extensible and powerful
    just the same. With our providers, we can determine the target destinations for
    our logs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: .NET 有一个内置的日志机制，它被嵌入到我们的应用程序启动操作中。我们得到一个开箱即用的日志库，它会在应用程序启动后立即记录所有发生的事情。这个机制与多个第三方日志提供程序一起工作，使其可扩展且功能强大。通过我们的提供程序，我们可以确定日志的目标目的地。
- en: 'We will start with the *ILogger* interface. This interface is an abstraction
    of the logging API that ships with .NET. It is made available to us through the
    `Microsoft.Extensions.Logging` NuGet package. This library provides us with the
    necessary classes, interfaces, and functionality for application logging and has
    providers for logging to *Console*, *Debug*, *Azure Log Stream*, *EventSource*,
    and *Windows Event Log*:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 *ILogger* 接口开始。这个接口是 .NET 伴随的日志 API 的抽象。它通过 `Microsoft.Extensions.Logging`
    NuGet 包提供给我们。这个库为我们提供了应用程序日志记录所需的必要类、接口和功能，并为 *Console*、*Debug*、*Azure Log Stream*、*EventSource*
    和 *Windows Event Log* 提供了日志记录提供程序：
- en: '**Console**: This provider outputs logs to the console. A console window appears
    when debugging and most IDEs (contextually, Visual Studio and Visual Studio Code)
    provide a debugging console window for runtime logs.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`System.Diagnostics.Debug` class.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**EventSource**: A cross-platform provider that can act as an event source
    with the name *Microsoft-Extensions-Logging*.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Windows Event Log**: A Windows-only provider that sends log output to the
    Windows Event Log. It will only log *Warning* level messages by default but can
    be configured as needed.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Log Stream**: Azure Log Stream supports viewing logs from the Azure
    portal during application runtime. We can easily write logs to this provider.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To get our .NET application to begin writing logs, we can simply inject `ILogger<T>`
    into the class from which logs should originate. `T` represents the name of the
    class that we are injecting the service into. This helps with log categorization
    and filtering later because the logs will automatically indicate the class name
    when they are generated. `ILogger<T>` is usually used by application code, which
    may exist in several places. Because the class name is being used as a *category*,
    it makes it easy for us to link the log entries back to the class that produced
    them. In the following code, we are injecting `ILogger<T>` into our appointments
    service controller:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Injecting `ILogger<T>` is standard compared to how we inject other services.
    The benefit of now having this logger present is that we can write logs to inform
    of the activities and errors in our API. If we need to log each time a list of
    appointments is retrieved through an API call, we can modify our `GET` method
    like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, when we make requests to the `GET` method for this service, we will see
    a message that looks like this appear in our console. Here, “console” refers to
    the console window that launches and shows us startup messages about the running
    .NET application, as well as the debug output in the IDE we are using:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that we can see not only the source calls but its namespace, which also
    plays a big role in helping us to determine which exact class is producing the
    log. We also get a log-level flag so that we can tell the severity at first glance.
    You will also notice that there are many other default log entries that we didn’t
    orchestrate. We can control the global levels and sources of logs that we wish
    to have in our application through the `appsettings.json` file. By default, it
    will have the following configuration:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This specifies that the minimum default level that should be output to the destinations
    is `Information` for the default logging source. Anything related to the inner
    workings of our application should only surface when it is a `Warning`. If we
    modified and placed them both at `Information`, then our logs would become far
    more chatty from the get-go.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: 'Our `LogLevel` methods have a standard layout that allows us to easily include
    additional information as needed. The possible parameters are as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `LogLevel` 方法有一个标准布局，允许我们根据需要轻松地包含额外的信息。可能的参数如下：
- en: '**eventId**: A numeric value that you would associate with an action in your
    application. There is no predefined standard for this, and you can assign your
    own values based on your organization and needs. This is an optional parameter
    but can be useful when we need to associate logs with a particular action.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**eventId**: 一个与你的应用程序中的操作相关联的数值。对此没有预定义的标准，你可以根据自己的组织和需求分配自己的值。这是一个可选参数，但在我们需要将日志与特定操作关联时可能很有用。'
- en: '`try`/`catch` block.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`try`/`catch` 块。'
- en: '`{username}` should then be provided in `messageArgs`.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{username}` 应该在 `messageArgs` 中提供。'
- en: '**messageArgs**: This is an array of objects that will bind to placeholders
    that are outlined in the message string. The binding will occur in the order that
    the parameters appear, so the values should be provided in that order as well.
    If a value is not provided, the placeholder will be printed out in the string.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**messageArgs**: 这是一个对象数组，它将绑定到消息字符串中概述的占位符。绑定将按照参数出现的顺序进行，因此值也应该按照这个顺序提供。如果没有提供值，占位符将按原样打印在字符串中。'
- en: 'An example that uses all the parameters could look something like this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用所有参数的一个示例可能如下所示：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we added exception handling to our endpoint, which gets the appointment
    record by ID. If there is an exception in carrying out any of the operations,
    we catch it and log it. We are using `100` as the `eventId` property for this
    operation, and we are logging the exception and including a custom message with
    some more information to help us contextualize the nature of the exception. We
    also included the ID of the record that caused the failure; notice the `{id}`
    placeholder that will map to the `id` argument. Giving your parameters the same
    name is not necessary, but it does help to reduce any confusion with the value
    bindings.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为我们的端点添加了异常处理，该端点通过 ID 获取预约记录。如果在执行任何操作时出现异常，我们将捕获它并记录它。我们为这次操作使用 `100`
    作为 `eventId` 属性，并记录异常，包括一些自定义消息和一些更多信息，以帮助我们确定异常的性质。我们还包含了导致失败的记录的 ID；注意 `{id}`
    占位符将映射到 `id` 参数。给参数相同的名称不是必需的，但它确实有助于减少任何与值绑定的混淆。
- en: 'If we want to extend the number of providers that should be used for each log
    message, we can configure the logging settings in the `Program.cs` file of our
    application. In a standard boilerplate ASP.NET Core project, we can add code that
    looks like this:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想扩展每个日志消息应使用的提供者数量，我们可以在应用程序的 `Program.cs` 文件中配置日志设置。在一个标准的样板 ASP.NET Core
    项目中，我们可以添加如下代码：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'First, we must clear any preconfigured providers and then add all the providers
    that we wish to support. Now, one log message will be written to several destinations.
    This can be a convenient way to fan out our log messages and have different monitoring
    methods attached to each destination. Remember that you should always be aware
    of the information security rules that govern your country and company and try
    not to expose too much information in too many places. We can also provide specific
    configurations per provider by modifying the logging configuration in the `appsettings.json`
    file, like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须清除任何预配置的提供者，然后添加我们希望支持的提供者。现在，一个日志消息将被写入多个目的地。这可以是一种方便的方式来分散我们的日志消息，并为每个目的地附加不同的监控方法。请记住，你应该始终了解你所在国家和公司的信息安全管理规则，并尽量避免在太多地方暴露太多信息。我们还可以通过修改
    `appsettings.json` 文件中的日志配置来为每个提供者提供特定的配置，如下所示：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We retain our default `LogLevel` for each log source, but then provide overrides
    per provider. If the log source is not defined underneath the provider’s configuration,
    then it will retain the default behaviors, but we do reserve the right to control
    what type of log each provider should prioritize.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个日志源保留默认的 `LogLevel`，但随后为每个提供者提供覆盖。如果日志源在提供者的配置下未定义，则它将保留默认行为，但我们保留控制每个提供者应优先考虑哪种日志类型的权利。
- en: 'If we need to extend support to Azure systems, we could make use of the Azure
    application’s file storage and/or blob storage. We can start by including `Microsoft.Extensions.Logging.AzureAppServices`
    via the `NuGet` package manager and then we can configure the logging services
    with code like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要扩展对 Azure 系统的支持，我们可以利用 Azure 应用程序的文件存储和/或 Blob 存储。我们可以通过 `NuGet` 软件包管理器包含
    `Microsoft.Extensions.Logging.AzureAppServices`，然后我们可以使用如下代码配置日志服务：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This will configure the app to use the filesystem as well as Blob storage in
    Azure. Based on App Services logs settings, there are some defaults that we can
    look for in terms of log output locations. Similarly, we can override the default
    logs that are being outputted by this provider by adding sections to the `appsettings.json`
    file with the aliases `AzureAppServicesBlob` and `AzureAppServicesFile`. We can
    also define `ApplicationInsights` if we intend to use that service for our application.
    To support `ApplicationInsights`, we need the `Microsoft.Extensions.Logging.ApplicationInsights`
    NuGet package. Azure Application Insights is a powerful log aggregation platform
    provided by Microsoft Azure and is an excellent choice for an Azure-hosted solution.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这将配置应用程序使用文件系统以及 Azure 中的 Blob 存储。根据 App Services 日志设置，我们可以查找一些默认的日志输出位置。同样，我们可以通过向
    `appsettings.json` 文件中添加具有别名 `AzureAppServicesBlob` 和 `AzureAppServicesFile` 的部分来覆盖此提供程序正在输出的默认日志。我们还可以定义
    `ApplicationInsights`，如果我们打算为我们的应用程序使用该服务。为了支持 `ApplicationInsights`，我们需要 `Microsoft.Extensions.Logging.ApplicationInsights`
    NuGet 软件包。Azure Application Insights 是由 Microsoft Azure 提供的强大日志聚合平台，是 Azure 托管解决方案的一个很好的选择。
- en: Several third-party frameworks extend the capabilities of the built-in logging
    API of .NET. We will explore how to integrate a popular one called **Serilog**
    in the next section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 几个第三方框架扩展了 .NET 内置日志 API 的功能。在下一节中，我们将探讨如何集成一个流行的框架，称为 **Serilog**。
- en: Adding Serilog
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加 Serilog
- en: Several third-party frameworks exist that extend the logging capabilities and
    options available to us in our .NET applications. Popular options include **Serilog**,
    **Loggr**, **Elmah.io**, and **NLog** to name a few. Each one has its pros and
    cons, but in this section, we will be exploring Serilog, how we can integrate
    it into our application, and what options it introduces to us.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几个第三方框架，它们扩展了我们 .NET 应用程序中可用的日志记录功能和选项。流行的选项包括 **Serilog**、**Loggr**、**Elmah.io**
    和 **NLog**，仅举几例。每个都有其优缺点，但在这个部分，我们将探讨 Serilog，我们将如何将其集成到我们的应用程序中，以及它为我们引入了哪些选项。
- en: 'Serilog extends `Microsoft.Extensions.Logging` and provides quick and fairly
    easy ways to override the default settings while retaining the full power and
    flexibility of the original framework. To get started, we need to install the
    `Serilog.AspNetCore` package. For non-web .NET Core projects, we need to use `Serilog.Extensions.Hosting`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Serilog 扩展 `Microsoft.Extensions.Logging`，并提供快速且相对简单的方法来覆盖默认设置，同时保留原始框架的全部功能和灵活性。要开始，我们需要安装
    `Serilog.AspNetCore` 软件包。对于非 Web .NET Core 项目，我们需要使用 `Serilog.Extensions.Hosting`：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Serilog has the concept of using sinks. A sink is like a logging provider in
    concept and represents an output channel for the logs being written by the framework.
    We need to add additional packages per sink that we wish to support. Popularly
    used sinks include *Console*, *File*, *Seq*, *SQL Server*, and *Azure Application
    Insights*, just to name a few. You can get a complete list from their GitHub wiki
    page: [https://github.com/serilog/serilog/wiki/Provided-Sinks](https://github.com/serilog/serilog/wiki/Provided-Sinks).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Serilog 有使用输出通道的概念。在概念上，输出通道类似于日志提供程序，代表框架写入的日志的输出通道。我们需要为每个我们希望支持的输出通道添加额外的包。常用的输出通道包括
    *Console*、*File*、*Seq*、*SQL Server* 和 *Azure Application Insights*，仅举几例。您可以从他们的
    GitHub wiki 页面获取完整的列表：[https://github.com/serilog/serilog/wiki/Provided-Sinks](https://github.com/serilog/serilog/wiki/Provided-Sinks)。
- en: 'For this exercise, we will be configuring Serilog to use the file and console
    sinks. We will also be adding parameters to our `appsettings.json` file. We will
    need the *expressions* extension to the base library to support parsing the JSON
    text into the required settings:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个练习，我们将配置 Serilog 以使用文件和控制台输出。我们还将向我们的 `appsettings.json` 文件中添加参数。我们需要将 *expressions*
    扩展添加到基本库中，以支持将 JSON 文本解析为所需的设置：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we can remove the `Logging` section from our `appsettings.json` file and
    replace it with the following JSON text:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从我们的 `appsettings.json` 文件中删除 `Logging` 部分，并用以下 JSON 文本替换它：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now, we have a similar structure where we can define logging defaults for the
    application, but we also have a `WriteTo` section that allows us to list the different
    channels that we want to support. We have only included the settings for `File`
    writes, and we have specified the target location to be a local folder called
    `logs`. Files will be created daily and automatically be given a name that is
    a combination of the `log-` expression and a date. This will make it easy for
    us to source the relevant files by day and each log will indicate a timestamp,
    making it easier to review the events.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个类似的结构，可以定义应用程序的日志默认设置，但我们还有一个`WriteTo`部分，允许我们列出我们想要支持的不同通道。我们只包括了`File`写入的设置，并指定目标位置为一个名为`logs`的本地文件夹。文件将每天自动创建，并赋予一个由`log-`表达式和日期组合而成的名称。这将使我们能够按日轻松检索相关文件，并且每个日志都会显示一个时间戳，使得回顾事件更加容易。
- en: 'Now, we can remove the `builder.Logging(…)` configuration and replace it with
    this:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以移除`builder.Logging(…)`配置，并用这个来替换：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will initialize our logger to use the `Console` sink and read the configuration
    object for the Serilog section defined previously. This will initialize the `Console`
    and `File` sinks. We can now look forward to seeing text files getting created
    and populated daily for each microservice that has implemented the file logging
    configuration for Serilog. The code that is needed to write the logs remains the
    same. We only need to repeat the injection steps outlined for `ILogger<T>`; Serilog
    will do the rest.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这将初始化我们的日志记录器以使用`Console`接收器和读取之前定义的Serilog部分的配置对象。这将初始化`Console`和`File`接收器。现在，我们可以期待看到为每个实现了Serilog文件日志配置的微服务每天创建并填充的文本文件。需要写入日志的代码保持不变。我们只需要重复为`ILogger<T>`概述的注入步骤；Serilog会完成其余的工作。
- en: Now, we have solved one issue where we are no longer blind to what is happening
    in our application. We can easily integrate logging into our services and review
    a more persistent output in the form of log files. However, we still have the
    challenge of needing to review several disparate logs across different systems
    to properly track what may have led to a failure at some point.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经解决了一个问题，我们不再对我们的应用程序发生的事情视而不见。我们可以轻松地将日志集成到我们的服务中，并以日志文件的形式审查更持久的输出。然而，我们仍然面临着需要审查不同系统中的多个不同日志，以正确追踪可能导致某个点失败的原因的挑战。
- en: This is where we need to explore methods of aggregating the logs and having
    them visible and searchable from one interface. We will explore how this can be
    done in the next section.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们需要探索汇总日志并使它们从一个界面中可见和可搜索的方法。我们将在下一节中探讨如何实现这一点。
- en: Log aggregation and its uses
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 日志聚合及其用途
- en: Log aggregation is the concept of capturing and consolidating logs from different
    sources into a centralized platform. This comes in handy in a distributed system
    where logs are generated from several sources, and we need a comprehensive view
    of all the messages and need to correlate and analyze the logs efficiently.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 日志聚合是将来自不同来源的日志捕获并整合到一个集中平台的概念。在分布式系统中，日志由多个来源生成，我们需要对所有消息有一个全面的了解，并需要有效地关联和分析日志。
- en: 'This log aggregation acts as a single source of truth when we need to troubleshoot
    application performance and errors or identify bottlenecks and points of failure
    or vulnerability. Several platforms allow us to aggregate our logs and they range
    from free to paid to cloud-hosted solutions. Some popular ones are *Azure Application
    Insights*, *Seq, DataDog*, and *ELK (Elasticsearch, Logstash, and Kibana)*, to
    name a few. In selecting a platform, we must consider the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要调试应用程序性能和错误或识别瓶颈、故障点或漏洞时，日志聚合充当单一的真实来源。几个平台允许我们聚合我们的日志，它们从免费到付费再到云托管解决方案不等。一些流行的平台包括*Azure
    Application Insights*、*Seq*、*DataDog*和*ELK (Elasticsearch, Logstash, and Kibana)*等，仅举几例。在选择平台时，我们必须考虑以下因素：
- en: '**Efficiency**: We all love and want efficient systems. The platform that we
    choose needs to feed into this narrative and make it as easy as possible to integrate
    logging, export log information in various formats, and sift and sort through
    log information as quickly as possible. Most log aggregators allow us to author
    queries that can intelligently sift through the logging noise and give us more
    pointed data.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**效率**：我们都喜欢并且希望系统高效。我们选择的平台需要符合这一叙述，并尽可能简化日志集成、以各种格式导出日志信息以及快速筛选和排序日志信息的过程。大多数日志聚合器允许我们编写查询，可以智能地筛选日志噪音，并给我们提供更具体的数据。'
- en: '**Processing power**: The platform needs to allow for comfortable throughput
    from several sources and be able to index, compress, and efficiently store these
    logs. We may not necessarily know their techniques to achieve this, but we can
    assess the accuracy of the indexing functions through our queries and the overall
    presentation of the data.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理能力**：该平台需要能够从多个来源提供舒适的吞吐量，并能够索引、压缩和高效地存储这些日志。我们可能不一定知道它们实现这一点的技术，但我们可以通过我们的查询和数据的整体展示来评估索引功能的准确性。'
- en: '**Real-time features**: Real-time monitoring is very important since we generally
    need log aggregation to monitor what is happening in our application. The more
    quickly the information is made available to us, the more quickly we can respond
    to a failure.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实时功能**：实时监控非常重要，因为我们通常需要日志聚合来监控应用程序中发生的事情。信息提供得越快，我们就能越快地响应故障。'
- en: '**Scalability**: The platform needs to be capable of handling varied periods
    of traffic and not breaking when there is a sudden shift in volume. We need to
    ensure that the performance of the system does not degrade under increased load.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：该平台需要能够处理不同的流量周期，并在流量突然变化时不会崩溃。我们需要确保系统在高负载下的性能不会下降。'
- en: '**Alerting mechanisms**: Some platforms have the built-in functionality to
    alert us to certain types of log events. Even if this is not built-in, we should
    have integration options through *APIs* and *WebHooks* that allow us to integrate
    with our third-party applications, which is where we spend most of our time.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警报机制**：一些平台具有内置的功能，可以提醒我们某些类型的日志事件。即使这不是内置的，我们也应该有通过*APIs*和*WebHooks*的集成选项，这样我们就可以与我们的第三方应用程序集成，这是我们大部分时间所在的地方。'
- en: '**Security**: Security is very important for our logging information, as we
    have mentioned previously. An ideal platform will encrypt data while it is at
    rest and while it is in transit. This is often a given, but we need to make sure.
    We may also need to be able to control user access.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**：安全性对我们日志信息非常重要，正如我们之前提到的。一个理想的平台将在数据静止和传输过程中加密数据。这通常是理所当然的，但我们需要确保。我们可能还需要能够控制用户访问。'
- en: '**Cost**: We all love free and cheap solutions. We cannot always have the best
    of both worlds but we can be sure that the platform offers a good return on the
    investment, relative to the features that we are being offered. Ensure that you
    do a proper cost-benefit analysis.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本**：我们都喜欢免费和便宜解决方案。我们不可能总是两者兼得，但我们确实可以确信，该平台提供的投资回报率是好的，相对于我们获得的功能而言。确保你进行适当的经济效益分析。'
- en: The easier way to integrate with a log aggregation platform is through tools
    and packages that are optimized for that kind of integration. We need to employ
    the services of libraries that are tuned to efficiently integrate with these platforms.
    In the next section, we will see how we can leverage *Serilog* and integrate with
    *Seq*.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 与日志聚合平台集成的最简单方法是使用针对此类集成优化的工具和包。我们需要利用那些针对与这些平台高效集成的库的服务。在下一节中，我们将看到如何利用*Serilog*与*Seq*集成。
- en: Integrating with Seq
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与Seq集成
- en: '*Seq*, pronounced seek, is a sleek (see what I did there?) log aggregation
    developed and maintained by *Datalust*. This platform has been developed to support
    log messaging templates output by *ASP.NET Core*, *Serilog*, and *Nlog*. It can
    also be extended to support other development frameworks as needed.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*Seq*，发音为seek，是由*Datalust*开发和维护的一个简洁（看看我做了什么？）日志聚合工具。这个平台是为了支持*ASP.NET Core*、*Serilog*和*Nlog*输出的日志消息模板而开发的。它也可以根据需要扩展以支持其他开发框架。'
- en: It gives us access to a powerful dashboard with leading data presentation and
    querying features. *Seq* can be installed on a local machine for free for individual
    development but will attract some costs as we look to use it in a more enterprise
    setting. It also offers a hosted solution, which removes the need for users to
    set it up locally.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 它为我们提供了一个功能强大的仪表板，具有领先的数据展示和查询功能。*Seq*可以免费安装在本地机器上进行个人开发，但如果我们打算在更企业化的环境中使用它，则会产生一些成本。它还提供托管解决方案，这消除了用户本地设置的需求。
- en: For this activity, we will use it locally and for free on our machine. We now
    have two options; we can use a *Docker* image and spin up a container for the
    application or install it on our local machine. It is available for *Windows*
    and *Linux* operating systems, so we will use the *Docker* option to cater to
    all scenarios.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个活动，我们将在本地免费使用它在我们的机器上。我们现在有两个选择；我们可以使用一个 *Docker* 镜像并为应用程序启动一个容器，或者在我们的本地机器上安装它。它适用于
    *Windows* 和 *Linux* 操作系统，因此我们将使用 *Docker* 选项来满足所有场景。
- en: 'We will start by downloading the Docker image with this command:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用以下命令下载 Docker 镜像：
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we have the latest Seq image, we will create our container with this
    command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了最新的 Seq 镜像，我们将使用以下命令创建我们的容器：
- en: '[PRE13]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now, we have a container that hosts an instance of Seq and can be accessed through
    port 5431, which is Seq’s default port. We can now navigate to `http://localhost:5341/#/events`
    to see our user interface for the aggregator. It will be empty, so now, we need
    to integrate our API with this new logging channel.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个容器，它托管了一个 Seq 实例，可以通过端口 5431 访问，这是 Seq 的默认端口。我们现在可以导航到 `http://localhost:5341/#/events`
    来查看我们的聚合器用户界面。它将是空的，因此现在我们需要将我们的 API 与这个新的日志通道集成。
- en: 'Now that we have Seq up and running, we can modify our service to begin sending
    logs to this platform. We already have Serilog installed, so we can add the Seq
    sink to our project by adding this package:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经启动并运行了 Seq，我们可以修改我们的服务，使其开始向这个平台发送日志。我们已经有 Serilog 安装了，所以我们可以通过添加这个包将
    Seq 源添加到我们的项目中：
- en: '[PRE14]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'With this new package, we can modify our `appsettings.json` Serilog section
    and add a new object block to the `WriteTo` section of the configuration. It will
    now look like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个新包，我们可以修改 `appsettings.json` 中的 Serilog 部分，并在配置的 `WriteTo` 部分添加一个新的对象块。它现在看起来像这样：
- en: '[PRE15]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We already have the configuration section being read at application startup,
    so the next time that the application starts up, all the default logs will be
    written to our local file as expected, but now also the Seq platform.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在应用程序启动时读取了配置部分，所以下次应用程序启动时，所有默认日志都将按预期写入我们的本地文件，但现在也将写入 Seq 平台。
- en: '*Figure 14.1* shows the Seq interface:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14.1* 显示了 Seq 界面：'
- en: '![Figure 14.1 – The Seq interface receiving logs from a microservice](img/Figure_14.1_B19100.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.1 – Seq 接收来自微服务的日志的界面](img/Figure_14.1_B19100.jpg)'
- en: Figure 14.1 – The Seq interface receiving logs from a microservice
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 – Seq 接收来自微服务的日志的界面
- en: Here, we can see the user interface outlining the default logs that get produced
    at application startup. What appears in this interface is relative to the logging
    configurations that we have added, as well as the log entries that we make as
    we go along. You will also notice some color-coded dots, which indicate the log
    level for the log entry. We can click on a line and expand it to see the details
    of the log message.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到用户界面概述了应用程序启动时产生的默认日志。出现在此界面中的内容与我们添加的日志配置以及我们在进行过程中创建的日志条目相关。您还会注意到一些彩色点，这些点表示日志条目的日志级别。我们可以点击一行并展开它以查看日志消息的详细信息。
- en: Now, these code modifications can be made to all services that we wish to add
    to the log aggregation initiative, and we can use this unified platform to interrogate
    logs as needed. With this in place, we need to understand the concept of log tracing
    in a distributed setting. We will discuss this next.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这些代码修改可以应用于我们希望添加到日志聚合计划的所有服务，我们可以使用这个统一的平台按需查询日志。有了这个，我们需要了解分布式环境中的日志跟踪概念。我们将在下一节讨论这个问题。
- en: Distributed log tracing
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式日志跟踪
- en: Distributed tracing is the method of monitoring logs and tracing issues in a
    microservices application. Developers and DevOps engineers both rely on logs to
    follow the path of a request as it travels through the various systems and checkpoints
    and then attempts to ascertain the point of failure. The more robust the logging,
    the easier it will be for them to pinpoint weak points, bugs, and bottlenecks
    in the application.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪是监控微服务应用程序日志和跟踪问题的方法。开发人员和 DevOps 工程师都依赖日志来跟踪请求在穿越各种系统和检查点时的路径，然后尝试确定失败点。日志越健壮，他们就越容易定位应用程序中的弱点、错误和瓶颈。
- en: Because microservices are designed to be autonomous and scale independently,
    it is common to have multiple instances of the service running simultaneously,
    which further complicates the request tracing process. We now need to backtrack
    which instance of the service handled the request, leading to even more complex
    tracing situations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于微服务被设计成是自主的并且可以独立扩展，通常会有多个服务实例同时运行，这进一步复杂化了请求跟踪过程。我们现在需要回溯哪个服务实例处理了请求，导致更复杂的跟踪情况。
- en: 'Distributed tracing is a technique that is geared toward solving these problems.
    It refers to a diagnostic methodology behind observing requests as they make their
    way through distributed systems. Each trace shows the activity of an individual
    user in the application. In an aggregated logging system, we will end up with
    a collection of traces that highlight the backend service and dependencies that
    have the biggest impact on performance. In distributed tracing, we have three
    main factors that help us to find our way around:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪是一种旨在解决这些问题的技术。它指的是在请求通过分布式系统时观察请求背后的诊断方法。每个跟踪显示了应用程序中单个用户的活动。在一个聚合的日志系统中，我们将得到一个突显对性能影响最大的后端服务和依赖关系的跟踪集合。在分布式跟踪中，我们有三个主要因素帮助我们找到方向：
- en: '**Trace**: Represents an end-to-end request from user activity.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪**：表示用户活动的一个端到端请求。'
- en: '**Span**: Represents work done by a single service in a specific period. Spans
    combine to form a trace.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跨度**：表示单个服务在特定时间段内完成的工作。跨度组合形成跟踪。'
- en: '**Tags**: Metadata about the span that helps us to properly categorize and
    contextualize the logs.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：关于日志跨度元数据的信息，帮助我们正确分类和上下文化日志。'
- en: 'Each span is a step in the entire journey of the request and is encoded with
    important data relating to the process that is carried out in the operation. This
    information can include things such as the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 每个跨度是请求整个旅程中的一步，并编码了与操作中执行的过程相关的重要数据。这些信息可能包括以下内容：
- en: The service’s name and address
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务的名称和地址
- en: Tags that can be used in queries and filters, such as the HTTP method, database
    host, and session ID, to name a few
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以用于查询和过滤的标签，例如 HTTP 方法、数据库主机和会话 ID 等
- en: Stack traces and details error messages
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 栈跟踪和详细错误消息
- en: .NET has evolved over the years to provide top-notch support for producing logs
    with these details as seamlessly as possible, through integrations with `OpenTelemetry`.
    Microsoft Azure also provides an excellent distributed tracing platform in *Azure
    Application Insights*, which is a platform that we mentioned previously. There
    are many other paid and open source solutions that can support our distributed
    tracing needs. For this chapter, we will use a free and simple platform called
    Jaeger. Let us explore how we can add telemetry enhancements to our services and
    visualize them with Jaeger.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: .NET 多年来已经发展到提供最高级的支持，通过集成 `OpenTelemetry` 来尽可能无缝地生成这些详细信息的日志。Microsoft Azure
    还提供了在 *Azure Application Insights* 中的优秀分布式跟踪平台，这是我们之前提到过的平台。还有许多其他付费和开源解决方案可以支持我们的分布式跟踪需求。对于本章，我们将使用一个免费且简单的平台，称为
    Jaeger。让我们探索如何将遥测增强添加到我们的服务中，并使用 Jaeger 进行可视化。
- en: Enhanced logging for distributed tracing
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强分布式跟踪的日志
- en: '`OpenTelemetry` is a popular open source project that is at the helm of standardizing
    logging standards for distributed and cloud-native applications. It helps us to
    generate and collect detailed logs, also called telemetry data, that contain traces
    and metrics. Given that it is an open standard, we are at liberty to choose a
    suitable visualization and analysis tool.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`OpenTelemetry` 是一个流行的开源项目，它负责为分布式和云原生应用程序标准化日志标准。它帮助我们生成和收集包含跟踪和指标的详细日志，也称为遥测数据。鉴于它是一个开放标准，我们可以自由选择合适的可视化和分析工具。'
- en: 'To install `OpenTelemetry` in our ASP.NET Core application, we need to execute
    the following commands in `dotnet cli`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的 ASP.NET Core 应用程序中安装 `OpenTelemetry`，我们需要在 `dotnet cli` 中执行以下命令：
- en: '[PRE16]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Between these three packages, we are installing ASP.NET Core `OpenTelemetry`
    support and support for exporting our telemetry data to a distributed tracing
    analysis platform called Jaeger. Jaeger is free and can be downloaded in ZIP format
    or set up as a Docker container. You can learn more here: [https://www.jaegertracing.io/download/](https://www.jaegertracing.io/download/).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这三个包之间，我们正在安装 ASP.NET Core `OpenTelemetry` 支持，以及将我们的遥测数据导出到一个名为 Jaeger 的分布式跟踪分析平台的支持。Jaeger
    是免费的，可以以 ZIP 格式下载或设置为 Docker 容器。您可以在此处了解更多信息：[https://www.jaegertracing.io/download/](https://www.jaegertracing.io/download/)。
- en: 'Now that we have the packages, we can make the following adjustments to our
    `Program.cs` file:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了这些包，我们可以对我们的 `Program.cs` 文件进行以下调整：
- en: '[PRE17]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: With this configuration, we are adding `OpenTelemetry` support to our application’s
    startup and then outlining various enrichments that we wish to include with each
    message that is sent to Jaeger. Note that `OpenTelemetry` has support for a few
    platforms, and you are at liberty to choose the one that best suits your needs.
    With this configuration, all traffic to our API endpoints will be logged with
    as many enrichment data points as we specified.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此配置，我们在应用程序的启动时添加了 `OpenTelemetry` 支持，并概述了我们希望包含在每个发送到 Jaeger 的消息中的各种增强功能。请注意，`OpenTelemetry`
    支持几个平台，您可以根据自己的需求选择最合适的平台。使用此配置，所有流量到我们的 API 端点都将记录我们指定的尽可能多的增强数据点。
- en: '*Figure 14.2* shows the Jaeger interface:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 14.2* 展示了 Jaeger 界面：'
- en: '![Figure 14.2 – Telemetry data that has been generated and deposited in the
    Jaeger aggregation platform](img/Figure_14.2_B19100.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.2 – 已生成并存储在 Jaeger 聚合平台上的遥测数据](img/Figure_14.2_B19100.jpg)'
- en: Figure 14.2 – Telemetry data that has been generated and deposited in the Jaeger
    aggregation platform
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 – 已生成并存储在 Jaeger 聚合平台上的遥测数据
- en: Jaeger is simple enough for us to get started and, as depicted in *Figure 14.2*,
    we can view all the services that send telemetry data, filter based on the operations
    we need to see, and review data across a specified timeline. These are general
    features of distributed tracing platforms and, once again, we need to ensure that
    we choose one that gives us the best value for our needs.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Jaeger 足够简单，我们可以轻松开始使用，如图 *图 14.2* 所示，我们可以查看所有发送遥测数据的服务，根据我们需要查看的操作进行过滤，并按指定的时间线审查数据。这些都是分布式跟踪平台的一般功能，我们再次需要确保我们选择一个最适合我们需求的平台。
- en: Now that we have explored logging and distributed tracing, let us wrap up this
    chapter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了日志记录和分布式跟踪，让我们总结本章内容。
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Logging is a simple concept that can save us a lot of time and trouble when
    reviewing our applications. The ability to write logs ships with .NET Core and
    we can easily leverage the native capabilities to begin producing log information
    about the operations of our applications.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录是一个简单的概念，在审查我们的应用程序时可以节省我们大量的时间和麻烦。写入日志的能力是 .NET Core 的组成部分，我们可以轻松利用原生功能来开始生成关于我们应用程序操作日志信息。
- en: We need to ensure that we do not log sensitive information and we must be aware
    of company and security policies when authoring our logs. We also need to ensure
    that our logs are stored securely both in transit and at rest. We also can log
    to multiple channels, but we should be careful when choosing these channels, relative
    to our security guidelines.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要确保我们不会记录敏感信息，并且在编写日志时必须了解公司和安全政策。我们还需要确保我们的日志在传输和静止状态下都得到安全存储。我们还可以将日志记录到多个通道，但在选择这些通道时，我们应该小心，相对于我们的安全指南。
- en: Several .NET Core frameworks enhance the natural capabilities of the built-in
    API and introduce even more integrations. A popular choice is Serilog, which has
    many extensions called sinks, which offer us a wide range of simultaneous log
    channel options. With it, we can easily create and manage log files on a rolling
    interval that we specify.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 几个 .NET Core 框架增强了内置 API 的自然功能，并引入了更多的集成。一个流行的选择是 Serilog，它有许多称为“sink”的扩展，为我们提供了广泛的并发日志通道选项。有了它，我们可以轻松地创建和管理我们指定的滚动间隔上的日志文件。
- en: Ideally, we will have multiple services writing logs and it will be tedious
    having each one log to its own file. This will force us to review multiple files
    to trace one request that might have spanned many touch points in our distributed
    application. For this reason, we employ the services of an aggregator, which will
    give our services a central area to deposit logs and give us and our team one
    area to focus on when sifting through logs.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们将拥有多个服务来记录日志，而每个服务都将其日志记录到自己的文件中将会非常繁琐。这将迫使我们检查多个文件来追踪一个可能跨越我们分布式应用多个接触点的请求。因此，我们聘请了聚合器的服务，这将为我们提供中央区域来存放日志，并为我们和我们的团队提供一个集中区域，以便在筛选日志时进行关注。
- en: Then, we ran into another issue where our logs need to contain certain details
    that allow us to properly associate them with a request. After, we looked at enriching
    our logs with unique IDs that help us to associate them to a point of origin and
    each other. This is called distributed tracing. We also reviewed how to include
    `OpenTelemetry` in our service and the use of a visualization tool to assist with
    the querying activities.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们遇到了另一个问题，我们的日志需要包含某些细节，以便我们能够正确地将它们与一个请求关联起来。之后，我们研究了如何通过添加唯一标识符来丰富我们的日志，这些标识符有助于我们将它们与原始点和其他日志关联起来。这被称为分布式追踪。我们还审查了如何在我们的服务中包含`OpenTelemetry`以及使用可视化工具来协助查询活动。
- en: Now we have finished exploring logging activities and best practices in a distributed
    system, in the next chapter, we will conclude what we have learned so far.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了对分布式系统中日志记录活动和最佳实践的探索，在下一章中，我们将总结到目前为止我们所学到的内容。
