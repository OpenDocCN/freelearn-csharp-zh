- en: Event Sourcing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件溯源
- en: You should already understand what domain events are, why they are important,
    and how to find and code them. Now, we will look into other uses for events. Hopefully,
    after reading this chapter, it will be clear why we need to use events to update
    the aggregate state. Before, we only used events inside our aggregates, and it
    might look a bit like overkill to raise those events and do the state transition
    separately, in the `When` method.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经理解了什么是领域事件，为什么它们很重要，以及如何找到和编码它们。现在，我们将探讨事件的其他用途。希望阅读完这一章后，你会明白为什么我们需要使用事件来更新聚合状态。在此之前，我们只在聚合内部使用事件，将事件提升并单独在`When`方法中进行状态转换可能看起来有些过度。
- en: This time, you will learn how events can be used to persist the state of an
    object, instead of using traditional persistence mechanisms, such as SQL or a
    document database. That is not an easy thing to grasp, but the reward is satisfying.
    Using events to represent the system behavior and derive its state for any given
    moment in time has many advantages. Of course, silver bullets do not exist, and
    before deciding whether Event Sourcing is for you, it is essential that you understand
    the possible drawbacks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，你将学习如何使用事件来持久化对象的状态，而不是使用传统的持久化机制，如SQL或文档数据库。这并不是一件容易掌握的事情，但回报是令人满意的。使用事件来表示系统行为并推导出任何给定时间点的状态有许多优点。当然，没有银弹，在决定事件溯源是否适合你之前，了解可能的缺点是至关重要的。
- en: We will continue developing our aggregates with more event handlers. Also, we
    will cover the concept of event streams and how streams relate to aggregates.
    We will use an event store to persist our aggregates in streams and load them
    back.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用更多的事件处理器来开发我们的聚合。同时，我们还将介绍事件流的概念以及流与聚合之间的关系。我们将使用事件存储在流中持久化我们的聚合，并将它们加载回来。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: What is Event Sourcing?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是事件溯源？
- en: Why do we use Event Sourcing?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们为什么使用事件溯源？
- en: The challenges and drawbacks of Event Sourcing
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件溯源的挑战和缺点
- en: Why Event Sourcing became popular in the DDD community
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么事件溯源在领域驱动设计社区中变得流行
- en: Using the Event Store
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用事件存储
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will be using the Event Store ([https://eventstore.org](https://eventstore.org/)),
    which is an open source database.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用事件存储（[https://eventstore.org](https://eventstore.org/)），这是一个开源数据库。
- en: The easiest way to run Event Store is to use Docker. We've used `docker-compose`
    in previous chapters, so it will be the same experience with the Event Store.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 运行事件存储最简单的方法是使用Docker。我们在前面的章节中使用了`docker-compose`，所以使用事件存储会有同样的体验。
- en: 'The code for this chapter contains a `docker-compose.yml` file that allows
    you to use Event Store by executing this command:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码包含一个`docker-compose.yml`文件，允许你通过执行以下命令来使用事件存储：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Docker will pull the latest image from Docker Hub and start a named container.
    Two ports are mapped by this command from the container to your machine: `2113`
    and `1113`. Port `2113` is used to access Event Store via HTTP, and `1113` is
    used for TCP connections.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Docker将从Docker Hub拉取最新镜像并启动一个命名容器。此命令将两个端口从容器映射到你的机器：`2113`和`1113`。端口`2113`用于通过HTTP访问事件存储，端口`1113`用于TCP连接。
- en: 'After the container starts, you can check its status by opening `http://localhost:2113` in
    your browser. You will get the following login prompt:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 容器启动后，你可以在浏览器中打开`http://localhost:2113`来检查其状态。你将得到以下登录提示：
- en: '![](img/b56a97c7-9a79-44c4-a71f-6661792c7413.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/b56a97c7-9a79-44c4-a71f-6661792c7413.png)'
- en: 'There, you need to enter the default credentials: `admin` as the username and `changeit` as
    the password. Then, click on the Sign In button, and the following screen should
    appear:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在那里，你需要输入默认凭据：用户名为`admin`，密码为`changeit`。然后，点击“登录”按钮，应该会出现以下屏幕：
- en: '![](img/125ecde9-c70f-4a12-929e-56405d528a8b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/125ecde9-c70f-4a12-929e-56405d528a8b.png)'
- en: The product version and menu items might differ, depending on the latest version
    of Event Store.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 产品版本和菜单项可能因Event Store的最新版本而有所不同。
- en: Why Event Sourcing
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么事件溯源
- en: In this section, we will not only discuss why one might want to use Event Sourcing—we
    will also look into the definition of this pattern and some history behind it.
    Like Greg Young often puts it, "*Event Sourcing is not new"*, and we will get
    into some history that should help you to understand the concept better.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们不仅将讨论为什么有人可能想要使用事件溯源——我们还将探讨这个模式的定义及其背后的历史。就像Greg Young经常说的那样，“*事件溯源并不新鲜*”，我们将探讨一些历史，这应该有助于你更好地理解这个概念。
- en: After that, we will get into the *why* part. Armed with some knowledge about
    its history, it won't be very hard to understand why this way of storing data
    is becoming more popular.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将探讨*为什么*。有了对其历史的了解，理解为什么这种存储数据的方式变得越来越流行就不会很难。
- en: By the end of this section, we will make it clear why one might not want to
    use Event Sourcing in their system, and what challenges are awaiting those who
    start using it for the first time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 到本节结束时，我们将清楚地说明为什么有人可能不想在他们的系统中使用事件溯源，以及那些第一次开始使用它的人将面临哪些挑战。
- en: Issues with state persistence
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 状态持久化的问题
- en: In the previous chapters, we used the term *domain event* many times. During
    the design phase, we used orange sticky notes to visualize domain events on the
    whiteboard. Later, during the implementation, we created classes for domain events.
    These classes translate things that happened in the system into something that
    the machine can read.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们多次使用了术语*领域事件*。在设计阶段，我们使用橙色便利贴在白板上可视化领域事件。后来，在实现阶段，我们为领域事件创建了类。这些类将系统中发生的事情转换成机器可以读取的内容。
- en: Each action in the domain model, represented as a method in aggregate, makes
    changes in the system state. We also made our aggregate to use events to describe
    these changes. When such a change is made, we then use the pattern-matching code
    to amend the aggregate state before it gets persisted to a database.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 领域模型中的每个动作，作为聚合中的方法表示，都会在系统状态中引起变化。我们还让我们的聚合使用事件来描述这些变化。当这种变化发生时，我们随后使用模式匹配代码在将其持久化到数据库之前修改聚合状态。
- en: 'Now, let''s suppose that we are not saving the aggregate state to the database,
    as we did in [Chapter 8](4eea9289-d77e-4568-a9c0-c5e1265e3b4e.xhtml), *CQRS -
    The Read Side*. Instead, we will collect all new events that are generated when
    an action is executed. For example, in our code for the `ClassifiedAd` aggregate,
    we have an `UpdatePrice` method:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们假设我们不是像在[第8章](4eea9289-d77e-4568-a9c0-c5e1265e3b4e.xhtml) *CQRS - 读取侧*中做的那样将聚合状态保存到数据库中，相反，我们将收集在执行动作时生成的新事件。例如，在我们的`ClassifiedAd`聚合代码中，我们有一个`UpdatePrice`方法：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This method already creates a new event when we call it from our application
    service. We also have the `When` method for projecting events to the aggregate
    state, so when we call the `Apply` method, such as in the preceding code snippet,
    the aggregate state changes accordingly:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从应用程序服务调用它时，这种方法已经创建了一个新的事件。我们还有一个`When`方法用于将事件投影到聚合状态，因此当我们调用`Apply`方法，例如在前面的代码片段中，聚合状态会相应地改变：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'So, if we look at how the aggregate state is changing over time, when we apply
    different events to it on a timeline, it will look like this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们观察聚合状态随时间的变化，当我们按时间线对其应用不同的事件时，它将看起来像这样：
- en: '![](img/55dff57b-3a4d-48d0-a949-b2629dc839aa.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/55dff57b-3a4d-48d0-a949-b2629dc839aa.png)'
- en: In the previous chapters, we were saving the aggregate state to the database
    by committing it to the repository for that aggregate type. Each time we needed
    to perform an operation of the aggregate, we would fetch its state back from the
    database by calling the `Get(int id)` method of the repository.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们通过将聚合状态提交到该聚合类型的存储库来将其保存到数据库中。每次我们需要执行聚合的操作时，我们都会通过调用存储库的`Get(int id)`方法从数据库中检索其状态。
- en: 'Each time we commit a new state, the previous state gets overwritten, so at
    any given moment, our database contains a snapshot of the system state, although
    there could have been many changes that made our system come to that state. We
    can visualize it using the timeline:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们提交新的状态时，之前的状态就会被覆盖，因此在任何给定时刻，我们的数据库都包含系统状态的快照，尽管可能有许多变化使我们的系统达到那种状态。我们可以使用时间线来可视化它：
- en: '![](img/6ef06f95-c9e9-4ad4-8ef3-037b3ba3208c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/6ef06f95-c9e9-4ad4-8ef3-037b3ba3208c.png)'
- en: 'This is how executing any action on an aggregate will look:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是执行聚合上的任何动作将看起来像什么：
- en: '![](img/43b9aed0-a542-4a68-b6d4-5fe7b1171769.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/43b9aed0-a542-4a68-b6d4-5fe7b1171769.png)'
- en: It works very well if we are only interested in the current state of things.
    We know the current sale price for a given classified ad. However, when the product
    owner says that we need to show a graph of the selling price history, we cannot
    do that. Another typical use case would be to only show those ads that had their
    price updated during the last couple of days. We can do this by adding the date
    of the last price update to our aggregate (just for the purpose of showing this
    new search result) but it will only work for new updates. It would mean that we
    cannot show the feature to our users before we collect enough data, since our
    persistence model is unable to provide us with any historical data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只对事物的当前状态感兴趣，那么效果非常好。我们知道特定分类广告的当前售价。然而，当产品所有者说我们需要显示售价历史图时，我们无法做到。另一个典型用例是只显示在过去几天内更新了价格的广告。我们可以通过将最后价格更新的日期添加到我们的聚合（仅用于显示这个新的搜索结果）来实现这一点，但这只适用于新的更新。这意味着在我们收集足够的数据之前，我们不能向用户展示这个功能，因为我们的持久化模型无法提供任何历史数据。
- en: As developers, we often encounter situations where we get some elements of a
    system in an unexpected or invalid state. Usually, we use log files to figure
    out what happened. When this approach fails, we start to interrogate the usual
    suspect—our users, who definitely did something wrong, something that they shouldn't
    have been even able to do. Of course, the users deny everything and say that they
    did nothing wrong, or did nothing at all; it happened **all by itself**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发者，我们经常遇到系统某些元素处于意外或无效状态的情况。通常，我们使用日志文件来找出发生了什么。当这种方法失败时，我们开始审问常被怀疑的对象——我们的用户，他们肯定做了什么错误的事情，甚至他们根本不应该能够做的事情。当然，用户否认一切，说他们什么都没做，或者什么都没做；事情**完全是自发发生的**。
- en: Anyone who has found themselves in such a situation remembers the level of despair
    that is usually associated with an inability to find a cause. We end up dealing
    with the consequences, fixing the system state according to our best knowledge
    of how it should be corrected. Sometimes these issues exist for months, or even
    years, without developers being able to determine the cause of the problem. It
    is because they don't know the sequence of events that happened in the system,
    which led to this invalid state.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 任何曾经陷入这种困境的人都会记得，通常与无法找到原因相关联的绝望程度。我们最终只能处理后果，根据我们最好的知识修复系统状态。有时这些问题存在数月甚至数年，开发者都无法确定问题的原因。这是因为他们不知道系统中发生的事件序列，导致了这种无效状态。
- en: The importance of keeping a history of the events that led to a particular state
    is well described by Mathias Verraes in his blog post from 2014, *Domain-Driven
    Design is Linguistic* ([http://verraes.net/2014/01/domain-driven-design-is-linguistic/](http://verraes.net/2014/01/domain-driven-design-is-linguistic/)).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Mathias Verraes 在他 2014 年的博客文章 *Domain-Driven Design is Linguistic* ([http://verraes.net/2014/01/domain-driven-design-is-linguistic/](http://verraes.net/2014/01/domain-driven-design-is-linguistic/))
    中很好地描述了保持导致特定状态的事件历史的重要性。
- en: As you would read there, having half a million Euros is the final system state.
    However, the preceding sequence of events might lead us to different conclusions
    about some other aspects of the system state that we did not consider before.
    If we want to add the emotional state or the level of happiness of our subjects
    to the system state, we won't be able to get this information if we haven't stored
    the history of events.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所读到的，拥有五十万欧元是最终的系统状态。然而，之前的事件序列可能会让我们对系统状态的某些其他方面得出不同的结论，这是我们之前没有考虑到的。如果我们想将我们的主题的情感状态或幸福水平添加到系统状态中，如果我们没有存储事件的历史，我们将无法获取这些信息。
- en: The issue of collecting the history of changes, for both reporting and debugging,
    can often be solved by introducing an artificial log of changes. Then, it would
    seem that all changes are being captured for future analysis. At the same time,
    there will be no direct relationship between event processing and records in the
    audit log. It could potentially lead to situations wherein some changes won't
    be recorded.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于收集变更历史，无论是为了报告还是调试，通常可以通过引入一个人工的变更日志来解决。这样，似乎所有变更都被捕获以供未来分析。同时，事件处理与审计日志中的记录之间将没有直接关系。这可能导致某些变更不会被记录。
- en: Another issue with only keeping the latest state is that to get any information
    about the system, we can only rely on those tables or documents that we use to
    persist our aggregates. Of course, if we have a CQRS system with two databases,
    we will be fetching the information from the read-side. But for those cases when
    we need to have a new screen in the system that contains data from different existing
    read models, the only thing we can do is make a complex query with joins to get
    the data we need. With time, it might diminish the advantages of using CQRS, because
    what we used to have optimized for reading is not tuned anymore, considering a
    bunch of new queries spanning across what looked like a perfectly clean model
    a while ago.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 仅保留最新状态的问题的另一个问题是，要获取关于系统的任何信息，我们只能依赖于我们用来持久化聚合的表或文档。当然，如果我们有一个具有两个数据库的CQRS系统，我们将从读取端获取信息。但对于那些需要在新屏幕中包含来自不同现有读取模型的数据的情况，我们唯一能做的就是执行一个复杂的带有连接的查询来获取所需的数据。随着时间的推移，这可能会削弱使用CQRS的优势，因为我们以前为了优化读取而优化的东西现在不再调整，考虑到一段时间前看起来完美无瑕的模型，现在却有一系列新的查询跨越了它。
- en: What is Event Sourcing?
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是事件溯源？
- en: We often need to see what behavior has triggered the state transition, and that
    is why we started using domain events. However, without having those events stored
    somewhere, to be used as the source of truth for the system state, we can never
    be sure that the behavior that we have recorded is precisely the one that brought
    our system to the state where it is now.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常需要看到哪些行为触发了状态转换，这就是我们开始使用领域事件的原因。然而，如果没有将这些事件存储在某个地方，用作系统状态的真相来源，我们就永远无法确定我们记录的行为是否正是将我们的系统带到当前状态的那个行为。
- en: The principle of Event Sourcing is encoded in its name. It is quite simple.
    We already have an event generation in place in our code. So, instead of persisting
    the state of our aggregate, we save all new events to the database. When we fetch
    the aggregate from the database, instead of reading its state as one record in
    a table or document, we read all events that were saved before and call the `When`
    method for each of those events. By doing that, we get the aggregate state reconstructed
    from history.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 事件溯源的原则体现在其名称中。它相当简单。我们已经在代码中实现了事件生成。因此，我们不是持久化聚合的状态，而是将所有新事件保存到数据库中。当我们从数据库中检索聚合时，我们不是像在表或文档中读取一个记录的状态，而是读取之前保存的所有事件，并对每个事件调用`When`方法。通过这样做，我们根据历史记录重建了聚合状态。
- en: Then, when we need to execute a command, we call a method of the aggregate,
    it generates new events, and we add those events to the list of events that are
    already in the database for that aggregate. It means that we never change or remove
    anything in the database; we only append new events.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，当我们需要执行一个命令时，我们调用聚合的方法，它生成新的事件，我们将这些事件添加到数据库中该聚合已经存在的事件列表中。这意味着我们永远不会更改或删除数据库中的任何内容；我们只追加新的事件。
- en: 'We can visualize the execution of a single operation like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样可视化单个操作的执行：
- en: '![](img/81f33f9e-34ab-4d61-bc4d-cf244cb07047.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/81f33f9e-34ab-4d61-bc4d-cf244cb07047.png)'
- en: Notice that although reading the aggregate might look more complicated since
    we are doing two activities (reading and executing `When`), in the code, it seems
    the same. We need to put the code to do the whole `Get` into the persistence implementation,
    and it will allow us to keep the persistence implementation unchanged, at least
    for the reading part.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，尽管读取聚合可能看起来更复杂，因为我们正在进行两个活动（读取和执行`When`），但在代码中，它似乎是一样的。我们需要将执行整个`Get`的代码放入持久化实现中，这将使我们能够保持持久化实现不变，至少对于读取部分来说是这样。
- en: This approach addresses the issues of having historical data for different purposes—as
    an audit log, as a ledger, as a source for reports that need to get data from
    the past, and as a path that could help to find a trail that led the system to
    come into an invalid state.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法解决了为不同目的保留历史数据的问题——作为一个审计日志、作为一个账本、作为一个需要从过去获取数据的报告来源，以及作为一个可能帮助找到导致系统进入无效状态的路径。
- en: One of the significant advantages of Event Sourcing is that it removes impedance
    mismatch. We were discussing this issue in [Chapter 7](1c04605e-ffe3-49fb-94c6-2bb6e4fe269d.xhtml), *Consistency
    Boundary*, when we talked about persisting aggregates to relational and document
    databases. Since using Event Sourcing we stop persisting object as-is entirely,
    the impedance mismatch just becomes irrelevant. Remember how complex the mapping
    between objects and databases could be? Being able to remove this burden from
    the software development process is a precious feature of using events to persist
    objects.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 事件源的一个显著优势是它消除了阻抗不匹配。我们曾在[第7章](1c04605e-ffe3-49fb-94c6-2bb6e4fe269d.xhtml)“一致性边界”中讨论过这个问题，当时我们谈到将聚合体持久化到关系数据库和文档数据库。自从使用事件源以来，我们完全停止了以原样持久化对象，阻抗不匹配就变得无关紧要了。还记得对象和数据库之间映射可能多么复杂吗？能够从软件开发过程中移除这一负担是使用事件持久化对象的宝贵特性。
- en: Event Sourcing around us
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 周围的事件源
- en: Although it might look like Event Sourcing is a new technique, it is not.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管事件源可能看起来是一种新技术，但它并不是。
- en: Back in 2007, Greg Young started the process of shaping Event Sourcing into
    the form that we have now. But, as Greg mentioned several times, we can trace
    similar techniques back to ancient Mesopotamia. The origins of writing are related
    to accounting, and cuneiform writing, the first known writing, was initially developed
    for accounting purposes. We know that from around 3500 BC, scribes recorded commercial
    transactions on clay tablets. Those tablets were then dried, making permanent,
    unchangeable records.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 回到2007年，格雷格·杨（Greg Young）开始将事件源塑造成我们现在的形式。但是，正如格雷格多次提到的，我们可以将这些类似的技术追溯到古代美索不达米亚。文字的起源与会计有关，楔形文字，已知的第一种文字，最初是为了会计目的而开发的。我们知道，从公元前3500年左右开始，书记员在泥板上记录商业交易。这些泥板随后被晾干，形成永久、不可更改的记录。
- en: Accounting has changed a lot since Mesopotamian and Sumerian times. Nevertheless,
    modern principles of accounting are similar to Event Sourcing. Each operation
    in double-entry accounting is recorded at least twice—once on a debit account
    and once on a credit account. These two records form one operation. The sum of
    amounts within an operation must be zero. There is no concept of state for an
    account in the chart of accounts. The running balance is a sum of the starting
    balance and the amounts from any record on that account. So, to get the current
    balance, we need to read all the records for that account.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 会计自美索不达米亚和苏美尔时代以来已经发生了很大变化。尽管如此，现代会计原则与事件源相似。复式记账法中的每一笔交易至少记录两次——一次在借方账户上，一次在贷方账户上。这两条记录构成一笔交易。一笔交易中金额的总和必须为零。在账户表中没有账户的状态概念。运行余额是期初余额和该账户上任何记录的金额之和。因此，要获取当前余额，我们需要读取该账户的所有记录。
- en: The same technique is used in many areas of finance. An example that we are
    all familiar with is banking. Bank accounts follow the same rule as accounts in
    bookkeeping. There is no *account balance* that is stored in a large SQL table
    that is called `Accounts`, in a field called `Balance`. It won't be possible for
    a bank to prove that the balance is correct in case of any disputes. The balance
    is therefore calculated by summing the amounts of all the transactions for that
    account. Of course, for a very intensively-used account, such sums would take
    too long to figure out. In this case, the bank makes an account snapshot once
    in a while. Most of us are familiar with the concept of the fiscal year. On one
    day, by the end of the fiscal year, all balances get fixed and all accounting
    is started anew, only transferring balances from the previous year.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的技术在金融的许多领域都被使用。我们都很熟悉的例子是银行业务。银行账户遵循与簿记中账户相同的规则。在名为“Accounts”的大SQL表中，没有存储在名为“Balance”的字段中的*账户余额*。在发生任何争议的情况下，银行无法证明余额是正确的。因此，余额是通过计算该账户所有交易的金额总和来计算的。当然，对于非常频繁使用的账户，这样的总和可能需要太长时间才能计算出来。在这种情况下，银行会偶尔制作账户快照。我们大多数人都熟悉财政年度的概念。在财政年度结束的那一天，所有余额都会固定下来，所有会计工作都会重新开始，只是将上一年度的余额转移过来。
- en: 'In any case, there are two common principles of Event Sourcing that are observed
    in real-world applications, such as accounting and banking:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，在现实世界的应用中，如会计和银行业务，都观察到了事件源的两个常见原则：
- en: Events are recorded for each operation, so an object state can be reconstructed
    by reading all those events
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每笔交易都会记录事件，因此可以通过读取所有这些事件来重建对象状态。
- en: Events cannot be changed or removed, because such an operation would undermine
    the whole concept of the audit log and make it invalid
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件不能被更改或删除，因为这会破坏整个审计日志的概念并使其无效。
- en: For the purpose of corrections, accountants make new transactions that compensate
    for previously-entered operations that appeared to be incorrect. The same happens
    in banks. If you get an amount placed on your account by mistake, the bank will
    never **remove** the transaction, although it is wrong. You will see another transaction
    on your account, taking the same sum of money away from you. We can also see it
    happening when we get partial refunds. Instead of changing the sum of a transaction
    that is being partially refunded, we get a new transaction for the amount of the
    partial refund.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了纠正错误，会计人员会创建新的交易来补偿之前输入的看似不正确的操作。在银行中也是如此。如果你账户上被错误地放置了一笔金额，银行永远不会**删除**这笔交易，尽管它是错误的。你会在账户上看到另一笔交易，从你那里扣除相同的金额。我们也可以在获得部分退款时看到这种情况。我们不会改变部分退款交易的金额，而是会得到一笔新的交易，用于部分退款的金额。
- en: Event Sourced aggregates
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件源聚合体
- en: Now, it is time to take a better look at how we can persist aggregates by saving
    the history of changes. In this section, we will discuss what event streams are
    and how we can use streams to persist aggregates to an event store and retrieve
    them. Of course, this implies that we will cover the topic of event stores, as
    well.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候更深入地了解我们如何通过保存变更历史来持久化聚合体了。在本节中，我们将讨论事件流是什么，以及我们如何使用流将聚合体持久化到事件存储中并检索它们。当然，这也意味着我们将涵盖事件存储的主题。
- en: Event streams
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件流
- en: So far, on all of the diagrams, we have seen events for only one aggregate.
    Of course, such a system is useless, and we need to find a way to store events
    for different aggregates, in order to make the system functional. The main requirement
    here would be that we need to be able to retrieve events for a single aggregate,
    preferably in one read. Of course, if there are thousands of events, we will need
    to split the read into multiple batches, but this is not in our scope right now.
    To achieve this ability to read events for only one aggregate, we need to write
    events with some metadata that indicates the aggregate identity. The second requirement is
    that events need to be read in the same strict order as they were written; and
    when we write changes as events to the database, these events need to be written
    in the exact order as we send them to the database.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在所有图表中，我们只看到了一个聚合体的事件。当然，这样的系统是没有用的，我们需要找到一种方法来存储不同聚合体的事件，以便使系统功能化。这里的主要要求是我们需要能够检索单个聚合体的事件，最好是单次读取。当然，如果有成千上万的事件，我们需要将读取分成多个批次，但这目前不在我们的范围内。为了实现只读取单个聚合体事件的这种能力，我们需要写入带有一些元数据的事件，这些元数据指示聚合体标识符。第二个要求是事件需要按照它们被写入的严格顺序读取；当我们将更改作为事件写入数据库时，这些事件需要按照我们发送到数据库的确切顺序写入。
- en: Events that are coming to the system in a particular order form an event stream.
    For the purpose of Event Sourcing, the most comfortable solution would be to have
    a database that allows us to have one stream per aggregate. In this case, we will
    write to a known stream and read from it. The stream name will be a combination
    of the aggregate type and the aggregate identity; for example, for our `ClassifiedAd`
    aggregate with an ID of `e99460470a7b4133827d06f32dd4714e`, the stream name would
    be `ClassifiedAd-e99460470a7b4133827d06f32dd4714e`. An aggregate stream contains
    all events that happened during the aggregate life cycle. When we decide that
    we don't need the aggregate in the system, we can either remove the whole stream
    or write a final event, such as `ClassifiedAdRemoved`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 按照特定顺序进入系统的事件形成事件流。为了实现事件源，最舒适的解决方案是拥有一个数据库，允许我们为每个聚合体创建一个单独的事件流。在这种情况下，我们将向一个已知的流中写入并从中读取。流名称将是聚合体类型和聚合体标识符的组合；例如，对于我们的`ClassifiedAd`聚合体，其ID为`e99460470a7b4133827d06f32dd4714e`，流名称将是`ClassifiedAd-e99460470a7b4133827d06f32dd4714e`。一个聚合体流包含在聚合体生命周期中发生的所有事件。当我们决定系统不再需要聚合体时，我们可以删除整个流或写入一个最终事件，例如`ClassifiedAdRemoved`。
- en: A critical feature of a database that we can use to persist events is to have
    a single stream with all events that have ever come to the system, in addition
    to individual streams. It won't be ideal, but we can deduce aggregate streams
    by controlling the stream ID metadata property, in case our database doesn't support
    separate streams natively. However, having a single stream that contains all events
    is absolutely necessary. Throughout the course of this book, we will reference
    this master stream as the `$all` stream, because this is what it is called in
    the Event Store, the database that we will use in our examples.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库的一个关键特性，我们可以用它来持久化事件，是除了单个流之外，还有一个包含系统中所有事件的单一流。这不会是最理想的，但我们可以通过控制流ID元数据属性来推断聚合流，以防我们的数据库不支持原生分离的流。然而，拥有包含所有事件的单一流是绝对必要的。在整个本书的过程中，我们将把这个主流称为`$all`流，因为在Event
    Store（我们将用于示例的数据库）中，它就是这样被称呼的。
- en: It is crucial to understand that we are referring to the same events when dealing
    with the `$all` stream and aggregate streams. You can see it in a way that all
    events are always present in the `$all` stream but in addition, there is an index
    that is put on top of these events. This index tells the system which individual
    stream an event belongs to.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这一点至关重要，当我们处理`$all`流和聚合流时，我们指的是相同的事件。你可以这样理解，所有事件始终存在于`$all`流中，但除此之外，还有一个对这些事件建立的索引。这个索引告诉系统一个事件属于哪个单个流。
- en: 'The following diagram represents the `$all` stream with some events that are
    also indexed per aggregate stream:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表表示了包含一些按聚合流索引的事件的`$all`流：
- en: '![](img/1f044552-bfa3-4849-8969-33e13ed65e55.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f044552-bfa3-4849-8969-33e13ed65e55.png)'
- en: Aggregate streams and the $all stream
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合流和$all流
- en: So far, we have been able to formulate the requirements for a database that
    we can use to persist our aggregate as streams of events. Now, we will look at
    concrete examples of such databases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经能够制定出我们可以用来持久化我们的聚合为事件流的数据库的要求。现在，我们将查看此类数据库的具体示例。
- en: Event stores
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件存储
- en: In the preceding section, we discussed that in order to consider a database
    to be used as an event store, we need to ensure that this database can store events
    and metadata and put indexes on the metadata. We cannot put any indexes on events,
    because there is no single denominator for event objects; they are all different.
    Metadata, however, is structured in a known way. For example, the stream name
    must be present in the metadata for all events.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了为了将数据库视为事件存储，我们需要确保这个数据库可以存储事件和元数据，并在元数据上建立索引。我们不能在事件上建立任何索引，因为事件对象没有单一的公因数；它们都是不同的。然而，元数据是以已知的方式结构化的。例如，流名称必须在所有事件的元数据中存在。
- en: 'Such a definition could lead us to a conclusion that any database that supports
    querying events by stream ID can be used as an event store. This is true. Here,
    you can find examples of how different databases can be used as event stores:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的定义可能会让我们得出结论，任何支持通过流ID查询事件的数据库都可以用作事件存储。这是真的。在这里，你可以找到不同数据库如何用作事件存储的例子：
- en: '| Database | How to store events | How to read a single stream |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 数据库 | 如何存储事件 | 如何读取单个流 |'
- en: '| --- | --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| RDBMS (SQL Server, PostgreSQL, and so on) | Use a single table; add one column
    for the stream name and one column for the event payload. One row is one event.
    | Select all rows where the stream name is what we want. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 关系数据库管理系统（SQL Server、PostgreSQL等） | 使用单个表；为流名称添加一个列，为事件负载添加一个列。一行是一个事件。 |
    选择所有流名称是我们想要的行。 |'
- en: '| Document database (MongoDB, Azure Cosmos DB, RavenDB) | Use a document collection.
    Each document should have a metadata object and a field to store the payload.
    One document is one event. | Query all documents where the stream name (part of
    the metadata) is what we need. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 文档数据库（MongoDB、Azure Cosmos DB、RavenDB） | 使用文档集合。每个文档都应该有一个元数据对象和一个用于存储负载的字段。一个文档就是一个事件。
    | 查询所有流名称（元数据的一部分）是我们需要的所有文档。 |'
- en: '| Partitioned tables (Azure Table Storage, AWS DynamoDB) | Use a single table;
    add one field for the stream name (or ID) to be used as the partition key and
    another field as the row key (Azure) or sort key (DynamoDB). The third field will
    contain the event payload. One record is one event. | Query all records where
    the partition key is the name of the stream we are reading. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 分区表（Azure Table Storage、AWS DynamoDB） | 使用单个表；添加一个用于流名称（或 ID）的字段，作为分区键，并添加另一个字段作为行键（Azure）或排序键（DynamoDB）。第三个字段将包含事件负载。一条记录代表一个事件。
    | 查询所有分区键为正在读取的流名称的记录。 |'
- en: '| Specialized database (Event Store) | Native support for streams. | Read all
    events from a single stream. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 专用数据库（事件存储） | 原生支持流。 | 从单个流中读取所有事件。 |'
- en: Notice that for some relational databases, there are tools and libraries that
    can help to store events for Event Sourced systems. For example, the Marten framework
    ([http://jasperfx.github.io/marten/](http://jasperfx.github.io/marten/)) uses
    the native PostgreSQL feature to store unstructured data in JSONB-type columns
    and has an event store implementation based on that database. The SQL Stream Store
    ([https://github.com/SQLStreamStore/SQLStreamStore](https://github.com/SQLStreamStore/SQLStreamStore))
    can also help you to use a variety of relational databases, including Microsoft
    SQL Server and PostgreSQL, as event stores. Both of these open source tools are
    actively being used in production systems around the world and have active communities
    behind them.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于某些关系型数据库，存在一些工具和库可以帮助存储事件源系统的数据。例如，Marten 框架([http://jasperfx.github.io/marten/](http://jasperfx.github.io/marten/))利用原生
    PostgreSQL 功能在 JSONB 类型的列中存储非结构化数据，并基于该数据库实现了一个事件存储。SQL Stream Store ([https://github.com/SQLStreamStore/SQLStreamStore](https://github.com/SQLStreamStore/SQLStreamStore))也可以帮助你使用各种关系型数据库，包括
    Microsoft SQL Server 和 PostgreSQL，作为事件存储。这两个开源工具在全球的生产系统中被积极使用，并且背后都有活跃的社区支持。
- en: So far, we've been concentrating on persisting a single aggregate as an event
    stream and reading all events for a single aggregate from the database. However,
    this is not the only characteristic that we need to be looking at for an event
    store that we would be comfortable using. If you haven't noticed yet, we haven't
    touched the query part, when we need to read data for some aggregates, based on
    some criteria. Our primary requirement for an event store does not include the
    ability to query anything except events by the stream name. Definitely, a query
    such as `ClassifiedAdsPendingReview` wouldn't be possible, just because we would
    need to read all events (potentially millions) for all classified ads and then
    query in the memory. This is not a feasible approach for production, although
    it might be quite useful for prototyping. To solve this issue, we need to get
    back to CQRS, and this time, we need to use domain events to build our read models.
    In the case of an Event Sourced system, we will have to use a conventional database,
    SQL or NoSQL, which can be queried, to handle the query side of CQRS, and this
    query side can only be built from events. Thus, we need to have a reliable way
    to get real-time (or near real-time) updates about all new events from  the event
    store to our read model builders. If we use traditional relational databases to
    store events, we almost inevitably turn to frequent polling. Some NoSQL databases,
    such as Azure Cosmos DB, RavenDB, and AWS DynamoDB, let us subscribe to the change
    stream and get information about all database operations. We will be using the
    term *subscription* when talking about this feature.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直专注于将单个聚合体作为事件流进行持久化，并从数据库中读取单个聚合体的所有事件。然而，这并不是我们需要关注的事件存储的唯一特性。如果你还没有注意到，我们还没有涉及到查询部分，当我们需要根据某些标准读取某些聚合体的数据时。我们对事件存储的主要要求并不包括通过流名称查询任何内容的能力。显然，像“ClassifiedAdsPendingReview”这样的查询是不可能的，因为我们可能需要读取所有分类广告的所有事件（可能数百万），然后在内存中进行查询。这种方法对于生产环境来说并不可行，尽管它可能对原型设计非常有用。为了解决这个问题，我们需要回到
    CQRS，这次我们需要使用领域事件来构建我们的读取模型。在事件源系统中，我们将不得不使用一个传统的数据库，SQL 或 NoSQL，它可以被查询，以处理 CQRS
    的查询方面，而这个查询方面只能从事件中构建。因此，我们需要有一种可靠的方法，从事件存储实时（或接近实时）地获取所有新事件的信息，并将其传递给我们的读取模型构建者。如果我们使用传统的关系型数据库来存储事件，我们几乎不可避免地会转向频繁轮询。一些
    NoSQL 数据库，如 Azure Cosmos DB、RavenDB 和 AWS DynamoDB，允许我们订阅变更流，并获取所有数据库操作的信息。当我们讨论这个特性时，我们将使用术语“订阅”。
- en: For all of the examples in this book, we will be using the Event Store ([https://eventstore.org](https://eventstore.org),)
    because it has years of experience building Event Sourced systems put into it
    by its creator, the *father* of CQRS and longtime advocate of Event Sourcing,
    Greg Young, the company behind this product and the open source developers community
    that keeps helping to make Event Store better. In addition, this product is free,
    and you only need to pay to get production-grade support. The Event Store has
    native support for store events, and it has transactional writes; we can subscribe
    to event streams to get all new (and existing) events from there, and so on.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本书中的所有示例，我们将使用事件存储库（[https://eventstore.org](https://eventstore.org)，）因为它包含了其创建者，CQRS的*之父*，长期倡导事件源模式的Greg
    Young，以及支持该产品的公司以及开源开发者社区多年的经验。此外，此产品是免费的，您只需付费即可获得生产级支持。事件存储库原生支持存储事件，并具有事务性写入；我们可以订阅事件流以获取所有新的（和现有的）事件，等等。
- en: Before going further, please ensure that you have completed the steps described
    in the *Technical requirements* section.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请确保您已经完成了*技术要求*部分中描述的步骤。
- en: Event-oriented persistence
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以事件为导向的持久化
- en: Now, we are going to write some code that will allow us to use events to persist
    our aggregates.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将编写一些代码，使我们能够使用事件来持久化我们的聚合。
- en: In [Chapter 9](6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml), *CQRS - The Read
    Side*, we used repositories to store aggregates, but now, we will do something
    else. Appending events to a stream for the `ClassifiedAd` aggregate is no different
    from doing the same thing for the `UserProfile` aggregate. The specifics of repositories
    therefore disappear, and everything about persisting aggregates and retrieving
    them is done in exactly the same way. Consequently, we can use one interface, `IAggregateStore`,
    that will handle the persistence for any type of aggregate.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml)，*CQRS - 读取侧*中，我们使用存储库来存储聚合，但现在，我们将做些不同的事情。将事件追加到`ClassifiedAd`聚合的流中与对`UserProfile`聚合做同样的事情没有区别。因此，存储库的具体细节消失了，关于持久化聚合和检索它们的所有事情都是完全以相同的方式进行。因此，我们可以使用一个接口，`IAggregateStore`，它将处理任何类型聚合的持久化。
- en: Now, let's start to implement some lower-level code to write events to Event
    Store streams and read them back. It will include serialization, paging, type
    handling, and optimistic concurrency.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始实现一些低级代码，以将事件写入事件存储库流并读取它们。它将包括序列化、分页、类型处理和乐观并发。
- en: Throughout this chapter, we will be using the term **event store** when talking
    about a place where we can write events to streams and read them back. When we
    use the term Event Store, we will be referring to the product that you should
    have been able to execute by following the *Technical requirements* section.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，当我们谈论可以写入事件到流并读取它们的地方时，我们将使用术语**事件存储库**。当我们使用术语Event Store时，我们将指的是您应该能够通过遵循*技术要求*部分来执行的产品。
- en: Writing to Event Store
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 写入事件存储库
- en: 'Before any read, there must be a write, so that is where we will start. Let''s
    look at the Event Store API to write events to streams. The method that we would
    most likely use is this one:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何读取之前，必须有一个写入，所以这就是我们将开始的地方。让我们看看事件存储库API来写入事件到流。我们最可能使用的方法是以下这个：
- en: '[PRE3]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'All of the parameters here are quite clear: a stream name and a list of events
    to be saved to the stream. Besides, we need to supply the aggregate version to
    handle optimistic concurrency. It will prevent overriding changes that someone
    else could have made in parallel by processing another command for the same aggregate.
    Event Store supports stream versioning out of the box, and we just need to supply
    the expected version when trying to save new events to the stream.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这里所有的参数都很清晰：一个流名称和要保存到流中的事件列表。此外，我们还需要提供聚合版本以处理乐观并发。它将防止其他人通过处理同一聚合的另一个命令并行进行的更改被覆盖。事件存储库默认支持流版本控制，我们只需在尝试将新事件保存到流中时提供预期的版本即可。
- en: 'We will start to write the code by adding the following interface to the `Marketplace.Framework`
    project:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过向`Marketplace.Framework`项目添加以下接口来开始编写代码：
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can compare it to the repository interfaces we used in [Chapter 8](4eea9289-d77e-4568-a9c0-c5e1265e3b4e.xhtml), *Aggregate
    Persistence*, and you'll see that the new interface is some kind of a generic
    repository. Although we discussed why using generic repositories is usually not
    a good idea, in our case, it is perfectly acceptable, since all persistence aspects are handled
    in the same way for all aggregates.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将它与我们在[第8章](4eea9289-d77e-4568-a9c0-c5e1265e3b4e.xhtml)，“聚合持久化”中使用的存储库接口进行比较，你会发现新的接口是一种通用的存储库。尽管我们讨论了为什么通常使用通用存储库不是一个好主意，但在我们的情况下，这是完全可以接受的，因为所有聚合的持久化方面都以相同的方式处理。
- en: 'The serialization code would require some external dependencies to be installed.
    In the preceding snippet, we used the `JsonConvert` class for serializing events
    to JSON. Therefore, we need to add the `Newtonsoft.Json` package to our `Marketplace.Framework`
    project. To get the Event Store API, we also need the `EventStore.ClientAPI.NetCore`
    package. We can either use the Manage NuGet Packages context menu on the project
    or run the following two commands in the Terminal window:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化代码需要安装一些外部依赖项。在前面提供的代码片段中，我们使用了`JsonConvert`类将事件序列化为JSON。因此，我们需要将`Newtonsoft.Json`包添加到我们的`Marketplace.Framework`项目中。为了获取事件存储API，我们还需要`EventStore.ClientAPI.NetCore`包。我们可以通过项目上的“管理NuGet包”上下文菜单，或者在终端窗口中运行以下两个命令来完成：
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now, we can start implementing this interface in a new class, `EsAggregateStore`,
    that we will add to the `Infrastructure` folder of the `Marketplace` project.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在一个新的类`EsAggregateStore`中开始实现这个接口，我们将把这个类添加到`Marketplace`项目的`Infrastructure`文件夹中。
- en: 'First, the stream name. At the beginning of this chapter, we already went through
    the concept of event streams, and since writing into one stream is a transaction,
    a stream becomes our transaction boundary, along with the aggregate boundary too.
    We will use the aggregate-per-stream strategy, and therefore, we can safely make
    the stream name derive from our aggregate name. But, what are the names of our
    aggregates? Well, we can start with the CRL type, such as `Marketplace.Domain.ClassifiedAd`.
    Then, we need to make those names unique. To do this, the obvious solution would
    be to add an aggregate ID. I want to cover two cases to create the stream ID: when
    we have an aggregate that needs to be persisted, and when we just have an ID of
    an aggregate that we want to load. To do that, I will add two methods to the `EsAggregateStore`
    class:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，是流名称。在本章的开头，我们已经讨论了事件流的概念，并且由于写入一个流是一个事务，流就成为了我们的事务边界，连同聚合边界一起。我们将使用聚合-流策略，因此我们可以安全地将流名称从我们的聚合名称派生出来。但是，我们的聚合名称是什么呢？嗯，我们可以从CRL类型开始，比如`Marketplace.Domain.ClassifiedAd`。然后，我们需要使这些名称唯一。为此，一个明显的解决方案是添加一个聚合ID。我想讨论两种创建流ID的情况：当我们需要持久化一个聚合时，以及当我们只想加载一个聚合的ID时。为了做到这一点，我将在`EsAggregateStore`类中添加两个方法：
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Looking further at the list of parameters for `AppendToStreamAsync`, the method
    doesn''t accept `IEnumerable<object>`, but instead expects a collection of objects
    that have the `EventData` type. This class has the following public members:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步查看`AppendToStreamAsync`方法的参数列表，这个方法不接受`IEnumerable<object>`，而是期望一个具有`EventData`类型的对象集合。这个类有以下公共成员：
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For us, it is important to understand that we need to save the event type as
    a string, so that we can deserialize the event back to an object of the event
    CLR type. We also have to convert the event object to a byte array when we save
    events, and convert a byte array to an object when we read events. So, for `Type`,
    we can again use the CLR type name of the event object. For the payload (`Data`),
    we can use whatever serialization is useful.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们来说，重要的是要理解我们需要将事件类型保存为字符串，这样我们才能将事件反序列化回事件CLR类型的对象。在保存事件时，我们还需要将事件对象转换为字节数组，在读取事件时将字节数组转换为对象。因此，对于`Type`，我们再次可以使用事件对象的CLR类型名称。对于有效载荷（`Data`），我们可以使用任何有用的序列化方式。
- en: Nevertheless, Event Store has a nice UI that can show us the content of events,
    but it only does that if an event is serialized as JSON. This is exactly what
    the `IsJson` Boolean property is for. For the majority of applications, which doesn't
    require optimizing the performance by using more compact representations and a
    faster serialization process, such as protobuf, it is enough to use JSON, and
    that's what we are going to do.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，事件存储有一个不错的用户界面，可以显示事件的内容，但它只会在事件被序列化为JSON格式时这样做。这正是`IsJson`布尔属性的作用所在。对于大多数不需要通过使用更紧凑的表示和更快的序列化过程（如protobuf）来优化性能的应用程序，使用JSON就足够了，这正是我们打算做的。
- en: 'Since we need to convert our objects to byte arrays and still use JSON, we
    can create a method that will help us in doing that:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们需要将我们的对象转换为字节数组并仍然使用JSON，我们可以创建一个方法来帮助我们完成这个任务：
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Then, we need to think of how to get a list of new events from an aggregate
    and build a collection of `EventData` objects to represent those events.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要考虑如何从一个聚合中获取新事件的列表，并构建一个表示这些事件的`EventData`对象集合。
- en: 'From the very early versions of our application, we have the `GetChanges` method.
    First, we had it in the `Entity` base class, which we later renamed `AggregateRoot`.
    We can finally start using this method to get all new events that are generated
    as part of command execution. Here is the code that will get all changes from
    an aggregate and build a collection of `EventData` objects, just like we need
    for calling the `AppendToStreamAsync` method:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们应用的早期版本开始，我们就有了`GetChanges`方法。最初，它在`Entity`基类中，后来我们将其重命名为`AggregateRoot`。我们最终可以开始使用这个方法来获取作为命令执行一部分生成的新事件。以下是获取聚合的所有更改并构建一个`EventData`对象集合的代码，正如我们调用`AppendToStreamAsync`方法所需的那样：
- en: '[PRE9]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the preceding snippet, we specify the short event type name to be used as
    the event type in Event Store. It will be something like `ClassifiedAdRenamed`.
    But, when we start loading events back, we need to deserialize JSON strings back
    to concrete event types. The `Newtonsoft.Json` library won''t understand the short-type;
    it needs to know the **fully-qualified class name** (**FQCN**). If the events
    are defined in a different assembly, we also need to include the assembly information.
    If we use FQCN as an event type for Event Store, we will get quite an ugly picture
    in the Event Store UI, since it will be polluted with all that technical information
    about namespaces and assembly names. I don''t like that, and therefore, I will
    still use the short-type name. However, we need a way to be able to tell the deserializer
    about the concrete event type. The best place to store any kind of technical information
    about the event is metadata, and that''s what I am going to do. First, I will
    add a private nested class that we''ll use for the event metadata:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们指定了要作为事件类型在事件存储中使用的短事件类型名称。它可能类似于`ClassifiedAdRenamed`。但是，当我们开始加载事件时，我们需要将JSON字符串反序列化为具体的事件类型。`Newtonsoft.Json`库不会理解短类型；它需要知道**完全限定类名**（**FQCN**）。如果事件定义在不同的程序集（assembly）中，我们还需要包含程序集信息。如果我们使用FQCN作为事件存储的事件类型，那么在事件存储UI中我们会看到一个相当丑陋的画面，因为它会被所有关于命名空间和程序集名称的技术信息所污染。我不喜欢这样，因此我仍然会使用短类型名称。然而，我们需要一种方法来告诉反序列化器具体的事件类型。存储关于事件的技术信息的最佳位置是元数据，这正是我将要做的。首先，我将添加一个私有的嵌套类，我们将用它来存储事件元数据：
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, I can modify the preceding code snippet to keep the FQCN with the event,
    as metadata:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我可以修改前面的代码片段，将FQCN与事件一起作为元数据保留：
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Using the event CLR type name as the event name and the FQCN in the event metadata
    is a temporary solution. For production systems, I would recommend using the concept
    of a *type mapper*, which translates CLR types to strings and back. This method
    gives you some freedom to change namespaces if needed, without breaking the ability
    to deserialize events that were persisted in the past. I will not go into detail
    on using the type mapper, but you will find the working code in the repository
    for [Chapter 13](https://www.packtpub.com/sites/default/files/downloads/Splitting_the_System.pdf), *Splitting
    the System*.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用事件CLR类型名称作为事件名称和在事件元数据中的FQCN是一个临时解决方案。对于生产系统，我建议使用**类型映射器**的概念，它将CLR类型转换为字符串，然后再转换回来。这种方法给你一些灵活性，在需要的情况下更改命名空间，而不会破坏过去持久化的事件的反序列化能力。我不会详细介绍如何使用类型映射器，但你将在[第13章](https://www.packtpub.com/sites/default/files/downloads/Splitting_the_System.pdf)的代码库中找到工作代码，*Splitting
    the System*。
- en: 'Let''s put this code into our new `EsAggregateStore` class:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这段代码放入我们的新`EsAggregateStore`类中：
- en: '[PRE12]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The only thing that we have not touched upon previously is `IEventStoreConnection`.
    All reads and writes between our application and Event Store need to be executed
    on the open TCP connection to the Event Store cluster, which can also be a single-node
    cluster that we can create by running the Docker image. Our application will establish
    the connection when it starts, and we need to close the connection when the application
    stops. We will add this infrastructure code to our executable project.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前没有涉及到的唯一一件事是 `IEventStoreConnection`。我们应用程序和事件存储之间的所有读取和写入操作都需要在打开到事件存储集群的TCP连接上执行，这也可以是一个通过运行Docker镜像创建的单节点集群。我们的应用程序将在启动时建立连接，我们需要在应用程序停止时关闭连接。我们将把这个基础设施代码添加到我们的可执行项目中。
- en: Reading from Event Store
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从事件存储中读取
- en: 'In our application service, the only command that doesn''t require reading
    an aggregate before handling is the `CreateClassifiedAd` command. For all other
    actions, we need to read our aggregate first, and that''s what we do by calling
    `_store.Load<ClassifiedAd>(id.ToString())`. While saving an aggregate to the store
    by collecting all changes and saving them to an event stream seems quite obvious,
    reading the aggregate back from the event stream is a little less trivial. Let''s
    describe the steps to retrieve an aggregate from the event store:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的应用程序服务中，唯一一个在处理之前不需要读取聚合的命令是 `CreateClassifiedAd` 命令。对于所有其他操作，我们需要首先读取我们的聚合，这就是我们通过调用
    `_store.Load<ClassifiedAd>(id.ToString())` 来做的。虽然将聚合保存到存储中，通过收集所有更改并将它们保存到事件流中看起来相当明显，但从事件流中读取聚合要稍微复杂一些。让我们描述从事件存储中检索聚合的步骤：
- en: Find out the stream name for an aggregate
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找聚合的流名称
- en: Read all of the events from the aggregate stream
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从聚合流中读取所有事件
- en: Loop through all of the events, and call the `When` handler for each of them
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历所有事件，并对每个事件调用 `When` 处理器
- en: After we have done all these steps, we will recover all the history of a given
    aggregate and use the aggregate event handling rules to reapply all historical
    events to an empty aggregate object. By doing this, we will be bringing our aggregate
    to its latest state.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成所有这些步骤之后，我们将恢复给定聚合的所有历史记录，并使用聚合事件处理规则将所有历史事件重新应用到空的聚合对象上。通过这样做，我们将把我们的聚合带到其最新状态。
- en: 'In the code, we will do all these steps in the `Load` method of the `EsAggregateStore`
    class:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们将在 `EsAggregateStore` 类的 `Load` 方法中执行所有这些步骤：
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s go through the `Load` method. In steps, it does the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 `Load` 方法来了解这些步骤。按步骤，它执行以下操作：
- en: Ensures that the aggregate ID parameter is not null
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保聚合ID参数不为空
- en: Gets the stream name for a given aggregate type
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取给定聚合类型的流名称
- en: Creates a new instance of the aggregate type by using reflections
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过反射创建聚合类型的新的实例
- en: Reads events from the stream as a collection of `ResolvedEvent` objects
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将流中的事件读取为 `ResolvedEvent` 对象的集合
- en: Deserializes those raw events to a collection of domain events
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些原始事件反序列化为领域事件的集合
- en: Calls the `Load` method of the empty aggregate instance to recover the aggregate
    state
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用空聚合实例的 `Load` 方法以恢复聚合状态
- en: There are a couple of things that need additional explanations.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 有几件事情需要额外的解释。
- en: First, we could have used the `new` constraint on the `T` generic type parameter,
    so we can instantiate an empty aggregate using a parameterless constructor. However,
    that would break encapsulation and force us to expose a public parameterless constructor,
    and we don't want that. Using reflections allows us to invoke the protected constructor
    that we already have in all our aggregate root types. You need to remember that
    this solution might cause performance issues if your system is dealing with loads
    of commands, and in such a case, an alternative solution is required. Exposing
    a public parameterless constructor could be an acceptable trade-off.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以在 `T` 泛型类型参数上使用 `new` 约束，这样我们就可以使用无参构造函数实例化一个空的聚合。然而，这将破坏封装性，并迫使我们公开一个无参构造函数，而我们不想这样做。使用反射允许我们调用我们已经在所有聚合根类型中存在的受保护的构造函数。你需要记住，如果您的系统处理大量命令，这种解决方案可能会引起性能问题，在这种情况下，需要另一个解决方案。公开一个无参构造函数可能是一个可接受的权衡。
- en: Secondly, we use a magic number, `1024`, to read what is called a **stream slice**,
    which is nothing more than a page. Your event streams can get bigger, and the
    Event Store doesn't allow us to read more than 4,096 events at once. For large
    streams, we would need to implement paging, but for this example, it is not necessary,
    since the life cycle of our aggregates don't assume having long streams.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们使用一个魔法数字 `1024` 来读取所谓的 **流切片**，这实际上只是一个页面。您的事件流可能会变得更大，Event Store 不允许我们一次性读取超过
    4,096 个事件。对于大型流，我们需要实现分页，但在这个例子中，由于我们的聚合的生命周期不假设有长流，所以这不是必要的。
- en: 'The last thing is the missing `Load` method for the `AggregateRoot` abstract
    class. We didn''t need this method, because we were not using Event Sourcing before.
    The `Load` method will complete the last step in the aggregate recovery sequence,
    looping through all events and calling the matching `When` for each of them. Let''s
    see how we can implement this method in the `AggregateRoot` class:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一件事情是 `AggregateRoot` 抽象类中缺失的 `Load` 方法。我们之前不需要这个方法，因为我们没有使用事件溯源。`Load` 方法将完成聚合恢复序列的最后一步，遍历所有事件并为每个事件调用匹配的
    `When`。让我们看看我们如何在 `AggregateRoot` 类中实现这个方法：
- en: '[PRE14]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, it is a very simple piece of code, and essentially, it represents
    what Event Sourcing is. We get a collection of events that we previously stored
    and then rebuild the state of our domain object from those events. The `When`
    method knows how to change the aggregate state for each event in the collection,
    so when we call it for each event from the history, we get our aggregate back
    to the last known state.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这是一段非常简单的代码，本质上，它代表了事件溯源是什么。我们获取我们之前存储的事件集合，然后从这些事件中重建我们的领域对象的状态。`When`
    方法知道如何为集合中的每个事件更改聚合状态，所以当我们为历史中的每个事件调用它时，我们就可以得到我们的聚合回到最后一个已知的状态。
- en: Notice that we also increase the `Version` property of the aggregate for each
    applied event, so we know what version our aggregate should have when we commit
    changes to the store. We discussed the aggregate version when talking about the
    optimistic concurrency. Unlike using state persistence, where we needed to have
    a property in our database for the aggregate version, we don't really store the
    version when we use events, because one event always increases the aggregate version
    by one, so we can just count events to get the current version.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们还为每个应用的事件增加了聚合的 `Version` 属性，这样我们就可以知道在将更改提交到存储时我们的聚合应该有什么版本。我们在讨论乐观并发时讨论了聚合版本。与使用状态持久化不同，我们需要在我们的数据库中有一个属性来存储聚合版本，当我们使用事件时，我们实际上并不存储版本，因为每个事件总是将聚合版本增加一，所以我们只需计算事件数量就可以得到当前版本。
- en: 'One last thing that I need to use to finalize the implementation of the `IAggregateStore`
    interface is the `Exists` method. There is no simple way to ask Event Store whether
    a stream exists, but we can easily overcome this by trying to read a single event
    from a given stream:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一件我需要用来最终实现 `IAggregateStore` 接口的事情是 `Exists` 方法。没有简单的方法来询问 Event Store 是否存在一个流，但我们可以通过尝试从一个给定的流中读取一个事件来轻松克服这个问题：
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: By now, we should have a working implementation of the aggregate persistence
    that uses events.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我们应该有一个使用事件的工作实现聚合持久化。
- en: The wiring infrastructure
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接配置基础设施
- en: To finish the work and make our application make use of all these changes, we
    need to write some initialization code for the Event Store connection, and also
    do the wiring for our application service so that it uses `EsAggregateStore`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成工作并使我们的应用程序利用所有这些更改，我们需要为 Event Store 连接编写一些初始化代码，并且还需要为我们的应用程序服务进行连接配置，以便它使用
    `EsAggregateStore`。
- en: 'First, we need to configure our application by using the .NET Core configuration
    extensions. We will start by adding a simple `appsettings.json` configuration
    file. The content for this file, for now, will just be a connection string for
    Event Store that runs locally:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要通过使用 .NET Core 配置扩展来配置我们的应用程序。我们将从添加一个简单的 `appsettings.json` 配置文件开始。目前，这个文件的内容将只是一个本地运行的
    Event Store 的连接字符串：
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then, we need to read this configuration so that we will have access to these
    values. To do that, we will change the `BuildConfiguration` method of our `Program`
    class:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要读取这个配置，这样我们就可以访问这些值。为此，我们将更改我们的 `Program` 类的 `BuildConfiguration` 方法：
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For the `settings` file to be copied to the application output directory, we
    need to change its properties in the `Marketplace.csproj` file, to ensure that
    the project file has lines like these:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将`settings`文件复制到应用程序输出目录，我们需要在`Marketplace.csproj`文件中更改其属性，以确保项目文件有如下这些行：
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The connection to Event Store needs to open when our application starts and
    close when we shut down the application. To enable this, we will implement the
    `Microsoft.Extensions.Hosting.IHostedService` interface with a new class called
    `HostedService`. To do that, we will add a new file, called `HostedService.cs`,
    to our executable project:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的应用程序启动时，需要打开到事件存储的连接，并在关闭应用程序时关闭。为了启用此功能，我们将使用名为`HostedService`的新类实现`Microsoft.Extensions.Hosting.IHostedService`接口。为此，我们将向可执行项目添加一个名为`HostedService.cs`的新文件：
- en: '[PRE19]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The final wiring takes place in the `Startup.cs` file, where we need to change
    the `ConfigureServices` method so it includes the Event Store connection and the
    `EsAggregateStore` registrations. Also, we need to register our `HostingService`,
    so that the web host knows that it needs to run something on startup and shutdown.
    The new version of the `Startup.ConfigureServices` method looks like this:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的连接发生在`Startup.cs`文件中，我们需要更改`ConfigureServices`方法，使其包括事件存储连接和`EsAggregateStore`注册。此外，我们需要注册我们的`HostingService`，以便网络主机知道它需要在启动和关闭时运行某些操作。`Startup.ConfigureServices`的新版本如下所示：
- en: '[PRE20]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Here, we created a new connection instance and registered it in the service
    collection as a singleton. It will then be injected into the `HostedService` constructor,
    and we will open it when the application starts. We will also change the registration
    for `IAggregateStore`, so that it takes our new `EsAggregateStore` class. Then,
    we will register `HostedService`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个新的连接实例，并将其作为单例注册到服务集合中。然后，它将被注入到`HostedService`构造函数中，并在应用程序启动时打开它。我们还将更改`IAggregateStore`的注册，使其使用我们新的`EsAggregateStore`类。然后，我们将注册`HostedService`。
- en: We will also use `store` as a parameter for our application services. This parameter
    replaces the repositories we used before, so we need to change both application
    services, as well.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用`store`作为应用程序服务的参数。此参数替换了我们之前使用的存储库，因此我们需要更改应用程序服务。
- en: The aggregate store in application services
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用程序服务中的聚合存储
- en: 'The changes required for application services are quite small. To make the
    work even more comfortable, I created a small extension for the `IApplicationService`
    interface that allows us to handle commands with one line of code. We already
    did it before, by using a private method `HandleUpdate` in each application service.
    Now, since we use the `IAggregateStore` interface instead of repositories, we
    can abstract that method, so that it has no dependencies on the specific infrastructure.
    Therefore, we can place it in the `Marketplace.Framework` project. Here is the
    code:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对应用程序服务的更改相当小。为了使工作更加舒适，我为`IApplicationService`接口创建了一个小的扩展，允许我们用一行代码处理命令。我们之前已经这样做过了，通过在每个应用程序服务中使用一个私有方法`HandleUpdate`。现在，由于我们使用`IAggregateStore`接口而不是存储库，我们可以抽象该方法，使其不依赖于特定的基础设施。因此，我们可以将其放置在`Marketplace.Framework`项目中。以下是代码：
- en: '[PRE21]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, we need to replace the repository dependency in the application service
    classes to `IAggregateStore` and change all calls. The work is a bit boring, and
    I have done it all for you, so here is the new code for `ClassifiedAdApplicationService`:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要将应用程序服务类中的存储库依赖项替换为`IAggregateStore`并更改所有调用。这项工作有点无聊，我已经为你全部完成了，所以以下是`ClassifiedAdApplicationService`的新代码：
- en: '[PRE22]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, the changes are quite small. We call `_store.Save`, and we don't
    need to commit, since we don't have an explicit unit of work, because we don't
    execute an operation on multiple aggregates at the same time, otherwise, we would
    break the rule of an aggregate in a transactional boundary, thereby not having
    a unit of work which isn't a problem. We also have no issues with detecting changes,
    since our changes are always represented as events, and we don't need any ORM
    magic to figure out what we need to update.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，更改相当小。我们调用`_store.Save`，由于我们不执行多个聚合的操作，因此不需要提交，因为我们没有显式的单元工作。否则，我们会违反事务边界内聚合的规则，从而没有单元工作，这不是问题。我们也没有检测更改的问题，因为我们的更改始终以事件的形式表示，我们不需要任何ORM魔法来找出我们需要更新什么。
- en: 'Following the same style, here is the new `UserProfileApplicationService` class:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 按照相同的风格，以下是新的`UserProfileApplicationService`类：
- en: '[PRE23]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: That's it; we don't need to do anything else to event-source our application!
    Let's see how it works now.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样；我们不需要对事件源应用程序做任何其他操作！现在让我们看看它是如何工作的。
- en: Running the event-sourced app
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行事件源应用程序
- en: Finally, we can try things out and see how we can execute commands using our
    API, which remains unchanged from [Chapter 9](6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml), *CQRS
    - The Read Side*. You might have noticed, however, that the query APIs and all
    code related to read models are not included in this chapter. That's because the
    read side of CQRS is vastly different from what we used for document and relational
    persistence.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以尝试一些操作，看看我们如何使用我们的API执行命令，该API与第9章[Chapter 9](6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml)中的内容保持一致，即*CQRS
    - The Read Side*。然而，您可能已经注意到，查询API以及与读取模型相关的所有代码都没有包含在本章中。这是因为CQRS的读取部分与我们用于文档和关系型持久化的方式大相径庭。
- en: When you start the app and visit the Swagger UI at `http://localhost:5000`,
    the screen that you will get is exactly the same as before. Of course, the Event
    Store must run at this time, either in a Docker container or as an executable.
    Running Event Store using `docker-compose` is described in the *Technical requirements*
    section. I used two new GUIDs as the new classified ad ID and owner ID, in order
    to create a new ad. So, I called the `POST` endpoint and got `200 OK` as a result.
    Right after that, I executed the `rename` command by making the `PUT` request
    with the same ID and some text for the title. These operations are no different
    from what we were doing earlier.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 当您启动应用程序并访问`http://localhost:5000`上的Swagger UI时，您将得到的屏幕与之前完全相同。当然，Event Store必须在此期间运行，无论是作为Docker容器还是可执行文件。在*技术要求*部分描述了如何使用`docker-compose`运行Event
    Store。我使用了两个新的GUID作为新的分类广告ID和所有者ID，以便创建一个新的广告。因此，我调用了`POST`端点并得到了`200 OK`的结果。紧接着，我通过使用相同ID和一些标题文本执行`rename`命令来执行`PUT`请求。这些操作与我们之前所做的是一样的。
- en: 'Now, we can look at the result of those operations in our new store. To do
    that, we need to visit the Event Store web UI by going to `http://localhost:2113`
    and log in by using the `admin` username and the `changeit` password. From there,
    we need to go to the Stream Browser page, and on the right-hand pane, there is
    a list of recently-changed streams. In this list, we can see the new stream for
    our new classified ad:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查看我们在新存储中执行这些操作的结果。为此，我们需要通过访问`http://localhost:2113`上的Event Store Web
    UI并使用`admin`用户名和`changeit`密码登录。从那里，我们需要转到流浏览器页面，在右侧面板中有一个最近更改的流列表。在这个列表中，我们可以看到我们新的分类广告的新流：
- en: '![](img/72963d6d-37f8-463c-934a-070468bf1b77.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/72963d6d-37f8-463c-934a-070468bf1b77.png)'
- en: Here is our new aggregate stream
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们的新聚合流
- en: 'You can click on the stream name to see what the stream contains. Here is what
    I have:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以点击流名称来查看流包含的内容。以下是我有的内容：
- en: '![](img/34dd146f-7a9e-4e58-b8a2-24a9651ea243.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/34dd146f-7a9e-4e58-b8a2-24a9651ea243.png)'
- en: Two new events in the stream
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 流中的两个新事件
- en: 'Here, we can see two events that were added to the stream after I executed
    two commands. I can continue to run commands using the API until I get the ad
    published. When I look at the Event Store stream after that, I will see more events
    that were added to it:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到在我执行了两个命令之后添加到流中的两个事件。我可以通过使用API继续运行命令，直到广告发布。当我查看执行后的Event Store流时，我会看到更多添加到其中的事件：
- en: '![](img/58b83135-38cd-4894-8b2b-12181fa2dbee.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/58b83135-38cd-4894-8b2b-12181fa2dbee.png)'
- en: More events are added if we execute more commands
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 执行更多命令时将添加更多事件
- en: That seems very nice. Each command triggers a state transition, but instead
    of overwriting the previous state with the new one, we can see the full history
    of changes, represented by events. For example, we can change the price several
    times, but we will always know about all the prices that the ad has had in the
    past.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来非常好。每个命令都会触发状态转换，但我们不是用新状态覆盖旧状态，而是可以看到由事件表示的完整变更历史。例如，我们可以多次更改价格，但我们总是会了解广告过去所有的价格。
- en: 'Now, let''s see what an event looks like. I will open event number 1, which
    has the `ClassifiedAdTitleChanged` type, by clicking on the event name. Here is
    what I can see in the browser:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一个事件看起来像什么。我将通过点击事件名称来打开编号为1的事件，该事件具有`ClassifiedAdTitleChanged`类型。以下是我在浏览器中看到的内容：
- en: '![](img/c051c6cd-96a3-4982-beec-0730e01efdbd.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/c051c6cd-96a3-4982-beec-0730e01efdbd.png)'
- en: Event content as JSON
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 事件内容作为JSON
- en: As you can see, the event data represents our domain event class—it has the
    aggregate ID and the title. The metadata only has one field that we decided to
    use for the purpose of deserialization—the FQCN of the event type. You can look
    at the content of other events to see what is stored there.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，事件数据代表我们的领域事件类——它具有聚合ID和标题。元数据只有一个字段，我们决定用于反序列化的目的——事件类型的完全限定名（FQCN）。你可以查看其他事件的内容，看看那里存储了什么。
- en: It might seem redundant to have the aggregate ID in each event, since the stream
    name already contains the ID, and to recover the aggregate state from events,
    we always read only one stream. We will see how this ID inside each event is used
    when we start building read models.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个事件中都包含聚合ID可能看起来有些冗余，因为流名称已经包含了ID，而且从事件中恢复聚合状态时，我们总是只读取一个流。当我们开始构建读取模型时，我们将看到每个事件内部的这个ID是如何被使用的。
- en: You can also execute some commands on the user profile command API to see the
    different type of aggregate to be stored in a stream with a different kind of
    name. Of course, it is possible to add more ads and users to the system now, and
    to see all those events coming into the Event Store.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在用户配置文件命令API上执行一些命令，以查看要在具有不同名称的流中存储的不同类型的聚合。当然，现在可以向系统中添加更多广告和用户，并查看所有这些事件进入Event
    Store。
- en: Congratulations; we have just converted our application to using Event Sourcing
    instead of a more traditional persistence. As you may have noticed, we didn't
    need to make any changes to our domain objects to make it work. We can even remove
    the setters from aggregate and value-object properties, and make those properties
    private for better encapsulation. None of those changes will have any effect on
    how aggregates get stored and loaded using events. That's because for this type
    of persistence, the impedance mismatch is gone. All our events are simple, plain
    objects with properties that have primitive or simple types. It means that those
    domain events can easily be serialized, and that's the only thing we need to ensure
    in order for the Event Sourcing to work. By the way, it is not a requirement for
    Event Store to use JSON serialization. You can certainly use something such as
    protobuf. However, in such cases, you will lose the ability to check the content
    of events in the UI, since it only understands JSON. Hence, we used the `IsJson`
    property of the `EventData` class to tell Event Store that our events are, in
    fact, JSON strings. Event Store also has an integrated projection engine that
    uses JavaScript to execute operations on events inside the store in order to produce
    new events or to run queries. This feature also requires that events are stored
    in JSON, since this is the format that the JavaScript code can easily interpret.
    We will not be touching upon the projections topic in this chapter, but we'll
    go back to it in [Chapter 11](c4156d9d-9130-4225-b205-ef76cb4bcca3.xhtml), *Projections
    and Queries.*
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜；我们刚刚将我们的应用程序转换为使用事件溯源而不是更传统的持久化方式。正如你可能已经注意到的，我们不需要对我们的领域对象进行任何更改来使其工作。我们甚至可以移除聚合和值对象属性的setter，并将这些属性设置为私有以提高封装性。这些更改都不会对使用事件存储聚合的存储和加载方式产生影响。这是因为对于这种类型的持久化，阻抗不匹配已经不存在了。我们所有的事件都是简单的、普通的对象，其属性具有原始或简单类型。这意味着这些领域事件可以轻松序列化，这就是我们为了使事件溯源工作需要确保的唯一事情。顺便说一句，Event
    Store使用JSON序列化并不是一个要求。你当然可以使用诸如protobuf之类的其他东西。然而，在这种情况下，你将失去在UI中检查事件内容的能力，因为UI只理解JSON。因此，我们使用了`EventData`类的`IsJson`属性来告诉Event
    Store，我们的事件实际上是JSON字符串。Event Store还集成了使用JavaScript执行操作的投影引擎，以便在存储中处理事件以生成新事件或运行查询。这个特性也要求事件以JSON格式存储，因为这是JavaScript代码可以轻松解释的格式。我们将在本章中不涉及投影主题，但将在第11章[投影和查询](c4156d9d-9130-4225-b205-ef76cb4bcca3.xhtml)中回到这个话题。
- en: Summary
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you got to use the feature of representing state transitions
    inside aggregates as events. I used that code style from the start intentionally,
    although I can imagine that it may have caused you some confusion. At the end
    of the day, why would you need to split each operation into `Apply` and `When`?
    Using that approach was necessary to prepare the readers for this chapter. Using
    domain events is a good practice, overall. Even if you don't use Event Sourcing,
    you should definitely consider using domain events to communicate updates between
    aggregates, and even between different Bounded Contexts, and using domain events
    for state transition makes it easy, because you will always have a list of changes
    as a collection of new events.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何在聚合（aggregate）内部将状态转换表示为事件。我故意从开始就使用这种代码风格，尽管我可以想象这可能会让你感到一些困惑。最终，为什么你需要将每个操作拆分为`Apply`和`When`？采用这种方法是为了让读者为这一章做好准备。使用领域事件（domain
    events）是一种良好的实践。即使你不使用事件源（Event Sourcing），你也应该考虑使用领域事件在聚合之间，甚至在不同的边界上下文（Bounded
    Contexts）之间进行更新通信，并且使用领域事件进行状态转换会使它变得容易，因为你会始终有一个包含新事件的更改列表。
- en: Since we had this collection ready, we only needed to figure out how to store
    those changes as-is, in an event stream that represents a single aggregate, and
    to also introduce the `Load` method to look through all events that we read from
    that stream to recover the aggregate state when we need to execute a new operation
    on it. That wasn't very hard. We used a bit of code to figure out how our infrastructure
    would work, and we needed to configure the serialization properly. We still kept
    the FQCN in the event metadata to be able to deserialize events back to C# objects,
    but we'll fix it in the future.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经有了这个集合，我们只需要弄清楚如何将这些更改以原样存储在表示单个聚合的事件流中，并且还需要引入`Load`方法来遍历我们从该流中读取的所有事件，以便在我们需要在该聚合上执行新操作时恢复聚合状态。这并不难。我们使用了一些代码来了解我们的基础设施将如何工作，并且我们需要正确配置序列化。我们仍然在事件元数据中保留了FQCN（完全限定类名），以便能够将事件反序列化为C#对象，但我们将在未来修复它。
- en: Event Store is a very efficient product when it comes to Event Sourcing and
    storing events in streams. Unlike Kafka, this product allows us to create millions
    of streams. Since our approach to store aggregates is to keep the events for each
    aggregate in a separate stream, this solution is perfectly suitable for us. If
    your company has issues, such as a limited number of pre-approved products used
    as databases, and you can't use Event Store just yet, you can look at libraries,
    such as SQL Stream Store ([https://github.com/SQLStreamStore/SQLStreamStore](https://github.com/SQLStreamStore/SQLStreamStore)),
    which implements an event store on a number of relational databases, including
    Microsoft SQL Server; or Marten ([http://jasperfx.github.io/marten/](http://jasperfx.github.io/marten/)),
    which uses the JSONB-type fields of PostgreSQL to implement both the document
    database and event store types of persistence.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 事件存储（Event Store）是处理事件源和存储事件流的一个非常高效的产品。与Kafka不同，这个产品允许我们创建数百万个流。由于我们的存储聚合的方法是将每个聚合的事件保存在单独的流中，这个解决方案非常适合我们。如果你的公司存在一些问题，比如作为数据库使用的预批准产品数量有限，并且你目前还不能使用事件存储（Event
    Store），你可以查看一些库，例如SQL Stream Store ([https://github.com/SQLStreamStore/SQLStreamStore](https://github.com/SQLStreamStore/SQLStreamStore))，它在一个关系数据库上实现了事件存储，包括Microsoft
    SQL Server；或者Marten ([http://jasperfx.github.io/marten/](http://jasperfx.github.io/marten/))，它使用PostgreSQL的JSONB类型字段来实现文档数据库和事件存储类型的持久化。
- en: In the next chapter, we will be looking at the challenges of querying the event-sourced
    system and solving these challenges by using separate read models and projections.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨查询事件源系统所面临的挑战，并通过使用单独的读取模型和投影来解决这些挑战。
- en: So far, you can see that Event Sourcing is not hard!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可以看到事件源（Event Sourcing）并不难！
- en: Further reading
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'There is not much literature about Event Sourcing available at the moment,
    but I can recommend watching a couple of talks by Greg Young, who coined the term
    CQRS and opened up Event Sourcing to the world:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 目前关于事件源（Event Sourcing）的文献并不多，但我可以推荐观看Greg Young的一些演讲，他提出了CQRS的概念，并将事件源（Event
    Sourcing）介绍给了全世界：
- en: '*A Decade of DDD, CQRS, Event Sourcing*, by Greg Young, DDD Europe 2016: [https://www.youtube.com/watch?v=LDW0QWie21s](https://www.youtube.com/watch?v=LDW0QWie21s)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《十年的DDD、CQRS、事件源》*，作者Greg Young，DDD Europe 2016：[https://www.youtube.com/watch?v=LDW0QWie21s](https://www.youtube.com/watch?v=LDW0QWie21s)'
- en: '*Event Sourcing*, Greg Young, GOTO Conference 2014: [https://www.youtube.com/watch?v=8JKjvY4etTY](https://www.youtube.com/watch?v=8JKjvY4etTY)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*事件源*，格雷格·杨，GOTO 会议 2014: [https://www.youtube.com/watch?v=8JKjvY4etTY](https://www.youtube.com/watch?v=8JKjvY4etTY)'
- en: 'If you were already exploring this topic, you might have encountered some blog
    posts about the dark side of Event Sourcing, which mainly involves issues with
    event versions and eventual consistency. We''ll be covering eventual consistency
    in the next chapter, and we''ll learn even touch upon the versioning of events
    briefly; for more in-depth coverage of the event versions topic, refer to Greg''s
    book:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经在这个主题上进行了探索，你可能已经遇到了一些关于事件源阴暗面的博客文章，这主要涉及到事件版本和最终一致性方面的问题。我们将在下一章中介绍最终一致性，并且还会简要提及事件的版本控制；对于事件版本主题的更深入探讨，请参考格雷格的书籍：
- en: '*Versioning in an Event Sourced System*, Greg Young, LeanPub 2017:[ https://leanpub.com/esversioning](https://leanpub.com/esversioning)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*事件源系统中的版本控制*，格雷格·杨，LeanPub 2017: [https://leanpub.com/esversioning](https://leanpub.com/esversioning)'
