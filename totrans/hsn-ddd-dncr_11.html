<html><head></head><body>
        

                            
                    <h1 class="header-title">Projections and Queries</h1>
                
            
            
                
<p>In <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml">Chapter 9</a>, <em>CQRS - The Read Side</em>, we changed our application to use events as the consistent aggregate storage. Instead of updating a snapshot of the state after handling a command, we can add new events to the stream that represents a single aggregate. We can then do a <em>left fold</em> on those events to reconstruct the aggregate state each time we load it again, before handling another command. In two lines of pseudo code, the essence of Event Sourcing can be represented as follows:</p>
<pre>// Loading:
state = foreach(event in history: state = when(state, event))

// Command handling:
event = handle(state, command)</pre>
<p>Here, <kbd>history</kbd> is what we load from the aggregate stream, <kbd>when</kbd> is the <kbd>AggregateRoot.When</kbd> method and <kbd>Handle</kbd> is one of the methods in the application service.</p>
<p>But, as I mentioned before, I removed all read models and the code associated with queries from the project for <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml" target="_blank">Chapter 9</a>, <em>CQRS - The Read Side</em>. That's because queries in an event sourced system are done differently. In this chapter, we are going to look at exactly that. By the end of the chapter, we'll have the working solution that we already implemented in <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank">Chapter 10</a>, <em>Event Sourcing</em>.</p>
<p>Throughout this chapter we are going to discuss the following topics:</p>
<ul>
<li>The issue of querying event streams</li>
<li>What are projections?</li>
<li>Projecting events to a document database</li>
<li>Projecting events to a relational database</li>
<li>Eventual consistency</li>
</ul>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Events and queries</h1>
                
            
            
                
<p>One thing that I've heard many times when talking about event sourcing with developers who are new to this technique, is the claim that event sourcing is not suitable for reporting. Let's first define what reporting is. Normally, we think of it as the ability to retrieve the system state from the database on demand, using filters and grouping, with minimal latency. Relational databases are quite good for this purpose since this was the main reason that relational databases were invented in the first place. If you are old enough, you might remember a short period of hype around object databases (<strong>ODBMSes</strong>, short for<strong> object-oriented database management system</strong>) in the mid-1990s. What could be better than storing entire objects to a database, without taking care of the impedance mismatch? In a world that is largely dominated by different kinds of <strong>relational database management systems</strong> (<strong>RDBMS</strong>), it is hard to digest the fact that the first object database for <strong>Massachusetts General Hospital Utility Multi-Programming System </strong>(<strong>MUMPS</strong> or <strong>M</strong>), was created back in 1966. However, the first prototype of a relational database, System R by IBM, was only in the works from 1974, and the first generally-available RDBMS was created by Oracle, which was released in 1979. Exactly the same year, the M database by InterSystems came to light. Then, for decades, InterSystems became a major vendor of object databases and released Caché by the end of the 1990s, which was still based on many design ideas of MUMPS.</p>
<p>So, why haven't object databases dominated the world by now? There are a number of opinions about this, but one thing we can be certain about is that object databases weren't optimized to query substantial amounts of data. Indexes in such databases were either automatic or client-based, and couldn't possibly cope with larger datasets. Object databases handle writes perfectly well, but weren't really able to perform efficient queries. That said, I have to admit that I am not an expert in object databases and the opinion here could just be speculation. Of course, another obvious reason is that in the 20<sup>th</sup> century, disk space was a real issue. Third-level normalization of relational databases definitely helped to save precious space. Notice that the renaissance of document databases, which entertain similar ideas to object databases by storing the entire object graph as a single document, was only possible due to increasing computing power and cheaper storage when data duplication stopped being an issue.</p>
<p>The main reason for CQRS gaining momentum was the urge to handle reads and writes separately due to severe differences in optimization techniques for those much more distinct operations. For a third-level normalized relational database, writes are easy and reads are hard. Such a database schema can hardly cope with a significant transactional load, maintaining the ability to respond to complex queries at the same time.</p>
<p class="mce-root"/>
<p>The same issue also applies to systems that use events as the source of truth, by storing business-defined events in an append-only fashion. In such systems, as we discussed in <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank">Chapter 10</a>, <em>Event Sourcing</em>, we don't have direct access to the system state. In order to get the current state of any object in the system, we must read all events from a stream that represents that particular object, and apply all events from that stream to an empty object to allow the events flow through the logic of state transitions. Basically, the object is being reborn every time we read it. Now, imagine that we need to run a query over a few thousand, or hundreds of thousands of such objects. This would mean that we probably need to load the whole system in memory before we can ask it for any information that spans across a dataset that contains more than one object. Such a system would certainly never work.</p>
<p>This is why CQRS is something that you can find in nearly every event-sourced system. Of course, there are systems that people call event-sourced, which continuously update the system state in an alternative database, for example, a relational database, at the same time as system-produced events. Sometimes, this happens in memory, or in one transaction if events are stored in the same database as the system state snapshot. In such a system, you usually find that events are, in fact, barely used for anything. Instead of loading an object from events, the application service would just get the latest object state from the snapshot database. It is a bit of a stretch to say that events are the source of truth in a system like this, as we won't be looking at this kind of scenario. At the same time, the techniques that you'll learn from this chapter might sound very similar to this, and I will do my best to explain the core differences.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building read models from events</h1>
                
            
            
                
<p>We are already familiar with read models from <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank">Chapter 10</a>, <em>Event Sourcing</em>. We understand that the read-write model is common for many systems that we build, and sometimes it is beneficial to use different models to persist the system state and to retrieve data that we need to show on the screen or give away to other parties using the API. For event-sourced systems, we must use different models because, as previously discussed, event streams aren't optimized to retrieve the current state of the system and apply filters on it.</p>
<p>Therefore, we will need to create read models for our system somewhere else; for instance, in data storage that supports such queries with ease. Here, we are free to choose what we use. We could use a document database, a relational database, maybe even a filesystem, or a combination of all of the aforementioned methods. However, how can we build such read models? Well, we already defined that the state of our system is derived from all those events we store when any state transition occurs. This could give us the idea that we also need to use events to build read models. We will be using projections to derive the state of our read models from the stream of events that our system produces.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Projections</h1>
                
            
            
                
<p>In relational algebra, a projection is a unary operation, written as <img class="fm-editor-equation" src="img/929a4a4e-9f8c-46b6-9052-8804f1cac8d7.png" style="width:6.75em;height:1.75em;"/>,where <img class="fm-editor-equation" src="img/b8bae4f3-c984-4bc1-8aba-ba97b40022bb.png" style="width:0.92em;height:1.08em;"/> is a tuple, and <img class="fm-editor-equation" src="img/b4fa0694-a2da-4d7b-af93-6e1156ca60c5.png" style="width:5.67em;height:1.00em;"/> are the attribute names for <img class="fm-editor-equation" src="img/b8daf2af-6577-41b7-a925-ddc45814b701.png" style="width:0.92em;height:1.08em;"/>. When such an operation is executed, it returns a set that only includes the specified attributes, and all other attributes are discarded.</p>
<p>If this sounds too complicated, we can explicitly represent a projection as a SQL query. Consider a <kbd>People</kbd> table with the following structure and data:</p>
<table style="border-collapse: collapse;width: 90%" border="1">
<thead>
<tr>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>Id</strong></p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>FirstName</strong></p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>LastName</strong></p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>City</strong></p>
</td>
<td>
<p class="CDPAlignLeft CDPAlign"><strong>Country</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>
<p><kbd>1</kbd></p>
</td>
<td>
<p><kbd>John</kbd></p>
</td>
<td>
<p><kbd>Smith</kbd></p>
</td>
<td>
<p><kbd>Bristol</kbd></p>
</td>
<td>
<p><kbd>United Kingdom</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>2</kbd></p>
</td>
<td>
<p><kbd>Jorrit</kbd></p>
</td>
<td>
<p><kbd>Bramsma</kbd></p>
</td>
<td>
<p><kbd>Eindhoven</kbd></p>
</td>
<td>
<p><kbd>The Netherlands</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>3</kbd></p>
</td>
<td>
<p><kbd>Jan Tore</kbd></p>
</td>
<td>
<p><kbd>Rosendal</kbd></p>
</td>
<td>
<p><kbd>Alta</kbd></p>
</td>
<td>
<p><kbd>Norway</kbd></p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>If we execute the <kbd>SELECT FirstName, LastName FROM People</kbd> query, we effectively execute a projection. We specify two attributes to be included in the result set—<kbd>FirstName</kbd> and <kbd>LastName</kbd>, so that we get a result as follows:</p>
<table style="border-collapse: collapse;width: 90%" border="1">
<thead>
<tr>
<th>FirstName</th>
<th>LastName</th>
</tr>
</thead>
<tbody>
<tr>
<td><kbd>John</kbd></td>
<td><kbd>Smith</kbd></td>
</tr>
<tr>
<td><kbd>Jorrit</kbd></td>
<td><kbd>Bramsma</kbd></td>
</tr>
<tr>
<td><kbd>Jan Tore</kbd></td>
<td><kbd>Rosendal</kbd></td>
</tr>
</tbody>
</table>
<p> </p>
<p>All other attributes are discarded. Notice that we don't include any filtering in the query. Filtering is called <strong>selection</strong> and indeed, in most of the cases, a SQL query combines both projection and selection to produce a concise set of data that we are interested in. You will have already noticed that we used projections in <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank"/><a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank">Chapter 10</a>, <em>Event Sourcing</em>, when we were retrieving a subset of attributes from a larger dataset of the whole system state, to be used for queries.</p>
<p>The process of building a piece of state from events is also called a <strong>projection</strong>, although we can't say that it operates on a single set where we choose a number of attributes that we want to project. However, we will need to project a subset of the whole event stream. Our read models also need to be updated as quickly as possible, but we only commit events to the store. It implies that we need to read all of these events as soon as they are committed, and project them. Usually, this is done either by polling the Event Store or by using a real-time subscription if the store supports it.</p>
<p>The process of building the read models from events using subscriptions and projections can be illustrated by the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/6b7f33f2-e35b-4960-8eb1-12f3df79a60c.png" style="width:57.33em;height:26.17em;"/></p>
<p>The command to read-model flow</p>
<p>When we execute a command, our aggregate is fully loaded from the aggregate stream by the application service. The aggregate then generates a new event (or several events) that represent the state transitions of the aggregate. Those events are committed to the store, so the store appends them to the end of the aggregate stream. A subscription receives these events and updates its read models.</p>
<p>This was the code from our aggregate class:</p>
<pre class="language-csharp">protected override void When(object @event)
{
    switch (@event)
    {
        case Events.UserRegistered e:
            Id = new UserId(e.UserId);
            FullName = new FullName(e.FullName);
            DisplayName = new DisplayName(e.DisplayName);
            break;
        case Events.UserFullNameUpdated e:
            FullName = new FullName(e.FullName);
            break;
        case Events.UserDisplayNameUpdated e:
            DisplayName = new DisplayName(e.DisplayName);
            break;
        case Events.ProfilePhotoUploaded e:
            PhotoUrl = e.PhotoUrl;
            break;
    }
}</pre>
<p>Here, we update the state of our <kbd>UserProfile</kbd> aggregate with each new event. Now, it is time to make a confession—this is also a projection. In this code, we project events that the <kbd>When</kbd> method receives to update the properties of our <kbd>UserProfile</kbd> object. There's nothing more to say about projections and I can conclude the chapter!</p>
<p>Jokes aside, we still have work to do. First of all, we need to find out how our read-model projections will receive new events.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Subscriptions</h1>
                
            
            
                
<p>Imagine our users are looking at a screen where they see the user interface for our marketplace. We already know how to let people execute operations. When a user does something, we send a <kbd>POST</kbd> or <kbd>PUT</kbd> request to the API. In turn, the API controller calls the application service and the command gets executed. The result of this would be either a <kbd>200 OK</kbd> response for a completed command or an error if something goes wrong. However, unlike a single-database system, where the data that we query is the same data on which we execute our commands, for an event-sourced application, this is not the case. Our read model is most probably located in a different database. This fact makes all of our queries eventually consistent. We will discuss this topic later in this book when we explore more advanced topics around event sourcing.</p>
<p>For now, we need to understand that our goal will be to minimize the time gap between the moment when an event is appended to the stream and the moment the read model gets updated. During the time between these two operations, the data that we show to the user is stale. Stale doesn't mean inconsistent, it is just not exactly up to date, and after a small delay, the query will eventually return more actual data. Mind the gap!</p>
<p>To minimize the time gap, we need to ensure that our projections receive new events in real time. Event Store can help here since it has a very nice subscriptions feature. There are two types of subscriptions in the Event Store—catch-up and persistent subscriptions, also known as <strong>competing consumers</strong>. The main difference is the <strong>checkpoint</strong> ownership. One more term for me to throw on you in this chapter!</p>
<p>A checkpoint is a specific position in the stream. As the projection has processed one event, it can store the checkpoint, so if the projection gets restarted, it will know where to start the processing and not project all events from the beginning of life. The concept of checkpoints is well-known in all systems that deal with real-time event processing, such as Kafka or Azure Event Hub.</p>
<p>If you decide to use some other product to store your events, you need to find out if it is possible to make real-time, or almost real-time subscriptions to the store and what you can use as the checkpoint. For example, you can use a SQL Server table to store events and use the auto-increment primary identity as the stream position. Then, you can continuously poll this table for new events and by doing that you will have a working subscription.</p>
<p>Checkpoints are unique to read models. I cited the code of the preceding <kbd>UserProfile.When</kbd> method and mentioned that it does what projections do as well. While that's true, for an aggregate instance, the <kbd>When</kbd> method is executed for all events of a single aggregate when we read the aggregate stream from the store before executing a command. Again, we read all the events from a single stream and call the <kbd>When</kbd> method for each event we get from the store. It's not hard. Projections, however, update their models continuously.</p>
<p>We could not allow ourselves to read all events from the whole store for each update, as this would defeat the purpose of having read models. Let's have a look at how read models listen to new events that come to the store:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/90f192d0-af21-4b74-ae42-25a48d76f9de.png" style="width:18.33em;height:24.33em;"/></p>
<p>The read model is updated by new events</p>
<p>For example, if our <strong>"My Ads"</strong> <strong>projection</strong> gets an <kbd>AdRenamed</kbd> event and starts updating its read model, something happens—something such as a network failure, a database failure, or someone powering off the machine where the projection was running. Somehow, after the issue is fixed, the projection itself needs to figure out which position it needs to start reading events to continue updating its read model. For the case I just described, we need to keep the number <strong>3</strong> somewhere after we successfully projected the <kbd>AdPublished</kbd> event. So, when our service restarts and the projection kicks in, it needs to start reading event number <strong>4</strong>, ignoring everything that happened before. By storing this number, we are establishing a checkpoint. Our projection takes responsibility for keeping its own checkpoint somewhere. The checkpoint is only updated when a new event has been successfully projected, so we guarantee that each event is projected at least once.</p>
<p>There are two ways to store the checkpoint—via a client-based checkpoint or a server-based checkpoint. We can logically conclude that a client-based checkpoint is maintained and stored by the client (subscription), and when using a server-based variant, the Event Store is responsible for this instead.</p>
<p>In Apache Kafka, the term <em>offset</em> is used for the same concept and, by default, the offset is maintained by the server.</p>
<p>A server-based checkpoint feature enables us to run multiple instances of the event consumer (a projection, in our case) and each consumer will get a portion of events. This concept is widely known in the messaging world. All message brokers support a similar pattern, which is called <strong>competing consumers</strong>. This pattern allows us to scale the process of handling messages (or events) easily, but the main issue here is that the order in which messages are processed cannot be guaranteed for competing consumers. That's easy to explain. Message-processing time cannot be fully predictable, as some glitches always happen in the network, and even on the machine where processes share computing and disk resources with other processes. As a result, the time needed to process one message can vary between different consumers, and even between identical messages for the same consumers. If we have multiple consumers that compete for messages, we will almost certainly get into a situation where one consumer has finished processing an event, <em>E<sub>n</sub></em>, while another consumer is still busy processing the <em>E</em><sub><em>n+1</em></sub> event. The free consumer then starts processing the E<sub>n+2</sub> event before the processing of the <em>E</em><sub><em>n+1</em></sub> event has even finished. Clearly, there is no ordering guarantee here. For projections, processing events in order are absolutely crucial. If two renames are executed one after another, we want the second update to be applied to the read model after the first one, with no exceptions. It is, however, not necessary to use competing consumers when using server-maintained checkpoints. If you have one single subscriber for the persistent subscription, it will receive events in order.</p>
<p>When the client maintains their own checkpoint, things become easier and harder at the same time. If we control the checkpoint, we can easily reset or move it. For projections, this means that we can easily rebuild the read model by resetting the checkpoint and removing the existing data. This process is called <strong>replay</strong> and it is, in fact, one of the most powerful features of event sourcing. The harder part is that we need to store the checkpoint somewhere and update it every time the projection processes a new event. The best practice here is that the checkpoint is stored in the same place (that is, the database) as the read model itself. Remember about replay? If we kill the database where our read model is stored, the checkpoint will be gone at once; and, if we run the projection again, it will start processing events from the zero position and eventually, the read model will be rebuilt from the ground up!</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>So, in this book, we will use real-time subscriptions with checkpoints that are maintained by the client. In Event Store, such subscriptions are called <strong>catch-up subscriptions</strong>. Why catch-up? It's easy to guess. Remember replay? No, I am not repeating myself. In case we want or need to rebuild the read model and kill both its data and its checkpoint, the projection will subscribe to the stream of events, starting with the zero position. Until it processes all historical events, it will not be consuming any new events. Only when the projection eventually catches up with the end of the stream, will we be able to switch it to process new events in real time. Event Store does this automatically and that's why we call it a catch-up subscription. Using this type of subscription allows us to add new projections and build new read models, even for a system that is in production for quite some time and has a lot of events. Our new projection will catch-up on all those historical events, switch to real-time processing, and, from that moment on, our new read model will be usable.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing projections</h1>
                
            
            
                
<p>Now it is time to start writing some code. We will use the final code of <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml" target="_blank">Chapter 9</a>, <em>CQRS - The Read Side</em><em>,</em> as the starting point. The final code for this chapter is located in the GitHub repository, in the <kbd>Chapter11</kbd> folder.</p>
<p>We will go step by step and start by implementing one subscription just to see how subscriptions work in the Event Store. Then, we will create a few real read models using both RavenDB and PostgreSQL.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Catch-up subscriptions</h1>
                
            
            
                
<p>In fact, to start making projections, we don't need any databases. I will show you a simple trick that allows you to go on with the initial development quickly, without any thoughts about the database engine that will be used to store read models. Very often, we don't really know what real life will bring us, and the database engine that we might have planned to use at the start might not be even suitable for the job we want to do. During the early stages of any project, the number of events we are working with is not significant, unless we want to put some synthetic tests on the system, or we are working with a high-frequency event-processing system. In our case, we deal with a rather simple classified ads website, so we don't expect a lot of events in the development environment and even in the system that we'd like to show to product owners and QA.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>What can we do to keep things really simple? Well, if the source of truth for our system is in the Event Store, why do we need to persist read models somewhere? It would be perfectly fine to keep them in memory and rebuild each time our application starts. That's exactly what we are going to do.</p>
<p>First, I want to use the code for <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml" target="_blank">Chapter 9</a>, <em>CQRS - The Read Side</em><em>,</em> as the starting point. Remember, it has no queries and no read models. To bring these things in, I copy some code files from <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank">Chapter 10</a>, <em>Event Sourcing,</em> and make minimal changes to minimize the work. So, I take only read models and queries from the <kbd>ClassifiedAd</kbd> folder of the main application project. Then, I remove some queries from the <kbd>Queries</kbd> file, because I only want to implement one to begin with. My new <kbd>Queries</kbd> class now looks like the following:</p>
<pre class="language-csharp">using System.Collections.Generic;
using System.Linq;

namespace Marketplace.ClassifiedAd
{
    public static class Queries
    {
        public static ReadModels.ClassifiedAdDetails Query(
            this IEnumerable&lt;ReadModels.ClassifiedAdDetails&gt; items,
            QueryModels.GetPublicClassifiedAd query) 
                =&gt; items.FirstOrDefault(<br/>                    x =&gt; x.ClassifiedAdId == query.ClassifiedAdId);
    }
}</pre>
<p>You can see that I don't use any database connection here. Instead, the extension method is applied to a simple <kbd>IEnumerable</kbd>, so this implies that I will be using a collection of items in memory.</p>
<p>Then, I also need to remove API endpoints that won't be used and keep only one of them. Also, I need to replace the database connection with <kbd>IEnumerable</kbd>:</p>
<pre class="language-csharp">using System.Collections.Generic;
using Marketplace.Infrastructure;
using Microsoft.AspNetCore.Mvc;
using Serilog;

namespace Marketplace.ClassifiedAd
{
    [Route("/ad")]
    public class ClassifiedAdsQueryApi : Controller
    {
        private static ILogger _log = <br/>        Log.ForContext&lt;ClassifiedAdsQueryApi&gt;();
        
        private readonly IEnumerable&lt;ReadModels.ClassifiedAdDetails&gt; <br/>        _items;

        public ClassifiedAdsQueryApi(<br/>            IEnumerable &lt;ReadModels.ClassifiedAdDetails&gt; items) =&gt; <br/>            _items = items;

        [HttpGet]
        public IActionResult Get(<br/>            QueryModels.GetPublicClassifiedAd request) =&gt; <br/>            RequestHandler.HandleQuery(() =&gt; _items.Query(request), <br/>            _log);
    }
}</pre>
<p>Notice that the <kbd>Get</kbd> method is not <kbd>async</kbd> anymore, because operations on collections are synchronous. Definitely, when we introduce some proper persistence, we would need to bring <kbd>async</kbd> back. Because of this change, I also need to change the <kbd>RequestHandler.HandleQuery</kbd> method so it will accept <kbd>Action</kbd> instead of <kbd>Func</kbd>, because we don't need to return <kbd>Task</kbd> for now:</p>
<pre class="language-csharp">public static IActionResult HandleQuery&lt;TModel&gt;(
    Func&lt;TModel&gt; query, ILogger log)
{
    try
    {
        return new OkObjectResult(query());
    }
    catch (Exception e)
    {
        log.Error(e, "Error handling the query");
        return new BadRequestObjectResult(new
        {
            error = e.Message, stackTrace = e.StackTrace
        });
    }
}</pre>
<p>From <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml" target="_blank">Chapter 9</a>, <em>CQRS - The Read Side</em><em>,</em> we have the <kbd>EsAggregateStore</kbd> class. It has some code that helps us to deserialize a resolved event that comes from the Event Store. We also need to do the same operation in our projection. Therefore, I take this code out to an extension method for the <kbd>ResolvedEvent</kbd> class, so that we can use the same code in projections:</p>
<pre class="language-csharp">using System;
using System.Text;
using EventStore.ClientAPI;
using Newtonsoft.Json;

namespace Marketplace.Infrastructure
{
    public static class EventDeserializer
    {
        public static object Deserialzie(this ResolvedEvent <br/>        resolvedEvent)
        {
            var meta = JsonConvert.DeserializeObject&lt;EventMetadata&gt;(
                Encoding.UTF8.GetString(resolvedEvent.Event.Metadata));
            var dataType = Type.GetType(meta.ClrType);
            var jsonData = Encoding.UTF8.GetString(<br/>                resolvedEvent.Event.Data);
            var data = JsonConvert.DeserializeObject(<br/>                jsonData, dataType);
            return data;
        }
    }
}</pre>
<p>As you remember, we keep the <strong>fully qualified class name</strong> (<strong>FQCN</strong>) of the event class in the event metadata, and <kbd>EventDeserialzier</kbd> uses it to get our domain event back. I also remove this code from <kbd>EsAggregateStore</kbd> to avoid duplication, so the <kbd>Load</kbd> method will look as follows:</p>
<pre class="language-csharp">public async Task&lt;T&gt; Load&lt;T, TId&gt;(TId aggregateId)
    where T : AggregateRoot&lt;TId&gt;
{
    if (aggregateId == null)
        throw new ArgumentNullException(nameof(aggregateId));

    var stream = GetStreamName&lt;T, TId&gt;(aggregateId);
    var aggregate = (T) Activator.CreateInstance(typeof(T), true);

    var page = await _connection.ReadStreamEventsForwardAsync(
        stream, 0, 1024, false);

    aggregate.Load(page.Events.Select(resolvedEvent =&gt; <br/>        resolvedEvent.Deserialzie()).ToArray());

    return aggregate;
}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Now, let's do the actual subscription. It will live in a new class that I'll place in the <kbd>infrastructure</kbd> folder. It will be handling a single read model, so it is not generic in any way and doesn't really belong there. However, this solution is not permanent and we will make it better a bit later.</p>
<p>For this class, I need an instance of <kbd>IEventStoreConnection</kbd>, so that I can create a subscription to it. I also need a reference to the read models collection, so I can put items in it and change the properties of the existing items. The class will have two simple methods—<kbd>Start</kbd> and <kbd>Stop</kbd>. The <kbd>Start</kbd> method creates a new subscription. Events will immediately start coming in, so the connection must be started before I can subscribe to it. Here is the code for the <kbd>Start</kbd> method:</p>
<pre class="language-csharp">public void Start()
{
    var settings = new CatchUpSubscriptionSettings(2000, 500,
        Log.IsEnabled(LogEventLevel.Verbose),
        true, "try-out-subscription");

    _subscription = _connection.SubscribeToAllFrom(Position.Start,
        settings, EventAppeared);
}</pre>
<p>There are some hard coded values here, which we will be reading from the application configuration later. The important line is where we subscribe. The method that I use is <kbd>SubscribeToAllFrom</kbd>. This method creates a subscription that will get all events that are persisted in the Event Store. The first parameter is where the subscription starts. Since our read model is not persisted and we will be rebuilding it from scratch every time the application starts, we must read it from the very beginning because that's why the parameter is getting <kbd>Position.Start</kbd>. The last parameter is a delegate, which will be called for each event that we receive from the subscription; we'll get back to it shortly.</p>
<p>The <kbd>Stop</kbd> method is very simple, it just stops the subscription, as follows:</p>
<pre class="language-csharp">public void Stop() =&gt; _subscription.Stop();</pre>
<p>Now, let's create some code for the <kbd>EventAppeared</kbd> method. There, we will be building our read model, and, as I previously mentioned, the code will be handling the same domain events that we are handling in the <kbd>When</kbd> method of our aggregates, in a very similar fashion.</p>
<p>Before we can use advanced pattern-matching, we need to get the domain event from the <kbd>ResolvedEvent</kbd> class instance that our <kbd>EventAppeared</kbd> receives as a parameter. Here is the beginning of this method:</p>
<pre class="language-csharp">private Task EventAppeared(EventStoreCatchUpSubscription subscription, ResolvedEvent resolvedEvent)
{
    var @event = resolvedEvent.Deserialzie();
    
    switch (@event)
    {
        case Events.ClassifiedAdCreated e:
            _items.Add(new ReadModels.ClassifiedAdDetails
            {
                ClassifiedAdId = e.Id
            });
            break;
        case Events.ClassifiedAdTitleChanged e:
            UpdateItem(e.Id, ad =&gt; ad.Title = e.Title);
            break;
    }

    return Task.CompletedTask;
}</pre>
<p>The first line will get the domain event, then we use pattern-matching to make necessary changes in the read model. The first case will create a new read model for each new classified ad, and the second case will update the title.</p>
<p>This code is fine, but it won't work, because, as I mentioned before, when we subscribe using <kbd>SubscribeToAllFrom</kbd>, we will get all the events. These events are coming from the <kbd>$all</kbd> stream. But the Event Store uses events for its own internal operations, so we will also get many events of that kind. Luckily, we can easily identify events that we don't need by the value of the <kbd>resolvedEvent.Event.EventType</kbd> property. All technical events that have the <kbd>stat</kbd> event type start with the dollar (<kbd>$</kbd>) sign, so we can filter them out.</p>
<p>One last thing to note for this class is that I use the <kbd>UpdateItem</kbd> method to simplify updates for existing items.</p>
<p>Here is the full code for the <kbd>EsSubscription</kbd> class:</p>
<pre class="language-csharp">using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using EventStore.ClientAPI;
using Marketplace.ClassifiedAd;
using Marketplace.Domain.ClassifiedAd;
using Serilog.Events;
using ILogger = Serilog.ILogger;

namespace Marketplace.Infrastructure
{
    public class EsSubscription
    {
        private static readonly ILogger Log = <br/>        Serilog.Log.ForContext&lt;EsSubscription&gt;();

        private readonly IEventStoreConnection _connection;
        private readonly IList&lt;ReadModels.ClassifiedAdDetails&gt; _items;
        private EventStoreAllCatchUpSubscription _subscription;

        public EsSubscription(IEventStoreConnection connection, <br/>            IList&lt;ReadModels.ClassifiedAdDetails&gt; items)
        {
            _connection = connection;
            _items = items;
        }

        public void Start()
        {
            var settings = new CatchUpSubscriptionSettings(2000, 500,
                Log.IsEnabled(LogEventLevel.Verbose),
                true, "try-out-subscription");

            _subscription = _connection.SubscribeToAllFrom(<br/>                Position.Start, settings, EventAppeared);
        }

        private Task EventAppeared(<br/>            EventStoreCatchUpSubscription <br/>            subscription, ResolvedEvent resolvedEvent)
        {
            if (resolvedEvent.Event.EventType.StartsWith("$")) <br/>                return Task.CompletedTask;
            
            var @event = resolvedEvent.Deserialzie();
            
            Log.Debug("Projecting event {type}", <br/>                @event.GetType().Name);

            switch (@event)
            {
                case Events.ClassifiedAdCreated e:
                    _items.Add(new ReadModels.ClassifiedAdDetails
                    {
                        ClassifiedAdId = e.Id
                    });
                    break;
                case Events.ClassifiedAdTitleChanged e:
                    UpdateItem(e.Id, ad =&gt; ad.Title = e.Title);
                    break;
                case Events.ClassifiedAdTextUpdated e:
                    UpdateItem(e.Id, ad =&gt; ad.Description = e.AdText);
                    break;
                case Events.ClassifiedAdPriceUpdated e:
                    UpdateItem(e.Id, ad =&gt;
                    {
                        ad.Price = e.Price;
                        ad.CurrencyCode = e.CurrencyCode;
                    });
                    break;
            }

            return Task.CompletedTask;
        }

        private void UpdateItem(Guid id, <br/>            Action&lt;ReadModels.ClassifiedAdDetails&gt; update)
        {
            var item = _items.FirstOrDefault(<br/>                x =&gt; x.ClassifiedAdId == id);
            if (item == null) return;

            update(item);
        }

        public void Stop() =&gt; _subscription.Stop();
    }
}</pre>
<p>Ideally, we'd need to wrap the deserialization call in a <kbd>try</kbd>-<kbd>catch</kbd> block, because we might get some events that we don't know about and it will cause our projection to break ungracefully. But again, we'll be making lots of changes in the code later on. Let's move on to the wiring part and try things out.</p>
<p>We must ensure that our subscription starts after the Event Store connection do indeed connect to the store. Right now, this operation happens in the <kbd>HostedService</kbd> class. Since it only handles the Event Store connection business, I will rename it to the <kbd>EventStoreService</kbd>. I also add the <kbd>EsSubscription</kbd> instance to its constructor, so we can start a subscription as soon as we connect. Here, you can see how this class looks after all those changes:</p>
<pre class="language-csharp">using System.Threading;
using System.Threading.Tasks;
using EventStore.ClientAPI;
using Marketplace.Infrastructure;
using Microsoft.Extensions.Hosting;

namespace Marketplace
{
    public class EventStoreService : IHostedService
    {
        private readonly IEventStoreConnection _esConnection;
        private readonly EsSubscription _subscription;

        public EventStoreService(<br/>            IEventStoreConnection esConnection, <br/>            EsSubscription subscription)
        {
            _esConnection = esConnection;
            _subscription = subscription;
        }

        public async Task StartAsync(<br/>            CancellationToken cancellationToken)
        {
            await _esConnection.ConnectAsync();
            _subscription.Start();
        }

        public Task StopAsync(CancellationToken cancellationToken)
        {
            _subscription.Stop();
            _esConnection.Close();
            
            return Task.CompletedTask;
        }
    }
}</pre>
<p>In the <kbd>Startup</kbd> class, I need to change the registrations and also create our fake storage instance (remember, that's just a collection). So, I change the code that registers the hosted service and add a couple of lines to that block of the <kbd>Startup.ConfigureServices</kbd> method:</p>
<pre class="language-csharp">var items = new List&lt;ReadModels.ClassifiedAdDetails&gt;();
services.AddSingleton&lt;IEnumerable&lt;ReadModels.ClassifiedAdDetails&gt;&gt;(items);

var subscription = new EsSubscription(esConnection, items);
services.AddSingleton&lt;IHostedService&gt;(<br/>    new EventStoreService(esConnection, subscription));</pre>
<p>We need to register the items collection, because our query API controller needs it to be injected by the service provider, as a constructor parameter.</p>
<p class="mce-root"/>
<p>One thing that we haven't done in <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml" target="_blank">Chapter 9</a>, <em>CQRS - The Read Side</em><em>,</em> is that despite us using Serilog for all of the logging, it was never initialized in the chapter code. We had nothing to log then really, but now it will be interesting to look at what we can log. So, I added a couple of lines at the beginning of the <kbd>Program.Main</kbd> method:</p>
<pre class="language-csharp">Log.Logger = new LoggerConfiguration()
    .MinimumLevel.Debug()
    .WriteTo.Console()
    .CreateLogger();</pre>
<p>Well, this is it. Now, if you have the same <kbd>docker-compose</kbd> running since <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml">Chapter 9</a>, <em>CQRS - The Read Side</em><em>, </em>and have some data in it (you should have it if you followed along with the code of <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml">Chapter 9</a>, <em>CQRS - The Read Side</em>), you can run the application and it will produce a kind of debug, as follows:</p>
<pre class="language-">Hosting environment: Development
Content root path: /~/Dev/ddd-book/chapter11/Marketplace/bin/Debug/netcoreapp2.1
Now listening on: http://localhost:5000
Application started. Press Ctrl+C to shut down.
[21:00:17 DBG] Projecting event ClassifiedAdCreated
[21:00:17 DBG] Projecting event ClassifiedAdTitleChanged
[21:00:17 DBG] Projecting event ClassifiedAdTextUpdated
[21:00:17 DBG] Projecting event ClassifiedAdPriceUpdated
[21:00:17 DBG] Projecting event ClassidiedAdSentForReview
[21:00:17 DBG] Projecting event ClassifiedAdPublished
[21:00:48 DBG] Projecting event ClassifiedAdCreated
[21:00:48 DBG] Projecting event ClassifiedAdTitleChanged
[21:00:48 DBG] Projecting event ClassifiedAdTextUpdated
[21:00:48 DBG] Projecting event ClassifiedAdPriceUpdated
[21:00:48 DBG] Projecting event ClassidiedAdSentForReview
[21:00:48 DBG] Projecting event ClassifiedAdPublished
[21:00:48 DBG] Projecting event ClassifiedAdCreated
[21:00:48 DBG] Projecting event ClassidiedAdSentForReview
[21:00:48 DBG] Projecting event ClassifiedAdTitleChanged
[21:00:48 DBG] Projecting event ClassifiedAdPublished
[21:00:48 DBG] Projecting event ClassifiedAdPriceUpdated
[21:00:48 DBG] Projecting event ClassifiedAdCreated
[21:00:48 DBG] Projecting event ClassifiedAdTextUpdated</pre>
<p>If you were working with <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank">Chapter 10</a>, <em>Event Sourcing</em>, code for a while and the Event Store was running for many days, you might notice some delay between events that belong to different classified ads. This is simply because all of those technical events are being continuously produced by Event Store and we get all of them. We ignore these events but we still need to read them, get to the application, check the name, and so on. This takes time. On the preceding debug output, you can see the delay of about 30 seconds, which means I let Event Store run 24/7 on my machine and it took me a while to work in <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml">Chapter 9</a>, <em>CQRS - The Read Side</em>! We don't really want to have this delay and luckily, Event Store sets a small <strong>time-to-live</strong> (<strong>TTL</strong>) value on these technical events. This means that, in theory, most of them should be deleted. However, events that are marked for deletion, aren't being cleaned up until we execute a scavenge operation. That's because removing events in real time would have a significant performance impact. Scavenging can be started from the Event Store UI by going to Admin, where you can press the Scavenge button at the top-right corner of the screen. After I scavenged my local store, the delay decreased to six seconds. But make no mistake, this happens once only when you start the application. All new events will be projected instantly.</p>
<p>Now, we can test our <kbd>GET</kbd> query endpoint to see if the projection actually worked. I will use the classified ad that I previously created when working on <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml">Chapter 9</a>, <em>CQRS - The Read Side</em>. Here is the query result in Swagger:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/5d977e9d-e006-4456-bb0f-c156e74f3d60.png" style="width:58.33em;height:41.25em;"/></p>
<p>The query retrieves data from the real model</p>
<p>The first projection worked! However, we can see that we only projected the classified ad events, and therefore, the seller's display name is empty. We will be fixing it shortly.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Cross-aggregate projections</h1>
                
            
            
                
<p>When people start doing event sourcing, one mistake that often happens is that developers try to get into the comfort zone of the persisted state of their aggregates as soon as they can. So, many interpret read models as a way to keep the aggregate state accessible in a query able store. I have done the same thing in the past, so you can trust me on that. For the purpose of keeping an aggregate state in some database, I used a nice feature of Event Store—internal projections. You can check the list of available internal projections by visiting the Projections page of the Event Store web UI. One of those projections is <kbd>$by-category</kbd>, which links all events to special category streams. For example, <kbd>$ce-ClassifiedAd</kbd> will contain all events for the <kbd>ClassifiedAd</kbd> aggregate. You can inspect it yourself by visiting <kbd>http://localhost:2113/web/index.html#/streams/$ce-ClassifiedAd</kbd>. and check the stream content (you need to ensure that <kbd>$by-category</kbd> projection is running). By creating a subscription for this stream you can, for example, build an aggregate snapshot. However, snapshots are not read models and normally should not be used as real models.</p>
<p>Read models always serve a certain purpose. As we were looking at CQRS in <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml"/><a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml"/><a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml">Chapter 9</a>, <em>CQRS - The Read Side</em><em>, </em>we were designing read models to answer specific queries. Often, we need some information on the screen, and therefore, we make a read model to get all the required information using one single query. Without CQRS, we might need to call several queries that would retrieve the state of several different types of entities from repositories, and combine the information at the API backend to one single response DTO. This is a common strategy when we use a <strong>Backend For Frontend</strong> (<strong>BFF</strong>) approach. With CQRS, however, we are free to choose what information to query, as soon as the query only works with entities from a single database. We will look into more complex scenarios when our system becomes a composition of multiple autonomous subsystems when we go through the topics of bounded contexts and microservices.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Projecting events from two aggregates</h1>
                
            
            
                
<p>Now, let's think about creating read models that are similar to what we had in <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml">Chapter 10</a>, <em>Event Sourcing</em>. We have already started with one of them and as you have seen in the preceding Swagger screenshot, the seller name is empty in the response we get. That's because the only events we're handling in our projection are the <kbd>ClassifiedAd</kbd> events. However, our store contains all events for the whole application.</p>
<p>Since we use the <kbd>SubscribeFromAllFrom</kbd> method of the <kbd>IEventStoreConnection</kbd> interface, our projection will receive all events. We currently filter our system events, so we should get everything else, including events for the <kbd>UserProfile</kbd> aggregate. It seems simple to add one more <kbd>case</kbd> to the pattern-matching switch and handle the <kbd>UserDisplayNameUpdated</kbd> event to set the <kbd>ReadModels</kbd> property correctly. That seems legit, so when the owner updates their display name, our read model will get updated too.</p>
<p>One issue here is that we cannot give the <kbd>UpdateItem</kbd> method any ID. When the user updates their display name, this action is not associated with any classified ad. This means that we need to run a query and update all ads where the owner ID is the ID of the user who changed the name. This task is not hard, so we can add one more method, called <kbd>UpdateMultipleItems</kbd>, and give it a query and an operation to execute on each item that is returned by the query:</p>
<pre class="language-csharp">private void UpdateMultipleItems(<br/>    Func&lt;ReadModels.ClassifiedAdDetails, bool&gt; query,
    Action&lt;ReadModels.ClassifiedAdDetails&gt; update)
{
    foreach (var item in _items.Where(query))
        update(item);
}</pre>
<p>We can specify the action easily, but what should be the query? Our read model doesn't contain the owner ID! Well, we can easily fix this by adding an additional property to the read model, called <kbd>SellerId</kbd>, which we will assign from <kbd>OwnerId</kbd>. There is no way in our system to change the ad owner, so it is safe to do this assignment only when the ad is created.</p>
<p>The new code for the projection will be as follows:</p>
<pre class="language-csharp">private Task EventAppeared(EventStoreCatchUpSubscription subscription, <br/>    ResolvedEvent resolvedEvent)
{
    if (resolvedEvent.Event.EventType.StartsWith("$")) <br/>        return Task.CompletedTask;
    
    var @event = resolvedEvent.Deserialzie();
    
    Log.Debug("Projecting event {type}", @event.GetType().Name);

    switch (@event)
    {
        case Events.ClassifiedAdCreated e:
            _items.Add(new ReadModels.ClassifiedAdDetails
            {
                ClassifiedAdId = e.Id,
                SellerId = e.OwnerId
            });
            break;
        case Events.ClassifiedAdTitleChanged e:
            UpdateItem(e.Id, ad =&gt; ad.Title = e.Title);
            break;
        case Events.ClassifiedAdTextUpdated e:
            UpdateItem(e.Id, ad =&gt; ad.Description = e.AdText);
            break;
        case Events.ClassifiedAdPriceUpdated e:
            UpdateItem(e.Id, ad =&gt;
            {
                ad.Price = e.Price;
                ad.CurrencyCode = e.CurrencyCode;
            });
            break;
        case Domain.UserProfile.Events.UserDisplayNameUpdated e:
            UpdateMultipleItems(x =&gt; x.SellerId == e.UserId, 
                x =&gt; x.SellersDisplayName = e.DisplayName);
            break;
    }

    return Task.CompletedTask;
}</pre>
<p>Of course, one thing to remember is how efficient the query will be on real storage. Since we are using a simple in-memory list, it is not an issue. In reality, one person would not have millions of classified ads, so the same query would work too, but we also need to remember that RavenDB only supports a limited number of operations per session, so an advanced technique might be needed if we expect to update thousands of items by this query.</p>
<p>Do you see another issue there? Of course, users don't really update their names that often. I don't actually remember changing my name since I was born. I do update some of my countless profiles on a number of online services that I use, but usually, I do this only once, especially when it comes to the name change. For our classified ad, the chance that the owner will update their name after the ad has been created and before it is removed is close to zero. So, what can we do?</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Multiple projections per subscription</h1>
                
            
            
                
<p>First, it seems that we need to build another projection that will handle events for the <kbd>UserProfile</kbd> aggregate and build a simple read model from them. We can use the same storage and keep everything in memory for now. Since we will have two projections, it makes sense to separate things and let our subscription handle multiple projections.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Since we will have one subscription that can handle multiple projections, we can rename our <kbd>EsSubscription</kbd> class to <kbd>ProjectionsManager</kbd>. It will need to accept projections as parameters and it is better to keep them in separate classes, so we need a simple interface. We can call it <kbd>IProjection</kbd> and place the file in the <kbd>Marketplace.Framework</kbd> project, as follows:</p>
<pre class="language-csharp">using System.Threading.Tasks;

namespace Marketplace.Framework
{
    public interface IProjection
    {
        Task Project(object @event);
    }
}</pre>
<p>Then, we need to move the pattern-matching code to a new implementation of this interface. It is better to group projections together, so I created a folder in the <kbd>Marketplace</kbd> project, called <kbd>Projections</kbd>, and added a new <kbd>ClassifiedAdDetailsProjection</kbd> class there. After that, I moved the code from the <kbd>EsSubscription.EventAppeared</kbd> method to this new class:</p>
<pre class="language-csharp">using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using Marketplace.Domain.ClassifiedAd;
using Marketplace.Framework;

namespace Marketplace.Projections
{
    public class ClassifiedAdDetailsProjection : IProjection
    {
        private List&lt;ReadModels.ClassifiedAdDetails&gt; _items;

        public ClassifiedAdDetailsProjection(List&lt;ReadModels.<br/>            ClassifiedAdDetails&gt; items)
        {
            _items = items;
        }

        public Task Project(object @event)
        {
            switch (@event)
            {
                case Events.ClassifiedAdCreated e:
                    _items.Add(new ReadModels.ClassifiedAdDetails
                    {
                        ClassifiedAdId = e.Id,
                        SellerId = e.OwnerId
                    });
                    break;
                case Events.ClassifiedAdTitleChanged e:
                    UpdateItem(e.Id, ad =&gt; ad.Title = e.Title);
                    break;
                case Events.ClassifiedAdTextUpdated e:
                    UpdateItem(e.Id, ad =&gt; ad.Description = e.AdText);
                    break;
                case Events.ClassifiedAdPriceUpdated e:
                    UpdateItem(e.Id, ad =&gt;
                    {
                        ad.Price = e.Price;
                        ad.CurrencyCode = e.CurrencyCode;
                    });
                    break;
                case Domain.UserProfile.Events.UserDisplayNameUpdated <br/>                e:
<br/>                    UpdateMultipleItems(x =&gt; x.SellerId == e.UserId,
                        x =&gt; x.SellersDisplayName = e.DisplayName);
                    break;
            }

            return Task.CompletedTask;
        }

        private void UpdateItem(Guid id,<br/>            Action&lt;ReadModels.ClassifiedAdDetails&gt; update)
        {
            var item = _items.FirstOrDefault(<br/>                x =&gt; x.ClassifiedAdId == id);
            if (item == null) return;

            update(item);
        }

        private void UpdateMultipleItems(<br/>            Func&lt;ReadModels.ClassifiedAdDetails, bool&gt; query,
            Action&lt;ReadModels.ClassifiedAdDetails&gt; update)
        {
            foreach (var item in _items.Where(query))
                update(item);
        }
    }
}</pre>
<p>We also need a new projection that will build a read model for user details, so I created another implementation of the <kbd>IProjection</kbd> interface and called it <kbd>UserDetailsProjection</kbd>. It makes sense to also move the <kbd>ReadModels.cs</kbd> files to the <kbd>Projections</kbd> folder to keep things together. Here is the user details projection code:</p>
<pre class="language-csharp">using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;
using Marketplace.Domain.UserProfile;
using Marketplace.Framework;

namespace Marketplace.Projections
{
    public class UserDetailsProjection : IProjection
    {
        List&lt;ReadModels.UserDetails&gt; _items;
        
        public UserDetailsProjection(<br/>            List&lt;ReadModels.UserDetails&gt; items)
        {
            _items = items;
        }
        
        public Task Project(object @event)
        {
            switch (@event)
            {
                case Events.UserRegistered e:
                    _items.Add(new ReadModels.UserDetails
                    {
                        UserId = e.UserId,
                        DisplayName = e.DisplayName
                    });
                    break;
                case Events.UserDisplayNameUpdated e:
                    UpdateItem(e.UserId, <br/>                        x =&gt; x.DisplayName = e.DisplayName);
                    break;
            }
            
            return Task.CompletedTask;
        }
        
        private void UpdateItem(Guid id, <br/>            Action&lt;ReadModels.UserDetails&gt; update)
        {
            var item = _items.FirstOrDefault(x =&gt; x.UserId == id);
            if (item == null) return;

            update(item);
        }
    }
}</pre>
<p>Of course, we need to add a new read model class to the <kbd>ReadModels.cs</kbd> file, as follows:</p>
<pre class="language-csharp">using System;

namespace Marketplace.Projections
{
    public static class ReadModels
    {
        public class ClassifiedAdDetails
        {
            public Guid ClassifiedAdId { get; set; }
            public string Title { get; set; }
            public decimal Price { get; set; }
            public string CurrencyCode { get; set; }
            public string Description { get; set; }
            public Guid SellerId { get; set; }
            public string SellersDisplayName { get; set; }
            public string[] PhotoUrls { get; set; }
        }

        public class UserDetails
        {
            public Guid UserId { get; set; }
            public string DisplayName { get; set; }
        }
    }
}</pre>
<p>Now, we need to finalize the projections manager so that it can accept multiple projections and call each of them when a new event appears. We want to be prepared for the future use of a real persistence store, so I want to keep all methods async, except <kbd>UpdateItem</kbd> and <kbd>UpdateItems</kbd>, which I can change later, as these are implementation details of individual projection classes. Here is the new <kbd>ProjectionManager</kbd> class code:</p>
<pre class="language-csharp">using System.Linq;
using System.Threading.Tasks;
using EventStore.ClientAPI;
using Marketplace.Framework;
using Serilog;
using Serilog.Events;

namespace Marketplace.Infrastructure
{
    public class ProjectionManager
    {
        private readonly IEventStoreConnection _connection;
        private readonly IProjection[] _projections;
        private EventStoreAllCatchUpSubscription _subscription;

        public ProjectionManager(IEventStoreConnection connection, 
            params IProjection[] projections)
        {
            _connection = connection;
            _projections = projections;
        }

        public void Start()
        {
            var settings = new CatchUpSubscriptionSettings(2000, 500,
                Log.IsEnabled(LogEventLevel.Verbose),
                true, "try-out-subscription");
            _subscription = _connection.SubscribeToAllFrom(<br/>                Position.Start, settings, EventAppeared);
        }

        public void Stop() =&gt; _subscription.Stop();

        private Task EventAppeared(EventStoreCatchUpSubscription _, 
            ResolvedEvent resolvedEvent)
        {
            if (resolvedEvent.Event.EventType.StartsWith("$")) <br/>                return Task.CompletedTask;
            
            var @event = resolvedEvent.Deserialzie();
            
            Log.Debug("Projecting event {type}", <br/>                @event.GetType().Name);
            return Task.WhenAll(_projections.Select(<br/>                x =&gt; x.Project(@event)));
        }
    }
}</pre>
<p>I want to keep logging all events that we project to see what is going on. In the last line of the <kbd>EventAppeared</kbd> method, you can see that we are collecting all of the tasks that project events for each projection and we want all these tasks to complete.</p>
<p>Next, we fix compilation errors in the <kbd>EventStoreService</kbd> class, so it uses <kbd>ProjectionManager</kbd>, instead of the removed (or renamed) <kbd>EsSubscription</kbd> class:</p>
<pre class="language-csharp">using System.Threading;
using System.Threading.Tasks;
using EventStore.ClientAPI;
using Marketplace.Infrastructure;
using Microsoft.Extensions.Hosting;

namespace Marketplace
{
    public class EventStoreService : IHostedService
    {
        private readonly IEventStoreConnection _esConnection;
        private readonly ProjectionManager _projectionManager;

        public EventStoreService(IEventStoreConnection esConnection, <br/>            ProjectionManager projectionManager)
        {
            _esConnection = esConnection;
            _projectionManager = projectionManager;
        }

        public async Task StartAsync(<br/>            CancellationToken cancellationToken)
        {
            await _esConnection.ConnectAsync();
            _projectionManager.Start();
        }

        public Task StopAsync(CancellationToken cancellationToken)
        {
            _projectionManager.Stop();
            _esConnection.Close();
            
            return Task.CompletedTask;
        }
    }
}</pre>
<p>The final thing before we can start the app is to wire things up in <kbd>Startup</kbd>. We need one more collection, this time of the <kbd>ReadModels.UserDetails</kbd>, so we can use it in controllers and give it to the <kbd>UserDetailsProjection</kbd> constructor as a parameter:</p>
<pre class="language-csharp">var classifiedAdDetails = new List&lt;ReadModels.ClassifiedAdDetails&gt;();
services.AddSingleton&lt;IEnumerable&lt;ReadModels.ClassifiedAdDetails&gt;&gt;(classifiedAdDetails);
var userDetails = new List&lt;ReadModels.UserDetails&gt;();
services.AddSingleton&lt;IEnumerable&lt;ReadModels.UserDetails&gt;&gt;(userDetails);

var projectionManager = new ProjectionManager(esConnection, 
    new ClassifiedAdDetailsProjection(classifiedAdDetails),
    new UserDetailsProjection(userDetails));</pre>
<p>This was some work, but now everything is done, I can finally press <em>F5</em> and see what happens. Well, nothing spectacular really; I only see the same events for an ad being projected again, but at least this part works as before. We see nothing new because I was cheating and created an ad without having any users in the system. Now I need to go back and create this user.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Event links and special streams</h1>
                
            
            
                
<p>Assuming that we keep running <kbd>docker-compose</kbd> from <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml" target="_blank">Chapter 10</a>, <em>Event Sourcing</em>, I can look up the owner ID of the only ad we have in the Event Store stream. The value I used there is <kbd>8dd8c5c6-6edb-4e42-ac9e-a232ea445b76</kbd>, so I can use the Swagger API for user profiles and create the following user:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/601ac523-3710-4bd9-81f0-199401128e98.png" style="width:51.42em;height:28.83em;"/></p>
<p>Creating a new user via the UserProfile API</p>
<p>I got a <kbd>200 OK</kbd> response and now I see more lines in the log, as follows:</p>
<pre>[21:58:04 DBG] Projecting event UserRegistered
[21:58:04 DBG] Projecting event UserRegistered
[21:58:04 DBG] Projecting event UserRegistered
[21:58:04 DBG] Projecting event UserRegistered</pre>
<p>Well, the new projection works, but why has this single event been projected four times? The mystery can be easily solved by looking at the <kbd>$all</kbd> stream that we used for our subscription:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a1582758-b15e-4fe9-afc0-f9b2cc8955e3.png" style="width:20.75em;height:34.42em;"/></p>
<p>Content of the $all stream</p>
<p>Here, you can see that several events were added to it. If we ignore system events, those of <kbd>0@$ce-UserProfile</kbd>, <kbd>0@$et-UserRegistered</kbd>, and so on look suspicious. These are linked events that were placed to different special streams by internal standard projections of Event Store. These internal projections are very helpful. For example, if you look at the <kbd>$ce-UserProfile</kbd> stream, you will find all events that were saved for all instances of the <kbd>UserProfile</kbd> aggregate. These <kbd>$ce</kbd> streams are known as category streams. Another stream type is the event type. For example, <kbd>$et-UserRegistered</kbd> contains all events of type <kbd>UserRegistered</kbd> from all other streams in the store.</p>
<p>However, we are subscribing to the <kbd>$all</kbd> stream and we don't need to get copies of a single event that is being linked to all those special streams. We could, of course, disable standard projections by going to the Projection tab of the Event Store UI and clicking the Stop all button, but that is not really a good way. Someone could come to our store later on and enable these projections again. But remember, these are linked events. We have a helpful parameter for the catch-up subscription, which is called <kbd>resolveLinkTos</kbd>, and we set it to <kbd>true</kbd>. Let's change it to <kbd>false</kbd> and see what happens. Here is the new code from the <kbd>ProjectionManager</kbd> class:</p>
<pre class="language-csharp">public void Start()
{
    var settings = new CatchUpSubscriptionSettings(2000, 500,
        Log.IsEnabled(LogEventLevel.Verbose),
        false, "try-out-subscription");
    _subscription = _connection.SubscribeToAllFrom(Position.Start,
        settings, EventAppeared);
}</pre>
<p>If I run the application now, the input is much different:</p>
<pre>[22:30:38 DBG] Projecting event ClassifiedAdCreated<br/>[22:30:38 DBG] Projecting event ClassifiedAdTitleChanged<br/>[22:30:38 DBG] Projecting event ClassifiedAdTextUpdated<br/>[22:30:38 DBG] Projecting event ClassifiedAdPriceUpdated<br/>[22:30:38 DBG] Projecting event ClassifiedAdSentForReview<br/>[22:30:38 DBG] Projecting event ClassifiedAdPublished<br/>[22:30:48 DBG] Projecting event UserRegistered</pre>
<p>It appears that events for the <kbd>ClassifiedAd</kbd> aggregate were also projected multiple times before, for the same reason. Now the log makes much more sense, and each event is only projected once, as expected.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Enriching read models</h1>
                
            
            
                
<p>At this moment, we have a collection that contains a single object of type <kbd>ReadModels.UserDetails</kbd> in memory. This object represents a single user, so we can find out what display name the user has if we have the user ID. This is helpful, but how can we use it to show the full details of our classified ad? There are two ways of doing this, considering that we are within a single-application boundary and use the same store (currently in memory) for all read models.</p>
<p class="mce-root"/>
<p>When developers start to deal with data that is spread across multiple data sources, the most obvious method that comes to their mind is to aggregate data on the edge. One of the most popular techniques is to build BFF. When the frontend needs to get some aggregated data, it sends one request to a single API endpoint at the backend, and the API itself calls different data sources and merges the data. This process can be illustrated by the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b36c5123-5e9a-4204-8903-d9872201f1e1.png" style="width:35.25em;height:19.67em;"/></p>
<p>The BFF pattern</p>
<p>In the simplest scenario, we can just do one database call with some sort of join, since we have the knowledge about keys for both data elements that we need to query. In more complex situations, we might find ourselves dealing with remote calls to microservices that own the data we need and do the join in memory. There are quite a few concerns about this approach. When we start using remote calls, we expose our API endpoint to potential failures of any of the services it needs to call and all sorts of networking issues that might happen. Another important aspect is that we have to do the join each time the BFF API endpoint is called. If this particular set of data is being used frequently, we will get into a situation where we need to make potentially expensive joins, instead of using the power of read models to retrieve a preprocessed set of denormalized data that is targeted in that particular use case.</p>
<p>There are a few ways to get more data in the read model than it receives in events that the projection receives.</p>
<p>If we have the necessary data that our read model needs, in the same aggregate, we can add properties to the event that aren't necessary to convey the state transition. For example, if we need to build a read model that will contain a list of ads for one user (<kbd>MyClassifiedAds</kbd>), we would need to include the owner ID to all events that the projection would need to handle, such as <kbd>ClassifiedAdTitleChanged</kbd> or <kbd>ClassifiedAdTextUpdated</kbd>. This method is sometimes referred to as using <strong>fat events</strong>, which is the opposite of <strong>slim events</strong> that contain the minimal amount of data that is necessary to explain what happened. But this method won't work for a cross-aggregate read model, so it is not an option that we need to explore now.</p>
<p>We are going to implement two other methods that will allow us to get the data from other sources—querying from a projection and event up casting.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Querying from a projection</h1>
                
            
            
                
<p>Currently, our main problem is that we don't have the name of the owner when our projection receives the <kbd>ClassifiedAdCreated</kbd> event. All other events for the classified ad aggregate don't have any effect on the owner, since the owner cannot be changed. We already handle the <kbd>UserDisplayNameUpdated</kbd> event in our projection, so we get the updated name if the ad owner decides to do such an update. To get the data we need, we will reach out to the <kbd>UserDetails</kbd> read model, using <kbd>OwnerId</kbd> from the event. The process would look like the following:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/193c9247-24db-43e1-bbb1-742e5302807b.png" style="width:50.08em;height:19.83em;"/></p>
<p>Enriching projections from another read model</p>
<p class="mce-root"/>
<p>Let's change our projection code to do this query. First of all, we don't have any knowledge about the other read model in the <kbd>ClassifiedAdDetailsProjection</kbd> class. This doesn't matter for now, as regardless of whether the data is stored in memory or in some database, we still need to get hold of it. A trivial way would be to give our projection a reference to the <kbd>UserDetails</kbd> storage and execute the query directly. But this approach, although very simple to implement, creates coupling between read models and projections. When such coupling is introduced, any future change will be harder to implement and testing will always be a challenge, since we always need to make sure that all storages are prepopulated with all the data we need.</p>
<p>A much more elegant and clean way is to give our projection an explicit way to retrieve <kbd>DisplayName</kbd> of a user for a given <kbd>UserId</kbd>. The easiest way to do this is by providing a delegate function so that we can add it as a parameter to the projection constructor:</p>
<pre class="language-csharp">public ClassifiedAdDetailsProjection(<br/>    List&lt;ReadModels.ClassifiedAdDetails&gt; items,
    Func&lt;Guid, string&gt; getUserDisplayName)
{
    _items = items;
    _getUserDisplayName = getUserDisplayName;
}</pre>
<p>Now, we can use this function to get the additional data we need for the read model, by adding the call to this function in the first <kbd>case</kbd> in the <kbd>ClassifiedAdDetailsProjection.Project</kbd> method:</p>
<pre class="language-csharp">case Events.ClassifiedAdCreated e:
    _items.Add(new ReadModels.ClassifiedAdDetails
    {
        ClassifiedAdId = e.Id,
        SellerId = e.OwnerId,
        SellersDisplayName = _getUserDisplayName(e.OwnerId)
    });
    break;</pre>
<p>The last thing that we need to do is to complete the wiring, since the <kbd>Startup</kbd> class doesn't compile anymore. We need to change the projection constructor call to the following:</p>
<pre class="language-csharp">var projectionManager = new ProjectionManager(esConnection, 
    new ClassifiedAdDetailsProjection(classifiedAdDetails, 
        userId =&gt; userDetails.FirstOrDefault(<br/>            x =&gt; x.UserId == userId)?.DisplayName),</pre>
<p>That's all we needed to do, and now I can start the application and query the same endpoint as before to get the enriched result:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ca953811-a9c1-4e4d-b938-d1e0489f6098.png" style="width:48.67em;height:40.92em;"/></p>
<p>The query result shows all the data we need</p>
<p>You can see that the <kbd>sellersDisplayName</kbd> property in the response is correctly set to the value we want.</p>
<p>There are quite a few aspects that need to be taken care of when using queries in projections, mainly to ensure reliability. The main goal of such work is to ensure that projections never fail. When the data that you need to query is located in the same storage as the read model that you are updating, the speed of processing and reliability of the query should be on an acceptable level. You might still want to apply a retry policy on the whole projection to mitigate issues of transient networking failures and similar situations. However, you should really not try querying external data sources to get additional data. We will discuss how to solve situations like this when we talk about integration aspects.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Upcasting events</h1>
                
            
            
                
<p>The most complex way to get more data into the read model is by using <strong>event upcasting</strong>. Basically, to implement this, we need to create a separate subscription to the Event Store that receives the slim event, gets the additional data from somewhere else, produces a new event with more data, and publishes it to a special stream. This stream could never be the aggregate stream since the new event is only needed to build a read model. We could choose a special name for the stream, such as <kbd>ClassifiedAd-Upcast</kbd>. Since the read model projection listens to the <kbd>$all</kbd> stream, it will receive and process these events as well. This method is only useful when the additional data is needed for different read models, so we can update all of them using one enriched event, hence we need to query for additional data only once.</p>
<p>We don't have many read models, but I can still demonstrate this approach on a single <kbd>ClassifiedAdDetails</kbd> event. Let's assume we need to include the owner's photo in the read model as soon as the ad gets published, so we can enrich the <kbd>ClassifiedAdPublished</kbd> event.</p>
<p>First, I need to add <kbd>SellersPhotoUrl</kbd> to the read model itself; it will be just a string, as follows:</p>
<pre class="language-csharp">public class ClassifiedAdDetails
{
    public Guid ClassifiedAdId { get; set; }
    public string Title { get; set; }
    public decimal Price { get; set; }
    public string CurrencyCode { get; set; }
    public string Description { get; set; }
    public Guid SellerId { get; set; }
    public string SellersDisplayName { get; set; }
    public string SellersPhotoUrl { get; set; }
    public string[] PhotoUrls { get; set; }
}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>We also need to get the owner ID to the up caster, otherwise, it doesn't know which user it needs to ask for the photo. Here, we can use the fat event method and add the <kbd>OwnerId</kbd> property to our <kbd>ClassifiedAdPublished</kbd> event. After I've added the property, I need to change the <kbd>Publish</kbd> method of the <kbd>ClassifiedAd</kbd> aggregate, so it will populate this property from the aggregate state:</p>
<pre class="language-csharp">public void Publish(UserId userId) =&gt;
    Apply(new Events.ClassifiedAdPublished
    {
        Id = Id, 
        ApprovedBy = userId,
        OwnerId = OwnerId
    });</pre>
<p>I also need to have the up casted event as a class, so I add it as follows:</p>
<pre class="language-csharp">public static class ClassifiedAdUpcastedEvents
{
    public static class V1
    {
        public class ClassifiedAdPublished
        {
            public Guid Id { get; set; }
            public Guid OwnerId { get; set; }
            public string SellersPhotoUrl { get; set; }
            public Guid ApprovedBy { get; set; }
        }
    }
}</pre>
<p>We were saving events to the Event Store before and the code is located in the <kbd>EsAggregateStore</kbd> class. Now, we need this code again, so that we can create a useful extension to the <kbd>IEventStoreConnection</kbd> interface to make saving events more convenient:</p>
<pre class="language-csharp">using System;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using EventStore.ClientAPI;
using Newtonsoft.Json;

namespace Marketplace.Infrastructure
{
    public static class EventStoreExtensions
    {
        public static Task AppendEvents(<br/>            this IEventStoreConnection connection,
            string streamName, long version,
            params object[] events)
        {
            if (events == null || !events.Any()) return <br/>                Task.CompletedTask;
            
            var preparedEvents = events
                .Select(@event =&gt;
                    new EventData(
                        eventId: Guid.NewGuid(),
                        type: @event.GetType().Name,
                        isJson: true,
                        data: Serialize(@event),
                        metadata: Serialize(<br/>                            new EventMetadata {ClrType = <br/>                                @event.GetType().AssemblyQualifiedName})
                    ))
                .ToArray();
            return connection.AppendToStreamAsync(
                streamName,
                version,
                preparedEvents);
        } 
        
        private static byte[] Serialize(object data)
            =&gt; Encoding.UTF8.GetBytes(<br/>                JsonConvert.SerializeObject(data));
    }
    
}</pre>
<p>Since this code is copied from the <kbd>EsAggregateStore</kbd> class, it would make sense to use this method there as well, and you can see the changed code in the GitHub repository.</p>
<p>Next, I need to create a new projection. I can call it <kbd>ClassifiedAdUpcasters</kbd> and put it to the <kbd>Projections</kbd> folder of the main project. The class needs to implement <kbd>IProjection</kbd> so that I can feed our <kbd>ProjectionManager</kbd> with it. In the <kbd>Project</kbd> method, I need to handle a single event; but for future use, I can still use the <kbd>switch</kbd> statement although it also has one <kbd>case</kbd>. In this <kbd>case</kbd>, I need to emit a new event to the upcasting stream, so I'd need to take <kbd>IEventStoreConnection</kbd> as a dependency. The code for the new class is shown as follows:</p>
<pre class="language-csharp">using System;<br/>using System.Threading.Tasks;<br/>using EventStore.ClientAPI;<br/>using Marketplace.Framework;<br/>using Marketplace.Infrastructure;<br/>using static Marketplace.Domain.ClassifiedAd.Events;<br/>using static Marketplace.Projections.ClassifiedAdUpcastedEvents;<br/><br/>namespace Marketplace.Projections<br/>{<br/>    public class ClassifiedAdUpcasters : IProjection<br/>    {<br/>        private readonly IEventStoreConnection _eventStoreConnection;<br/>        private readonly Func&lt;Guid, string&gt; _getUserPhoto;<br/>        private const string StreamName = "UpcastedClassifiedAdEvents";<br/><br/>        public ClassifiedAdUpcasters(<br/>            IEventStoreConnection eventStoreConnection,<br/>            Func&lt;Guid, string&gt; getUserPhoto)<br/>        {<br/>            _eventStoreConnection = eventStoreConnection;<br/>            _getUserPhoto = getUserPhoto;<br/>        }<br/><br/>        public async Task Project(object @event)<br/>        {<br/>            switch (@event)<br/>            {<br/>                case ClassifiedAdPublished e:<br/>                    var photoUrl = _getUserPhoto(e.OwnerId);<br/>                    var newEvent = new V1.ClassifiedAdPublished<br/>                    {<br/>                        Id = e.Id,<br/>                        OwnerId = e.OwnerId,<br/>                        ApprovedBy = e.ApprovedBy,<br/>                        SellersPhotoUrl = photoUrl<br/>                    };<br/>                    await _eventStoreConnection.AppendEvents(<br/>                        StreamName,<br/>                        ExpectedVersion.Any,<br/>                        newEvent);<br/>                    break;<br/>            }<br/>        }<br/>    }<br/><br/>    public static class ClassifiedAdUpcastedEvents<br/>    {<br/>        public static class V1<br/>        {<br/>            public class ClassifiedAdPublished<br/>            {<br/>                public Guid Id { get; set; }<br/>                public Guid OwnerId { get; set; }<br/>                public string SellersPhotoUrl { get; set; }<br/>                public Guid ApprovedBy { get; set; }<br/>            }<br/>        }<br/>    }<br/>}</pre>
<p>As you can see in the code, I need to get a function that will allow the projection to get the user photo URL from somewhere. As soon as this projection received the <kbd>ClassifiedAdPublished</kbd> event, it will query the photo URL and emit a new, enriching event to the <kbd>UpcastedClassifiedAds</kbd> stream.</p>
<p>We also need to project the upcasted event in the <kbd>ClassifiedAdDetails</kbd> projection, so I add one more <kbd>case</kbd> to the <kbd>Project</kbd> method:</p>
<pre class="language-csharp">case V1.ClassifiedAdPublished e:
    UpdateItem(e.Id, ad =&gt; ad.SellersPhotoUrl = e.SellersPhotoUrl);
    break;</pre>
<p>The last thing is the wiring, where I need to add this new projection to the projection manager, so it will include it in the subscription processing. So, I need to change the <kbd>Startup.cs</kbd> file, as follows:</p>
<pre class="language-csharp">var projectionManager = new ProjectionManager(esConnection, 
    new ClassifiedAdDetailsProjection(classifiedAdDetails, 
        userId =&gt; userDetails.FirstOrDefault(<br/>            x =&gt; x.UserId == userId)?.DisplayName),
    new UserDetailsProjection(userDetails),
    new ClassifiedAdUpcasters(esConnection,
        userId =&gt; userDetails.FirstOrDefault(<br/>            x =&gt; x.UserId == userId)?.PhotoUrl));</pre>
<p>Here, you can see that I use <kbd>esConnection</kbd>, which has been instantiated before for the aggregate store, and the function to query the user photo URL from the <kbd>UserDetails</kbd> read model.</p>
<p>When everything is done, I can run the application again. In Swagger, I use the user profile command API to add the photo URL to the user, then use the classified ad command API to first request the ad to be published, and then publish it. Once I complete these operations via the API, I can go back to the query API and get the new details. The new result includes the photo URL, as expected:</p>
<pre class="language-json">{
  "classifiedAdId": "556bc798-bacc-4bb8-a55b-50144add4f17",
  "title": "Wooden table",
  "price": 10,
  "currencyCode": "EUR",
  "description": "The table is 100 years old but still solid. Probably <br/>  worth a fortune.",
  "sellerId": "8dd8c5c6-6edb-4e42-ac9e-a232ea445b76",
  "sellersDisplayName": "JustPrejudice",
  "sellersPhotoUrl": "https://www.biography.com/.image/t_share<br/>  /MTE1ODA0OTcxNTQ2ODcxMzA5/jane-austen-9192819-1-402.jpg",
  "photoUrls": null
}</pre>
<p>We can also look to the Event Store UI and check the content of the upcasted events stream by going to <kbd>http://localhost:2113/web/index.html#/streams/UpcastedClassifiedAdEvents</kbd>. The stream shows one event, and when I click on it, I see the following content:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a19f1b02-924b-4c64-a714-b245c243e6b7.png" style="width:51.00em;height:25.25em;"/></p>
<p>The consent of the upcasted event</p>
<p>Be aware that since we keep everything in memory, and our projections start from the very beginning of the <kbd>$all</kbd> stream each time the application starts, the up caster will handle the event again and will produce as many upcasted events as the number of times you run the application. The only way to avoid this is, of course, to store the stream position after we process each event. When we stop and start the application, we read the stored position and only start processing new events. We will dive into this in the next section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Persistent storage</h1>
                
            
            
                
<p>By now, we already have a few projections that build some useful read models that we can potentially use for the UI of our application. However, these read models aren't persistent and when we stop the app, everything disappears. Of course, read models are quickly rebuilt when we start the app again, and although it is a perfectly fine way to build read models at the beginning of the development cycle, this won't work for a production system. In addition, if we use upcasting, we will emit up cast events each time the app starts, since the upcasting subscription will process all events again. So, it is now time to persist our read models to a database.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Checkpoints</h1>
                
            
            
                
<p>As we have seen before, our application reprocesses all events in all projections when we start it. That's because we give <kbd>Position.Start</kbd> as the initial position when we create a subscription in the <kbd>ProjectionManager</kbd> code. Since we want to store our read models in the database, we also need to start giving the subscription an actual position after processing events. This means that we also need to keep the position persisted somewhere. In different systems, such a position can be called differently. In event log systems, such as Kafka or Azure Event Hub, the term <strong>offset</strong> is used. Event Store uses the term <strong>checkpoint</strong> and this is what we are going to use in this book.</p>
<p>Ideally, we would keep the checkpoint in the same database as the read models for that subscription. For some database engines, it is even possible to wrap all read model updates and checkpoint updates into a single transaction, and that might be desirable. Using this method definitely makes the projection-handling code more complex, since a single transaction needs to pass through to all projections and to the checkpoint store.</p>
<p>We will be using RavenDB, and although it supports some sort of multi-document transactions, we won't be doing this to keep the code simpler. So, the first thing I need to do is to define an interface for the checkpoint store. For this, I add an <kbd>ICheckpointStore</kbd> file to the <kbd>Marketplace.Framework</kbd> project. The code is very simple; we only need a couple of methods, as follows:</p>
<pre class="language-csharp">using System.Threading.Tasks;
using EventStore.ClientAPI;

namespace Marketplace.Framework
{
    public interface ICheckpointStore
    {
        Task&lt;Position&gt; GetCheckpoint();
        Task StoreCheckpoint(Position checkpoint);
    }
}</pre>
<p>Here, <kbd>Position</kbd> is the <kbd>struct</kbd> defined in the Event Store API, and we might want to try to avoid putting infrastructural dependencies in this project, but it will work for now.</p>
<p>We also need a document for RavenDB where the checkpoint will be stored. It needs to have an <kbd>Id</kbd> field of type string and the actual position:</p>
<pre class="language-csharp">using EventStore.ClientAPI;

namespace Marketplace.Infrastructure
{
    public class Checkpoint
    {
        public string Id { get; set; }
        public Position Position { get; set; }
    }
}</pre>
<p>Next, we need to implement this interface. Since I plan to store everything in RavenDB, it would be logical to call the implementation, <kbd>RavenDbCheckpointStore</kbd>. I add this class to the <kbd>Marketplace</kbd> project in the <kbd>Infrastructure</kbd> folder:</p>
<pre class="language-csharp">using System;<br/>using System.Threading.Tasks;<br/>using EventStore.ClientAPI;<br/>using Marketplace.Framework;<br/>using Raven.Client.Documents.Session;<br/><br/>namespace Marketplace.Infrastructure<br/>{<br/>    public class RavenDbCheckpointStore : ICheckpointStore<br/>    {<br/>        private readonly Func&lt;IAsyncDocumentSession&gt; _getSession;<br/>        private readonly string _checkpointName;<br/><br/>        public RavenDbCheckpointStore(<br/>            Func&lt;IAsyncDocumentSession&gt; getSession,<br/>            string checkpointName)<br/>        {<br/>            _getSession = getSession;<br/>            _checkpointName = checkpointName;<br/>        }<br/><br/>        public async Task&lt;Position&gt; GetCheckpoint()<br/>        {<br/>            using var session = _getSession();<br/>            var checkpoint = await session<br/>                .LoadAsync&lt;Checkpoint&gt;(_checkpointName);<br/>            return checkpoint?.Position ?? Position.Start;<br/>        }<br/><br/>        public async Task StoreCheckpoint(Position position)<br/>        {<br/>            using var session = _getSession();<br/>            <br/>            var checkpoint = await session<br/>                .LoadAsync&lt;Checkpoint&gt;(_checkpointName);<br/>            <br/>            if (checkpoint == null)<br/>            {<br/>                checkpoint = new Checkpoint<br/>                {<br/>                    Id = _checkpointName<br/>                };<br/>                await session.StoreAsync(checkpoint);<br/>            }<br/><br/>            checkpoint.Position = position;<br/>            await session.SaveChangesAsync();<br/>        }<br/>    }<br/>}</pre>
<p>Although the code is a bit long, it is not very complex. We need to give a session factory as a parameter for this class. We also need some sort of an identifier, in case we have multiple subscriptions. This <kbd>checkpointName</kbd> string will be used as the <kbd>Checkpoint</kbd> document ID.</p>
<p>In <kbd>GetCheckpoint</kbd>, we try to load the document, and if it doesn't exist, the method returns <kbd>Position.Start</kbd>, so that we can subscribe to the very beginning. It replicates the no-checkpoint situation and, in case you need to rebuild all read models from the ground up, you just need to remove this document, along with all documents for read models.</p>
<p>When we save the checkpoint, we must try loading one to see if it exists. If it does, we update it with the new position, otherwise, we store a new document.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The next thing is, of course, our <kbd>ProjectionManager</kbd>. It needs to be able to work with the checkpoint store. We don't need it to know about RavenDB since it is only needed for projections and the checkpoint store. But it needs to call the checkpoint store when making a subscription and to save the position after projecting each event. So, we need to add the <kbd>ICheckpointStore</kbd> parameter and call the two methods that this interface has, as follows:</p>
<pre class="language-csharp">using System.Linq;
using System.Threading.Tasks;
using EventStore.ClientAPI;
using Marketplace.Framework;
using Serilog;
using Serilog.Events;

namespace Marketplace.Infrastructure
{
    public class ProjectionManager
    {
        private readonly IEventStoreConnection _connection;
        private readonly ICheckpointStore _checkpointStore;
        private readonly IProjection[] _projections;
        private EventStoreAllCatchUpSubscription _subscription;

        public ProjectionManager(
            IEventStoreConnection connection, 
            ICheckpointStore checkpointStore, 
            params IProjection[] projections)
        {
            _connection = connection;
            _checkpointStore = checkpointStore;
            _projections = projections;
        }

        public async Task Start()
        {
            var settings = new CatchUpSubscriptionSettings(2000, 500,
                Log.IsEnabled(LogEventLevel.Verbose),
                false, "try-out-subscription");

            var position = await _checkpointStore.GetCheckpoint();
            _subscription = _connection.SubscribeToAllFrom(position,
                settings, EventAppeared);
        }

        public void Stop() =&gt; _subscription.Stop();

        private async Task EventAppeared(<br/>            EventStoreCatchUpSubscription _, 
            ResolvedEvent resolvedEvent)
        {
            if (resolvedEvent.Event.EventType.StartsWith("$")) return;
            
            var @event = resolvedEvent.Deserialzie();
            
            Log.Debug("Projecting event {type}", <br/>                @event.GetType().Name);
            await Task.WhenAll(_projections.Select(<br/>                x =&gt; x.Project(@event)));

            await _checkpointStore.StoreCheckpoint(<br/>                resolvedEvent.OriginalPosition.Value);
        }
    }
}</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Persisting read models</h1>
                
            
            
                
<p>Since we need RavenDb anyway, I used some code from <a href="75bc64ae-a642-42b2-a44a-05ae0cb2b750.xhtml">Chapter 10</a>, <em>Event Sourcing,</em> but made it a little more advanced. I moved the initialization of the document store to a separate method in the <kbd>Startup</kbd> class. The method will use the <kbd>appsettings.json</kbd> configuration section instead of hard coded values. It will also create the database if it doesn't exist, so we don't need to create it manually. It is not important for the content of this chapter to know how the database is configured, you can check the code snippet of the book to see how it is done. Check the settings file there as well, to see the configuration structure.</p>
<p>After these changes are made, I need to change the <kbd>Startup.ConfigureServices</kbd> method, so it calls the store initialization method. We need to have a document session factory and also register <kbd>IAsyncDocumentSession</kbd> in the services collection since we'll need it in the query API controller. Here are some of the changes in the registration:</p>
<pre class="language-csharp">var documentStore = ConfigureRavenDb(<br/>    Configuration.GetSection("ravenDb"));

Func&lt;IAsyncDocumentSession&gt; getSession = <br/>    () =&gt; documentStore.OpenAsyncSession();

services.AddTransient(c =&gt; getSession());</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>To make things simpler for individual projections, since they all will be using RavenDB for now, I created a simple base abstract class called <kbd>RavenDbProjecion</kbd>. It accepts the session factory for its constructor and contains a helpful method to execute updates on read model documents and that's why the class is a generic class, so we will use the read model class type as a generic parameter:</p>
<pre class="language-csharp">using System;<br/>using System.Linq.Expressions;<br/>using System.Threading.Tasks;<br/>using Marketplace.Framework;<br/>using Raven.Client.Documents;<br/>using Raven.Client.Documents.Linq;<br/>using Raven.Client.Documents.Session;<br/><br/>namespace Marketplace.Infrastructure<br/>{<br/>    public abstract class RavenDbProjection&lt;T&gt; : IProjection<br/>    {<br/>        protected RavenDbProjection(<br/>            Func&lt;IAsyncDocumentSession&gt; getSession<br/>        )<br/>            =&gt; GetSession = getSession;<br/><br/>        protected Func&lt;IAsyncDocumentSession&gt; GetSession { get; }<br/><br/>        public abstract Task Project(object @event);<br/><br/>        protected Task Create(Func&lt;Task&lt;T&gt;&gt; model)<br/>            =&gt; UsingSession(<br/>                async session =&gt; <br/>                    await session.StoreAsync(await model())<br/>            );<br/><br/>        protected Task UpdateOne(Guid id, Action&lt;T&gt; update)<br/>            =&gt; UsingSession(<br/>                session =&gt;<br/>                    UpdateItem(session, id, update)<br/>            );<br/><br/>        protected Task UpdateWhere(<br/>            Expression&lt;Func&lt;T, bool&gt;&gt; where,<br/>            Action&lt;T&gt; update<br/>        ) =&gt; UsingSession(<br/>            session =&gt;<br/>                UpdateMultipleItems(<br/>                    session, where, update<br/>                )<br/>        );<br/><br/>        private static async Task UpdateItem(<br/>            IAsyncDocumentSession session, Guid id,<br/>            Action&lt;T&gt; update<br/>        )<br/>        {<br/>            var item = await session<br/>                .LoadAsync&lt;T&gt;(id.ToString());<br/><br/>            if (item == null) return;<br/><br/>            update(item);<br/>        }<br/><br/>        async Task UpdateMultipleItems(<br/>            IAsyncDocumentSession session,<br/>            Expression&lt;Func&lt;T, bool&gt;&gt; query, Action&lt;T&gt; update<br/>        )<br/>        {<br/>            var items = await session<br/>                .Query&lt;T&gt;()<br/>                .Where(query)<br/>                .ToListAsync();<br/>            foreach (var item in items)<br/>                update(item);<br/>        }<br/><br/>        protected async Task UsingSession(<br/>            Func&lt;IAsyncDocumentSession, Task&gt; operation<br/>        )<br/>        {<br/>            using var session = GetSession();<br/><br/>            await operation(session);<br/>            await session.SaveChangesAsync();<br/>        }<br/>    }<br/>}</pre>
<p>You have already seen <kbd>UpdateItem</kbd> and <kbd>UpdateMultipleItems</kbd>, which were implemented inside projection classes. Since the code is very similar, I was able to isolate it in the abstract class. I also made these methods private and made three methods with simpler signatures: <kbd>Create</kbd>, <kbd>UpdatedOne</kbd>, and <kbd>UpdateWhere</kbd>. Notice also the <kbd>UsingSession</kbd> method.</p>
<p>Since we are using the session factory, it will be our responsibility to dispose of it after use. To avoid the endless noise of the <kbd>using</kbd> statement in the projection code, we will be calling the <kbd>UsingSession</kbd> method that will do it for us. It also persists all changes that are done by the delegate that it calls before disposing of the session.</p>
<p>In order to save read models as documents to RavenDB, we must comply with the database engine conventions to make our life simpler. Therefore, we must change all identity properties to have the <kbd>Id</kbd> name and the type string (now we have <kbd>Guid</kbd>). In all places where type mismatches, I changed usages of <kbd>Guid</kbd> fields by calling <kbd>ToString()</kbd>.</p>
<p>Now we are ready to convert the simplest projection to use RavenDB, and this will be the <kbd>UserDetailsProjection</kbd>. I changed it to inherit from the <kbd>RavenDbProjection</kbd> abstract class, so the helper method can go away. We need a constructor since it is required by the base class, but overall, the code is now smaller. The only real change was that I used those new helper methods to make the code simpler. Here is the new code:</p>
<pre class="language-csharp">using System;<br/>using System.Threading.Tasks;<br/>using Marketplace.Domain.UserProfile;<br/>using Marketplace.Infrastructure;<br/>using Raven.Client.Documents.Session;<br/><br/>namespace Marketplace.Projections<br/>{<br/>    public class UserDetailsProjection<br/>        : RavenDbProjection&lt;ReadModels.UserDetails&gt;<br/>    {<br/>        public UserDetailsProjection(<br/>            Func&lt;IAsyncDocumentSession&gt; getSession<br/>        ) : base(getSession) { }<br/><br/>        public override Task Project(object @event) =&gt; <br/>            @event switch<br/>            {<br/>                Events.UserRegistered e =&gt;<br/>                    Create(<br/>                        () =&gt; Task.FromResult(<br/>                            new ReadModels.UserDetails<br/>                            {<br/>                                Id = e.UserId.ToString(),<br/>                                DisplayName = e.DisplayName<br/>                            }<br/>                        )<br/>                    ),<br/>                Events.UserDisplayNameUpdated e =&gt;<br/>                    UpdateOne(<br/>                        e.UserId,<br/>                        x =&gt; x.DisplayName = e.DisplayName<br/>                    ),<br/>                Events.ProfilePhotoUploaded e =&gt;<br/>                    UpdateOne(<br/>                        e.UserId,<br/>                        x =&gt; x.PhotoUrl = e.PhotoUrl<br/>                    ),<br/>                _ =&gt; Task.CompletedTask<br/>            };<br/>    }<br/>}</pre>
<p>Our second projection is more serious, so we need to make more changes, but still, the difference is not huge. We need to give it the session factory too, since it is required for the <kbd>RavenDbProjection</kbd> base class. An important change is that, since we can imagine the user display name query to be asynchronous, we need to change the delegate signature to return <kbd>Task&lt;string&gt;</kbd> instead of a string. All other changes are related to implementing updates by calling the <kbd>Update</kbd> and <kbd>UpdateWhere</kbd> methods of the base class. One thing to notice, in addition to this, is related to the asynchronous query of the user profile, so when we call the query, we need to await the call. Here is the full code:</p>
<pre class="language-csharp">using System;<br/>using System.Linq.Expressions;<br/>using System.Threading.Tasks;<br/>using Marketplace.ClassifiedAd;<br/>using Marketplace.Infrastructure;<br/>using Raven.Client.Documents.Session;<br/>using static Marketplace.Domain.ClassifiedAd.Events;<br/>using static Marketplace.Domain.UserProfile.Events;<br/>using static Marketplace.Projections.ClassifiedAdUpcastedEvents;<br/>using static Marketplace.Projections.ReadModels;<br/><br/>namespace Marketplace.Projections<br/>{<br/>    public class ClassifiedAdDetailsProjection<br/>        : RavenDbProjection&lt;ClassifiedAdDetails&gt;<br/>    {<br/>        private readonly Func&lt;Guid, Task&lt;string&gt;&gt;<br/>            _getUserDisplayName;<br/><br/>        public ClassifiedAdDetailsProjection(<br/>            Func&lt;IAsyncDocumentSession&gt; getSession,<br/>            Func&lt;Guid, Task&lt;string&gt;&gt; getUserDisplayName<br/>        )<br/>            : base(getSession)<br/>            =&gt; _getUserDisplayName = getUserDisplayName;<br/><br/>        public override Task Project(object @event) =&gt;<br/>            @event switch<br/>            {<br/>                ClassifiedAdCreated e =&gt;<br/>                    Create(async () =&gt;<br/>                        new ClassifiedAdDetails<br/>                        {<br/>                            Id = e.Id.ToString(),<br/>                            SellerId = e.OwnerId,<br/>                            SellersDisplayName =<br/>                                await _getUserDisplayName(<br/>                                    e.OwnerId<br/>                                )<br/>                        }<br/>                    ),<br/>                ClassifiedAdTitleChanged e =&gt;<br/>                    UpdateOne(e.Id, ad =&gt; ad.Title = e.Title),<br/>                ClassifiedAdTextUpdated e =&gt;<br/>                    UpdateOne(e.Id, ad =&gt; ad.Description = e.AdText),<br/>                ClassifiedAdPriceUpdated e =&gt;<br/>                    UpdateOne(<br/>                        e.Id,<br/>                        ad =&gt;<br/>                        {<br/>                            ad.Price = e.Price;<br/>                            ad.CurrencyCode = e.CurrencyCode;<br/>                        }<br/>                    ),<br/>                UserDisplayNameUpdated e =&gt;<br/>                    UpdateWhere(<br/>                        x =&gt; x.SellerId == e.UserId,<br/>                        x =&gt; x.SellersDisplayName = e.DisplayName<br/>                    ),<br/>                V1.ClassifiedAdPublished e =&gt;<br/>                    UpdateOne(<br/>                        e.Id,<br/>                        ad =&gt; ad.SellersPhotoUrl = e.SellersPhotoUrl<br/>                    ),<br/>                _ =&gt; Task.CompletedTask<br/>            };<br/>    }<br/>}<br/><br/></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The last projection is our up caster. Since it doesn't use RavenDB, there is no need to inherit it from the base class. The only change I needed to make there is to change the query delegate so that it will return <kbd>Task&lt;string&gt;</kbd>, and the query call needs to be awaited:</p>
<pre class="language-csharp">var photoUrl = await _getUserPhoto(e.OwnerId);</pre>
<p>I won't be putting the full class code here, since the changes are minimal.</p>
<p>One thing to take care of is, of course, to create those queries in the <kbd>UserDetails</kbd> read model, since we won't be going to a simple <kbd>List</kbd>. To make the code a little simpler, I created a small class called <kbd>Queries</kbd> in the <kbd>ReadModels.UserDetails</kbd> namespace, with one method that will obtain the profile for a single user:</p>
<pre class="language-csharp">using System;<br/>using System.Threading.Tasks;<br/>using Raven.Client.Documents.Session;<br/>using static Marketplace.Projections.ReadModels;<br/><br/>namespace Marketplace.UserProfile<br/>{<br/>    public static class Queries<br/>    {<br/>        public static Task&lt;UserDetails&gt; GetUserDetails(<br/>            this Func&lt;IAsyncDocumentSession&gt; getSession,<br/>            Guid id<br/>        )<br/>        {<br/>            using var session = getSession();<br/><br/>            return session.LoadAsync&lt;UserDetails&gt;(id.ToString());<br/>        }<br/>    }<br/>}</pre>
<p>This is an extension method not to the session object itself, but to a session factory, since we must dispose of the session after calling this query. This will be different for controllers, since there, the service collection will give us a session as a transient dependency.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Wrapping up</h1>
                
            
            
                
<p>All we need to do now is some wiring and make some small changes in the query API controller.</p>
<p class="mce-root"/>
<p>First, the <kbd>EventStoreService</kbd> class needs to await the call to <kbd>projectionManager.Start()</kbd>, since this method is now <kbd>async</kbd>. Then, we need to fix the query API controller, by making changes to the <kbd>Queries</kbd> extensions class to use the document session:</p>
<pre class="language-csharp">using System.Threading.Tasks;<br/>using Raven.Client.Documents.Session;<br/>using static Marketplace.ClassifiedAd.QueryModels;<br/>using static Marketplace.Projections.ReadModels;<br/><br/>namespace Marketplace.ClassifiedAd<br/>{<br/>    public static class Queries<br/>    {<br/>        public static Task&lt;ClassifiedAdDetails&gt; Query(<br/>            this IAsyncDocumentSession session,<br/>            GetPublicClassifiedAd query<br/>        ) =&gt;<br/>            session.LoadAsync&lt;ClassifiedAdDetails&gt;(<br/>                query.ClassifiedAdId.ToString()<br/>            );<br/>    }<br/>}</pre>
<p>Since the query is now asynchronous, we need to prepare our <kbd>RequestHandler.HandleQuery</kbd> so that it can await the query, and also return <kbd>Task&lt;IActionResult&gt;</kbd> so the controller can be <kbd>async</kbd> as well:</p>
<pre class="language-csharp">public static async Task&lt;IActionResult&gt; HandleQuery&lt;TModel&gt;(
    Func&lt;Task&lt;TModel&gt;&gt; query, ILogger log)
{
    try
    {
        return new OkObjectResult(await query());
    }
    catch (Exception e)
    {
        log.Error(e, "Error handling the query");
        return new BadRequestObjectResult(<br/>            new
            {
                error = e.Message, stackTrace = e.StackTrace
            });
    }
}</pre>
<p>The last change for the API will be to fix the controller itself so that it can get the session injected as a dependency and become <kbd>async</kbd>:</p>
<pre class="language-csharp">using System.Threading.Tasks;
using Marketplace.Infrastructure;
using Microsoft.AspNetCore.Mvc;
using Raven.Client.Documents.Session;
using Serilog;

namespace Marketplace.ClassifiedAd
{
    [Route("/ad")]
    public class ClassifiedAdsQueryApi : Controller
    {
        private readonly IAsyncDocumentSession _session;
        private static ILogger _log = <br/>        Log.ForContext&lt;ClassifiedAdsQueryApi&gt;();
        
        public ClassifiedAdsQueryApi(IAsyncDocumentSession session) =&gt; 
            _session = session;

        [HttpGet]
        public Task&lt;IActionResult&gt; <br/>        Get(QueryModels.GetPublicClassifiedAd request)
            =&gt; RequestHandler.HandleQuery(() =&gt; <br/>                _session.Query(request), _log);
    }
}</pre>
<p>The final thing to fix is the <kbd>Startup</kbd> class. I already mentioned the RavenDB initialization and the preceding registration code. We only need to make a few necessary changes to register our projection manager and all projections. Remember that we changed the query delegates to be async, so there are quite a few changes in the following lines of code:</p>
<pre class="language-csharp">var projectionManager = new ProjectionManager(esConnection,
    new RavenDbCheckpointStore(getSession, "readmodels"),
    new ClassifiedAdDetailsProjection(getSession,
        async userId =&gt; (await <br/>        getSession.GetUserDetails(userId))?.DisplayName),
    new ClassifiedAdUpcasters(esConnection,
        async userId =&gt; (await <br/>        getSession.GetUserDetails(userId))?.PhotoUrl),
        new UserDetailsProjection(getSession));</pre>
<p>First, we added the checkpoint store parameter. Then, we added the session factory as a parameter to two projections that use RavenDB. Finally, both queries became async and used the same session factory combined with our new query extension.</p>
<p>All is done, and it is now time to run the application and see what happens.</p>
<p>After I pressed <em>F5</em>, I saw messages in the log that the same events as we saw earlier are being projected. This is expected, since we started from scratch again. Now I can call the query API again to see that the result is just as I expected it to be. If I start the application again, it produces no logs from projections, since now we persisted the checkpoint and started the subscription from where we stopped. So, unless we start making new operations, we won't get new events. Our application will be processing all updates in real time from now on.</p>
<p>Let's see what have we got in the database. When I open the RavenDB Studio UI by going to <kbd>http://localhost:8080</kbd>, I see that the <kbd>Marketplace_Chapter11</kbd> database is present, so I can click on it and check the content. In the database, I found three documents in different collections, as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a0260f40-d945-4f8d-abb5-84a8743616a4.png" style="width:53.83em;height:19.42em;"/></p>
<p>Three collections in RavenDB</p>
<p>Two of these documents are our read models and one document is the checkpoint. Let's see what the <kbd>ClassifiedAdDetails</kbd> document contains. As expected, we got all the information that we were projecting from our events:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/3d67244b-2d5b-4b9b-8f1f-ac692e3300a4.png" style="width:57.33em;height:30.92em;"/></p>
<p>The read model as a RavenDB document</p>
<p>Now we can check what the checkpoint document contains. It has the ID of our checkpoint name and the JSON content is something like the following (you might have different values):</p>
<pre class="language-json">{
    "Position": {
        "CommitPosition": 48771203,
        "PreparePosition": 48771203
    },
    "@metadata": {
        "@collection": "Checkpoints",
        "Raven-Clr-Type": "Marketplace.Infrastructure.Checkpoint, Marketplace"
    }
}</pre>
<p>By this point, we have all read models properly stored in the database, so we can build more queries from it, just like we did in <a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml"/><a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml"/><a href="6f50ee65-024a-4c46-89c8-343183b05b8f.xhtml">Chapter 9</a>, <em>CQRS - The Read Side</em>.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we took CQRS to a whole new level and learned how to query data that we initially stored as streams of events. Since event streams are hard to query on demand, we need to build snapshots of data that we can show to our users. The power of event-sourced read models is that we can build virtually an unlimited number of use case-specific read models, with very precise sets of data. We could avoid things such as joins across object collections or tables, or even between remote services. We can remove all read models at once and rebuild them from scratch, using only events. If we somehow created our projection in a way that it showed the wrong data on screen, then we can quickly catch the bug and fix the read models by removing and rebuilding them.</p>
<p>Of course, everything has its trade-offs. Sometimes, we can't receive all the data that we need for a read model from the event that we project. However, we went through several techniques to avoid this limitation.</p>
<p>Still, we should remember that when the system grows, the number of events grows too, and building a new read model or rebuilding the one that existed before, but had a bug that we needed to fix and then build all records in the database again, may take a very long time. For systems with billions of events, it can take days or even weeks. There are ways to improve performance for projections, which I will mention later when we discuss the advanced topics of event sourcing. However, remember, by default, events are projected sequentially and the order is very important. So, the usual techniques that we apply in the messaging world, such as competing consumers for horizontal scaling, aren't directly applicable for projections. It is possible, however, to partition projections by splitting the <kbd>$all</kbd> stream into several streams by a given property. Event Store projections that are written in JavaScript and run directly on the server can be used for that purpose.</p>
<p>While we have gone through some quite advanced topics already, the last few chapters have been very technical. In <a href="01e2a3de-465b-48aa-b297-e75269799cbb.xhtml"/><a href="https://www.packtpub.com/sites/default/files/downloads/Splitting_the_System.pdf">Chapter 13</a>, <em>Splitting the System,</em> we return to the concepts of <strong>Domain-Driven Design</strong> (<strong>DDD</strong>), and will discuss the most important idea of DDD—that no complex system in the problem space can be implemented as a single system in the solution space. We will go on to the topic of bounded context and context mapping.</p>


            

            
        
    </body></html>