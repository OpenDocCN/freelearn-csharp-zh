- en: Scaling Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务扩展
- en: Imagine you are part of a development and support team that is responsible for
    developing the company's flagship product—TaxCloud. TaxCloud helps taxpayers file
    their own taxes and charges them a small fee upon the successful filing of taxes.
    Consider you had developed this application using microservices. Now, say the
    product gets popular and gains traction, and suddenly, on the last day of tax
    filing, you get a rush of consumers wanting to use your product and file their
    taxes. However, the payment service of your system is slow, which has almost brought
    the system down, and all the new customers are moving to your competitor's product.
    This is a lost opportunity for your business.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你是一个开发和支持团队的一员，该团队负责开发公司的旗舰产品——TaxCloud。TaxCloud帮助纳税人自行申报税收，并在成功申报税收后收取一小笔费用。假设你使用微服务开发了此应用程序。现在，假设产品变得流行并获得关注，突然在申报税收的最后一天，你迎来了大量消费者想要使用你的产品并申报税收。然而，你系统的支付服务速度很慢，这几乎使系统崩溃，所有新客户都转向了你的竞争对手的产品。这对你的业务来说是一个失去的机会。
- en: 'Even though this is a fictitious scenario, it can very well happen to any business.
    In e-commerce, we have always experienced these kinds of things in real life,
    especially on special occasions such as Christmas and Black Friday. All in all,
    they point toward one major significant characteristic—the scalability of the system.
    Scalability is one of the most important non-functional requirements of any mission-critical
    system. Serving a couple of users with hundreds of transactions is not the same
    as serving millions of users with several million transactions. In this chapter,
    we will discuss scalability in general. We''ll also discuss how to scale microservices
    individually, what to consider when we design them, and how to avoid cascading
    failure using different patterns. By the end of this chapter, you will have learned
    about:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个虚构的场景，但它可能发生在任何业务中。在电子商务中，我们在现实生活中一直经历过这些事情，尤其是在圣诞节和黑色星期五这样的特殊场合。总的来说，它们指向一个主要的重要特征——系统的扩展性。扩展性是任何关键任务系统最重要的非功能性需求之一。为几百个用户提供数百笔交易与为几百万用户提供数百万笔交易是不同的。在本章中，我们将讨论扩展性的一般概念。我们还将讨论如何单独扩展微服务，设计它们时需要考虑什么，以及如何使用不同的模式避免级联故障。到本章结束时，你将了解以下内容：
- en: Horizontal scaling
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水平扩展
- en: Vertical scaling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垂直扩展
- en: The Scale Cube model of scalability
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展性立方模型
- en: Scaling infrastructure using Azure scale sets and Docker Swarm
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Azure 规模集和 Docker Swarm 进行基础设施扩展
- en: Scaling a service design through data model caching and response caching
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数据模型缓存和响应缓存扩展服务设计
- en: The circuit breaker pattern
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断路器模式
- en: Service discovery
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务发现
- en: Scalability overview
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展性概述
- en: Design decisions impact the scalability of a single microservice. As with other
    application capabilities, decisions that are made during the design and early
    coding phases largely influence the scalability of services.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 设计决策影响单个微服务的扩展性。与其他应用程序功能一样，在设计阶段和早期编码阶段做出的决策在很大程度上影响了服务的扩展性。
- en: Microservice scalability requires a balanced approach between services and their
    supporting infrastructures. Services and their infrastructures also need to to
    be scaled in harmony.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务扩展需要平衡服务及其支持基础设施的方法。服务和其基础设施也需要和谐地扩展。
- en: Scalability is one of the most important non-functional characteristics of a system
    as it can handle more payload. It is often felt that scalability is usually a
    concern for large-scale distributed systems. Performance and scalability are two
    different characteristics of a system. Performance deals with the throughput of
    the system, whereas scalability deals with serving the desired throughput for
    a larger number of users or a larger number of transactions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展性是系统最重要的非功能性特性之一，因为它可以处理更多的负载。通常认为，扩展性通常是大规模分布式系统关注的问题。性能和扩展性是系统的两种不同特性。性能涉及系统的吞吐量，而扩展性涉及为更多用户或更多交易提供服务所需的吞吐量。
- en: Scaling infrastructure
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展基础设施
- en: Microservices are modern applications and usually take advantage of the cloud.
    Therefore, when it comes to scalability, the cloud provides certain advantages.
    However, it is also about automation and managing costs. So even in the cloud,
    we need to understand how to provision infrastructure, such as virtual machines
    or containers, to successfully serve our microservices-based application even
    in the case of sudden traffic spikes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务是现代应用程序，通常利用云服务。因此，当谈到可扩展性时，云提供了一定的优势。然而，这也关乎自动化和管理成本。因此，即使在云中，我们也需要了解如何配置基础设施，例如虚拟机或容器，以便在突发流量激增的情况下成功服务于我们的基于微服务应用程序。
- en: Now we will visit each component of our infrastructure and see how we can scale
    it. The initial scaling up and scaling out methods are applied more to hardware
    scaling. With the Auto Scaling feature, you will understand Azure virtual manager
    scale sets. Finally, you will learn about scaling with containers in Docker Swarm
    mode.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将访问我们基础设施的每个组件，看看我们如何扩展它。最初的向上扩展和向外扩展方法更多地应用于硬件扩展。有了自动扩展功能，你将了解Azure虚拟管理器规模集。最后，你将学习在Docker
    Swarm模式下使用容器进行扩展。
- en: Vertical scaling (scaling up)
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垂直扩展（向上扩展）
- en: '**Scaling up** is a term used for achieving scalability by adding more resources
    to the same machine. It includes the addition of more memory or processors with
    higher speed or simply the migration of applications to a more powerful macOS.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**扩展**是一个术语，指的是通过向同一台机器添加更多资源来实现可扩展性。这包括添加更多内存或更高速度的处理器的操作，或者简单地将应用程序迁移到更强大的macOS上。'
- en: With upgrades in hardware, there is a limit as to how you can scale the machine.
    It is more likely that you are just shifting the bottleneck rather than solving
    the real problem of improving scalability. If you add more processors to the machine,
    you might shift the bottleneck to memory. Processing power does not increase the
    performance of your system linearly. At a certain point, the performance of a
    system stabilizes even if you add more processing capacity. Another aspect of
    scaling up is that since only one machine is serving all the requests, it becomes
    a single point of failure as well.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着硬件的升级，你能够扩展机器的程度是有限的。更有可能的是，你只是在转移瓶颈，而不是解决提高可扩展性的真正问题。如果你向机器添加更多处理器，你可能会将瓶颈转移到内存上。处理能力并不线性地提高你的系统性能。在某个点上，即使你添加更多的处理能力，系统的性能也会稳定下来。向上扩展的另一个方面是，由于只有一个机器在处理所有请求，它也成为了一个单点故障。
- en: In summary, scaling vertically is easy since it involves no code changes; however,
    it is quite an expensive technique. Stack Overflow is one of those rare examples
    of a .NET-based system that is scaled vertically.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，垂直扩展很容易，因为它不涉及代码更改；然而，这是一种相当昂贵的技巧。Stack Overflow是那些罕见的基于.NET的系统之一，它进行了垂直扩展。
- en: Horizontal scaling (scaling out)
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 水平扩展（向外扩展）
- en: If you do not want to scale vertically, you can always scale your system horizontally.
    Often, it is also referred to as **scaling out**. Google has really made this
    approach quite popular. The Google search engine is running out of inexpensive
    hardware boxes. So, despite being a distributed system, scaling out helped Google
    in its early days expand its search process in a short amount of time while being
    inexpensive. Most of the time, common tasks are assigned to worker machines and
    their output is collected by several machines doing the same task. This kind of
    arrangement also survives through failures. To scale out, load balancing techniques
    are useful. In this arrangement, a load balancer is usually added in front of
    all the clusters of the nodes. So, from a consumer perspective, it does not matter
    which machine/box you are hitting. This makes it easy to add capacity by adding
    more servers. Adding servers to clusters improves scalability linearly.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不想垂直扩展，你总是可以水平扩展你的系统。通常，这也被称为**向外扩展**。谷歌确实使这种方法变得非常流行。谷歌搜索引擎正耗尽廉价的硬件盒子。因此，尽管它是一个分布式系统，但向外扩展帮助谷歌在其早期快速扩展其搜索过程，同时成本较低。大多数时候，常见任务分配给工作机器，它们的输出由执行相同任务的多台机器收集。这种安排也能通过故障生存。要向外扩展，负载均衡技术是有用的。在这种安排中，通常在所有节点集群的前面添加一个负载均衡器。因此，从消费者角度来看，你击中哪台机器/盒子并不重要。这使得通过添加更多服务器来增加容量变得容易。向集群添加服务器可以线性地提高可扩展性。
- en: Scaling out is a successful strategy when the application code does not depend
    on the server it is running on. If the request needs to be executed on a specific
    server, that is, if the application code has server affinity, it will be difficult
    to scale out. However, in the case of stateless code, it is easier to get that
    code executed on any server. Hence, scalability is improved when a stateless code
    is run on horizontally scaled machines or clusters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序代码不依赖于其运行的服务器时，扩展是成功的策略。如果请求需要在特定的服务器上执行，即如果应用程序代码具有服务器亲和性，那么扩展将会很困难。然而，在无状态代码的情况下，更容易在任何服务器上执行该代码。因此，当在水平扩展的机器或集群上运行无状态代码时，可扩展性得到了提高。
- en: Due to the nature of horizontal scaling, it is a commonly used approach across
    the industry. You can see many examples of large scalable systems managed this
    way, for example, Google, Amazon, and Microsoft. We recommend that you scale microservices
    in a horizontal fashion as well.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由于水平扩展的性质，这在整个行业中是一种常用的方法。你可以看到许多大型可扩展系统就是这样管理的，例如，谷歌、亚马逊和微软。我们建议你以水平方式扩展微服务。
- en: Microservice scalability
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务可扩展性
- en: In this section, we will review the scaling strategies available for microservices.
    We will look at the Scale Cube model of scalability, how to scale the infrastructure
    layer for microservices, and embed scalability in microservice design.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾可用于微服务的扩展策略。我们将查看可扩展性的规模立方体模型，如何为微服务扩展基础设施层，以及在微服务设计中嵌入可扩展性。
- en: Scale Cube model of scalability
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可扩展性的规模立方体模型
- en: 'One way to look at scalability is by understanding Scale Cube. In the book *The
    Art of Scalability: Scalable Web Architecture, Processes, and Organizations for
    the Modern Enterprise*, Martin L. Abbott and Michael T. Fisher define Scale Cube
    as viewing and understanding system scalability. Scale Cube applies to microservice architectures
    as well:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 了解可扩展性的一种方法是通过理解规模立方体。在《可扩展性的艺术：现代企业的可扩展网络架构、流程和组织》一书中，马丁·L·艾博特和迈克尔·T·费舍尔将规模立方体定义为观察和理解系统可扩展性的方法。规模立方体也适用于微服务架构：
- en: '![](img/2d5760c4-f65e-462d-8133-ddf0ba025fe9.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/2d5760c4-f65e-462d-8133-ddf0ba025fe9.png)'
- en: In this three-dimensional model of scalability, the origin (0,0,0) represents
    the least scalable system. It assumes that the system is a monolith deployed on
    a single server instance. As shown, a system can be scaled by putting the right
    amount of effort into three dimensions. To move a system towards the right scalable
    direction, we need the right trade-offs. These trade-offs will help you gain the
    highest scalability for your system. This will help your system cater to increasing
    customer demand. This is signified by the **Scale Cube** model. Let's look into
    every axis of this model and discuss what they signify in terms of microservice
    scalability.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个可扩展性的三维模型中，原点（0,0,0）代表最不可扩展的系统。它假设系统是在单个服务器实例上部署的单体。如图所示，系统可以通过在三个维度上投入适量的努力来进行扩展。为了将系统推向正确的可扩展方向，我们需要做出正确的权衡。这些权衡将帮助您获得系统最高的可扩展性。这将帮助您的系统满足不断增长的客户需求。这由**规模立方体**模型表示。让我们来看看这个模型的每一个轴，并讨论它们在微服务可扩展性方面的含义。
- en: Scaling of x axis
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: x轴的扩展
- en: Scaling over the *x *axis means running multiple instances of an application
    behind a load balancer. This is a very common approach used in monolithic applications.
    One of the drawbacks of this approach is that any instance of an application can
    utilize all the data available for the application. It also fails to address application
    complexity.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在*x*轴上进行扩展意味着在负载均衡器后面运行应用程序的多个实例。这是一种在单体应用程序中非常常见的做法。这种方法的缺点之一是，应用程序的任何实例都可以利用为该应用程序提供的所有数据。它也未能解决应用程序的复杂性。
- en: Microservices should not share a global state or a kind of data store that can
    be accessed by all the services. This will create a bottleneck and a single point
    of failure. Hence, approaching microservice scaling merely over the *x *axis of
    Scale Cube would not be the right approach.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务不应该共享全局状态或一种可以被所有服务访问的数据存储。这将会造成瓶颈和单点故障。因此，仅仅在规模立方体的*x*轴上扩展微服务并不是正确的做法。
- en: Now let's look at *z *axis scaling. We have skipped *y *axis scaling for a reason.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看*z*轴的扩展。我们跳过*y*轴扩展是有原因的。
- en: Scaling of z axis
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: z轴的扩展
- en: 'The *z *axis scaling is based on a split, which is based on the customer or
    requestor of a transaction. While *z *axis splits may or may not address the monolithic
    nature of instructions, processes, or code, they very often do address the monolithic
    nature of the data necessary to perform these instructions, processes, or code.
    Naturally, in *z *axis scaling, there is one dedicated component responsible for
    applying the bias factor. The bias factor might be a country, request origin,
    customer segment, or any form of subscription plan associated with the requestor
    or request. Note that *z *axis scaling has many benefits, such as improved isolation
    and caching for requests; however, it also suffers from the following drawbacks:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*z* 轴的缩放是基于一个分割，这个分割基于事务的客户或请求者。虽然 *z* 轴分割可能或可能不会解决指令、过程或代码的单一性质，但它们经常解决执行这些指令、过程或代码所需数据的单一性质。自然地，在
    *z* 轴缩放中，有一个专门负责应用偏差因素的组件。偏差因素可能是一个国家、请求来源、客户细分或与请求者或请求相关的任何形式的订阅计划。请注意，*z* 轴缩放有许多好处，例如提高了请求的隔离和缓存；然而，它也遭受以下缺点：'
- en: It has increased application complexity.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它增加了应用复杂性。
- en: It needs a partitioning scheme, which can be tricky especially if we ever need
    to repartition data.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它需要一个分区方案，这在需要重新分区数据时尤其棘手。
- en: It doesn't solve the problems of increasing development and application complexity.
    To solve these problems, we need to apply *y *axis scaling.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它没有解决日益增长的开发和应用复杂性问题。为了解决这些问题，我们需要应用 *y* 轴缩放。
- en: Due to the preceding nature of *z *axis scaling, it is not suitable for use
    in the case of microservices.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *z* 轴缩放的前置性质，它不适合在微服务中使用。
- en: Scaling of y axis
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*y* 轴的缩放'
- en: The *y *axis scaling is based on a functional decomposition of an application
    into different components. The *y *axis of Scale Cube represents the separation
    of responsibility by the role or type of data, or work performed by a certain
    component in a transaction. To split the responsibility, we need to split the
    components of the system as per their actions or roles performed. These roles
    might be based on large portions of a transaction or a very small one. Based on
    the size of the roles, we can scale these components. This splitting scheme is
    referred to as *service or resource-oriented splits*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* 轴的缩放是基于将应用程序分解为不同组件的功能分解。Scale Cube 的 *y* 轴表示通过角色或数据类型、或某个组件在事务中执行的工作来分离责任。为了分割责任，我们需要根据系统组件执行的动作或角色来分割系统组件。这些角色可能基于事务的大块或非常小的一部分。根据角色的规模，我们可以对这些组件进行缩放。这种分割方案被称为
    *服务或资源导向分割*。'
- en: This very much resembles what we see in microservices. We split the entire application
    based on its roles or actions, and we scale individual microservice as per its
    role in the system. This resemblance is not accidental; it is the product of the
    design. So we can fairly say that *y *axis scaling is quite suitable for microservices.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常类似于我们在微服务中看到的情况。我们根据其角色或动作来分割整个应用程序，并根据其在系统中的角色来缩放单个微服务。这种相似性并非偶然；它是设计的结果。因此，我们可以相当肯定地说，*y*
    轴缩放非常适合微服务。
- en: Understanding *y *axis scaling is very significant for scaling a microservice
    architecture-based system. So, effectively, we are saying that microservices can
    be scaled by splitting them as per their roles and actions. Consider an order
    management system that is designed to, say, meet certain initial customer demand;
    for this, splitting the application into services such as customer service, order
    service, and payment service will work fine. However, if demand increases, you
    would need to review the existing system closely. You might discover the sub-components
    of an already existing service, which can very well be separated again since they
    are performing a very specific role in that service and the application as a whole.
    This revisit to design with respect to increased demand/load may trigger the re-splitting
    of the order service into a quote service, order processing service, order fulfillment
    service, and so on. Now, a quote service might need more computing power, so we
    might push more instances (identical copies behind it) when compared to other
    services.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 理解*Y*轴的扩展对于基于微服务架构的系统的扩展非常重要。因此，实际上我们是在说，可以通过根据它们的角色和动作来分割微服务来实现扩展。考虑一个旨在满足一定初始客户需求的订单管理系统；为此，将应用程序拆分为客户服务、订单服务和支付服务等服务将工作得很好。然而，如果需求增加，您可能需要仔细审查现有系统。您可能会发现已经存在的服务的子组件，由于它们在服务以及整个应用程序中扮演着非常特定的角色，因此可以再次分离。这种针对增加的需求/负载而对设计进行回顾可能会触发将订单服务重新拆分为报价服务、订单处理服务、订单履行服务等。现在，报价服务可能需要更多的计算能力，因此与其他服务相比，我们可能会推送更多的实例（其后的相同副本）。
- en: This is a near real-world example of how we should scale microservices on the
    AFK Scale Cube's three-dimensional model. You can observe this kind of three-dimensional
    scalability and *y *axis scaling of services in some well-known microservice architectures
    that belong to the industry, such as Amazon, Netflix, and Spotify.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在AFK规模立方体的三维模型上对微服务进行扩展的近乎真实世界的例子。您可以在一些属于行业的知名微服务架构中观察到这种三维可扩展性和*Y*轴扩展的服务，例如亚马逊、Netflix和Spotify。
- en: Characteristics of a scalable microservice
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可扩展微服务的特性
- en: 'In the Scale Cube section, we largely focused on scaling the characteristics
    of an entire system or application. In this section, we will focus on scaling
    the characteristics of an individual microservice. A microservice is said to be
    scalable and performant when it exhibits the following major characteristics:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在“规模立方体”部分，我们主要关注整个系统或应用程序特性的扩展。在本节中，我们将关注单个微服务特性的扩展。一个微服务被认为具有可扩展性和高性能，当它展现出以下主要特性时：
- en: 'Known growth curve: For example, in the case of an order management system,
    we need to know how many orders are supported by the current services and how
    they are proportionate to the order fulfillment service metric (measured in *requests
    per seconds*). The currently measured metrics are called **baseline figures**.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已知的增长曲线：例如，在订单管理系统的情况下，我们需要知道当前服务支持多少订单，以及它们与订单履行服务指标（以每秒请求数衡量）的比例。目前测量的指标被称为**基线数据**。
- en: 'Well-studied usage metrics: The traffic pattern generally reveals customer
    demand, and based on customer demand, many parameters mentioned in the previous
    sections regarding microservices can be calculated. Hence, microservices are instrumented,
    and monitoring tools are the necessary companions of microservices.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究良好的使用指标：流量模式通常揭示客户需求，基于客户需求，可以计算前几节中提到的关于微服务的许多参数。因此，微服务被装备了，监控工具是微服务的必要伴侣。
- en: 'Effective use of infrastructure resources: Based on qualitative and quantitative
    parameters, the anticipation of resource utilization can be done. This will help
    the team predict the cost of infrastructure and plan for it.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有效利用基础设施资源：基于定性和定量参数，可以预测资源利用率。这将帮助团队预测基础设施成本并为其制定计划。
- en: 'Ability to measure, monitor, and increase the capacity using an automated infrastructure:
    Based on the operational and growth pattern of the resource consumption of microservices,
    it is very easy to plan for future capacity. Nowadays, with cloud elasticity,
    it is even more important to be able to plan and automate capacity. Essentially,
    cloud-based architecture is cost-driven architecture.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够使用自动化基础设施进行测量、监控和增加容量：基于微服务资源消耗的操作和增长模式，很容易为未来的容量进行规划。如今，随着云弹性，能够规划和自动化容量变得更加重要。本质上，基于云的架构是成本驱动型架构。
- en: Known bottlenecks: Resource requirements include the specific resources (compute,
    memory, storage, and I/O) that each microservice needs. Identifying these are
    essential for a smoother operational and scalable service. If we identify resource
    bottlenecks, they can be worked on and eliminated.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已知的瓶颈：资源需求包括每个微服务需要的特定资源（计算、内存、存储和I/O）。确定这些对于更顺畅的操作和可扩展的服务是至关重要的。如果我们确定了资源瓶颈，它们可以被处理并消除。
- en: Has dependency scaling in the same ratio: This is self-explanatory. However,
    you cannot just focus on a microservice, leaving its dependencies as bottlenecks.
    A microservice is as scalable as its least scaling dependency.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有相同比例的依赖性扩展：这一点不言而喻。然而，你不能只关注一个微服务，而将其依赖项作为瓶颈。一个微服务的可扩展性与其最少的扩展依赖性一样。
- en: Fault tolerant and highly available: Failure is inevitable in distributed systems.
    If you encounter a microservice instance failure, it should be automatically rerouted
    to a healthy instance of the microservice. Just putting load balancers in front
    of microservice clusters won't be sufficient in this case. Service discovery tools
    are quite helpful for satisfying this characteristic of scalable microservices.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有容错性和高可用性：在分布式系统中，故障是不可避免的。如果你遇到一个微服务实例故障，它应该自动重定向到一个健康的微服务实例。仅仅在微服务集群前放置负载均衡器在这种情况下是不够的。服务发现工具对于满足可扩展微服务的这一特性非常有帮助。
- en: 'Has a scalable data persistence mechanism: Individual data store choices and
    design should be scalable and fault-tolerant for scalable microservices. Caching
    and separating out read and write storage will help in this case.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有可扩展的数据持久机制：对于可扩展的微服务，单个数据存储的选择和设计应该是可扩展和容错的。在这种情况下，缓存和分离读取和写入存储将有所帮助。
- en: 'Now, while we are discussing microservices and scalability, the natural arrangement
    of scaling comes into the picture, which is nothing but the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们讨论微服务和可扩展性时，自然出现的扩展顺序是以下内容：
- en: 'Scaling the infrastructure: Microservices operate well over dynamic and software-defined
    infrastructure. So, scaling the infrastructure is an essential component of scaling
    microservices.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施的扩展性：微服务在动态和软件定义的基础设施上运行良好。因此，扩展基础设施是扩展微服务的一个基本组成部分。
- en: 'Scaling around service design: Microservice design comprises of an HTTP-based
    API as well as a data store in which the local state for the services is stored.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围绕服务设计进行扩展：微服务设计包括基于HTTP的API以及一个数据存储，其中存储了服务的本地状态。
- en: Scaling the infrastructure
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展基础设施
- en: 'In this section, we will visit all the layers of the microservice infrastructure
    and see them in relation to each other, that is, how each individual infrastructure
    layer can be scaled. In our microservice implementation, there are two major components.
    One is virtual machines and the other is the container hosted on the virtual or
    physical machine. The following diagram shows a logical view of the microservice
    infrastructure:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将访问微服务基础设施的所有层，并观察它们之间的关系，即每个单独的基础设施层如何进行扩展。在我们的微服务实现中，有两个主要组件。一个是虚拟机，另一个是托管在虚拟机或物理机上的容器。以下图表显示了微服务基础设施的逻辑视图：
- en: '![](img/55de4676-81c0-41bd-82d4-1c02be78f4f0.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/55de4676-81c0-41bd-82d4-1c02be78f4f0.png)'
- en: Scaling virtual machines using scale sets
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用规模集扩展虚拟机
- en: Scaling virtual machines is quite simple and easy in Azure Cloud. This is where
    microservices shine through. With scale sets, you can raise the instances of the
    same virtual machine images in a short amount of time, and automatically too,
    based on the ruleset. Scale sets are integrated with Azure Autoscale.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure云中扩展虚拟机非常简单和容易。这正是微服务大放异彩的地方。使用规模集，你可以在短时间内增加相同虚拟机镜像的实例，并且可以根据规则集自动进行。规模集与Azure自动扩展集成。
- en: Azure virtual machines can be created in such a way so that as a group, they
    always serve the requests even if the volume of the requests increases. In specific
    situations, they can also be deleted automatically if those virtual machines are
    not needed to perform the workload. This is taken care of by the virtual machine
    scale set.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 虚拟机可以以这种方式创建，使得作为一个组，它们即使在请求量增加的情况下也能始终提供服务。在特定情况下，如果这些虚拟机不需要执行工作负载，它们也可以自动删除。这是由虚拟机规模集来处理的。
- en: Scale sets also integrate well with load balancers in Azure. Since they are
    represented as compute resources, they can be used with Azure's Resource Manager.
    Scale sets can be configured so that virtual machines can be created or deleted
    on demand. This helps manage virtual machines with the mindset of `pets vs. cattle`, which
    we saw earlier in the chapter in terms of deployment.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '规模集也与Azure中的负载均衡器很好地集成。由于它们被视为计算资源，因此可以与Azure的资源管理器一起使用。规模集可以配置为按需创建或删除虚拟机。这有助于以“宠物与牛群”的心态管理虚拟机，这是我们之前在部署章节中看到的。 '
- en: For applications that need to scale compute resources in and out, scale operations
    are implicitly balanced across the fault and update domains.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要动态扩展和缩减计算资源的应用程序，扩展操作在故障域和更新域之间隐式平衡。
- en: With scale sets, you don't need to correlate loops of independent resources,
    such as NICs, storage accounts, and virtual machines. Even while scaling out,
    how are we going to take care of the availability of these virtual managers? All
    such concerns and challenges have already been addressed with virtual machine
    scale sets.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用规模集，您不需要关联独立资源（如NIC、存储帐户和虚拟机）的循环。即使在扩展时，我们如何确保这些虚拟管理器的可用性？所有这些关注和挑战都已经通过虚拟机规模集得到了解决。
- en: A scale set allows you to automatically grow and shrink an application based
    on demand. Let's say there's a threshold of 40% utilization. So, maybe once we
    reach 40% utilization, we'll begin to experience performance degradation. And
    at 40% utilization, new web servers get added. A scale set allows you to set a
    rule, as mentioned in the previous sections. An input to a scale set is a virtual
    machine. The rules on a scale set say that at 40% average CPU, for five minutes,
    Azure will add another virtual machine to the scale set. After doing this, calibrate
    the rule again. If the performance is still above 40%, add a third virtual machine
    until it reaches the acceptable threshold. Once the performance drops below 40%,
    it will start deleting these virtual machines based on traffic inactivity and
    so on to reduce the cost of operation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 规模集允许您根据需求自动扩展和缩减应用程序。假设有一个40%的利用率阈值。所以，也许一旦我们达到40%的利用率，我们就会开始体验到性能下降。在40%的利用率时，会添加新的Web服务器。规模集允许您设置规则，如前几节所述。规模集的输入是一个虚拟机。规模集上的规则表示，在40%的平均CPU使用率下，五分钟内，Azure将为规模集添加另一个虚拟机。完成此操作后，再次校准规则。如果性能仍然高于40%，则添加第三个虚拟机，直到达到可接受的阈值。一旦性能低于40%，它将开始根据流量不活跃等因素删除这些虚拟机，以降低运营成本。
- en: So by implementing a scale set, you can construct a rule for the performance
    and make your application bigger to handle the greater load by simply automatically
    adding and removing virtual machines. You, as the administrator, will be left
    with nothing to do once these rules are established.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过实施规模集，您可以构建性能规则，并通过简单地自动添加和删除虚拟机来使应用程序变大以处理更大的负载。一旦这些规则建立，作为管理员，您将无事可做。
- en: Azure Autoscale measures performance and determines when to scale up and down.
    It is also integrated with the load balancer and NAT. Now, the reason they're
    integrated with the load balancer and with NAT is because as we add these additional
    virtual machines, we're going to have a load balancer and a NAT device in front.
    As requests keep coming in, in addition to deploying the virtual machine, we've
    got to add a rule that allows traffic to be redirected to the new instances. The
    great thing about scale sets is that they not only add virtual machines but also
    work with all the other components of the infrastructure, including things such
    as network load balancers.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 自动扩展会衡量性能并确定何时进行扩展和缩减。它还与负载均衡器和NAT集成。现在，它们与负载均衡器和NAT集成的理由是因为随着我们添加这些额外的虚拟机，我们将在前面有一个负载均衡器和NAT设备。随着请求的不断涌入，除了部署虚拟机外，我们还需要添加一条规则，允许流量被重定向到新实例。规模集的好处在于，它们不仅添加虚拟机，还与基础设施的所有其他组件协同工作，包括网络负载均衡器等。
- en: In the Azure Portal, a scale set can be viewed as a single entry, even though
    it has multiple virtual machines included in it. To look at the configuration
    and specification details of virtual machines in a scale set, you will have to
    use the Azure Resource Explorer tool. It's a web-based tool available at [https://resources.azure.com](https://resources.azure.com).
    Here you can view all the objects in your subscription. You can view scale sets
    in the Microsoft.Compute section.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure Portal 中，规模集可以被视为单个条目，尽管它包含多个虚拟机。要查看规模集中虚拟机的配置和详细规格，你必须使用 Azure Resource
    Explorer 工具。这是一个基于网络的工具，可在 [https://resources.azure.com](https://resources.azure.com)
    上找到。在这里，你可以查看你订阅中的所有对象。你可以在 Microsoft.Compute 部分中查看规模集。
- en: Building a scale set is very easy using the Azure templates repository. Once
    you create your own **Azure Resource Manager** (**ARM**) template, you can also
    create custom templates based on scale sets. Due to scope and space constraints,
    we have omitted a detailed discussion and instructions on how to build a scale
    set. You can follow these instructions by utilizing the ARM templates given at
    [https://github.com/gbowerman/azure-myriad](https://github.com/gbowerman/azure-myriad).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Azure 模板存储库构建规模集非常简单。一旦你创建了自定义的 **Azure 资源管理器** (**ARM**) 模板，你还可以根据规模集创建自定义模板。由于范围和空间限制，我们省略了关于如何构建规模集的详细讨论和说明。你可以通过利用在
    [https://github.com/gbowerman/azure-myriad](https://github.com/gbowerman/azure-myriad)
    提供的 ARM 模板来遵循这些说明。
- en: An availability set is an older technology, and this feature has limited support.
    Microsoft recommends that you migrate to virtual machine scale sets for faster
    and more reliable autoscale support.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性集是一项较旧的技术，并且此功能支持有限。Microsoft 建议你迁移到虚拟机规模集以获得更快和更可靠的自动扩展支持。
- en: Auto Scaling
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动扩展
- en: With the help of monitoring solutions, we can measure the performance parameters
    of an infrastructure. This is usually in the form of performance SLAs. Auto Scaling
    gives us the ability to increase or decrease the resources available to the system,
    based on performance thresholds.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过监控解决方案，我们可以衡量基础设施的性能参数。这通常以性能 SLA 的形式出现。自动扩展使我们能够根据性能阈值增加或减少系统可用的资源。
- en: The Auto Scaling feature adds additional resources to cater to increased load.
    It works in reverse, as well. If the load is reduced, then Auto Scaling reduces
    the number of resources available to perform the task. Auto Scaling does it all
    without pre-provisioning the resources, and does this in an automated way.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展功能添加额外的资源以应对增加的负载。它也可以反向工作。如果负载减少，那么自动扩展会减少可用于执行任务的资源数量。自动扩展无需预先配置资源，并以自动化的方式进行。
- en: Auto Scaling can scale in both ways—vertically (adding more resources to the
    existing resource type) or horizontally (adding resources by creating another
    instance of that type of resource).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展可以以两种方式扩展——垂直（向现有资源类型添加更多资源）或水平（通过创建该类型资源的另一个实例来添加资源）。
- en: The Auto Scaling feature makes a decision regarding adding or removing resources
    based on two strategies. One is based on the available metrics of the resource
    or on meeting some system threshold value. The other type of strategy is based
    on time, for example, between 9 a.m. and 5 p.m. IST, instead of three web servers;
    the system needs 30 web servers.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展功能基于两种策略来决定添加或移除资源。一种是基于资源的可用指标或达到某些系统阈值值。另一种策略是基于时间，例如，在印度标准时间上午9点到下午5点之间，系统需要30个Web服务器，而不是三个。
- en: Azure monitoring instruments every resource; all the metric-related data is
    collected and monitored. Based on the data collected, Auto Scaling makes decisions.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 监控每个资源；所有与指标相关的数据都被收集和监控。基于收集的数据，自动扩展做出决策。
- en: Azure Monitor autoscale applies only to virtual machine scale sets, cloud services,
    and app services (for example, web apps).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Monitor 自动扩展仅适用于虚拟机规模集、云服务和应用程序服务（例如，Web 应用程序）。
- en: Container scaling using Docker Swarm
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Docker Swarm 进行容器扩展
- en: Earlier, in the chapter on deployment, we looked at how to package a microservice
    into a Docker container. We also discussed in detail why containerization is useful
    in the microservice world. In this section, we will advance our skills with Docker
    and also see how easily we can scale our microservices with Docker Swarm.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部署章节中，我们探讨了如何将微服务打包到 Docker 容器中。我们还详细讨论了为什么容器化在微服务世界中是有用的。在本节中，我们将通过 Docker
    提升我们的技能，并了解我们如何轻松地使用 Docker Swarm 扩展我们的微服务。
- en: Inherently, microservices are distributed systems and need to be distributed
    and isolated resources. Docker Swarm provides container orchestration clustering
    capabilities so that multiple Docker engines can work as single virtual engines.
    This is similar to load balancer capabilities; besides, it also creates new instances
    of containers or deletes containers, if the need arises.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，微服务是分布式系统，需要分布式和隔离的资源。Docker Swarm提供了容器编排集群功能，使得多个Docker引擎可以作为一个单一的虚拟引擎工作。这类似于负载均衡器的功能；此外，如果需要，它还可以创建容器的新实例或删除容器。
- en: You can use any of the available service discovery mechanisms, such as DNS,
    consul, or zookeeper tools, with Docker Swarm.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用任何可用的服务发现机制，如DNS、consul或zookeeper工具，与Docker Swarm一起使用。
- en: A swarm is a cluster of Docker engines or nodes where you can deploy your microservices
    as *services*. Now, do not confuse these services with microservices. Services
    are a different concept in Docker implementation. A **service** is the definition
    of the tasks to execute on the worker nodes. You may want to understand the node
    we are referring to in the last sentence. The node, in Docker Swarm context, is
    used for the Docker engine participating in a cluster. A complete swarm demo is
    possible, and ASP.NET Core images are available in the ASP.NET-Docker project
    on GitHub ([https://github.com/aspnet/aspnet-docker](https://github.com/aspnet/aspnet-docker)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一群（swarm）是由Docker引擎或节点组成的集群，你可以在其中部署你的微服务作为*服务*。现在，请不要将这些服务与微服务混淆。在Docker实现中，服务是一个不同的概念。一个**服务**是定义在工作节点上要执行的任务。你可能想了解我们上一句话中提到的节点。在Docker
    Swarm的上下文中，节点用于参与集群的Docker引擎。一个完整的swarm演示是可能的，并且ASP.NET Core镜像可以在GitHub上的ASP.NET-Docker项目中找到（[https://github.com/aspnet/aspnet-docker](https://github.com/aspnet/aspnet-docker)）。
- en: The Azure Container Service has recently been made available. It is a good solution
    for scaling and orchestrating Linux or Windows containers using DC/OS, Docker
    Swarm, or Google Kubernetes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Azure容器服务最近已经可用。它是一个使用DC/OS、Docker Swarm或Google Kubernetes扩展和编排Linux或Windows容器的良好解决方案。
- en: Now that we have understood how to scale a microservice infrastructure, let's
    revisit the scalability aspects of microservice design in the following sections.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何扩展微服务基础设施，接下来让我们在以下章节中回顾微服务设计的可扩展性方面。
- en: Scaling service design
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务设计扩展
- en: In these sections, we will look at the components/concerns that need to be taken
    care of while designing or implementing a microservice. With infrastructure scaling
    taking care of service design, we can truly unleash the power of the microservice's
    architecture and get a lot of business value in terms of making a microservice
    a true success story. So, what are the components in service design? Let's have
    a look.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些章节中，我们将探讨在设计或实现微服务时需要关注的组件/问题。随着基础设施扩展负责服务设计，我们才能真正释放微服务架构的潜力，并在将微服务打造成真正的成功故事方面获得大量的商业价值。那么，服务设计中有哪些组件？让我们来看看。
- en: Data persistence model design
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据持久化模型设计
- en: In traditional applications, we have always relied on relational databases to
    persist user data. Relational databases are not new to us. They emerged in the
    70s as a way of storing persistent information in a structured way that would
    allow you to make queries and perform data maintenance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统应用中，我们一直依赖关系型数据库来持久化用户数据。关系型数据库对我们来说并不陌生。它们在70年代出现，作为一种以结构化方式存储持久信息的方法，允许你进行查询和执行数据维护。
- en: In today's world of microservices, modern applications need to be scaled at
    the hyperscale stage. We are not recommending here that you abandon the use of
    relational databases in any sense. They still have their valid use cases. However,
    when we mix read and write operations in a single database, complications arise
    where we need to have increased scalability. Relational databases enforce relationships
    and ensure the consistency of data. Relational databases work on the well-known
    ACID model. So, in relational databases, we use the same data model for both read
    and write operations.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今的微服务世界中，现代应用程序需要在超大规模阶段进行扩展。我们在这里并不建议你完全放弃使用关系型数据库。它们仍然有其有效的用例。然而，当我们在一个数据库中混合读写操作时，会出现复杂性，需要增加可扩展性。关系型数据库强制执行关系并确保数据的一致性。关系型数据库基于众所周知的ACID模型。因此，在关系型数据库中，我们使用相同的数据模型进行读写操作。
- en: However, the needs of read and write operations are quite different. In most
    cases, read operations usually have to be quicker than write operations. Read
    operations can also be done using different filter criteria, returning a single
    row or a result set. In most write operations, there is a single row or column
    involved, and usually, write operations take a bit longer when compared to read
    operations. So, we can either optimize and serve reads or optimize and serve writes
    in the same data model.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，读操作和写操作的需求相当不同。在大多数情况下，读操作通常需要比写操作更快。读操作还可以使用不同的过滤标准进行，返回单行或结果集。在大多数写操作中，只涉及单行或列，并且通常与读操作相比，写操作需要更长的时间。因此，我们可以在同一数据模型中优化并服务读操作，或者优化并服务写操作。
- en: 'How about we split the fundamental data model into two halves: one for all
    the read operations and the other for all the write operations? Now things become
    far simpler, and it is easy to optimize both the data models with different strategies.
    The impact of this on our microservices is that they, in turn, become highly scalable
    for both kinds of operations.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否可以将基本数据模型分为两半：一半用于所有读操作，另一半用于所有写操作？现在事情变得简单多了，并且可以很容易地使用不同的策略优化这两个数据模型。这对我们的微服务的影响是，它们反过来，对这两种操作都变得高度可扩展。
- en: This particular architecture is known as **Common Query Responsibility Segregation**
    (**CQRS**). As a natural consequence, CQRS also gets extended in terms of our
    programming model. Now, the database-object relationship between our programming
    models has become much simpler and more scalable.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这种特定的架构被称为**通用查询责任分离**（**CQRS**）。作为一个自然的结果，CQRS也在我们的编程模型方面得到了扩展。现在，我们的编程模型中的数据库-对象关系变得简单得多，并且更可扩展。
- en: 'With this comes the next fundamental element in scaling a microservice implementation:
    the caching of data.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这带来了扩展微服务实现的基本要素的下一个基本元素：数据的缓存。
- en: Caching mechanism
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存机制
- en: Caching is the simplest way to increase the application's throughput. The principle
    is very easy. Once the data is read from data storage, it is kept as close as
    possible to the processing server. In future requests, the data is served directly
    from the data storage or cache. The essence of caching is to minimize the amount
    of work that a server has to do. HTTP has a built-in cache mechanism embedded
    in the protocol itself. This is the reason it scales so well.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存是提高应用程序吞吐量的最简单方法。其原理非常简单。一旦数据从数据存储中读取，就尽可能地靠近处理服务器保存。在未来的请求中，数据直接从数据存储或缓存中提供。缓存的本质是尽量减少服务器需要完成的工作量。HTTP协议本身内置了缓存机制。这也是它能够如此高效扩展的原因。
- en: With respect to microservices, we can cache at three levels, namely client side,
    proxy, and server side. Let's look at each of them.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 关于微服务，我们可以在三个级别上进行缓存，即客户端、代理和服务器端。让我们看看每一个。
- en: First, we have client-side caching. With client-side caching, clients store
    cached results. So the client is responsible for doing the cache invalidation.
    Usually, the server provides guidance, using mechanisms, such as cache control
    and expiry headers, about how long it can keep the data and when it can request
    fresh data. With browsers supporting HTML5 standards, there are more mechanisms
    available, such as local storage, an application cache, or a web SQL database,
    in which the client can store more data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们有客户端缓存。在客户端缓存中，客户端存储缓存的结果。因此，客户端负责执行缓存失效。通常，服务器通过使用诸如缓存控制和过期头等机制提供指导，关于数据可以保持多长时间以及何时可以请求新鲜数据。随着浏览器支持HTML5标准，有更多的机制可用，例如本地存储、应用程序缓存或Web
    SQL数据库，客户端可以在其中存储更多数据。
- en: Next, we move onto the proxy side. Many reverse proxy solutions, such as Squid,
    HAProxy, and NGINX, can act as cache servers as well.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们转向代理端。许多反向代理解决方案，如Squid、HAProxy和NGINX，也可以作为缓存服务器。
- en: 'Now let''s discuss server-side caching in detail. In server-side caching, we
    have the following two types:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细讨论服务器端缓存。在服务器端缓存中，我们有以下两种类型：
- en: 'Response caching: This is an important kind of caching mechanism for a web
    application UI, and honestly, it is simple and easy to implement as well. In response
    to caching, cache-related headers get added to the responses served from microservices.
    This can drastically improve the performance of your microservice. In ASP.NET Core,
    you can implement response caching using the `Microsoft.AspNetCore.ResponseCaching`
    package.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应缓存：这对于Web应用程序UI来说是一种重要的缓存机制，而且说实话，它简单易实现。对于缓存，相关头信息会被添加到微服务提供的响应中。这可以显著提高你的微服务性能。在ASP.NET
    Core中，你可以使用`Microsoft.AspNetCore.ResponseCaching`包实现响应缓存。
- en: 'Distributed caching for persisted data: A distributed cache enhances microservice
    throughput due to the fact that the cache will not require an I/O trip to any
    external resource. This has the following advantages:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式缓存用于持久化数据：由于缓存不需要对任何外部资源进行I/O操作，因此分布式缓存可以提高微服务的吞吐量。这具有以下优势：
- en: Microservice clients get the exact same results.
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务客户端将获得完全相同的结果。
- en: The distributed cache is backed up by a persistence store and runs as a different
    remote process. So even if the app server restarts or has any problems, it in
    no way affects the cache.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式缓存由持久化存储支持，并作为不同的远程进程运行。因此，即使应用服务器重启或出现任何问题，也不会影响缓存。
- en: The source's data store has fewer requests made to it.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源数据存储的请求次数更少。
- en: You can use distributed providers, such as CacheCow, Redis (for our book *Azure
    Redis Cache*), or Memcache, in a clustered mode for scaling your microservice
    implementation.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用分布式提供程序，如CacheCow、Redis（用于我们的书*Azure Redis Cache*）或Memcache，以集群模式扩展你的微服务实现。
- en: In the following section, we will provide an overview of CacheCow and Azure
    Redis Cache.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将概述CacheCow和Azure Redis Cache。
- en: CacheCow
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CacheCow
- en: CacheCow comes into the picture when you want to implement HTTP caching on both
    the client and server. This is a lightweight library, and currently, ASP.NET Web
    API support is available. CacheCow is open source and comes with an MIT license
    that is available on GitHub ([https://github.com/aliostad/CacheCow](https://github.com/aliostad/CacheCow))[.](https://github.com/aliostad/CacheCow)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想要在客户端和服务器上实现HTTP缓存时，CacheCow就派上用场了。这是一个轻量级的库，目前支持ASP.NET Web API。CacheCow是开源的，并附带MIT许可证，可在GitHub上找到([https://github.com/aliostad/CacheCow](https://github.com/aliostad/CacheCow))。
- en: 'To get started with CachCow, you need to get ready for both the server and
    client. The important steps are:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用CacheCow，你需要为服务器和客户端做好准备。重要步骤包括：
- en: Install the `Install-Package CacheCow.Server` NuGet package within your ASP.NET
    Web API project; this will be your server.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你的ASP.NET Web API项目中安装`Install-Package CacheCow.Server` NuGet包；这将是你服务器。
- en: Install the `Install-Package CacheCow.Client`  NuGet package within your client
    project; the client application will be WPF, Windows Form, Console, or any other
    web application.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你的客户端项目中安装`Install-Package CacheCow.Client` NuGet包；客户端应用程序将是WPF、Windows Form、控制台或任何其他Web应用程序。
- en: Create a cache store. You need to create a cache store at the server side that
    requires a database for storing cache metadata ([https://github.com/aliostad/CacheCow/wiki/Getting-started#cache-store](https://github.com/aliostad/CacheCow/wiki/Getting-started#cache-store)).
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个缓存存储。你需要在服务器端创建一个缓存存储，该存储需要一个数据库来存储缓存元数据([https://github.com/aliostad/CacheCow/wiki/Getting-started#cache-store](https://github.com/aliostad/CacheCow/wiki/Getting-started#cache-store))。
- en: If you want to use memcache, refer to [https://github.com/aliostad/CacheCow/wiki/Getting-started](https://github.com/aliostad/CacheCow/wiki/Getting-started) for
    more information.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用memcache，请参考[https://github.com/aliostad/CacheCow/wiki/Getting-started](https://github.com/aliostad/CacheCow/wiki/Getting-started)获取更多信息。
- en: Azure Redis Cache
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Redis Cache
- en: 'Azure Redis Cache is built on top of an open source called **Redis** ([https://github.com/antirez/redis](https://github.com/antirez/redis)),
    which is an in-memory database and persists on a disk. As per Microsoft ([https://azure.microsoft.com/en-in/services/cache/](https://azure.microsoft.com/en-in/services/cache/)):'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Redis Cache建立在开源项目**Redis**([https://github.com/antirez/redis](https://github.com/antirez/redis))之上，这是一个内存数据库，并持久化在磁盘上。根据微软([https://azure.microsoft.com/en-in/services/cache/](https://azure.microsoft.com/en-in/services/cache/))：
- en: '"Azure Redis Cache is based on the popular open source Redis cache. It gives
    you access to a secure, dedicated Redis cache, managed by Microsoft and accessible
    from any application within Azure."'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: “Azure Redis Cache基于流行的开源Redis缓存。它为你提供了一个安全、专用的Redis缓存，由微软管理，并且可以从Azure中的任何应用程序访问。”
- en: 'Getting started with Azure Redis Cache is very simple with the help of these
    steps:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些步骤的帮助下，使用Azure Redis Cache入门非常简单：
- en: Create a web API project—refer to our code example in [Chapter 2](047f5d0b-a008-48e2-9c7f-c57c16e671f9.xhtml),
    *Implementing Microservices*.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个Web API项目——请参阅我们[第2章](047f5d0b-a008-48e2-9c7f-c57c16e671f9.xhtml)中的代码示例，*实现微服务*。
- en: Implement Redis—for a referral point use [https://github.com/StackExchange/StackExchange.Redis](https://github.com/StackExchange/StackExchange.Redis)
    and install the `Install-Package StackExchange.Redis` NuGet package.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现Redis——作为一个参考点使用[https://github.com/StackExchange/StackExchange.Redis](https://github.com/StackExchange/StackExchange.Redis)并安装`Install-Package
    StackExchange.Redis` NuGet包。
- en: Update your config file for `CacheConnection` ([https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#configure-the-application-to-use-redis-cache](https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#configure-the-application-to-use-redis-cache)).
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新你的`CacheConnection`配置文件（[https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#configure-the-application-to-use-redis-cache](https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#configure-the-application-to-use-redis-cache)）。
- en: Then publish on Azure ([https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#publish-the-application-to-azure](https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#publish-the-application-to-azure)).
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后在Azure上发布（[https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#publish-the-application-to-azure](https://docs.microsoft.com/en-us/azure/redis-cache/cache-web-app-howto#publish-the-application-to-azure)）。
- en: 'You can also use this template to create Azure Redis Cache:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用此模板创建Azure Redis Cache：
- en: '[https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-redis-cache-sql-database](https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-redis-cache-sql-database)
    For complete details on Azure Redis Cache refer to this URL:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-redis-cache-sql-database](https://github.com/Azure/azure-quickstart-templates/tree/master/201-web-app-redis-cache-sql-database)
    关于Azure Redis Cache的完整详细信息，请参阅此URL：'
- en: '[https://docs.microsoft.com/en-us/azure/redis-cache/](https://docs.microsoft.com/en-us/azure/redis-cache/)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.microsoft.com/en-us/azure/redis-cache/](https://docs.microsoft.com/en-us/azure/redis-cache/)'
- en: Redundancy and fault tolerance
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 冗余和容错性
- en: We understand that a system's ability to deal with failure and recover from
    failure is not the same as that offered by scalability. However, we cannot deny
    that they are closely related abilities in terms of the system. Unless we address
    the concerns of availability and fault tolerance, it will be challenging to build
    highly scalable systems. In a general sense, we achieve availability by making
    redundant copies available to different parts/components of the system. So, in
    the upcoming section, we will touch upon two such concepts.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们理解，一个系统处理故障和从故障中恢复的能力并不等同于提供的可扩展性。然而，我们无法否认，它们在系统层面上是密切相关的能力。除非我们解决可用性和容错性的问题，否则构建高度可扩展的系统将具有挑战性。在一般意义上，我们通过向系统的不同部分/组件提供冗余副本来实现可用性。因此，在接下来的章节中，我们将涉及两个这样的概念。
- en: Circuit breakers
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 断路器
- en: A circuit breaker is a safety feature in an electronic device that, in the event
    of a short circuit, breaks the electricity flow and protects the device, or prevents
    any further damage to the surroundings. This exact idea can be applied to software
    design. When a dependent service is not available or not in a healthy state, a
    circuit breaker prevents calls from going to that dependent service and redirects
    the flow to an alternate path for a configured period of time.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器是电子设备中的一个安全特性，在发生短路的情况下，它会切断电流流动并保护设备，或者防止对周围环境造成进一步损害。这个确切的想法可以应用于软件设计。当一个依赖的服务不可用或不在健康状态时，断路器会阻止调用该依赖服务，并将流量重定向到配置时间段内的备用路径。
- en: 'In his famous book, *Release It! Design and Deploy Production-Ready Software*, Michael
    T. Nygard gives details about the circuit breaker. A typical circuit breaker pattern
    is shown in the following diagram:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在他的著名书籍《发布它！设计和部署生产就绪软件》中，Michael T. Nygard详细介绍了断路器。以下图中显示了典型的断路器模式：
- en: '![](img/83e7a3c1-1650-48ec-b0a7-93ba4e863052.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83e7a3c1-1650-48ec-b0a7-93ba4e863052.png)'
- en: As shown in the diagram, the circuit breaker acts as a state machine with three
    states.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，断路器作为一个具有三个状态的有限状态机。
- en: Closed state
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关闭状态
- en: This is the initial state of the circuit, which depicts a normal flow of control.
    In this state, there is a failure counter. If `OperationFailedException` occurs
    in this flow, the failure counter is increased by `1`. If the failure counter
    keeps increasing, meaning the circuit encounters more exception, and reaches the
    failure threshold set, the circuit breaker transitions to an *Open* state. But
    if the calls succeed without any exception or failure, the failure count is reset.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这是电路的初始状态，描述了正常的控制流程。在这个状态下，有一个失败计数器。如果在这个流程中发生 `OperationFailedException`，失败计数器增加
    `1`。如果失败计数器持续增加，意味着电路遇到更多的异常，达到设定的失败阈值，断路器将转换到开启状态。但如果调用成功且没有任何异常或失败，失败计数器将被重置。
- en: Open state
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开启状态
- en: In the *Open* state, a circuit has already tripped and a timeout counter has
    started. If a timeout is reached and a circuit still keeps on failing, the flow
    of code enters into the Half-Open state.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在开启状态，电路已经跳闸，并开始计时。如果达到超时并且电路仍然失败，代码流程将进入半开状态。
- en: Half-Open state
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 半开状态
- en: In the Half-Open state, the state machine/circuit breaker component resets the
    timeout counter and again tries to open the circuit, reinitiating the state change
    to the Open state. However, before doing so, it tries to perform regular operations, say
    a call to the dependency; if it succeeds, then instead of the Open state, the
    circuit breaker component changes the state to Closed. This is so that the normal
    flow of the operation can happen, and the circuit is closed again.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在半开状态，状态机/断路器组件重置超时计数器，并再次尝试打开电路，重新启动状态变化到开启状态。然而，在这样做之前，它试图执行常规操作，比如对依赖项的调用；如果成功，那么断路器组件不会改变状态到开启状态，而是将状态改为关闭。这样，操作的正常流程就可以发生，电路再次关闭。
- en: For .NET-based microservices, if you want to implement the circuit breaker and
    a couple of fault-tolerant patterns, there is a good library named *Polly* available
    in the form of a NuGet package. It comes with extensive documentation and code
    samples, and moreover, has a fluent interface. You can add *Polly* from [http://www.thepollyproject.org/](http://www.thepollyproject.org/)
    or by just issuing the `install--Package Polly` command from the package manager
    console in Visual Studio.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于.NET的微服务，如果您想实现断路器和一些容错模式，有一个名为 *Polly* 的优秀库，它以NuGet包的形式提供。它附带详细的文档和代码示例，并且还有一个流畅的接口。您可以从
    [http://www.thepollyproject.org/](http://www.thepollyproject.org/) 或通过在Visual
    Studio的包管理器控制台中执行 `install--Package Polly` 命令来添加 *Polly*。
- en: Service discovery
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务发现
- en: For a small implementation, how can you determine the address of a microservice?
    For any .NET developer, the answer is that we simply put the IP address and port
    of service in the configuration file and we are good. However, when you deal with
    hundreds or thousands of them dynamically, configured at runtime, you have a service
    location problem.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小型实现，您如何确定微服务的地址？对于任何.NET开发者来说，答案是我们在配置文件中简单地放置服务的IP地址和端口，我们就完成了。然而，当您处理数百或数千个动态配置的服务时，您就有了一个服务位置问题。
- en: 'Now if you peek a bit deeper, we are trying to solve two parts of the problem:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果我们再深入一点，我们正在尝试解决问题的两个部分：
- en: 'Service registration: This is the process of registration within the central
    registry of some kind, where all the service-level metadata, host lists, ports,
    and secrets are stored.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务注册：这是在某种集中式注册中注册的过程，其中存储了所有服务级别的元数据、主机列表、端口和密钥。
- en: 'Service discovery: Establishing communication at runtime with a dependency
    through a centralized registry component is service discovery.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务发现：通过集中式注册组件在运行时与依赖项建立通信是服务发现。
- en: 'Any service registration and discovery solution needs to have the following
    characteristics to make it considerable as a solution for the microservice services
    discovery problem:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 任何服务注册和发现解决方案都需要以下特性，才能使其成为微服务服务发现问题的解决方案：
- en: The centralized registry itself should be highly available
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集中式注册本身应该具有高可用性
- en: Once a specific microservice is up, it should receive the requests automatically
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦特定的微服务启动，它应该自动接收请求
- en: Intelligent and dynamic load balancing capabilities should exist in the solution
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决方案中应存在智能和动态的负载均衡能力
- en: The solution should be able to monitor the capability of the service health
    status and the load it is subjected to
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决方案应该能够监控服务的健康状态和它所承受的负载
- en: The service discovery mechanism should be capable of diverting the traffic to
    other nodes or services from unhealthy nodes, without any downtime or impact on
    its consumers
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务发现机制应该能够将流量从不良节点重定向到其他节点或服务，而无需停机或对其消费者产生影响。
- en: If there is a change in the service location or metadata, the service discovery
    solution should be able to apply the changes without impacting the existing traffic
    or service instances
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果服务位置或元数据发生变化，服务发现解决方案应该能够在不影响现有流量或服务实例的情况下应用这些更改。
- en: 'Some of the service discovery mechanisms are available within the open source
    community. They are as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 一些服务发现机制在开源社区中可用。如下所示：
- en: 'Zookeeper: Zookeeper ([http://zookeeper.apache.org/](http://zookeeper.apache.org/)) is
    a centralized service for maintaining configuration information and naming, providing
    distributed synchronization, and providing group services. It''s written in Java,
    is strongly consistent (CP), and uses the Zab ([http://www.stanford.edu/class/cs347/reading/zab.pdf](http://www.stanford.edu/class/cs347/reading/zab.pdf)) protocol
    to coordinate changes across the ensemble (cluster).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zookeeper：Zookeeper([http://zookeeper.apache.org/](http://zookeeper.apache.org/))是一个集中式服务，用于维护配置信息和命名，提供分布式同步，并提供组服务。它用Java编写，强一致性（CP），并使用Zab([http://www.stanford.edu/class/cs347/reading/zab.pdf](http://www.stanford.edu/class/cs347/reading/zab.pdf))协议在集群中协调更改。
- en: 'Consul: Consul makes it simple for services to register themselves and discover
    other services via a DNS or HTTP interface. It registers external services, such
    as SaaS providers, as well. It also acts as a centralized configuration store
    in the form of key values. It also has failure detection properties. It is based
    on the peer-to-peer gossip protocol.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Consul：Consul使得服务能够通过DNS或HTTP接口简单地注册自己并发现其他服务。它还注册外部服务，如SaaS提供商。它还充当一个以键值形式存在的集中式配置存储。它还具有故障检测属性。它基于对等八卦协议。
- en: 'Etcd: Etcd is a highly available key-value store for shared configuration and
    service discovery. It was inspired by Zookeeper and Doozer. It''s written in Go,
    uses Raft ([https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf)) for
    consensus, and has an HTTP-plus JSON-based API.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Etcd：Etcd是一个高度可用的键值存储，用于共享配置和服务发现。它受到Zookeeper和Doozer的启发。它用Go编写，使用Raft([https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf))进行共识，并具有基于HTTP-plus
    JSON的API。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Scalability is one of the critical advantages of pursuing the microservice architectural
    style. We looked at the characteristics of microservice scalability. We discussed
    the Scale Cube model of scalability and how microservices can scale on the *y *axis
    via functional decomposition of the system. Then we approached the scaling problem
    with the scaling infrastructure. In the infrastructure segment, we looked at the
    strong capability of Azure Cloud to scale, utilizing the Azure scale sets and
    container orchestration solutions, such as Docker Swarm, DC/OS, and Kubernetes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性是追求微服务架构风格的关键优势之一。我们探讨了微服务可扩展性的特点。我们讨论了可扩展性立方体模型以及微服务如何在*y*轴上通过系统的功能分解进行扩展。然后，我们通过扩展基础设施来处理扩展问题。在基础设施部分，我们研究了Azure
    Cloud强大的扩展能力，利用Azure扩展集和容器编排解决方案，如Docker Swarm、DC/OS和Kubernetes。
- en: In the later stages of the chapter, we focused on scaling with a service design
    and discussed how our data model should be designed. We also discussed certain
    considerations, such as having a split CQRS style model, while designing the data
    model for high scalability. We also briefly touched on caching, especially distributed
    caching, and how it improves the throughput of the system. In the last section,
    to make our microservices highly scalable, we discussed the circuit breaker pattern
    and service discovery mechanism, which are essential for the scalability of microservice
    architecture.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后期阶段，我们专注于通过服务设计进行扩展，并讨论了我们的数据模型应该如何设计。我们还讨论了某些考虑因素，例如在设计高可扩展性的数据模型时采用分割CQRS风格模型。我们还简要提到了缓存，特别是分布式缓存，以及它是如何提高系统吞吐量的。在最后一节中，为了使我们的微服务具有高度可扩展性，我们讨论了断路器模式和发现机制，这对于微服务架构的可扩展性至关重要。
- en: In the next chapter, we will look at the reactive nature of microservices and
    the characteristics of reactive microservices.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨微服务的反应性及其特点。
