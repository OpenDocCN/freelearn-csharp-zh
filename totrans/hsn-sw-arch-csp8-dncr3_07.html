<html><head></head><body>
        

                            
                    <h1 class="header-title">Applying a Microservice Architecture to Your Enterprise Application</h1>
                
            
            
                
<p class="mce-root">This chapter is dedicated to describing highly scalable architectures based on small modules called microservices. The microservices architecture allows for fine-grained scaling operations where every single module can be scaled as required without it affecting the remainder of the system. Moreover, they allow for better <strong>Continuous Integration/Continuous Deployment</strong> (<strong>CI/CD</strong>) by permitting every system subpart to evolve and be deployed independently of the others.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li class="mce-root">What are microservices?</li>
<li>When do microservices help?</li>
<li>How does .NET Core deal with microservices?</li>
<li>Which tools are needed to manage microservices?</li>
<li>Use case – logging a microservice</li>
</ul>
<p>By the end of this chapter, you will have learned how to implement a microservice in .NET Core based on this chapter's use case.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>In this chapter, you will require the following:</p>
<ul>
<li>Visual Studio 2017 or 2019 free Community Edition or better with all the database tools installed.</li>
<li>A free Azure account. The <em>Creating an Azure account</em> section in <a href="14b5c5da-4042-439e-9e5a-2e19ba4c4930.xhtml">Chapter 1</a>, <em>Understanding the Importance of Software Architecture</em>, explains how to create one.</li>
<li>A local emulator for Azure Service Fabric to debug your microservices in Visual Studio. It is free and can be downloaded from <a href="https://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&amp;appid=MicrosoftAzure-ServiceFabric-CoreSDK">https://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&amp;appid=MicrosoftAzure-ServiceFabric-CoreSDK</a>. To avoid installation issues, ensure your version of Windows is up to date. Moreover, the emulator uses PowerShell high-privilege-level commands that, by default, are blocked by PowerShell. To enable them, you need to execute the following command in the Visual Studio Package Manager Console or in any PowerShell console. Visual Studio or an external PowerShell console must be started as an <em>administrator</em> for the following command to be successful:</li>
</ul>
<pre style="color: black;padding-left: 60px"><strong>Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force -Scope CurrentUser</strong></pre>
<ul>
<li>Docker CE for Windows if you want to debug Docker containerized microservices in Visual Studio (<a href="https://store.docker.com/editions/community/docker-ce-desktop-windows?tab=description">https://store.docker.com/editions/community/docker-ce-desktop-windows?tab=description</a>).</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">What are microservices?</h1>
                
            
            
                
<p>Microservice architectures allow each module that makes up a solution to be scaled independently from the others to achieve the maximum throughput with minimal cost. In fact, scaling whole systems instead of their current bottlenecks inevitably results in a remarkable waste of resources, so a fine-grained control of subsystem scaling has a considerable impact on the system's overall cost.</p>
<p>However, microservices are more than scalable components – they are software building blocks that can be developed, maintained, and deployed independently of each other. Splitting development and maintenance among modules that can be independently developed, maintained, and deployed improves the overall system's CI/CD cycle (the <em>CI/CD</em> concept was explained in more detail in the <em>Organizing your work using Azure DevOps</em> section in <a href="bc26065f-b001-4123-9524-3bbfa87bfadd.xhtml">Chapter 3</a>, <em>Documenting Requirements with Azure DevOps</em>).</p>
<p class="mce-root"/>
<p>The CI/CD improvement is due to microservice <em>independence</em> because it enables the following:</p>
<ul>
<li>Scaling and distributing microservices on different types of hardware.</li>
<li>Since each microservice is deployed independently from the others, there can't be binary compatibility or database structure compatibility constraints. Therefore, there is no need to align the versions of the different microservices that compose the system. This means that each of them can evolve, as needed, without being constrained by the others.</li>
<li>Assigning their development to completely separate smaller teams, thus simplifying job organization and reducing all the inevitable coordination inefficiencies that arise when handling large teams.</li>
<li>Implementing each microservice with more adequate technologies and in a more adequate environment, since each microservice is an independent deployment unit. This means choosing tools that best fit your requirements and an environment that minimizes development efforts and/or maximizes performance.</li>
<li>Since each microservice can be implemented with different technologies, programming languages, tools, and operating systems, enterprises can use all available human resources by matching environments with developers' competences. For instance, underused Java developers can also be involved in .NET projects if they implement microservices in Java with the same required behavior.</li>
<li>Legacy subsystems can be embedded in independent microservices, thus enabling them to cooperate with newer subsystems. This way, companies may reduce the time to market of new system versions. Moreover, this way, legacy systems can evolve slowly toward more modern systems with an acceptable impact on costs and the organization.</li>
</ul>
<p>The next subsection explains how the concept of microservices was conceived. Then, we will continue this introductory section by exploring basic microservice design principles and analyzing why microservices are often designed as Docker containers.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Microservices and the evolution of the concept of modules</h1>
                
            
            
                
<p>For a better understanding of the advantages of microservices, as well as their design techniques, we must keep the two-folded nature of software modularity, and of software modules, in mind:</p>
<ul>
<li>Code modularity refers to a code organization that makes it easy for us to modify a chunk of code without it affecting the remainder of the application. It is usually enforced with object-oriented design, where <em>modules</em> can be identified with classes.</li>
<li>Deployment modularity depends on what your deployment units are and which properties they have. The simplest deployment units are executable files and libraries. Thus, for instance, <strong>dynamic link libraries</strong> (<strong>DLL</strong>) are, for sure, more modular than static libraries since they must not be linked with the main executable before being deployed.</li>
</ul>
<p>While the fundamental concepts of code modularity have reached stasis, the concept of deployment modularity is still evolving and microservices are currently state of the art along this evolution path.</p>
<p>As a short review of the main milestones on the path that led to microservices, we can say that, first, monolithic executables were broken into static libraries. Later on, dynamic link libraries replaced static libraries.</p>
<p>A great change took place when .NET (and other analogous frameworks, such as Java) improved the modularity of executables and libraries. In fact, with .NET, they can be deployed on different hardware and on different operating systems since they are deployed in an intermediary language that's compiled when the library is executed for the first time. Moreover, they overcome some versioning issues of previous DLLs since any executable brings with it a DLL with a version that differs from the version of the same DLL that is installed in the operating system.</p>
<p>However, .NET can't accept two referenced DLLs – let's say, A and B – using two different versions of a common dependency – let's say, C. For instance, suppose there is a newer version of A with a lot of new features we would like to use that, in turn, rely on a newer version of C that's not supported by B. In a similar situation, we should renounce the newer version of A because of the incompatibility of C with B. This difficulty has led to two important changes:</p>
<ul>
<li>The development world moved from DLLs and/or single files to package management systems such as NuGet and npm, which automatically check version compatibility with the help of <em>semantic versioning</em>.</li>
<li><strong>Service-Oriented Architecture</strong> (<strong>SOA</strong>). Deployment units started being implemented as XML and then as REST web services. This solves the version compatibility problem since each web service runs in a different process and can use the most adequate version of each library with no risk of causing incompatibilities with other web services. Moreover, the interface that's exposed by each web service is platform-agnostic, that is, web services can connect with applications using any framework and run on any operating system since web service protocols are based on universally accepted standards. SOAs and protocols will be discussed in more detail in <a href="3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml">Chapter 12</a>, <em>Applying Service-Oriented Architectures with .NET Core</em>.</li>
</ul>
<p>Microservices are an evolution of SOA and add more features and more constraints that improve scalability and the modularity of services to improve the overall CI/CD cycle. It's sometimes said that <em>microservices are SOA done well</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Microservice design principles</h1>
                
            
            
                
<p>To sums things up, the microservice architecture is an SOA that maximizes independence and fine-grained scaling. Now that we've clarified all the advantages of microservice independence and fine-grained scaling, as well as the very nature of independence, we are in a position to look at microservice design principles.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Let start with principles that arise from the independence constraint:</p>
<ul>
<li><strong>Independence of design choices</strong>: The design of each microservice must not depend on the design choices that were made in the implementation of other microservices. This principle enables the full independence of each microservice CI/CD cycle and leaves us with more technological choices on how to implement each microservice. This way, we can choose the best available technology to implement each microservice.<br/>
Another consequence of this principle is that different microservices can't connect to the same shared storage (database or filesystem) since sharing the same storage also means sharing all the design choices that determined the structure of the storage subsystem (database table design, database engine, and so on). Thus, either a microservice has its own data storage or it has no storage at all and communicates with other microservices that take care of handling storage.<br/>
Here, having dedicated data storage doesn't mean that the physical database is distributed within the process boundary of the microservice itself, but that the microservice has exclusive access to a database or set of database tables that are handled by an external database engine. In fact, for performance reasons, database engines must run on dedicated hardware and with OS and hardware features that are optimized for their storage functionalities. Usually, <em>independence of design choices</em> is interpreted in a lighter form by distinguishing between logical and physical microservices. More specifically, a logical microservice is implemented with several physical microservices that use the same data storage but that are load-balanced independently. That is, the logical microservice is designed as a logical unity and then split into more physical microservices to achieve better load balance.</li>
</ul>
<ul>
<li><strong>Independence from the deployment environment</strong>: Microservices are scaled out on different hardware nodes and different microservices can be hosted on the same node. Therefore, the less a microservice relies on the services offered by the operating system and on other installed software, the more available hardware nodes it can be deployed on. More node optimization can also be performed.<br/>
This is the reason why microservices are usually containerized and use Docker. Containers will be discussed in more detail in the <em>Containers and Docker</em> subsection of this chapter, but basically, containerization is a technique that allows each microservice to bring its dependencies with it so that it can run anywhere.</li>
<li><strong>Loose coupling</strong>: Each microservice must be loosely coupled with all the other microservices. This principle has a two-folded nature. On the one hand, this means that, according to object-oriented programming principles, the interface that's exposed by each microservice must not be too specific, but as general as possible. However, it also means that communications among microservices must be minimized in order to reduce communication costs since microservices don't share the same address space and run on different hardware nodes.</li>
<li><strong>No chained requests/responses</strong>: When a request reaches a microservice, it must not cause a recursive chain of nested requests/responses to other microservices since a similar chain would result in an unacceptable response time. Chained requests/responses can be avoided if the private data models of all the microservices synchronize with push notifications each time they change. In other words, as soon as the data that's handled by a microservice changes, those changes are sent to all the microservices that may need them to serve their requests. This way, each microservice has all the data it needs to serve all its incoming requests in its private data storage, with no need to ask other microservices for the data that it lacks.<br/>
In conclusion, every microservice must contain all the data it needs to serve incoming requests and ensure fast responses. To keep their data models up to date and ready for incoming requests, microservices must communicate their data changes as soon as they take place. These data changes should be communicated through asynchronous messages since synchronous nested messages cause unacceptable performance because they block all the threads involved in the call tree until a result is returned.</li>
</ul>
<p>It is worth pointing out that the first constraint we mentioned is substantially the Bounded Context principle of domain-driven design, which we will talk about in detail in <a href="2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml">Chapter 10</a>, <em>Understanding the Different Domains in Software Solutions</em>. In this chapter, we will see that, often, a full domain-driven design approach is useful for the <em>update</em> subsystem of each microservice.</p>
<p>It's not trivial that the opposite is also true, that is, that systems that have been developed according to the Bounded Context principle are better implemented with a microservice architecture. In fact, once a system has been decomposed into several completely independent and loosely coupled parts, it is very likely that these different parts need to be scaled independently because of different traffic and different resources requirements.</p>
<p>The preceding constraints are some best practices for building a reusable SOA. More details on these best practices will be given in <a href="3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml">Chapter 12</a>, <em>Applying Service-Oriented Architectures with .NET Core</em>, but nowadays, most SOA best practices are automatically enforced by tools and frameworks that are used to implement web services.</p>
<p>Fine-grained scaling requires that microservices are small enough to isolate well-defined functionalities, but this also requires a complex infrastructure that takes care of automatically instantiating microservices, allocating instances on nodes, and scaling them as needed. These kinds of structure will be discussed in the <em>Which tools are needed to manage Microservices?</em> section of this chapter.</p>
<p>Moreover, fine-grained scaling of distributed microservices that communicate through asynchronous communication requires each microservice to be resilient. In fact, communication that's directed to a specific microservice instance may fail due to a hardware fault or for the simple reason that the target instance was killed or moved to another node during a load balancing operation.</p>
<p>Temporary failures can be overcome with exponential retries. This is where we retry the same operation after each failure with a delay that increases exponentially until a maximum number of attempts is reached. For instance, first, we would retry after 10 milliseconds, and if this retried operation results in a failure, a new attempt is done after 20 milliseconds, then after 40 milliseconds, and so on.</p>
<p>On the other hand, long-term failures often cause an explosion of retry operations that may saturate all system resources in a way that is similar to a Denial Of Service Attack. Therefore, usually, exponential retries are used together with a <em>circuit break strategy</em>: after a given number of failures, a long-term failure is assumed and access to the resource is prevented for a given time by returning an immediate failure without attempting the communication operation.</p>
<p>It is also fundamental that the congestion of some subsystems, due to either failure or to a requests peak, does not propagate to other system parts, in order to prevent overall system congestion. <strong>Bulkhead isolation</strong> avoids congestion propagation in the following ways:</p>
<ul>
<li>Only a maximum number of similar simultaneous outbound requests are allowed, let's say, 10. This is similar to putting an upper bound on thread creation.</li>
<li>Requests exceeding the previous bound are queued.</li>
<li>If the maximum queue length is reached, any further requests result in exceptions being thrown to abort them.</li>
</ul>
<p>Retry policies may make it so that the same message is received and processed several times because the sender has received no confirmation that the message has been received or simply because it has timed-out the operation, while the receiver actually received the message. The only possible solution to this problem is designing all messages so that they're idempotent, that is, designing messages in such a way that processing the same message several times has the same effect as processing it once.</p>
<p>Updating a database table field to a value, for instance, is an idempotent operation since repeating it once or twice has exactly the same effect. However, incrementing a decimal field is not an idempotent operation. Microservice designers should make an effort to design the overall application with as many idempotent messages as possible. The remaining non-idempotent messages must be transformed into idempotent ones in the following ways, or with some other similar technique:</p>
<ul>
<li>Attach both a time and some identifier that uniquely identify each message.</li>
<li>Store all the messages that have been received in a dictionary that's been indexed by the unique identifier attached to the message mentioned in the previous point.</li>
<li>Reject old messages.</li>
<li>When a message that may be a duplicate is received, verify whether it's contained in the dictionary. If it is, then it has already been processed, so reject it.</li>
<li>Since old messages are rejected, they can be periodically removed from the dictionary to avoid it growing exponentially.</li>
</ul>
<p>We will use this technique in the example at the end of this chapter.</p>
<p>In the next subsection, we will talk about microservice containerization based on Docker.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Containers and Docker</h1>
                
            
            
                
<p>We've already discussed the advantages of having microservices that don't depend on the environment where they run: better hardware usage, the ability to mix legacy software with newer modules, the ability to mix several development stacks in order to use the best stack for each module implementation, and so on. Independence on the hosting environment can be easily achieved by deploying each microservice with all its dependencies on a private virtual machine.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>However, starting a virtual machine with its private copy of the operating system takes a lot of time, and microservices must be started and stopped quickly to reduce load balancing and fault recovery costs. In fact, new microservices may be started either to replace faulty ones or because they were moved from one hardware node to another to perform load balancing. Moreover, adding a whole copy of the operating system to each microservice instance would be an excessive overhead.</p>
<p>Luckily, microservices can rely on a lighter form of technology: containers. Containers are a kind of light virtual machine. They do not virtualize a full machine – they just virtualize the <strong>operating system</strong> (<strong>OS</strong>) filesystem level that sits on top of the OS kernel. They use the OS of the hosting machine (kernel, DLLs, and drivers) and rely on the OS's native features to isolate processes and resources to ensure an isolated environment for the images they run.</p>
<p>As a consequence, containers are tied to a specific operating system but they don't suffer the overhead of copying and starting a whole OS in each container instance.</p>
<p>On each host machine, containers are handled by a runtime that takes care of creating them from <em>images</em> and creating an isolated environment for each of them. The most famous container runtime is Docker, which is a <em>de facto</em> standard for containerization.</p>
<p>Images are files that specify what is put in each container and which container resources, such as communication ports, to expose outside the container. None of the images need to explicitly specify their full content, but they can reference other images. This way, images are built by adding new software and configuration information on top of existing images.</p>
<p>For instance, if you want to deploy a .NET Core application as a Docker image, it is enough to just add your software and files to your Docker image and then reference an already existing .NET Core Docker image.</p>
<p>To allow for easy image referencing, images are grouped into registries that may be either public or private. They are similar to NuGet or npm registries. Docker offers a public registry (<a href="https://github.com/Particular/Workshop/tree/master/demos/asp-net-core">https://hub.docker.com/_/registry</a>) where you can find most of the public images you may need to reference in your own images. However, each company can define private registries. For instance, Azure offers a private container registry service: <kbd>https://azure.microsoft.com/en-us/services/container-registry/</kbd>.</p>
<p>Before instantiating each container, the Docker runtime must solve all the recursive references. This cumbersome job is not performed each time a new container is created since the Docker runtime has a cache where it stores the fully assembled images that correspond to each input image and that it's already processed.</p>
<p class="mce-root">Since each application is usually composed of several modules to be run in different containers, Docker also allows <kbd>.yml</kbd> files, also known as composition files, that specify the following information:</p>
<ul>
<li>Which images to deploy.</li>
<li>How the internal resources that are exposed by each image must be mapped to the physical resources of the host machine. For instance, how communication ports that are exposed by Docker images must be mapped to the ports of the physical machine.</li>
</ul>
<p>We will analyze Docker images and <kbd>.yml</kbd> files in the <em>How does .NET Core deal with Microservices?</em> section of this chapter.</p>
<p>The Docker runtime handles images and containers on a single machine but, usually, containerized microservices are deployed and load-balanced on clusters that are composed of several machines. Clusters are handled by pieces of software called <strong>Orchestrators</strong>. Orchestrators will be discussed in the <em>Which tools are needed to manage microservices?</em> section of this chapter.</p>
<p class="mce-root">Now that we have understood what microservices are, what problems they can solve, and their basic design principles, we are ready to analyze when and how to use them in our system architecture. The next section analyzes when we should use them.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">When do microservices help?</h1>
                
            
            
                
<p>The answer to this question requires us to understand the roles microservices play in modern software architectures. We will look at this in the following subsections.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Layered architectures and microservices</h1>
                
            
            
                
<p>Enterprise systems are usually organized in logical independent layers. The first layer is the one that interacts with the user and is called the presentation layer, while the last layer takes care of storing/retrieving data and is called the data layer. Requests originate in the presentation layer and pass through all the layers until they reach the data layer, and then come back, traversing all the layers in reverse until they reach the presentation layer, which takes care of presenting the results to the user/client. Layers can't be <em>jumped</em>.</p>
<p>Each layer takes data from the previous layer, processes it, and passes it to the next layer. Then, it receives the results from its next layer and sends them back to its previous layer. Also, thrown exceptions can't jump layers – each layer must take care of intercepting all the exceptions and either <em>solving them</em> somehow or transforming them into other exceptions that are expressed in the language of its previous layer. The layer architecture ensures the complete independence of the functionalities of each layer from all the other layers of their functionalities.</p>
<p>For instance, we can change the database engine without affecting all the layers that are above the data layer. In the same way, we can completely change the user interface, that is, the presentation layer, without affecting the remainder of the system.</p>
<p>Moreover, each layer implements a different kind of system specification. The data layer takes care of what the system <em>must remember</em>, the presentation layer takes care of the system-user interaction protocol, and all the layers that are in the middle implement the domain rules, which specify how data must be processed (for instance, how an employed paycheck must be computed). Typically, the data and presentation layers are separated by just one domain rule layer, called the business or application layer.</p>
<p>Each layer <em>speaks</em> a different language: the data layer <em>speaks</em> the language of the chosen storage engine, the business layer speaks the language of domain experts, and the presentation layer speaks the language of users. So, when data and exceptions pass from one layer to another, they must be translated into the language of the destination layer.</p>
<p>A detailed example of how to build a layered architecture will be given in the <em>Use case - Logging Microservices</em> section in <a href="2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml">Chapter 10</a>, <em>Understanding the Different Domains in Software Solutions</em>, which is dedicated to domain-driven design.</p>
<p>That being said, how do microservices fit into a layered architecture? Are they adequate for the functionalities of all the layers or of just some layers? Can a single microservice span several layers?</p>
<p>The last question is the easiest to answer: yes! In fact, we've already stated that microservices should store the data they need within their logical boundaries. Therefore, there are microservices that span the business and data layers. Some others take care of encapsulating shared data and remain confined in the data layer. Thus, we may have business layer microservices, data layer microservices, and microservices that span both layers. So, what about the presentation layer?</p>
<p>The presentation layer can also fit into a microservice architecture if it is implemented on the server-side. Single-page applications and mobile applications run the presentation layer on the client machine, so they either connect directly to the business microservices layer or, more often, to an <em>API Gateway</em> that exposes the public interface and takes care of routing requests to the right microservices.</p>
<p>In a microservices architecture, when the presentation layer is a website, it can be implemented with a set of microservices. However, if it requires heavy web servers and/or heavy frameworks, containerizing them may not be convenient. This decision must also consider the loss of performance that happens when containerizing the web server and the possible need for hardware firewalls between the web server and the remainder of the system.</p>
<p>ASP.NET Core is a lightweight framework that runs on the light Kestrel web server, so it can be containerized efficiently and used in a microservice for intranet applications. However, public high-traffic websites require dedicated hardware/software components that prevent them from being deployed together with other microservices. In fact, while Kestrel is an acceptable solution for an intranet website, public websites need a more complete web server such as IIS. In this case, security requirements are more compelling and require specialized hardware/software components.</p>
<p>Monolithic websites can be easily broken into load-balanced smaller subsites without microservice-specific technologies, but a microservice architecture can bring all the advantages of microservices into the construction of a single HTML page. More specifically, different microservices may take care of different areas of each HTML page. Unfortunately, at the time of writing, such a similar scenario is not easy to implement with the available .NET and .NET Core technology.</p>
<p>A proof of concept that implements a website with ASP.NET Core-based microservices that cooperate in the construction of each HTML page can be found here: <a href="https://github.com/Particular/Workshop/tree/master/demos/asp-net-core">https://github.com/Particular/Workshop/tree/master/demos/asp-net-core</a>. The main limit of this approach is that microservices cooperate just to generate the data that's needed to generate the HTML page and not to generate the actual HTML page. Instead, this is handled by a monolithic gateway. In fact, at the time of writing, frameworks such as ASP.NET Core MVC don't provide any facilities for the distribution of HTML generation. We will return to this example in <a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml">Chapter 13</a>, <em>Presenting ASP.NET Core MVC</em>.</p>
<p>Now that we've clarified which parts of a system can benefit from the adoption of microservices, we are ready to state the rules when it comes to deciding how they're adopted.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">When is it worth considering microservice architectures?</h1>
                
            
            
                
<p>Microservices can improve the implementation of both the business and data layer, but their adoption has some costs:</p>
<ul>
<li>Allocating instances to nodes and scaling them has a cost in terms of cloud fees or internal infrastructures and licenses.</li>
<li>Splitting a unique process into smaller communicating processes increases communication costs and hardware needs, especially if the microservices are containerized.</li>
<li>Designing and testing software for a microservice requires more time and increases human resources costs. In particular, making microservices resilient and ensuring that they adequately handle all possible failures, as well as verify these features with integration tests, can increase the development time by more than one order of magnitude.</li>
</ul>
<p>So, when are microservices worth the cost of using them? Are there functionalities that must be implemented as microservices?</p>
<p>A rough answer to the first question is: yes, when the application is big enough in terms of traffic and/or software complexity. In fact, as an application grows in complexity and its traffic increases, it's recommended that we pay the costs connected to scaling it since this allows for more scaling optimization and better handling when it comes to the development team. The costs we pay for these would soon exceed the cost of microservice adoption.</p>
<p>Thus, if fine-grained scaling makes sense for our application, and if we are able to estimate the savings that fine-grained scaling and development give us, we can easily compute an overall application throughput limit that makes the adoption of microservices convenient.</p>
<p>Microservice costs can also be justified by the market value of our products/services increasing. Since the microservice architecture allows us to implement each microservice with a technology that has been optimized for its use, the quality that's added to our software may justify all or part of the microservice costs.</p>
<p>However, scaling and technology optimizations are not the only parameters to consider. Sometimes, we are forced to adopt a microservice architecture without being able to perform a detailed cost analysis.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>If the size of the team that takes care of the CI/CD of the overall system grows too much, the organization and coordination of this big team cause difficulties and inefficiencies. In this type of situation, it is desirable to move to an architecture that breaks the whole CI/CD cycle into independent parts that can be taken care of by smaller teams.</p>
<p>Moreover, since these development costs are only justified by a high volume of requests, we probably have high traffic being processed by independent modules that have been developed by different teams. Therefore, scaling optimizations and the need to reduce interaction between development teams makes the adoption of a microservice architecture very convenient.</p>
<p>From this, we may conclude that, if the system and the development team grows too much, it is necessary to split the development team into smaller teams, each working on an efficient Bounded Context subsystem. It is very likely that, in a similar situation, a microservices architecture is the only possible option.</p>
<p>Another situation that forces the adoption of a microservice architecture is the integration of newer subparts with legacy subsystems based on different technologies since containerized microservices are the only way to implement an efficient interaction between the legacy system and the new subparts in order to gradually replace the legacy subparts with newer ones. Similarly, if our team is composed of developers with experience in different development stacks, an architecture based on containerized microservices may become a <em>must</em>.</p>
<p>In the next section, we will analyze building blocks and tools that are available so that we can implement .NET Core-based microservices.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How does .NET Core deal with microservices?</h1>
                
            
            
                
<p>.NET Core was conceived as a multi-platform framework that was light and fast enough to implement efficient microservices. In particular, ASP.NET Core is the ideal tool for implementing REST APIs to communicate with a microservice, since it can run efficiently with light web servers such as Kestrel and is itself light and modular.</p>
<p>The whole .NET Core framework evolved with microservices as a strategic deployment platform in mind and has facilities and packages for building efficient and light HTTP communication to ensure service resiliency and to handle long-running tasks. The following subsections describe some of the different tools or solutions that we can use to implement a .NET Core-based microservice architecture.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">.NET Core communication facilities</h1>
                
            
            
                
<p>Microservices need two kinds of communication channel:</p>
<ul>
<li>A communication channel to receive external requests, either directly or through an API Gateway. HTTP is the usual protocol for external communication due to available web services standards and tools. .NET Core's main HTTP communication facility is ASP.NET Core since it's a lightweight HTTP framework, which makes it ideal for implementing Web APIs in small microservices. We will describe ASP.NET Core App in detail in <a href="3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml">Chapter 12</a>, <em>Applying Service-Oriented Architectures with .NET Core</em>, which is dedicated to HTTP services. .NET Core also offers an efficient and modular HTTP client solution that is able to pool and reuse heavy connection objects. Also, the <kbd>HttpClient</kbd> class will be described in more detail in <a href="3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml">Chapter 12</a>, <em>Applying Service-Oriented Architectures with .NET Core</em>.</li>
<li>A different type of communication channel to push updates to other microservices. In fact, we have already mentioned that intra-microservice communication cannot be triggered by an on-going request since a complex tree of blocking calls to other microservices would increase request latency to an unacceptable level. As a consequence, updates must not be requested immediately before they're used and should be pushed whenever state changes take place. Ideally, this kind of communication should be asynchronous to achieve acceptable performance. In fact, synchronous calls would block the sender while they are waiting for the result, thus increasing the idle time of each microservice. However, synchronous communication that just puts the request in a processing queue and then returns confirmation of the successful communication instead of the final result is acceptable if communication is fast enough (low communication latency and high bandwidth). A publisher/subscriber communication would be preferable since, in this case, the sender and receiver don't need to know each other, thus increasing the microservices' independence. In fact, all the receivers that are interested in a certain type of communication merely need to register to receive a specific <em>event</em>, while senders just need to publish those events. All the wiring is performed by a service that takes care of queuing events and dispatching them to all the subscribers. The publisher/subscriber pattern will be described in more detail in <a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml"/><a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml"/><a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml">Chapter 9</a>, <em>Design Patterns and .NET Core Implementation</em>, along with other useful patterns.</li>
</ul>
<p>While .NET Core doesn't directly offer tools that may help in asynchronous communication or client/server tools that implement a publisher/subscriber communication, Azure offers a similar service with <em>Azure Service Bus</em>. Azure Service Bus handles both queued asynchronous communication through Azure Service Bus <em>queues</em> and publisher/subscriber communication through Azure Service Bus <em>topics</em>.</p>
<p>Once you've configured an Azure Service Bus on the Azure portal, you can connect to it in order to send messages/events and to receive messages/events through a client contained in the <kbd>Microsoft.Azure.ServiceBus</kbd> NuGet package.</p>
<p>Azure Service Bus has two types of communication: queue-based and topic-based. In queue-based communication, each message that's placed in the queue by a sender is removed from the queue by the first receiver that pulls it from the queue. Topic-based communication, on the other hand, is an implementation of the publisher/subscriber pattern. Each topic has several subscriptions and a different copy of each message sent to a topic can be pulled from each topic subscription.</p>
<p>The design flow is as follows:</p>
<ol>
<li>Define an Azure Service Bus private namespace.</li>
<li>Get the root connection strings that were created by the Azure portal and/or define new connection strings with fewer privileges.</li>
<li>Define queues and/or topics where the sender will send their messages in binary format.</li>
<li>For each topic, define names for all the required subscriptions.</li>
<li>In the case of queue-based communication, the sender sends messages to a queue and the receivers pull messages from the same queue. Each message is delivered to one receiver. That is, once a receiver gains access to the queue, it reads and removes one or more messages.</li>
<li>In the case of topic-based communication, each sender sends messages to a topic, while each receiver pulls messages from the private subscription associated with that topic.</li>
</ol>
<p>There are also other commercial alternatives to Azure Service Bus, such as NServiceBus, MassTransit, Brighter, and ActiveMQ. There is also a free open source option: RabbitMQ . RabbitMQ can be installed locally, on a virtual machine, or in a Docker container. Then, you can connect with it through the client contained in the <kbd>RabbitMQ.Client</kbd> NuGet package.</p>
<p>The functionalities of RabbitMQ are similar to the ones offered by Azure Service Bus but you have to take care of all the implementation details, confirmations of performed operations, and so on, while Azure Service Bus takes care of all the low-level tasks and offers you a simpler interface. Azure Service Bus and RabbitMQ will be described alongside Publisher/Subscriber-based communication in <a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml">Chapter 9</a>, <em>Design Patterns and .NET Core Implementation</em>.</p>
<p>If microservices are published to Azure Service Fabric, which will be described in the next section, we can use a built-in reliable binary communication. Communication is resilient since communication primitives automatically use a retry policy. This communication is synchronous, but this is not a big limitation since microservices in Azure Service Fabric have built-in queues; thus, once the receiver has received a message, they can just put it in a queue and return it immediately, without blocking the sender.</p>
<p>The messages in the queue are then processed by a separate thread. The main limitation of this built-in communication is that it is not based on the publisher/subscriber pattern; the senders and receivers must know each other. When this is not acceptable, you should use Azure Service Bus. We will learn how to use Service Fabric's built-in communication in the <em>Use case - logging microservices</em> section of this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Resilient task execution</h1>
                
            
            
                
<p>Resilient communication and, in general, resilient task execution can be implemented easily with the help of a .NET Core library called Polly, which is maintained by the .NET Foundation. Polly is available through the Polly NuGet package.</p>
<p>In Polly, you define policies, and then execute tasks in the context of that policy, as follows:</p>
<pre>var myPolicy = Policy<br/>  .Handle&lt;HttpRequestException&gt;()<br/>  .Or&lt;OperationCanceledException&gt;()<br/>  .Retry(3);<br/>....<br/>....<br/>myPolicy.Execute(()=&gt;{<br/>    //your code here<br/>});</pre>
<p>The first part of each policy specifies the exceptions that must be handled. Then, you specify what to do when one of those exceptions is captured. In the preceding code, the <kbd>Execute</kbd> method is retried up to three times if a failure is reported either by an <kbd>HttpRequestException</kbd> exception or by an <kbd>OperationCanceledException</kbd> exception.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>The following is the implementation of an exponential retry policy:</p>
<pre>var erPolicy= Policy<br/>    ...<br/>    //Exceptions to handle here<br/>    .WaitAndRetry(6, <br/>        retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2,<br/>            retryAttempt)));</pre>
<p>The first argument of <kbd>WaitAndRetry</kbd> specifies that a maximum of six retries is performed in case of failure. The lambda function passed as second argument specifies how much time to wait before the next attempt. In the specific example, this time grows exponentially with the number of the attempt with a power of 2 (2 seconds for the first retry, 4 seconds for the second retry, and so on).</p>
<p>The following is a simple Circuit Breaker policy:</p>
<pre>var cbPolicy=Policy<br/>    .Handle&lt;SomeExceptionType&gt;()<br/>    .CircuitBreaker(6, TimeSpan.FromMinutes(1));</pre>
<p>After six failures, the task can't be executed for 1 minute since an exception is returned.</p>
<p>The following is the implementation of the Bulkhead Isolation policy (see the <em>Microservices design principles</em> section for more information):</p>
<pre>Policy<br/>  .Bulkhead(10, 15)</pre>
<p>A maximum of 10 parallel executions is allowed in the <kbd>Execute</kbd> method. Further tasks are inserted in an execution queue. This has a limit of 15 tasks. If the queue limit is exceeded, an exception is thrown.</p>
<p>For the Bulkhead policy to work properly and, in general, for every strategy to work properly, task executions must be triggered through the same policy instance; otherwise, Polly is unable to count how many executions of a specific task are active.</p>
<p>Policies can be combined with the <kbd>Wrap</kbd> method:</p>
<pre>var combinedPolicy = Policy
  .Wrap(erPolicy, cbPolicy);</pre>
<p>Polly offers several more options, such as generic methods for tasks that return a specific type, timeout policies, task result caching, the ability to define custom policies, and so on. The link to the official Polly documentation is in the <em>Further reading</em> section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using generic hosts</h1>
                
            
            
                
<p>Each microservice may need to run several independent threads, each performing a different operation on requests received. Such threads need several resources, such as database connections, communication channels, specialized modules that perform complex operations, and so on. Moreover, all processing threads must be adequately initialized when the microservice is started and gracefully stopped when the microservice is stopped as a consequence of either load balancing or errors.</p>
<p>All of these needs led the .NET Core team to conceive and implement <em>hosted services</em> and <em>hosts</em>. A host creates an adequate environment for running several tasks, known as <strong>hosted services</strong>, and provides them with resources, common settings, and graceful start/stop.</p>
<p>The concept of a web host was mainly conceived to implement the ASP.NET Core web framework, but, with effect from .NET Core 2.1, the host concept was extended to all .NET applications. All features related to the concept of "host" are contained in the <kbd>Microsoft.Extensions.Hosting</kbd> NuGet package.</p>
<p>First, you need to configure the host with a fluent interface, starting with a <kbd>HostBuilder</kbd> instance. The final step of this configuration is calling the <kbd>Build</kbd> method, which assembles the actual host with all the configuration information we provided:</p>
<pre>var myHost=new HostBuilder()<br/>    //Several chained calls<br/>    //defining Host configuration<br/>    .Build();</pre>
<p>Host configuration includes defining the common resources, defining the default folder for files, loading the configuration parameters from several sources (JSON files, environment variables, and any arguments that are passed to the application), and declaring all the hosted services.</p>
<p>Then, the host can be started, which causes all the hosted services to be started:</p>
<pre>host.Start();</pre>
<p>The program remains blocked on the preceding instruction until the host is shutdown. The host can be shutdown either by one of the hosted services or externally by calling <kbd>await host.StopAsync(timeout)</kbd>. Here, <kbd>timeout</kbd> is a time span defining the maximum time to wait for the hosted services to stop gracefully. After this time, all the hosted services are aborted if they haven't been terminated.</p>
<p>Often, the fact that a microservice is being shutdown is signaled by a <kbd>CancelationToken</kbd> being passed when the microservice is started by the orchestrator. This happens when microservices are hosted in Azure Service Fabric.</p>
<p>In this case, instead of using <kbd>host.Start()</kbd>, we can use the <kbd>RunAsync</kbd> method and pass it the <kbd>CancelationToken</kbd> that we received from the orchestrator:</p>
<pre>await host.RunAsync(cancelationToken)</pre>
<p>This way of shutting down is triggered as soon as the <kbd>cancelationToken</kbd> enters a canceled state. By default, the host has a 5-second timeout for shutting down; that is, it waits 5 seconds before exiting once a shutdown has been requested. This time can be changed within the <kbd>ConfigureServices</kbd> method, which is used to declare <em>hosted services</em> and other resources:</p>
<pre>var myHost = new HostBuilder()<br/>    .ConfigureServices((hostContext, services) =&gt;<br/>    {<br/>        services.Configure&lt;HostOptions&gt;(option =&gt;<br/>        {<br/>            option.ShutdownTimeout = System.TimeSpan.FromSeconds(10);<br/>        });<br/>        ....<br/>        ....<br/>        //further configuration<br/>    })<br/>    .Build();</pre>
<p>However, increasing the host timeout doesn't increase the orchestrator timeout, so if the host waits too long, the whole microservice is killed by the orchestrator.</p>
<p>Hosted services are implementations of the <kbd>IHostedService</kbd> interface, whose only methods are <kbd>StartAsync(CancellationToken)</kbd> and <kbd>StopAsync(CancellationToken</kbd>). Both methods are passed a <kbd>CancelationToken</kbd>. The <kbd>CancelationToken</kbd> in the <kbd>StartAsync</kbd> method signals that a shutdown was requested. The <kbd>StartAsync</kbd> method periodically checks this <kbd>CancelationToken</kbd> while performing all operations needed to start the host, and if it is signaled the host start process is aborted. On the other hand, the <kbd>CancelationToken</kbd> in the <kbd>StopAsync</kbd> method signals that the shutdown timeout expired.</p>
<p>Hosted services must be declared in the same <kbd>ConfigureServices</kbd> method that's used to define host options, as follows:</p>
<pre>services.AddHostedService&lt;MyHostedService&gt;();</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Most declarations inside <kbd>ConfigureServices</kbd> require the addition of the following namespace:</p>
<pre>using Microsoft.Extensions.DependencyInjection;</pre>
<p>Usually, the <kbd>IHostedService</kbd> interface isn't implemented directly but can be inherited from the <kbd>BackgroundService</kbd> abstract class, which exposes the easier-to-implement <kbd>ExecuteAsync(CancellationToken)</kbd> method, which is where we can place the whole logic of the service. A shutdown is signaled by passing <kbd>CancellationToken</kbd> as an argument, which is easier to handle. We will look at an implementation of <kbd>IHostedService</kbd> in the example at the end of this chapter.</p>
<p>To allow a hosted service to shutdown the host, we need to declare an <kbd>IApplicationLifetime</kbd> interface as its constructor parameter:</p>
<pre>public class MyHostedService: BackgroundService <br/>{<br/>    private applicationLifetime;<br/>    public MyHostedService(IApplicationLifetime applicationLifetime)<br/>    {<br/>        this.applicationLifetime=applicationLifetime;<br/>    }<br/>    protected Task ExecuteAsync(CancellationToken token) <br/>    {<br/>        ...<br/>        applicationLifetime.StopApplication();<br/>        ...<br/>    }<br/>}</pre>
<p>When the hosted service is created, it will be automatically passed an implementation of <kbd>IApplicationLifetime</kbd>, whose <kbd>StopApplication</kbd> method will trigger the host shutdown. This implementation is handled automatically, but we can declare custom resources whose instances will be automatically passed to all the host service constructors that declare them as parameters. There are several ways to define these resources:</p>
<pre>services.AddTransient&lt;MyResource&gt;();<br/>services.AddTransient&lt;IResourceInterface, MyResource&gt;();<br/>services.AddSingleton&lt;MyResource&gt;();<br/>services.AddSingleton&lt;IResourceInterface, MyResource&gt;();</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>When we use <kbd>AddTransient</kbd>, a different instance is created and passed to all the constructors that require an instance of that type. On the other hand, with <kbd>AddSingleton</kbd>, a unique instance is created and passed to all the constructors that require the declared type. The overload with two generic types allows you to pass an interface and a type that implements that interface. This way, a constructor requires the interface and is decoupled from the specific implementation of that interface.</p>
<p>If resource constructors contain parameters, they will be automatically instantiated with the types declared in <kbd>ConfigureServices</kbd> in a recursive fashion. This pattern of interaction with resources is called <strong>dependency injection</strong> (<strong>DI</strong>) and will be discussed in detail in <a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml">Chapter 9</a>, <em>Design Patterns and .NET Core Implementation</em>.</p>
<p><kbd>HostBuilder</kbd> also has a method we can use to define the default folder:</p>
<pre>.UseContentRoot("c:\\&lt;deault path&gt;")</pre>
<p>It also has methods that we can use to add logging targets:</p>
<pre>.ConfigureLogging((hostContext, configLogging) =&gt;<br/>    {<br/>        configLogging.AddConsole();<br/>        configLogging.AddDebug();<br/>    })</pre>
<p>The preceding example shows a console-based logging source, but we can also log into Azure targets with adequate providers. The <em>Further reading</em> section contains links to some Azure logging providers that can work with microservices that have been deployed in Azure Service Fabric. Once you've configured logging, you can enable your hosted services and log custom messages by adding an <kbd>ILoggerFactory</kbd> parameter in their constructors.</p>
<p>Finally, <kbd>HostBuilder</kbd> has methods we can use to read configuration parameters from various sources:</p>
<pre>.ConfigureHostConfiguration(configHost =&gt;<br/>    {<br/>        configHost.AddJsonFile("settings.json", optional: true);<br/>        configHost.AddEnvironmentVariables(prefix: "PREFIX_");<br/>        configHost.AddCommandLine(args);<br/>    })</pre>
<p>The way parameters can be used from inside the application will be explained in more detail in <a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml">Chapter 13</a>, <em>Presenting ASP.NET Core MVC</em>, which is dedicated to ASP.NET Core.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Visual Studio support for Docker</h1>
                
            
            
                
<p>Visual Studio offers support for creating, debugging, and deploying Docker images. Docker deployment requires us to install <em>Docker CE for Windows</em> on our development machine so that we can run Docker images. The download link can be found in the <em>Technical requirements</em> section at the beginning of this chapter. Before we start any development activity, we must ensure it is installed and running (you should see a Docker icon in the window notification bar when the Docker runtime is running).</p>
<p>Docker support will be described with a simple ASP.NET Core MVC project. Let's create one. To do so, follow these steps:</p>
<ol>
<li>Name the project <kbd>MvcDockerTest</kbd>.</li>
<li>For simplicity, disable authentication.</li>
<li>You are given the option to add Docker support when you create the project, but please don't check the Docker support checkbox. You can test how Docker support can be added to any project after it has been created.</li>
</ol>
<p>Once you have your ASP.NET Core MVC application scaffolded and running, right-click on its project icon in the Solution Explorer and select Container Orchestrator Support | Docker Compose. This will enable not only the creation of a Docker image but also the creation of a Docker Compose project, which helps you configure Docker Compose files so that they run and deploy several Docker images simultaneously. In fact, if you add another MVC project to the solution and enable container orchestrator support for it, the new Docker image will be added to the same Docker Compose file.</p>
<p>The advantage of enabling Docker Compose instead of just <kbd>docker</kbd> is that you can manually configure how the image is run on the development machine, as well as how Docker image ports are mapped to external ports by editing the Docker Compose files that are added to the solution.</p>
<p>If your Docker runtime has been installed properly and is running, you should be able to run the Docker image from Visual Studio.</p>
<p>Let's analyze the Docker file that was created by Visual Studio. It is a sequence of image creation steps. Each step enriches an existing image with something else with the help of the <kbd>From</kbd> instruction, which is a reference to an already existing image. The following is the first step:</p>
<pre>FROM microsoft/dotnet:x.x-aspnetcore-runtime AS base<br/>WORKDIR /app<br/>EXPOSE 80<br/>EXPOSE 443</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>The first step uses the <kbd>microsoft/dotnet:x.x-aspnetcore-runtime</kbd> ASP.NET Core runtime that was published by Microsoft in the Docker public repository (where <kbd>x.x</kbd> is the ASP.NET Core version that was selected in your project).</p>
<p>The <kbd>WORKDIR</kbd> command creates the directory that follows the current directory within the image that is going to be created. If the directory doesn't exist yet, it is created in the image. The two <kbd>EXPOSE</kbd> commands declare which ports of the image ports will be exposed outside the image and mapped to the actual hosting machine. Mapped ports are decided in the deployment stage either as command-line arguments of a Docker command or within a Docker Compose file. In our case, there are two ports: one for HTTP (80) and another for HTTPS (443).</p>
<p>This intermediate image is cached by Docker, which doesn't need to recompute it since it doesn't depend on the code we write on the selected version of the ASP.NET Core runtime.</p>
<p>The second step produces a different image that will not be used to deploy. Instead, it will be used to create application-specific files that will be deployed:</p>
<pre>FROM microsoft/dotnet:x.x-sdk AS build<br/>WORKDIR /src<br/>COPY MvcDockerTest/MvcDockerTest.csproj MvcDockerTest/<br/>RUN dotnet restore MvcDockerTest/MvcDockerTest.csproj<br/>COPY . .<br/>WORKDIR /src/MvcDockerTest<br/>RUN dotnet build MvcDockerTest.csproj -c Release -o /app<br/><br/>FROM build AS publish<br/>RUN dotnet publish MvcDockerTest.csproj -c Release -o /app</pre>
<p>This step starts from the ASP.NET SDK image, which contains parts we don't need to add for deployment; these are needed to process the project code. The new <kbd>src</kbd> directory is created in the <kbd>build</kbd> image and made the current image directory. Then, the project file is copied into <kbd>/src/MvcDockerTest</kbd>.</p>
<p>The <kbd>RUN</kbd> command executes an operating system command on the image. In this case, it calls the <kbd>dotnet</kbd> runtime, asking it to restore the NuGet packages that were referenced by the previously copied project file.</p>
<p>Then, the <kbd>COPY..</kbd> command copies the whole project file tree into the <kbd>src</kbd> image directory. Finally, the project directory is made the current directory and the <kbd>dotnet</kbd> runtime is asked to build the project in release mode and copy all the output files into the new <kbd>/app</kbd> directory. Finally, a new image called <strong>publish</strong> executes the <kbd>publish</kbd> command on the output files.</p>
<p>The final step starts from the image that we created in the first step, which contains the ASP.NET Core runtime, and adds all the files that were published in the previous step:</p>
<pre>FROM base AS final<br/>WORKDIR /app<br/>COPY --from=publish /app .<br/>ENTRYPOINT ["dotnet", "MvcDockerTest.dll"]</pre>
<p>The <kbd>ENTRYPOINT</kbd> command specifies the operating system command that's needed to execute the image. It accepts an array of strings. In our case, it accepts the <kbd>dotnet</kbd> command and its first command-line argument, that is, the DLL we need to execute.</p>
<p>If we right-click on our project and click Publish, we are presented with several options:</p>
<ul>
<li>Publish the image to an existing or new web app (automatically created by Visual Studio)</li>
<li>Publish to one of several Docker registries, including a private Azure Container Registry that, if it doesn't already exist, can be created from within Visual Studio</li>
<li>Publish to an Azure Virtual machine</li>
</ul>
<p>Docker Compose support allows you to run and publish a multi-container application and add further images, such as a containerized database that is available everywhere.</p>
<p>The following Docker Compose file adds two ASP.NET Core applications to the same Docker image:</p>
<pre>version: '3.4'<br/><br/>services:<br/>  mvcdockertest:<br/>    image: ${DOCKER_REGISTRY-}mvcdockertest<br/>    build:<br/>      context: .<br/>      dockerfile: MvcDockerTest/Dockerfile<br/><br/>  mvcdockertest1:<br/>    image: ${DOCKER_REGISTRY-}mvcdockertest1<br/>    build:<br/>      context: .<br/>      dockerfile: MvcDockerTest1/Dockerfile</pre>
<p>The preceding code references existing Docker files. Any environment-dependent information is placed in the <kbd>docker-compose.override.yml</kbd> file, which is merged with the <kbd>docker-compose.yml</kbd> file when the application is launched from Visual Studio:</p>
<pre>version: '3.4'<br/><br/>services:<br/>  mvcdockertest:<br/>    environment:<br/>      - ASPNETCORE_ENVIRONMENT=Development<br/>      - ASPNETCORE_URLS=https://+:443;http://+:80<br/>      - ASPNETCORE_HTTPS_PORT=44355<br/>    ports:<br/>      - "3150:80"<br/>      - "44355:443"<br/>    volumes:<br/>      - ${APPDATA}/Asp.NET/Https:/root/.aspnet/https:ro<br/>      - ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro<br/>  mvcdockertest1:<br/>    environment:<br/>      - ASPNETCORE_ENVIRONMENT=Development<br/>      - ASPNETCORE_URLS=https://+:443;http://+:80<br/>      - ASPNETCORE_HTTPS_PORT=44317<br/>    ports:<br/>      - "3172:80"<br/>      - "44317:443"<br/>    volumes:<br/>      - ${APPDATA}/Asp.NET/Https:/root/.aspnet/https:ro<br/>      - ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro</pre>
<p>For each image, the file defines some environment variables, which will be defined in the image when the application is launched, the port mappings, and some host files.</p>
<p>The files in the host are directly mapped into the images, so if the image isn't projected to a host containing those files, the image won't run properly. Each declaration contains the path in the host, how the path is mapped in the image, and the desired access rights. In our case, <kbd>volumes</kbd> are used to map the self-signed https certificate that's used by Visual Studio and the user secrets (encrypted settings) that are used by ASP.NET Core.</p>
<p>Now, suppose we want to add a containerized SQL Server instance. We would need something like the following instructions split between <kbd>docker-compose.yml</kbd> and <kbd>docker-compose.override.yml</kbd>:</p>
<pre>sql.data:<br/>  image: mssql-server-linux:latest<br/>environment:<br/>- SA_PASSWORD=Pass@word<br/>- ACCEPT_EULA=Y<br/>ports:<br/>- "5433:1433"</pre>
<p>Here, the preceding code specifies the properties of the SQL Server container, as well as the SQL server's configuration and installation parameters. More specifically, the preceding code contains the following information:</p>
<ul>
<li><kbd>sql.data</kbd> is the name that's given to the container.</li>
<li><kbd>image</kbd> specifies where to take the image from. In our case, the image is contained in a public Docker registry.</li>
<li><kbd>environment</kbd> specifies the environment variables that are needed by SQL Server, that is, the administrator password and the acceptance of a SQL Server license.</li>
<li>As usual, <kbd>ports</kbd> specifies the port mappings.</li>
</ul>
<p><kbd>docker-compose.override.yml</kbd> is used to run the images from within Visual Studio. If you need to specify parameters for either the production environment or the testing environment, you can add further <kbd>docker-compose-xxx.override.yml</kbd> files, such as <kbd>docker-compose-staging.override.yml</kbd> and <kbd>docker-compose-production.override.yml</kbd>, and then launch them manually in the target environment with something like the following code:</p>
<pre><strong>docker-compose -f docker-compose.yml -f docker-compose-staging.override.yml</strong></pre>
<p>Then, you can destroy all the containers with the following code:</p>
<pre><strong>docker-compose -f docker-compose.yml -f docker-compose.test.staging.yml down</strong></pre>
<p>While <kbd>docker-compose</kbd> has a limited capability when it comes to handling node clusters, it is mainly used in testing and development environments. For production environments, more sophisticated tools are needed, as we will see in the <em>Which tools are needed to manage microservices?</em> section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Azure and Visual Studio support for microservice orchestration</h1>
                
            
            
                
<p>Visual Studio has a specific project template for microservice applications, based on the Service Fabric platform, where you can define various microservices, configure them, and deploy them to Azure Service Fabric, which is a microservice orchestrator. Azure Service Fabric will be described in more detail in the next section.</p>
<p>In this section, we will describe the various types of microservice you can define within a Service Fabric Application. A complete code example will be provided in the last section of this chapter. If you want to debug microservices on your development machine, you need to install the Service Fabric emulator listed in this chapter's technical requirements.</p>
<p>Service Fabric Applications can be found by selecting <em>cloud in Visual Studio project type drop-down filter</em> . Once you've selected the project, you can choose from a variety of services:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/daf2b3ce-48b4-4c21-9e48-d2a24156449d.png" style="width:33.42em;height:17.33em;"/></p>
<p>All projects under .NET Core use a microservice model that is specific to Azure Service Fabric. The Guest executable adds a wrapper around an existing Windows application to turn it into a microservice that can run in Azure Service Fabric. The Container application enables the addition of any Docker image in the Service Fabric Application. All the other choices scaffold a template that allows you to code a microservice with a Service Fabric-specific pattern.</p>
<p>Once you select any of the choices in the preceding screenshot and you fill in all the request information, Visual Studio creates two projects: an application project that contains configuration information for the overall application and a project for the specific service you have chosen that contains both the service code and service-specific configuration. If you want to add more microservices to your application, right-click on the application project and select Add | New Service Fabric Service.</p>
<p>If you right-click on the solution and select Add | New project, a new Service Fabric application will be created instead of a new service being added to the already existing application.</p>
<p>If you select Guest Executable, you need to provide the following:</p>
<ul>
<li>A folder containing the main executable file, along with all the files it needs to work properly. You need this if you want to create a copy of this folder in your project or simply to link to the existing folder.</li>
<li>The main executable file.</li>
<li>Arguments to pass on the command line to that executable.</li>
<li>Which folder to use as a working folder on Azure. You want to use the folder containing the main executable (<kbd>CodeBase</kbd>), the folder where Azure Service Fabric will package the whole microservice (<kbd>CodePackage</kbd>), or a new subfolder named <kbd>Work</kbd>.</li>
</ul>
<p>If you select Container, you need to provide the following:</p>
<ul>
<li>The complete name of a Docker image in your private Azure Container Registry.</li>
<li>The username that will be used to connect to Azure Container Registry. The password will be specified manually in the same <kbd>RepositoryCredentials</kbd> XML element of the application configuration file that was automatically created for the username.</li>
<li>The port where you can access your service (Host Port) and the port inside the container the Host Port must be mapped to (Container Port). The Container Port must be the same port that was exposed in the Docker file and used to define the Docker image.</li>
</ul>
<p>Afterward, you may need to add further manual configuration to ensure that your Docker application works properly. The <em>Further reading</em> section contains links to the official documentation where you can find more details.</p>
<p class="mce-root"/>
<p>There are five types of .NET Core native Service Fabric services. The Actor service pattern is an opinionated pattern that was conceived several years ago by Carl Hewitt. We will not discuss it here, but the <em>Further reading</em> section contains some links that provide more information on this.</p>
<p>The remaining four patterns refer to the usage (or not) of ASP.NET Core as the main interaction protocol and to the fact that the service has or hasn't got an internal state. In fact, Service Fabric allows microservices to use distributed queues and dictionaries that are globally accessible to all instances of the microservice that declares them, independent of the hardware node where they are running (they are serialized and distributed to all available instances when they're needed).</p>
<p>Stateful and stateless templates differ mainly in terms of their configuration. All native services are classes that specify just two methods:</p>
<pre>protected override IEnumerable&lt;ServiceReplicaListener&gt; CreateServiceReplicaListeners()<br/><br/>protected override async Task RunAsync(CancellationToken cancellationToken)</pre>
<p>The <kbd>CreateServiceReplicaListeners</kbd> method specifies a list of listeners that are used by the microservice to receive messages and the code that handles those messages. Listeners may use any protocol, but they are required to specify an implementation of the relative socket.</p>
<p><kbd>RunAsync</kbd> contains the code for background threads that asynchronously run tasks that are triggered by received messages. Here, you can build a host that runs several hosted services.</p>
<p>ASP.NET Core templates follow the same pattern; however, they use a unique ASP.NET Core-based listener and no <kbd>RunAsync</kbd> implementation since background tasks can be launched from inside ASP.NET Core. However, you may add further listeners to the array of listeners returned by the <kbd>CreateServiceReplicaListeners</kbd> implementation created by Visual Studio, and also a custom <kbd>RunAsync</kbd> override.</p>
<p>More details on Service Fabric's native services pattern will be provided in the <em>Which tools are needed to manage microservices?</em> section, while a complete code example will be provided in the <em>Testing the application</em> section of this chapter, which is dedicated to this book's use case.</p>
<p>While this section presented the tools we can use to build the code for our microservices, the next section describes the tools we can use to define and manage the clusters where our microservices will be deployed.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Which tools are needed to manage microservices?</h1>
                
            
            
                
<p>Effectively handling microservices in your CI/CD cycles requires both a private Docker image registry and a state of-the-art microservice orchestrator that's capable of doing the following:</p>
<ul>
<li>Allocating and load-balancing microservices on available hardware nodes</li>
<li>Monitoring the health state of services and replacing faulty services if hardware/software failures occur</li>
<li>Logging and presenting analytics</li>
<li>Allowing the designer to dynamically change requirements such as hardware nodes allocated to a cluster, the number of service instances, and so on</li>
</ul>
<p>The following subsection describes the Azure facilities we can use to store Docker images and to orchestrate microservices.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Defining your private Docker registry in Azure</h1>
                
            
            
                
<p>Defining your private Docker registry in Azure is easy. Just type <kbd>Container registries</kbd> into the Azure search bar and select Container registries. On the page that appears, click on the Add button.</p>
<p>The following form will appear:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ebb61911-66fb-490c-ab9b-760c77695884.png" style="width:18.33em;height:27.00em;"/></p>
<p>The name you select is used to compose the overall registry URI: <kbd>&lt;name&gt;.azurecr.io</kbd>. As usual, you can specify the subscription, resource group, and location. The SKU dropdown lets you choose from various levels of offerings that differ in terms of performance, available memory, and a few other auxiliary features.</p>
<p>If you enable Admin user, an admin user will be created whose username is <kbd>&lt;name&gt;</kbd> and whose password is created automatically by the portal; otherwise, the user will log in with your Azure portal credentials. Once Admin user has been selected, their login information will be available under the resource <em>Access key</em> menu item.</p>
<p>Whenever you mention image names in Docker commands or in a Visual Studio publish form, you must prefix its name with the registry URI: <kbd>&lt;name&gt;.azurecr.io/&lt;my imagename&gt;</kbd>.</p>
<p>If images are created with Visual Studio, then they can be published by following the instructions that appear once you've published the project. Otherwise, you must use <kbd>docker</kbd> commands to push them into your registry.</p>
<p>Let's say you have the image in another registry. The first step pulls the image onto your local machine:</p>
<pre><strong>docker pull other.registry.io/samples/myimage</strong> </pre>
<p>If there are several versions of the preceding image, the latest will be pulled since no version was specified. The version of the image can be specified as follows:</p>
<pre><strong>docker pull other.registry.io/samples/myimage:version1.0</strong> </pre>
<p>Using the following command, you should see <kbd>myimage</kbd> within the list of local images:</p>
<pre><strong>docker images</strong></pre>
<p>Now, log in to Azure by typing in the following command and providing your credentials:</p>
<pre><strong>docker login myregistry.azurecr.io</strong></pre>
<p>Then, tag the image with the path you want to assign in the Azure registry:</p>
<pre><strong>docker tag myimage myregistry.azurecr.io/testpath/myimage</strong></pre>
<p>Both the name and destination tag may have versions (<kbd>:&lt;version name&gt;</kbd>).</p>
<p>Finally, push it:</p>
<pre><strong>docker push myregistry.azurecr.io/testpath/myimage</strong></pre>
<p>In this case, you can specify a version; otherwise, the latest version is pushed.</p>
<p>By doing this, you can remove the image from your local computer using the following command:</p>
<pre><strong>docker rmi myregistry.azurecr.io/testpath/myimage</strong></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Azure Service Fabric</h1>
                
            
            
                
<p>Azure Service Fabric is the main Microsoft orchestrator that can host Docker containers, native .NET applications, and a distributed computing model called <strong>reliable services</strong>. We've already explained how we can create and publish applications that contain these three types of service in the <em>Azure and Visual Studio support for microservice orchestration</em> subsection. In this section, we will explain how to create an Azure Service Fabric cluster in the Azure portal and provide some more details on <strong>reliable services</strong>. More practical details regarding <em>reliable services</em> will be provided in the example described in the <em>Use case - logging microservices</em> section.</p>
<p>You can enter the Service Fabric section of Azure by typing <kbd>Service Fabric</kbd> into the Azure search bar and selecting Service Fabric Cluster. A multi-step wizard will appear. The following subsections describe the available steps.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Step 1: Basic information</h1>
                
            
            
                
<p>The following screenshot shows the creation of Azure Service Fabric:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f3a6d357-a608-41a5-8a8d-64a8106434a6.png" style="width:20.25em;height:41.25em;"/></p>
<p class="mce-root">Here, you can choose the operating system, resource group, subscription, location, and username and password you want to use to connect the remote desktop to all the cluster nodes. You are required to choose a cluster name, which will be used to compose the cluster URI as <kbd>&lt;cluster name&gt;.&lt;location&gt;.cloudapp.azure.com</kbd>, where <kbd>location</kbd> is a name associated with the datacenter location you have chosen.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Step 2: Cluster configuration</h1>
                
            
            
                
<p>In the second step, you can configure the number of nodes and their features:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/06c97604-b097-4c3f-92eb-942c3e65149e.png" style="width:35.50em;height:30.83em;"/></p>
<p>You can specify up to three node types. Nodes of a different node type can be scaled independently, and node type 1, called the <strong>primary node</strong> type, is where Azure Service Fabric runtime services will be hosted. For each node type, you can specify the type of machine (durability tier), machine dimensions (CPU and RAM), and the initial number of nodes.</p>
<p>You can also specify all the ports that will be visible from outside the cluster (Custom endpoints).</p>
<p>The services that are hosted on the different nodes of a cluster can communicate through any port since they are part of the same local network. Therefore, <em>Custom endpoints</em> must declare the ports that need to accept traffic from outside the cluster. The port that's exposed in <em>Custom endpoints</em> is the cluster's public interface, which can be reached through the cluster URI, that is, <kbd>&lt;cluster name&gt;.&lt;location&gt;.cloudapp.azure.com</kbd>. Their traffic is automatically redirected to all the microservices that have had the same ports opened by the cluster load balancer.</p>
<p>To understand the <em>enable reverse proxy</em> option, we must explain how communications are sent to several instances of services whose physical addresses change during their lifetimes. From within the cluster, services are identified with a URI such as <kbd>fabric://&lt;application name&gt;/&lt;service name&gt;</kbd>. That is, this name allows us to access one of the several load-balanced instances of <kbd>&lt;service name&gt;</kbd>. However, these URIs can't be used directly by communication protocols. Instead, they are used to get the physical URI of the required resource, along with all its available ports and protocols from the Service Fabric naming service.</p>
<p>Later, we will learn how to perform this operation with <em>reliable services</em>. However, this model is not adequate for Dockerized services that weren't conceived to run specifically on Azure Service Fabric since they are not aware of Service Fabric-specific naming services and APIs.</p>
<p>Therefore, Service Fabric provides two more options that we can use to standardize URLs instead of interacting directly with its naming service:</p>
<ul>
<li><strong>DNS</strong>: Each service can specify its <kbd>hostname</kbd> (also known as its <strong>DNS name</strong>). The DNS service takes care of translating it into the actual service URL. For example, if a service specifies an <kbd>order.processing</kbd> DNS name and it has an HTTP endpoint on port <kbd>80</kbd> and a <kbd>/purchase</kbd> path, we can reach this endpoint with <kbd>http://order.processing:80/purchase</kbd>.</li>
<li><strong>Reverse proxy:</strong> Service Fabric's Reverse Proxy intercepts all the calls that have been directed to the cluster address and uses the name service to send them to the right application and service within that application. Addresses that are resolved by the reverse proxy service have the following structure: <kbd>&lt;cluster name&gt;.&lt;location&gt;.cloudapp.azure.com: &lt;port&gt;//&lt;app name&gt;/&lt;service name&gt;/&lt;endpoint path&gt;?PartitionKey=&lt;value&gt; &amp; PartitionKind=value</kbd>. Here, partition keys are used to optimize state, fully reliable services and will be explained at the end of this subsection. This means that stateless services lack the query string part of the previous address. Thus, a typical address that's solved by reverse proxy may be something similar to <kbd>myCluster.eastus.cloudapp.azure.com: 80//myapp/myservice/&lt;endpoint path&gt;?PartitionKey=A &amp; PartitionKind=Named</kbd>. If the preceding endpoint is called from a service hosted on the same cluster, we can specify <kbd>localhost</kbd> instead of the complete cluster name (that is, from the same cluster, not from the same node): <kbd>localhost: 80//myapp/myservice/&lt;endpoint path&gt;?PartitionKey=A &amp; PartitionKind=Named</kbd>.</li>
</ul>
<p>By default, the DNS service is activated but the reverse proxy isn't. Therefore, we must enable it by checking the <em>Enable reverse proxy</em> checkbox in the second step of Service Fabric's configuration.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Step 3: Security configuration</h1>
                
            
            
                
<p>Once we've submitted the second step, we come to a security page:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f0decbde-2744-4755-86b1-dce6c85fa72b.png" style="width:33.75em;height:18.25em;"/></p>
<p>If we choose the basic option, the wizard creates an X509 certificate to secure our communication with the cluster. Otherwise, we can select an existing one from the Azure Key Vault. If you don't have a Key Vault, the wizard will make you create one so that you can store the newly created certificate. In the certificate options, locate the certificate usage option and select publishing/deploying. If you don't, you will receive an error message, along with some instructions telling you what to do to fix the issue.</p>
<p>Once the certificate is ready, download it onto your machine (by following the wizard's instructions) and double-click on it to install it in your local machine. The certificate will be used to deploy applications from your machine. Specifically, you are required to insert the following information into the Cloud Publish Profile of your Visual Studio Service Fabric applications (see this chapter's <em>Use case – logging microservices</em> section for more details):</p>
<pre>&lt;ClusterConnectionParameters <br/>    ConnectionEndpoint="&lt;cluster name&gt;.&lt;location <br/>    code&gt;.cloudapp.azure.com:19000"<br/>    X509Credential="true"<br/>    ServerCertThumbprint="&lt;server certificate thumbprint&gt;"<br/>    FindType="FindByThumbprint"<br/>    FindValue="&lt;client certificate thumbprint&gt;"<br/>    StoreLocation="CurrentUser"<br/>    StoreName="My" /&gt;</pre>
<p>Since both the client (Visual Studio) and the server use the same certificate for authentication, the server and client thumbprint are the same. The certificate thumbprint can be copied from your Azure Key Vault. It is worth mentioning that you can add also client-specific certificates with the main server certificate by selecting the Custom option in <em>step 3</em>.</p>
<p>Once you submit your certificate, you are presented with a summary of your configuration. Submitting your approval will create the cluster. Pay attention to this: a cluster may spend your Azure free credit in a short time, so just keep your cluster on when you're testing. After, you should delete it.</p>
<p>As we mentioned in the <em>Azure and Visual Studio support for microservices orchestration</em> subsection, Azure Service Fabric supports two kinds of <em>reliable service</em>: stateless and stateful. Stateless services either don't store permanent data or they store it in external supports such as the Redis Cache or databases (see <a href="77cdecb5-cef4-4b02-80a1-052ad366b9f3.xhtml">Chapter 7</a>, <em>How to Choose Your Data Storage in the Cloud</em>, for the main storage options offered by Azure).</p>
<p>Stateful services, on the other hand, use Service Fabric-specific distributed dictionaries and queues. Each distributed data structure is accessible from all the <em>identical</em> replicas of a service, but only one replica, called the primary replica, is allowed to write on them to avoid synchronized access to those distributed resources, which may cause bottlenecks. All the other replicas, known as secondary replicas, can only be read from these distributed data structures.</p>
<p>You can check if a replica is primary by looking at the context object your code receives from the Azure Service Fabric runtime, but usually, you don't need to do this. In fact, when you declare your service endpoints, you are required to declare those that are read-only. A read-only endpoint is supposed to receive requests so that it can read data from the shared data structures. Therefore, since only read-only endpoints are activated for secondary replicas, if you implement them correctly, write/update operations should be automatically prevented on stateful secondary replicas with no need to perform further checks.</p>
<p>In stateful services, secondary replicas enable parallelism on read operations, so in order to get parallelism on write/update operations, stateful services are assigned different data partitions. More specifically, for each stateful service, Service Fabric creates a primary instance for each partition. Then, each partition may have several secondary replicas.</p>
<p>Distributed data structures are shared between the primary instance of each partition and its secondary replicas. The whole extent of data that can be stored in a stateful service is split among the chosen number of partitions, according to a partition key that is generated by a hashing algorithm on the data to be stored.</p>
<p>Typically, partition keys are integers that belong to a given interval that is split among all the available partitions. For instance, a partition key can be generated by calling the .NET <kbd>GetHashCode()</kbd> method on one or more string fields to get integers that are then processed to get a unique integer (using, for instance, an exclusive or operation on the integer bits). Then, this integer can be constrained to the integer interval that was chosen for the partition key by taking the remainder of an integer division (for instance, the remainder of a division for 1,000 will be an integer in the 0-999 interval).</p>
<p>Let's say we want four partitions, which will be selected with an integer key in the 0-999 interval. Here, Service Fabric will automatically create four primary instances of our stateful service and assign them the following four partition key subintervals: 0-249, 250-499, 500-749, 750-999.</p>
<p>From within your code, you are required to compute the partition key of the data you send to a stateful service. Then, Service Fabric's runtime will select the right primary instance for you. The <em>Use case – logging microservices</em> section at the end of this chapter provides more practical details on this and how to use reliable services in practice.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Azure Kubernetes Service (AKS)</h1>
                
            
            
                
<p>Kubernetes is an advanced open source orchestrator that you can install locally on your private machine's cluster. At the time of writing, it is the most widespread orchestrator, so Microsoft offers it as an alternative to Azure Service Fabric. Also, if you prefer Azure Service Fabric, you may be forced to use the <strong>Azure Kubernetes Service</strong> (<strong>AKS</strong>) since some advanced solutions (for instance, some big data solutions) are built on top of Kubernetes. This subsection provides a short introduction to AKS, but more details can by found in the official documentation, which is referenced in the <em>Further reading</em> section.</p>
<p>To create an AKS cluster, type <kbd>AKS</kbd> into Azure search, select Kubernetes services, and then click the Add button. The following form will appear:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/230c287a-5924-48e3-842a-167e84e49f0c.png"/></p>
<p>As usual, you are required to specify a subscription, resource group, and location. Then, you can choose a unique name (Kubernetes cluster name), the prefix of the cluster URI (DNS name prefix), and the version of Kubernetes you would like to use. For computational power, you are asked to select a machine template for each node (Node size) and the number of nodes. If you click Next, you can provide security information, namely a <em>service principal</em>, and specify whether you wish to enable role-based access control. In Azure, service principals are accounts that are associated with services you may use to define resource access policies. If you have no experience with this concept and/or if you don't have any preexisting service principals, you can let the wizard create one for you.</p>
<p>There are other settings you can change too, but the default values work well.</p>
<p>Once you've created the Kubernetes cluster, you can interact with it through the <kbd>kubectl</kbd> command-line tool. <kbd>kubectl</kbd> is integrated into the Azure console, so you need just to activate your cluster credentials. Select the Azure console at the top of the page portal and then type in the following command:</p>
<pre><strong>az aks get-credentials --resource-group &lt;resource group&gt; --name &lt;cluster name&gt;</strong></pre>
<p>The preceding command downloads the credentials that were automatically created to enable your interaction with the cluster and configures the Kubernetes CLI so that it can use them.</p>
<p>Then, if you write <kbd>kubectl get nodes</kbd>, you should get a list of available Kubernetes nodes.</p>
<p>Docker images can be loaded into the cluster and configured by writing a <kbd>.yaml</kbd> configuration file, such as <kbd>myClusterConfiguration.yaml</kbd>, and typing the following:</p>
<pre><strong>kubectl apply -f myClusterConfiguration.yaml</strong></pre>
<p>You can create and edit this file by writing <kbd>nano</kbd> on the Azure console to launch the nano editor. Once you're in the editor, you can paste content from a local file and then save it.</p>
<p>The preceding command deploys the application and runs it. The deployment state can be monitored with the following command:</p>
<pre><strong>kubectl get service MyDeployment --watch</strong></pre>
<p>Here, <kbd>MyDeployment</kbd> is the name that's given to deployment in the <kbd>.yaml</kbd> file.</p>
<p>When the cluster is no longer needed, you can delete it with the following command:</p>
<pre><strong>az aks delete --resource-group &lt;resource group&gt; --name &lt;cluster name&gt; --no-wait</strong></pre>
<p>The application state can be monitored by selecting Insights from the resource Azure menu. Here, you can apply filters and select the information you need.</p>
<p><kbd>.yaml</kbd> files have the same structure as JSON files but they have a different syntax. You have objects and lists but object properties are not surrounded by <kbd>{}</kbd> and lists are not surrounded by <kbd>[]</kbd>. Instead, nested objects are declared by simply indenting their content with spaces. The number of spaces can be freely chosen, but once they've been chosen, they must be used coherently.</p>
<p>List items can be distinguished from object properties by preceding them with a hyphen (<kbd>-</kbd>). <kbd>.yaml</kbd> files can contain several sections that are separated by a line containing the <kbd>---</kbd> string. Typically, you define a <kbd>Deployment</kbd> that describes which images to deploy and how many replicas they must have. Each deployment groups a set of images to be deployed together on the same node, which means that each replica that's deployed in any node must have all those images installed. A set of images to be deployed together is called a <strong>pod</strong>.</p>
<p>For instance, the following configuration deploys two replicas of a single image pod:</p>
<pre>apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: MyDeployment<br/>spec:<br/>  replicas: 2<br/>  selector:<br/>    matchLabels:<br/>      app: MyApplication<br/>  template:<br/>    ...<br/>    ...</pre>
<p>The initial header declares the Kubernetes API version to use and the kind of object we are going to define (a deployment), and assigns a name to the object. The deployment name can be used at a later time to modify the cluster with deployment edit commands.</p>
<pre>template:<br/>    metadata:<br/>      labels:<br/>        app: MyApplication<br/>    spec:<br/>      containers:<br/>      - name: MyContainerName<br/>        image: myregistry.azurecr.io/testpath/myimage<br/>        resources:<br/>          requests:<br/>            cpu: 100m<br/>            memory: 128Mi<br/>          limits:<br/>            cpu: 250m<br/>            memory: 256Mi<br/>        ports:<br/>        - containerPort: 80<br/>        - name: http<br/>        env:<br/>        - name: MyEnvironmetVariable<br/>          value: "MyEnvironmetVariable"</pre>
<p>On the other hand, the <kbd>spec</kbd> attribute under the template lists all the containers that will compose each replica of the pod.</p>
<p class="mce-root">In turn, each container has a name and specifies the Docker image to be used to instantiate it. Then, it specifies the average computational resources that are needed and their maximum limits. Finally, it specifies the ports that are exposed externally. These ports are not forwarded to a different port and are exposed as they are. This port setting overrides the EXPOSE Docker file setting.</p>
<p>Finally, we can specify some environment variables to set inside each container.</p>
<p>Since there are several replicas of the same services located on different nodes, and since allocating services to nodes may change dynamically, there is a problem when it comes to internal communication among pods and internal-to-external communication. This problem is solved by defining services that offer a unique entry point for all instances of a pod. A service definition can be added to the same <kbd>.yaml</kbd> file, separated by <kbd>---</kbd>:</p>
<pre>---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: MyApplication-service<br/>spec:<br/>  ports:<br/>  - port: 8080<br/>    targetPort: 80<br/>    protocol: TCP<br/>    name: http<br/>  selector:<br/>    app: MyApplication</pre>
<p class="mce-root"/>
<p>The preceding definition creates a service that's exposed on port <kbd>8080</kbd>, which redirects all requests to port <kbd>80</kbd> of a <kbd>MyApplication</kbd> replica. The pod that's served by the service is selected by the <kbd>selector</kbd> property. The service IP is internally visible, but client pods don't need to know the service IP since the services can be reached through their names, just like hosts in a classic network. Thus, in this case, <kbd>MyApplication-service:8080</kbd> does the job.</p>
<p>If we need a publicly accessible IP, we need to add <kbd>type: LoadBalancer</kbd> under <kbd>spec</kbd> before <kbd>ports</kbd>. AKS will select a public IP for you. We can get the chosen public IP by watching the deployment process with <kbd>kubectl get service MyDeployment --watch</kbd> until the IP is selected. If we bought an IP address in the same resource group as AKS, we can specify this IP address by adding <kbd>clusterIP: &lt;your IP&gt;</kbd> under the service <kbd>spec</kbd>.</p>
<p>Pods can be organized into namespaces if we create namespaces in our <kbd>.yaml</kbd> files:</p>
<pre>apiVersion: v1<br/>kind: Namespace  <br/>metadata:   <br/>    name: my-namespace   <br/>    labels:     <br/>        name: my-namespace</pre>
<p>Then, you can target objects (services or deployments) in a namespace by adding <kbd>namespace: &lt;your namespace&gt;</kbd> after its name in its definition metadata. Similarly, you can target <kbd>kubectl</kbd> commands in a specific namespace by adding them with the <kbd>-- namespace=&lt;your namespace&gt;</kbd> option.</p>
<p>The use case in the next section will provide more details when it comes to defining a Service Fabric application. More details on Kubernetes clusters can be found in the references listed in the <em>Further reading</em> section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Use case – logging microservices</h1>
                
            
            
                
<p>In this section, we will take a look at a microservice-based system that logs data about purchases relating to various destinations in our WWTravelClub use case. In particular, we will design microservices that takes care of computing daily revenues per location. Here, we're assuming that these microservices receive data from other subsystems hosted in the same Azure Service Fabric application. More specifically, each purchase log message is composed of the location name, the overall package cost, and the date and time of the purchase.</p>
<p>As a first step, let's ensure that the Service Fabric emulator that we mentioned in the <em>Technical requirements</em> section of this chapter has been installed and is running on your development machine. Now, we need so switch it so that it runs <strong>5 nodes</strong>.</p>
<p>Now, we can follow the steps we explained in the <em>Azure and Visual Studio support for microservice orchestration</em> section to create a Service Fabric project named <kbd>PurchaseLogging</kbd>. Select a .NET Core stateful reliable service and name it <kbd>LogStore</kbd>.</p>
<p class="mce-root">The solution that's created by Visual Studio is composed of a <kbd>PurchaseLogging</kbd> project, which represents the overall application, and a <kbd>LogStore</kbd> project, which will contain the implementation of the first microservice that's included in the <kbd>PurchaseLogging</kbd> application.</p>
<p>Under the <kbd>PackageRoot</kbd> folder, the <kbd>LogStore</kbd> service and each reliable service contain the <kbd>ServiceManifest.xml</kbd> configuration file and a <kbd>Settings.xml</kbd> folder (under the <kbd>Config</kbd> subfolder). The <kbd>Settings.xml</kbd> folder contains some settings that you can read from the service code. The initial file contains predefined settings that are needed by the Service Fabric runtime. Let's add a new settings section, as shown in the following code:</p>
<pre>&lt;?xml version="1.0" encoding="utf-8" ?&gt;<br/>&lt;Settings  <br/>           <br/>          &gt; <br/>  &lt;!-- This is used by the StateManager's replicator. --&gt;<br/>  &lt;Section Name="ReplicatorConfig"&gt;<br/>    &lt;Parameter Name="ReplicatorEndpoint" Value="ReplicatorEndpoint" /&gt;<br/>  &lt;/Section&gt;<br/>  &lt;!-- This is used for securing StateManager's replication traffic. --&gt;<br/>  &lt;Section Name="ReplicatorSecurityConfig" /&gt;<br/><br/>  &lt;!-- Below the new Section to add --&gt;<br/>  <br/>  &lt;Section Name="Timing"&gt;<br/>    &lt;Parameter Name="MessageMaxDelaySeconds" Value="" /&gt;<br/>  &lt;/Section&gt;<br/>&lt;/Settings&gt;</pre>
<p>We will use the value of <kbd>MessageMaxDelaySeconds</kbd> to configure the system component and ensure message idempotency. The setting value is empty, because most of the settings are overridden by the overall application settings contained in the <kbd>PurchaseLogging</kbd> project.</p>
<p class="mce-root"/>
<p>The <kbd>ServiceManifest.xml</kbd> file contains some configurations tags that are automatically handled by Visual Studio, as well as a list of endpoints. Two endpoints are preconfigured since they are used by the Service Fabric runtime. Here, we must add the configuration details of all the endpoints our microservice will listen to. Each endpoint definition has the following format:</p>
<pre>&lt;Endpoint Name="&lt;endpoint name&gt;" PathSuffix="&lt;the path of the endpoint URI&gt;" Protocol="&lt;a protcolo like Tcp, http, https, etc.&gt;" Port="the exposed port" Type="&lt;Internal or Input&gt;"/&gt;</pre>
<p>If <kbd>Type</kbd> is <kbd>Internal</kbd>, the port will be opened just inside the cluster's local network; otherwise, the port will be available from outside the cluster as well. In the preceding case, we must declare that port in the configuration of the Azure Service Fabric cluster as well, otherwise the cluster load balancer/firewall will not forward messages to it.</p>
<p>Public ports can be reached directly from the cluster URI (<kbd>&lt;cluster name&gt;.&lt;location code&gt;.cloudapp.azure.com</kbd>) since the load balancer that interfaces each cluster will forward the input traffic it receives to them.</p>
<p>In this example, we won't define endpoints since we are going to use remoting-based communication, which has already been defined, for all internal interactions, but we will show you how to use them.</p>
<p>The <kbd>PurchaseLogging</kbd> project contains a reference to the <kbd>LogStore</kbd> project under the <em>services</em> Solution Explorer node and contains various folders with various XML configuration files. More specifically, we have the following folders:</p>
<ul>
<li><kbd>ApplicationPackageRoot</kbd>, which contains the overall application manifest named <kbd>ApplicationManifest.xml</kbd>. This file contains some initial parameter definitions and then further configurations. Parameters have the following format:</li>
</ul>
<pre style="padding-left: 60px">&lt;Parameter Name="&lt;parameter name&gt;" DefaultValue="&lt;parameter definition&gt;" /&gt;</pre>
<ul>
<li>Once defined, parameters can replace any value in the remainder of the file. Parameter values are referenced by enclosing the parameter name between square brackets, as shown in the following code:</li>
</ul>
<pre style="padding-left: 60px">&lt;UniformInt64Partition PartitionCount="[LogStore_PartitionCount]" LowKey="0" HighKey="1000" /&gt;</pre>
<p style="padding-left: 60px">Some parameters define the number of replicas and partitions for each service and are automatically created by Visual Studio:</p>
<pre style="padding-left: 60px">&lt;Parameter Name="LogStore_MinReplicaSetSize" DefaultValue="1" /&gt;<br/>&lt;Parameter Name="LogStore_PartitionCount" DefaultValue="2" /&gt;<br/>&lt;Parameter Name="LogStore_TargetReplicaSetSize" DefaultValue="1" /&gt;</pre>
<p style="padding-left: 60px">Let's replace the initial values suggested by Visual Studio with those in the preceding code. We will use just two partitions to show you how partitions work, but you can increase this value to improve write/update parallelism. Each partition of the <kbd>LogStore</kbd> service doesn't need several replicas since replicas improve performance on read operations and this service is not designed to offer read services. Therefore, you may choose just one replica, or at most two, to make the system redundant and more robust to failures.</p>
<p style="padding-left: 60px">The preceding parameters are used to define the role of the <kbd>LogStore</kbd> service inside the overall application. This definition is generated automatically by Visual Studio in the same file, below the initial definition created by Visual studio, with just the partition interval changed to 0-1,000:</p>
<pre style="padding-left: 60px">&lt;Service Name=LogStore ServicePackageActivationMode="ExclusiveProcess"&gt;<br/>    &lt;StatefulService ServiceTypeName="LogStoreType" <br/>    TargetReplicaSetSize=<br/>    "[LogStore_TargetReplicaSetSize]" <br/>    MinReplicaSetSize="[LogStore_MinReplicaSetSize]"&gt;<br/>        &lt;UniformInt64Partition PartitionCount="<br/>        [LogStore_PartitionCount]" <br/>        LowKey="0" HighKey="1000" /&gt;<br/>    &lt;/StatefulService&gt;<br/>&lt;/Service&gt;</pre>
<ul>
<li><kbd>ApplicationParameters</kbd> contains possible overrides for parameters defined in <kbd>ApplicationManifest.xml</kbd> for various deployment environments: the cloud (that is, the actual Azure Service Fabric cluster) and local emulators with one or five nodes.</li>
<li class="mce-root"><kbd>PublishProfiles</kbd> contains the settings that are needed to publish the application in the same environments handled by the <kbd>ApplicationParameters</kbd> folder. You just need to customize the cloud publish profile with the actual name of your Azure Service Fabric URI and with the authentication certificate you downloaded during the Azure cluster configuration process:</li>
</ul>
<pre style="color: black;padding-left: 60px">&lt;ClusterConnectionParameters <br/>    ConnectionEndpoint="&lt;cluster name&gt;.&lt;location <br/>    code&gt;.cloudapp.azure.com:19000"<br/>    X509Credential="true"<br/>    ServerCertThumbprint="&lt;server certificate thumbprint&gt;"<br/>    FindType="FindByThumbprint"<br/>    FindValue="&lt;client certificate thumbprint&gt;"<br/>    StoreLocation="CurrentUser"<br/>    StoreName="My" /&gt;</pre>
<p>The remaining steps that need to be followed in order to complete the application have been organized into several subsections. Let's start by looking at ensuring message idempotency.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ensuring message idempotency</h1>
                
            
            
                
<p>Messages can become lost because of failures or small timeouts caused by load balancing. Here, we will use a predefined remoting-based communication that performs automatic message retries in the case of failures. However, as we explained in the <em>Microservice design principles</em> subsection, this may cause the same messages to be received twice. Since we are summing up the revenues of purchase orders, we must protect ourselves from summing up the same purchase several times.</p>
<p>To do this, we will implement a library containing the necessary tools to ensure that message replicas are discarded.</p>
<p>Let's add a new .NET Standard 2.0 library project called <strong>IdempotencyTools</strong> to our solution. Now, we can remove the initial class scaffolded by Visual studio. This library needs a reference to the same version of the <kbd>Microsoft.ServiceFabric.Services</kbd> NuGet package referenced by <kbd>LogStore</kbd>, so let's verify the version number and add the same NuGet package reference to the <kbd>IdempotencyTools</kbd> project.</p>
<p>The main tool that ensures message idempotency is the <kbd>IdempotentMessage</kbd> class:</p>
<pre>using System;<br/>using System.Runtime.Serialization;<br/><br/>namespace IdempotencyTools<br/>{<br/>    [DataContract]<br/>    public class IdempotentMessage&lt;T&gt;<br/>    {<br/>        [DataMember]<br/>        public T Value { get; protected set; }<br/>        [DataMember]<br/>        public DateTimeOffset Time { get; protected set; }<br/>        [DataMember]<br/>        public Guid Id { get; protected set; }<br/><br/>        public IdempotentMessage(T originalMessage)<br/>        {<br/>            Value = originalMessage;<br/>            Time = DateTimeOffset.Now;<br/>            Id = Guid.NewGuid();<br/>        }<br/>    }<br/>}</pre>
<p>We added the <kbd>DataContract</kbd> and <kbd>DataMember</kbd> attributes since they are needed by the remoting communication serializer we are going to use for all internal messages. Basically, the receding class is a wrapper that adds a <kbd>Guid</kbd> and a time mark to the message class instance that's passed to its constructor.</p>
<p>The <kbd>IdempotencyFilter</kbd> class uses a distributed dictionary to keep track of the messages it's already received. To avoid the indefinite growth of this dictionary, older entries are periodically deleted. Messages that are too old to be found in the dictionary are automatically discarded.</p>
<p>The time interval entries are kept in the dictionary and are passed in the <kbd>IdempotencyFilter</kbd> static factory method, which creates new filter instances, along with the dictionary name and the <kbd>IReliableStateManager</kbd> instance, which are needed to create the distributed dictionary:</p>
<pre>public class IdempotencyFilter<br/>{<br/>    protected IReliableDictionary&lt;Guid, DateTimeOffset&gt; dictionary;<br/>    protected int maxDelaySeconds;<br/>    protected DateTimeOffset lastClear;<br/>    protected IReliableStateManager sm;<br/>    protected IdempotencyFilter() { }<br/>    public static async Task&lt;IdempotencyFilter&gt; NewIdempotencyFilter(<br/>        string name, <br/>        int maxDelaySeconds, <br/>        IReliableStateManager sm)<br/>    {<br/>        var result = new IdempotencyFilter();<br/>        result.dictionary = await <br/>            sm.GetOrAddAsync&lt;IReliableDictionary&lt;Guid, DateTimeOffset&gt;&gt; <br/>            (name);<br/>        result.maxDelaySeconds = maxDelaySeconds;<br/>        result.lastClear = DateTimeOffset.Now;<br/>        result.sm = sm;<br/>        return result;<br/>    }<br/>...<br/>...</pre>
<p>The dictionary contains each message time mark indexed by the message <kbd>Guid</kbd> and is created by invoking the <kbd>GetOrAddAsync</kbd> method of the <kbd>IReliableStateManager</kbd> instance with the dictionary type and name. <kbd>lastClear</kbd> contains the time of the removal of all old messages.</p>
<p>When a new message arrives, the <kbd>NewMessage</kbd> method checks whether it must be discarded. If the message must be discarded, it returns <kbd>null</kbd>; otherwise, it adds the new message to the dictionary and returns the message without the <kbd>IdempotentMessage</kbd> wrapper:</p>
<pre>public async Task&lt;T&gt; NewMessage&lt;T&gt;(IdempotentMessage&lt;T&gt; message)<br/>{<br/>    DateTimeOffset now = DateTimeOffset.Now;<br/>    if ((now - lastClear).TotalSeconds &gt; 1.5 * maxDelaySeconds)<br/>    {<br/>        await Clear();<br/>    }<br/>    if ((now - message.Time).TotalSeconds &gt; maxDelaySeconds)<br/>        return default(T);<br/>    using (ITransaction tx = this.sm.CreateTransaction())<br/>    {<br/>        ...<br/>        ...<br/>    }<br/> }</pre>
<p>As a first step, the method verifies whether it's time to clear the dictionary and whether the message is too old. Then, it starts a transaction to access the dictionary. All distributed dictionary operations must be enclosed in a transaction, as shown in the following code:</p>
<pre>using (ITransaction tx = this.sm.CreateTransaction())<br/>{<br/>    var result = await dictionary.TryGetValueAsync(tx, <br/>    message.Id);<br/>    if (result.HasValue)<br/>    {<br/>        tx.Abort();<br/>        return default(T);<br/>    }<br/>    else<br/>    {<br/>        await dictionary.TryAddAsync(tx, message.Id, message.Time);<br/>        await tx.CommitAsync();<br/>        return message.Value;<br/>    }<br/>}</pre>
<p>If the message <kbd>Guid</kbd> is found in the dictionary, the transaction is aborted since the dictionary doesn't need to be updated and the method returns <kbd>default(T)</kbd>, which is actually <kbd>null</kbd> since the message must not be processed. Otherwise, the message entry is added to the dictionary and the unwrapped message is returned.</p>
<p>The code of the <kbd>Clear</kbd> method can be found in the GitHub repository associated with this book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Interaction library</h1>
                
            
            
                
<p>There are some types that must be shared among all microservices. If the internal communication is implemented with either remoting or WCF, each microservice must expose an interface with all the methods other microservices call. Such interfaces must be shared among all microservices. Moreover, with all communication interfaces, the classes that implement the messages must also be shared among all microservices (or among some subsets of them). Therefore, all of these structures are declared in external libraries that are referenced by the microservices.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>Now, let's add a new .NET Standard 2.0 library project called <kbd>Interactions</kbd> to our solution. Since this library must use the <kbd>IdempotentMessage</kbd> generic class, we must add it as a reference to the <kbd>IdempotencyTools</kbd> project. We must also add a reference to the remoting communication library contained in the <kbd>Microsoft.ServiceFabric.Services.Remoting</kbd> NuGet package since all interfaces that are used to expose the microservice's remote methods must inherit from the <kbd>IService</kbd> interface defined in this package.</p>
<p><kbd>IService</kbd> is an empty interface that declares the communication role of the inheriting interface. The <kbd>Microsoft.ServiceFabric.Services.Remoting</kbd> NuGet package version must match the version of the <kbd>Microsoft.ServiceFabric.Services</kbd> package declared in the other projects.</p>
<p>The following code shows the declarations of the interface that need to be implemented by the <kbd>LogStore</kbd> class:</p>
<pre>using System;<br/>using System.Collections.Generic;<br/>using System.Text;<br/>using System.Threading.Tasks;<br/>using IdempotencyTools;<br/>using Microsoft.ServiceFabric.Services.Remoting;<br/><br/>namespace Interactions<br/>{<br/>    public interface ILogStore: IService<br/>    {<br/>        Task&lt;bool&gt; LogPurchase(IdempotentMessage&lt;PurchaseInfo&gt; <br/>        idempotentMessage);<br/>    }<br/>}</pre>
<p>The following is the code of the <kbd>PurchaseInfo</kbd> message class, which is referenced in the <kbd>ILogStore</kbd> interface:</p>
<pre>using System;<br/>using System.Collections.Generic;<br/>using System.Runtime.Serialization;<br/>using System.Text;<br/><br/>namespace Interactions<br/>{<br/>    [DataContract]<br/>    public class PurchaseInfo<br/>    {<br/>        [DataMember]<br/>        public string Location { get; set; }<br/>        [DataMember]<br/>        public decimal Cost { get; set; }<br/>        [DataMember]<br/>        public DateTimeOffset Time { get; set; }<br/>    }<br/>}</pre>
<p>Now, we are ready to implement our main <kbd>LogStore</kbd> microservice.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing the receiving side of communication</h1>
                
            
            
                
<p>To implement the <kbd>LogStore</kbd> microservice, we must add a reference to the <kbd>Interaction</kbd> library, which will automatically create references to the remoting library and to the <kbd>IdempotencyTools</kbd> project. Then, the <kbd>LogStore</kbd> class must implement the <kbd>ILogStore</kbd> interface:</p>
<pre>internal sealed class LogStore : StatefulService, <strong>ILogStore<br/>...<br/>...<br/></strong>private IReliableQueue&lt;IdempotentMessage&lt;PurchaseInfo&gt;&gt; LogQueue = null;<br/>public async Task&lt;bool&gt; <br/>    LogPurchase(IdempotentMessage&lt;PurchaseInfo&gt; idempotentMessage)<br/>{<br/>    if (LogQueue == null) return false;<br/>    using (ITransaction tx = this.StateManager.CreateTransaction())<br/>    {<br/>        await LogQueue.EnqueueAsync(tx, idempotentMessage);<br/>        await tx.CommitAsync();<br/>        return true;<br/>    }<br/>}</pre>
<p>Once the service receives a <kbd>LogPurchase</kbd> call from the remoting runtime, it puts the message in the <kbd>LogQueue</kbd> to avoid the caller remaining blocked, waiting for message processing completion. This way, we achieve both the reliability of a synchronous message passing protocol (the caller knows that the message has been received) and the performance advantages of asynchronous message processing that are typical of asynchronous communication.</p>
<p class="mce-root"/>
<p><kbd>LoqQueue</kbd>, as a best practice for all distributed collections, is created in the <kbd>RunAsync</kbd> method, so <kbd>LogQueue</kbd> may be null if the first call arrives before the Azure Service Fabric runtime has called <kbd>RunAsync</kbd>. In this case, the method returns <kbd>false</kbd> to signal that the service isn't ready yet. Otherwise, a transaction is created to enqueue the new message.</p>
<p>However, our service will not receive any communication if we don't furnish an implementation of <kbd>CreateServiceReplicaListeners()</kbd> that returns all the listeners that the service would like to activate. In the case of remoting communications, there is a predefined method that performs the whole job, so we just need to call it:</p>
<pre>protected override IEnumerable&lt;ServiceReplicaListener&gt; <br/>    CreateServiceReplicaListeners()<br/>{<br/>    return this.CreateServiceRemotingReplicaListeners&lt;LogStore&gt;();<br/>}</pre>
<p>Here, <kbd>CreateServiceRemotingReplicaListeners</kbd> is an extension method defined in the remoting communication library. It creates listeners for both primary replicas and secondary replicas (for read-only operations). When creating the client, we can specify whether its communications are addressed just to primary replicas or also to secondary replicas.</p>
<p>If you would like to use different listeners, you must create an <kbd>IEnumerable</kbd> of <kbd>ServiceReplicaListener</kbd> instances. For each listener, you must invoke the <kbd>ServiceReplicaListener</kbd> constructor with three arguments:</p>
<ul>
<li>A function that receives the reliable service context object as its input and returns an implementation of the <kbd>ICommunicationListener</kbd> interface.</li>
<li>The name of the listener. This second argument becomes obligatory when the service has more than one listener.</li>
<li>A Boolean that is true if the listener must be activated on secondary replicas.</li>
</ul>
<p>For instance, if we would like to add both custom and HTTP listeners, the code becomes something like the following:</p>
<pre>return new ServiceReplicaListener[]<br/>{<br/>    new ServiceReplicaListener(context =&gt; <br/>    new MyCustomHttpListener(context, "&lt;endpoint name&gt;"),             <br/>    "CustomWriteUpdateListener", true),<br/><br/>    new ServiceReplicaListener(serviceContext =&gt;<br/>    new KestrelCommunicationListener(serviceContext, "&lt;endpoint name&gt;" <br/>    (url, listener) =&gt;<br/>        {<br/>           ...<br/>        })<br/>        "HttpReadOnlyListener",<br/>    true)<br/>};</pre>
<p><kbd>MyCustomHttpListener</kbd> is a custom implementation of <kbd>ICommunicationListener</kbd>, while <kbd>KestrelCommunicationListener</kbd> is a predefined HTTP listener based on Kestrel and ASP.NET Core. The following is the full code that defines the <kbd>KestrelCommunicationListener</kbd> listener:</p>
<pre>new ServiceReplicaListener(serviceContext =&gt;<br/>new KestrelCommunicationListener(serviceContext, "&lt;endpoint name&gt;" (url, listener) =&gt;<br/>{<br/>    return new WebHostBuilder()<br/>    .UseKestrel()<br/>    .ConfigureServices(<br/>        services =&gt; services<br/>        .AddSingleton&lt;StatefulServiceContext&gt;(serviceContext)<br/>        .AddSingleton&lt;IReliableStateManager&gt;(this.StateManager))<br/>                         <br/>    .UseContentRoot(Directory.GetCurrentDirectory())<br/>    .UseStartup&lt;Startup&gt;()<br/>    .UseServiceFabricIntegration(listener, <br/>                            <br/>    ServiceFabricIntegrationOptions.UseUniqueServiceUrl)<br/>    .UseUrls(url)<br/>    .Build();<br/>})<br/>"HttpReadOnlyListener",<br/>true)</pre>
<p>Usually, <kbd>ICommunicationListener</kbd> implementations accept the node context and an endpoint name in their constructors and are responsible for reading the endpoint data defined in the <kbd>ServiceManifest.xml</kbd> service, as well as creating a listening endpoint that satisfies the specification contained there. They do this in their <kbd>CommunicationListener.OpenAsync</kbd> method:</p>
<pre>public async Task&lt;string&gt; OpenAsync(CancellationToken cancellationToken)<br/>{<br/>    EndpointResourceDescription serviceEndpoint = serviceContext<br/>    .CodePackageActivationContext.GetEndpoint("ServiceEndpoint");<br/>    //create service URI that depend on current Ip <br/>    (FabricRuntime.GetNodeContext().IPAddressOrFQDN)<br/>    //partition id (serviceContext.PartitionId)<br/>    //and replica id (serviceContext.ReplicaOrInstanceId)<br/>    //open the listener<br/>    return &lt;computedURISchema&gt;;<br/>}</pre>
<p><kbd>&lt;computedURISchema&gt;</kbd> is the URI with the IP address replaced by a "+". Once returned by <kbd>OpenAsync</kbd>, it is published in the Service Fabric naming service and used to compute the actual service address from the cluster node IP address it's been deployed in.</p>
<p><kbd>ICommunicationListener</kbd> implementations must also have a <kbd>Close</kbd> method, which must close the opened communication channel, and an <kbd>Abort</kbd> method, which must <strong>immediately</strong> close the communication channel (ungracefully, that is, without informing connected clients and so on).</p>
<p>Now that we have turned communications on, we can implement the service logic.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing service logic</h1>
                
            
            
                
<p>Service logic is executed by the tasks that are launched as independent threads when <kbd>RunAsync</kbd> is invoked by the Service Fabric runtime. It's good practice to create an <kbd>IHost</kbd> and design all the tasks as <kbd>IHostedService</kbd> implementations when you only need to implement one task. In fact, <kbd>IHostedService</kbd> implementations are independent chunks of software that are easier to unit-test. <kbd>IHost</kbd> and <kbd>IHostedService</kbd> were discussed in detail in the <em>Using generic hosts</em> subsection.</p>
<p>In this section, we will implement the logic that computes daily revenues for each location into an <kbd>IHostedservice</kbd> named <kbd>ComputeStatistics</kbd>, which uses a distributed dictionary whose keys are the location names and whose values are instances of a class called <kbd>RunningTotal</kbd>. This class stores the current running total and the day that is being computed:</p>
<pre>namespace LogStore<br/>{<br/>    public class RunningTotal<br/>    {<br/>        public DateTime Day { get; set; }<br/>        public decimal Count { get; set; }<br/><br/>        public RunningTotal <br/>                Update(DateTimeOffset time, decimal value)<br/>        {<br/>            ...<br/>        }<br/>    }<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>This class has an <kbd>Update</kbd> method that updates the instance when a new purchase message is received. First of all, the incoming message time is normalized to universal time. Then, the day part of this time is extracted and compared with the current <kbd>Day</kbd> of the running total, as shown in the following code:</p>
<pre>public RunningTotal Update(DateTimeOffset time, decimal value)<br/>        {<br/>            var normalizedTime = time.ToUniversalTime();<br/>            var newDay = new DateTime(normalizedTime.Year, <br/>                    normalizedTime.Month, normalizedTime.Day);<br/>           ... <br/>           ...<br/>        }</pre>
<p>If it's a new day, we assume that the running total computation of the previous day has finished, so the <kbd>Update</kbd> method returns it in a new <kbd>RunningTotal</kbd> instance and resets <kbd>Day</kbd> and <kbd>Count</kbd> so that it can compute the new day running total. Otherwise, the new value is added to the running <kbd>Count</kbd> and the method returns <kbd>null</kbd>, meaning that the day total isn't ready yet. This implementation can be seen in the following code:</p>
<pre>public RunningTotal Update(DateTimeOffset time, decimal value)<br/>{<br/>    ...<br/>    ...<br/>    var result = newDay &gt; Day &amp;&amp; Day != DateTime.MinValue ? <br/>    new RunningTotal<br/>    {<br/>        Day=Day,<br/>        Count=Count<br/>    } <br/>    : null;<br/>    if(newDay &gt; Day) Day = newDay;<br/>    if (result != null) Count = value;<br/>    else Count += value;<br/>    return result;<br/>}</pre>
<p>The <kbd>IHostedService</kbd> implementation of <kbd>ComputeStatistics</kbd> needs some parameters to work properly, as follows:</p>
<ul>
<li>The queue containing all the incoming messages</li>
<li>The <kbd>IReliableStateManager</kbd> service, so that it can create the distributed dictionary where it stores data</li>
<li>The <kbd>ConfigurationPackage</kbd> service, so that it can read the settings defined in the <kbd>Settings.xml</kbd> service file and possibly those overridden in the application manifest</li>
</ul>
<p>The preceding parameters must be passed in the <kbd>ComputeStatistics</kbd> constructor when a <kbd>ComputeStatistics</kbd> instance is created by <kbd>IHost</kbd> through dependency injection. We will return to the <kbd>IHost</kbd> definition in the next subsection. For now, let's concentrate on the <kbd>ComputeStatistics</kbd> constructor and its fields:</p>
<pre>namespace LogStore<br/>{<br/>    public class ComputeStatistics : BackgroundService<br/>    {<br/>        IReliableQueue&lt;IdempotentMessage&lt;PurchaseInfo&gt;&gt; queue;<br/>        IReliableStateManager stateManager;<br/>        ConfigurationPackage configurationPackage;<br/>        public ComputeStatistics(<br/>            IReliableQueue&lt;IdempotentMessage&lt;PurchaseInfo&gt;&gt; queue,<br/>            IReliableStateManager stateManager,<br/>            ConfigurationPackage configurationPackage)<br/>        {<br/>            this.queue = queue;<br/>            this.stateManager = stateManager;<br/>            this.configurationPackage = configurationPackage;<br/>        }</pre>
<p>All the constructor parameters are stored in private fields so that they can be used when <kbd>ExecuteAsync</kbd> is called:</p>
<pre>protected async override Task ExecuteAsync(CancellationToken stoppingToken)<br/>{<br/>    bool queueEmpty = false;<br/>    var delayString=configurationPackage.Settings.Sections["Timing"]<br/>        .Parameters["MessageMaxDelaySeconds"].Value;<br/>    var delay = int.Parse(delayString);<br/>    var filter = await IdempotencyFilter.NewIdempotencyFilter(<br/>        "logMessages", delay, stateManager);<br/>    var store = await<br/>        stateManager.GetOrAddAsync&lt;IReliableDictionary&lt;string, RunningTotal&gt;&gt;("partialCount");<br/>....<br/>...</pre>
<p>Before entering its loop, the <kbd>ComputeStatistics</kbd> service prepares some structures and parameters. It declares that the queue isn't empty so that it can start dequeuing messages. Then, it extracts <kbd>MessageMaxDelaySeconds</kbd> from the service settings and turns it into an integer. The value of this parameter was left empty in the <kbd>Settings.xml</kbd> file. Now, it's time to override it and define its actual value in <kbd>ApplicationManifest.xml</kbd>:</p>
<pre>&lt;ServiceManifestImport&gt;<br/>    &lt;ServiceManifestRef ServiceManifestName="LogStorePkg" ServiceManifestVersion="1.0.0" /&gt;<br/>    &lt;!--code to add start --&gt;<br/>    &lt;ConfigOverrides&gt;<br/>      &lt;ConfigOverride Name="Config"&gt;<br/>        &lt;Settings&gt;<br/>          &lt;Section Name="Timing"&gt;<br/>            &lt;Parameter Name="MessageMaxDelaySeconds" Value="[MessageMaxDelaySeconds]" /&gt;<br/>          &lt;/Section&gt;<br/>        &lt;/Settings&gt;<br/>      &lt;/ConfigOverride&gt;<br/>    &lt;/ConfigOverrides&gt;<br/>    &lt;!--code to add end--&gt;<br/>&lt;/ServiceManifestImport&gt;</pre>
<p><kbd>ServiceManifestImport</kbd> imports the service manifest in the application and overrides some configuration. Its version number must be changed every time its content and/or the service definition is changed and the application is redeployed in Azure because version number changes tell the Service Fabric runtime what to change in the cluster. Version numbers also appear in other configuration settings. They must be changed every time the entities they refer to change.</p>
<p><kbd>MessageMaxDelaySeconds</kbd> is passed to the instance of the idempotency filter, along with a name for the dictionary of the already received messages, and with the instance of the <kbd>IReliableStateManager</kbd> service. Finally, the main distributed dictionary that's used to store running totals is created.</p>
<p>After this, the service enters its loop and finishes when <kbd>stoppingToken</kbd> is signaled, that is, when the Service Fabric runtime signals that the service is going to be stopped:</p>
<pre>while (!stoppingToken.IsCancellationRequested)<br/>    {<br/>        while (!queueEmpty &amp;&amp; !stoppingToken.IsCancellationRequested)<br/>        {<br/>            RunningTotal total = null;<br/>            using (ITransaction tx = stateManager.CreateTransaction())<br/>            {<br/>                ...<br/>                ... <br/>                ...<br/>            }<br/>        }<br/>        await Task.Delay(100, stoppingToken);<br/>        queueEmpty = false;<br/>    }<br/>} </pre>
<p>The inner loop runs until the queue isn't empty and then exits and waits 100 milliseconds before verifying whether new messages have been enqueued:</p>
<pre>await Task.Delay(100, stoppingToken);<br/>queueEmpty = false;</pre>
<p>The following is the code for the inner loop, which is enclosed in a transaction:</p>
<pre>RunningTotal total = null;<br/>using (ITransaction tx = stateManager.CreateTransaction())<br/>{<br/>    var result = await queue.TryDequeueAsync(tx);<br/>    if (!result.HasValue) queueEmpty = true;<br/>    else<br/>    {<br/>        var item = await filter.NewMessage&lt;PurchaseInfo&gt;(result.Value);<br/>        if(item != null)<br/>        {<br/>            var counter = await store.TryGetValueAsync(tx, <br/>            item.Location);<br/>            //counter update<br/>            ...<br/>        }<br/>        ...<br/>        ...<br/>    }<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Here, the service is trying to dequeue a message. If the queue is empty, it sets <kbd>queueEmpty</kbd> to <kbd>true</kbd> to exit the loop; otherwise, it passes the message through the idempotency filter. If the message survives this step, it uses it to update the running total of the location referenced in the message. However, correct operation of the distributed dictionary requires that the old counter is replaced with a new counter each time an entry is updated. Accordingly, the old counter is copied into a new <kbd>RunningTotal</kbd> object. This new object can be updated with the new data if we call the <kbd>Update</kbd> method:</p>
<pre>    //counter update    <br/>    var newCounter = counter.HasValue ? <br/>    new RunningTotal<br/>    {<br/>        Count=counter.Value.Count,<br/>        Day= counter.Value.Day<br/>    }<br/>    : new RunningTotal();<br/>    total = newCounter.Update(item.Time, item.Cost);<br/>    if (counter.HasValue)<br/>        await store.TryUpdateAsync(tx, item.Location, <br/>        newCounter, counter.Value);<br/>    else<br/>        await store.TryAddAsync(tx, item.Location, newCounter);</pre>
<p>Then, the transaction is committed, as shown in the following code:</p>
<pre>if(item != null)<br/>{<br/>  ...<br/>  ...<br/>}<br/>await tx.CommitAsync();<br/>if(total != null)<br/>{<br/>    await SendTotal(total, item.Location);<br/>}</pre>
<p>When the <kbd>Update</kbd> method returns a complete computation result, that is when the <kbd>total != null</kbd> method is called:</p>
<pre>protected async Task SendTotal(RunningTotal total, string location)<br/>{<br/>   //Empty, actual application would send data to a service <br/>   //that exposes daily statistics through a public Http endpoint         <br/>}</pre>
<p class="mce-root"/>
<p>The <kbd>SendTotal</kbd> method sends the total to a service that publicly exposes all the statistics through an HTTP endpoint. After reading <a href="3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml">Chapter 12</a>, <em>Applying Service-Oriented Architectures with .NET Core</em>, which is dedicated to the Web API, you may want to implement a similar service with a stateless ASP.NET Core microservice connected to a database. The stateless ASP.NET Core service template automatically creates an ASP.NET Core-based HTTP endpoint for you.</p>
<p>However, since this service must receive data from the <kbd>SendTotal</kbd> method, it also needs remote-based endpoints. Therefore, we must create them, just like we did for the <kbd>LogStore</kbd> microservice, and concatenate the remote-based endpoint array with the preexisting array containing the HTTP endpoint.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Defining the microservice's host</h1>
                
            
            
                
<p>Now, we have everything in place to define the microservice's <kbd>RunAsync</kbd> method:</p>
<pre>protected override async Task RunAsync(CancellationToken cancellationToken)<br/>{<br/>    // TODO: Replace the following sample code with your own logic <br/>    // or remove this RunAsync override if it's not needed in your service.<br/>    cancellationToken.ThrowIfCancellationRequested();<br/>    LogQueue = await <br/>        this.StateManager<br/>        .GetOrAddAsync&lt;IReliableQueue<br/>        &lt;IdempotentMessage&lt;PurchaseInfo&gt;&gt;&gt;("logQueue");<br/>    var configurationPackage = Context<br/>        .CodePackageActivationContext<br/>        .GetConfigurationPackageObject("Config");<br/>    ...<br/>    ...</pre>
<p>Here, the method verifies whether the cancellation token was signaled, in which case we throw an exception to abort the method. Then, the service queue is created, and the service settings are saved in <kbd>configurationPackage</kbd>.</p>
<p>After that, we can create the <kbd>IHost</kbd> service, as we explained in the <em>Using generic hosts</em> subsection:</p>
<pre>var host = new HostBuilder()<br/>    .ConfigureServices((hostContext, services) =&gt;<br/>    {<br/>        services.AddSingleton(this.StateManager);<br/>        services.AddSingleton(this.LogQueue);<br/>        services.AddSingleton(configurationPackage);<br/>        services.AddHostedService&lt;ComputeStatistics&gt;();<br/>    })<br/>    .Build();<br/>await host.RunAsync(cancellationToken);</pre>
<p><kbd>ConfigureServices</kbd> defines all singletons instances that may be needed by <kbd>IHostedService</kbd> implementations, so they are injected into the constructor of all the implementations that reference their types. Then, <kbd>AddHostedService</kbd> declares the unique <kbd>IHostedService</kbd> of the microservice. Once the <kbd>IHost</kbd> is built, we run it until the <kbd>RunAsync</kbd> cancellation token is signaled. When the cancellation token is signaled, the request to shutdown is passed to all <kbd>IHostedService</kbd> implementations.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Communicating with the service</h1>
                
            
            
                
<p class="mce-root">Since we haven't implemented the whole purchase logic yet, we will implement a stateless microservice that sends random data to the <kbd>LogStore</kbd> service. Right-click on the <kbd>PurchaseLogging</kbd> project in the Solution Explorer and select Add | Service Fabric Service. Then, select the .NET Core stateless template and name the new microservice project <kbd>FakeSource</kbd>.</p>
<p>Now, let's add a reference to the <kbd>Interaction</kbd> project. Before moving on to the service code, we need to update the replica count of the newly created service in <kbd>ApplicationManifest.xml</kbd> and in all the other environment-specific parameter overrides (the cloud, one local cluster node, five local cluster nodes):</p>
<pre>&lt;Parameter Name="FakeSource_InstanceCount" DefaultValue="2" /&gt;</pre>
<p>This fake service needs no listeners and its <kbd>RunAsync</kbd> method is straightforward:</p>
<pre>string[] locations = new string[] { "Florence", "London", "New York", "Paris" };<br/><br/>protected override async Task RunAsync(CancellationToken cancellationToken)<br/>{<br/>    Random random = new Random();<br/>    while (true)<br/>    {<br/>        cancellationToken.ThrowIfCancellationRequested();<br/><br/>        PurchaseInfo message = new PurchaseInfo<br/>        {<br/>            Time = DateTimeOffset.Now,<br/>            Location= locations[random.Next(0, locations.Length)],<br/>            Cost= 200m*random.Next(1, 4)<br/>        };<br/>        //Send message to counting microservices <br/>        ...<br/>        ...<br/>       <br/>        await Task.Delay(TimeSpan.FromSeconds(1), cancellationToken);<br/>    }<br/>}</pre>
<p>In each loop, a random message is created and sent to the counting microservices. Then, the thread sleeps for a second and starts a new loop. The code that sends the created messages is as follows:</p>
<pre>//Send message to counting microservices <br/>var partition = new ServicePartitionKey(Math.Abs(message.Location.GetHashCode()) % 1000);<br/>var client = ServiceProxy.Create&lt;ILogStore&gt;(<br/>    new Uri("fabric:/PurchaseLogging/LogStore"), partition);<br/>try<br/>{<br/>    while (!await client.LogPurchase(new  <br/>    IdempotentMessage&lt;PurchaseInfo&gt;(message)))<br/>    {<br/>        await Task.Delay(TimeSpan.FromMilliseconds(100),   <br/>        cancellationToken);<br/>    }<br/>}<br/>catch<br/>{<br/><br/>}</pre>
<p>Here, a key in the 0-9,999 interval is computed from the location string. This integer is passed to the <kbd>ServicePartitionKey</kbd> constructor. Then, a service proxy is created, and the URI of the service to call and the partition key are passed. The proxy uses this data to ask the naming service for a physical URI for a primary instance for the given partition value.</p>
<p><kbd>ServiceProxy.Create</kbd> also accepts a third optional argument that specifies whether messages that are sent by the proxy can also be routed to secondary replicas. The default is that messages are routed just to primary instances. If the message target returns <kbd>false</kbd>, meaning that it's not ready (remember that <kbd>LogPurchase</kbd> returns <kbd>false</kbd> when the <kbd>LogStore</kbd> message queue hasn't been created yet), the same transmission is attempted after 100 milliseconds.</p>
<p class="mce-root"/>
<p>Sending messages to a remoting target is quite easy. However, other communication listeners require that the sender interacts manually with the naming service to get a physical service URI. This can be done with the following code:</p>
<pre>ServicePartitionResolver resolver = ServicePartitionResolver.GetDefault();<br/><br/>ResolvedServicePartition partition =     <br/>await resolver.ResolveAsync(new Uri("fabric:/MyApp/MyService"), <br/>    new ServicePartitionKey(.....), cancellationToken);<br/>//look for a primary service only endpoint<br/>var finalURI= partition.Endpoints.First(p =&gt; <br/>    p.Role == ServiceEndpointRole.StatefulPrimary).Addreess;<br/></pre>
<p>Moreover, in the case of generic communication protocols, we must manually handle failures and retries with a library such as Polly (see the <em>Resilient task execution</em> subsection for more information).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing the application</h1>
                
            
            
                
<p>To test that the application actually computes running purchase totals, let's place a breakpoint in the <kbd>ComputeStatistics.cs</kbd> file:</p>
<pre>total = newCounter.Update(item.Time, item.Cost);<br/>if (counter.HasValue)...//put breakpoint on this line</pre>
<p>Each time the breakpoint is hit, look at the content of <kbd>newCounter</kbd> to verify how the running totals of all the locations change.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we described what microservices are and how they have evolved from the concept of a module. Then, we talked about the advantages of microservices and when it's worth using them, as well as general criteria for their design. We also explained what Docker containers are and analyzed the strong connection between containers and microservice architectures.</p>
<p>Then, we took on a more practical implementation by describing all the tools that are available in .NET Core so that we can implement microservice-based architectures. We also described infrastructures that are needed by microservices and how the Azure cluster offers Azure Kubernetes Services and Azure Service Fabric.</p>
<p>Finally, we put these concepts into practice by implementing a Service Fabric application. Here, we looked at the various ways in which Service Fabric applications can be implemented.</p>
<p>The next chapter focuses on how to use ORMs and Entity Framework Core to interact with various kinds of database while keeping our code independent from the database engine we've selected.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>What is the two-folded nature of the module concept?</li>
<li>Is scaling optimization the only advantage of microservices? If not, list some further advantages.</li>
<li>What is Polly?</li>
<li>What is <kbd>ConfigureServices</kbd>?</li>
<li>What Docker support is offered by Visual Studio?</li>
<li>What Docker application method is more powerful: the one based on <kbd>.yml</kbd> files or the one based on <kbd>.yaml</kbd> files?</li>
<li>What kinds of port must be declared during the definition of an Azure Service Fabric cluster?</li>
<li>Why are partitions of reliable stateful services needed?</li>
<li>How can we declare that a remoting communication must be addressed by secondary replicas? What about for other types of communication?</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>The following are links to the official documentation for Azure Service Bus and RabbitMQ, two event bus technologies:</p>
<ul>
<li><strong>Azure Service Bus</strong>: <a href="https://docs.microsoft.com/en-us/azure/service-bus-messaging/">https://docs.microsoft.com/en-us/azure/service-bus-messaging/</a></li>
<li><strong>RabbitMQ</strong>: <a href="https://www.rabbitmq.com/getstarted.html">https://www.rabbitmq.com/getstarted.html</a></li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The documentation for Polly, a tool for reliable communication/tasks, can be found here: <a href="https://github.com/App-vNext/Polly">https://github.com/App-vNext/Polly</a>.</p>
<p>More information on Docker can be found on Docker's official website: <a href="https://docs.docker.com/">https://docs.docker.com/</a>.</p>
<p>The official documentation for Kubernetes and <kbd>.yaml</kbd> files can be found here: <a href="https://kubernetes.io/docs/home/">https://kubernetes.io/docs/home/</a>.</p>
<p>The official documentation for Azure Kubernetes can be found here: <a href="https://docs.microsoft.com/en-US/azure/aks/">https://docs.microsoft.com/en-US/azure/aks/</a>.</p>
<p>The official documentation for Azure Service Fabric can be found here: <a href="https://docs.microsoft.com/en-US/azure/service-fabric/">https://docs.microsoft.com/en-US/azure/service-fabric/</a>.</p>
<p>The official documentation for Azure Service Fabric's reliable services can be found here: <a href="https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-introduction">https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-introduction</a>.</p>
<p>More information about the Actor model can be found here: <a href="https://www.researchgate.net/publication/234816174_Actors_A_conceptual_foundation_for_concurrent_object-oriented_programming">https://www.researchgate.NET/publication/234816174_Actors_A_conceptual_foundation_for_concurrent_object-oriented_programming</a>.</p>
<p>The official documentation for Actor models that can be implemented in Azure Service Fabric can be found here: <a href="https://docs.microsoft.com/en-US/azure/service-fabric/service-fabric-reliable-actors-introduction">https://docs.microsoft.com/en-US/azure/service-fabric/service-fabric-reliable-actors-introduction</a>.</p>
<p>Microsoft has also implemented an advanced actor model that is independent of Service Fabric. This is known as the Orleans framework. More information about Orleans can be found at the following links:</p>
<ul>
<li><strong>Orleans – Virtual Actors</strong>: <a href="https://www.microsoft.com/en-us/research/project/orleans-virtual-actors/?from=https%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Forleans%2F">https://www.microsoft.com/en-us/research/project/orleans-virtual-actors/?from=https%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Forleans%2F</a></li>
<li><strong>Orleans</strong> <strong>Documentation</strong>: <a href="http://dotnet.github.io/orleans/Documentation/">http://dotnet.github.io/orleans/Documentation/</a></li>
</ul>


            

            
        
    </body></html>