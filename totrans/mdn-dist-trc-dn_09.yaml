- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Best Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we focused on how to collect, enrich, correlate, and
    use individual telemetry signals. In this chapter, we’re going to discuss what
    information to collect and how to represent it efficiently using all the available
    signals. We’ll start by providing recommendations on how to pick a suitable telemetry
    signal and suggest cross-signal cost optimization strategies. Finally, we’ll explore
    about OpenTelemetry semantic conventions and use them to create consistent telemetry
    supported by most observability vendors.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll learn how to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Find telemetry signals that work for your scenarios
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Control telemetry costs with aggregation, sampling, and verbosity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Follow common practices when reporting telemetry with OpenTelemetry semantic
    conventions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to use existing semantics for common
    technologies or create your own cross-signal and cross-service conventions.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are no specific requirements for this chapter, and there are no associated
    code files either.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the right signal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we discussed individual telemetry signals in *Chapters 6* to *8*, we provided
    suggestions on when to use each of them. Let’s do a quick recap:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distributed traces** describe individual network calls and other interesting
    operations in detail. Spans have causal relationships, allowing us to understand
    the request flow in distributed systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traces document the request flow through the system and are essential for investigating
    errors or outliers in the long tail of latency distribution. Traces provide means
    to correlate other telemetry signals.
  prefs: []
  type: TYPE_NORMAL
- en: '**Metrics** collect aggregated data with low-cardinality attributes and provide
    a low-resolution view of the overall system state. They help optimize telemetry
    collection and reduce storage costs and query time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Events** provide highly structured information about individual occurrences
    of important things. The key difference between spans and events is that spans
    have unique contexts and describe something that lasts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events have high-cardinality attributes and can help answer ad hoc questions
    about system behavior and usage.
  prefs: []
  type: TYPE_NORMAL
- en: '**Logs** provide details about operations in a human-readable and less structured
    format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are useful for debugging things when other signals don’t provide enough
    information. Also, logs are the only signal that supports verbosity.
  prefs: []
  type: TYPE_NORMAL
- en: '**Profiles** are low-level performance data describing individual operations
    within a single process that helps optimize performance and identify resource
    bottlenecks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When instrumenting some specific scenario, we usually need a combination of
    signals.
  prefs: []
  type: TYPE_NORMAL
- en: For example, to get observability into network calls, we need traces to ensure
    we can track the request flow across services and correlate other signals. Logs
    are necessary to record exceptions and warnings, describe local operations, and
    provide debug-level data for complicated investigations. Finally, we may need
    metrics to record non-sampled measurements, optimize collection, and reduce query
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Before thinking about signals, we should have an idea of what information we
    want to be available, how we’re going to use it, how fast and frequently we need
    it, how many details we want to capture, for how long we need it, how much we
    can afford, and the downtime cost.
  prefs: []
  type: TYPE_NORMAL
- en: The answers to these questions should shape our decisions around observability.
  prefs: []
  type: TYPE_NORMAL
- en: Essentially, we have multiple trade-offs between having enough data to investigate
    issues fast and the cost of the observability solution. For example, collecting
    too many traces would give us all the details we need to investigate all sorts
    of issues. It would have a noticeable performance impact and significantly increase
    observability backend costs. As a result, traces might become so deep and detailed
    that it would be hard to understand where the problems are.
  prefs: []
  type: TYPE_NORMAL
- en: The conversation about a good set of telemetry signals is not possible without
    talking about costs. Let’s see how we can control them.
  prefs: []
  type: TYPE_NORMAL
- en: Getting more with less
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we usually need to collect multiple signals about the same component,
    we need to be able to tune them individually, depending on our needs.
  prefs: []
  type: TYPE_NORMAL
- en: The key is to reduce the volume of expensive, but not essential, data, potentially
    replacing it with cheaper options while keeping the system observable. We saw
    how we can do this by combining hot and cold storage or changing the retention
    period in [*Chapter 8*](B19423_08.xhtml#_idTextAnchor131), *Writing Structured
    and Correlated Logs*. Here, let’s focus on the collection side.
  prefs: []
  type: TYPE_NORMAL
- en: While observability vendors have different pricing models, it’s common for them
    to bill for traces, logs, and events depending on the volume, and for metrics
    depending on the number of time series. Queries (or API calls) can also be charged
    for and may have concurrency limits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, we can always add or remove instrumentations or stop writing logs
    and events, but there are a few more factors affecting how much telemetry is collected:'
  prefs: []
  type: TYPE_NORMAL
- en: We can control tracing volume with the sampling rate and by adding or removing
    new attributes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To control the number of metric time series, we can add or remove resource attributes
    or drop dimensions or instruments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can tune logging verbosity for individual categories or do so globally and
    add or remove attributes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications’ needs may vary, depending on their maturity, the number of changes,
    the downtime they can afford, and other factors – let’s go through several examples
    to demonstrate possible compromises they can apply.
  prefs: []
  type: TYPE_NORMAL
- en: Building a new application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When writing the first version of an application, telemetry can play a critical
    role in helping teams investigate issues and move faster. The interesting part
    here is that we don’t know which type of telemetry we need and how we’re going
    to use it.
  prefs: []
  type: TYPE_NORMAL
- en: We can leverage existing instrumentations that allow us to focus our efforts
    on building the application and having all means to debug it as it evolves, while
    also finding answers to questions about telemetry we outlined before.
  prefs: []
  type: TYPE_NORMAL
- en: The initial stages are a great time to design the observability story and it
    makes sense to start with the most flexible signals – traces, events, and logs.
    Initially, telemetry volume is likely to be low, so recording traces with a high
    sampling rate or just rate-limiting should be affordable. Also, we probably don’t
    have strict SLAs yet and don’t use dashboards and alerts much.
  prefs: []
  type: TYPE_NORMAL
- en: Until we get some real users, metrics or events might be unnecessary, but this
    is a good time to experiment and get familiar with them.
  prefs: []
  type: TYPE_NORMAL
- en: Even if the telemetry volume is quite low and we can capture verbose data, we
    should avoid adding excessive amounts of telemetry and should remove unused signals.
  prefs: []
  type: TYPE_NORMAL
- en: Evolving applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As our application starts getting some real users, getting performance data
    quickly becomes critical. By this time, we have more clarity on what’s important
    to measure in the application and how to debug issues (hopefully not relying on
    verbose logging).
  prefs: []
  type: TYPE_NORMAL
- en: This is the time to optimize and tune telemetry collection. As the load grows,
    we usually want to lower the sampling rate for traces and reduce log verbosity.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we would probably need to create alerts and build dashboards that are
    much more efficient when done over metrics, as we discussed in [*Chapter 7*](B19423_07.xhtml#_idTextAnchor115),
    *Adding Custom Metrics*. While instrumentation libraries should cover the basics,
    we might need to add custom metrics where we previously relied on queries over
    traces. As we scale up, the number of time series only increases with the number
    of service instances.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we might also decide to collect precise and unsampled usage data
    with events and metrics.
  prefs: []
  type: TYPE_NORMAL
- en: The application is still changing a lot and we frequently need to investigate
    functional issues for specific requests and optimize requests from the long tail
    of latency. So, tracing still plays a key role in day-to-day work. We might need
    to instrument more layers in the application to capture logical operations or
    add applications-specific context. At the same time, we may find some auto-instrumentations
    too verbose and can tune them to remove unnecessary attributes or suppress some
    spans.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, we need to capture profiles or use diagnostic tools to investigate
    lower-level issues, so having a continuous profiler or adding `dotnet-monitor`
    in a sidecar could make such investigations much easier.
  prefs: []
  type: TYPE_NORMAL
- en: If the application (or some parts of it) becomes more stable due to having fewer
    and fewer issues, it makes sense to remove non-essential traces and reduce the
    sampling rate for stable services or endpoints. Tail-based sampling could help
    capture more traces for failures or long requests.
  prefs: []
  type: TYPE_NORMAL
- en: When the application is not changing anymore except for basic maintenance, but
    more importantly, if it does not have many issues and investigations, it could
    be reasonable to reduce tracing to just incoming and outgoing requests, potentially
    forwarding logs to colder storage.
  prefs: []
  type: TYPE_NORMAL
- en: Performance-sensitive scenarios
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instrumentation introduces performance overhead. Between traces, metrics, and
    logs, traces are the most expensive. When instrumenting an HTTP request, this
    overhead is usually negligible compared to the call itself.
  prefs: []
  type: TYPE_NORMAL
- en: But in some cases, instrumentation costs can be too high. For example, when
    returning cached responses or rate-limiting requests across all service instances,
    logging or tracing all such calls can significantly impact performance. Moreover,
    if we recorded a trace for every request, a DDOS attack or buggy client might
    kill our observability pipeline, if not the whole service.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing overhead, to some extent, can be reduced with sampling, which protects
    the observability pipeline and reduces the number of allocations when populating
    attributes, but a new `Activity` is created and a new `SpanId` is generated, regardless
    of the sampling decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding tracing for a hot path should be done with caution. Keep the number
    of traces to a minimum: trace incoming requests only if the corresponding request
    is going to be processed by your application and avoid tracing outgoing network
    calls to the leaf services if they’re extremely fast or reliable. For example,
    it makes sense to report an event instead of a span when talking to Redis.'
  prefs: []
  type: TYPE_NORMAL
- en: Metrics are the most performant telemetry signal and should be preferred for
    a hot path when possible. For example, reporting the Redis call duration as a
    metric with a cache hit/miss dimension would likely be cheaper than an event.
    And for tracing purposes, we can put a hit/miss flag as an attribute on an existing
    current span (for example, one representing an incoming request).
  prefs: []
  type: TYPE_NORMAL
- en: Recording exceptions and errors is usually fine from a performance perspective
    since exceptions create a huge overhead anyway. But in the case of a failure storm,
    we get too many of them, so it’s a good idea to throttle exception reporting.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing efficient, useful, but minimalistic instrumentation usually requires
    several iterations. Luckily, OpenTelemetry provides a set of semantic conventions
    for common scenarios that can help with it. Let’s see how.
  prefs: []
  type: TYPE_NORMAL
- en: Staying consistent with semantic conventions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important questions we’re yet to discuss is what information
    to add to telemetry signals to make them useful – this is where OpenTelemetry
    semantic conventions come into play.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic conventions describe what information to collect for specific technologies,
    such as HTTP or gRPC calls, database operations, messaging scenarios, serverless
    environments, runtime metrics, resource attributes, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic conventions are part of the OpenTelemetry specification and have been
    published in the specification repository at [https://github.com/open-telemetry/opentelemetry-specification](https://github.com/open-telemetry/opentelemetry-specification).
    They apply to all instrumentations authored by the OpenTelemetry project.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, semantic conventions are in an experimental status.
    The community is actively working on stabilization and the attributes I use in
    this book will likely be renamed or changed in other ways.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of semantic conventions is to unify telemetry collection for specific
    scenarios or technology across languages, runtimes, and libraries. For example,
    traces and metrics for all HTTP clients look very similar, making it possible
    to visualize or query HTTP telemetry or diagnose problems in the same way for
    any application. Let’s look at HTTP semantic conventions to understand how they
    work and give you an idea of what other conventions look like.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic conventions for HTTP requests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The conventions cover tracing and metrics for incoming and outgoing HTTP requests.
    Spans with `client` kind describe outgoing requests, whereas `server` spans describe
    incoming requests. Instrumentations create a new span for each attempt.
  prefs: []
  type: TYPE_NORMAL
- en: '`client` HTTP spans contain attributes that describe the request, response,
    and remote destination. According to the current version, a minimal HTTP client
    instrumentation must report the following attributes: `http.method`, `http.url`,
    `net.peer.name`, `net.peer.port`, and `http.status_code`.'
  prefs: []
  type: TYPE_NORMAL
- en: If a response is not received, the `http.status_code` attribute is not populated;
    instead, the span status would indicate an error and provide a status description
    that explained what happened. The port (`net.peer.port`) attribute may be skipped
    if it’s 80 or 443\. Other attributes are required, so all instrumentations that
    follow conventions must populate them in all scenarios. These attributes, combined
    with the span start timestamp, duration, and status, provide a minimal necessary
    description of the HTTP request.
  prefs: []
  type: TYPE_NORMAL
- en: All the attributes except `http.status_code` should be provided at the span
    start time – this allows us to make sampling decisions based on these attributes.
  prefs: []
  type: TYPE_NORMAL
- en: You probably noticed that the host and port information is available inside
    the URL and via separate attributes. The URL is a high-cardinality attribute,
    but the host and port are very likely to be of low cardinality, so reporting all
    of them allows us to unify instrumentation code and report traces and metrics
    in one place. It also makes it possible to calculate metrics from traces and simplify
    queries.
  prefs: []
  type: TYPE_NORMAL
- en: Minimal HTTP server instrumentation reports the `http.method`, `http.status_code`,
    `http.scheme`, `http.target`, `net.host.name`, `net.host.port`, and `http.route`
    attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Since HTTP servers don’t have full URLs readily available, instrumentations
    don’t construct them and report individual URL components instead. Route information
    is provided by an HTTP framework such as ASP.NET Core and even there, you may
    handle requests in middleware without using routing. Reporting route is quite
    important for metrics, as we’ve seen in [*Chapter 7*](B19423_07.xhtml#_idTextAnchor115),
    *Adding Custom Metrics*, so if you don’t have the route available out of the box,
    you might want to provide one manually to distinguish different classes of API
    calls. HTTP client and server instrumentations usually also report recommended
    attributes, such as the `User-Agent` header, request and response content length,
    HTTP protocol version, and remote IP address.
  prefs: []
  type: TYPE_NORMAL
- en: Conventions also standardize attribute value types – for example, `http.status_code`
    has an integer type, simplifying comparison at query time.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the full HTTP tracing conventions at [https://opentelemetry.io/docs/reference/specification/trace/semantic_conventions/http](https://opentelemetry.io/docs/reference/specification/trace/semantic_conventions/http).
  prefs: []
  type: TYPE_NORMAL
- en: Metrics are based on the same tracing attributes and cover request duration,
    content size, and the number of active requests on servers. The metrics conventions
    are available at [https://opentelemetry.io/docs/reference/specification/metrics/semantic_conventions/http-metrics](https://opentelemetry.io/docs/reference/specification/metrics/semantic_conventions/http-metrics).
  prefs: []
  type: TYPE_NORMAL
- en: HTTP semantic conventions provide a good set of default things to collect. You
    can move between teams, companies, and web frameworks, or start using a different
    programming language, but OpenTelemetry instrumentations would provide a common
    baseline everywhere.
  prefs: []
  type: TYPE_NORMAL
- en: Having a reliable set of required attributes helps the backend visualize traces
    and service maps, build dashboards, and automate analysis and issue detection.
  prefs: []
  type: TYPE_NORMAL
- en: General considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you need to instrument some specific technology or scenario and no suitable
    instrumentation library is available, make sure to also check whether there is
    an applicable semantic convention. By following it, you will be able to leverage
    any experiences built on top of it by your observability backend, prevent inconsistent
    signals coming from different parts of your system, and also save some time designing
    and polishing your signals.
  prefs: []
  type: TYPE_NORMAL
- en: But what if you want to instrument something very specific to your application,
    such as adding spans for logical operations or adding usage metrics? Let’s see.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we’ve seen in [*Chapter 6*](B19423_06.xhtml#_idTextAnchor098), *Tracing Your
    Code*, we can create a new `Activity` instance without specifying any parameters.
    By default, it’s named after the caller method and has an `internal` kind.
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry recommends using low-cardinality span names. HTTP client span
    names follow the `HTTP <method>` pattern (for example, `HTTP GET`), while the
    HTTP server span name looks like `<method> <route>` (for example, `GET /users/{userId}`).
    The span name describes a class of operations and is frequently used to group
    common spans.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important property is the span kind: it helps backends visualize and
    query traces them. `client` spans represent outgoing requests – their context
    is propagated over the wire, and they become remote parents of `server` spans.
    When instrumenting a remote call, we would typically want to create a new span
    for each attempt so that we know how long an attempt took, how many there were,
    and what the backoff interval was.'
  prefs: []
  type: TYPE_NORMAL
- en: The `server` spans are those that track incoming requests; they either have
    no parents or have a remote parent.
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry also defines `consumer` and `producer` kinds – they are used in
    asynchronous scenarios where a request-response pattern is not applicable. A `producer`
    span could be a parent of a `consumer` span (or be linked to it), but it usually
    ends before the corresponding `consumer` span.
  prefs: []
  type: TYPE_NORMAL
- en: All other spans are `internal`. For example, to represent an I/O operation or
    a local long-running call, we should use the `internal` kind. When instrumenting
    client library calls or logical operations that can do multiple HTTP requests
    underneath, it makes sense to describe them as `internal` spans.
  prefs: []
  type: TYPE_NORMAL
- en: If an operation ends with an error, we should reflect it with a span status,
    but this can be tricky. For example, HTTP semantic conventions recommend setting
    the status to an error on the client side if a response was not received, there
    were too many redirects, or when the status code was in the 4xx or 5xx ranges.
    But for HTTP servers, a 4xx response does not indicate an error and should be
    left unset. Even for client requests, status codes such as 404 (`Not Found`) do
    not necessarily indicate an error and can be used to check whether some resource
    exists.
  prefs: []
  type: TYPE_NORMAL
- en: When recording errors, the status description can be used to record some predictable
    and short information about it, such as its exception type and/or message. Exceptions
    follow their own semantic conventions – we discussed this in [*Chapter 6*](B19423_06.xhtml#_idTextAnchor098),
    *Tracing Your Code*. They can be huge (because of stack traces), so we should
    avoid recording handled exceptions.
  prefs: []
  type: TYPE_NORMAL
- en: Attributes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Application-specific context or details about an operation can be recorded in
    attributes. Before inventing a new attribute name, make sure you check existing
    semantic conventions to see whether something similar is defined there already.
    For example, you can use general network attributes to describe remote destinations
    or host and RPC calls.
  prefs: []
  type: TYPE_NORMAL
- en: If you must create a new attribute, use a short name that consists of basic
    Latin characters. OpenTelemetry recommends using namespaces to avoid naming collisions
    (they are delimited with the dot (`.`) character) and using `snake_case` to separate
    words. For example, in `http.status_code`, `http` is a namespace. So, if you’re
    defining a new attribute specific to your company, it makes sense to use the company
    name in the namespace.
  prefs: []
  type: TYPE_NORMAL
- en: The number of attributes per span is limited to 128 by default, but this limit
    can be increased.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping consistent names and value types across your system can be challenging,
    so it’s a good idea to come up with some registry to keep them consistent.
  prefs: []
  type: TYPE_NORMAL
- en: So, which information would you add to attributes? Anything that describes your
    operation, except sensitive information or secrets. Be cautious with long values
    and avoid adding something that needs to be serialized or calculated – use verbose
    logging for it.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also a good idea to avoid duplication and record a reasonable set of information,
    moving static attributes to resources instead of spans.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When creating instruments, we can provide a name, unit, and description.
  prefs: []
  type: TYPE_NORMAL
- en: Instrument names are case-insensitive and consist of alphanumeric characters,
    underscores, dots, and dashes. Instrument names must be short – up to 63 characters.
  prefs: []
  type: TYPE_NORMAL
- en: Instrument names are formatted similarly to attribute names and support namespaces
    – for example, the `http.server.active_requests` counter or the `http.server.duration`
    histogram, which represent the number of active HTTP requests and server-side
    duration of requests, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Units usually follow UCUM standards ([https://ucum.org/](https://ucum.org/))
    and it’s important to keep them consistent for the same instrument across the
    whole system.
  prefs: []
  type: TYPE_NORMAL
- en: Attribute naming conventions are common between different signals and usually,
    metrics rely on a subset of tracing attributes. The most important characteristic
    of metric attributes is low cardinality, which we described in [*Chapter 7*](B19423_07.xhtml#_idTextAnchor115),
    *Adding* *Custom Metrics*.
  prefs: []
  type: TYPE_NORMAL
- en: Before adding custom metrics, make sure to check whether there is an existing
    instrumentation library or an OpenTelemetry semantic convention. For example,
    there is a generic one for RPC requests, process and system resource utilization
    metrics, databases, and other technology-specific ones, such as Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we discussed suggestions and recommendations for telemetry
    collection. To describe some scenario or operation, we usually need multiple signals:
    tracing enables correlation and causation, logs provide additional information
    not covered by traces, events collect usage information, and metrics optimize
    instrumentations, queries, and alerts.'
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your application’s needs and stability, you can control costs by
    tuning the sampling rate on tracing and using metrics for performance data and
    events for usage reports.
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry semantic conventions provide instrumentation recipes for common
    technologies and concepts. By following them, you can create high-quality instrumentations
    with good defaults that you can tune to your needs. Observability backends can
    provide their best experiences to help you visualize, detect anomalies, and perform
    other semi-automated analyses. For proprietary technologies or application-specific
    instrumentation, where there are no existing conventions, it’s important to follow
    general the OpenTelemetry specification and naming patterns and report telemetry
    consistently across your system.
  prefs: []
  type: TYPE_NORMAL
- en: With this, you should be ready to instrument advanced scenarios with multiple
    signals and provide a rich context while following the available practices. In
    the next chapter, we’re going to apply these skills to instrument gRPC streaming
    calls that are not covered by any existing conventions. Stay tuned.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Can you instrument a tiny stateless RESTful microservice with tracing only?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When working on an application that processes thousands of requests per second
    on each instance, which sampling rate would you choose?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Your application communicates with client devices over web sockets. How would
    you approach instrumenting this communication?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
