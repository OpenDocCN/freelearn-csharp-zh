<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-73">
    <a id="_idTextAnchor073">
    </a>
    
     4
    
   </h1>
   <h1 id="_idParaDest-74">
    <a id="_idTextAnchor074">
    </a>
    
     Performance Optimization and Profiling
    
   </h1>
   <p>
    
     In this chapter, we delve into the crucial aspect of ensuring that our code not only functions correctly but also runs efficiently.
    
    
     While writing code that works is essential, optimizing its performance is equally vital, especially in today’s fast-paced digital landscape where users expect swift and
    
    
     
      responsive applications.
     
    
   </p>
   <p>
    
     In the preceding chapters, we laid the groundwork by mastering unit testing,
    
    <strong class="bold">
     
      test-driven development
     
    </strong>
    
     (
    
    <strong class="bold">
     
      TDD
     
    </strong>
    
     ), advanced debugging strategies, and code analysis.
    
    
     Now, we shift our focus to the optimization and profiling tools available within Visual Studio 2022, empowering ourselves to
    
    <a id="_idIndexMarker257">
    </a>
    
     fine-tune our applications for
    
    
     
      optimal performance.
     
    
   </p>
   <p>
    
     Throughout this chapter, we will explore various techniques and methodologies aimed at enhancing the speed, responsiveness, and resource efficiency of our software.
    
    
     We’ll begin by introducing the fundamentals of performance optimization and the importance of utilizing profiling tools to identify bottlenecks and areas
    
    
     
      for improvement.
     
    
   </p>
   <p>
    
     Key topics covered in this chapter include
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      Introduction to
     
     
      
       performance optimization
      
     
    </li>
    <li>
     
      Utilizing Visual Studio
     
     
      
       profiling tools
      
     
    </li>
    <li>
     
      Analyzing
     
     
      
       CPU usage
      
     
    </li>
    <li>
     
      Memory profiling
     
     
      
       and optimization
      
     
    </li>
    <li>
     
      Optimizing
     
     
      
       database interaction
      
     
    </li>
   </ul>
   <p>
    
     By mastering these concepts and techniques, we’ll learn how to pinpoint performance issues, optimize critical sections of our code base, and ensure that our applications deliver a seamless user experience under various workloads
    
    
     
      and conditions.
     
    
   </p>
   <p>
    
     Let’s begin our journey toward building faster, more efficient
    
    
     
      software together.
     
    
   </p>
   <h1 id="_idParaDest-75">
    <a id="_idTextAnchor075">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     While writing this chapter, I used the following version of
    
    
     
      Visual Studio:
     
    
   </p>
   <ul>
    <li>
     
      Visual Studio Enterprise 2022
     
     
      
       Version
      
     
     
      
       17.12.0
      
     
    </li>
    <li>
     
      
       Preview 1.0
      
     
    </li>
   </ul>
   <p>
    
     The code files for this chapter can found
    
    
     
      at
     
    
    <a href="https://github.com/PacktPublishing/Mastering-Visual-Studio-2022/tree/main/ch04">
     
      
       https://github.com/PacktPublishing/Mastering-Visual-Studio-2022/tree/main/ch04
      
     
    </a>
    
     
      .
     
    
   </p>
   <h1 id="_idParaDest-76">
    <a id="_idTextAnchor076">
    </a>
    
     Introduction to performance optimization
    
   </h1>
   <p>
    
     Performance optimization
    
    <a id="_idIndexMarker258">
    </a>
    
     in software development involves refining an application to operate with maximum efficiency, minimizing resource consumption such as memory, CPU, and bandwidth.
    
    
     This process includes analyzing performance at various development stages, often focusing on enhancing efficiency once a stable version of the product has
    
    
     
      been established.
     
    
   </p>
   <p>
    
     The main step in our performance optimization process is
    
    <em class="italic">
     
      identifying bottlenecks
     
    </em>
    
     , as it allows us to pinpoint the specific areas of our code that are causing performance issues.
    
    <strong class="bold">
     
      Bottlenecks
     
    </strong>
    
     are
    
    <a id="_idIndexMarker259">
    </a>
    
     points in our code where the execution slows down significantly, often due to resource constraints or inefficient algorithms.
    
    
     By identifying these bottlenecks, we can focus our optimization efforts on where they will have the most impact, leading to more efficient and faster applications.
    
    
     This targeted approach not only improves the performance of our application but also enhances the overall user experience by reducing load times and improving responsiveness.
    
    
     Furthermore, identifying bottlenecks early in the development process can prevent costly rework and delays, as it becomes more economical to address performance issues before they become entrenched in our application’s architecture.
    
    
     In essence, the ability to identify and address bottlenecks is a key skill for us as developers aiming to create high-performance applications, ensuring that our software runs smoothly
    
    
     
      and efficiently.
     
    
   </p>
   <p>
    
     Performance optimization could be performed at different levels and offers different paths
    
    
     
      of exploration:
     
    
   </p>
   <ul>
    <li>
     
      At the design level, the architecture of the system plays a crucial role in its performance.
     
     
      Designing with performance in mind involves making strategic decisions about how the system interacts with hardware and network resources.
     
     
      For instance, reducing network latency can be achieved by minimizing network requests, ideally making a single request instead of multiple.
     
     
      This approach not only reduces the load on the network but also simplifies the application’s architecture, making it easier to maintain
     
     
      
       and scale.
      
     
    </li>
    <li>
     
      Implementation choices in the
     
     <a id="_idIndexMarker260">
     </a>
     
      source code also have a significant impact on system optimization.
     
     
      Employing efficient coding practices is crucial for achieving system optimization.
     
     
      This includes avoiding unnecessary computations, which can significantly reduce the computational overhead of the application.
     
     
      For example, using
     
     <strong class="bold">
      
       Language-Integrated Query
      
     </strong>
     
      (
     
     <strong class="bold">
      
       LINQ
      
     </strong>
     
      ) for
     
     <a id="_idIndexMarker261">
     </a>
     
      data manipulation can lead to code that is more readable yet potentially more efficient than traditional loops.
     
     
      Additionally, utilizing C#’s asynchronous programming features, such as async and await, can help to improve the responsiveness of applications by allowing them to perform other tasks while waiting for long-running operations
     
     
      
       to complete.
      
     
    </li>
    <li>
     
      The choice of algorithms and data structures is a critical factor in system performance.
     
     
      Efficient algorithms and data structures can significantly reduce the time complexity of operations, allowing the system to handle larger datasets and more complex tasks with ease.
     
     
      Ideally, algorithms should operate at constant (O(1)), logarithmic (O(log n)), linear (O(n)), or log-linear (O(n log n)) time complexities.
     
     
      Algorithms with quadratic complexity (O(n^2)) can struggle to scale efficiently, especially as the size of the dataset grows.
     
     
      Similarly, abstract data types, which encapsulate data and operations in a single entity, can be more efficient for system optimization compared to more complex
     
     
      
       data structures.
      
     
    </li>
    <li>
     
      Optimizing at the build level involves making decisions during the build process that can tailor the application for specific processor models or environments.
     
     
      This can include disabling unnecessary software features, which can reduce the size of the executable and improve its performance.
     
     
      Additionally, build-level optimizations can involve the use of compiler flags that enable specific optimizations, such as loop unrolling or function inlining, which can improve the efficiency of the
     
     
      
       generated code.
      
     
    </li>
   </ul>
   <p>
    
     You may have noticed that I categorized the algorithm by complexity using Big O notation; let’s take a refresher about
    
    
     
      this notation.
     
    
   </p>
   <p>
    
     Big O notation
    
    <a id="_idIndexMarker262">
    </a>
    
     serves as a mathematical representation utilized to characterize the performance or complexity of algorithms, particularly concerning their runtime behavior with increasing
    
    
     
      input size.
     
    
   </p>
   <p>
    
     Proficiency in
    
    <a id="_idIndexMarker263">
    </a>
    
     understanding Big O notation holds significant importance for software engineers.
    
    
     It equips us with the ability to evaluate and contrast the efficiency of diverse algorithms.
    
    
     Consequently, we can make well-informed decisions regarding the selection of algorithms suitable for
    
    
     
      specific scenarios.
     
    
   </p>
   <p>
    
     The following points outline the well-known Big
    
    
     
      O notations:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Constant time O(1)
      
     </strong>
     
      : Execution
     
     <a id="_idIndexMarker264">
     </a>
     
      time remains unchanged irrespective of
     
     
      
       input data
      
     
    </li>
    <li>
     <strong class="bold">
      
       Logarithmic time O(log n)
      
     </strong>
     
      : Complexity
     
     <a id="_idIndexMarker265">
     </a>
     
      increases by one unit for each doubling of
     
     
      
       input data
      
     
    </li>
    <li>
     <strong class="bold">
      
       Linear time O(n)
      
     </strong>
     
      : Execution
     
     <a id="_idIndexMarker266">
     </a>
     
      time increases linearly with the size of the
     
     
      
       input data
      
     
    </li>
    <li>
     <strong class="bold">
      
       Log-linear time O(n log n)
      
     </strong>
     
      : Complexity
     
     <a id="_idIndexMarker267">
     </a>
     
      grows as a combination of linear
     
     
      
       and logarithmic
      
     
    </li>
    <li>
     <strong class="bold">
      
       Quadratic time O(n^2)
      
     </strong>
     
      : Time taken
     
     <a id="_idIndexMarker268">
     </a>
     
      is proportional to the square of the number
     
     
      
       of elements
      
     
    </li>
    <li>
     <strong class="bold">
      
       Cubic time O(n^3)
      
     </strong>
     
      : Execution
     
     <a id="_idIndexMarker269">
     </a>
     
      time is proportional to the cube of the number
     
     
      
       of elements
      
     
    </li>
    <li>
     <strong class="bold">
      
       Exponential time O(2^n)
      
     </strong>
     
      : Time
     
     <a id="_idIndexMarker270">
     </a>
     
      doubles for every new
     
     
      
       element added
      
     
    </li>
    <li>
     <strong class="bold">
      
       Factorial time O(n!)
      
     </strong>
     
      : Complexity
     
     <a id="_idIndexMarker271">
     </a>
     
      grows factorially based on the size of
     
     
      
       the dataset
      
     
    </li>
   </ul>
   <p>
    
     Now that we’ve explored the fundamental principles of performance optimization in software development, let’s delve into practical methods for identifying and addressing performance issues.
    
    
     Some invaluable tools for our endeavor are Visual Studio profiling tools.
    
    
     By leveraging the capabilities of these tools, we can gain deeper insights into our application’s performance and streamline the optimization process.
    
    
     Let’s examine how Visual Studio profiling tools can be effectively utilized to enhance the performance of our
    
    
     
      software applications.
     
    
   </p>
   <h1 id="_idParaDest-77">
    <a id="_idTextAnchor077">
    </a>
    
     Utilizing Visual Studio profiling tools
    
   </h1>
   <p>
    
     Visual Studio profiling tools
    
    <a id="_idIndexMarker272">
    </a>
    
     are a suite of performance measurement and diagnostic tools integrated into Visual Studio.
    
    
     In this section, we will explore how to use it and explore what tools are offered to explore and monitor
    
    
     
      our applications.
     
    
   </p>
   <p>
    
     To open the
    
    <a id="_idIndexMarker273">
    </a>
    
     Performance Profiler, we go to
    
    <strong class="bold">
     
      Debug
     
    </strong>
    
     |
    
    <strong class="bold">
     
      Performance Profiler
     
    </strong>
    
     or press
    
    <em class="italic">
     
      Alt
     
    </em>
    
     +
    
    
     <em class="italic">
      
       F2
      
     </em>
    
    
     
      .
     
    
   </p>
   <div><div><img alt="Figure 4.1 – Performance Profiler" src="img/B22218_04_1.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.1 – Performance Profiler
    
   </p>
   <p>
    
     Before clicking on the
    
    <strong class="bold">
     
      Start
     
    </strong>
    
     button, let’s review the various options the Performance Analyzer feature offers us for profiling
    
    
     
      our applications.
     
    
   </p>
   <h2 id="_idParaDest-78">
    <a id="_idTextAnchor078">
    </a>
    
     Analyzing .NET asynchronous events
    
   </h2>
   <p>
    
     .NET’s async and await
    
    <a id="_idIndexMarker274">
    </a>
    
     features allow us to analyze the asynchronous
    
    <a id="_idIndexMarker275">
    </a>
    
     events that are organized chronologically, displaying start time, end time, and duration, in a table of activities that occurred during our profiling session.
    
    
     Tasks are labeled in the
    
    
     <strong class="bold">
      
       Name
      
     </strong>
    
    
     
      column.
     
    
   </p>
   <div><div><img alt="Figure 4.2 – .NET Async" src="img/B22218_04_2.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.2 – .NET Async
    
   </p>
   <p>
    
     If a task isn’t complete within the collection session, an
    
    <em class="italic">
     
      Incomplete
     
    </em>
    
     label appears in the
    
    <strong class="bold">
     
      End
     
    </strong>
    
     <strong class="bold">
      
       Time
      
     </strong>
    
    
     
      column.
     
    
   </p>
   <p>
    
     To investigate a specific task or activity, we can right-click the row and select
    
    <strong class="bold">
     
      Go To Source File
     
    </strong>
    
     to see where in our code that
    
    
     
      activity happened.
     
    
   </p>
   <p>
    
     Understanding the characteristics of async performance is crucial.
    
    
     While async methods are meant to enhance application responsiveness and scalability, they do introduce some overhead due to the state machine created by the compiler.
    
    
     However, this overhead is generally minimal and efficient for
    
    
     
      high-throughput scenarios.
     
    
   </p>
   <p>
    
     When comparing the
    
    <a id="_idIndexMarker276">
    </a>
    
     performance of async versus sync code, we need to consider the nature of the operations being performed.
    
    
     For operations inherently asynchronous (such as
    
    <strong class="bold">
     
      input/output
     
    </strong>
    
     (
    
    <strong class="bold">
     
      I/O
     
    </strong>
    
     )-bound operations), async methods
    
    <a id="_idIndexMarker277">
    </a>
    
     can provide significant performance
    
    <a id="_idIndexMarker278">
    </a>
    
     benefits by freeing up threads to handle other requests while waiting.
    
    
     However, for CPU-bound operations, the performance difference between async and sync methods may
    
    
     
      be negligible.
     
    
   </p>
   <p>
    
     For effective performance monitoring of our application using .NET’s async and await features, we can utilize the
    
    <strong class="bold">
     
      .NET Async
     
    </strong>
    
     tool in
    
    <a id="_idIndexMarker279">
    </a>
    
     Visual Studio for detailed analysis of asynchronous code execution.
    
    
     Additionally, external tools such as Stackify Retrace offer comprehensive monitoring capabilities for .NET applications, including support for async/await.
    
    
     Understanding the performance characteristics of async methods and the nature of the operations being performed is crucial for making informed decisions about when to employ async
    
    
     
      programming patterns.
     
    
   </p>
   <h2 id="_idParaDest-79">
    <a id="_idTextAnchor079">
    </a>
    
     Monitoring with .NET Counters
    
   </h2>
   <p>
    
     Visual Studio 2022 integrates
    
    <a id="_idIndexMarker280">
    </a>
    
     the .
    
    <strong class="bold">
     
      NET Counters
     
    </strong>
    
     tool, which is an advanced feature that allows
    
    <a id="_idIndexMarker281">
    </a>
    
     developers like us to visualize performance counters over time directly within the Visual Studio profiler.
    
    
     This tool proves to be particularly useful for monitoring and analyzing various metrics of .NET applications, such as CPU usage, garbage collector heap size, and any custom counters we might have implemented in our applications.
    
    
     This integration enables us to leverage the power of .NET Counters directly from within the Visual Studio environment, providing a more seamless and integrated experience for performance monitoring
    
    
     
      and analysis.
     
    
   </p>
   <p>
    
     Visual Studio 2022 enhanced the .NET Counters tool to support two innovative metrics:
    
    <strong class="source-inline">
     
      UpDownCounter
     
    </strong>
    
     and
    
    <strong class="source-inline">
     
      ObservableCounter
     
    </strong>
    
     .
    
    <strong class="source-inline">
     
      UpDownCounter
     
    </strong>
    
     enables real-time tracking of values with both incremental and decremental changes, which is ideal for monitoring dynamic values such as user interactions in web applications.
    
    
     On the other hand,
    
    <strong class="source-inline">
     
      ObservableCounter
     
    </strong>
    
     autonomously manages aggregated totals, offering customizable callback delegates for precise control.
    
    
     This feature can be particularly useful for optimizing server resources
    
    <a id="_idIndexMarker282">
    </a>
    
     by efficiently managing active
    
    
     
      session totals.
     
    
   </p>
   <p>
    
     Additionally, a filter flyout feature in the tool allows us to conveniently filter data points based on tags.
    
    
     This dynamic adjustment feature significantly enhances the flexibility and streamlining of monitoring dynamic values in
    
    
     
      our projects.
     
    
   </p>
   <p>
    
     While collecting data, we can see live values of .NET Counters and view graphs of multiple
    
    
     
      counters simultaneously.
     
    
   </p>
   <div><div><img alt="Figure 4.3 – .NET Counters" src="img/B22218_04_3.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.3 – .NET Counters
    
   </p>
   <p>
    
     Once we stop
    
    <a id="_idIndexMarker283">
    </a>
    
     collection, we get a detailed report showing minimum, maximum, and average values for each counter in the selected time range.
    
    
     This report provides
    
    <a id="_idIndexMarker284">
    </a>
    
     us with a comprehensive overview of the performance metrics of our application, helping us identify and address performance bottlenecks
    
    
     
      more effectively.
     
    
   </p>
   <h2 id="_idParaDest-80">
    <a id="_idTextAnchor080">
    </a>
    
     Tracking .NET Object Allocation
    
   </h2>
   <p>
    
     The
    
    <strong class="bold">
     
      .NET Object Allocation Tracking
     
    </strong>
    
     tool proves
    
    <a id="_idIndexMarker285">
    </a>
    
     particularly valuable for understanding allocation patterns in .NET code and optimizing an application’s memory usage by
    
    <a id="_idIndexMarker286">
    </a>
    
     identifying the most memory-intensive methods.
    
    
     However, it’s important to note that while this tool can reveal where objects are allocated, it does not elucidate why an object remains
    
    
     
      in memory.
     
    
   </p>
   <p>
    
     We initiate the tool by clicking on the
    
    <strong class="bold">
     
      Start
     
    </strong>
    
     button, and the tool offers the
    
    <strong class="bold">
     
      Start with collection paused
     
    </strong>
    
     option before starting the profiler if we prefer to commence with data
    
    
     
      collection paused.
     
    
   </p>
   <div><div><img alt="Figure 4.4 – Start analysis" src="img/B22218_04_4.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.4 – Start analysis
    
   </p>
   <p>
    
     This allows us to manually commence data collection by clicking the
    
    <strong class="bold">
     
      Record
     
    </strong>
    
     button in the diagnostic
    
    
     
      session view.
     
    
   </p>
   <p>
    
     After executing the tool, we can halt the collection or close our application to review the data.
    
    
     The tool furnishes comprehensive memory allocation data, including the location of objects that are allocating memory and the amount of memory those objects are allocating.
    
    
     It also displays the number of objects that occupy memory within a specific allocation type or function, as well as the amount of memory consumed instead of the number
    
    
     
      of objects.
     
    
   </p>
   <p>
    
     Additionally, the tool
    
    <a id="_idIndexMarker287">
    </a>
    
     presents a
    
    <strong class="bold">
     
      Collections
     
    </strong>
    
     view, which illustrates how many
    
    <a id="_idIndexMarker288">
    </a>
    
     objects were collected or retained during garbage collection, offering insights into garbage collection events such as the type of garbage collection, the reason for the event, and the size of
    
    <a id="_idIndexMarker289">
    </a>
    
     the
    
    <strong class="bold">
     
      large object heap
     
    </strong>
    
     (
    
    <strong class="bold">
     
      LOH
     
    </strong>
    
     ) and
    
    <strong class="bold">
     
      pinned object heap
     
    </strong>
    
     (
    
    <strong class="bold">
     
      POH
     
    </strong>
    
     ) after
    
    <a id="_idIndexMarker290">
    </a>
    
     the garbage collector
    
    
     
      was executed.
     
    
   </p>
   <h2 id="_idParaDest-81">
    <a id="_idTextAnchor081">
    </a>
    
     Viewing the event
    
   </h2>
   <p>
    
     The
    
    <strong class="bold">
     
      Events
     
    </strong>
    <strong class="bold">
     
      Viewer
     
    </strong>
    
     tool allows us to
    
    <a id="_idIndexMarker291">
    </a>
    
     examine the collected information after our application
    
    <a id="_idIndexMarker292">
    </a>
    
     has stopped, like a post-mortem analysis.
    
    
     It displays a list of events such as module load, thread start, and system configuration, aiding in diagnosing our application’s performance within the Visual
    
    
     
      Studio profiler.
     
    
   </p>
   <p>
    
     To enable
    
    <a id="_idIndexMarker293">
    </a>
    
     custom
    
    <strong class="bold">
     
      Event Tracing for Windows
     
    </strong>
    
     (
    
    <strong class="bold">
     
      ETW
     
    </strong>
    
     ) events, we can instrument our code with custom events and configure them to appear in the Events Viewer.
    
    
     This involves setting up the provider’s name and GUID for our custom event code.
    
    
     For C# custom event code, we set the same provider’s name value that we used when declaring our event code, and for the native custom event code, we set the provider GUID based on the GUID for the custom event code.
    
    
     Once configured, these custom events will appear in the Events Viewer when we collect a
    
    
     
      diagnostics trace.
     
    
   </p>
   <p>
    
     The Events Viewer
    
    <a id="_idIndexMarker294">
    </a>
    
     can display up to 20,000 events at a time.
    
    
     To focus on specific events, we can filter the display by selecting the
    
    <strong class="bold">
     
      Event
     
    </strong>
    
     filter.
    
    
     Additionally, we can see the percentage of the total number of events that occurred for each provider, providing a breakdown of where our time is being spent.
    
    
     This filtering and breakdown help in
    
    <a id="_idIndexMarker295">
    </a>
    
     identifying the most relevant events for
    
    
     
      our analysis.
     
    
   </p>
   <p>
    
     For example, to
    
    <a id="_idIndexMarker296">
    </a>
    
     enable custom
    
    
     
      ETW events:
     
    
   </p>
   <ol>
    <li>
     
      First, build our custom
     
     
      
       event code.
      
     
    </li>
    <li>
     
      Then, in the
     
     <strong class="bold">
      
       Performance Profiler
      
     </strong>
     
      window (accessed via
     
     <em class="italic">
      
       Alt
      
     </em>
     
      +
     
     <em class="italic">
      
       F2
      
     </em>
     
      ), enable
     
     <strong class="bold">
      
       Events Viewer
      
     </strong>
     
      and select the
     
     <strong class="bold">
      
       Settings
      
     </strong>
     
      icon next
     
     
      
       to it.
      
     
    </li>
    <li>
     
      In the dialog box, enable the first row under
     
     <strong class="bold">
      
       Additional Providers
      
     </strong>
     
      and configure it according to our custom
     
     
      
       event code.
      
     
    </li>
    <li>
     
      For native custom event code, we set the
     
     <strong class="bold">
      
       Provider GUID
      
     </strong>
     
      value and leave the
     
     <strong class="bold">
      
       Provider Name
      
     </strong>
     
      value empty or use its
     
     
      
       default value.
      
     
    </li>
    <li>
     
      For C# custom event code, we set the same
     
     <strong class="bold">
      
       Provider Name
      
     </strong>
     
      value that we used when declaring our event code, leaving the
     
     <strong class="bold">
      
       Provider GUID
      
     </strong>
     
      empty.
     
     
      After configuration, our custom events will appear in the Events Viewer when we collect a
     
     
      
       diagnostics trace.
      
     
    </li>
   </ol>
   <p>
    
     This tool is particularly useful
    
    <a id="_idIndexMarker297">
    </a>
    
     for us as developers looking to diagnose performance issues or understand the behavior of our applications in
    
    <a id="_idIndexMarker298">
    </a>
    
     detail.
    
    
     It provides a comprehensive view of our application’s activity and
    
    
     
      performance metrics.
     
    
   </p>
   <h2 id="_idParaDest-82">
    <a id="_idTextAnchor082">
    </a>
    
     Analyzing File I/O
    
   </h2>
   <p>
    
     The
    
    <strong class="bold">
     
      File IO
     
    </strong>
    
     tool in Visual
    
    <a id="_idIndexMarker299">
    </a>
    
     Studio is a powerful profiling tool designed to help us optimize our file
    
    <a id="_idIndexMarker300">
    </a>
    
     I/O operations, thereby improving the performance of our applications.
    
    
     This tool is particularly useful for diagnosing slow loading times and inefficient data read or write patterns.
    
    
     It provides detailed information about file read and write operations during a profiling session, including the files accessed, the target process for each file, and aggregate information for each file.
    
    
     The tool also offers features such as the
    
    <strong class="bold">
     
      Duplication Factor
     
    </strong>
    
     , which
    
    <a id="_idIndexMarker301">
    </a>
    
     helps us identify whether more data is being read or written than necessary, indicating potential areas for optimization, such as caching results of
    
    
     
      file reads.
     
    
   </p>
   <p>
    
     The File IO tool provides file read and write information with files read during the profiling session.
    
    
     The files are autogenerated in a report after collection and arranged by their target process with aggregate information displayed.
    
    
     If we right-click on one of the rows, we can go to the source in our code.
    
    
     If an aggregate row was read multiple times, we can expand it to see the individual read operations for that file with its frequency, if they were read
    
    
     
      multiple times.
     
    
   </p>
   <h2 id="_idParaDest-83">
    <a id="_idTextAnchor083">
    </a>
    
     Analyzing database performance
    
   </h2>
   <p>
    
     The
    
    <strong class="bold">
     
      Database Profiler
     
    </strong>
    
     tool in Visual
    
    <a id="_idIndexMarker302">
    </a>
    
     Studio is a feature designed to help us developers
    
    <a id="_idIndexMarker303">
    </a>
    
     diagnose and optimize the performance of database operations within our applications.
    
    
     It proves particularly useful for applications that use .NET Core with either ADO.NET or Entity Framework Core, offering insights into database activities such as query execution times, the connection strings used, and where in the code these queries are being made.
    
    
     This tool is part of the Performance Profiler in Visual Studio and has been available since Visual Studio 2019 version
    
    
     
      16.3 onwards.
     
    
   </p>
   <p>
    
     Once we start the profiling session, we interact with our application as we would normally, performing actions that we suspect might be causing database performance issues.
    
    
     After completing our actions, we stop the collection in Visual Studio.
    
    
     The tool then processes the collected data and displays a table of the queries that occurred during our profiling session, along with a graph showing the timing and frequency of these queries.
    
    
     This information can help us identify long-running queries, inefficient connection strings, or other performance bottlenecks in our
    
    
     
      database operations.
     
    
   </p>
   <p>
    
     Furthermore, the Database Profiler tool supports analyzing traces collected using dotnet trace, allowing us to collect data from anywhere .NET Core runs, including Linux, and analyze it in Visual Studio.
    
    
     This feature is particularly useful for diagnosing performance issues in environments where Visual Studio is not installed or for scripting the collection of
    
    
     
      performance traces.
     
    
   </p>
   <p>
    
     In summary, the Database Profiler tool
    
    <a id="_idIndexMarker304">
    </a>
    
     in Visual Studio is a powerful diagnostic tool for us
    
    <a id="_idIndexMarker305">
    </a>
    
     developers working with .NET Core applications that interact with databases.
    
    
     It provides detailed insights into database operations, helping us identify and resolve performance issues
    
    
     
      more effectively.
     
    
   </p>
   <h2 id="_idParaDest-84">
    <a id="_idTextAnchor084">
    </a>
    
     Instrumenting our .NET applications
    
   </h2>
   <p>
    
     In Visual Studio, we utilize
    
    <a id="_idIndexMarker306">
    </a>
    
     instrumentation tools for collecting precise call counts and call times, which are crucial for performance profiling and optimization.
    
    
     There are two main types of instrumentation
    
    <a id="_idIndexMarker307">
    </a>
    
     
      methods available:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Static instrumentation
      
     </strong>
     
      : This
     
     <a id="_idIndexMarker308">
     </a>
     
      method involves modifying the program’s files before they run.
     
     
      We use a tool called VSInstr to insert
     
     <a id="_idIndexMarker309">
     </a>
     
      instrumentation code into the application’s binaries.
     
     
      Static instrumentation is effective for collecting detailed timing data but can break strong name signing due to file modification.
     
     
      It also requires files to be deployed in a specific order, which can be cumbersome for
     
     
      
       complex programs.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Dynamic instrumentation
      
     </strong>
     
      : Introduced in
     
     <a id="_idIndexMarker310">
     </a>
     
      Visual Studio 2022
     
     <a id="_idIndexMarker311">
     </a>
     
      version 17.5, this method does not alter the program’s files.
     
     
      Instead, it loads the files into memory and modifies them at runtime to collect instrumentation information.
     
     
      Dynamic instrumentation provides more accurate information, especially for smaller parts of the program, and allows for the investigation of specific code sections.
     
     
      It avoids the issue of breaking strong name signing since the instrumentation happens at runtime.
     
     
      This approach simplifies the process of finding and
     
     <a id="_idIndexMarker312">
     </a>
     
      instrumenting files, especially in
     
     <a id="_idIndexMarker313">
     </a>
     
      
       complex programs.
      
     
    </li>
   </ul>
   <p>
    
     This tool is like the CPU Usage tool but focuses on wall clock time instead of CPU utilization, making it suitable for scenarios where understanding the execution time of functions
    
    
     
      is critical.
     
    
   </p>
   <p>
    
     By using the
    
    <a id="_idIndexMarker314">
    </a>
    
     aforementioned tools, we can gather valuable insights into our
    
    
     
      application’s performance.
     
    
   </p>
   <p>
    
     However, to ensure optimal accuracy in our performance measurements, it’s advisable to profile our applications in the
    
    <strong class="bold">
     
      Release
     
    </strong>
    
     mode rather than the
    
    <strong class="bold">
     
      Debug
     
    </strong>
    
     mode.
    
    
     Debug builds can introduce additional overhead, potentially skewing
    
    
     
      our results.
     
    
   </p>
   <p>
    
     When we find ourselves needing to inspect variable values or use breakpoints during analysis, we should consider leveraging the debugger-integrated tools found in the
    
    <strong class="bold">
     
      Diagnostic Tools
     
    </strong>
    
     window.
    
    
     These tools are tailored for such tasks and may offer a more suitable environment for
    
    
     
      our analysis.
     
    
   </p>
   <p>
    
     To gain a holistic understanding of our application’s performance, we can take advantage of Visual Studio’s capability to utilize multiple profiling tools simultaneously.
    
    
     This approach allows us to examine our application’s performance from different perspectives, providing a more
    
    
     
      comprehensive analysis.
     
    
   </p>
   <p>
    
     You may have noticed that I have missed three tools offered by the Profiler Performance tools.
    
    
     I will highlight them in the next sections, beginning with the CPU
    
    
     
      Usage analyzer.
     
    
   </p>
   <h1 id="_idParaDest-85">
    <a id="_idTextAnchor085">
    </a>
    
     Analyzing CPU Usage
    
   </h1>
   <p>
    
     The
    
    <strong class="bold">
     
      CPU Usage
     
    </strong>
    
     tool
    
    <a id="_idIndexMarker315">
    </a>
    
     in Visual Studio is designed to help us identify high CPU utilization
    
    <a id="_idIndexMarker316">
    </a>
    
     and other related performance issues in our applications.
    
    
     It can be used for both local trace sessions and production environments, providing insights into where optimizations might be needed.
    
    
     To use the CPU Usage tool without the debugger, we should set the solution configuration to
    
    <strong class="bold">
     
      Release
     
    </strong>
    
     and select
    
    <strong class="bold">
     
      Local Windows Debugger (or Local Machine)
     
    </strong>
    
     as the deployment target.
    
    
     Under available tools, we select
    
    <strong class="bold">
     
      CPU Usage
     
    </strong>
    
     , and then we
    
    
     
      select
     
    
    
     <strong class="bold">
      
       Start
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     If we enable the start with collection paused option, data collection will not begin until we select the
    
    <strong class="bold">
     
      Record
     
    </strong>
    
     button in the diagnostic session view.
    
    
     After the app starts, the diagnostic session begins, displaying CPU usage data.
    
    
     Once we’re finished collecting data, we select
    
    <strong class="bold">
     
      Stop Collection
     
    </strong>
    
     .
    
    
     The tool then analyzes the data and displays a report, which can be filtered and searched for specific threads
    
    
     
      or nodes.
     
    
   </p>
   <p>
    
     The CPU Usage tool is particularly useful for diagnosing performance issues in our code base, identifying bottlenecks, and understanding CPU usage patterns.
    
    
     It provides automatic insights and various views of our data, enabling us to analyze and diagnose performance issues effectively.
    
    
     This tool is beneficial in production and difficult to debug at the moment but can be captured and analyzed using this tool to understand potential causes and
    
    
     
      suggest fixes.
     
    
   </p>
   <p>
    
     The CPU Usage tool is particularly useful for diagnosing slow-downs, process hangs, and identifying bottlenecks in your code base, making it an essential tool for optimizing
    
    
     
      application performance.
     
    
   </p>
   <p>
    
     When running this profiler tools spot the usage of CPU/second and collect traces generating a report with a graph to visualize the peak and valley of
    
    
     
      CPU usage.
     
    
   </p>
   <p>
    
     When we first start the
    
    <a id="_idIndexMarker317">
    </a>
    
     CPU Usage toll, it will collect a large amount of data per second
    
    <a id="_idIndexMarker318">
    </a>
    
     to analyze what is going on in our application, and by default, it’s set at
    
    
     <strong class="source-inline">
      
       1000
      
     </strong>
    
    
     
      samples/second.
     
    
   </p>
   <p>
    
     We can personalize the rate of the number of samples collected by second, by clicking on the gear at the right of the
    
    <strong class="bold">
     
      CPU Usage
     
    </strong>
    
     label in the profile console (
    
    
     <em class="italic">
      
       Figure 4
      
     </em>
    
    <em class="italic">
     
      .1
     
    </em>
    
     ) before hitting the
    
    <strong class="bold">
     
      Start
     
    </strong>
    
     button.
    
    
     Depending on our needs, we can adjust the accuracy of their results and the data
    
    
     
      collection time.
     
    
   </p>
   <div><div><img alt="Figure 4.5 – The CPU Usage settings" src="img/B22218_04_5.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.5 – The CPU Usage settings
    
   </p>
   <p>
    
     When we stop the collection
    
    <a id="_idIndexMarker319">
    </a>
    
     or shut down our application, CPU usage tools generate
    
    <a id="_idIndexMarker320">
    </a>
    
     reports.
    
    
     Initially, we land on the summary page, which displays a swim lane graph, the
    
    <strong class="bold">
     
      Top Functions
     
    </strong>
    
     section, and the
    
    <strong class="bold">
     
      Hot
     
    </strong>
    
     <strong class="bold">
      
       Path
      
     </strong>
    
    
     
      section.
     
    
   </p>
   <div><div><img alt="Figure 4.6 – The Summary page" src="img/B22218_04_6.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.6 – The Summary page
    
   </p>
   <p>
    
     Here, we can narrow down the potential bottleneck by right-clicking and dragging on the graph to surround the
    
    <a id="_idIndexMarker321">
    </a>
    
     peak we want to focus on.
    
    
     By doing that, we effectively filter the
    
    <a id="_idIndexMarker322">
    </a>
    
     graph
    
    
     
      by time.
     
    
   </p>
   <p>
    
     By clicking on the
    
    <strong class="bold">
     
      Open details…
     
    </strong>
    
     link, we can digg deeper into the five
    
    
     
      other views:
     
    
   </p>
   <ul>
    <li>
     
      <strong class="bold">
       
        Caller/Callee
       
      </strong>
     
    </li>
    <li>
     
      <strong class="bold">
       
        Call Tree
       
      </strong>
     
    </li>
    <li>
     
      <strong class="bold">
       
        Modules
       
      </strong>
     
    </li>
    <li>
     
      <strong class="bold">
       
        Functions
       
      </strong>
     
    </li>
    <li>
     
      <strong class="bold">
       
        Flame Graph
       
      </strong>
     
    </li>
   </ul>
   <p>
    
     Let’s understand each of these
    
    
     
      in detail:
     
    
   </p>
   <ul>
    <li>
     
      In the
     
     <strong class="bold">
      
       Caller/Callee
      
     </strong>
     
      view, we can observe the relationship between a selected function and the functions that called it (
     
     <strong class="bold">
      
       Calling Functions
      
     </strong>
     
      ) as well as the functions it called (
     
     <strong class="bold">
      
       Called Functions
      
     </strong>
     
      ).
     
     
      It offers insights into the total time taken by the selected function and its percentage of the overall app running time.
     
     
      Additionally, it provides information on the time spent exclusively in the function body (
     
     <strong class="bold">
      
       Function Body
      
     </strong>
     
      ).
     
     
      This view helps us understand the impact of a function on the application’s performance and identify
     
     
      
       potential bottlenecks.
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 4.7 – Caller/Callee" src="img/B22218_04_7.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.7 – Caller/Callee
    
   </p>
   <ul>
    <li>
     
      The
     
     <strong class="bold">
      
       Call Tree
      
     </strong>
     
      view
     
     <a id="_idIndexMarker323">
     </a>
     
      presents a hierarchical representation of the function
     
     <a id="_idIndexMarker324">
     </a>
     
      calls in our application, starting from the top-level pseudo-node.
     
     
      It includes system and framework code (under an
     
     <strong class="source-inline">
      
       [External Code]
      
     </strong>
     
      node) as well as
     
     
      
       user-code methods.
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 4.8 – The Call Tree view" src="img/B22218_04_8.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.8 – The Call Tree view
    
   </p>
   <p class="list-inset">
    
     This view is useful for understanding the sequence and nesting of function calls, aiding in the identification of the most CPU-intensive paths in
    
    
     
      our application.
     
    
   </p>
   <ul>
    <li>
     
      In the
     
     <strong class="bold">
      
       Modules
      
     </strong>
     
      view, we
     
     <a id="_idIndexMarker325">
     </a>
     
      can see a list of modules containing functions, which
     
     <a id="_idIndexMarker326">
     </a>
     
      can be particularly useful when analyzing
     
     
      
       external code.
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 4.9 – The Modules view" src="img/B22218_04_9.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.9 – The Modules view
    
   </p>
   <p class="list-inset">
    
     It helps us understand which modules are contributing the most to CPU usage, assisting in the identification of third-party libraries or system components that might be
    
    
     
      impacting performance.
     
    
   </p>
   <ul>
    <li>
     
      The
     
     <strong class="bold">
      
       Functions
      
     </strong>
     
      view lists
     
     <a id="_idIndexMarker327">
     </a>
     
      all the functions in our application, sorted by their
     
     <a id="_idIndexMarker328">
     </a>
     
      CPU usage.
     
     
      It provides detailed information such as
     
     <strong class="bold">
      
       Total CPU
      
     </strong>
     
      (the time spent by the function and any functions it called) and
     
     <strong class="bold">
      
       Self CPU
      
     </strong>
     
      (the time spent exclusively in the
     
     
      
       function body).
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 4.10 – The Functions view" src="img/B22218_04_10.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.10 – The Functions view
    
   </p>
   <p class="list-inset">
    
     This view is essential for identifying the most resource-intensive functions in our application and focusing on
    
    
     
      optimization efforts.
     
    
   </p>
   <ul>
    <li>
     
      A
     
     <strong class="bold">
      
       flame graph
      
     </strong>
     
      is a
     
     <a id="_idIndexMarker329">
     </a>
     
      visualization that represents the call stack of our
     
     <a id="_idIndexMarker330">
     </a>
     
      application over time.
     
     
      It helps in identifying hot paths, that is sequences of function calls that consume a significant amount of
     
     <a id="_idIndexMarker331">
     </a>
     
      CPU time.
     
     
      The width of each function in the graph corresponds to the amount of CPU time it consumes, making it easier to spot performance bottlenecks.
     
     
      The
     
     <strong class="bold">
      
       Flame Graph
      
     </strong>
     
      view is particularly useful for understanding the overall CPU usage patterns of our application and pinpointing specific areas
     
     
      
       for optimization.
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 4.11 – Flame Graph" src="img/B22218_04_11.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.11 – Flame Graph
    
   </p>
   <p class="list-inset">
    
     We can flip the view according to our preferences by using the
    
    <strong class="bold">
     
      Flip Flame Graph
     
    </strong>
    
     option and zooming in on our point
    
    
     
      of interest.
     
    
   </p>
   <p>
    
     For debugging sessions, the
    
    <a id="_idIndexMarker332">
    </a>
    
     CPU Usage tool can be accessed through the
    
    <strong class="bold">
     
      Diagnostic Tools
     
    </strong>
    
     window, which appears automatically unless turned off.
    
    
     We can select whether to see
    
    <strong class="bold">
     
      CPU Usage
     
    </strong>
    
     ,
    
    <strong class="bold">
     
      Memory Usage
     
    </strong>
    
     , or both, with the
    
    <strong class="bold">
     
      Select Tools
     
    </strong>
    
     setting on the toolbar.
    
    
     The tool is enabled by default for CPU
    
    
     
      utilization analysis.
     
    
   </p>
   <p>
    
     When the debugger pauses, the
    
    <a id="_idIndexMarker333">
    </a>
    
     CPU Usage tool in the
    
    <strong class="bold">
     
      Diagnostic Tools
     
    </strong>
    
     window collects information about the functions executing in our application, listing the functions performing work and providing a timeline graph for focusing on specific segments of the
    
    
     
      sampling session.
     
    
   </p>
   <p>
    
     While CPU usage and memory usage are related, they do not have a direct correlation.
    
    
     The impact of one on the other depends on the specific tasks being performed by the applications running on the system.
    
    
     Monitoring both metrics is crucial for optimizing system performance and effectively managing
    
    
     
      energy consumption.
     
    
   </p>
   <p>
    
     Now that we’ve explored how to analyze CPU usage, let’s continue our journey by monitoring
    
    
     
      memory allocation.
     
    
   </p>
   <h1 id="_idParaDest-86">
    <a id="_idTextAnchor086">
    </a>
    
     Memory profiling and optimization
    
   </h1>
   <p>
    
     Just as a reminder, a memory leak
    
    <a id="_idIndexMarker334">
    </a>
    
     occurs when a computer program mishandles memory allocations, leading to unreleased memory that is no longer needed.
    
    
     .NET applications are generally less vulnerable to memory leaks due to automatic garbage collection and the fact that .NET applications are written in managed code.
    
    
     This means that the runtime has control over memory allocation and deallocation.
    
    
     However, if we produce code with smells or misuse the disposable pattern, memory leaks can
    
    
     
      still occur.
     
    
   </p>
   <p>
    
     In this section, we will explore how we can leverage Visual Studio to resolve memory leaks using the
    
    <strong class="bold">
     
      Memory Usage
     
    </strong>
    
     profiling tools and then the diagnostic tools available
    
    
     
      while debugging.
     
    
   </p>
   <h2 id="_idParaDest-87">
    <a id="_idTextAnchor087">
    </a>
    
     Using the Memory Usage tools
    
   </h2>
   <p>
    
     To find and resolve a memory leak, we
    
    <a id="_idIndexMarker335">
    </a>
    
     can use the
    
    <strong class="bold">
     
      Memory Usage
     
    </strong>
    
     tool in Visual Studio.
    
    
     It is a robust profiling feature designed to monitor and analyze our application’s memory usage effectively.
    
    
     It supports various application types, including .NET, ASP.NET, C++, and mixed-mode applications.
    
    
     This versatile tool can be utilized both with and without the debugger, catering to different development scenarios.
    
    
     One of its key strengths lies in its ability to identify memory leaks and inefficient memory
    
    
     
      usage patterns.
     
    
   </p>
   <p>
    
     During our diagnostic sessions, the Memory Usage tool provides a timeline graph illustrating memory fluctuations as our application runs.
    
    
     This graphical representation aids in pinpointing areas of our code that may be collecting or generating data inefficiently, potentially leading to memory leaks or excessive
    
    
     
      memory usage.
     
    
   </p>
   <div><div><img alt="Figure 4.12 – Memory usage graph" src="img/B22218_04_12.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.12 – Memory usage graph
    
   </p>
   <p>
    
     We can take detailed snapshots of our application’s memory state at different intervals using this tool.
    
    
     These snapshots can then be compared to pinpoint the root causes of memory issues.
    
    
     They showcase critical metrics such as the total number of objects and bytes in memory, along with the differences between
    
    
     
      consecutive snapshots.
     
    
   </p>
   <div><div><img alt="Figure 4.13 – The Memory Usage report types" src="img/B22218_04_13.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.13 – The Memory Usage report types
    
   </p>
   <p>
    
     We can delve deeper into
    
    <a id="_idIndexMarker336">
    </a>
    
     these snapshots through detailed Memory Usage report views, gaining insights into the types and instances present in each snapshot or the variances between
    
    
     
      two snapshots.
     
    
   </p>
   <p>
    
     Once data collection is stopped, the Memory Usage tool presents an overview page containing memory usage data.
    
    
     This overview helps us grasp the memory impact of our application and spot areas that could benefit
    
    
     
      from optimization.
     
    
   </p>
   <p>
    
     For more advanced analysis, the Memory Usage tool provides insights into various memory issues such as duplicate strings, sparse arrays, and event handler leaks, particularly beneficial for managed
    
    
     
      memory analysis.
     
    
   </p>
   <div><div><img alt="Figure 4.14 – The Memory Usage report insights" src="img/B22218_04_14.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.14 – The Memory Usage report insights
    
   </p>
   <p>
    
     Leveraging these insights allows us to identify and resolve common memory problems
    
    
     
      more efficiently.
     
    
   </p>
   <p>
    
     Some scenarios could need to focus and dig deeper into some specific part of our code base, and for that, we can use the diagnostic tools available in
    
    
     
      debugging mode.
     
    
   </p>
   <h2 id="_idParaDest-88">
    <a id="_idTextAnchor088">
    </a>
    
     Exploring Memory Usage while debugging
    
   </h2>
   <p>
    
     For this part, I
    
    <a id="_idIndexMarker337">
    </a>
    
     will create a small console app that you can retrieve on GitHub.
    
    
     The following code includes a
    
    <strong class="source-inline">
     
      while
     
    </strong>
    
     loop that fills a List of string with a large
    
    
     
      random string:
     
    
   </p>
   <pre class="source-code">
List&lt;string&gt; list = new();
while (true)
{
    list.Add(GenRandomStr(10000));
    Thread.Sleep(1);
}
static string GenRandomStr(int length)
{
    Random rnd = new();
    var chars = new List&lt;char&gt;();
    for (var i = 0; i &lt; length; i++)
    {
        var a = (char)rnd.Next(65, 122);
        chars.Add(a);
    }
    return string.Concat(chars);
}</pre>
   <p>
    
     In the preceding
    
    <a id="_idIndexMarker338">
    </a>
    
     code block, we begin by setting breakpoints in our application where we suspect the memory leak might be occurring.
    
    
     This could be at the start of a function or a region of code that we suspect is causing the
    
    
     
      memory leak.
     
    
   </p>
   <p>
    
     For this example, since the code is straightforward, we will set breakpoints at the closing bracket of
    
    
     
      the loop.
     
    
   </p>
   <p>
    
     Additionally, in more complex scenarios, we can utilize other profiler tools to identify suspect locations in our
    
    
     
      code base.
     
    
   </p>
   <p>
    
     Next, we will use the
    
    <strong class="bold">
     
      diagnostic tools
     
    </strong>
    
     , and by
    
    <a id="_idIndexMarker339">
    </a>
    
     default, it opens at the launch of the debugger.
    
    
     If not, you
    
    <a id="_idIndexMarker340">
    </a>
    
     can reach it by navigating to the top bar menu and clicking
    
    <strong class="bold">
     
      Debug
     
    </strong>
    
     |
    
    <strong class="bold">
     
      Windows
     
    </strong>
    
     |
    
    <strong class="bold">
     
      Show
     
    </strong>
    
     <strong class="bold">
      
       Diagnostic Tools
      
     </strong>
    
    
     
      .
     
    
   </p>
   <div><div><img alt="Figure 4.15 – Diagnostic Tools" src="img/B22218_04_15.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.15 – Diagnostic Tools
    
   </p>
   <p>
    
     In the
    
    <strong class="bold">
     
      Diagnostic Tools
     
    </strong>
    
     window, we retrieve the
    
    <strong class="bold">
     
      Events
     
    </strong>
    
     ,
    
    <strong class="bold">
     
      Process Memory
     
    </strong>
    
     , and
    
    <strong class="bold">
     
      CPU
     
    </strong>
    
     usage graph.
    
    
     For our example, we will observe the
    
    <strong class="bold">
     
      Process Memory
     
    </strong>
    
     section, where memory usage increases
    
    <a id="_idIndexMarker341">
    </a>
    
     as the loop iterates.
    
    
     Additionally, we can monitor the work of the garbage collector to assess its impact on
    
    
     
      memory allocation.
     
    
   </p>
   <p>
    
     To analyze the heap stack, we can take a snapshot with the
    
    <strong class="bold">
     
      Take Snapshot
     
    </strong>
    
     option.
    
    
     This action will generate a report of the memory state at different intervals, as we observed in the profiler tools
    
    
     
      description previously.
     
    
   </p>
   <div><div><img alt="Figure 4.16 – A Memory Usage snapshot" src="img/B22218_04_16.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.16 – A Memory Usage snapshot
    
   </p>
   <p>
    
     In
    
    
     <em class="italic">
      
       Figure 4
      
     </em>
    
    <em class="italic">
     
      .16
     
    </em>
    
     , we can observe that the
    
    <strong class="bold">
     
      Heap Size
     
    </strong>
    
     and number of
    
    <strong class="bold">
     
      Objects
     
    </strong>
    
     dangerously increase between our snapshots.
    
    
     This indicates poor deallocation, or in other words, a
    
    
     
      memory leak.
     
    
   </p>
   <p>
    
     We can dig deeper by clicking on the
    
    <strong class="bold">
     
      View Heap
     
    </strong>
    
     option to explore
    
    <strong class="bold">
     
      Object Type
     
    </strong>
    
     by size
    
    
     
      and number.
     
    
   </p>
   <div><div><img alt="Figure 4.17 – Memory Usage" src="img/B22218_04_17.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.17 – Memory Usage
    
   </p>
   <p>
    
     Here, we can see that the cause of our memory leak is
    
    <strong class="source-inline">
     
      List&lt;String&gt;
     
    </strong>
    
     , which will
    
    
     
      never deallocate.
     
    
   </p>
   <p>
    
     While CPU and memory can provide insight into the performance of our application, most of the latency observed in software comes from the database interactions and in the next section, we will see how to
    
    
     
      optimize them.
     
    
   </p>
   <h1 id="_idParaDest-89">
    <a id="_idTextAnchor089">
    </a>
    
     Optimizing database interactions
    
   </h1>
   <p>
    
     Visual Studio 2022 introduces a new analyzer tool
    
    <a id="_idIndexMarker342">
    </a>
    
     named
    
    <strong class="bold">
     
      Database Profiler
     
    </strong>
    
     .
    
    
     It allows us to explore the database
    
    <a id="_idIndexMarker343">
    </a>
    
     interactions in
    
    
     
      our application.
     
    
   </p>
   <p>
    
     In this section, we will explore how to use the Database Profiler tools and how they can help us identify query optimization opportunities in our
    
    
     
      code base.
     
    
   </p>
   <p>
    
     To open it, we go through
    
    <strong class="bold">
     
      Performance Profiler
     
    </strong>
    
     and select
    
    <strong class="bold">
     
      Database
     
    </strong>
    
     , where we can combine it with
    
    <strong class="bold">
     
      CPU Usage
     
    </strong>
    
     for
    
    
     
      more insight.
     
    
   </p>
   <div><div><img alt="Figure 4.18 – Selecting the Database and CPU Usage tools" src="img/B22218_04_18.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.18 – Selecting the Database and CPU Usage tools
    
   </p>
   <p>
    
     When we click on the
    
    <strong class="bold">
     
      Start
     
    </strong>
    
     button, the profiler will launch our application and start collecting data.
    
    
     During this time, we can perform long-running actions on our application to identify the root cause
    
    
     
      of latency.
     
    
   </p>
   <p>
    
     After clicking on
    
    <a id="_idIndexMarker344">
    </a>
    
     the
    
    <strong class="bold">
     
      Stop Collection
     
    </strong>
    
     button, we launch the generation of
    
    
     
      the report.
     
    
   </p>
   <div><div><img alt="Figure 4.19 – Database report" src="img/B22218_04_19.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.19 – Database report
    
   </p>
   <p>
    
     The database report will show us a table with information about queries executed; by default, it shows columns with the
    
    
     
      following information:
     
    
   </p>
   <ul>
    <li>
     
      The start time of
     
     
      
       the query
      
     
    </li>
    <li>
     
      The SQL code of
     
     
      
       the query
      
     
    </li>
    <li>
     
      The duration
     
     
      
       of execution
      
     
    </li>
    <li>
     
      The number of
     
     
      
       records affected
      
     
    </li>
    <li>
     
      The number of
     
     
      
       records reads
      
     
    </li>
   </ul>
   <p>
    
     In larger applications, we can incorporate multiple databases, such as when utilizing the
    
    <strong class="bold">
     
      Command-Query Responsibility Segregation
     
    </strong>
    
     (
    
    <strong class="bold">
     
      CQRS
     
    </strong>
    
     ) pattern
    
    <a id="_idIndexMarker345">
    </a>
    
     alongside database replication, for example.
    
    
     To help us in our investigation, we can display three more columns by right-clicking on the display one and checking which one
    
    
     
      we need.
     
    
   </p>
   <div><div><img alt="Figure 4.20 – Database report managing column" src="img/B22218_04_20.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.20 – Database report managing column
    
   </p>
   <p>
    
     The additional
    
    <a id="_idIndexMarker346">
    </a>
    
     columns are
    
    
     
      as follows:
     
    
   </p>
   <ul>
    <li>
     
      <strong class="bold">
       
        Database
       
      </strong>
     
    </li>
    <li>
     
      <strong class="bold">
       
        Connection String
       
      </strong>
     
    </li>
    <li>
     <strong class="bold">
      
       Query Source
      
     </strong>
     
      displaying the data provider used (EFCore, Dapper, ADO.NET,
     
     
      
       or Others)
      
     
    </li>
   </ul>
   <p>
    
     Coupling with the CPU Usage tools, we can easily zoom on the consuming period to examine query launch in
    
    
     
      this time.
     
    
   </p>
   <div><div><img alt="Figure 4.21 – Database report time filtered" src="img/B22218_04_21.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.21 – Database report time filtered
    
   </p>
   <p>
    
     When we identify a
    
    <a id="_idIndexMarker347">
    </a>
    
     query that might catch our attention due to its long transaction duration or large number of associated queries, we
    
    
     
      could investigate.
     
    
   </p>
   <p>
    
     Finally, in the list of queries, we can easily jump into the code source for further investigations or even refactoring, by right-clicking on the row we are interested in and selecting
    
    <strong class="bold">
     
      Go To
     
    </strong>
    
     <strong class="bold">
      
       Source File
      
     </strong>
    
   </p>
   <div><div><img alt="Figure 4.22 – Go To Source File" src="img/B22218_04_22.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 4.22 – Go To Source File
    
   </p>
   <p>
    
     The power of
    
    <a id="_idIndexMarker348">
    </a>
    
     Visual Studio profiling tools lies in the ability to combine some of its tools for a comprehensive investigation.
    
    
     My advice is to utilize the three tools highlighted in this chapter: the Memory Usage, CPU Usage, and Database tools.
    
    
     This will help in quickly identifying issues such as queries that generate excessive memory allocation and CPU utilization, especially
    
    <a id="_idIndexMarker349">
    </a>
    
     when working with
    
    <strong class="bold">
     
      Object Relational Mapping
     
    </strong>
    
     (
    
    <strong class="bold">
     
      ORMs
     
    </strong>
    
     ), such as EF Core or Dapper, that need to instantiate objects to
    
    
     
      run queries.
     
    
   </p>
   <h1 id="_idParaDest-90">
    <a id="_idTextAnchor090">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     This chapter provided key insights to leverage Visual Studio profiling tools to aid in our investigation and optimization of performance bottlenecks, resulting in improved
    
    
     
      application performance.
     
    
   </p>
   <p>
    
     Throughout this chapter, we’ve covered a range of topics, from understanding the fundamentals of performance optimization to utilizing Visual Studio’s profiling tools effectively.
    
    
     We’ve learned how to analyze CPU usage and identify memory and database bottlenecks to identify and optimize critical sections and our code base for
    
    
     
      improved performance.
     
    
   </p>
   <p>
    
     As we conclude this chapter, we mark the end of the first part of our journey in mastering core development skills.
    
    
     From unit testing and TDD to advanced debugging strategies, code analysis, and now performance optimization and profiling, you have laid a solid foundation for your
    
    
     
      development journey.
     
    
   </p>
   <p>
    
     In the upcoming chapters, we’ll continue to expand our horizons, delving into advanced topics such as multi-platform app UI development, advanced web development tools, machine learning integration, and advanced cloud integration
    
    
     
      and services.
     
    
   </p>
   <p>
    
     To start the second part, we will dive into the world of cross-platform development by exploring tools offered by Visual Studio
    
    
     
      for MAUI.
     
    
   </p>
  </div>
 

  <div><h1 id="_idParaDest-91" lang="en-US" xml:lang="en-US">
    <a id="_idTextAnchor091">
    </a>
    
     Part 2: Advancing Development Horizons
    
   </h1>
   <p>
    
     In this second part, we focus on expanding your development expertise with advanced techniques for building versatile applications leveraging Visual Studio.
    
    
     From multi-platform app UI development and advanced web tools to machine learning integration and cloud services, these chapters equip you with the skills to build modern, scalable, and intelligent applications, pushing the boundaries of your
    
    
     
      development capabilities.
     
    
   </p>
   <p>
    
     This part has the
    
    
     
      following chapters:
     
    
   </p>
   <ul>
    <li>
     <a href="B22218_05.xhtml#_idTextAnchor092">
      <em class="italic">
       
        Chapter 5
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Multi-Platform App UI Development
      
     </em>
    </li>
    <li>
     <a href="B22218_06.xhtml#_idTextAnchor112">
      <em class="italic">
       
        Chapter 6
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Advanced Web Development Tools
      
     </em>
    </li>
    <li>
     <a href="B22218_07.xhtml#_idTextAnchor124">
      <em class="italic">
       
        Chapter 7
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Machine Learning Integration
      
     </em>
    </li>
    <li>
     <a href="B22218_08.xhtml#_idTextAnchor132">
      <em class="italic">
       
        Chapter 8
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Advanced Cloud Integration and Services
      
     </em>
    </li>
   </ul>
  </div>
  <div><div></div>
  </div>
 </body></html>