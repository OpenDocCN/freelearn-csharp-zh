- en: 19 Introduction to Microservices Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before you begin: Join our book community on Discord'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Give your feedback straight to the author himself and chat to other early readers
    on our Discord server (find the "architecting-aspnet-core-apps-3e" channel under
    EARLY ACCESS SUBSCRIPTION).
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/EarlyAccess](https://packt.link/EarlyAccess)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Qr code Description automatically generated](img/file127.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The chapter covers some essential microservices architecture concepts. It is
    designed to get you started with those principles and an overview of the concepts
    surrounding microservices, which should help you make informed decisions about
    whether to go for a microservices architecture or not.Since microservices architecture
    is larger in scale than the previous application-scale patterns we visited and
    often involves complex components or setup, there is very limited C# code in the
    chapter. Instead, I explain the concepts and list open-source or commercial offerings
    that you can leverage to apply these patterns to your applications. Moreover,
    you should not aim to implement many of the pieces discussed in the chapter because
    it can be a lot of work to get them right, and they don’t add business value,
    so you are better off just using an existing implementation instead. There is
    more context about this throughout the chapter.Monolithic architecture patterns,
    such as Vertical Slice and Clean Architecture, are still good to know, as you
    can apply those to individual microservices. Don’t worry—all of the knowledge
    you have acquired since the beginning of this book is not forfeit and is still
    worthwhile.In this chapter, we cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What are microservices?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to event-driven architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with message queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the Publish-Subscribe pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing Gateway patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project – REPR.BFF—that transforms the REPR project into microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Revisiting the CQRS pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Microservices Adapter pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: What are microservices?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Microservices represent an application that is divided into multiple smaller
    applications. Each application, or microservice, interacts with the others to
    create a scalable system. Usually, microservices are deployed to the cloud as
    containerized or serverless applications.Before getting into too many details,
    here are the principles to keep in mind when building microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: Each microservice should be a cohesive unit of business.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each microservice should own its data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each microservice should be independent of the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Furthermore, everything we have studied so far—the other principles of designing
    software—applies to microservices but on another scale. For example, you don’t
    want tight coupling between microservices (solved by microservices independence),
    but the coupling is inevitable (as with any code). There are numerous ways to
    solve this problem, such as the Publish-Subscribe pattern.There are no hard rules
    about how to design microservices, how to divide them, how big they should be,
    and what to put where. Nevertheless, I’ll lay down a few foundations to help you
    get started and orient your journey into microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Cohesive unit of business
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A microservice should have a single business responsibility. Always design
    the system with the domain in mind, which should help you divide the application
    into multiple pieces. If you know **Domain-Driven Design** (**DDD**), a microservice
    will most likely represent a **Bounded Context**, which in turn is what I call
    a *cohesive unit of business*. Basically, a cohesive unit of business (or bounded
    context) is a self-contained part of the domain with limited interactions with
    other parts.Even if a **microservice** has *micro* in its name, it is more important
    to group logical operations under it than to aim at a micro-size. Don’t get me
    wrong here; if your unit is tiny, that’s even better. However, suppose you split
    a unit of business into multiple smaller parts instead of keeping it together
    (breaking cohesion); you are likely to introduce useless chattiness within your
    system (coupling between microservices). This could lead to performance degradation
    and to a system that is harder to debug, test, maintain, monitor, and deploy.
    Moreover, it is easier to split a big microservice into smaller pieces than to
    assemble multiple microservices back together. Try to apply the SRP to your microservices:
    a microservice should have only one reason to change unless you have a good reason
    to do otherwise.'
  prefs: []
  type: TYPE_NORMAL
- en: Ownership of data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each microservice should be the source of truth of its cohesive unit of business.
    A microservice should share its data through an API (a web API/HTTP, for example)
    or another mechanism (integration events, for example). It should own that data
    and not share it with other microservices directly at the database level.For instance,
    two different microservices should never access the same relational database table.
    If a second microservice needs some of the same data, it can create its own cache,
    duplicate the data, or query the owner of that data but not access the database
    directly; **never**.This data-ownership concept is probably the most critical
    part of the microservices architecture and leads to microservices independence.
    Failing at this will most likely lead to a tremendous number of problems. For
    example, if multiple microservices can read or write data in the same database
    table, each time something changes in that table, all of them must be updated
    to reflect the changes. If different teams manage the microservices, that means
    cross-team coordination. If that happens, each microservice is not independent
    anymore, which opens the floor to our next topic.
  prefs: []
  type: TYPE_NORMAL
- en: Microservice independence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At this point, we have microservices that are cohesive units of business and
    own their data. That defines **independence**.This independence allows the systems
    to scale while having minimal to no impact on the other microservices. Each microservice
    can also scale independently without needing the whole system to be scaled. Additionally,
    when the business requirements grow, each part of that domain can evolve independently.Furthermore,
    you could update one microservice without impacting the others or even have a
    microservice go offline without the whole system stopping.Of course, microservices
    have to interact with one another, but the way they do should define how well
    your system runs. A little like Vertical Slice architecture, you are not limited
    to using one set of architectural patterns; you can independently make specific
    decisions for each microservice. For example, you could choose a different way
    for how two microservices communicate with each other versus two others. You could
    even use different programming languages for each microservice.
  prefs: []
  type: TYPE_NORMAL
- en: I recommend sticking to one or a few programming languages for smaller businesses
    and organizations, as you most likely have fewer developers, and each has more
    to do. Based on my experience, you want to ensure business continuity when people
    leave and make sure you can replace them and not sink the ship due to some obscure
    technologies used here and there (or too many technologies).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that we’ve covered the basics, let’s jump into the different ways microservices
    can communicate using event-driven architecture.
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to event-driven architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Event-driven architecture** (**EDA**) is a paradigm that revolves around
    consuming streams of events, or data in motion, instead of consuming static states.What
    I define by a static state is the data stored in a relational database table or
    other types of data stores, like a NoSQL documents store. That data is dormant
    in a central location and waiting for actors to consume and mutate it. It is stale
    between every mutation; the data (a record, for example) represents a finite state.On
    the other hand, data in motion is the opposite: you consume the ordered events
    and determine the change in state that each event brings or what process the program
    should trigger in reaction to an event.What is an event? People often interchange
    the words event, message, and command. Let’s try to clarify this:'
  prefs: []
  type: TYPE_NORMAL
- en: A message is a piece of data that represents something.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A message can be an object, a JSON string, bytes, or anything else your system
    can interpret.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An event is a message that represents something that happened in the past.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A command is a message sent to tell one or more recipients to do something.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A command is sent (past tense), so we can also consider it an event.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A message usually has a payload (or body), headers (metadata), and a way to
    identify it (this can be through the body or headers).We can use events to divide
    a complex system into smaller pieces or have multiple systems talk to each other
    without creating tight coupling. Those systems could be subsystems or external
    applications, such as microservices.Like a REST API''s **Data Transfer Objects
    (DTOs)**, events become the data contracts that tie the multiple systems together
    (coupling). It is essential to think about that carefully when designing events.
    Of course, we cannot foresee the future, so we can only do so much to get it perfect
    the first time. We can version the events to improve maintainability.EDA is a
    fantastic way of breaking tight coupling between microservices but requires rewiring
    your brain to learn this newer paradigm. Tooling is becoming more mature, and
    expertise is less scarce than more linear ways of thinking (like using point-to-point
    communication and relational databases). However, this is slowly changing and
    well worth learning.Before moving further, we can categorize events into the following
    overlapping buckets:'
  prefs: []
  type: TYPE_NORMAL
- en: Domain events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enterprise events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we explore next, all types of events play a similar role with different intents
    and scopes.
  prefs: []
  type: TYPE_NORMAL
- en: Domain events
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A domain event is a term based on DDD representing an event in the domain. This
    event could then trigger other pieces of logic to be executed subsequently. It
    allows us to divide a complex process into multiple smaller processes. Domain
    events work well with domain-centric designs, like Clean Architecture, as we can
    use them to split complex domain objects into multiple smaller pieces. Domain
    events are usually application events. For example, we can use MediatR to publish
    domain events inside an application.To summarize, **domain events integrate pieces
    of domain logic together while keeping the domain logic segregated**, leading
    to loosely coupled components that hold one domain responsibility each (single
    responsibility principle).
  prefs: []
  type: TYPE_NORMAL
- en: Integration events
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Integration events are like domain events but propagate messages to external
    systems, integrating multiple systems together while keeping them independent.
    For example, a microservice could send the `new user registered` event message
    that other microservices react to, like saving the `user id` to enable additional
    capabilities or sending a greeting email to that new user.We use a message broker
    or message queue to publish such events. We explore those after covering application
    and enterprise events.To summarize, **integration events integrate multiple systems
    together while keeping them independent**.
  prefs: []
  type: TYPE_NORMAL
- en: Application events
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An application event is an event that is internal to an application; it is just
    a matter of scope. If the event is internal to a single process, that event is
    also a domain event (most likely). If the event crosses microservices boundaries
    that your team owns (the same application), it is also an integration event. The
    event itself won’t be different; it is the reason why it exists and its scope
    that describes it as an application event or not.To summarize, **application events
    are related to a single application**.
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise events
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An enterprise event describes an event that crosses internal enterprise boundaries.
    These are tightly coupled with your organizational structure. For example, a microservice
    sends an event that other teams, part of other divisions or departments, consume.The
    governance model around those events should differ from application events only
    your team consumes and be more strict with strong oversight.Someone must consider
    who can consume that data, under what circumstances, the impact of changing the
    event schema (data contract), schema ownership, naming conventions, data-structure
    conventions, and more, or risk building an unstable data highway.
  prefs: []
  type: TYPE_NORMAL
- en: I like to see EDA as a central **data highway** in the middle of applications,
    systems, integrations, and organizational boundaries, where the events (data)
    flow between systems in a loosely coupled manner.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s like a highway where cars flow between cities (without traffic jams). The
    cities are not controlling what car goes where but are open to visitors.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: To summarize, **enterprise events are integration events that cross organizational
    boundaries**.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this overview of event-driven architecture, we defined events, messages,
    and commands. An event is a snapshot of the past, a message is data, and a command
    is an event that suggests other systems take action. Since all messages are from
    the past, calling them events is accurate. We then organized events into a few
    overlapping buckets to help identify the intents. We can send events for different
    objectives, but whether it is about designing independent components or reaching
    out to different parts of the business, an event remains a payload that respects
    a certain format (schema). That schema is the data contract (coupling) between
    the consumers of those events. That data contract is probably the most important
    piece of it all: break the contract, break the system.Now, let’s see how event-driven
    architecture can help us follow the **SOLID** principles at cloud-scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**S**: Systems are independent of each other by raising and responding to events.
    The events themselves are the glue that ties those systems together. Each piece
    has a single responsibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O**: We can modify the system’s behaviors by adding new consumers to a particular
    event without impacting the other applications. We can also raise new events to
    build a new process without affecting existing applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L**: N/A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I**: Instead of building a single system, EDA allows us to create multiple
    smaller systems that integrate through data contracts (events), and those contracts
    are the messaging interfaces of the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D**: EDA enables systems to break tight coupling by depending on the events
    (interfaces/abstractions) instead of communicating directly with one another,
    inverting the dependency flow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EDA does not only come with advantages; it also has a few drawbacks that we
    explore in subsequent sections of the chapter.Next, we explore message queues
    followed by the Publish-Subscribe pattern, two ways of interacting with events.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with message queues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A **message queue** is nothing more than a queue we leverage to send ordered
    messages. A queue works on a **First In, First Out** (**FIFO**) basis. If our
    application runs in a single process, we could use one or more `Queue<T>` instances
    to send messages between our components or a `ConcurrentQueue<T>` instance to
    send messages between threads. Moreover, queues can be managed by an independent
    program to send messages in a distributed fashion (between applications or microservices).A
    distributed message queue can add more or less features to the mix, especially
    for cloud programs that handle failures at more levels than a single server. One
    of those features is the **dead letter queue**, which stores messages that failed
    some criteria in another queue. For example, if the target queue is full, a message
    could be sent to the **dead letter queue** instead. One could requeue such messages
    by putting the message back at the end of the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Beware that requeing messages change the order of the messages. If the order
    is important in your app, consider this.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Many messaging queue protocols exist; some are proprietary, while others are
    open source. Some messaging queues are cloud-based and used *as a service*, such
    as Azure Service Bus and Amazon Simple Queue Service. Others are open source and
    can be deployed to the cloud or on-premises, such as Apache ActiveMQ.If you need
    to process messages in order and want each message to be delivered to a single
    recipient at a time, a **message queue** seems like the right choice. Otherwise,
    the **Publish-Subscribe** pattern could be a better fit for you.Here is a basic
    example that illustrates what we just discussed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.1: A publisher that enqueues a message with a subscriber that dequeues
    it](img/file128.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.1: A publisher that enqueues a message with a subscriber that dequeues
    it'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a more concrete example, in a distributed user registration process, when
    a user registers, we could want to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Send a confirmation email.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Process their picture and save one or more thumbnails.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Send an onboarding message to their in-app mailbox.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To sequentially achieve this, one operation after the other, we could do the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.2: A process flow that sequentially executes three operations that
    happen after a user creates an account](img/file129.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.2: A process flow that sequentially executes three operations that
    happen after a user creates an account'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the user would not receive the *Onboarding Message* if the process
    crashes during the *Process Thumbnail* operation. Another drawback would be that
    to insert a new operation between the *Process Thumbnail* and *Send an onboarding
    message* steps, we’d have to modify the *Send an onboarding message* operation
    (tight coupling).If the order does not matter, we could queue all the messages
    from the *Auth Server* instead, right after the user’s creation, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.3: The Auth Server is queuing the operations sequentially while
    different processes execute them in parallel](img/file130.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.3: The Auth Server is queuing the operations sequentially while different
    processes execute them in parallel'
  prefs: []
  type: TYPE_NORMAL
- en: This process is better, but the *Auth Server* now controls what should happen
    once a new user has been created. The *Auth Server* was queuing an event in the
    previous workflow that told the system that a new user registered. However, now,
    it has to be aware of the post-processing workflow to queue each operation sequentially
    to enqueue the correct commands. Doing this is not wrong in itself and is easier
    to follow when you dig into the code, but it creates tighter coupling between
    the services where the *Auth Server* is aware of the external processes. Moreover,
    it packs too many responsibilities into the *Auth Server*.
  prefs: []
  type: TYPE_NORMAL
- en: SRP-wise, why would an authentication/authorization server be responsible for
    anything other than authentication, authorization, and managing that data?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If we continue from there and want to add a new operation between two existing
    steps, we would only have to modify the *Auth Server*, which is less error-prone
    than the preceding workflow.If we want the best of both worlds, we could use the
    **Publish-Subscribe** pattern instead, which we cover next, and continue building
    on top of this example.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you need messages to be delivered sequentially, a queue might be the right
    tool. The example we explored was destined to fail from the beginning, but it
    allowed us to explore the thinking process behind designing the system. Sometimes,
    the first idea is not the best and can be improved by exploring new ways of doing
    things or learning new skills. Being open-minded to the ideas of others can also
    lead to better solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, just speaking out loud makes our own brain solve the issue by itself.
    So explain the problem to someone and see what happens.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Message queues are amazing at buffering messages for high-demand scenarios
    where an application may not be able to handle spikes of traffic. In that case,
    the messages are enqueued so the application can catch up at its own speed, reading
    them sequentially.Implementing distributed message queues requires a lot of knowledge
    and effort and is not worth it for almost all scenarios. The big cloud providers
    like AWS and Azure offer fully managed message queue systems as a service. You
    can also look at **ActiveMQ**, **RabbitMQ**, or any **Advanced Message Queuing
    Protocol** (**AMQP**) broker.One essential aspect of choosing the right queue
    system is whether you are ready and have the skills to manage your own distributed
    message queue. Suppose you want to speed up development, cut infrastructure management
    costs, and have enough money. In that case, you could use a fully managed offering
    for at least your production environment, especially if you expect a large volume
    of messages. On the other hand, using a local or on-premise instance for development
    or smaller-scale usage may save you a considerable sum of money. Choosing an open
    source system with fully managed cloud offerings is a good way to achieve both:
    low local development cost with an always available high-performance cloud production
    offering that the service provider maintains for you.Another aspect is to base
    your choice on needs. Have clear requirements and ensure the system you choose
    does what you need. Some offerings cover multiple use cases like queues and pub-sub,
    leading to a simplified tech stack requiring fewer skills.Before moving to the
    pub-sub pattern, let’s see how message queues can help us follow the **SOLID**
    principles at the app scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**S**: Helps centralize and divide responsibilities between applications or
    components without them directly knowing each other, breaking tight coupling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O**: Allows us to change the message producer’s or subscriber’s behaviors
    without the other knowing about it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L**: N/A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I**: Each message and handler can be as small as needed, while each microservice
    indirectly interacts with the others to solve the bigger problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D**: By not knowing the other dependencies (breaking tight coupling between
    microservices), each microservice depends only on the messages (abstractions)
    instead of concretions (the other microservices API).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One drawback is the delay between enqueuing a message and processing a message.
    We talk about delay and latency in more detail in subsequent sections.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the Publish-Subscribe pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Publish-Subscribe** pattern (Pub-Sub) is similar to what we did using
    **MediatR** and what we explored in the *Getting started with message queues*
    section. However, instead of sending one message to one handler (or enqueuing
    a message), we publish (send) a message (event) to zero or more subscribers (handlers).
    Moreover, the publisher is unaware of the subscribers; it only sends messages
    out, hoping for the best (also known as **fire and forget**).
  prefs: []
  type: TYPE_NORMAL
- en: Using a message queue does not mean you are limited to only one recipient.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We can use **Publish-Subscribe** in-process or in a distributed system through
    a **message broker**. The message broker is responsible for delivering the messages
    to the subscribers. Using a message broker is the way to go for microservices
    and other distributed systems since they are not running in a single process.This
    pattern has many advantages over other ways of communication. For example, we
    could recreate the state of a database by replaying the events that happened in
    the system, leading to the **event sourcing** pattern. More on that later.The
    design depends on the technology used to deliver the messages and the system's
    configuration. For example, you could use **MQTT** to deliver messages to **Internet
    of Things** (**IoT**) devices and configure them to retain the last message sent
    on each topic. That way, when a device connects to a topic, it receives the latest
    message. You could also configure a **Kafka** broker that keeps a long history
    of messages and asks for all of them when a new system connects to it. All of
    that depends on your needs and requirements.
  prefs: []
  type: TYPE_NORMAL
- en: '**MQTT and Apache Kafka**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you were wondering what MQTT is, here is a quote from their website [https://adpg.link/mqtt](https://adpg.link/mqtt):'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*“MQTT is an OASIS standard messaging protocol for the Internet of Things (IoT).
    It is designed as an extremely lightweight publish/subscribe messaging transport
    […]”*'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here is a quote from Apache Kafka’s website [https://adpg.link/kafka](https://adpg.link/kafka):'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*“Apache Kafka is an open-source distributed event streaming platform […]”*'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We cannot cover every single scenario of every system that follows every protocol.
    Therefore, I’ll highlight some shared concepts behind the Pub-Sub design pattern
    so you know how to get started. Then, you can dig into the specific technology
    you want (or need) to use.A topic is a way to organize events, a channel, a place
    to read or write specific events so consumers know where to find them. As you
    can probably imagine, sending all events to the same place is like creating a
    relational database with a single table: it would be suboptimal and hard to manage,
    use, and evolve.To receive messages, subscribers must subscribe to topics (or
    the equivalent of a topic):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.4: A subscriber subscribes to a pub-sub topic](img/file131.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.4: A subscriber subscribes to a pub-sub topic'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second part of the Pub-Sub pattern is to publish messages, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.5: A publisher is sending a message to the message broker. The
    broker then forwards that message to N subscribers, where N can be zero or more](img/file132.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.5: A publisher is sending a message to the message broker. The broker
    then forwards that message to *N* subscribers, where *N* can be zero or more'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many abstracted details here depend on the broker and the protocol. However,
    the following are the two primary concepts behind the Publish-Subscribe pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: Publishers publish messages to topics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subscribers subscribe to topics to receive messages when they are published.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security is a crucial implementation detail not illustrated here. Security is
    mandatory in most systems; not every subsystem or device should have access to
    all topics.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Publishers and subscribers could be any part of any system. For example, many
    Microsoft Azure services are publishers (for example, Blob storage). You can then
    have other Azure services (for example, Azure Functions) subscribe to those events
    and react to them.You can also use the **Publish-Subscribe** pattern inside your
    applications—there’s no need to use cloud resources for that; this can even be
    done inside the same process (we explore this in the next chapter).The most significant
    advantage of the Publish-Subscribe pattern is breaking tight coupling between
    systems. One system publishes events while others consume them without the systems
    knowing each other.That loose coupling leads to scalability, where each system
    can scale independently, and messages can be processed in parallel using the required
    resources. It is also easier to add new processes to a workflow since the systems
    are unaware of the others. To add a new process that reacts to an event, you only
    have to create a new microservice, deploy it, start to listen to one or more events,
    and process them.On the downside, the message broker can become the application’s
    single point of failure and must be configured appropriately. It is also essential
    to consider the best delivery policies for each message type. An example of a
    policy could be to ensure the delivery of crucial messages while delaying less
    time-sensitive messages and dropping unimportant messages during load surges.If
    we revisit our previous example using Publish-Subscribe, we end up with the following
    simplified workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.6: The Auth Server is publishing an event representing the creation
    of a new user. The broker then forwards that message to the three subscribers,
    who then execute their tasks in parallel](img/file133.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.6: The Auth Server is publishing an event representing the creation
    of a new user. The broker then forwards that message to the three subscribers,
    who then execute their tasks in parallel'
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on this workflow, we broke the tight coupling between the *Auth Server*
    and the post-registration process. The *Auth Server* is unaware of the workflow,
    and the individual services are unaware of each other. Moreover, if we want to
    add a new task, we only have to create or update a microservice that subscribes
    to the right topic (in this case, the “new user registered” topic).The current
    system does not support synchronization and does not handle process failures or
    retries, but it is a good start since we combine the pros of the message queue
    examples and leave the cons behind.Using an event broker inverts the dependency
    flow. The diagrams we explored show the message flow, but here’s what happens
    on the dependency sides of things:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.7: A diagram representing the inverted dependency flow of using
    the pub-sub pattern](img/file134.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.7: A diagram representing the inverted dependency flow of using the
    pub-sub pattern'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have explored the Publish-Subscribe pattern, we look at message
    brokers, then dig deeper into EDA and leverage the Publish-Subscribe pattern to
    create a persistent database of events that can be replayed: the Event Sourcing
    pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: Message brokers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A message broker is a program that allows us to send (**publish**) and receive
    (**subscribe**) messages. It plays the mediator role at scale, allowing multiple
    applications to talk to each other without knowing each other (**loose coupling**).
    The message broker is usually the central piece of any event-based distributed
    system that implements the publish-subscribe pattern.An application (**publisher**)
    publishes messages to topics, while other applications (**subscribers**) receive
    messages from those topics. The notion of **topics** may differ from one protocol
    or system to another, but all systems I know have a topic-like concept to route
    messages to the right place. For example, you can publish to the `Devices` topic
    using Kafka, but to `devices/abc-123/do-something` using MQTT.How you name your
    topics depends significantly on the system you are using and the scale of your
    installation. For example, MQTT is a lightweight event broker recommending a path-like
    naming convention. On the other hand, Apache Kafka is a full-featured event broker
    and event streaming platform that is not opinionated about topic names, leaving
    you in charge of that. Depending on the scale of your implementation, you can
    use the entity name as the topic name or may need prefixes to identify who in
    the enterprise can interact with what part of the system. Due to the small scale
    of the examples in the chapter, we stick with simple topic names, making the examples
    easier to understand.The message broker is responsible for forwarding the messages
    to the registered recipients. The lifetime of those messages can vary by broker
    or even per individual message or topic.There are multiple message brokers out
    there using different protocols. Some brokers are cloud-based, such as Azure Event
    Grid. Other brokers are lightweight and more suited for IoT, such as Eclipse Mosquitto/MQTT.
    In contrast to MQTT, others are more robust and allow for high-velocity data streaming,
    such as Apache Kafka.What message broker to use should be based on the requirements
    of the software you are building. Moreover, you are not limited to one broker.
    Nothing stops you from picking a message broker that handles the dialogs between
    your microservices and using another to handle the dialogs with external IoT devices.
    If you are building a system in Azure, want to go serverless, or prefer paying
    for SaaS components that scale without investing maintenance time, you can leverage
    Azure services such as Event Grid, Service Bus, and Queue Storage. If you prefer
    open-source software, you can choose Apache Kafka and even run a fully managed
    cloud instance as a service using Confluent Cloud if you don’t want to manage
    your own cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The event sourcing pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have explored the Publish-Subscribe pattern, learned what an event
    is, and talked about event brokers, it is time to explore **how to replay the
    state of an application**. To achieve this, we can follow the **event sourcing
    pattern**.The idea behind event sourcing is to **store a chronological list of
    events** instead of a single entity, where that collection of events becomes the
    source of truth. That way, every single operation is saved in the right order,
    helping with concurrency. Moreover, we could replay all of these events to generate
    an object’s current state in a new application, allowing us to deploy new microservices
    more easily.Instead of just storing the data, if the system propagates it using
    an event broker, other systems can cache some of it as one or more **materialized
    views**.
  prefs: []
  type: TYPE_NORMAL
- en: A **materialized view** is a model created and stored for a specific purpose.
    The data can come from one or more sources, improving performance when querying
    that data. For example, the application returns the materialized view instead
    of querying multiple other systems to acquire the data. You can view the materialized
    view as a cached entity that a microservice stores in its own database.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One of the drawbacks of event sourcing is data consistency. There is an unavoidable
    delay between when a service adds an event to the store and when all the other
    services update their materialized views. We call this phenomenon **eventual consistency**.
  prefs: []
  type: TYPE_NORMAL
- en: '**Eventual consistency** means that the data will be consistent at some point
    in the future, but not outright. The delay can be from a few milliseconds to much
    longer, but the goal is to keep that delay as small as possible.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Another drawback is the complexity of creating such a system compared to a
    single application that queries a single database. Like the microservices architecture,
    event sourcing is not just rainbows and unicorns. It comes at a price: **operational
    complexity**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In a microservices architecture, each piece is smaller, but gluing them together
    has a cost. For example, the infrastructure to support microservices is more complex
    than a monolith (one app and one database). The same goes for event sourcing;
    all applications must subscribe to one or more events, cache data (materialized
    view), publish events, and more. This **operational complexity** represents the
    shift of complexity from the application code to the operational infrastructure.
    In other words, it requires more work to deploy and maintain multiple microservices
    and databases and to fight the possible instability of network communication between
    those external systems than it does for a single application containing all of
    the code. Monoliths are simpler: they work or don’t; they rarely partially work.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A crucial aspect of event sourcing is appending new events to the store and
    never changing existing events (append-only). In a nutshell, microservices communicating
    using the Pub-Sub pattern publish events, subscribe to topics, and generate materialized
    views to serve their clients.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s explore an example of what could happen if we combine what we just studied.
    **Context**: We need to build a program that manages IoT devices. We begin by
    creating two microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: The `DeviceTwin` microservice handles an IoT device’s twin’s data (digital representation
    of the device).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Networking` microservice manages the networking-related information of
    IoT devices (how to reach a device).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As a visual reference, the final system could look as follows (we cover the
    `DeviceLocation` microservice later):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.8: Three microservices communicating using the Publish-Subscribe
    pattern](img/file135.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.8: Three microservices communicating using the Publish-Subscribe
    pattern'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the user interactions and the published events:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A user creates a twin in the system named Device 1\. The `DeviceTwin` microservice
    saves the data and publishes the `DeviceTwinCreated` event with the following
    payload:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In parallel, the `Networking` microservice must know when a device is created,
    so it subscribed to the `DeviceTwinCreated` event. When a new device is created,
    the `Networking` microservice creates default networking information for that
    device in its database; the default is `unknown`. This way, the `Networking` microservice
    knows what devices exist or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.9: A workflow representing the creation of a device twin and its
    default networking information](img/file136.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.9: A workflow representing the creation of a device twin and its
    default networking information'
  prefs: []
  type: TYPE_NORMAL
- en: 'A user then updates the networking information of that device and sets it to
    `MQTT`. The `Networking` microservice saves the data and publishes the `NetworkingInfoUpdated`
    event with the following payload:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This is demonstrated by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.10: A workflow representing updating the networking type of a device](img/file137.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.10: A workflow representing updating the networking type of a device'
  prefs: []
  type: TYPE_NORMAL
- en: 'A user changes the device’s display name to `Kitchen Thermostat`, which is
    more relevant. The `DeviceTwin` microservice saves the data and publishes the
    `DeviceTwinUpdated` event with the following payload. The payload uses **JSON
    patch** to publish only the differences instead of the whole object (see the *Further
    reading* section for more information):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram demonstrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.11: A workflow representing a user updating the name of the device
    to Kitchen Thermostat](img/file138.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.11: A workflow representing a user updating the name of the device
    to Kitchen Thermostat'
  prefs: []
  type: TYPE_NORMAL
- en: 'From there, let’s say another team designed and built a new microservice that
    organizes the devices at physical locations. This new `DeviceLocation` microservice
    allows users to visualize their devices’ location on a map, such as a map of their
    house.The `DeviceLocation` microservice subscribes to all three events to manage
    its materialized view, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: When receiving a `DeviceTwinCreated` event, it saves its unique identifier and
    display name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When receiving a `NetworkingInfoUpdated` event, it saves the communication type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When receiving a `DeviceTwinUpdated` event, it updates the device’s display
    name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When the service is deployed for the first time, it replays all events from
    the beginning (**event sourcing**); here is what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '`DeviceLocation` receives the `DeviceTwinCreated` event and creates the following
    model for that object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram demonstrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.12: The DeviceLocation microservice replaying the DeviceTwinCreated
    event to create its materialized view of the device twin](img/file139.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.12: The DeviceLocation microservice replaying the DeviceTwinCreated
    event to create its materialized view of the device twin'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `DeviceLocation` microservice receives the `NetworkingInfoUpdated` event,
    which updates the networking type to `MQTT`, leading to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram demonstrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.13: The DeviceLocation microservice replaying the NetworkingInfoUpdated
    event to update its materialized view of the device twin](img/file140.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.13: The DeviceLocation microservice replaying the NetworkingInfoUpdated
    event to update its materialized view of the device twin'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `DeviceLocation` microservice receives the `DeviceTwinUpdated` event, updating
    the device’s name. The final model looks like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram demonstrates this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.14: The DeviceLocation microservice replaying the DeviceTwinUpdated
    event to update its materialized view of the device twin](img/file141.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.14: The DeviceLocation microservice replaying the DeviceTwinUpdated
    event to update its materialized view of the device twin'
  prefs: []
  type: TYPE_NORMAL
- en: 'From there, the `DeviceLocation` microservice is initialized and ready. Users
    could set the kitchen thermostat’s location on the map or continue using the other
    microservices. When a user queries the `DeviceLocation` microservice for information
    about `Kitchen Thermostat`, it displays the **materialized view**, which contains
    all the required information without sending external requests.With that in mind,
    we could spawn new instances of the `DeviceLocation` microservice or other microservices,
    and they could generate their materialized views from past events—all of that
    with very limited to no knowledge of other microservices. In this type of architecture,
    a microservice can only know about events, not the other microservices. How a
    microservice handles events should be relevant only to that microservice, never
    to the others. The same applies to both publishers and subscribers.This example
    illustrates the event sourcing pattern, integration events, the materialized view,
    the use of a message broker, and the Publish-Subscribe pattern.In contrast, using
    direct communication (HTTP, gRPC, and so on) would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.15: Three microservices communicating directly with one another](img/file142.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.15: Three microservices communicating directly with one another'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we compare both approaches by looking at the first diagram (*Figure 16.7*),
    we can see that the message broker plays the role of a **mediator** and breaks
    the direct coupling between the microservices. By looking at the preceding diagram
    (*Figure 16.14*), we can see the tight coupling between the microservices, where
    the `DeviceLocation` microservice would need to interact with the `DeviceTwin`
    and `Networking` microservices directly to build the equivalent of its materialized
    view. Furthermore, the `DeviceLocation` microservice translates one interaction
    into three since the `Networking` microservice also talks to the `DeviceTwin`
    microservice, leading to indirect tight coupling between microservices, which
    can negatively impact performance.Suppose eventual consistency is not an option,
    or the Publish-Subscribe pattern cannot be applied or could be too hard to apply
    to your scenario. In this case, microservices can directly call each other. They
    can achieve this using HTTP, gRPC, or any other means that best suits that particular
    system’s needs.I won’t be covering this topic in this book, but one thing to be
    careful of when calling microservices directly is the indirect call chain that
    could bubble up fast. You don’t want your microservices to create a super deep
    call chain, or your system will likely become very slow. Here is an abstract example
    of what could happen to illustrate what I mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.16: A user calling microservice A, which then triggers a chain
    reaction of subsequent calls, leading to disastrous performance](img/file143.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.16: A user calling microservice A, which then triggers a chain reaction
    of subsequent calls, leading to disastrous performance'
  prefs: []
  type: TYPE_NORMAL
- en: 'In terms of the preceding diagram, let’s think about failures (for one). If
    microservice C goes offline, the whole request ends with an error. No matter the
    measures we put in place to mitigate the risks, if microservice C cannot recover,
    the system will remain down; goodbye to microservices’ promise of independence.
    Another issue is latency: ten calls are made for a single operation; that takes
    time.Such chatty systems have most likely emerged from an incorrect domain modeling
    phase, leading to multiple microservices working together to handle trivial tasks.
    Now think of *Figure 16.15* but with 500 microservices instead of 6\. That could
    be catastrophic!This type of interdependent microservices system is known as the
    **Death Star anti-pattern**. We can see the Death Star anti-pattern as a *distributed
    big ball of mud*. One way to avoid such pitfalls is to ensure that the bounded
    contexts are well segregated and that responsibilities are well distributed. A
    good domain model should allow you to avoid building a Death Star and create the
    “most correct” system possible instead. No matter the type of architecture you
    choose, if you are not building the right thing, you may end up with a big ball
    of mud or a Death Star. Of course, the Pub-Sub pattern and EDA can help us break
    the tight coupling between microservices to avoid such issues.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Publish-Subscribe pattern uses events to break tight coupling between parts
    of an application. In a microservices architecture, we can use a message broker
    and integration events to allow microservices to talk to each other indirectly.
    The different pieces are now coupled with the data contract representing the event
    (its schema) instead of each other, leading to a potential gain in flexibility.
    One risk of this type of architecture is breaking events’ consumers by publishing
    breaking changes in the event’s format without letting them know or without having
    events versioning in place so they can adapt to the changes. Therefore, it is
    critical to think about event schema evolutions thoroughly. Most systems evolve,
    as will events, but since schemas are the glue between systems in a Publish-Subscribe
    model, it is essential to treat them as such. Some brokers, like Apache Kafka,
    offer a schema store and other mechanisms to help with these; some don’t.Then,
    we can leverage the event sourcing pattern to persist those events, allowing new
    microservices to populate their databases by replaying past events. The event
    store then becomes the source of truth of those systems. Event sourcing can also
    become very handy for tracing and auditing purposes since the whole history is
    persisted. We can also replay messages to recreate the system’s state at any given
    point in time, making it very powerful for debugging purposes. The storage size
    requirement for the event store is something to consider before going down the
    event sourcing path. The event store could grow quite large because we have been
    keeping all messages since the beginning of time and could grow fast based on
    the number of events sent. You could compact the history to reduce the data size
    but lose part of the history. Once again, you must decide based on the requirements
    and ask yourself the appropriate questions. For example, is it acceptable to lose
    part of the history? How long should we keep the data? Do we want to keep the
    original data in cheaper storage if we need it later? Do we even need replaying
    capabilities? Can we afford to keep all the data forever? What are the data retention
    policies or regulations the system must follow? Craft your list of questions based
    on the specific business problem you want to solve. This advice applies to all
    aspects of software engineering: clearly define the business problem first, then
    find how to fix it. Such patterns can be compelling but take time to learn and
    implement. Like message queues, cloud providers offer fully managed brokers as
    a service. Those can be faster to get started with than building and maintaining
    your own infrastructure. If building servers is your thing, you can use open-source
    software to “economically” build your stack or pay for managed instances of such
    software to save yourself the trouble. The same tips as with message queues apply
    here; for example, you can leverage a managed service for your production environment
    and a local version on the developer’s machine.Apache Kafka is one of the most
    popular event brokers that enables advanced functionalities like event streaming.
    Kafka has partially and fully managed cloud offerings like Confluent Cloud. Redis
    Pub/Sub is another open-source project with fully managed cloud offerings. Redis
    is also a key-value store trendy for distributed caching scenarios. Other offerings
    are (but are not limited to) Solace PubSub+, RabbitMQ, and ActiveMQ. Once again,
    I suggest comparing the offerings with your requirements to make the best choice
    for your scenarios.Now, let’s see how the Publish-Subscribe pattern can help us
    follow the **SOLID** principles at cloud-scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**S**: Helps centralize and divide responsibilities between applications or
    components without them directly knowing each other, breaking tight coupling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O**: Allows us to change how publishers and subscribers behave without directly
    impacting the other microservices (breaking tight coupling between them).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L**: N/A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I**: Each event can be as small as needed, leading to multiple smaller communication
    interfaces (data contracts).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D**: The microservices depend on events (abstractions) instead of concretions
    (the other microservices), breaking tight coupling between them and inverting
    the dependency flow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you may have noticed, pub-sub is very similar to message queues. The main
    difference is the way messages are read and dispatched:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Queues: Messages are pulled one at a time, consumed by one service, and then
    disappear.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pub-Sub: Messages are read in order and sent to all consumers instead of to
    only one, like with queues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I intentionally kept the **Observer design pattern** out of this book since
    we rarely need it in .NET. C# offers multicast events, which are well-versed in
    replacing the Observer pattern (in most cases). If you don’t know the Observer
    pattern, don’t worry–chances are, you will never need it. Nevertheless, if you
    already know the Observer pattern, here are the differences between it and the
    Pub-Sub pattern.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the Observer pattern, the subject keeps a list of its observers, creating
    direct knowledge of their existence. Concrete observers also often know about
    the subject, leading to even more knowledge of other entities and more coupling.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the Pub-Sub pattern, the publisher is not aware of the subscribers; it is
    only aware of the message broker. The subscribers are not aware of the publishers
    either, only of the message broker. The publishers and subscribers are linked
    only through the data contract of the messages they publish or receive.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We could view the Pub-Sub pattern as the distributed evolution of the Observer
    pattern or, more precisely, like adding a mediator to the Observer pattern.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Next, we explore some patterns that directly call other microservices by visiting
    a new kind of **Façade**: the **Gateway**.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Gateway patterns
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When building a microservices-oriented system, the number of services grows
    with the number of features; the bigger the system, the more microservices you
    have.When you think about a user interface that has to interact with such a system,
    this can become tedious, complex, and inefficient (dev-wise and speed-wise). Gateways
    can help us achieve the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Hide complexity by routing requests to the appropriate services.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hide complexity by aggregating responses and translating one external request
    into many internal ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hide complexity by exposing only the subset of features that a client needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translate a request into another protocol.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A gateway can also centralize different processes, such as logging and caching
    requests, authenticating and authorizing users and clients, enforcing request
    rate limits, and other similar policies.You can see gateways as façades, but instead
    of being a class in a program, it is a program of its own, shielding other programs.
    There are multiple variants of the Gateway pattern, and we explore many of them
    here.Regardless of the type of gateway you need, you can code it yourself or leverage
    existing tools to speed up the development process.
  prefs: []
  type: TYPE_NORMAL
- en: Beware that there is a strong chance that your homemade gateway version 1.0
    has more flaws than a proven solution. This tip is not only applicable to gateways
    but to most complex systems. That being said, sometimes, no proven solution does
    exactly what we want, and we have to code it ourselves, which is where the real
    fun begins!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An open-source project that could help you out is Ocelot ([https://adpg.link/UwiY](https://adpg.link/UwiY)).
    It is an API gateway written in C# that supports many things that we expect from
    a gateway. You can route requests using configuration or write custom code to
    create advanced routing rules. Since it is open source, you can contribute to
    it, fork it, and explore the source code if necessary.If you want a managed offering
    with a long list of features, you can explore Azure API Management ([https://adpg.link/8CEX](https://adpg.link/8CEX)).
    It supports security, load-balancing, routing, and more. It also offers a service
    catalog where teams can consult and manage the APIs with internal teams, partners,
    and customers.We can see a gateway as a **reverse proxy** that offers advanced
    functionalities. A Gateway fetches the information clients request, which can
    come from one or more resources, possibly from one or more servers. A reverse
    proxy usually routes a request to only one server. A reverse proxy often serves
    as a load balancer. Microsoft released a reverse proxy named YARP, written in
    C# and open-source ([https://adpg.link/YARP](https://adpg.link/YARP)). Microsoft
    built it for their internal teams. YARP is now part of Azure App Service ([https://adpg.link/7eu4](https://adpg.link/7eu4)).
    If YARP does what you need, it seems like a stable enough product to invest in
    that will evolve and be maintained over time. A significant advantage of such
    a service is the ability to deploy it with your application, optionally as a container,
    allowing us to use it locally during development.Now, let’s explore a few types
    of gateways.
  prefs: []
  type: TYPE_NORMAL
- en: Gateway Routing pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can use this pattern to hide the complexity of our system by having the
    gateway route requests to the appropriate services.For example, let’s say we have
    two microservices: one that holds our device data and another that manages device
    locations. We want to show the latest known location of a specific device (`id=102`)
    and display its name and model.To achieve that, a user requests the web page,
    and then the web page calls two services (see the following diagram). The `DeviceTwin`
    microservice is accessible from `service1.domain.com`, and the `Location` microservice
    is accessible from `service2.domain.com`. From there, the web application must
    track the two services, their domain name, and their operations. The UI has to
    handle more complexity as we add more microservices. Moreover, if we decide to
    change `service1` to `device-twins` and `service2` to `location`, we’d also need
    to update the web application. If there is only a UI, it is still not so bad,
    but if we have multiple user interfaces, each has to handle that complexity.Furthermore,
    if we want to hide the microservices inside a private network, it would be impossible
    unless all the user interfaces are also part of that private network (which exposes
    it). Here’s the diagram representing the interactions mentioned previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.17: A web application and a mobile app that are calling two microservices
    directly](img/file144.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.17: A web application and a mobile app that are calling two microservices
    directly'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can implement a gateway that does the routing for us to fix some of these
    issues. That way, instead of knowing what services are accessible through what
    sub-domain, the UI only has to know the gateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.18: A web application and a mobile app that are calling two microservices
    through a gateway application](img/file145.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.18: A web application and a mobile app that are calling two microservices
    through a gateway application'
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, this brings some possible issues to the table as the gateway becomes
    a single point of failure. We could consider using a load balancer to ensure we
    have strong enough availability and fast enough performance. Since all requests
    pass through the gateway, we may also need to scale it up at some point.We should
    also ensure the gateway supports failure by implementing different resiliency
    patterns, such as **Retry** and **Circuit Breaker**. The chances that an error
    will occur on the other side of the gateway increase with the number of microservices
    you deploy and the number of requests sent to those microservices.You can also
    use a routing gateway to reroute the URI to create easier-to-use URI patterns.
    You can also reroute ports; add, update, or remove HTTP headers; and more. Let’s
    explore the same example but using different URIs. Let’s assume the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Microservice** | **URI** |'
  prefs: []
  type: TYPE_TB
- en: '| API 1 (get a device) | `internal.domain.com:8001/{id}` |'
  prefs: []
  type: TYPE_TB
- en: '| API 2 (get a device location) | `internal.domain.com:8002/{id}` |'
  prefs: []
  type: TYPE_TB
- en: 'Table 19.1: Internal microservice URI patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: 'UI developers would have a harder time remembering what port is leading to
    what microservice and what is doing what (and who could blame them?). Moreover,
    we could not transfer the requests as we did earlier (only routing the domain).
    We could use the gateway as a way to create memorable URI patterns for developers
    to consume, like these:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Gateway URI** | **Microservice URI** |'
  prefs: []
  type: TYPE_TB
- en: '| `gateway.domain.com/devices/{id}` | `internal.domain.com:8001/{id}` |'
  prefs: []
  type: TYPE_TB
- en: '| `gateway.domain.com/devices/{id}/location` | `internal.domain.com:8002/{id}`
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 19.1: Memorable URI patterns that are easier to use and semantically
    meaningful.'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, we took the ports out of the equation to create usable, meaningful,
    and easy-to-remember URIs.However, we are still making two requests to the gateway
    to display one piece of information (the location of a device and its name/model),
    which leads us to our next Gateway pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Gateway Aggregation pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another role we can give to a gateway is aggregating requests to hide complexity
    from its consumers. Aggregating multiple requests into one makes it easier for
    consumers of a microservices system to interact with it; clients need to know
    about one endpoint instead of multiple. Moreover, it moves the chattiness from
    the client to the gateway, which is closer to the microservices, lowering the
    many calls’ latency, and thus making the request-response cycle faster.Continuing
    with our previous example, we have two UI applications that contain a feature
    to show a device’s location on a map before identifying it using its name/model.
    To achieve this, they must call the device twin endpoint to obtain the device’s
    name and model and the location endpoint to get its last known location. So, two
    requests to display a small box times two UIs means four requests to maintain
    a simple feature. If we extrapolate, we could end up managing a huge number of
    HTTP requests for a handful of features.Here is a diagram showing our feature
    in its current state:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.19: A web application and a mobile app that are calling two microservices
    through a gateway application](img/file146.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.19: A web application and a mobile app that are calling two microservices
    through a gateway application'
  prefs: []
  type: TYPE_NORMAL
- en: 'To remedy this problem, we can apply the Gateway Aggregation pattern to simplify
    our UIs and offload the responsibility of managing those details to the gateway.By
    applying the Gateway Aggregation pattern, we end up with the following simplified
    flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.20: A gateway that aggregates the response of two requests to serve
    a single request from both a web application and a mobile app](img/file147.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.20: A gateway that aggregates the response of two requests to serve
    a single request from both a web application and a mobile app'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous flow, the Web App calls the Gateway that calls the two APIs,
    then crafts a response combining the two responses it got from the APIs. The Gateway
    then returns that response to the Web App. With that in place, the Web App is
    loosely coupled with the two APIs while the Gateway plays the intermediary. With
    only one HTTP request, the Web App has all the information it needs, aggregated
    by the Gateway.Next, let’s explore the steps that occurred. The following diagram
    shows that the Web App makes a single request (1) while the gateway makes two
    calls (2 and 4). In the diagram, the requests are sent in series, but we could
    have sent them in parallel to speed things up:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.21: The order in which the requests take place](img/file148.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.21: The order in which the requests take place'
  prefs: []
  type: TYPE_NORMAL
- en: Like the routing gateway, an aggregation gateway can become the bottleneck of
    your application and a single point of failure, so beware of that.Another important
    point is the latency between the gateway and the internal APIs. The clients will
    wait for every response if the latency is too high. So, deploying the gateway
    close to the microservices it interacts with could become crucial for system performance.
    The gateway can also implement caching to improve performance further and make
    subsequent requests faster.Next, we explore another type of gateway that creates
    specialized gateways instead of generic ones.
  prefs: []
  type: TYPE_NORMAL
- en: Backend for Frontend pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Backend for Frontend (BFF) pattern is yet another variation of the Gateway
    pattern. With Backend for Frontend, instead of building a general-purpose gateway,
    we build a gateway per user interface (for each application that interacts with
    the system), lowering the complexity. Moreover, it allows for fine-grained control
    of what endpoints are exposed. It removes the chances of app B breaking when changes
    are made to app A. Many optimizations can come out of this pattern, such as sending
    only the data that’s required for each call instead of sending data that only
    a few applications are using, saving some bandwidth along the way.Let’s say that
    our Web App needs to display more data about a device. To achieve that, we would
    need to change the endpoint and send that extra information to the mobile app
    as well. However, the mobile app doesn’t need that information since it doesn’t
    have room on its screen to display it. Next is an updated diagram that replaces
    the single gateway with two gateways, one per frontend:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.22: Two Backend for Frontend gateways; one for the Web App and
    one for the Mobile App](img/file149.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.22: Two Backend for Frontend gateways; one for the Web App and one
    for the Mobile App'
  prefs: []
  type: TYPE_NORMAL
- en: 'Doing this allows us to develop specific features for each frontend without
    impacting the other. Each gateway now shields its particular frontend from the
    rest of the system and the other frontend. This is the most important benefit
    this pattern brings: client independence.Once again, the Backend for Frontend
    pattern is a gateway. Like other variations of the Gateway pattern, it can become
    the bottleneck of its frontend and its single point of failure. The good news
    is that the outage of one BFF gateway limits the impact to a single frontend,
    shielding the other frontends from that downtime.'
  prefs: []
  type: TYPE_NORMAL
- en: Mixing and matching gateways
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we’ve explored three variations of the Gateway pattern, it is important
    to note that we can mix and match them, either at the codebase level or as multiple
    microservices.For example, a gateway can be built for a single client (backend
    for frontend), perform simple routing, and aggregate results.We can also mix them
    as different applications, for example, by putting multiple backend for frontend
    gateways in front of a more generic gateway to simplify the development and maintenance
    of those backend for frontend gateways.Beware that each hop has a cost. The more
    pieces you add between your clients and your microservices, the more time it will
    take for those clients to receive the response (latency). Of course, you can put
    mechanisms in place to lower that overhead, such as caching or non-HTTP protocols
    such as gRPC, but you still must consider it. That goes for everything, not just
    gateways.Here is an example illustrating this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.23: A mix of the Gateway patterns](img/file150.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.23: A mix of the Gateway patterns'
  prefs: []
  type: TYPE_NORMAL
- en: As you’ve possibly guessed, the Generic Gateway is the single point of failure
    of all applications, while at the same time, each backend for frontend gateway
    is a point of failure for its specific client.
  prefs: []
  type: TYPE_NORMAL
- en: A **service mesh** is an alternative to help microservices communicate with
    one another. It is a layer, outside of the application, that proxies communications
    between services. Those proxies are injected on top of each service and are referred
    to as **sidecars**. The service mesh can also help with distributed tracing, instrumentation,
    and system resiliency. If your system needs service-to-service communication,
    a service mesh would be an excellent place to look.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A gateway is a façade that shields or simplifies access to one or more other
    services. In this section, we explored the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Routing**: This forwards a request from point A to point B (a reverse proxy).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aggregation**: This combines the result of multiple sub-requests into a single
    response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backend for Frontend**: This is used in a one-to-one relationship with a
    frontend.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use any microservices pattern, including gateways, and like any other
    pattern, we can mix and match them. Just consider the advantages, but also the
    drawbacks, that they bring to the table. If you can live with them, you’ve got
    your solution.Gateways often become the single point of failure of the system,
    so that is a point to consider. On the other hand, a gateway can have multiple
    instances running simultaneously behind a load balancer. Moreover, we must also
    consider the delay added by calling a service that calls another service since
    that slows down the response time.All in all, a gateway is a great tool to simplify
    consuming microservices. They also allow hiding the microservices topology behind
    them, possibly even isolated in a private network. They can also handle cross-cutting
    concerns such as security.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is imperative to use gateways as a requests passthrough and avoid coding
    business logic into them; gateways are just reverse proxies. Think single responsibility
    principle: a gateway is a façade in front of your microservices cluster. Of course,
    you can unload specific tasks into your gateways like authorization, resiliency
    (retry policies, for example), and similar cross-cutting concerns, but the business
    logic must remain in the backend microservices.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The BFF’s role is to simplify the UI, so moving logic from the UI to the BFF
    is encouraged.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In most cases, I recommend against rolling out your hand-crafted gateway and
    suggest leveraging existing offerings instead. There are many open-source and
    cloud gateways that you can use in your application. Using existing components
    leaves you more time to implement the business rules that solve the issues your
    program is trying to tackle.Of course, cloud-based offerings exist, like Azure
    Application Gateway and Amazon API Gateway. Both are extendable with cloud offerings
    like load balancers and **web application firewalls** (**WAF**). For example,
    Azure Application Gateway also supports autoscaling, zone redundancy, and can
    serve as **Azure Kubernetes Service** (**AKS**) Ingress Controller (in a nutshell,
    it controls the traffic to your microservices cluster).If you want more control
    over your gateways or to deploy them with your application, you can leverage one
    existing options, like Ocelot, YARP, or Envoy.Ocelot is an open source production-ready
    API Gateway programmed in .NET. Ocelot supports routing, request aggregation,
    load-balancing, authentication, authorization, rate limiting, and more. It also
    integrates well with Identity Server. In my eyes, the biggest advantage of Ocelot
    is that you create the .NET project yourself, install a NuGet package, configure
    your gateway, and then deploy it like any other ASP.NET Core application. Since
    Ocelot is written in .NET, extending it if needed or contributing to the project
    or its ecosystem is easier.To quote their GitHub `README.md` file: « *YARP is
    a reverse proxy toolkit for building fast proxy servers in .NET using the infrastructure
    from ASP.NET and .NET. The key differentiator for YARP is that it''s been designed
    to be easily customized and tweaked to match the specific needs of each deployment
    scenario.* »Envoy is an « *open source edge and service proxy, designed for cloud-native
    applications* », to quote their website. Envoy is a **Cloud Native Computing Foundation**
    (**CNCF**) graduated project originally created by Lyft. Envoy was designed to
    run as a separate process from your application, allowing it to work with any
    programming language. Envoy can serve as a gateway and has an extendable design
    through TCP/UDP and HTTP filters, supports HTTP/2 and HTTP/3, gRPC, and more.Which
    offering to choose? If you are looking for a fully managed service, look at the
    cloud provider’s offering of your choice. Consider YARP or Ocelot if you are looking
    for a configurable reverse proxy or gateway that supports the patterns covered
    in this chapter. If you have complex use cases that Ocelot does not support, you
    can look into Envoy, a proven offering with many advanced capabilities. Please
    remember that these are just a few possibilities that can play the role of a gateway
    in a microservices architecture system and are not intended to be a complete list.Now,
    let’s see how gateways can help us follow the **SOLID** principles at cloud-scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**S**: A gateway can handle routing, aggregation, and other similar logic that
    would otherwise be implemented in different components or applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O**: I see many ways to tackle this one, but here are two takes on this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Externally, a gateway could reroute its sub-requests to new URIs without its
    consumers knowing about it, as long as its contract does not change.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Internally, a gateway could load its rules from configurations, allowing it
    to change without updating its code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**L**: N/A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I**: Since a backend for frontend gateway serves a single frontend system,
    one contract (interface) per frontend system leads to multiple smaller interfaces
    instead of one big general-purpose gateway.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D**: We could see a gateway as an abstraction, hiding the real microservices
    (implementations) and inverting the dependency flow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we build a BFF and evolve e-commerce application from *Chapter 18*.
  prefs: []
  type: TYPE_NORMAL
- en: Project – REPR.BFF
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This project leverages the Backend for Frontend (BFF) design pattern to reduce
    the complexity of using the low-level API of the *REPR project* we created in
    *Chapter 18*. The BFF endpoints act as several types of gateway we explore.This
    design makes two layers of API, so let’s start here.
  prefs: []
  type: TYPE_NORMAL
- en: Layering APIs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From a high-level architecture perspective, we can leverage multiple layers
    of APIs to group different levels of operation granularity. For example, in this
    case, we have two layers:'
  prefs: []
  type: TYPE_NORMAL
- en: Low-level APIs that offer atomic foundational operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-level APIs that offer domain-specific functionalities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here’s a diagram that represents this concept (high-level APIs are BFFs in
    this case, but the design could be nuanced):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.24: diagram showcasing a two-layer architecture.](img/file151.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.24: diagram showcasing a two-layer architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: The low-level layer showcases atomic foundational operations, like adding an
    item to the shopping basket and removing an item from the shopping basket. Those
    operations are simple, so they are more complicated to use. For example, loading
    the products in the user’s shopping cart requires multiple API calls, one to get
    the items and quantity and one per item to get the product details like its name
    and price. The high-level layer offers domain-specific functionalities, which
    are easier to use but can become more complex. For example, a single endpoint
    could handle adding, updating, and deleting items from the shopping basket, making
    its usage trivial for its consumer but its logic more complex to implement. Moreover,
    the product team could prefer a shopping cart to a shopping basket, so the endpoint’s
    URL could reflect this.Let’s have a look at the advantages and disadvantages.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of a two-layer design
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Separation of Concerns:** This architecture separates the generic functionalities
    from the domain-specific ones, promoting cleaner code and modularization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability:** Each layer can be scaled independently based on the demand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility and Reusability:** The low-level APIs can be reused across multiple
    high-level functionalities or applications, promoting code reusability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimized Data Fetching:** BFFs can call multiple low-level APIs, aggregate
    responses, and send only the necessary data to the frontend, reducing payload
    sizes and making frontend development more straightforward.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Easier Maintenance:** We can address issues in a specific domain without
    touching the low-level generic APIs. On the other hand, we can fix an issue in
    a lower-level API, which will propagate to all the domains.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tailored User Experience:** High-level APIs can be crafted specifically for
    individual client types (web, mobile, etc.), ensuring an optimal user experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security:** Domain-specific functionalities can implement additional security
    measures relevant to their context without burdening the low-level APIs with unnecessary
    complexity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disadvantages of a two-layer design
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Increased Complexity:** Maintaining two layers introduces additional deployment,
    monitoring, and management complexity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Potential Performance Overhead:** An additional layer introduces latency,
    especially if not properly optimized.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Duplication:** There''s potential for code duplication when similar logic
    gets implemented in multiple high-level functionalities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tight Coupling Concerns:** Changes in the low-level APIs can impact multiple
    domain-specific functionalities. A poor design could lead to a tightly coupled
    distributed system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Coordination Required:** As the system evolves, ensuring that the low-level
    APIs meet the needs of all high-level functionalities requires more coordination
    among development teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overhead in Development:** Developers need to consider two layers, which
    can slow down the development process, especially if there''s a need to modify
    both layers to achieve a specific feature or fix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Potential for Stale Data:** If high-level functionalities cache data from
    low-level APIs, there''s potential for serving stale data to users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased Risk of Failures:** Introducing additional APIs increases the odds
    of one of them experiencing issues or outages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While a two-layer design can offer flexibility and optimization, it also introduces
    additional complexities. The decision to use such an architecture should be based
    on the specific needs of the project, the anticipated scale, and the capabilities
    of the development and operations teams.We look at booting up these APIs next.
  prefs: []
  type: TYPE_NORMAL
- en: Running the microservices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s start by exploring the deployment topology. First, we split the *Chapter
    18* REPR project into two services: *Baskets* and *Products*. Then, we add a *BFF*
    API that fronts the two services to simplify using the system. We do not have
    a UI per se, but one `http` file per project exists to simulate HTTP requests.
    Here’s a diagram that represents the relationship between the different services:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.25: a diagram that represents the deployment topology and relationship
    between the different services](img/file152.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.25: a diagram that represents the deployment topology and relationship
    between the different services'
  prefs: []
  type: TYPE_NORMAL
- en: The easiest and most extendable way to start the projects is to use Docker,
    but it is optional; we can also start the three projects manually. Using Docker
    opens many possibilities, like using a real SQL Server to persist the data between
    runs and add more pieces to our puzzle, like a Redis cache or an event broker,
    to name a few.Let’s start by manually starting the apps.
  prefs: []
  type: TYPE_NORMAL
- en: Manually starting the projects
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We have three projects and need three terminals to start them all. From the
    chapter directory, you can execute the following commands, one set per terminal
    window, and all projects should start:# In one terminal
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Doing this should work. You can use the `PROJECT_NAME.http` files to test the
    APIs.Next, let’s explore the second option about using Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Using Docker Compose to run the projects
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: At the same level as the solution file, the `docker-compose.yml`, `docker-compose.override.yml`,
    and various `Dockerfile` files are preconfigured to make the projects start in
    the correct order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a link to get started with Docker: [https://adpg.link/1zfM](https://adpg.link/1zfM)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Since ASP.NET Core uses HTTPS by default, we must register a development certificate
    with the container, so let’s start here.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring HTTPS
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This section quickly explores using PowerShell to set up HTTPS on Windows.
    If you are using a different operating system or if the instructions are not working,
    please consult the official documentation: [https://adpg.link/o1tu](https://adpg.link/o1tu)First,
    we must generate a development certificate. In a PowerShell terminal, run the
    following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The preceding commands create a `pfx` file with the password `devpassword` (you
    must provide a password, or it won’t work), then tell .NET to trust the dev certificates.From
    there, the `ASPNETCORE_Kestrel__Certificates__Default__Path` and `ASPNETCORE_Kestrel__Certificates__Default__Password`
    environment variables are configured in the `docker-compose.override.yml` file
    and should be taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: If you change the certificate location or the password, you must update the
    `docker-compose.override.yml` file.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Composing the application
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now that we set up HTTPS, we can build the container using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We can execute the following command to start the containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This should start the containers and feed you an aggregated log with a color
    per service. The beginning of the log trail should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'To stop the services, press `Ctrl+C`. When you want to destroy the running
    application, enter the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now, with `docker compose up`, our services should be running. To make sure,
    let’s try them out.
  prefs: []
  type: TYPE_NORMAL
- en: Briefly testing the services
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The project contains the following services, each containing an `http` file
    you can leverage to query the services using Visual Studio or in VS Code using
    an extension:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Service | HTTP file | Host |'
  prefs: []
  type: TYPE_TB
- en: '| `REPR.Baskets` | `REPR.Baskets.http` | [https://localhost:60280](https://localhost:60280)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `REPR.BFF` | `REPR.BFF.http` | [https://localhost:7254](https://localhost:7254)
    |'
  prefs: []
  type: TYPE_TB
- en: '| `REPR.Products` | `REPR.Products.http` | [https://localhost:57362](https://localhost:57362)
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 19.3: each service, HTTP file, and HTTPS hostname and port.'
  prefs: []
  type: TYPE_NORMAL
- en: We can leverage the HTTP requests from each directory to test the API. I suggest
    starting by trying the low-level APIs, then the BFF, so you know if something
    is wrong with them directly instead of wondering what is wrong with the BFF (which
    calls the low-level APIs).
  prefs: []
  type: TYPE_NORMAL
- en: I use the *REST Client* extension in VS Code ([https://adpg.link/UCGv](https://adpg.link/UCGv))
    and the built-in support in Visual Studio 2022 version 17.6 or later.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here’s a part of the `REPR.Baskets.http` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The highlighted lines are variables that the requests reuse. The `###` characters
    act as a separator between requests. In VS or VS Code, you should see a `Send
    request` button on top of each request. Executing the `POST` request, then the
    `GET` should output the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: If you can reach one endpoint, this means the service is running. Nonetheless,
    feel free to play with the requests, modify them, and add more.
  prefs: []
  type: TYPE_NORMAL
- en: I did not move the tests over from *Chapter 18*. Automating the validation of
    our deployment could be a good exercise for you to test your testing skills.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: After you validate that the three services are running, we can continue and
    look at how the BFF communicates with the Baskets and Products services.
  prefs: []
  type: TYPE_NORMAL
- en: Creating typed HTTP clients using Refit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The BFF service must communicate to the Baskets and Products services. The
    services are REST APIs, so we must leverage HTTP. We could leverage the out-of-the-box
    ASP.NET Core `HttpClient` class and `IHttpClientFactory` interface, then send
    raw HTTP requests to the downstream APIs. On the other hand, we could also create
    a typed client, which translates the HTTP calls to simple method calls with evocative
    names. We are exploring the second option, encapsulating the HTTP calls inside
    the typed clients.The concept is simple: we create one interface per service and
    translate its operation into methods. Each interface revolves around a service.
    Optionally, we can aggregate the services under a master interface to inject the
    aggregate service and have access to all child services. Moreover, this central
    access point allows us to reduce the number of injected services to one and improve
    discoverability with IntelliSense. Here’s a diagram representing this concept:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.25: UML class diagram representing a generic typed client class
    hierarchy.](img/file153.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.25: UML class diagram representing a generic typed client class hierarchy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, the `IClient` interface is composed and exposes the
    other typed clients, each of which queries a specific downstream API.In our case,
    we have two downstream services, so our interface hierarchy looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.26: UML class diagram representing the BFF downstream typed client
    class hierarchy.](img/file154.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.26: UML class diagram representing the BFF downstream typed client
    class hierarchy.'
  prefs: []
  type: TYPE_NORMAL
- en: After implementing this, we can query the downstream APIs from our code without
    worrying about their data contract because our client is strongly typed.We leverage
    *Refit*, an open-source library, to implement the interfaces automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could use any other library or barebone ASP.NET Core `HttpClient`; it does
    not matter. I picked *Refit* to leverage its code generator, save myself the trouble
    of writing the boilerplate code, and save you the time of reading through such
    code. Refit on GitHub: [https://adpg.link/hneJ](https://adpg.link/hneJ).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I used the out-of-the-box `IHttpClientFactory` functionalities in the past,
    so if you want to reduce the number of dependencies in your project, you can also
    use that instead. Here’s a link to help you get started: [https://adpg.link/HCj7](https://adpg.link/HCj7).'
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Refit acts like Mapperly and generates code based on attributes, so all we have
    to do is define our methods, and Refit writes the code.
  prefs: []
  type: TYPE_NORMAL
- en: The *BFF* project references the *Products* and *Baskets* projects to reuse
    their DTOs. I could have architected this in many different ways, including hosting
    the typed client in a library of its own so we could share it between many projects.
    We could also extract the DTOs from the web applications to one or more shared
    projects so we don’t depend on the web applications themselves. For this demo,
    there is no need to overengineer the solution.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let’s look at the typed client interfaces, starting with the `IBasketsClient`
    interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding interface leverages Refit’s attributes (highlighted) to explain
    to its code generator what to write. The operations themselves are self-explanatory
    and carry the features’ DTOs over HTTP.Next, we look at the `IProductsClient`
    interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The preceding interface is similar to `IBasketsClient` but creates a typed bridge
    on the *Products* API.
  prefs: []
  type: TYPE_NORMAL
- en: The generated code contains much gibberish code and would be very hard to clean
    enough to make it relevant to study, so let’s assume those interfaces have working
    implementations instead.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Next, let’s look at our aggregate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding interface exposes the two clients we had Refit generate for us.
    Its implementation is fairly straightforward as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding default implementation composes itself through constructor injection,
    exposing the two typed clients.Of course, dependency injection means we must register
    services with the container. Let’s start with some configuration. To make the
    setup code parametrizable and allow the Docker container to override those values,
    we extract the services base addresses to the settings file like this (`appsettings.Development.json`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code defines two keys, one per service, which we then load individually
    in the `Program.cs` file, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code loads the two configurations into variables.
  prefs: []
  type: TYPE_NORMAL
- en: We can leverage all the techniques we learned in *Chapter 9*, *Options, Settings,
    and Configuration*, to create a more elaborate system.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Next, we register our Refit clients like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, calling the `AddRefitClient` method replaces the .NET
    `AddHttpClient` method and registers our auto-generated client with the container.
    Because Refit registration returns an `IHttpClientBuilder` interface, we can use
    the `ConfigureHttpClient` method to configure the `HttpClient` as we would any
    other typed HTTP client. In this case, we set the `BaseAddress` property to the
    values of the previously loaded settings.Next, we must also register our aggregate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: I picked a transient state because the service only fronts other services, so
    it will serve the other services as they are registered, regardless of whether
    it is the same instance every time. Moreover, it needs a transient or scoped lifetime
    because the BFF must manage who is the current customer, not the client. It would
    be quite a security vulnerability to allow users to decide who they want to impersonate
    for every request.
  prefs: []
  type: TYPE_NORMAL
- en: The project does not authenticate the users, but the service we explore next
    is designed to make this evolve, abstracting and managing this responsibility
    so we could add authentication without impacting the code we are writing.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s explore how we manage the current user.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a service that serves the current customer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To keep the project simple, we are not using any authentication or authorization
    middleware, yet we want our BFF to be realistic and to handle who’s querying the
    downstream APIs. To achieve this, let’s create the `ICurrentCustomerService` interface
    that abstracts this away from the consuming code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The only thing that interface does is provide us with the identifier representing
    the current customer. Since we do not have authentication in the project, let’s
    implement a development version that always returns the same value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we must register it in the `Program.cs` class like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: With this last piece, we are ready to write some features in our BFF service.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a project that uses authentication, you can inject the `IHttpContextAccessor`
    interface into a class to access the current `HttpContext` object that contains
    a `User` property that enables access to the current user’s `ClaimsPrincipal`
    object, which should include the current user’s `CustomerId`. Of course, you must
    ensure the authentication server returns such a claim. You must register the accessor
    using the following method before using it: `builder.Services.AddHttpContextAccessor()`.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The BFF service serves an unexisting user interface, yet we can imagine what
    it needs to do; it must:'
  prefs: []
  type: TYPE_NORMAL
- en: Serve the product catalog so customers can browse the shop.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serve a specific product to render a product details page.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serve the list of items in a user’s shopping cart.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable users to manage their shopping cart by adding, updating, and removing
    items.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, the list of features could go on, like allowing the users to purchase
    the items, which is the ultimate goal of an e-commerce website. However, we are
    not going that far. Let’s start with the catalog.
  prefs: []
  type: TYPE_NORMAL
- en: Fetching the catalog
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The catalog acts as a routing gateway and forwards the requests to the `Products`
    downstream service.The first endpoint serves the whole catalog by using our typed
    client (highlighted):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Sending the following requests should hit the endpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The endpoint should respond with something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a visual representation of what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.27: a sequence diagram representing the BFF routing the request
    to the Products service](img/file155.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.27: a sequence diagram representing the BFF routing the request to
    the Products service'
  prefs: []
  type: TYPE_NORMAL
- en: 'The other catalog endpoint is very similar and also simply routes the request
    to the correct downstream service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Sending an HTTP call will result in the same as calling it directly because
    the BFF only acts as a router.We explore more exciting features next.
  prefs: []
  type: TYPE_NORMAL
- en: Fetching the shopping cart
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The *Baskets* service only stores the `customerId`, `productId`, and `quantity`
    properties. However, a shopping cart page displays the product name and price,
    but the *Products* service manages those two properties.To overcome this problem,
    the endpoint acts as an aggregation gateway. It queries the shopping cart and
    loads all the products from the *Products* service before returning an aggregated
    result, removing the burden of managing this complexity from the client/UI.Here’s
    the code main feature code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code starts by fetching the items from the Baskets service and
    then loads the products using the `Parallel.ForEachAsync` method before returning
    the aggregated result.The `Parallel` class allows us to execute multiple operations
    in parallel, in this case, multiple HTTP calls. There are many ways of achieving
    a similar result using .NET, and this is one of those. When an HTTP call succeeds,
    it adds a `BasketProduct` item to the `result` collection. Once all operations
    are completed, the endpoint returns the collection of `BasketProduct` objects,
    which contains all the combined information required by the user interface to
    display the shopping cart. Here’s the `BasketProduct` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The sequence of this endpoint is like this (the `loop` represents the `Parallel.ForEachAsync`
    method):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.28: A sequence diagram representing the shopping cart endpoint
    interacting with the Products and the Baskets downstream services.](img/file156.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.28: A sequence diagram representing the shopping cart endpoint interacting
    with the Products and the Baskets downstream services.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the requests to the *Products* service are sent in parallel, we cannot
    predict the order they will complete. Here is an excerpt from the application
    log depicting what can happen (I omitted the logging code in the book, but it
    is available on GitHub):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding trace shows that we requested products `3` and `2` but received
    inverted responses (`2` and `3`). This is a possibility when running code in parallel.When
    we send the following request to the BFF:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The BFF returns a response similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The preceding example showcases the aggregated result, simplifying the logic
    the client (UI) must implement to display the shopping cart.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are not ordering the results, the items will not always be in the same
    order. As an exercise, you could sort the results using one of the existing properties
    or add a property that saves when a customer adds the item to the cart and sort
    the items using this new property; the first item added is displayed first, and
    so on.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s move to the last endpoint and explore how the BFF manages the shopping
    cart items.
  prefs: []
  type: TYPE_NORMAL
- en: Managing the shopping cart
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One of the primary goals of our BFF is to reduce the frontend’s complexity.
    When examining the *Baskets* service, we realized it would add a bit of avoidable
    complexity if we were only to serve the raw operation, so instead, we decided
    to encapsulate all of the shopping cart logic behind a single endpoint. When a
    client POST to the `api/cart` endpoint, it:'
  prefs: []
  type: TYPE_NORMAL
- en: Adds a non-existent item.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update an existing item’s quantity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove an item that has a quantity equal to 0 or less.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With this endpoint, the clients don’t have to worry about adding or updating.
    Here’s a simplified sequence diagram that represents this logic:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.29: A sequence diagram that displays the high-level algorithm of
    the cart endpoint.](img/file157.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.29: A sequence diagram that displays the high-level algorithm of
    the cart endpoint.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As the diagram depicts, we call the remove endpoint if the quantity is inferior
    or equal to zero. Otherwise, we try to add the item to the basket. If the endpoint
    returns a `409 Conflict`, we try to update the quantity. Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code follows the same pattern but contains the previously explained
    logic. We explore the two highlighted methods next, starting with the `RemoveItemFromCart`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The highlighted code of the preceding block leverages the typed HTTP client
    and sends a remove item command to the *Baskets* service. If the item is not in
    the cart, the code ignores the error and continues. Why? Because it does not affect
    the business logic or the end-user experience. Maybe the customer clicked the
    remove or update button twice. However, the code propagates to the client any
    other error.Let’s explore the `AddOrUpdateItem` method’s code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding logic is very similar to the other method. It starts by adding
    the item to the cart. If it receives a `409 Conflict`, it tries to update its
    quantity. Otherwise, it lets the exception bubble up the stack to let an exception
    middleware catch it later to uniformize the error messages.With that code in place,
    we can send `POST` requests to the `api/cart` endpoint for adding, updating, and
    removing an item from the cart. The three operations return an empty `200 OK`
    response.Assuming we have an empty shopping cart, the following request adds *10*
    *Habanero Peppers* (`id=3`) to the shopping cart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The following request adds *5 Apples* (`id=2`) to the cart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The following request updates the quantity to *20* *Habanero Peppers* (`id=3`)
    :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The following request removes the *Apples* (`id=2`) from the cart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Leaving us with *20* *Habanero Peppers* in our shopping cart (`GET https://localhost:7254/api/cart`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The requests of the previous sequence are all in the same format, reaching the
    same endpoint but doing different things, which makes it very easy for the frontend
    client to manage.
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer having the UI to manage the operations individually or want to
    implement a batch update feature, you can; this is only an example of what you
    can leverage a BFF for.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We are now done with the BFF service.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we learned about using the Backend for Frontend (BFF) design
    pattern to front a micro e-commerce web application. We discussed layering APIs
    and the advantages and disadvantages of a two-layer design. We autogenerated strongly
    typed HTTP clients using Refit, managed a shopping cart, and fetched the catalog
    from the BFF. We learned how to use a BFF to reduce complexity by moving domain
    logic from the frontend to the backend by implementing multiple Gateway patterns.Here
    are a few benefits that we explored:'
  prefs: []
  type: TYPE_NORMAL
- en: The BFF pattern can significantly simplify the interaction between frontend
    and backend systems. It provides a layer of abstraction that can reduce the complexity
    of using low-level atomic APIs. It separates generic and domain-specific functionalities
    and promotes cleaner, more modular code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A BFF can act as a gateway that routes specific requests to relevant services,
    reducing the work the frontend has to perform. It can also serve as an aggregation
    gateway, gathering data from various services into a unified response. This process
    can simplify frontend development by reducing the complexity of the frontend and
    the number of separate calls the frontend must make. It can also reduce the payload
    size transported between the frontend and backend.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each BFF is tailored to a specific client, optimizing the frontend interaction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A BFF can handle issues in one domain without affecting the low-level APIs or
    the other applications, thus providing easier maintenance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A BFF can implement security logic, such as specific domain-oriented authentication
    and authorization rules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite these benefits, using a BFF may also increase complexity and introduce
    potential performance overhead. Using a BFF is no different than any other pattern
    and must be counter-balanced and adapted to the specific needs of a project.Next,
    we revisit CQRS on a distributed scale.
  prefs: []
  type: TYPE_NORMAL
- en: Revisiting the CQRS pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Command Query Responsibility Segregation** (**CQRS**) applies the **Command
    Query Separation** (**CQS**) principle. Compared to what we saw in *Chapter 14*,
    *Mediator and CQRS Design Patterns*, we can push CQRS further using microservices
    or serverless computing. Instead of simply creating a clear separation between
    commands and queries, we can divide them even more using multiple microservices
    and data sources.**CQS** is a principle stating that a method should either return
    data or mutate data, but not both. On the other hand, **CQRS** suggests using
    one model to read the data and one model to mutate the data.**Serverless computing**
    is a cloud execution model where the cloud provider manages the servers and allocates
    the resources on-demand, based on usage and configuration. Serverless resources
    fall into the platform as a service (PaaS) offering.Let’s come back to our IoT
    example again. We queried the last known location of a device in the previous
    examples, but what about the device updating that location? This can mean pushing
    many updates every minute. To solve this issue, we are going to use CQRS and focus
    on two operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Updating the device location.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reading the last known location of a device.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simply put, we have a `Read Location` microservice, a `Write Location` microservice,
    and two databases. Remember that each microservice should own its data. This way,
    a user can access the last known device location through the read microservice
    (query model), while a device can punctually send its current position to the
    write microservice (command model). By doing this, we split the load from reading
    and writing the data as both occur at different frequencies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.30: Microservices that apply CQRS to divide the reads and writes
    of a device’s location](img/file158.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.30: Microservices that apply CQRS to divide the reads and writes
    of a device’s location'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding schema that illustrates the concept, the reads are queries,
    and the writes are commands. How to update the Read DB once a new value is added
    to the Write DB depends on the technology at play. One essential thing in this
    type of architecture is that, per the CQRS pattern, a command should not return
    a value, enabling a “fire and forget” scenario. With that rule in place, consumers
    don’t have to wait for the command to complete before doing something else.
  prefs: []
  type: TYPE_NORMAL
- en: Fire and forget does not apply to every scenario; sometimes, we need synchronization.
    Implementing the Saga pattern is one way to solve coordination issues.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Conceptually, we can implement this example by leveraging serverless cloud
    infrastructures, such as Azure Functions. Let’s revisit this example using a high-level
    conceptual serverless design:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.31: Using Azure services to manage a CQRS implementation](img/file159.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.31: Using Azure services to manage a CQRS implementation'
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous diagram illustrates the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The device sends its location regularly by posting it to *Azure Function 1*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Azure Function 1* then publishes the `LocationAdded` event to the event broker,
    which is also an event store (the Write DB).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All subscribers to the `LocationAdded` event can now handle the event appropriately,
    in this case, *Azure Function 2*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Azure Function 2* updates the device''s last known location in the *Read DB*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any subsequent queries should result in reading the new location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The message broker is also the event store in the preceding diagram, but we
    could store events elsewhere, such as in an Azure Storage Table, in a time-series
    database, or in an Apache Kafka cluster. Azure-wise, the datastore could also
    be CosmosDB. Moreover, I abstracted this component for multiple reasons, including
    the fact that there are multiple “as-a-service” offerings to publish events in
    Azure and multiple ways of using third-party components (both open-source and
    proprietary).Furthermore, the example demonstrates **eventual consistency** well.
    All the last known location reads between *steps 1* and *4* get the old value
    while the system processes the new location updates (commands). If the command
    processing slows down for some reason, a longer delay could occur before the next
    read database updates. The commands could also be processed in batches, leading
    to another kind of delay. No matter what happens with the command processing,
    the read database is available all that time, whether it serves the latest data
    or not and whether the write system is overloaded or not. This is the beauty of
    this type of design, but it is more complex to implement and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: '**Time-series databases** are optimized for temporally querying and storing
    data, where you always append new records without updating old ones. This kind
    of NoSQL database can be useful for temporal-intensive usage, like metrics.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Once again, we used the Publish-Subscribe pattern to get another scenario going.
    Assuming that events are persisted forever, the previous example could also support
    event sourcing. Furthermore, new services could subscribe to the `LocationAdded`
    event without impacting the code that has already been deployed. For example,
    we could create a SignalR microservice that pushes the updates to its clients.
    It is not CQRS-related, but it flows well with everything that we’ve explored
    so far, so here is an updated conceptual diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.32: Adding a SignalR service as a new subscriber without impacting
    the other part of the system](img/file160.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.32: Adding a SignalR service as a new subscriber without impacting
    the other part of the system'
  prefs: []
  type: TYPE_NORMAL
- en: The SignalR microservice could be custom code or an Azure SignalR Service (backed
    by another Azure Function); it doesn’t matter. With this design, the Web App could
    know that a change occurred before the Read DB gets updated.
  prefs: []
  type: TYPE_NORMAL
- en: With this design, I wanted to illustrate that dropping new services into the
    mix is easier when using a Pub-Sub model than with point-to-point communication.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As you can see, a microservices system adds more and more small pieces that
    indirectly interconnect with each other over one or more message brokers. Maintaining,
    diagnosing, and debugging such systems is harder than with a single application;
    that’s the **operational complexity** we discussed earlier. However, containers
    can help deploy and maintain such systems.Starting in ASP.NET Core 3.0, the ASP.NET
    Core team invested much effort into **distributed tracing**. Distributed tracing
    is necessary to find failures and bottlenecks related to an event that flows from
    one program to another (such as microservices). If something bugs out, it is important
    to trace what the user did to isolate the error, reproduce it, and then fix it.
    The more independent pieces there are, the harder it can become to make that trace
    possible. This is outside the scope of this book, but it is something to consider
    if you plan to leverage microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and potential risks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section explores some advantages and risks of separating a data store's
    read and write operations using the CQRS pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Benefits of the CQRS pattern
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Scalability:** Given that read and write workloads can be scaled independently,
    CQRS can lead to much higher scalability in a distributed cloud- or microservices-based
    applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simplified and Optimized Models:** It separates the read model (query responsibility)
    and write model (command responsibility), which simplifies application development
    and can optimize performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility:** Different models increase the number of choices one can make,
    increasing flexibility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced Performance:** CQRS can prevent unnecessary data fetching and allows
    choosing an optimized database for each job, improving the performance of both
    read and write operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased Efficiency:** It enables parallel development on complex applications,
    as teams can work independently on the separate read and write sides of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Potential Risks of using the CQRS pattern
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Complexity:** CQRS adds complexity to the system. It may not be necessary
    for simple CRUD apps and could over-complicate the application unnecessarily.
    Therefore, using CQRS only in complex systems and when the advantages outweigh
    the cons is advisable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Consistency:** It can introduce eventual consistency issues between
    the read and write sides because the read model''s updates are asynchronous, which
    might not fit every business requirement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Increased Development Effort:** CQRS could mean increased development, testing,
    and maintenance efforts due to handling two separate models and more pieces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning Curve:** The pattern has its own learning curve. Team members unfamiliar
    with the CQRS pattern will require training and to gain some experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Synchronization Challenges:** Maintaining synchronization between the read
    and write models can be challenging, especially in high data volume cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'CQRS helps divide queries and commands and helps encapsulate and isolate each
    block of logic independently. Mixing that concept with serverless computing or
    microservices architecture allows us to scale reads and writes independently.
    We can also use different databases, empowering us with the tools we need for
    the transfer rate required by each part of that system (for example, frequent
    writes and occasional reads or vice versa).Major cloud providers like Azure and
    AWS provide serverless offerings to help support such scenarios. Each cloud provider’s
    documentation should help you get started. Meanwhile, for Azure, we have Azure
    Functions, Event Grid, Event Hubs, Service Bus, Cosmos DB, and more. Azure also
    offers bindings between the different services that are triggered or react to
    events for you, removing a part of the complexity yet locking you down with that
    vendor.Now, let’s see how CQRS can help us follow the **SOLID** principles at
    the cloud scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**S**: Dividing an application into smaller reads and writes applications (or
    functions) leans toward encapsulating single responsibilities into different programs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O**: CQRS, mixed with serverless computing or microservices, helps extend
    the software without needing us to modify the existing code by adding, removing,
    or replacing applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L**: N/A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I**: CQRS set us up to create multiple small interfaces (or programs) with
    a clear distinction between commands and queries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D**: N/A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the Microservice Adapter pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Microservice Adapter pattern allows adding missing features, adapting one
    system to another, or migrating an existing application to an event-driven architecture
    model, to name a few possibilities. The Microservice Adapter pattern is similar
    to the Adapter pattern we cover in *Chapter 9*, *Structural Patterns*, but applied
    to a microservices system that uses event-driven architecture instead of creating
    a class to adapt an object to another signature.In the scenarios we cover in this
    section, the microservices system represented by the following diagram can be
    replaced by a standalone application as well; this pattern applies to all sorts
    of programs, not just microservices, which is why I abstracted away the details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.33: Microservice system representation used in the subsequent examples](img/file161.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.33: Microservice system representation used in the subsequent examples'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the examples we are covering next and possible usages of this pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: Adapting an existing system to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decommissioning a legacy application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adapting an event broker to another.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start by connecting a standalone system to an event-driven one.
  prefs: []
  type: TYPE_NORMAL
- en: Adapting an existing system to another
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this scenario, we have an existing system of which we don’t control the
    source code or don’t want to change, and we have a microservices system built
    around an event-driven architecture model. We don’t have to control the source
    code of the microservices system either as long as we have access to the event
    broker.Here is a diagram that represents this scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.34: A microservices system that interacts with an event broker
    and an existing system that is disconnected from the microservices](img/file162.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.34: A microservices system that interacts with an event broker and
    an existing system that is disconnected from the microservices'
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see from the preceding diagram, the existing system is disconnected
    from the microservices and the broker. To adapt the existing system to the microservices
    system, we must subscribe or publish certain events. Let’s see how to read data
    from the microservices (subscribe to the broker) and then update that data into
    the existing system.When we control the existing system’s code, we can open the
    source code, subscribe to one or more topics, and change the behaviors from there.
    In our case, we don’t want to do that or can’t, so we can’t directly subscribe
    to topics, as demonstrated by the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.35: Missing capabilities to connect an existing system to an event-driven
    one](img/file163.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.35: Missing capabilities to connect an existing system to an event-driven
    one'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where the microservice adapter comes into play and allows us to fill
    the capability gap of our existing system. To add the missing link, we create
    a microservice that subscribes to the appropriate events, then apply the changes
    in the existing system, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.36: An adapter microservice adding missing capabilities to an existing
    system](img/file164.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.36: An adapter microservice adding missing capabilities to an existing
    system'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see in the preceding diagram, the `Adapter` microservice gets the
    events (subscribes to one or more topics) and then uses that data from the microservices
    system to execute some business logic on the existing system.In this design, the
    new `Adapter` microservice allowed us to add missing capabilities to a system
    we had no control over with little to no disruption to users’ day-to-day activities.The
    example assumes the existing system had some form of extensibility mechanism like
    an API. If the system does not, we would have to be more creative to interface
    with it.For example, the microservices system could be an e-commerce website,
    and the existing system could be a legacy inventory management system. The adapter
    could update the legacy system with new order data.The existing system could also
    be an old **customer relationship management** (**CRM**) system that you want
    to update when users of the microservices application execute some actions, like
    changing their phone number or address.The possibilities are almost endless; you
    create a link between an event-driven system and an existing system you don’t
    control or don’t want to change. In this case, the microservice adapter allows
    us to follow the **Open-Closed principle** by extending the system without changing
    the existing pieces. The primary drawback is that we are deploying another microservice
    that has direct coupling with the existing system, which may be best for temporary
    solutions. On that same line of thought, next, we replace a legacy application
    with a new one with limited to no downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Decommissioning a legacy application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this scenario, we have a legacy application to decommission and a microservices
    system to which we want to connect some existing capabilities. To achieve this,
    we can create one or more adapters to migrate all features and dependencies to
    the new model.Here is a representation of the current state of our system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.37: The original legacy application and its dependencies](img/file165.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.37: The original legacy application and its dependencies'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding diagram shows the two distinct systems, including the legacy
    application we want to decommission. Two other applications, dependency A and
    B, directly depend on the legacy application. The exact migration flow is strongly
    dependent on your use case. If you want to keep the dependencies, we want to migrate
    them first. To do that, we can create an event-driven `Adapter` microservice that
    breaks the tight coupling between the dependencies and the legacy application
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.38: Adding a microservice adapter that implements the event-driven
    flow required to break tight coupling between the dependencies and the legacy
    application](img/file166.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.38: Adding a microservice adapter that implements the event-driven
    flow required to break tight coupling between the dependencies and the legacy
    application'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding diagram shows an `Adapter` microservice and the rest of a microservices
    system that communicates using an event broker. As we explored in the previous
    example, the adapter was placed there to connect the legacy application to the
    microservices. Our scenario focuses on removing the legacy application and migrating
    its two dependencies. Here, we carved out the required capabilities using the
    adapter, allowing us to migrate the dependencies to an event-driven model and
    break tight coupling with the legacy application. Such migration could be done
    in multiple steps, migrating each dependency one by one, and we could even create
    one adapter per dependency. For the sake of simplicity, I chose to draw only one
    adapter. You may want to revisit this choice if your dependencies are large or
    complex.Once we are done migrating the dependencies, our systems look like the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.39: The dependencies are now using an event-driven architecture,
    and the adapter microservice is bridging the gap between the events and the legacy
    system](img/file167.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.39: The dependencies are now using an event-driven architecture,
    and the adapter microservice is bridging the gap between the events and the legacy
    system'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, the Adapter microservice executes the operations against
    the legacy application API that the two dependencies were doing before. The dependencies
    are now publishing events instead of using the API. For example, when an operation
    happens in `DependencyB`, it publishes an event to the broker. The Adapter microservice
    picks up that event and executes the original operation against the API. Doing
    this creates more complexity and is a temporary state.With this new architecture
    in place, we can start migrating existing features away from the legacy application
    into the new application without impacting the dependencies; we broke tight coupling.
  prefs: []
  type: TYPE_NORMAL
- en: From this point forward, we are applying the **Strangler Fig** pattern to migrate
    the legacy system piece by piece to our new architecture. For the sake of simplicity,
    think of the Strangler Fig pattern as migrating features from one application
    to another, one by one. In this case, we replaced one application with another,
    but we could also use the same patterns to split an application into multiple
    smaller applications (like microservices).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I left a few links in the further reading section in case migrating legacy systems
    is something you do or simply if you want to know more about that pattern.
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: The following diagram is a visual representation that adds the modern application
    we are building to replace the legacy application. That new modern application
    could also be a purchased product you are putting in place instead; the concepts
    we are exploring apply to both use cases, but the exact steps are directly related
    to the technology at play.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.40: The modern application to replace the legacy application is
    starting to emerge by migrating capabilities to that new application](img/file168.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.40: The modern application to replace the legacy application is starting
    to emerge by migrating capabilities to that new application'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the preceding diagram, we see the new modern application has appeared. Each
    time we deploy a new feature to the new application, we can remove it from the
    adapter, leading to a graceful transition between the two models. At the same
    time, we are keeping the legacy application in place to continue to provide the
    capabilities that are not yet migrated.Once all the features we want to keep are
    migrated, we can remove the adapter and decommission the legacy application, leading
    to the following system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.41: The new system topology after the retirement of the legacy
    application, showing the new modern application and its two loosely coupled dependencies](img/file169.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.41: The new system topology after the retirement of the legacy application,
    showing the new modern application and its two loosely coupled dependencies'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram shows the new system topology encompassing a new modern
    application and the two original dependencies that are now loosely coupled through
    event-driven architecture. Of course, the bigger the migration, the more complex
    it will be and the longer it will take, but the Adapter Microservice pattern is
    one way to help do a partial or complete migration from one system to another.Like
    the preceding example, the main advantage is adding or removing capabilities without
    impacting the other systems, which allows us to migrate and break the tight coupling
    between the different dependencies. The downside is the added complexity of this
    temporary solution. Moreover, during the migration step, you will most likely
    need to deploy both the modern application and the adapter in the correct sequence
    to ensure both systems are not handling the same events twice, leading to duplicate
    changes. For example, updating the phone number to the same value twice should
    be all right because it leads to the same final data set. However, creating two
    records instead of one should be more important to mitigate as it may lead to
    integrity errors in the data set. For example, creating an online order twice
    instead of once could create customer dissatisfaction or internal issues.And voilà,
    we decommissioned a system using the Microservice Adapter pattern without breaking
    its dependencies. Next, we look at an **Internet of Things** (**IoT**) example.
  prefs: []
  type: TYPE_NORMAL
- en: Adapting an event broker to another
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this scenario, we are adapting an event broker to another. In the following
    diagram, we look at two use cases: one that translates events from broker B to
    broker A (left) and the other that translates events from broker A to broker B
    (right). Afterwards, we explore a more concrete example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.42: An adapter microservice that translates events from broker
    B to broker A (left) and from broker A to broker B (right)](img/file170.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.42: An adapter microservice that translates events from broker B
    to broker A (left) and from broker A to broker B (right)'
  prefs: []
  type: TYPE_NORMAL
- en: We can see the two possible flows in the preceding diagram. The first flow,
    on the left, allows the adapter to read events from broker B and publish them
    to broker A. The second flow, on the right, enables the adapter to read events
    from broker A and publish them to broker B. Those flows allow us to translate
    or copy events from one broker to another by leveraging the Microservice Adapter
    pattern.
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 16.35*, there is one adapter per flow. I did that to make the two
    flows as independent as possible, but the adapters could be a single microservice.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This pattern can be very useful for an IoT system where your microservices
    leverage Apache Kafka internally for its full-featured suite of event-streaming
    capabilities but use MQTT to communicate with the low-powered IoT devices that
    connect to the system. An adapter can solve this problem by translating the messages
    from one protocol to the other. Here is a diagram that represents the complete
    flows, including a device and the microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.43: Complete protocol adapter flows, including a device and microservices](img/file171.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19.43: Complete protocol adapter flows, including a device and microservices'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we explore what the events could be, let’s explore both flows step by
    step. The left flow allows getting events inside the system from the devices through
    the following sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: A device publishes an event to the MQTT broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The adapter reads that event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The adapter publishes a similar or different event to the Kafka broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Zero or more microservices subscribed to the event act on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the other hand, the right flow allows getting events out of the system to
    the devices through the following sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: A microservice publishes an event to the Kafka broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The adapter reads the event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The adapter publishes a similar or different event to the MQTT broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Zero or more devices subscribed to the event act on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You don’t have to implement both flows; the adapter could be bidirectional (supporting
    both flows), we could have two unidirectional adapters that support one of the
    flows, or we could allow the communication to flow only one way (in or out but
    not both). The choice relates to your specific use cases.Concrete examples of
    sending a message from a device to a microservice (left flow) could be sending
    its GPS position, a status update (the light is now on), or a message indicating
    a sensor failure.Concrete examples of sending a message to a device (right flow)
    could be to remotely control a speaker’s volume, flip a light on, or send a confirmation
    that a message has been acknowledged.In this case, the adapter is not a temporary
    solution but a permanent capability. We could leverage such adapters to create
    additional capabilities with minimal impact on the rest of the system. The primary
    downside is deploying one or more other microservices, but your system and processes
    are probably robust enough to handle that added complexity when leveraging such
    capabilities.This third scenario that leverages the Microservice Adapter is our
    last. Hopefully, I sparked your imagination enough to leverage this simple yet
    powerful design pattern.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We explored the Microservice Adapter pattern that allows us to connect two
    elements of a system by adapting one to the other. We explored how to push information
    from an event broker into an existing system that does not support such capabilities.
    We also explored how to leverage an adapter to break tight coupling, migrate features
    into a newer system, and decommission a legacy application seamlessly. We finally
    connected two event brokers through an adapter microservice, allowing a low-powered
    IoT device to communicate with a microservices system without draining their battery
    and without the complexity it would incur to use a more complex communication
    protocol.This pattern is very powerful and can be implemented in many ways, but
    it all depends on the exact use cases. You can write an adapter using a serverless
    offering like an Azure function, no-code/low-code offerings like Power Automate,
    or C#. Of course, these are just a few examples. The key to designing the correct
    system is to nail down the problem statement because once you know what you are
    trying to fix, the solution becomes clearer.Now, let’s see how the Microservice
    Adapter pattern can help us follow the **SOLID** principles at cloud-scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**S**: The microservice adapter helps manage long- or short-term responsibilities.
    For example, adding an adapter that translates between two protocols or creating
    a temporary adapter to decommission a legacy system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**O**: You can leverage microservice adapters to dynamically add or remove
    features without impacting or with limited impact on the rest of the system. For
    example, in the IoT scenario, we could add support for a new protocol like AMQP
    without changing the rest of the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**L**: N/A'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I**: Adding smaller adapters can make changes easier and less risky than
    updating large legacy applications. As we saw in the legacy system decommissioning
    scenario, we could also leverage temporary adapters to split large applications
    into smaller pieces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D**: A microservice adapter inverts the dependency flow between the system
    it adapts. For example, in the legacy system decommissioning scenario, the adapter
    reversed the flow from the two dependencies to the legacy system by leveraging
    an event broker.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The microservices architecture is different from everything we’ve covered in
    this book and how we build monoliths. Instead of one big application, we split
    it into multiple smaller ones called microservices. Microservices must be independent
    of one another; otherwise, we will face the same problems associated with tightly
    coupled classes, but at the cloud scale.We can leverage the Publish-Subscribe
    design pattern to loosely couple microservices while keeping them connected through
    events. Message brokers are programs that dispatch those messages. We can use
    event sourcing to recreate the application’s state at any point in time, including
    when spawning new containers. We can use application gateways to shield clients
    from the microservices cluster’s complexity and publicly expose only a subset
    of services.We also looked at how we can build upon the CQRS design pattern to
    decouple reads and writes of the same entities, allowing us to scale queries and
    commands independently. We also looked at using serverless resources to create
    that kind of system.Finally, we explored the Microservice Adapter pattern that
    allowed us to adapt two systems together, decommission a legacy application, and
    connect two event brokers. This pattern is simple but powerful at inverting the
    dependency flow between two dependencies in a loosely coupled manner. The use
    of the pattern can be temporary, as we saw in the legacy application decommissioning
    scenario, or permanent, as we saw in the IoT scenario.On the other hand, microservices
    come at a cost and are not intended to replace all that exists. Building a monolith
    is still a good idea for many projects. Starting with a monolith and migrating
    it to microservices when scaling is another solution. This allows us to develop
    the application faster (monolith). It is also easier to add new features to a
    monolith than it can be to add them to a microservice application. Most of the
    time, mistakes cost less in a monolith than in a microservices application. You
    can also plan your future migration toward microservices, which leads to the best
    of both worlds while keeping operational complexity low. For example, we could
    leverage the Publish-Subscribe pattern through MediatR notifications in your monolith
    and migrate the events dispatching responsibility to a message broker later when
    migrating your system to microservices architecture (if the need ever arises).
    We are exploring ways to organize our monolith in *Chapter 20*, *Modular Monolith*.I
    don’t want you to discard the microservices architecture, but I want to ensure
    you weigh up the pros and cons of such a system before blindly jumping in. Your
    team’s skill level and ability to learn new technologies may also impact the cost
    of jumping into the microservices boat.**DevOps** (development [Dev] and IT operations
    [Ops]) or **DevSecOps** (adding security [Sec] to the DevOps mix), which we do
    not cover in the book, is essential when building microservices. It brings deployment
    automation, automated quality checks, auto-composition, and more. Your microservices
    cluster will be very hard to deploy and maintain without that.Microservices are
    great when you need scaling, want to go serverless, or split responsibilities
    between multiple teams, but keep the operational costs in mind.In the next chapter,
    we combine the microservices and monolith worlds.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s take a look at a few practice questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What is the most significant difference between a **message queue** and a **pub-sub**
    model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is **event sourcing**?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Can an **application gateway** be both a **routing gateway** and an **aggregation
    gateway**?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it true that real CQRS requires a serverless cloud infrastructure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a significant advantage of using the BFF design pattern?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are a few links that will help you build on what you learned in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Event Sourcing pattern by Martin Fowler: [https://adpg.link/oY5H](https://adpg.link/oY5H)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Event Sourcing pattern by Microsoft: [https://adpg.link/ofG2](https://adpg.link/ofG2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Publisher-Subscriber pattern by Microsoft: [https://adpg.link/amcZ](https://adpg.link/amcZ)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Event-driven architecture by Microsoft: [https://adpg.link/rnck](https://adpg.link/rnck)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Microservices architecture and patterns on microservices.io: [https://adpg.link/41vP](https://adpg.link/41vP)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Microservices architecture and patterns by Martin Fowler: [https://adpg.link/Mw97](https://adpg.link/Mw97)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Microservices architecture and patterns by Microsoft: [https://adpg.link/s2Uq](https://adpg.link/s2Uq)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RFC 6902 (JSON Patch): [https://adpg.link/bGGn](https://adpg.link/bGGn)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'JSON Patch in ASP.NET Core web API: [https://adpg.link/u6dw](https://adpg.link/u6dw)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Strangler Fig Application pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Martin Fowler: [https://adpg.link/Zi9G](https://adpg.link/Zi9G)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Microsoft: [https://adpg.link/erg2](https://adpg.link/erg2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The message queue gets a message and has a single subscriber dequeue it. If
    nothing dequeues a message, it stays in the queue indefinitely (FIFO model). The
    Pub-Sub model gets a message and sends it to zero or more subscribers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Event sourcing is the process of chronologically accumulating events that happened
    in a system instead of persisting in the current state of an entity. It allows
    you to recreate the entity's state by replaying those events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes, you can mix Gateway patterns (or sub-patterns).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No, you can deploy micro-applications (microservices) on-premises if you want
    to.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It separates generic functionalities from app-specific ones, promoting cleaner
    code and modularization. It also helps simplify the frontend.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
