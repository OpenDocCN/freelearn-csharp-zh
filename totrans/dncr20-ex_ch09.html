<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" epub:prefix="z3998: http://www.daisy.org/z3998/2012/vocab/structure/#" lang="en" xml:lang="en">
<head>
    <title>Microservices with .NET Core</title>
    <link href="css/style.css" rel="stylesheet" type="text/css"/>
    <link href="68851547a55f.css" rel="stylesheet" type="text/css"/>
  </head>
  <body>
    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Microservices with .NET Core</h1>
                </header>
            
            <article>
                
<p class="mce-root">Over the last few years, a paradigm shift has happened in the way applications are designed, in the form of suites of smaller and independently deployable services, also known as <strong>microservice architecture</strong> or just <strong>microservices</strong>. The intent is to <span>develop simpler and independent services, to release them quickly, and to release them often and ensure that if one service is down then other services are not impacted, making the app more robust, reliable, and highly scalable. In the spirit of this new philosophy, and keeping up with the latest and greatest in the technology space, we will</span> cover the following topics in this chapter:</p>
<ul>
<li>Introduction to microservices</li>
<li>Handy things to know</li>
<li>Blazor—a new experiment from the ASP.NET team</li>
<li>What's coming in .NET Core 2.1</li>
</ul>
<p class="mce-root"><span>We have a lot to cover, so let's start with microservices.</span></p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introduction to microservices</h1>
                </header>
            
            <article>
                
<p>To better understand and appreciate the microservice architecture, we first need to see what a service is and how the traditional service monolithic architecture has limitations that can be overcome by microservices. Once we have this context set up, we will define microservices.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">A traditional service</h1>
                </header>
            
            <article>
                
<p>When we create any server-side enterprise app, it must support a variety of different clients, including desktop and mobile browsers, mobile apps, and so on. We may also expose APIs, so that third parties can consume them and integrate with our system. Like third parties, we may also need to integrate our application with other applications through APIs. The app would handle the requests by executing business logic, then performing read-write operations by accessing a database and/or other data providers and systems, and return an HTML/JSON/XML response. What I have described here is a typical enterprise application. We have different logical modules in the application to fulfill the business requirements. These modules are what we can refer to as services.</p>
<p>In essence, a service is just a software component that provides functionality to other pieces of software within your system. <span>A service should be well defined, self contained, and should not depend on the context or state of other services.</span> The other pieces of software could be anything—a website, a web app, a mobile app, a desktop app, or even another service. If I were to give an example, take any e-commerce website of your choice. The website displays the products and the deals. To display products and deals, it talks to a service. The service is actually responsible for the creation,update, deletion, and retrieval of data from the database, so the service provides functionality to the website.</p>
<p>The communication between the different software components and the service normally happens over a network using some kind of communication protocol. For example, your Facebook mobile app communicates to a service through the internet. A system which uses a service or multiple services in this fashion has what's called a <strong>service-oriented architecture</strong>, abbreviated as <strong>SOA</strong>. The idea behind SOA is to use a thick server rather than a thick client. This way, many clients can have the same functionality. In future, we can have newer or different types of clients connecting to the same service, reusing this functionality. As a software architecture, SOA has been very successful. A few of the benefits and features of SOA are:</p>
<ul>
<li>It allows the application to scale up when demand increases, by enabling us to have a copy of the service on multiple servers. When the burst of traffic comes in, a load balancer will redirect requests to a specific instance of the service. We can have multiple instances of a service.</li>
<li>It allows reusability of functionality. For instance, in a shopping web app, the function to create an order could be the same functionality, which is triggered by a mobile app on our service. So, it's the same code creating an order for both the website and the mobile app.</li>
<li>It allows standardized contracts or interface-based development. When a client application calls a service, it actually invokes a method in the service. The signature of the method typically doesn't change when the service implementation changes, so we can upgrade our service without having to upgrade our clients, as long as the contract and the signature of the method doesn't change. This way, we do not have to upgrade the clients when the service is upgraded.</li>
<li>It is stateless. When a request comes from a client to a service, that instance of the service does not have to remember the previous request from that specific client. It has all the information from the request that it needs in order to retrieve all the data associated with the previous request within the service, so a service does not have to remember the previous call the client has made to that particular instance of the service and no context needs to be maintained. It's stateless, therefore any instance of the service can honor any income request from a client, because it does not have to remember any previous interaction with any other instance of a service.</li>
<li>It is simple to develop, deploy, and scale the application.</li>
</ul>
<p>We should now have a fair idea of the SOA that we may have been using without knowing what it is for years. Traditional services, which may be using SOA, have typically been deployed as a monolith. Monolith consists of two words, mono and lith. Mono means single and lith means stone. However, in a software dictionary, monolithic architecture refers to applications that are deployed as a single unit. An important consideration when developing an application is how easy it is to learn and modify, and how quickly new developers can become productive on the application. These desired features give rise to an architecture that is simple and easily understandable. Another desired aspect is that it should be easy to deploy. Keeping all these things in mind, the architecture would be a layered application that has a user interface layer which communicates to a service layer, which does the data manipulation on the data provider. A typical layered application architecture would look as shown here:</p>
<div class="CDPAlignCenter CDPAlign"><img height="89" width="367" src="assets/10cb449a-f43b-4443-b69c-de7fb2542d1e.png"/></div>
<p><span>The application is deployed as a single monolithic application and we can run multiple instances of the application behind a load balancer in order to scale and improve availability.</span></p>
<p>Over time, as the number of users of the application grows and new enhancements are added to the application, the code base grows at a rapid pace and it becomes difficult to understand and modify the code. So, the developers become less productive, especially the new ones. Since it is complex to understand and modify the code base, the bug count in the application increases, which degrades the quality of the application. As the code base grows, the IDE (such as Visual Studio) becomes overloaded and hence slower, making developers less productive. A <span>large monolithic application is also an obstacle to continuous deployment. In order to update/deploy one component, the entire application needs to be deployed, which results in down time. A monolithic application is also an obstacle to scaling development. Once the application gets to a certain size, it's useful to divide up the engineering organization into teams that focus on specific functional areas. The trouble with a monolithic application is that it prevents the teams from working independently, as the code and functionality is coupled in a single monolith. Monolithic architecture forces us to be married to a technology stack. So if we have used a Java stack, we need to be with Java as long as the application lasts, even if there are better tools and technology innovations in other stacks.</span></p>
<p class="mce-root"><span>The monolithic architecture of an e-commerce website is shown here:</span></p>
<div class="CDPAlignCenter CDPAlign"><img height="318" width="276" src="assets/ecd1e776-88ea-44a5-8495-27a9d4114e7e.png"/></div>
<p><span>Due to these limitations, monolithic architecture, which has been around for a quite a while, has started to lose popularity over the years. Data speaks for itself. So, if we look at the Google trend report for SOA over the last five years, it is a graph of losing interest over time. It can be seen at <a href="https://trends.google.com/trends/explore?date=today%205-y&amp;q=SOA">https://trends.google.com/trends/explore?date=today%205-y&amp;q=SOA</a>:<a href="https://trends.google.com/trends/explore?date=today%205-y&amp;q=SOA"></a></span></p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/e91d2568-a095-4273-8065-f03c8339a105.png"/></div>
<p>Unfortunate but true, as it happens everywhere else, a loss for one is a gain for another. The decline of SOA has seen the rise of microservices. If we look at the Google trend report for microservices over the same period of the last five years, we see a graph of increasing interest over time, as shown here. This can be seen at <a href="https://trends.google.com/trends/explore?date=today%205-y&amp;q=Microservice">https://trends.google.com/trends/explore?date=today%205-y&amp;q=Microservice</a>:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/b1cf0db8-5840-4717-87eb-4f82eacc7f76.png"/></div>
<p>This is not just because it is trending, but because major large enterprises such as Netflix, Amazon, eBay, and so on have talked about the way they scaled and eased out the continuous delivery of their services using microservice architecture, so microservice architecture design doesn't seems to be a buzz to ignore. This architectural framework is one of the core selling points for emerging start-ups, such as Docker, which at the time of writing is valued at about $1 billion while still in funding.</p>
<p>Let's have a look at microservices.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Microservices</h1>
                </header>
            
            <article>
                
<p><strong>Microservices,</strong> also known as <span>the <strong>microservice architecture</strong>, is an architectural style that structures an application as a collection of loosely coupled independent services that implement business capabilities. The microservice architecture enables the continuous delivery and deployment of large, complex applications. It also enables an organization to evolve its technology stack.</span> The microservice architecture is basically an improved version of SOA, and therefore it shares all the key characteristics of SOA, such as scalability, re-usability, standardized contracts in interfaces for backwards compatibility, and the idea of having a <span>stateless</span> service that we discussed previously. <span>Microservice capabilities are expressed formally with business-oriented APIs. In short, the microservice architectural style defines a setup where application components are standalone applications of their own. These independent application components talk to each other either using <strong>Remote Method Invocation</strong> (<strong>RMI</strong>), RESTful web services or push messaging. Each microservice owns its related domain data model and domain logic, based on different data storage technologies and different programming languages.</span></p>
<p>Because of the name, you may ask what the size of a microservice should be. When developing microservices, size is not a critical factor to consider. The imperative point is to make loosely coupled services, so that we have autonomy of development, and deployment and scaling for each service. Obviously, we should strive to make them as small as possible, as long as we don't have an excessive number of direct dependencies upon other microservices.</p>
<p>The following image shows a typical microservice architecture of an e-commerce website:</p>
<div class="CDPAlignCenter CDPAlign"><img height="235" width="228" src="assets/29a01e66-81bc-4472-990d-dda58543f138.png"/></div>
<p>We can see that, compared to the monolithic architecture, this has a lot more modularity and autonomy and the services communicate with other microservices. Think of a situation where, due to some unavoidable issue, <strong>Payment Services</strong> goes down, maybe due to bad code being checked in. The users of the site would still be able to view and update the cart. Only the payment functionality would be down and the rest of the services would keep serving the users. Now, think about a monolithic architecture where there is no independence of module and this sort of bad code issue happens. The chances of failure in such cases would be higher in monolithic architecture and we may even have a situation where a number of features stop working due to dependency.</p>
<p>The following image presents a good comparison between monolithic and microservice architectures:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/41472c96-127f-4c77-989f-ca4257bc8c54.png"/></div>
<p>Microsoft has provided a sample reference app and architecture guidance for microservices with ASP.NET Core. The sample is available on GitHub at <a href="https://github.com/dotnet-architecture/eShopOnContainers">https://github.com/dotnet-architecture/eShopOnContainers</a><span>.<a href="https://trends.google.com/trends/explore?date=today%205-y&amp;q=SOA"></a></span></p>
<p>To get a reasonable understanding and hands-on experience in the development of microservices, it is recommended that the reader has a good look at the repository. What we have discussed is the tip of the iceberg and just an introduction to microservices. We will conclude this discussion with the reference links to microservices, so that enthusiastic readers can gain more insights into this new paradigm:</p>
<ul>
<li><strong>.NET application architecture</strong>: <a href="https://www.microsoft.com/net/learn/architecture">https://www.microsoft.com/net/learn/architecture</a></li>
<li><strong>News on .NET architecture</strong>: <a href="https://github.com/dotnet-architecture/News">https://github.com/dotnet-architecture/News</a></li>
<li><strong>Martin Fowler on microservices</strong>: <a href="http://martinfowler.com/articles/microservices.html">http://martinfowler.com/articles/microservices.html</a></li>
<li><strong>Microservice architecture pattern</strong>: <a href="http://microservices.io/patterns/microservices.html">http://microservices.io/patterns/microservices.html</a></li>
</ul>
<p>In the next section, we will be discussing tips and tricks that I found really helpful while doing development, debugging, and monitoring the ASP.NET Core 2.0 web apps.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Handy things to know</h1>
                </header>
            
            <article>
                
<p>It's important for us to understand that there are fundamental architecture differences between ASP.NET and ASP.NET Core. A few of the important ones are listed here:</p>
<ul>
<li><span><span>An important difference between ASP.NET and ASP.NET Core is that ASP.NET Core doesn't have a request queue, unlike ASP.NET. The <kbd>RequestQueue</kbd> class which resides in the <kbd>System.Web</kbd> namespace is designed to prevent thread pool starvation in ASP.NET. This no longer exists in ASP.NET Core, so as you can rightly guess, there can be thread pool starvation if we do not write proper code. Just so that we are on the same page, starvation describes a situation where a thread is unable to gain regular access to shared resources and is unable to make progress. This happens when shared resources are made unavailable for long periods by greedy long running threads. For example, suppose an object provides a synchronized method that often takes a long time to return. If one thread invokes this method frequently, other threads that also need frequent synchronized access to the same object will often be blocked.</span></span></li>
<li><kbd>AppDomain</kbd> is another area where ASP.NET Core is different to ASP.NET. Running many instances of <kbd>AppDomain</kbd> require runtime support and are generally quite expensive. ASP.NET Core doesn't use <kbd>AppDomain</kbd>. There is a single process and a single <kbd>AppDomain</kbd>, if that makes things easier to comprehend.</li>
<li>ASP.NET Core doesn't have <kbd>SyncronizationContext</kbd>. If you don't know <kbd>SyncronizationContext</kbd>, don't worry. We are discussing it right now. C# 5 came with two new keywords, <kbd>async</kbd> and <kbd>await</kbd>, which provide a new and easier asynchronous programming experience. The approach to use is simple. Have the <kbd>async</kbd> keyword in the method definition. Change the return type of the method from <kbd>T</kbd> to <kbd>Task&lt;T&gt;</kbd> or <kbd>Task</kbd>, if it doesn't return anything (I would not recommend using <kbd>void</kbd>, unless it's an event handler method). It is also a good practice to use the <kbd>async</kbd> suffix in the method name, so that it is easy to identify that the method is asynchronous. You would also need to use at least one <kbd>await</kbd> statement in the method. Under the hood, the compiler translates the <kbd>async</kbd> method into a state machine and virtually converts it into a method that is invoked multiple times, once at the actual method invocation that proceeds till the statement containing the <kbd>await</kbd> keyword and then returns. When the statement containing the <kbd>await</kbd> keyword is executed, the method is invoked again from there and executes the remainder of the statements, in the same fashion. The following code lists a sample <kbd>async</kbd> method leveraging the <kbd>async</kbd> and <kbd>await</kbd> keywords:</li>
</ul>
<pre style="padding-left: 60px">public async Task&lt;Stream&gt; GetFileContentAsync()<br/>{<br/>    using(var httpClient = new HttpClient())<br/>    {<br/>        var stream = await <br/>        httpClient.GetStreamAsync(<br/>        "http://localhost:9596/api/Files/1");<br/>        return stream;<br/>    }<br/>}</pre>
<p style="padding-left: 60px">An important feature of the <kbd>async</kbd> and <kbd>await</kbd> keywords is support for <kbd>SyncronizationContext</kbd>. <kbd>SyncronizationContext</kbd> has been inside the framework since .NET 2.0 and is not something newly added to the framework. As discussed previously, when we <kbd>await</kbd> on an <kbd>async</kbd> method, the compiler hooks up the continuation, if there is any, and the resulting code is aware of the context. So, if the <kbd>SyncronizationContext</kbd> is available, the <kbd>await</kbd> expression will capture it and use it to invoke the continuation, very similar to the <kbd>ContinueWith</kbd> method offered in the <strong>Task Parallel Library</strong> (<strong>TPL</strong>). <kbd>SyncronizationContext</kbd> should be used with utmost care and if we consume the method in blocking fashion, it may lead to deadlock. For example, in a non-ASP.NET Core environment, if we wait on a <kbd>Task</kbd> using the <kbd>Wait</kbd> method or using the <kbd>Result</kbd> property, we block the main thread. When eventually the task completes inside that method in the thread pool, it will invoke the continuation to post back to the main thread. But since we have blocked the main thread and the task is waiting for the main thread, we will have deadlock. As a precaution, library writers are advised to use <kbd>ConfigureAwait(false)</kbd> while invoking <kbd>async</kbd> APIs, to avoid deadlock. Now that we know <kbd>SyncronizationContext</kbd>, remember that ASP.NET Core doesn't have it! So <kbd>ConfigureAwait(false)</kbd> doesn't do anything in ASP.NET Core. But that doesn't mean threads can't get blocked in ASP.NET Core. Bad code can still do wonders.</p>
<ul>
<li>While ASP.NET works on top of <kbd>System.Web</kbd>, has a rather tight integration with <strong>Internet Information Server</strong> (<strong>IIS</strong>), and runs inside the IIS process (<kbd>w3wp.exe</kbd>), ASP.NET Core runs outside of the IIS process. The <strong>ASP.NET Core Module</strong> (<strong>ANCM</strong>) enables the ASP.NET Core apps to run behind IIS in a reverse proxy configuration, which we saw in an earlier chapter. Just to refresh our memories, the work of the proxy or forward proxy is to send a request to the server on behalf of a client, while that of the reverse proxy is to receive the request on behalf of a server. The following image is the high-level architecture of ASP.NET Core. Notice that the center box containing ANCM is the only module that runs inside of <kbd>w3wp.exe</kbd>. The <strong>Kestrel</strong> server and the <strong>App Code</strong> runs inside <kbd>dotnet.exe</kbd>. Contrast it with traditional ASP.NET, which runs inside <kbd>w3wp.exe</kbd>:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img src="assets/3c4df845-3c71-4052-82dc-21e1bd7fb594.png"/></div>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">General tips</h1>
                </header>
            
            <article>
                
<p>Now that we know the differences, let's move on to some tips and tricks that are based on top of these architectural differences and more:</p>
<ul>
<li>Recently, I was working on the performance optimization of the ASP.NET Core app. We had used in-memory caching with a cache get timeout of five seconds. You would expect that any data from in-memory caching would be retrieved in a matter of milliseconds as it is an in-process cache and this was generally true. However, under load we figured out that data was not getting picked up from the cache. Once we added logging, we figured out that the <kbd>Get</kbd> operation in cache was timing out. Yes, even with a five-second value, we had a timeout while fetching data from the cache. On investigation, we figured out that we had thread starvation in the app. As discussed previously, there is no <kbd>RequestQueue</kbd> class in ASP.NET Core for avoiding this, so here are some tips to avoid thread starvation:
<ul>
<li>Always prefer to use <kbd>async</kbd> all the way, that is, all the APIs must be <kbd>async</kbd>.</li>
<li><span>Avoid blocking APIs in your ASP.NET Core application as much as possible. So,</span> <strong>DON'T USE</strong>:
<ul>
<li><kbd>Task.Wait()</kbd></li>
<li><kbd>Task.Result</kbd></li>
<li><kbd>Thread.Sleep</kbd></li>
<li><kbd>GetAwaiter().GetResult()</kbd>.</li>
</ul>
</li>
<li>Avoid <kbd>sync</kbd> over <kbd>async</kbd> as they are essentially blocking <kbd>async</kbd> methods.</li>
<li>Avoid <kbd>async</kbd> over <kbd>sync</kbd> as they have scalability issues.</li>
<li>Log thread pool stats in the application code. This helps identify thread starvation. Here is the sample code that can be used for logging thread stats. It gives stats for both <kbd>iopc</kbd> and <kbd>worker</kbd> threads:</li>
</ul>
</li>
</ul>
<pre style="padding-left: 60px">        private static int GetThreadPoolStats(out string iocp, out <br/>        string worker)<br/>        {<br/>            int maxIoThreads, maxWorkerThreads;<br/>            ThreadPool.GetMaxThreads(out maxWorkerThreads, out <br/>            maxIoThreads);<br/><br/>            int freeIoThreads, freeWorkerThreads;<br/>            ThreadPool.GetAvailableThreads(out freeWorkerThreads, <br/>            out freeIoThreads);<br/><br/>            int minIoThreads, minWorkerThreads;<br/>            ThreadPool.GetMinThreads(out minWorkerThreads, out <br/>            minIoThreads);<br/><br/>            int busyIoThreads = maxIoThreads - freeIoThreads;<br/>            int busyWorkerThreads = maxWorkerThreads - <br/>            freeWorkerThreads;<br/>            iocp = $"(Busy={busyIoThreads},<br/>            Free={freeIoThreads},Min=<br/>            {minIoThreads},Max={maxIoThreads})";<br/>            worker = $"(Busy={busyWorkerThreads},Free=<br/>            {freeWorkerThreads},Min={minWorkerThreads},Max=<br/>            {maxWorkerThreads})";<br/>            return busyWorkerThreads;<br/>        }</pre>
<ul>
<li style="list-style-type: none">
<ul>
<li>Use tools such as <a href="https://github.com/benaadams/Ben.BlockingDetector">https://github.com/benaadams/Ben.BlockingDetector</a> <span>to diagnose blocking.</span></li>
<li>Set minimum threads using <kbd>ThreadPool.SetMinThreads</kbd> to keep you safe from starvation. The number of minimum threads depends on what your app does and you may have to fine-tune it based on your testing. Note that <kbd>ThreadPool</kbd> can quickly (read instantly) span the threads up to the minimum number of thread pool threads specified. After that, if more threads are needed, they are throttled by 500 ms and this can cause delays or timeouts in service, which are hard to comprehend in production environments.</li>
<li>You may also want to read about this issue here: <a href="https://github.com/aspnet/KestrelHttpServer/issues/2104">https://github.com/aspnet/KestrelHttpServer/issues/2104</a>.</li>
</ul>
</li>
<li><span>The concept of <kbd>AppDomain</kbd> no longer exists in ASP.NET Core, so for code isolation, Microsoft recommends processes and/or containers. For dynamic loading of assemblies, the</span> <span>recommendation is to use the <kbd>AssemblyLoadContext</kbd> class.</span></li>
<li>Since there is no <kbd>SyncronizationContext</kbd> in ASP.NET Core, thankfully there shouldn't be any deadlocks in ASP.NET Core if you block a task through <kbd>Task.Wait</kbd> or <kbd>Task.Result</kbd>. However, this should not be taken as a license to use blocking. We must always strive for <kbd>async</kbd> all the way.</li>
<li>As discussed previously, <kbd>ConfigureAwait (false)</kbd> has no effect in ASP.NET Core, so the following two code snippets work the same way:</li>
</ul>
<pre style="padding-left: 60px">var stream = await   <br/>httpClient.GetStreamAsync("http://localhost:9596/api/Files/1");<br/>var stream = await <br/>httpClient.GetStreamAsync("http://localhost:9596/api/Files/1").ConfigureAwait(false);</pre>
<ul>
<li>Task continuations in ASP.NET Core are queued to <kbd>ThreadPool</kbd> and hence can run in parallel. Don't be surprised if your <kbd>task.ContinueWith(x=&gt;SomeFunction())</kbd> stops working in ASP.NET Core.</li>
<li><kbd>HttpContext</kbd> is not thread safe. Accessing it in parallel may lead to unreliable data and issues.</li>
<li>Use Swagger for API testing and documentation. <span>Swagger makes it incredibly easy to document and test your APIs. I highly recommend you make use of Swagger for the documentation of APIs. There are other tools such as Postman and Fiddler that can be used for testing the APIs but Swagger does a great job at it as well. Performing a basic API test is as simple as reading this link: <a href="https://swagger.io/blog/how-to-perform-a-basic-api-test/">https://swagger.io/blog/how-to-perform-a-basic-api-test/</a>. Read the steps for using Swagger to generate documentation at <a href="https://docs.microsoft.com/en-us/aspnet/core/tutorials/web-api-help-pages-using-swagger?tabs=visual-studio">https://docs.microsoft.com/en-us/aspnet/core/tutorials/web-api-help-pages-using-swagger?tabs=visual-studio</a>.<a href="https://docs.microsoft.com/en-us/aspnet/core/tutorials/web-api-help-pages-using-swagger?tabs=visual-studio"></a></span></li>
<li><span>The <kbd>InMemory</kbd> provider of Ef Core is very useful when you want to test components using something that approximates connecting to the real database, without the overhead of actual database operation. Please see this link for the step-by-step approach: <a href="https://docs.microsoft.com/en-us/ef/core/miscellaneous/testing/in-memory">https://docs.microsoft.com/en-us/ef/core/miscellaneous/testing/in-memory</a>.<a href="https://docs.microsoft.com/en-us/ef/core/miscellaneous/testing/in-memory"></a></span></li>
<li>ANCM is designed in such a way that if your first request takes a lot of time, it will disconnect the client and close the process.</li>
<li>Security is one of the most important but often overlooked aspects in the development of web apps. Security is such a vast topic to cover that it is beyond the scope of this book, but I would highly recommend developers thoroughly go through the security documentation of ASP.NET Core at <a href="https://docs.microsoft.com/en-us/aspnet/core/security/">https://docs.microsoft.com/en-us/aspnet/core/security/</a> and inculcate their learning in day-to-day development activities.</li>
<li><span>At times, we may have an issue even while starting the app, due to an incorrect code. Though the console logger logs the output in the console window that appears briefly at the startup, as soon as the console vanishes (which happens pretty quickly), we have no means to know what happened or what prevented the app from being started. In such situations, generally the ASP.NET Core module configuration can help us unearth the root cause of the issue. The configuration is done in the <kbd>aspNetCore</kbd> section of the <kbd>system.webserver</kbd> node present in the <kbd>web.config</kbd> file, which is located at the root of the web app. We can enable the output logging and specify the log file path. So, in such cases, the detailed error message will be logged, and we will be able to identify the cause of the issue. The following entry from <kbd>web.config</kbd> illustrates this:</span></li>
</ul>
<pre style="padding-left: 60px"><span>&lt;aspNetCore processPath=".\PacktLetsChat.exe"                 stdoutLogEnabled="true"                 stdoutLogFile=".\logs" /&gt;   &lt;/system.webServer&gt;</span></pre>
<p style="padding-left: 60px"><span>When the app is deployed in Azure, the <kbd>stdoutLogFile</kbd> path is modified to direct</span> the app <span>to the <kbd>LogFiles</kbd> folder of the app.</span></p>
<p>In this section, we discussed a few points relating to the usage of ASP.NET Core. In the next section, we will discuss a few tips on performance.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Performance tips</h1>
                </header>
            
            <article>
                
<p><span>ASP.NET Core is one of the fastest platforms on the fundamentals of web request routing, as per benchmarks. Read the complete story at <a href="https://www.techempower.com/blog/2016/11/16/framework-benchmarks-round-13/">https://www.techempower.com/blog/2016/11/16/framework-benchmarks-round-13/</a>.</span> In this section, we will discuss the points we can use to achieve better performance in our ASP.NET Core apps:</p>
<ul>
<li>It might sound repetitive, but please use <kbd>async</kbd> all the way. This is key to the performance of an ASP.NET Core app.</li>
<li>Test, test, and test! Perform load testing of your app early and often to find the issues early in development. Our team, in fact, came up with a radical idea to identify performance bottlenecks. The idea is to write middleware, that calculates the response time of the API, and if the response time is higher than the threshold, throw an exception, so the developer has to fix it. I would not recommend going this drastic but the intent is to identify the performance issues early in the game. If your app is deployed in Azure, you can do the performance testing in the Azure portal itself, using the following simple steps (here I am assuming there is no authentication header needed, otherwise we can write Visual Studio performance tests as well):
<ol>
<li>In the Azure portal, navigate to the App Service that we wish to performance test.</li>
<li>On the left panel of the App Service, there is an item called <span class="packt_screen">Performance test</span>. Click on it. It will open the <span class="packt_screen">P<span class="packt_screen">erformance test</span></span> blade.</li>
<li>Enter the required fields for user load and duration. Each of the fields has a help tool tip so it should be easy to identify the purpose of each field.</li>
<li>Configure the test to use either a manual URL or a Visual Studio web test. If you select manual test, you will need to specify the URL that needs to be load tested. If of a Visual Studio web test, you will need to upload the Visual Studio web test file.</li>
<li>Click <strong><span class="packt_screen">Done</span></strong> and then click <strong><span class="packt_screen">Run test</span></strong>.</li>
<li>The performance test will run and display the run stats, such as successful requests, failed requests with errors, memory and CPU usage, and so on:
<div class="CDPAlignCenter CDPAlign"><img height="362" width="259" src="assets/51840ec0-f83a-473d-b6b3-686ce738248a.png"/></div>
</li>
</ol>
</li>
<li>Use caching to store static, less frequently changing and frequently accessed data. If you are building an enterprise application, consider leveraging the Azure Redis cache for fast data access.</li>
<li>Use the garbage collector in server garbage collection mode. This will ensure that your memory footprint doesn't increase over time. This can be done by the following configuration in the <kbd>web.config</kbd> file, or add an <kbd>app.config</kbd> file with the following code:</li>
</ul>
<pre style="padding-left: 60px">&lt;configuration&gt; <br/>   &lt;runtime&gt; <br/>      &lt;gcServer enabled="true"/&gt; <br/>   &lt;/runtime&gt; <br/>&lt;/configuration&gt;</pre>
<div class="packt_infobox">You can read more about the <kbd>gcServer</kbd> element at <a href="https://docs.microsoft.com/en-us/dotnet/framework/configure-apps/file-schema/runtime/gcserver-element">https://docs.microsoft.com/en-us/dotnet/framework/configure-apps/file-schema/runtime/gcserver-element</a>.</div>
<ul>
<li>If you make use of web APIs in your application, use <kbd>HttpClient</kbd> to make the API calls. Remember to create the <kbd>HttpClient</kbd> instance only once and reuse it multiple times, that is, create a singleton instance of <kbd>HttpClient</kbd> and don't create it every time. In terms of Dependency Injection, use it as singleton and not as transient or scoped.</li>
<li>While developing the API, follow these rules:
<ul>
<li><strong>Bring only the data that you need</strong>: For the purpose of code re-usability, I have seen teams using a single API that returns a plethora of data, even though only a part of it is needed. For a small number of users, it may not perform badly, but as the user load increases, this will start causing performance bottlenecks, so be very miserly with the data that your service returns.</li>
<li><strong>Choice of serializer</strong>: A considerable amount of time is spent by a service API in serializing the data and then sending it as a response. The client then gets the response and deserializes it back which again takes time. It is worth investing in a serializer that does the job faster, to provide better response time performance. There are a number of serializers at the developer's disposal such as JSON, BSON, MessagePack, Protocol Buffers, and so on. We recently changed JSON to MessagePack and found massive performance gains, as a MessagePack payload is about 66% of JSON and about three times as fast.</li>
<li><strong>Compression:</strong> Think of compressing the data sent from the service API to the client. This will be beneficial to mobile users, as well as to whoever may be using your app on a flaky and low bandwidth network, so less data to load would make apps faster. Also, by compressing the payload, we make our application scalable as the bandwidth available to us is limited. There are numerous ways of doing it. Of course, <kbd>HttpClient</kbd> has support for <kbd>GZip</kbd> compression so we can leverage it. Equally important is the fact that we can choose what properties to serialize. So, if your entity has ten properties and you need only two properties, then it makes perfect sense to serialize only those two properties and ignore the remaining eight properties, to reduce the payload. This is well supported in JSON and we made extensive use of it, and in a few cases came down from 32 MB data to less than 1 MB data. Imagine if this API is called by hundreds of users!</li>
</ul>
</li>
<li>Make good use of bundling and minification, as discussed in an earlier chapter.</li>
<li><span>Response caching reduces the number of requests a client or proxy makes to a web server. Response caching also reduces the amount of work the web server performs to generate a response, hence improving the performance. Please make a note that response caching is not supported for ASP.NET Core Razor pages, but support is expected to come in ASP.NET Core 2.1.</span></li>
<li>While using parallelism or multiple threads to write data, make use of concurrent collections. In fact, if you think you may have multiple threads modifying a collection, it's always safe to use concurrent collections, with little overhead.</li>
<li>Avoid API or database calls inside a loop. In the case of APIs, try to create an API that takes the collection as input and processes that to return a consolidated but trimmed set of required data. In the case of a database, create a stored procedure that accepts a user-defined table as a parameter and returns the data in one go. This will make the application less chatty.</li>
<li>Do not perform string concatenation inside loops. Use <kbd>StringBuilder</kbd> if you need to concatenate strings inside loops.</li>
<li>Visual Studio has great support for profiling your application to identify high CPU issues, so do make good use of the Visual Studio profiler while in the development phase. It's very simple to use, as illustrated in these steps:
<ol>
<li>Ensure that the app that you wish to profile is up and running in the machine.</li>
<li>Open Visual Studio and in the quick launch, search for <span class="packt_screen">Performance Explorer</span>. Alternatively, you can navigate through <span class="packt_screen">Debug | Profiler | Performance Explorer | Attach/Detach,</span> as shown here:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/f4952a2a-0817-435e-9dc3-47fd3956883c.png"/></div>
<ol start="3">
<li>It will open a dialog, displaying the list of running processes. Select the process that you wish to profile and click <span class="packt_screen">Attach.</span></li>
<li>The profiling will start. Now is the time to reproduce your high CPU issue and once it is reproduced, stop the profiling. It will generate a detailed profiling report. We will see what the profile report looks like a little later when we discuss profiling in Azure.</li>
</ol>
</li>
</ul>
<ul>
<li>Profile your memory to identify whether there is a memory leak. Always remember, that if your memory percentage remains constant or keeps increasing over a period of time, there may be a memory leak. <span>Memory leak can be described as a situation where a program holds on to the memory even if that memory is discarded and no longer needed. Due to bad coding, the developer code can prevent the <strong>Garbage Collector</strong> (<strong>GC</strong>) from reclaiming the memory, and hence, used memory keeps increasing over a period of time, resulting in performance issues or failures.</span> Apart from Visual Studio, there are many good profiling tools that can be used such as dotTrace, MemProfiler, ANTS Memory Profiler, PerfView, to name a few. One of the common causes of memory leak in the ASP.NET Core applications that I have encountered is wrong Dependency Injection. So, if an object needs to be scoped or transient and you register it as a singleton, we may be injecting memory leak if it's not meant to be a singleton. Static objects and dictionaries are another common cause of memory leak, so please think multiple times before marking an object as static.</li>
<li>ASP.NET Core has support for analyzers. <span>Code analysis, as the name suggests, is the analysis of the code to identify potential code issues, such as improper coding, noncompliance to standards, security violations, and design problems. Code analysis can be static or dynamic. In static, the analysis is done without actually running the code. StyleCop, FxCop are few of the most well-known and frequently used code analyzers.</span> Make use of analyzers to identify code issues early. A few of the great ones are <kbd>Microsoft.CodeAnalysis</kbd>, <span><kbd>SonarAnalyzer.Csharp</kbd>, <kbd>FxCop analyzer</kbd>, <kbd>Roslynator.Analyzers</kbd>, and <kbd>Stylecop analyzer</kbd>, to name a few. These are also simple to use—right-click on the project and select <span class="packt_screen">Nuget Package Manager</span>. Search for the analyzer of your choice and install it. Build your project and observe the warnings and errors in the error window. This will help you nail a variety of issues, such as possible performance bottlenecks, security vulnerabilities, as well as not following best practices.</span></li>
</ul>
<div class="packt_infobox">Read this excellent MSDN blog post on performance improvements in ASP.NET Core: <a href="https://blogs.msdn.microsoft.com/dotnet/2017/06/07/performance-improvements-in-net-core/">https://blogs.msdn.microsoft.com/dotnet/2017/06/07/performance-improvements-in-net-core/</a>.<br/>
Also, read the official performance documentation of ASP.NET Core at <a href="https://docs.microsoft.com/en-us/aspnet/core/performance/">https://docs.microsoft.com/en-us/aspnet/core/performance/</a>.</div>
<p>Next, we will look at a few of the cool and handy features of Azure that can help us be more productive.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Azure tips</h1>
                </header>
            
            <article>
                
<p>Azure has a plethora of features and most of them remain unexplored or unused by a number of developers, though they are extremely useful and provide value. A few of the important ones I came across are listed here:</p>
<ul>
<li><strong>Azure in your pocket</strong>: We will start with a cheesy one. Yes, Azure in your pocket. Now Azure is available as a mobile app, and you can virtually carry your Azure subscription wherever you go. You can keep track of your Azure resources on the go and stay connected—anytime, anywhere. The following image shows a glimpse of the Azure mobile app:
<div class="CDPAlignCenter CDPAlign"><img style="text-align: center;color: #333333;font-size: 1em" height="476" width="268" src="assets/d12f8f80-285f-47f6-8381-552aadc944ac.png"/></div>
</li>
</ul>
<ul>
<li><strong>Advisor</strong>: In the left panel of the Azure portal, there is an item called <span class="packt_screen">Advisor</span>. Although it's free, it's a relatively lesser-used and talked about feature of Azure. It's completely free and it provides real-time advisory services on your Azure resources, based on how they are used. Just click on the <span class="packt_screen">Advisor</span> and it will give security, performance, cost, and availability recommendations. The recommendations can also be downloaded in CSV or PDF format. Here is the teaser of Azure Advisor:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img src="assets/502b6376-7da3-4313-a53b-291a50aedd71.png"/></div>
<ul>
<li><strong>Security Center</strong>: Just like <span class="packt_screen">Advisor</span>, there is a <span class="packt_screen">Security Center</span> option in the left panel. This is a great and free feature of Azure. It does threat detection all the Azure resources in your subscription and gives pointed recommendations. It also lets you know of any security incidents that occurred with your resources and threat assessment reports. There is a paid plan which has advanced threat detection but the free option is a good starting point. The following image shows the <span class="packt_screen">Security Center</span>:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img src="assets/52cad30f-da83-436a-b310-8a831c0997d4.png"/></div>
<ul>
<li><strong>Activity logs</strong>: When I have worked in a team that is working on Azure, there have been instances where I am working on the web app and some other team member accidentally changes the configuration, or maybe restarts or deletes a resource, and I have no clue what happened. I have myself been the culprit, modifying the configuration while the performance test was running, which restarted the web app. Azure has a solution for these kinds of situations as well. Every action that a user does is logged in the activity log of the resource you are working with. So, next time you encounter something like this, just go and see the activity log, as shown here. In the Azure portal, go to the resource you wish to see the activity log of. On the left panel of the resource, click on <span class="packt_screen">Activity Log</span>. You can also apply filters and choose the time duration for which you wish to see the activity log:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img src="assets/1a49b25f-8382-4241-8193-8e2af8b8d833.png"/></div>
<ul>
<li><strong>Diagnostic logging</strong>: If you are running into issues in the app deployed in Azure and do not know what's going on, enable logging and Application Insights in your app. We looked at Application Insights earlier. Logging can give us details such as failed request tracing and detailed error logs. You will see two options for Application Logging—<span class="packt_screen">Blob</span> and <span class="packt_screen">Filesystem</span>. As the name suggests, logs are stored in blob and filesystem. Filesystem logging is enabled only for 12 hours, as there is a risk of logs eating up memory. The following image shows the diagnostic logging configuration:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="509" width="202" src="assets/779e4da9-2644-4bf0-8ade-71cb02493c79.png"/></div>
<ul>
<li><strong>Diagnosing and solving issues</strong>: This is another cool feature in Azure. If you run into issues or suspect something is going wrong in your App Service, Azure provides very good diagnoses and a fix for the issues. It is able to clearly identify whether the issue is due to a platform or application code issue. It diagnoses a variety of problem categories such as web app down, slow web app, high CPU usage, high memory usage, web app restarted, TCP connections. It has a chat interface making it easier to use. Just click on one of the problem categories and it will do the analysis on the app for the last 24 hours and share the graph and findings, which makes it extremely easy to identify the issue. It will also give recommendations if you need to scale out your app. Also, you can do a health checkup of the resource on demand, which gives a single view for application errors, performance, CPU, and memory usage. This is definitely a very handy tool to use for diagnosis. Here is the screenshot for diagnosing and solving issues:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img src="assets/d9b7e223-36d8-44ba-a9c2-03eebc20cf50.png"/></div>
<ul>
<li><strong>Diagnostics as a Service (DaaS)</strong>: Yet another great troubleshooting tool for developers is DaaS. When you open the diagnose and solve issues blade for your App Service, there is a panel on the right displaying a number of links:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="566" width="197" src="assets/3c7d2aaf-ca58-46d3-90bb-d89655987fcf.png"/></div>
<p style="padding-left: 60px">Each of them is a great diagnostic and support tool in itself, but we will focus on DaaS. I would highly recommend you explore each of these links. Coming back to DaaS, this is what it looks like:</p>
<div class="CDPAlignCenter CDPAlign"><img height="221" width="335" src="assets/f2267c33-46bf-41f3-b576-d994519f3125.png"/></div>
<p style="padding-left: 60px">It has support for ASP.NET, PHP, and Java applications. We will select <span class="packt_screen">ASP.NET</span> as our application type and when we do that, we will see ASP.NET-specific diagnosers such as <span class="packt_screen">CLR Profiler</span>, <span class="packt_screen">Event Viewer Logs</span>, <span class="packt_screen">Memory Dump</span>, and <span class="packt_screen">HTTP Logs</span>. Based on the diagnosis that we need to do, we can select appropriate options. I generally check everything whenever I am doing diagnosis. <span class="packt_screen">Memory Dump</span> analysis can be great to identify memory leaks, but the dump needs to be taken when you observe constant high or increasing memory usage. Now, how to do it. Well, it's simple, you can see the memory and CPU usage of your App Service in the <span class="packt_screen">Overview</span> blade of your App Service in the portal. Note that you would need at least two memory dumps to confirm a memory leak. Likewise, <span class="packt_screen">CLR Profiler</span> can be used to find out what section of your code is doing the most work at the time of profiling, so it's important to profile when the time issue is occurring in your App Service. After selecting the options, click <span class="packt_screen">R<span>un</span></span>.</p>
<p style="padding-left: 60px">Azure will capture the data and then perform the analysis, and share the analysis report which you download and act upon, as shown in the following screenshot:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img src="assets/1b183337-c5f3-41ca-9cea-d2b460ca50a6.png"/></div>
<p style="padding-left: 60px">The <span class="packt_screen">CLR Profiler</span> <kbd>.diagsession</kbd> file can be downloaded by clicking on the <kbd>.diagsession</kbd> file shown in the image under the <span class="packt_screen">Collection Status</span> column, and opened in Visual Studio. It will give you the hot path as well as the code block and methods doing the most work during the profiling session. The <span class="packt_screen">Memory Dump</span> can also be downloaded and you can do a memory dump analysis locally using Windbg or DebugDiag, as needed. Azure provides a DebugDiag analysis report which can be directly downloaded.</p>
<ul>
<li><strong>Azure Service Profiler</strong>: Use Azure Service Profiler to identify high CPU issues. This has great support for ASP.NET Core 2.0. The setup details and value it provides can be seen at <a href="https://www.azureserviceprofiler.com/">https://www.azureserviceprofiler.com/</a>. On installing this Profiler for your web app, it will run as a web job and diagnose the issue by identifying the hot paths. It also s<span>ummarizes performance data to find long-tail performance problems.</span></li>
<li><strong>Profiling the app for high CPU</strong>: With the detailed metrics on CPU and memory provided by Azure, we can easily identify whether the App Service is using high CPU. If it is, how do we figure out what is causing the app to use high CPU? Yes, profiling. Profiling is easy to do in Visual Studio and even in Azure. Even though DaaS does the profiling, I always see <kbd>w3wp.exe</kbd> getting profiled and not the actual application <kbd>.exe</kbd> that we have built. To profile our application code, we can do the following simple steps:
<ol>
<li>In the Azure portal, select the App Service that you wish to profile (search for the App Service and click it).</li>
<li>In the left panel of the App Service, click on <span class="packt_screen">Advanced Tools</span>. This will open the <span class="packt_screen">Advanced Tools</span> blade. Click on the <span class="packt_screen">Go</span> button in this blade. This will take you to the Kudu site of your App Service. There is a shortcut to reach here. If your App Service URL is <a href="http://myappservice.azurewebsites.net">http://myappservice.azurewebsites.net</a>, then the corresponding Kudu site would be <a href="http://myappservice.scm.azurewebsites.net">http://myappservice.<strong>scm</strong>.azurewebsites.net</a>. Notice <kbd>scm</kbd> between <kbd>myappservice</kbd> and <kbd>azurewebsites.net</kbd>. You must have required access to the Kudu site, so not everyone can go to the Kudu site of any website:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7b91ffaa-1eb3-4da3-b782-54895d5c72bb.png"/></div>
<ol start="3">
<li>In the top bar, select <span class="packt_screen">Process explorer.</span> This will open the <span class="packt_screen">Process Explorer</span> as shown here:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/7d5bdf46-c149-4041-9db8-3cdf4207e597.png"/></div>
<ol start="4">
<li>Click on the <span class="packt_screen">Start Profiling</span> button of your application <kbd>.exe</kbd>, when you observe high CPU in the app. It will take a while to start profiling. Once the profiling is done, click on <span class="packt_screen">Stop Profiling</span>. This will start generating the diagnostics and generate the <kbd>.diagsession</kbd> file, which you will be prompted to download.</li>
<li>Upon downloading the file, open it with Visual Studio. It will show the CPU graph. There will be a button called <span class="packt_screen">C</span><span class="packt_screen">reate detailed report</span><span>. Click on it and it will open a nice-looking report with hot paths, a summary, and will lead you to the code causing the high CPU, as shown here:</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img src="assets/79c138b4-1f4b-465b-ab47-545726067c37.png"/></div>
</li>
<li><strong>Support</strong>: Now that we know the Kudu site, another diagnostic tool that may be useful is Azure App Service Support, which can be browsed by appending <kbd>/support</kbd> in the Kudu site URL. For the preceding example, the support site would be <a href="http://myappservice.scm.azurewebsites.net/support">http://myappservice.scm.azurewebsites.net/support</a>. As of writing this chapter, it is in a preview state. We can <span class="packt_screen">Observe</span>, <span class="packt_screen">Analyze</span>, and <span class="packt_screen">Mitigate</span> the issues from here, as shown in the following screenshot. The <span class="packt_screen">Observe</span> section can be used to view stats such as requests/second and errors/sec. The <span class="packt_screen">Analyze</span> section can be used to view <span class="packt_screen">FREB (<strong>F</strong>ailed <strong>R</strong>equest <strong>E</strong>rror <strong>B</strong>uffering) Logs</span>, <span class="packt_screen">Event Viewer</span> logs, and running <span class="packt_screen">Diagnostics</span> to figure out CPU and memory issues. The <span class="packt_screen">Mitigate</span> section has a switch to autoheal the app. Most memory and CPU issues are resolved upon restart and that is where the autoheal feature comes into the picture. If you have a scenario where you need to recycle the application automatically, after it has served, say, <em>X</em> number of requests in <em>Y</em> amount of time, you can consider autoheal as an option—<em>X</em> and <em>Y</em> can be configured by means of a rule:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="276" width="531" src="assets/98dd093c-23ed-4a30-bd6c-259228453019.png"/></div>
<ul>
<li><strong>New support request</strong>: If none of these options seem to have helped you identify the issue, which shouldn't happen often if done well, you can leverage the expertise of Azure support to help you with an issue, by creating a <span class="packt_screen">New support request</span> in the left panel of your App Service, as shown here:</li>
</ul>
<div class="CDPAlignCenter CDPAlign"><img height="238" width="527" src="assets/91bb1d5d-6ef3-4a0e-9f3a-e19c0becbe55.png"/></div>
<p>Next, let's have a quick look at a new experimental project of the ASP.NET team called Blazor.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Introducing Blazor</h1>
                </header>
            
            <article>
                
<p>Blazor is a new experiment by the ASP.NET team. Blazor got its name from two words, Browser and Razor.</p>
<p>Blazor is an experimental web UI framework using C#, Razor, and HTML, running in the browser through WebAssembly.</p>
<p>What is WebAssembly? <strong>WebAssembly</strong> or <strong>wasm</strong> <span>is an open, new-age format standard, with an initial version that has reportedly reached cross-browser consensus. It is described as <em>a new portable, size-and load-time-efficient format suitable for compilation to the Web.</em> WebAssembly is a new type of code that can be run in modern web browsers. It is a low-level assembly-like language with a compact binary format that runs with near-native performance and provides languages, such as C/C++, with a compilation target so that they can run on the web. It is also designed to run alongside JavaScript, allowing both to work together. It is a browser improvement. Since it is a binary format, we'll be able to compile binary bundles that compress to a smaller size than the text JavaScript. Smaller payloads means faster delivery and so it may run faster than JavaScript.</span></p>
<p><span>Blazor runs .NET code in the browser via a small, portable .NET runtime called <strong>DotNetAnywhere</strong> (<strong>DNA</strong>) compiled to WebAssembly. Essentially, Blazor makes life easier and happier for developers like me who are not great at JavaScript and want to write less of it. You can code your entire app in C#, Razor, and HTML, which runs inside the browser, without having to write a single line of JavaScript and it works just like any <strong>Single-Page Application</strong> (<strong>SPA</strong>). It gives all the benefits of a rich and modern platform while letting us use .NET end to end.</span></p>
<p>Blazor is developed as a personal project by Steve Sanderson, who is part of the ASP.NET team and works out of the UK. He has a detailed blog which talks about it and how it works. It can be read at <a href="http://blog.stevensanderson.com/2018/02/06/blazor-intro/">http://blog.stevensanderson.com/2018/02/06/blazor-intro/</a>.<a href="http://blog.stevensanderson.com/2018/02/06/blazor-intro/"></a></p>
<p>Other blogs providing great insights into Blazor can be read at <a href="https://visualstudiomagazine.com/articles/2017/08/09/blazor.aspx">https://visualstudiomagazine.com</a>.<a href="https://visualstudiomagazine.com/articles/2017/08/09/blazor.aspx">/articles/2017/08/09/blazor.aspx</a> and <a href="https://blogs.msdn.microsoft.com/webdev/2018/02/06/blazor-experimental-project/">https://blogs.msdn.microsoft.com/webdev/2018/02/06/blazor-experimental-project/</a>.<a href="https://blogs.msdn.microsoft.com/webdev/2018/02/06/blazor-experimental-project/"></a></p>
<p>The demo of Blazor can be seen at <a href="https://blazor-demo.github.io/">https://blazor-demo.github.io/</a>.<a href="https://blazor-demo.github.io/"></a></p>
<p>If this sounds exciting, there is even more exciting stuff in the upcoming 2.1 release of ASP.NET Core. Let's have a sneak peek at it.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">What's coming in .NET Core 2.1</h1>
                </header>
            
            <article>
                
<p>The preview version of .NET Core 2.1 is launched on February 27th 2018. We can start developing a .NET Core 2.1 application using Visual Studio 2017 15.6 Preview 6 or later, and also using Visual Studio Code. Let's see what is newly added to .NET Core 2.1.</p>
<ul>
<li><strong>Build performance:</strong> In .NET Core 2.1, build time performance has improved. CLI tools and MSBuild have improved and are much faster than before.</li>
<li><strong>Minor version roll forward:</strong> We can run the .NET Core X.x application on later minor versions with the same major version range, such as .NET Core 2.1 applications on .NET Core 2.6. This roll forward feature is applicable to minor versions only, so 2.1 can't be automatically rolled forward to .NET Core 3.0, or any other major version. Roll forward behavior is only relevant when the expected .NET Core version is not present in the given environment. We can disable this feature using:
<ul>
<li><strong>Environment variable</strong>: <kbd>DOTNET_ROLL_FORWARD_ON_NO_CANDIDATE_FX=0</kbd></li>
<li><strong>runtimeconfig.json</strong>: <kbd>rollForwardOnNoCandidateFx=0</kbd></li>
<li><strong>CLI</strong>: <kbd>roll-forward-on-no-candidate-fx=0</kbd></li>
</ul>
</li>
<li><strong>Sockets performance and HTTP managed handler:</strong> As part of the new version, socket performance has increased. Sockets are the basis of outgoing and incoming network communication. In .NET Core 2.0 ASP.NET, the Kestrel web server and <kbd>HttpClient</kbd> use native <kbd>Socket</kbd> not the .NET <kbd>Socket</kbd> class. There will be three significant performance improvements for sockets. It supports <kbd>Span&lt;T&gt;</kbd> and <kbd>Memory&lt;T&gt;</kbd> in <kbd>Socket</kbd> and <kbd>NetworkStream</kbd>. <kbd>SocketHttpHandler</kbd> performance has improved. A few benefits are:
<ul>
<li>Platform dependencies have been eliminated on libcurl (linux) and WinHTTP (Windows)—this simplifies both development, deployment, and servicing</li>
<li>Consistent behavior across all platforms and platform/dependency versions</li>
<li>We can opt in to using the <kbd>SocketHTTPHandler</kbd> in one of the following ways with Preview 1:
<ul>
<li><strong>Environment variable</strong>: <kbd>COMPlus_UseManagedHttpClientHandler=true</kbd></li>
<li><strong>AppContext</strong>: <kbd>System.Net.Http.UseManagedHttpClientHandler=true</kbd></li>
</ul>
</li>
</ul>
</li>
<li><strong>Span&lt;T&gt;</strong>, <strong>Memory&lt;T&gt;:</strong>&#160;New types are introduced for using arrays and for other types of memory, which is efficient and increases performance. Using <kbd>Span</kbd>, we can pass a subset of an array, for example 5 elements of a 100 element array, we can create a <kbd>Span&lt;T&gt;</kbd> which provides a virtual of that array, without time or space cost. Now, no need to make a copy of those five arrays. This is also <kbd>struct</kbd>, so no allocation cost. With slicing capabilities, it obviates the need for expensive copying and allocation in many cases, such as string manipulation buffer management and so on. Here is an example of creating <kbd>Span&lt;T&gt;</kbd> from an array:</li>
</ul>
<pre style="padding-left: 60px">var arrayExample= new byte[10];<br/>Span&lt;byte&gt; bytes = arrayExample; // Implicit cast from T[] to Span&lt;T&gt;</pre>
<p style="padding-left: 60px">From there, we can easily and efficiently create a <kbd>Span</kbd> to represent/point to just a subset of this array, utilizing an overload of the span’s <kbd>Slice</kbd> method. From there, you can index into the resulting span to write and read data in the relevant portion of the original array:</p>
<pre style="padding-left: 60px">Span&lt;byte&gt; slicedBytes = bytes.Slice(start: 5, length: 2);<br/>slicedBytes[0] = 42;<br/>slicedBytes[1] = 43;<br/>Assert.Equal(42, slicedBytes[0]);<br/>Assert.Equal(43, slicedBytes[1]);<br/>Assert.Equal(arrayExample [5], slicedBytes[0]);<br/>Assert.Equal(arrayExample [6], slicedBytes[1]);<br/>slicedBytes[2] = 44; // Throws IndexOutOfRangeException<br/>bytes[2] = 45; // OK<br/>Assert.Equal(arrayExample [2], bytes[2]);<br/>Assert.Equal(45, arr[2]);<br/> </pre>
<ul>
<li><strong>Windows Compatibility Pack:</strong> When we port existing code from the .NET Framework to .NET Core, we can use the <a href="https://blogs.msdn.microsoft.com/dotnet/2017/11/16/announcing-the-windows-compatibility-pack-for-net-core/">new Windows Compatibility Pack</a>. It provides access additional 20,000 APIs, compared to what is available in .NET Core. This includes <kbd>System.Drawing</kbd>, EventLog, WMI, Performance Counters, and Windows Services. The following example illustrates accessing the Window registry with APIs provided by the Windows Compatibility Pack. The sample fetches the value of <kbd>TechnicalEditor</kbd> of book <kbd>NetCore2ByExample</kbd> from <kbd>CurrentUser</kbd> registry hive:</li>
</ul>
<pre style="padding-left: 60px">using (var userHiveRegKey = Registry.CurrentUser.OpenSubKey(@"Software\Packt\Books\NetCore2ByExample"))<br/>        {<br/>           var value = userHiveRegKey?.GetValue("TechnicalEditor");<br/>        }</pre>
<p>To learn more about .NET Core 2.1 features, please visit the following resources:</p>
<ul>
<li><a href="https://blogs.msdn.microsoft.com/webdev/2018/02/02/asp-net-core-2-1-roadmap/">https://blogs.msdn.microsoft.com/webdev/2018/02/02/asp-net-core-2-1-roadmap/</a></li>
<li><a href="https://github.com/dotnet/core/blob/master/roadmap.md">https://github.com/dotnet/core/blob/master/roadmap.md</a></li>
</ul>
<p>With this, we conclude the chapter.</p>


            </article>

            
        </section>
    </div>


    <div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we got an overview of microservice architecture how it is an extension of SOA and overcomes the limitations of traditional monolithic apps. We also learned the important architectural differences between ASP.NET and ASP.NET Core. We discussed a few tips to keep in mind while developing ASP.NET Core 2.0 applications, due to the architectural differences. We then discussed a few handy tips to improve the performance of ASP.NET Core apps. We discussed a few tips on Azure as well and then moved our discussion to the new experimental project of the ASP.NET Core team, called Blazor. We concluded the chapter with a discussion on the features that are coming in ASP.NET Core 2.1. In the next and final chapter of the book, we will discuss functional programming with F#.</p>


            </article>

            
        </section>
    </div>
</body>
</html>