- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hot Dog or Not Hot Dog Using Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will learn how to use machine learning to create a model
    that we can use for image classification. We will export the model as an **Onnx**
    model that we can use on all platforms – that is, Android, iOS, macOS, and Windows.
    To train and export models, we will use Azure Cognitive Services and the Custom
    Vision service.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have exported the models, we will learn how to use them in a .NET MAUI
    app.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Training a model with Azure Cognitive Services and the Custom Vision service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Onnx models for image classification using ML.NET
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using custom routes in .NET MAUI for navigation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to complete this project, you need to have Visual Studio for Mac
    or PC installed, as well as the .NET MAUI components. See *Chapter 1*, *Introduction
    to .NET MAUI*, for more details on how to set up your environment. You also need
    an Azure account. If you have a Visual Studio subscription, there are a specific
    amount of Azure credits included each month. To activate your Azure benefits,
    go to [https://my.visualstudio.com](https://my.visualstudio.com).
  prefs: []
  type: TYPE_NORMAL
- en: You can also create a free account, where you can use selected services for
    free over 12 months. You will get $200 worth of credit to explore any Azure service
    for 30 days, and you can also use the free services at any time. Read more at
    [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/).
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have and do not want to sign up for a free Azure account, the
    trained model is available in the source code for this chapter. You can download
    and use the pre-trained model instead.
  prefs: []
  type: TYPE_NORMAL
- en: The source code for this chapter is available at the GitHub repository for the
    book at [https://github.com/PacktPublishing/MAUI-Projects-3rd-Edition](https://github.com/PacktPublishing/MAUI-Projects-3rd-Edition).
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The term **machine learning** was coined in 1959 by Arthur Samuel, an American
    pioneer in **artificial intelligence** (**AI**). Tom M. Mitchell, an American
    computer scientist, provided the following more formal definition of machine learning
    later:'
  prefs: []
  type: TYPE_NORMAL
- en: “A computer program is said to learn from experience E with respect to some
    class of tasks T and performance measure P if its performance at tasks in T, as
    measured by P, improves with experience E.”
  prefs: []
  type: TYPE_NORMAL
- en: In simpler terms, this quote describes a computer program that can learn without
    being explicitly programmed. In machine learning, algorithms are used to build
    a mathematical model of sample data or training data. The models are used for
    computer programs to make predictions and decisions without being explicitly programmed
    for the task in question.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will learn about a few different machine learning services
    and APIs that are available when developing a .NET MAUI application. Some APIs
    are only available for specific platforms, such as Core ML, while others are cross-platform.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Cognitive Services – Custom Vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Custom Vision is a tool or service that can be used to train models for image
    classification and to detect objects in images. With Custom Vision, we can upload
    our own images and tag them so that they can be trained for image classification.
    If we train a model for object detection, we can also tag specific areas of an
    image. Because models are already pre-trained for basic image recognition, we
    don’t need a large amount of data to get a great result. The recommendation is
    to have at least 30 images per tag.
  prefs: []
  type: TYPE_NORMAL
- en: When we have trained a model, we can use it with an API, which is part of the
    Custom Vision service. We can also export models for **Core ML** (**iOS**), **TensorFlow**
    (**Android**), the **Open Neural Network Exchange** (**ONNX**), and a **Dockerfile**
    (**Azure IoT Edge**, **Azure Functions**, and **Azure ML**). These models can
    be used to carry out classification or object detection without being connected
    to the Custom Vision service.
  prefs: []
  type: TYPE_NORMAL
- en: You will need an Azure subscription to use it – go to [https://azure.com/free](https://azure.com/free)
    to create a free subscription, which should be enough to complete this project.
  prefs: []
  type: TYPE_NORMAL
- en: Core ML
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Core ML is a framework that was introduced in iOS 11\. Core ML makes it possible
    to integrate machine learning models into iOS apps. On top of Core ML, we have
    high-level APIs, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Vision APIs for image analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural language APIs for natural language processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech to convert audio to text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sound analysis to identify sounds in audio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GameplayKit to evaluate learned decision trees and strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More information
  prefs: []
  type: TYPE_NORMAL
- en: More information about Core ML can be found in the official documentation from
    Apple at [https://developer.apple.com/documentation/coreml](https://developer.apple.com/documentation/coreml).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorFlow is an open source machine learning framework. However, TensorFlow
    can be used for more than simply running models on mobile devices – it can also
    be used to train models. To run it on mobile devices, we have TensorFlow Lite.
    The models that are exported from Azure Cognitive Services are for TensorFlow
    Lite. There are also C# bindings for TensorFlow Lite that are available as a NuGet
    package.
  prefs: []
  type: TYPE_NORMAL
- en: More information
  prefs: []
  type: TYPE_NORMAL
- en: More information about TensorFlow can be found in the official documentation
    at [https://www.tensorflow.org/](https://www.tensorflow.org/).
  prefs: []
  type: TYPE_NORMAL
- en: ML.Net
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'ML.NET is an open source and cross-platform machine learning framework with
    support for iOS, macOS, Android, and Windows, all from a familiar environment
    – C#. ML.NET provides **AutoML**, a set of productivity tools that make building,
    training, and deploying custom models easy. ML.NET can be used in the following
    scenarios and more:'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis and product recommendation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object detection and image classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Price prediction, sales spike detection, and forecasting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fraud detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer segmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have a broad overview of the technologies at play, we will focus
    on using ML.NET, since it is a cross-platform framework and built for C#. Let’s
    look at the project we are going to build next.
  prefs: []
  type: TYPE_NORMAL
- en: The project overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have seen the TV series *Silicon Valley*, you have probably heard of
    the *Not Hotdog* application. In this chapter, we will learn how to build that
    app. The first part of this chapter will involve collecting the data that we will
    use to create a machine learning model that can detect whether a photo contains
    a hot dog.
  prefs: []
  type: TYPE_NORMAL
- en: In the second part of the chapter, we will build an app using .NET MAUI and
    ML.NET, where the user can either take a new photo or pick a photo in the photo
    library, analyzing it to see whether it contains a hot dog. The estimated time
    for completing this project is 120 minutes.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can use either Visual Studio 2022 on a PC or Visual Studio for Mac to do
    this project. To build an iOS app using Visual Studio for PC, you must have a
    Mac connected. If you don’t have access to a Mac at all, you can choose to just
    do the Android and Windows parts of this project.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, if you only have a Mac, you can choose to just do the iOS and macOS
    or Android parts of this project.
  prefs: []
  type: TYPE_NORMAL
- en: Building the Hot Dog or Not Hot Dog application using machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s get started! We will first train a model for image classification that
    we can use later in the chapter to decide whether a photo contains a hot dog.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'If you do not want to go through the effort of training a model, you can download
    a pre-trained model from the following URL: [https://github.com/PacktPublishing/MAUI-Projects-3rd-Edition/tree/main/Chapter12/HotdogOrNot/Resources/Raw](https://github.com/PacktPublishing/MAUI-Projects-3rd-Edition/tree/main/Chapter12/HotdogOrNot/Resources/Raw).'
  prefs: []
  type: TYPE_NORMAL
- en: Training a model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To train a model for image classification, we need to collect photos of hot
    dogs and photos that aren’t of hot dogs. Because most items in the world are not
    hot dogs, we need more photos that don’t contain hot dogs. It’s better if the
    photos of hot dogs cover a lot of different hot dog scenarios – with bread, ketchup,
    or mustard. This is so that the model will be able to recognize hot dogs in different
    situations. When we collect photos that aren’t of hot dogs, we also need to have
    a large variety of photos that are both of items that are like hot dogs and that
    are completely different from hot dogs.
  prefs: []
  type: TYPE_NORMAL
- en: The model that is in the solution on GitHub was trained with 240 photos, 60
    of which were of hot dogs, and 180 of which were not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have collected all the photos, we will be ready to start training the
    model by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://customvision.ai](https://customvision.ai).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in and create a new project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Give the project a name – in our case, `HotDogOrNot`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select a resource or create a new one by clicking **Create new**. Fill in the
    dialog box, and select **CustomVision.Training** in the **Kind** dropdown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The project type should be **Classification**, and the classification type should
    be **Multiclass (Single tag** **per image)**.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Select **General (compact)** as the domain. We use a compact domain if we want
    to export models and run them on a mobile device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click **Create project** to continue, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.1 – Creating a new AI project](img/B19214_12_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Creating a new AI project
  prefs: []
  type: TYPE_NORMAL
- en: Once we have created a project, we can start to upload images and tag them.
  prefs: []
  type: TYPE_NORMAL
- en: Tagging images
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The easiest way to get images is to go to Google and search for them. We will
    start by adding photos of hot dogs by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Click **Add images**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the photos of hot dogs that should be uploaded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tag the photos with `hotdog`, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Uploading images of hot dogs](img/B19214_12_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Uploading images of hot dogs
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have uploaded all the photos of hot dogs, it’s time to upload photos
    that aren’t of hot dogs by following the following steps. For best results, we
    should also include photos of objects that look similar to hot dogs but are not:'
  prefs: []
  type: TYPE_NORMAL
- en: Click the **Add images** button above the gallery of uploaded images.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the photos that aren’t of hot dogs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tag the photos with `Negative`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A Negative tag is used for photos that don’t contain any objects that we have
    created other tags for. In this case, none of the photos we will upload contain
    hot dogs, as can be seen in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Uploading images that aren’t hot dogs](img/B19214_12_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Uploading images that aren’t hot dogs
  prefs: []
  type: TYPE_NORMAL
- en: Once we have uploaded the photos, it’s time to train a model.
  prefs: []
  type: TYPE_NORMAL
- en: Training a model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Not all the photos that we are uploading will be used for training; some will
    be used for verification to give us a score about how good the model is. If we
    upload photos in chunks and train the model after each chunk, we will be able
    to see our scores improving. To train a model, click the green **Train** button
    at the top of the page, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 12.4 – Training the mode\uFEFFl](img/B19214_12_4.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.4 – Training the model
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the result of a training iteration where the
    precision of the model is **91.7%**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5 – Model verification results](img/B19214_12_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.5 – Model verification results
  prefs: []
  type: TYPE_NORMAL
- en: Once we have trained a model, we will export it so that it can be used on a
    device.
  prefs: []
  type: TYPE_NORMAL
- en: Exporting a model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can use the APIs if we want to, but to make fast classifications and to
    be able to do this offline, we will add the models to the app packages. Click
    the **Export** button and then on **ONNX** to download the model, as shown in
    the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6 – Exporting the model](img/B19214_12_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 – Exporting the model
  prefs: []
  type: TYPE_NORMAL
- en: Once we have downloaded the ONNX model, it’s time to build the app.
  prefs: []
  type: TYPE_NORMAL
- en: Building the app
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our app will use the trained models to classify photos, according to whether
    they are photos of hot dogs. We will use the same ONNX model for all platforms
    in the .NET MAUI app.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the new project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s begin, as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to create a new .NET MAUI projec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open Visual Studio 2022, and select **Create a** **new project**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 12.7 – Visual Studio\uFEFF 2022](img/B19214_12_7.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.7 – Visual Studio 2022
  prefs: []
  type: TYPE_NORMAL
- en: This will open the **Create a new** **project** wizard.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the search field, type in `maui`, and select the **.NET MAUI App** item
    from the list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 12.8 – Create a new pro\uFEFFject](img/B19214_12_8.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.8 – Create a new project
  prefs: []
  type: TYPE_NORMAL
- en: Click **Next**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Complete the next step of the wizard by naming your project. We will call our
    application `HotdogOrNot` in this case. Move on to the next dialog box by clicking
    **Next**, as illustrated in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 12.9 – Configure your new pro\uFEFFject](img/B19214_12_9.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 12.9 – Configure your new project
  prefs: []
  type: TYPE_NORMAL
- en: The last step will prompt you for the version of .NET Core to support. At the
    time of writing, .NET 6 is available as **Long-Term Support** (**LTS**), and .NET
    7 is available as **Standard Term Support**. For the purposes of this book, we
    will assume that you are using .NET 7.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 12.10 – Additional information](img/B19214_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.10 – Additional information
  prefs: []
  type: TYPE_NORMAL
- en: Finalize the setup by clicking **Create**, and wait for Visual Studio to create
    the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you run the app now, you should see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11 – The HotdogOrNot applicaton](img/B19214_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.11 – The HotdogOrNot applicaton
  prefs: []
  type: TYPE_NORMAL
- en: Just like that, the app is created. Next, let’s start creating the image classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying images with machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The first thing we will do is add the ONNX ML model to the project, by following
    these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract the `.zip` file that we got from the Custom Vision service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find the `.onnx` file, and rename it `hotdog-or-not.onnx`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add it to the `Resources/Raw` folder in the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once we add the file to the project, we are ready to create the implementation
    of the image classifier. The code that we will use for image classification will
    be shared between the .NET MAUI-supported platforms. We can create an interface
    for the classifier by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new folder named `ImageClassifier`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new class called `ClassifierOutput` in the `ImageClassifier` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Modify the `ClassifierOutput` class to look like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a new interface called `IClassifier` in the `ImageClassifier` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a method called `Classify` that returns `ClassifierOutput` and takes `byte[]`
    as an argument.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your interface should look like the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have the interface for the classifier, we can move on to the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Using ML.NET for image classiﬁcation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We are now ready to create the implementation of the `IClassifier` interface.
    Before we jump right into the implementation, let’s take a look at the high-level
    steps that will need to happen so that we understand the flow a little better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our trained model, `hotdog-or-not.onnx`, has specific input and output parameters,
    and we will need to convert the image that we want to classify into the input
    format before submitting it to the ML.NET framework. Additionally, we need to
    ensure that the image is in the correct shape before submitting it. The shape
    of the image is defined by the size, width, height, and color format. If the image
    does not match the input format, then it needs to be resized and converted before
    submission, or you will run the risk of the image being classified incorrectly.
    For image classification models that are generated by the Custom Vision service,
    such as the *hotdog-or-not* model, the inputs and outputs look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12 – Model inputs and outputs from Netron](img/B19214_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.12 – Model inputs and outputs from Netron
  prefs: []
  type: TYPE_NORMAL
- en: 'The input to the model is formatted into a multidimensional array named `data`.
    There are four dimensions that make up the array:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The image**: The format allows you to submit multiple images at once; however,
    for this app, we will only submit one image at a time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0` is blue, `1` is green, and `2` is red'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The height**: Each index is a position along the *y*, or vertical, axis of
    an image, in the range between 0 and 223'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The width**: Each index is a position along the *x*, or horizontal, axis
    of an image, in the range between 0 and 223'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The value is the color value for that specific image, color, and *x* and *y*
    positions. For example, `data[0,2,64,64]` would be the value of the green channel
    in the first image at a position of 64 pixels from the left and 64 pixels from
    the bottom of the image.
  prefs: []
  type: TYPE_NORMAL
- en: To reduce the number of incorrect classifications, we need to scale all the
    images for submission to 224 x 224 pixels and order the color channels properly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can do that by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new class called `MLNetClassifier` in the `ImageClassifier` folder
    of the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the `IClassifier` interface.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement the `Classify` method from the interface, as shown in the following
    code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'So far, we have not referenced any classes from ML.NET. To use the ML.NET APIs,
    we will need to add a reference to the NuGet package, by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: In the project, install the `Microsoft.ML.OnnxRuntime` NuGet package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accept any license dialog boxes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This will install the relevant NuGet packages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we are referencing the ML.NET package, we can compile the ONNX ML
    model by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: At the top of the `MLNetClassifier` file, add the `using Microsoft.ML.Onnx``Runtime;`
    declaration.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `MLNetClassifier` class, add the following fields:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the `MLNetClassifier` constructor, add the following lines of code to initialize
    the `OnnxRuntime` session, replacing the `// Initialize Model` `here` comment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let’s discuss the preceding code before moving on. The constructor for the
    `MLNetClassifier` class accepts `byte[]` as a parameter. This represents the ML
    model file. `byte[]` is then passed into a new instance of `InferenceSession`,
    which is the main entry point into the ML.NET API. Once the model is loaded into
    the session, we can then inspect the model for certain properties, such as the
    image format (`isBGR`), the color value range (`isRange255`), the input name,
    and the input size. We cache these values in the class fields for use during classification.
    Your `MLNetClassifier` class should now look like the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We can now move on to implementing the `Classify` method of the `MLNetClassifier`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step in running a classification is to get the input into the correct
    format. For image classification, that means resizing the image to the right dimensions
    and organizing the color values into the expected format. The image data is then
    loaded into `Tensor`, which is how we pass data into an ML.NET model. The following
    steps will create a method named `LoadInputTensor` to do just that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add a new method named `LoadInputTensor` after the `Classify` method in the
    `MLNetClassififier` class. This method will accept four parameters, `byte[]`,
    `int`, and two Booleans, and return a tuple of `Tensor<float>` and `byte[]`. Your
    method should look like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Inside `LoadInputTensor`, we will create the `return` objects and add the following
    highlighted lines of code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The next step is to resize the image; we will use the **ImageSharp** NuGet library
    to make this very easy.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Add the ImageSharp NuGet package to the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following lines of code to resize the image, replacing the `\\ Add
    code` `here` comment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This code uses the ImageSharp library to load the image from `byte[]`. The image
    is then resized to the size required by the model. We use the `imageSize` field,
    whose value captures the model requirement from the constructor. Finally, we set
    up a call to the `ProcessPixelRows` method that will allow us to manipulate the
    individual pixels in the image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Due to conflicts in naming between .NET MAUI and ImageSharp, we must add a
    declaration that tells the compiler which class we really want to use at the top
    of the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The next section of code will also need the following highlighted declarations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To get the input image into the correct color format required by the model,
    we use the `ProcessPixelRows` method from the `ImageSharp` library. This method
    provides a writable buffer for us to manipulate. Use the following highlighted
    code, in place of the `// Add Code here` comment, to iterate over the resized
    image data, putting the color values into the right order and clamping the values
    between 0 and 255, if required:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: What this code does is simple – using the provided source variable, it iterates
    over each row in the image, and each pixel in the row. If the model expects the
    colors to be in the blue, green, and red order, `isBGR` is `true`, and then the
    extracted color values are placed in the input tensor in that order; otherwise,
    they are added to the input tensor in the red, green, and blue order. The tricky
    part here is accessing the correct element for each pixel. The tensor is organized
    into four dimensions, as explained previously. The first element will always be
    zero for this model, since we are only processing one image at a time. The second
    dimension is the color channel, so you will see that change for the red, green,
    and blue color values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Finally, if the model expects color values to be in the range of 0 to 255, `isRange255`,
    then each color channel is clamped to that range.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The last thing that we will do is copy the contents of the resized image to
    the `pixelBytes` array so that we can display the image to the user. Add the following
    highlighted code to do this; note that the previous code has been omitted for
    brevity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that we have written the code to process the image and populate the input
    tensor, we can complete the `Classify` method by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Replace the `// Code will be added here` comment with a call to the `LoadInputTensor`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, we can run the session, passing in the newly created input tensor and
    capturing the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We grab the label from the output result, which will be used to determine whether
    this image contains a hotdog or not:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, we can get the confidence level of the result, which tells us how sure
    the model is of the classification. This will be used when we display the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can return the result of the classification using the `ClassifierOutput`
    class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The last step is to finish the `MLNetClassifier` implementation by implementing
    the `ClassifierOutput` class. Update your `ClassifierOutput` class by adding the
    highlighted code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `ClassifierOutput` class is used to encapsulate the four values that will
    be used in the UI and expose them as public properties. The `Create` static method
    is used to create an instance of the class. The `Create` method validates the
    arguments provided and sets the public properties appropriately for use by the
    UI.
  prefs: []
  type: TYPE_NORMAL
- en: We have now written the code to recognize hot dogs in an image.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can build the user interface for the application and call `MLNetClasssifier`
    to classify an image.
  prefs: []
  type: TYPE_NORMAL
- en: Requesting app permissions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we dive right into building the rest of the app functionality, we need
    to address permissions. This app will have two buttons that the user will use,
    one to take a photo and another to select a photo from the device. This is similar
    to the functionality that we saw in *Chapter 6*, *Building a Photo Gallery App
    Using CollectionView and CarouselView*, where we needed to request permission
    from the user before accessing the camera or device storage. However, we will
    implement the permissions differently than we did in that chapter. Since gaining
    access to the camera and accessing photos on the user’s device requires separate
    permissions, we will request them from each button handler.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to add a class to help us with the permission checks:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new class named `AppPermissions` in the project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Modify the class definition to add a `partial` modifier, and remove the default
    constructor:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following method to the `AppPermissions` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `CheckRequiredPermission` method is used to ensure that our app has the
    right permissions before we attempt any operations that might fail if we don’t.
    Its implementation is to call the .NET MAUI `CheckSyncStatus` with the provided
    permission type in `TPermission`. It returns `PermissionStatus`, which is `enum`.
    We are mostly interested in the `Denied` and `Granted` values.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Add the `CheckAndRequestRequiredPermission` method to the `AppPermissions`
    class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The `CheckAndRequestRequiredPermission` method handles the intricacies of requesting
    access from the user. The first step is to simply check and see whether the permission
    has already been granted and, if it has, return the status. Next, if we are on
    iOS and the permission has been denied, it cannot be requested again, so you must
    instruct the user on how to grant permission to the app by using the settings
    panel. Android includes in the request behavior the ability to nag the user if
    they have denied access. This behavior is exposed through .NET MAUI with the `ShouldShowRationale`
    method. It will return `false` for any platform that does not support this behavior,
    and on Android, it will return `true` the first time after the user denies access
    and `false` if the user denies it a second time. Finally, we request access to
    the permission from the user. Again, .NET MAUI hides all the platform implementation
    details from us, making checking and requesting access to certain resources very
    straightforward.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Look familiar?
  prefs: []
  type: TYPE_NORMAL
- en: If the preceding code looks familiar, then you are right. It is based on the
    implementation that is described in the .NET MAUI documentation. You can find
    it at [https://learn.microsoft.com/en-us/dotnet/maui/platform-integration/appmodel/permissions](https://learn.microsoft.com/en-us/dotnet/maui/platform-integration/appmodel/permissions).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the shared `AppPermissions` in place, we can start with the
    platform configuration. Before we can use the media picker, however, we need to
    do some configuration for each platform. We will start with Android.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Android API version 33, three new permissions were added to enable read
    access to media files – `ReadMediaImages`, `ReadMediaVideos`, and `ReadMediaAudio`.
    Prior to API version 33, all that was required was the `ReadExternalStorage` permission.
    To access the camera, we will need both `Camera` and `WriteExternalStorage` permissions.
    To properly request the correct permission for the API version of the device,
    open `MauiApplication.cs` in the `Platform/Android` folder and modify it to look
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: <queries>
  prefs: []
  type: TYPE_NORMAL
- en: <intent>
  prefs: []
  type: TYPE_NORMAL
- en: <action android:name="android.media.action.IMAGE_CAPTURE" />
  prefs: []
  type: TYPE_NORMAL
- en: </intent>
  prefs: []
  type: TYPE_NORMAL
- en: </queries>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: <key>NSCameraUsageDescription</key>
  prefs: []
  type: TYPE_NORMAL
- en: <string>This app needs access to the camera to take photos.</string>
  prefs: []
  type: TYPE_NORMAL
- en: <key>NSPhotoLibraryUsageDescription</key>
  prefs: []
  type: TYPE_NORMAL
- en: <string>This app needs access to photos.</string>
  prefs: []
  type: TYPE_NORMAL
- en: <key>NSMicrophoneUsageDescription</key>
  prefs: []
  type: TYPE_NORMAL
- en: <string>This app needs access to microphone.</string>
  prefs: []
  type: TYPE_NORMAL
- en: <key>NSPhotoLibraryAddUsageDescription</key>
  prefs: []
  type: TYPE_NORMAL
- en: <string>This app needs access to the photo gallery.</string>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: <Capabilities>
  prefs: []
  type: TYPE_NORMAL
- en: <rescap:Capability Name="runFullTrust" />
  prefs: []
  type: TYPE_NORMAL
- en: <DeviceCapability Name="webcam"/>
  prefs: []
  type: TYPE_NORMAL
- en: </Capabilities>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: using CommunityToolkit.Mvvm.ComponentModel;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using HotdogOrNot.ImageClassifier;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: namespace HotdogOrNot.ViewModels;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'public partial class MainViewModel : ObservableObject'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: private IClassifier classifier;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public MainViewModel()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Task InitTask() => Task.Run(async () =>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using var modelStream = await FileSystem.OpenAppPackageFileAsync("hotdog-or-not.onnx");
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using var modelMemoryStream = new MemoryStream();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: modelStream.CopyTo(modelMemoryStream);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var model = modelMemoryStream.ToArray();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: _classifier = new MLNetClassifier(model);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '});'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'public partial class MainViewModel : ObservableObject'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: IClassifier _classifier;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Task initTask;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public MainViewModel()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: _ = InitAsync();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public Task InitAsync()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if (initTask == null || initTask.IsFaulted)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: initTask = InitTask();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return initTask;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: // Code omitted for brevity
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: private async Task<byte[]> ConvertPhotoToBytes(FileResult photo)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if (photo == null) return Array.Empty<byte>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using var stream = await photo.OpenReadAsync();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using MemoryStream memoryStream = new();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: stream.CopyTo(memoryStream);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return memoryStream.ToArray();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: namespace HotdogOrNot.Models;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public class Result
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public bool IsHotdog { get; set; }
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public float Confidence { get; set; }
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public byte[] PhotoBytes { get; set; }
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[ObservableProperty]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: private bool isClassifying;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: async Task<Result> RunClassificationAsync(byte[] imageToClassify)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: try
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: await InitAsync().ConfigureAwait(false);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var result = _classifier.Classify(imageToClassify);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return new Result()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: IsHotdog = result.TopResultLabel == "hotdog",
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Confidence = result.TopResultScore,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: PhotoBytes = result.Image
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '};'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: catch
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: catch
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return new Result
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: IsHotdog = false,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Confidence = 0.0f,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: PhotoBytes = imageToClassify
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '};'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: finally
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: finally
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: MainThread.BeginInvokeOnMainThread(() => IsClassifying = false);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[RelayCommand()]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public async void TakePhoto()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if (MediaPicker.Default.IsCaptureSupported)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var status = await AppPermissions.CheckAndRequestRequiredPermissionAsync<Permissions.Camera>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if (status == PermissionStatus.Granted) {
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: status = await AppPermissions.CheckAndRequestRequiredPermissionAsync<Permissions.StorageWrite>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if (status == PermissionStatus.Granted)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: FileResult photo = await MediaPicker.Default.CapturePhotoAsync(new MediaPickerOptions()
    { Title = "Hotdog or Not?" });
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var imageToClassify = await ConvertPhotoToBytes(photo);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var result = await RunClassificationAsync(imageToClassify);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: await MainThread.InvokeOnMainThreadAsync(async () => await
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Shell.Current.GoToAsync("Result", new Dictionary<string, object>() { { "result",
    result } })
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: );
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[RelayCommand()]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public async void PickPhoto()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var status = await AppPermissions.CheckAndRequestRequiredPermissionAsync<Permissions.Photos>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if (status == PermissionStatus.Granted)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: FileResult photo = await MediaPicker.Default.PickPhotoAsync();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var imageToClassify = await ConvertPhotoToBytes(photo);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var result = await RunClassificationAsync(imageToClassify);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: await MainThread.InvokeOnMainThreadAsync(async () => await
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Shell.Current.GoToAsync("Result", new Dictionary<string, object>() { { "result",
    result } })
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: );
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: private bool CanExecuteClassification() => !IsClassifying;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[RelayCommand(CanExecute = nameof(CanExecuteClassification))]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public async void TakePhoto()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[RelayCommand(CanExecute = nameof(CanExecuteClassification))]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public async void PickPhoto()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <ContentPage
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: x:Class="HotdogOrNot.Views.MainView"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: x:DataType="viewModels:MainViewModel"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Title="Hotdog or Not hotdog">
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <HorizontalStackLayout VerticalOptions="Center" HorizontalOptions="CenterAndExpand">
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <Button Text="Take Photo" Command="{Binding TakePhotoCommand}" WidthRequest="150"
    HeightRequest="150" Margin="20" FontSize="Large"/>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <Button Text="Pick Photo" Command="{Binding PickPhotoCommand}" WidthRequest="150"
    HeightRequest="150" Margin="20" FontSize="Large"/>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: </HorizontalStackLayout>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: </ContentPage>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: public MainView(MainViewModel viewModel)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: InitializeComponent();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: BindingContext = viewModel; NavigationPage.SetBackButtonTitle(this, string.Empty);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: using CommunityToolkit.Mvvm.ComponentModel;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: using HotdogOrNot.Models;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: namespace HotdogOrNot.ViewModels;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'public partial class ResultViewModel : ObservableObject'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[ObservableProperty]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: private string title;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[ObservableProperty]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: private string description;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[ObservableProperty]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: byte[] photoBytes;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public ResultViewModel()
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: public void Initialize(Result result)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: PhotoBytes = result.PhotoBytes;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if (result.IsHotdog && result.Confidence > 0.9)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Title = "Hot dog";
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Description = "This is for sure a hot dog";
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: else if (result.IsHotdog)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Title = "Maybe";
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Description = "This is maybe a hot dog";
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: else
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Title = "Not a hot dog";
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Description = "This is not a hot dog";
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'public partial class ResultViewModel : ObservableObjectvoid method, ApplyQueryAttributes,
    that accepts a parameter named query of the IDictionary<string, object> type:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: public void ApplyQueryAttributes(IDictionary<string, object> query)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Initialize(query["result"] as Result);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}/'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: using System.Globalization;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: namespace HotdogOrNot.Converters;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'public class BytesToImageConverter : IvalueConverter'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public object Convert(object value, Type targetType, object parameter, CultureInfo
    culture)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: throw new NotImplementedException();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: public object ConvertBack(object value, Type targetType, object parameter, CultureInfo
    culture)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: throw new NotImplementedException();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: public object Convert(object value, Type targetType, object parameter, CultureInfo
    culture)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: if(value == null)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return null;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var bytes = (byte[])value;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: var stream = new MemoryStream(bytes);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return ImageSource.FromStream(() => stream);
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '}'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: <ContentPage     xmlns:converters="clr-
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: namespace:HotdogOrNot.Converters"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: x:Class="HotdogOrNot.Views.ResultView" Title="{Binding Title}">
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <ContentPage.Resources>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <converters:BytesToImageConverter x:Key="ToImage" />
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: </ContentPage.Resources>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <Grid>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <Grid.RowDefinitions>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <RowDefinition Height="2*" />
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <RowDefinition Height="*" />
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: </Grid.RowDefinitions>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <Image Source="{Binding PhotoBytes, Converter=
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '{StaticResource ToImage}}" Aspect="AspectFill" />'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <Label Grid.Row="1" HorizontalOptions="Center" FontAttributes="Bold" Margin="10"
    Text="{Binding Description}" />
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: </Grid>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: </ContentPage>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: public ResultView (ResultViewModel viewModel)
  prefs: []
  type: TYPE_NORMAL
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: InitializeComponent ();
  prefs: []
  type: TYPE_NORMAL
- en: BindingContext = viewModel;
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: <?xml version="1.0" encoding="UTF-8" ?>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <Shell
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: x:Class="HotdogOrNot.AppShell"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Shell.FlyoutBehavior="Disabled">
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: <ShellContent
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Title="Home"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ContentTemplate="{DataTemplate views:MainView}"
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Route="MainView" />
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: </Shell>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '#if DEBUG'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: builder.Logging.AddDebug();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '#endif'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: builder.Services.AddTransient<Views.MainView>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: builder.Services.AddTransient<Views.ResultView>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: builder.Services.AddTransient<ViewModels.MainViewModel>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: builder.Services.AddTransient<ViewModels.ResultViewModel>();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: return builder.Build();
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: public AppShell()
  prefs: []
  type: TYPE_NORMAL
- en: '{'
  prefs: []
  type: TYPE_NORMAL
- en: Routing.RegisterRoute("Result", typeof(HotdogOrNot.Views.ResultView));
  prefs: []
  type: TYPE_NORMAL
- en: InitializeComponent();
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
