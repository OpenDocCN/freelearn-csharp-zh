<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-144">
    <a id="_idTextAnchor174">
    </a>
    
     12
    
   </h1>
   <h1 id="_idParaDest-145">
    <a id="_idTextAnchor175">
    </a>
    
     Caching Strategies for Enhanced Performance
    
   </h1>
   <p>
    
     It’s been frequently mentioned how minimal APIs should be just that, minimal.
    
    
     For the most part, this minimalism has been based on minimizing real estate – trying to keep the visible footprint of our code on the page as minimal as possible.
    
    
     But minimalism in APIs also extends to the resource footprint, meaning that, where possible, we should minimize the strain put on the system by overusing database/network connections
    
    
     
      and CPU.
     
    
   </p>
   <p>
    
     Enhancing the performance of APIs through minimalism is the goal, and this can be achieved in part
    
    
     
      by caching.
     
    
   </p>
   <p>
    
     When data is cached, it is stored following its first use for reuse in future operations.
    
    
     By doing this, we can reduce the latency or overhead incurred when fetching
    
    
     
      that data.
     
    
   </p>
   <p>
    
     In this chapter, we’re going to cover the following
    
    
     
      main topics:
     
    
   </p>
   <ul>
    <li>
     
      Introduction to caching in
     
     
      
       minimal APIs
      
     
    </li>
    <li>
     
      In-memory
     
     
      
       caching techniques
      
     
    </li>
    <li>
     
      Distributed
     
     
      
       caching strategies
      
     
    </li>
    <li>
     
      
       Response caching
      
     
    </li>
   </ul>
   <h1 id="_idParaDest-146">
    <a id="_idTextAnchor176">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     Visual Studio 2022 or Visual Studio Code will be required to run the code in this chapter.
    
    
     You will also need SQL Server 2022 installed on your system, with a working database you can query as an example.
    
    
     It is recommended that you complete
    
    <a href="B20968_09.xhtml#_idTextAnchor143">
     
      <em class="italic">
       
        Chapter 9
       
      </em>
     
    </a>
    
     before this chapter so that you have the example employee database configured
    
    
     
      for use.
     
    
   </p>
   <p>
    
     The code for this chapter is available in the GitHub repository
    
    
     
      at:
     
    
    <a href="https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9">
     
      
       https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     This chapter demonstrates distributed caching strategies that require an in-memory caching provider – in this example’s case, Redis.
    
    
     Installing Redis is not within the scope of this book, but documentation on how to install Redis or host it in Azure can be found at
    
    <a href="https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/quickstart-create-redis">
     
      https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/quickstart-create-redis
     
    </a>
    
     
      and
     
    
    <a href="https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/">
     
      
       https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     The way to use Redis on your local Windows machine would be to install it through
    
    <strong class="bold">
     
      Windows Subsystem for Linux
     
    </strong>
    
     (
    
    <strong class="bold">
     
      WSL
     
    </strong>
    
     ) and
    
    <a id="_idIndexMarker477">
    </a>
    
     host it on your local WSL instance.
    
    
     More information on installing WSL can be found
    
    
     
      here:
     
    
    <a href="https://learn.microsoft.com/en-us/windows/wsl/install">
     
      
       https://learn.microsoft.com/en-us/windows/wsl/install
      
     
    </a>
    
     
      .
     
    
   </p>
   <h1 id="_idParaDest-147">
    <a id="_idTextAnchor177">
    </a>
    
     Introduction to caching in minimal APIs
    
   </h1>
   <p>
    
     APIs execute operations, and operations (usually) rely on data or state.
    
    
     Data needs to be retrieved or calculated as it either exists
    
    <em class="italic">
     
      at rest
     
    </em>
    
     (i.e., in a database or in a remote file location) or it exists as
    
    <em class="italic">
     
      data in use
     
    </em>
    
     (i.e., data that is yet to be calculated to produce
    
    
     
      other data).
     
    
   </p>
   <p>
    
     Whichever way we look at it, there is overhead in retrieving data, whether it is retrieved as-is or whether it is the result of a computation.
    
    
     Caching
    
    <a id="_idIndexMarker478">
    </a>
    
     aims to reduce that overhead by making use of data or state that has already been produced from its
    
    
     
      original source.
     
    
   </p>
   <p>
    
     It could be argued that computing is so fast now that the overhead should be minimal to the point that caching is no longer needed.
    
    
     This would, however, be woefully inaccurate.
    
    
     Looking at a single operation in isolation, such as retrieving a record from a SQL database, may seem extremely quick, but at scale, the benefits of caching become
    
    
     
      more apparent.
     
    
   </p>
   <p>
    
     Let’s take a working example of how caching can be beneficial.
    
    
     A start-up has built a system that can be used to send alerts to mobile devices, accessible via a minimal API.
    
    
     They must ensure that requests are allowed to be processed by calling clients, so they require an API key to be sent in the request headers for validation during
    
    
     
      each request.
     
    
   </p>
   <p>
    
     To validate the key, the start-up’s developers decided to outsource the key validation to a cloud company that manages the key and the encryption algorithms to be used – hosting an API itself for this purpose.
    
    
     The start-up is charged per request for validating
    
    
     
      the key.
     
    
   </p>
   <p>
    
     In the early days, the cost of validating keys went relatively unnoticed because they had a low number of sporadic requests.
    
    
     However, as soon as their business started to grow, so did the number of requests.
    
    
     Soon, they had a scary invoice from their cloud partner for a huge amount of API validations, charged
    
    
     
      per request.
     
    
   </p>
   <p>
    
     Caching
    
    <a id="_idIndexMarker479">
    </a>
    
     could have been used to mitigate the cost of validating API keys.
    
    
     An initial request could be made to validate the key, and then the result could be cached.
    
    
     From then on, when requests using that key are received, there would be an initial check against the cache first.
    
    
     If there is a record in the cache that validates the key, there is no need to call the paid API to validate it.
    
    
     Each cached record has an expiration date, meaning that it can be refreshed by calling the paid API again.
    
    
     This dramatically reduces the financial effects of validating
    
    
     
      API keys.
     
    
   </p>
   <p>
    
     We’ve established that caching is good for performance, reducing latency, and supporting overall application scalability, but what type of caching should we use?
    
    
     To answer this, we will explore three key caching methods available in minimal API development: in-memory caching, distributed caching, and
    
    
     
      response caching.
     
    
   </p>
   <h1 id="_idParaDest-148">
    <a id="_idTextAnchor178">
    </a>
    
     In-memory caching techniques
    
   </h1>
   <p>
    
     Out of the various caching techniques supported by ASP.NET Core,
    
    <strong class="bold">
     
      in-memory caching
     
    </strong>
    
     is
    
    <a id="_idIndexMarker480">
    </a>
    
     probably the
    
    <a id="_idIndexMarker481">
    </a>
    
     simplest.
    
    
     This type of caching stores its contents in the memory of the machine hosting the
    
    
     
      minimal API.
     
    
   </p>
   <p>
    
     The implementation of the cache is based on
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     , included within the
    
    <strong class="source-inline">
     
      Microsoft.Extensions.Caching.Memory
     
    </strong>
    
     package, which is usually included by default in ASP.NET
    
    
     
      Core projects.
     
    
   </p>
   <p>
    
     Like other core services,
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     is available using dependency injection, so we can quite easily inject it as needed within various areas of a
    
    
     
      minimal API.
     
    
   </p>
   <p>
    
     Using this cache type, we can store an object, which is our minimal requirement, but we can also very easily specify an expiration time, which is a best practice as periodically recycling the cache keeps it
    
    
     
      running smoothly.
     
    
   </p>
   <p>
    
     Let’s explore a simple example within a minimal API.
    
    
     I’m going to use the API project from
    
    <a href="B20968_09.xhtml#_idTextAnchor143">
     
      <em class="italic">
       
        Chapter 9
       
      </em>
     
    </a>
    
     (which is available on GitHub) as a foundation for this example project.
    
    
     Our aim is to mitigate the latency and overhead incurred when communicating with
    
    
     
      a database.
     
    
   </p>
   <p>
    
     In this API, we have an endpoint that allows clients to get an employee with a specific ID.
    
    
     The API will use Entity Framework to run a SQL query against the database, returning the result in the
    
    
     
      request response.
     
    
   </p>
   <p>
    
     Using an
    
    <a id="_idIndexMarker482">
    </a>
    
     in-memory cache, we
    
    <a id="_idIndexMarker483">
    </a>
    
     can add some optimization logic to this operation.
    
    
     Here are the steps we are going to
    
    
     
      work through:
     
    
   </p>
   <ol>
    <li>
     
      Run the operation as requested, fetching the data from
     
     
      
       the database.
      
     
    </li>
    <li>
     
      Check the in-memory cache to see whether the employee with this ID is
     
     
      
       currently cached.
      
     
    </li>
    <li>
     
      If it isn’t, add the retrieved employee to
     
     
      
       the cache.
      
     
    </li>
    <li>
     
      Return the employee in the
     
     
      
       request response.
      
     
    </li>
    <li>
     
      Create a request for the same employee (
     
     
      
       same ID).
      
     
    </li>
    <li>
     
      Get the employee from the cache instead of
     
     
      
       the database.
      
     
    </li>
    <li>
     
      Return the cached employee to
     
     
      
       the client.
      
     
    </li>
   </ol>
   <p>
    
     Before we can achieve this goal, we need to reference
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     in
    
    
     
      the project.
     
    
   </p>
   <p>
    
     First, add
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     to the dependency injection container
    
    
     
      in
     
    
    
     <strong class="source-inline">
      
       Program.cs
      
     </strong>
    
    
     
      :
     
    
   </p>
   <pre class="console">
builder.Services.AddMemoryCache();</pre>
   <p>
    
     Then, you can create the
    
    <strong class="source-inline">
     
      GET
     
    </strong>
    
     endpoint, injecting this
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     object along
    
    
     
      with
     
    
    
     <strong class="source-inline">
      
       DapperService
      
     </strong>
    
    
     
      :
     
    
   </p>
   <pre class="source-code">
app.MapGet(
    "/employees/{id}",
    async (int id,
           [FromServices] DapperService dapperService,
           IMemoryCache memoryCache) =&gt;
{
});</pre>
   <p>
    
     Now that you have a cache, you can add code for retrieving values
    
    
     
      from it:
     
    
   </p>
   <pre class="source-code">
if(memoryCache.TryGetValue(id, out var result))
{
    return result;
}</pre>
   <p>
    
     By first running a check, we can avoid unnecessary execution of code and get the required object to the client much quicker, also avoiding a call into the database
    
    
     
      via Dapper.
     
    
   </p>
   <p>
    
     Assuming that the item doesn’t exist, we will use our original logic of looking up the
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     record from the database using
    
    <strong class="source-inline">
     
      DapperService
     
    </strong>
    
     .
    
    
     However, instead of returning the item straight away, we will first add it to
    
    
     
      the cache:
     
    
   </p>
   <pre class="source-code">
<code>  var employee = await dapperService.GetEmployeeById(id);</code>
<code>  memoryCache.Set&lt;Employee&gt;(employee.Id, employee);</code></pre>
   <p>
    
     This works well but, ideally, we don’t want this to stay in the cache forever.
    
    
     It’s a good idea to refresh the cache periodically because data may change, and we want to ensure we are getting the most up-to-date data where possible while balancing this with reducing latency from
    
    
     
      database transactions.
     
    
   </p>
   <p>
    
     We can strike this
    
    <a id="_idIndexMarker484">
    </a>
    
     balance by imposing an expiration on cached objects.
    
    
     This needs to be done
    
    <a id="_idIndexMarker485">
    </a>
    
     after the retrieval of the
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     object but before it is added to the cache.
    
    
     Let’s set an expiry of
    
    <strong class="source-inline">
     
      30
     
    </strong>
    
     seconds as
    
    
     
      an example:
     
    
   </p>
   <pre class="source-code">
var cacheEntryOptions = new MemoryCacheEntryOptions()
    .SetSlidingExpiration(TimeSpan.FromSeconds(30));</pre>
   <p>
    
     By creating an instance of
    
    <strong class="source-inline">
     
      MemoryCacheEntryOptions
     
    </strong>
    
     , we have defined some cache configuration parameters that can be passed into the cache when we add a new object to it.
    
    
     Update the
    
    <strong class="source-inline">
     
      cache.Set()
     
    </strong>
    
     method to include
    
    
     
      this parameter:
     
    
   </p>
   <pre class="source-code">
memoryCache.Set&lt;Employee&gt;(
    employee.Id,
    employee,
    cacheEntryOptions);</pre>
   <p>
    
     Your endpoint
    
    <a id="_idIndexMarker486">
    </a>
    
     should now
    
    <a id="_idIndexMarker487">
    </a>
    
     look
    
    
     
      like this:
     
    
   </p>
   <pre class="source-code">
            app.MapGet("/employees/{id}",
            async (int id,
                   [FromServices] DapperService
                   dapperService, IMemoryCache memoryCache)
                   =&gt;
            {
                if(memoryCache.TryGetValue(id,
                    out var result))
                {
                    return result;
                }
                var employee = await
                    dapperService.GetEmployeeById(id);
                var cacheEntryOptions = new
                    MemoryCacheEntryOptions()
                        .SetSlidingExpiration(
                            TimeSpan.FromSeconds(30));
                memoryCache.Set&lt;Employee&gt;(
                    employee.Id,
                    employee,
                    cacheEntryOptions);
                return Results.Ok(employee);
            });</pre>
   <p>
    
     There you go!
    
    
     You’ve successfully introduced caching to your minimal API endpoint
    
    
     
      using
     
    
    
     <strong class="source-inline">
      
       IMemoryCache
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     In-memory caching is
    
    <a id="_idIndexMarker488">
    </a>
    
     most likely the default caching strategy when starting an API project, but if
    
    <a id="_idIndexMarker489">
    </a>
    
     your system has growth in adoption, then scalability and high availability will become increasingly important measurements of success.
    
    
     When looking to scale, distributed caching strategies can be adopted with the use of a reputable caching framework.
    
    
     Let’s look at one of the most famous caching
    
    
     
      technologies, Redis.
     
    
   </p>
   <h1 id="_idParaDest-149">
    <a id="_idTextAnchor179">
    </a>
    
     Distributed caching strategies
    
   </h1>
   <p>
    
     A
    
    <strong class="bold">
     
      distributed caching strategy
     
    </strong>
    
     uses
    
    <a id="_idIndexMarker490">
    </a>
    
     methods such as
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     within an architecture that supports scalability.
    
    
     In contrast to
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     , distributed caching
    
    <a id="_idIndexMarker491">
    </a>
    
     involves a connection between the ASP.NET application hosting your minimal API and the
    
    
     
      caching provider.
     
    
   </p>
   <p>
    
     In this example, the caching provider I will be
    
    <a id="_idIndexMarker492">
    </a>
    
     using
    
    
     
      is
     
    
    
     <strong class="bold">
      
       Redis
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     Redis is an in-memory caching provider that can also be used as an in-memory database.
    
    
     It is available as an open source product for installation on-premises or in
    
    
     
      the cloud.
     
    
   </p>
   <p>
    
     For the purposes of this demonstration, I installed Redis on an Ubuntu machine as a basic service.
    
    
     I then updated the Redis configuration so that Redis binds to
    
    <strong class="source-inline">
     
      0.0.0.0
     
    </strong>
    
     , listening on the default port of
    
    <strong class="source-inline">
     
      6379
     
    </strong>
    
     .
    
    
     This should only be relevant to you if your Redis service is running on a separate machine like
    
    
     
      mine is.
     
    
   </p>
   <p>
    
     With a Redis instance available, I can add the required NuGet packages to the API project for interacting with Redis as
    
    
     
      a cache.
     
    
   </p>
   <p>
    
     Add the
    
    <strong class="source-inline">
     
      NRedisStack
     
    </strong>
    
     package to
    
    
     
      the project:
     
    
   </p>
   <pre class="console">
dotnet add package NRedisStack</pre>
   <p>
    
     We will still be interacting with the cache in
    
    <strong class="source-inline">
     
      Program.cs
     
    </strong>
    
     , so we need to reference namespaces from
    
    
     <strong class="source-inline">
      
       NRedisStack
      
     </strong>
    
    
     
      here:
     
    
   </p>
   <pre class="console">
using StackExchange.Redis;</pre>
   <p>
    
     Now, we can update the endpoint for retrieving employees by
    
    <strong class="source-inline">
     
      Id
     
    </strong>
    
     with a new cache, replacing the
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     implementation
    
    
     
      with Redis.
     
    
   </p>
   <p>
    
     We start by
    
    <a id="_idIndexMarker493">
    </a>
    
     creating
    
    <strong class="source-inline">
     
      ConfigurationOptions
     
    </strong>
    
     , which can be passed as
    
    <a id="_idIndexMarker494">
    </a>
    
     a parameter when connecting to the
    
    
     
      Redis instance:
     
    
   </p>
   <pre class="source-code">
ConfigurationOptions options = new ConfigurationOptions
{
    EndPoints = { { "REDIS IP", 6379 } },
};
ConnectionMultiplexer redis =
    ConnectionMultiplexer.Connect(options);
IDatabase db = redis.GetDatabase();</pre>
   <p>
    
     Following this, we should now have a Redis connection that can be referenced in the
    
    <strong class="source-inline">
     
      db
     
    </strong>
    
     variable.
    
    
     Next, we will add the equivalent logic for caching from the
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     example, where we first check for a cache entry with a key (the
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     ID as a string, in this case) and return that if it exists, returning the
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     instance from the cache if
    
    
     
      it does:
     
    
   </p>
   <pre class="source-code">
var employeeIdKey = id.ToString();
var cachedEmployee = db.StringGet(employeeIdKey);
if (cachedEmployee.HasValue)
{
    return Results.Ok(
       JsonSerializer.Deserialize&lt;Employee&gt;(cachedEmployee)
    );
}</pre>
   <p>
    
     When calling
    
    <strong class="source-inline">
     
      StringGet()
     
    </strong>
    
     to retrieve a relevant entry from Redis, if it doesn’t exist already, an object will be returned with
    
    <strong class="source-inline">
     
      HasValues
     
    </strong>
    
     set to
    
    <strong class="source-inline">
     
      false
     
    </strong>
    
     .
    
    
     Assuming that the Redis cache doesn’t contain the
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     record we’re looking for, we fetch it from the database and
    
    <a id="_idIndexMarker495">
    </a>
    
     cache it before
    
    <a id="_idIndexMarker496">
    </a>
    
     returning it to
    
    
     
      the client:
     
    
   </p>
   <pre class="source-code">
var employee = await dapperService.GetEmployeeById(id);
db.StringSet(
    employeeIdKey,
    JsonSerializer.Serialize(employee));</pre>
   <p>
    
     Please note that Redis doesn’t natively support the insertion of strongly typed .NET objects, so we need to convert the
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     object to a JSON string through serialization when saving it and deserialize it from a JSON string to an
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     object when
    
    
     
      retrieving it.
     
    
   </p>
   <p>
    
     Your updated Redis-connected endpoint should now look
    
    
     
      like this:
     
    
   </p>
   <pre class="source-code">
app.MapGet(
    "/employees/{id}",
    async (int id,
           [FromServices] DapperService dapperService) =&gt;
{
    ConfigurationOptions options = new ConfigurationOptions
        {
          EndPoints = { { "192.168.2.8", 6379 } },
        };
        ConnectionMultiplexer redis =
            ConnectionMultiplexer.Connect(options);
        IDatabase db = redis.GetDatabase();
        var employeeIdKey = id.ToString();
        var cachedEmployee = db.StringGet(employeeIdKey);
        if (cachedEmployee.HasValue)
        {
            return Results.Ok(
                JsonSerializer.Deserialize&lt;Employee&gt;(
                    cachedEmployee));
        }
        var employee = await
            dapperService.GetEmployeeById(id);
        return Results.Ok(employee);
});</pre>
   <p>
    
     Implementing a cache in a separately hosted environment using something such as Redis has introduced more flexibility to our minimal API.
    
    
     I encourage you to take this simple example further by creating a generic service that can facilitate the interactions between ASP.NET and the Redis cache so that you are ultimately decoupling the API from its caching system.
    
    
     In the future, should you wish to move away from Redis to a different caching
    
    <a id="_idIndexMarker497">
    </a>
    
     technology, you need to be able to do this without affecting the original
    
    
     
      API
     
    
    
     <a id="_idIndexMarker498">
     </a>
    
    
     
      code.
     
    
   </p>
   <p>
    
     We’ve covered two examples of caching strategies so far.
    
    
     Let’s wrap up with a third technique, focusing on the caching of
    
    
     
      request responses.
     
    
   </p>
   <h1 id="_idParaDest-150">
    <a id="_idTextAnchor180">
    </a>
    
     Response caching
    
   </h1>
   <p>
    <strong class="bold">
     
      Response caching
     
    </strong>
    
     works
    
    <a id="_idIndexMarker499">
    </a>
    
     within the same logical principles as the previous two caching
    
    <a id="_idIndexMarker500">
    </a>
    
     strategies, but instead of caching database objects in memory, it caches responses at the
    
    
     
      HTTP level.
     
    
   </p>
   <p>
    
     Like
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     , minimal APIs can leverage ASP.NET’s native middleware by enabling response caching as a feature
    
    
     
      in
     
    
    
     <strong class="source-inline">
      
       Program.cs
      
     </strong>
    
    
     
      :
     
    
   </p>
   <pre class="source-code">
var builder = WebApplication.CreateBuilder(args);
builder.Services.AddResponseCaching();
var app = builder.Build();
app.UseResponseCaching();</pre>
   <p>
    
     Once enabled, response caching is very simple to add to a
    
    <strong class="source-inline">
     
      GET
     
    </strong>
    
     endpoint.
    
    
     We can add
    
    <strong class="source-inline">
     
      HttpContext
     
    </strong>
    
     to the parameters, and then, whenever we have the
    
    <strong class="source-inline">
     
      Employee
     
    </strong>
    
     object and are ready to return it, we can set the response to be cached for a certain amount of time, meaning that requesting the same data within that time will simply return the cached HTTP response
    
    <a id="_idIndexMarker501">
    </a>
    
     instead of
    
    <a id="_idIndexMarker502">
    </a>
    
     touching
    
    
     
      the database:
     
    
   </p>
   <pre class="source-code">
    app.MapGet(
        "/employees/{id}",
        async (int id,
               [FromServices] DapperService dapperService,
               HttpContext context) =&gt;
    {
        var employee = await
            dapperService.GetEmployeeById(id);
        context.Response.GetTypedHeaders().CacheControl =
            new Microsoft.Net.Http.Headers
                .CacheControlHeaderValue()
    {
        Public = true,
        MaxAge = TimeSpan.FromSeconds(60)
    };
        context.Response.Headers[Microsoft.Net.Http.Headers
            .HeaderNames.Vary] =
                new string[] { "Accept-Encoding" };
        return Results.Ok(employee);
});</pre>
   <p>
    
     As you can see, this is a
    
    <a id="_idIndexMarker503">
    </a>
    
     remarkably straightforward way to cache frequent responses, and the
    
    <a id="_idIndexMarker504">
    </a>
    
     expiry time can, of course, be adjusted as needed.
    
    
     You could even combine the caching approaches, having an in-memory cache that retrieves the data and then caching
    
    
     
      the response.
     
    
   </p>
   <p>
    
     With three working examples of caching in a minimal API under our belt, let’s review what we’ve learned in
    
    
     
      this chapter.
     
    
   </p>
   <h1 id="_idParaDest-151">
    <a id="_idTextAnchor181">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     In this chapter, we have explored caching using three different strategies: ASP.NET in-memory, distributed, and
    
    
     
      response caching.
     
    
   </p>
   <p>
    
     We started by defining caching as a concept, relating it to the context of minimal APIs, before exploring a hypothetical scenario of a company looking to save on the cost of retrieving data via APIs with
    
    
     
      a cache.
     
    
   </p>
   <p>
    
     Following this, we explored the ASP.NET native method of caching in memory, learning about
    
    <strong class="source-inline">
     
      IMemoryCache
     
    </strong>
    
     and how it can be implemented within an endpoint to limit the overhead produced by database transactions.
    
    
     We also learned how to make cached
    
    
     
      data expire.
     
    
   </p>
   <p>
    
     Then, we took this knowledge and expanded on it, following similar caching principles within a distributed cache in the form
    
    
     
      of Redis.
     
    
   </p>
   <p>
    
     Finally, we reviewed an example of response caching, allowing us to take frequently sent requests and bypass the database by resending a previously sent
    
    
     
      HTTP request.
     
    
   </p>
   <p>
    
     In the next chapter, we will explore the best practices you can observe to increase the readibility, scalibility and maintainability of your
    
    
     
      minimal APIs.
     
    
   </p>
  </div>
 

  <div><h1 id="_idParaDest-152" lang="en-US" xml:lang="en-US">
    <a id="_idTextAnchor182">
    </a>
    
     Part 4 - Best Practices, Design, and Deployment
    
   </h1>
   <p>
    
     In the final part, we shift our focus to the principles of robust API design and deployment.
    
    
     You’ll learn about best practices for shipping production-ready minimal APIs, as well as strategies for testing and maintaining compatibility across
    
    
     
      different environments.
     
    
   </p>
   <p>
    
     This part has the
    
    
     
      following chapters:
     
    
   </p>
   <ul>
    <li>
     <a href="B20968_13.xhtml#_idTextAnchor183">
      <em class="italic">
       
        Chapter 13
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Best Practices for Minimal API Resiliency
      
     </em>
    </li>
    <li>
     <a href="B20968_14.xhtml#_idTextAnchor200">
      <em class="italic">
       
        Chapter 14
       
      </em>
     </a>
     
      ,
     
     <em class="italic">
      
       Unit Testing
      
     </em>
     <em class="italic">
      
       , Compatibility, and Deployment of Minimal APIs
      
     </em>
    </li>
   </ul>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
  <div><div></div>
  </div>
 </body></html>