<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-306"><a id="_idTextAnchor585"/>14</h1>
<h1 id="_idParaDest-307"><a id="_idTextAnchor586"/>CI/CD for ASP.NET Core Using Azure Pipelines and GitHub Actions</h1>
<p>In the previous chapters, we have explored the fundamentals of building, testing, and running ASP.NET Core applications. We have also discussed how to access data from a database using <code>dotnet run</code> command to run our applications locally. Now, it is time to take the next step in our ASP.NET Core journey and learn how to deploy our applications to the cloud.</p>
<p>In this chapter, we will explore the concept of <strong class="bold">continuous integration and continuous delivery/deployment</strong> (<strong class="bold">CI/CD</strong>). This chapter will focus on two popular CI/CD tools and platforms: Azure Pipelines and GitHub Actions.</p>
<p>We will discuss the following topics in this chapter:</p>
<ul>
<li>Introduction to CI/CD</li>
<li>Containerizing ASP.NET Core applications using Docker</li>
<li>CI/CD using Azure Pipelines</li>
<li>GitHub Actions<a id="_idTextAnchor587"/></li>
</ul>
<p>Upon completion of this chapter, you will have a basic understanding of containerization concepts and the ability to build and deploy your ASP.NET Core applications to the cloud using either of these tools.</p>
<h1 id="_idParaDest-308"><a id="_idTextAnchor588"/>Technical requirements</h1>
<p>The code examples in this chapter can be found at <a href="https://github.com/PacktPublishing/Web-API-Development-with-ASP.NET-Core-8/tree/main/samples/chapter14/">https://github.com/PacktPublishing/Web-API-Development-with-ASP.NET-Core-8/tree/main/samples/chapter14/</a>.<a id="_idTextAnchor589"/></p>
<h1 id="_idParaDest-309"><a id="_idTextAnchor590"/>Introduction to CI/CD</h1>
<p>Developers<a id="_idIndexMarker1530"/> work on code every day – they may create new features, fix bugs, or refactor existing code. In a team environment, multiple developers may be working on the same code base. A developer may create a new feature, while another developer may be fixing a bug. The code base is constantly changing, and it is important to ensure that the code changes made by different developers do not conflict with each other and do not break any existing functionalities. To avoid such issues, developers should integrate their code changes frequently.</p>
<p>Additionally, when the application is ready to be deployed, it is important to consider the different environments it may be deployed to, such as development, staging, or production. Different environments may have different configurations, and the deployment process may be different for each environment. To ensure that the application is deployed correctly and consistently, it is ideal to automate the deployment process. This is where CI/CD comes in.</p>
<p>The acronym <em class="italic">CI/CD</em> can have different interpretations depending on the context. <strong class="bold">CI</strong>, a development practice that allows developers to integrate code changes regularly. <strong class="bold">CD</strong> can refer to either <strong class="bold">continuous delivery</strong> or <strong class="bold">continuous deployment</strong>, which are often used interchangeably. It is not worth debating the exact definitions of these terms, as in most cases, <em class="italic">CD</em> means building, testing, and deploying the applications to the production environment (and, potentially, other environments) frequently and automatically.</p>
<p>CI/CD pipelines are key components of <strong class="bold">DevOps</strong>, a combination of the words <strong class="bold">development</strong> and <strong class="bold">operations</strong>. DevOps has evolved over the years and is generally defined as a set of practices, tools, and processes that enable continuous delivery of value to end users. While DevOps is a vast topic, this chapter will focus on CI/CD pipelines specifically.</p>
<p>A typical <a id="_idIndexMarker1531"/>CI/CD process is shown in the following diagram:</p>
<div><div><img alt="Figure 14.1 – A typical CI/CD process" src="img/B18971_14_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – A typical CI/CD process</p>
<p>The steps in <em class="italic">Figure 14</em><em class="italic">.1</em> are <a id="_idIndexMarker1532"/>described as follows:</p>
<ol>
<li>The developer creates a new feature or fixes a bug in the code base and then commits the changes to the shared code repository. If the team is using Git as its <strong class="bold">version control system</strong> (<strong class="bold">VCS</strong>), the <a id="_idIndexMarker1533"/>developer will create a pull request to submit the changes.</li>
<li>The pull request will initiates the CI pipeline, which will build the application and execute tests. If the build or tests fail, the developer will be notified, allowing them to address the issue promptly.</li>
<li>If the build and tests are successful and the pull request is approved by the team, the code changes will be merged into the <code>main</code> branch. This ensures that the code is up to date and aligns with the team’s standards.</li>
<li>The merge will trigger the CI pipeline to build the application and publish the artifacts (for example, binaries, configuration files, Docker images, and so on) to the artifact repository.</li>
<li>The CD pipeline can be triggered manually or automatically. The CD pipeline then deploys the application to the target environment (for example, development, staging, or production environment).</li>
</ol>
<p>The CI/CD process <a id="_idIndexMarker1534"/>can be more complex than what is shown in <em class="italic">Figure 14</em><em class="italic">.1</em>. For example, the CI pipeline may require static code analysis, code test coverage, and other quality checks. The CD pipeline may need to apply different configurations for different environments or have different deployment strategies, such as blue/green deployment or canary deployment. With the increasing complexity of CI/CD pipelines, DevOps engineers are in high demand as they possess the skills to implement these pipelines using the various tools and platforms available.</p>
<p>Before we delve into the details of CI/CD, let us first introduce some concepts and terminologies that are commonly used in CI<a id="_idTextAnchor591"/>/CD.</p>
<h2 id="_idParaDest-310"><a id="_idTextAnchor592"/>CI/CD concepts and terminologies</h2>
<p>It is essential to<a id="_idIndexMarker1535"/> understand key concepts and terminologies commonly used in CI/CD. The following are some of the most common terms used in CI/CD:</p>
<ul>
<li><strong class="bold">Pipeline</strong>: A pipeline <a id="_idIndexMarker1536"/>is an automated process used to build, test, and deploy applications. They can be triggered manually or automatically and can even be set up to be triggered by other pipelines. This helps streamline the development process, ensuring that applications are built, tested, and deployed quickly and efficiently.</li>
<li><strong class="bold">Build</strong>: A build <a id="_idIndexMarker1537"/>is a process that involves compiling the source code and creating the necessary binaries or Docker images. This ensures that the code is ready for deployment.</li>
<li><strong class="bold">Test</strong>: A <a id="_idIndexMarker1538"/>pipeline may include automated tests, such as unit tests, integration tests, performance tests, or <strong class="bold">end-to-end</strong> (<strong class="bold">E2E</strong>) tests. These tests can be incorporated <a id="_idIndexMarker1539"/>into the pipeline to ensure that the code changes do not break any existing functionalities. This helps to ensure that the software remains stable and reliable.</li>
<li><strong class="bold">Artifact</strong>: An artifact is<a id="_idIndexMarker1540"/> a file or collection of files – normally, the output of a build process. Examples of artifacts include binary files, a Docker image, or a ZIP file containing the binary files. These artifacts can then be used as inputs for the deployment process.</li>
<li><strong class="bold">Containerization</strong>: Containerization is a method of packaging an application and its<a id="_idIndexMarker1541"/> dependencies into a container image, which can be deployed and run in a consistent environment, regardless of the host operating system. One of the most popular containerization tools is Docker. Containerization offers numerous benefits, such as improved scalability, portability, and resource utilization.</li>
<li><strong class="bold">VCS</strong>: VCSs are <a id="_idIndexMarker1542"/>an essential tool for software development, allowing developers to track and manage changes to source code. Git is one of the most widely used VCSs, providing developers with an effective way to manage their code base.</li>
<li><strong class="bold">Deployment</strong>: Deployment<a id="_idIndexMarker1543"/> is the process of deploying the application to the target environment. It involves configuring the application to meet the requirements of the environment, as well as ensuring that it is secure and ready for use.</li>
<li><code>main</code> branch can trigger the CI pipeline to build and publish artifacts. The successful CI pipeline can trigger the CD pipeline to deploy the application to non-production environments. However, the CD pipeline may need to be triggered manually to deploy the application to the production environment as a safety measure.</li>
</ul>
<p>Gaining an understanding of the fundamental concepts and terminologies associated with CI/CD is essential for successful implementation. As many different tools and platforms can be used to implement CI/CD pipelines, we will discuss the details in the follo<a id="_idTextAnchor593"/>wing sections.</p>
<h2 id="_idParaDest-311"><a id="_idTextAnchor594"/>Understanding the importance of CI/CD</h2>
<p>CI/CD plays an<a id="_idIndexMarker1545"/> important role in DevOps. It helps the team respond to changes and deliver value to end users frequently, safely, and reliably. As CI/CD pipelines are automated, they can streamline the process of delivering software and reduce the time and effort needed to deploy applications to the production environment. Additionally, CI/CD helps maintain a stable and reliable code base. </p>
<p>In order to successfully implement a CI/CD pipeline, the team must adhere to certain practices. Automated tests should be conducted to ensure that code changes do not break any existing functionalities. Additionally, a well-defined deployment strategy should be established, such as staging the application in a development environment before deploying it to the production environment. By following these practices, the team can reduce <strong class="bold">time to market</strong> (<strong class="bold">TTM</strong>) and<a id="_idIndexMarker1546"/> deliver the application to end users faster and more frequently.</p>
<p>CI/CD practices help <a id="_idIndexMarker1547"/>development teams in the following ways:</p>
<ul>
<li><strong class="bold">Faster feedback</strong>: CI/CD pipelines can be triggered automatically when code changes are committed to the shared code repository. This provides developers with faster feedback on code changes, allowing them to address any issues early in the development process.</li>
<li><strong class="bold">Reduced manual effort and risk</strong>: CI/CD pipelines automate the deployment process, reducing manual effort and risk. This decreases the time and effort needed for production deployment, eliminating manual and error-prone processes.</li>
<li><strong class="bold">Consistency</strong>: Automated builds and deployments ensure consistency across different environments. This reduces the risk of deployment failures due to configuration issues or <em class="italic">it works on my </em><em class="italic">machine</em> problems.</li>
<li><strong class="bold">Enhanced quality</strong>: Automated tests can be integrated into CI/CD pipelines, which helps to ensure that the code base remains stable and reliable. CI/CD pipelines can also run other quality checks, such as static code analysis and code test coverage, which leads to higher-quality code.</li>
<li><strong class="bold">Rapid delivery and agility</strong>: CI/CD pipelines enable the team to release new features and bug fixes to end users faster and more frequently. This allows businesses to respond quickly to customer needs and market changes.</li>
</ul>
<p>With these<a id="_idIndexMarker1548"/> benefits in mind, it is clear that CI/CD is a must-have for any development team. No one would want to go back to the days of manual builds and deployments anymore, as it is time-consuming and error-prone.</p>
<p>We have now learned some concepts of CI/CD and why it is important. In the next section, we will discuss how to containerize ASP.NET Core applicat<a id="_idTextAnchor595"/>ions using Docker.</p>
<h1 id="_idParaDest-312"><a id="_idTextAnchor596"/>Containerizing ASP.NET Core applications using Docker</h1>
<p>Many years ago, when<a id="_idIndexMarker1549"/> we deployed applications to the production environment, we needed to ensure that the target environment had the correct version of the .NET Framework installed. Developers were struggling with the <em class="italic">it works on my machine</em> problem, as development environments may have had different configurations than the production environment, including software versions, operating systems, and hardware. This often led to deployment failures due to configuration issues.</p>
<p>The introduction of .NET Core, a cross-platform and open-source framework, has enabled us to deploy our applications on any platform, including Windows, Linux, and macOS. However, for successful deployment, we still need to ensure that the target environment has the correct runtime installed. This is where contain<a id="_idTextAnchor597"/>erization comes in.</p>
<h2 id="_idParaDest-313"><a id="_idTextAnchor598"/>What is containerization?</h2>
<p>Containers<a id="_idIndexMarker1550"/> are lightweight, isolated, and portable environments that contain all the necessary dependencies for running an application. Unlike <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>), they<a id="_idIndexMarker1551"/> do not require a separate guest operating system as they share the host operating system kernel. This makes them more lightweight and portable than VMs, as they can run on any platform that supports the container runtime. Containers also provide isolation, ensuring that applications are not affected by changes in the environment.</p>
<p>Containerization is a powerful tool that enables us to package our applications and their dependencies into a single container image. <strong class="bold">Docker</strong> is <a id="_idIndexMarker1552"/>one of the most popular <a id="_idIndexMarker1553"/>containerization solutions, offering support for Windows, Linux, and macOS for development purposes, as well as many variants of Linux, such as Ubuntu, Debian, and CentOS, for production environments. Additionally, Docker is compatible with cloud platforms, including <a id="_idIndexMarker1554"/>Azure, <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), and <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>). If we use Docker <a id="_idIndexMarker1555"/>as the container runtime, then the container images are <a id="_idIndexMarker1556"/>called <strong class="bold">Docker images</strong>.</p>
<p>Docker images are a convenient way to package an application and its dependencies. They contain all the components necessary to run an application, such as the application code (binaries), runtime or SDK, system tools, and configurations. Docker images are immutable, meaning they cannot be changed once they are created. To store these images, they are placed in a registry, such<a id="_idIndexMarker1557"/> as Docker Hub, <strong class="bold">Azure Container Registry</strong> (<strong class="bold">ACR</strong>), or<a id="_idIndexMarker1558"/> AWS <strong class="bold">Elastic Container Registry</strong> (<strong class="bold">ECR</strong>). Docker Hub is<a id="_idIndexMarker1559"/> a public registry that offers many pre-built images. Alternatively, a private registry can be created to store custom Docker images.</p>
<p>Once a Docker image has been created, it can be used to create a Docker container. A Docker container is an isolated, in-memory instance of a Docker image, with its own filesystem, network, and memory. This makes creating a container much faster than booting up a VM and also allows for fast destruction and rebuilding of a container from the same image. In addition, multiple containers can be created from the same image, which is useful for scaling out applications. If any container fails, it can be destroyed and rebuilt from the same image in a matter of seconds, making containerization a powerful tool.</p>
<p>The files in a Docker image are stackable. <em class="italic">Figure 14</em><em class="italic">.2</em> shows an example of a container filesystem that contains an ASP.NET Core app and its dependencies:</p>
<div><div><img alt="Figure 14.2 – Docker container file system" src="img/B18971_14_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Docker container file system</p>
<p><em class="italic">Figure 14</em><em class="italic">.2</em> illustrates <a id="_idIndexMarker1560"/>the layers of a Docker container. On top of the kernel layer is the base image layer, which is an empty container image created from Ubuntu. On top of the base image layer is the ASP.NET Core runtime layer, then the ASP.NET Core app layer. When a container is created, Docker adds a final writeable layer on top of the other layers. This writeable layer can be used to store temporary files, such as logs. However, as we mentioned earlier, Docker images are immutable, so any changes made to the writeable layer will be lost when the container is destroyed. This is why we should not store any persistent data in a container. Instead, we should store the data in a volume, which is a directory on the host machine that is mounted into the container.</p>
<p>This is a very simplified explanation of Docker images and containers. Next, let us install Docker and create a Docker image for <a id="_idTextAnchor599"/>our ASP.NET Core application.</p>
<h2 id="_idParaDest-314"><a id="_idTextAnchor600"/>Installing Docker</h2>
<p>You can <a id="_idIndexMarker1561"/>download Docker Desktop from the following links:</p>
<ul>
<li>Windows: <a href="https://docs.docker.com/desktop/install/windows-install/ ">https://docs.docker.com/desktop/install/windows-install/</a></li>
<li>Mac: <a href="https://docs.docker.com/desktop/install/mac-install/ ">https://docs.docker.com/desktop/install/mac-install/</a></li>
<li>Linux: <a href="https://docs.docker.com/desktop/install/linux-install/ ">https://docs.docker.com/desktop/install/linux-install/</a></li>
</ul>
<p>Please follow the official documentation to install Docker on your machine.</p>
<p>If you use<a id="_idIndexMarker1562"/> Windows, please use the <strong class="bold">Windows Subsystem for Linux 2</strong> (<strong class="bold">WSL 2</strong>) backend <a id="_idIndexMarker1563"/>instead of Hyper-V. WSL 2 is a compatibility layer that allows Linux binary executables to be run natively on Windows. Using WSL 2 as the backend for Docker Desktop on Windows provides better performance than the Hyper-V backend.</p>
<p>To install WSL 2 on Windows, please follow the instructions at this link: <a href="https://learn.microsoft.com/en-us/windows/wsl/install">https://learn.microsoft.com/en-us/windows/wsl/install</a>. By default, WSL 2 uses the Ubuntu distribution. You can also install other Linux distributions, such as Debian, CentOS, or Fedora.</p>
<p>After installing WSL 2, you can check the version of WSL by running the following command in PowerShell:</p>
<pre class="console">
wsl -l -v</pre> <p>If you see the <code>VERSION</code> field shows <code>2</code>, that means WSL 2 is installed correctly. Then, you can install Docker Desktop and choose WSL 2 as the backend. If you have multiple Linux distributions installed, you can choose the default distribution to use with Docker Desktop. Go to <strong class="bold">Settings</strong> | <strong class="bold">Resources</strong> | <strong class="bold">WSL integration</strong>, and choose the distribution you want to use with Docker Desktop, as shown in <em class="italic">Figure 14</em><em class="italic">.3</em>:</p>
<div><div><img alt="Figure 14.3 – Choosing the default Linux distribution to use with Docker Desktop" src="img/B18971_14_03.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 – Choosing the default Linux distribution to use with Docker Desktop</p>
<p>Here is the example output of the <code>wsl -l -v</code> command, which shows two Linux distros installed on this machine; the default distro is <code>Ubuntu-22.04</code>:</p>
<pre class="source-code">
  NAME                   STATE           VERSION* Ubuntu-22.04           Running         2
  Ubuntu                 Stopped         2
  docker-desktop-data    Running         2
  docker-desktop         Running         2</pre>
<p>Docker Desktop installs two internal Linux distros:</p>
<ul>
<li><code>docker-desktop</code>: This is used to run the Docker engine</li>
<li><code>docker-desktop-data</code>: This is used to store containers and images</li>
</ul>
<p>Note that <a id="_idIndexMarker1564"/>Docker may consume a lot of resources on your machine. If you feel that Docker slows down your machine or consumes too many resources, you can configure the resources allocated to WSL 2 following the instructions in this link: <a href="https://learn.microsoft.com/en-us/windows/wsl/wsl-config#configure-global-options-with-wslconfig">https://learn.microsoft.com/en-us/windows/wsl/wsl-config#configure-global-options-with-wslconfig</a>.</p>
<p>After installing Docker Desktop, we can now create a Docker image for our ASP.NET Core application. In the next section, we will discuss some commands t<a id="_idTextAnchor601"/>hat are commonly used in Docker.</p>
<h2 id="_idParaDest-315"><a id="_idTextAnchor602"/>Understanding Dockerfiles</h2>
<p>To demonstrate<a id="_idIndexMarker1565"/> how to build and run Docker images, we will need a sample ASP.NET Core application. You can create a new ASP.NET Core web API project using the following command:</p>
<pre class="console">
dotnet new webapi -o BasicWebApiDemo -controllers</pre> <p>Alternatively, you can clone the sample code from the <code>/samples/chapter14/MyBasicWebApiDemo </code>folder in the book's GitHub repository.</p>
<p>Docker images can be built using a Dockerfile, a text file containing a list of instructions used to build the image. You can create a Dockerfile in the root directory of the ASP.NET Core project <a id="_idIndexMarker1566"/>manually, or you can use VS 2022 to create it for you. To create a Dockerfile using VS 2022, right-click on the project in Solution Explorer, then select <strong class="bold">Add</strong> | <strong class="bold">Docker Support</strong>. You will see the following dialog:</p>
<div><div><img alt="Figure 14.4 – Adding Docker support to an ASP.NET Core project in VS 2022" src="img/B18971_14_04.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Adding Docker support to an ASP.NET Core project in VS 2022</p>
<p>There are two options here: <strong class="bold">Linux</strong> and <strong class="bold">Windows</strong>. It is recommended to use Linux for development purposes, as the Linux image is smaller than the Windows image. Docker was originally designed for Linux, so it is more mature on Linux than on Windows. Many cloud platforms, such as Azure, AWS, and GCP, support Linux containers. However, not all Windows servers support Windows containers. Unless you have strong reasons to host your application on a Windows server, you should choose <strong class="bold">Linux</strong> here.</p>
<p>Once you have selected the <code>Dockerfile</code> without any file extension. This allows us to build the Docker image using the <code>docker build</code> command without needing to specify the Dockerfile name. The default Dockerfile created by VS 2022 will resemble the following:</p>
<pre class="source-code">
#See https://aka.ms/customizecontainer to learn how to customize your debug container and how Visual Studio uses this Dockerfile to build your images for faster debugging.FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base
USER app
WORKDIR /app
EXPOSE 8080
EXPOSE 8081
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
ARG BUILD_CONFIGURATION=Release
WORKDIR /src
COPY ["BasicWebApiDemo.csproj", "."]
RUN dotnet restore "./BasicWebApiDemo.csproj"
COPY . .
WORKDIR "/src/."
RUN dotnet build "BasicWebApiDemo.csproj" -c $BUILD_CONFIGURATION -o /app/build
FROM build AS publish
RUN dotnet publish "BasicWebApiDemo.csproj" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false
FROM base AS final
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT ["dotnet", "BasicWebApiDemo.dll"]</pre>
<p>Let us go through the Dockerfile line by line:</p>
<pre class="source-code">
FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base</pre> <p>The <code>FROM</code> instruction specifies the base image to use. The <code>FROM</code> instruction must be the first instruction in a Dockerfile. In this case, we are using the <code>mcr.microsoft.com/dotnet/aspnet:8.0</code> image, which is the ASP.NET Core runtime image. This image is provided by Microsoft. <code>mcr.microsoft.com</code> is the domain name of <a id="_idIndexMarker1567"/>the <code>AS base</code> means we are giving this image a name, which is <code>base</code>. This name can be used later in the Dockerfile to refer to this image.</p>
<pre class="source-code">
USER app</pre> <p>Next, the <code>USER</code> instruction<a id="_idIndexMarker1569"/> specifies the username or <code>app</code> user is created by the base image. This user is not a superuser, so it is more secure than the root user.</p>
<pre class="source-code">
WORKDIR /app</pre> <p>The <code>WORKDIR</code> instruction sets the working directory inside of the container for these instructions: <code>RUN</code>, <code>CMD</code>, <code>COPY</code>, <code>ADD</code>, <code>ENTRYPOINT</code>, and so on. This instruction is similar to the <code>cd</code> command in the terminal. It supports both absolute and relative paths. If the directory does not exist, it will be created. In this example, the working directory is set to <code>/app</code>.</p>
<pre class="source-code">
EXPOSE 8080EXPOSE 8081</pre>
<p>The <code>EXPOSE</code> instruction exposes the specified port(s) to the container when it is running. Note that this instruction does not actually publish the port to the host machine. It just means the container will listen on the specified port(s). By default, the <code>EXPOSE</code> instruction exposes the port(s) on the TCP protocol. In this case, the container will listen on ports <code>8080</code> and <code>8081</code>.</p>
<pre class="source-code">
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS buildARG BUILD_CONFIGURATION=Release
WORKDIR /src</pre>
<p>In the preceding lines, we are using a different image, which is the <code>mcr.microsoft.com/dotnet/sdk:8.0</code> image, and naming it <code>build</code>. This image contains the .NET SDK, which is used to build the application. The <code>ARG</code> instruction defines a variable that can be used later in the Dockerfile. In this case, we are defining a variable called <code>BUILD_CONFIGURATION</code> and setting its default value to <code>Release</code>. The <code>WORKDIR</code> instruction sets the working directory to <code>/src</code>.</p>
<pre class="source-code">
COPY ["BasicWebApiDemo.csproj", "."]RUN dotnet restore "./BasicWebApiDemo.csproj"</pre>
<p>The <code>COPY</code> instruction<a id="_idIndexMarker1571"/> copies files or directories from the source (on the local machine) to the destination (the filesystem of the container). In this case, we are copying the <code>.csproj</code> file to the current directory. The <code>RUN</code> instruction executes the specified command on top of the current image and creates a new layer, then commits the results. The new layer will be used for the next step in the Dockerfile. In this case, we are running the <code>dotnet restore</code> command to restore the NuGet packages.</p>
<pre class="source-code">
COPY . .WORKDIR "/src/."
RUN dotnet build "BasicWebApiDemo.csproj" -c $BUILD_CONFIGURATION -o /app/build</pre>
<p>In the preceding lines, we are copying all the files from the local machine to the current directory in the container. Then, we are setting the working directory to <code>/src</code>. Finally, we are running the <code>dotnet build</code> command to build the application. Note that we are using the <code>BUILD_CONFIGURATION</code> variable defined earlier in the Dockerfile.</p>
<pre class="source-code">
FROM build AS publishRUN dotnet publish "BasicWebApiDemo.csproj" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false</pre>
<p>Again, the <code>FROM</code> instruction uses the <code>build</code> image we defined earlier and names it <code>publish</code>. Then, the <code>RUN</code> instruction runs the <code>dotnet publish</code> command to publish the application. The <code>$BUILD_CONFIGURATION</code> variable is used again. The published application will be placed in the <code>/</code><code>app/publish</code> directory.</p>
<pre class="source-code">
FROM base AS finalWORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT ["dotnet", "BasicWebApiDemo.dll"]</pre>
<p>Next, we rename the <code>base</code> image as <code>final</code> and set the working directory to <code>/app</code>. To run the application, we <a id="_idIndexMarker1572"/>only need the runtime, so we do not need the SDK image. Then, the <code>COPY</code> instruction copies the published application from the <code>app/publish</code> directory of the <code>publish</code> image to the current directory. Finally, the <code>ENTRYPOINT</code> instruction specifies the command to run when the container starts. In this case, we are running the <code>dotnet BasicWebApiDemo.dll</code> command to start the ASP.NET Core application.</p>
<p>You can find more information about Dockerfile instructions in the official documentation provided by Docker: <a href="https://docs.docker.com/engine/reference/builder/">https://docs.docker.com/engine/reference/builder/</a>. Next, let<a id="_idTextAnchor603"/> us move on to building a Docker image.</p>
<h2 id="_idParaDest-316"><a id="_idTextAnchor604"/>Building a Docker image</h2>
<p>Docker <a id="_idIndexMarker1573"/>provides a set of commands that can be used to build, run, and manage Docker images and containers. To build a Docker image, go to the root directory of the ASP.NET Core project we created earlier, then run the following command:</p>
<pre class="console">
docker build -t basicwebapidemo .</pre> <p>The <code>-t</code> option is used to tag the image with a name. <code>.</code> at the end means the current directory. Docker expects to find a file named <code>Dockerfile</code> in the current directory. If you have renamed the Dockerfile or the Dockerfile is not located in the current directory, you can use the <code>-f</code> option to specify the Dockerfile name, such as <code>docker build -t basicwebapidemo -f </code><code>MyBasicWebApiDemo/MyDockerfile MyBasicWebApiDemo</code>.</p>
<p>The output<a id="_idIndexMarker1574"/> shows that Docker is building the image layer by layer. Each instruction in the Dockerfile will create a layer in the image and add more content on top of the previous layer. The layers are cached, so if a layer has not changed, it will not be rebuilt for the next build. But if a layer has changed (for example, if we update the source code), then the layer that copies the source code will be rebuilt, and all the layers after that will be affected and need to be rebuilt as well.</p>
<p>Now, let us review the default Dockerfile generated by VS 2022. Why does it copy all the files after running the <code>dotnet restore</code> command? It is because if we only update the source code but the NuGet packages have not changed, then the <code>dotnet restore</code> command will not be executed again as the layer is cached. This can improve the build performance. However, if we update the NuGet packages, meaning the <code>.csproj</code> file has <a id="_idIndexMarker1575"/>changed, then the <code>dotnet restore</code> command will be executed again.</p>
<p>Here are some tips <a id="_idIndexMarker1576"/>for writing Dockerfiles:</p>
<ul>
<li>Consider the order of layers. Layers that are less likely to change should be placed before layers that are more likely to change.</li>
<li>Keep layers small as much as possible. Do not copy unnecessary files. You can configure the <code>.dockerignore</code> file to exclude files or directories from the build context. If you use VS 2022 to create the Dockerfile, it will generate a <code>.dockerignore</code> file for you. Alternatively, you can manually create a text file named <code>.dockerignore</code> and then edit it. Here is a sample <code>.</code><code>dockerignore</code> file:<pre class="source-code">
# Exclude build results, Npm cache folder, and some other files**/bin/**/obj/**/.git**/.vs**/.vscode**/global.json**/Dockerfile**/.dockerignore**/node_modules</pre><p class="list-inset">For more information about the <code>.dockerignore</code> file, please refer to the official documentation here: <a href="https://docs.docker.com/engine/reference/builder/#dockerignore-file">https://docs.docker.com/engine/reference/builder/#dockerignore-file</a>.</p></li> <li>Keep as<a id="_idIndexMarker1577"/> few layers as possible. For example, to host an ASP.NET Core application, we can reduce the number of layers by using the <code>mcr.microsoft.com/dotnet/aspnet</code> image. This image contains the ASP.NET Core runtime already, eliminating the need to install the SDK in the container. You can also combine commands into a single <code>RUN</code> instruction.</li>
<li>Use multi-stage builds. Multi-stage builds allow us to use multiple <code>FROM</code> instructions in a Dockerfile. Each <code>FROM</code> instruction can be used to create a new image. The final image will only contain the layers from the last <code>FROM</code> instruction. This can reduce the size of the final image. For example, we can use the <code>mcr.microsoft.com/dotnet/sdk</code> image to build the application and then use the <code>mcr.microsoft.com/dotnet/aspnet</code> image to run the application. This way, the final image will only contain the ASP.NET Core runtime, and it will not contain the SDK, which is not needed for running the application. To learn more about multi-stage builds, please refer to the official documentation here: <a href="https://docs.docker.com/develop/develop-images/multistage-build/">https://docs.docker.com/develop/develop-images/multistage-build/</a>.<p class="list-inset">For more information on optimizing Docker builds, please refer to the official documentation here: <a href="https://docs.docker.com/build/cache/">https://docs.docker.com/build/cache/</a>.</p></li>
</ul>
<p>We can use the following command to list all Docker images on our machine:</p>
<pre class="console">
docker images</pre> <p>The output should be similar to this:</p>
<pre class="console">
REPOSITORY      TAG     IMAGE ID       CREATED              SIZEbasicwebapidemo latest  b0d8d94d219c   About a minute ago   222MB</pre>
<p>The <code>basicwebapidemo</code> image is the one we just built. Each image has a <code>TAG</code> value and an <code>IMAGE ID</code> value. The <code>TAG</code> value is a human-readable name for the image. By default, the tag is <code>latest</code>. We can specify a different tag when building the image. For example, we can use the following command to build the image with the <code>v1</code> tag:</p>
<pre class="console">
docker build -t basicwebapidemo:v1 .</pre> <p>In the <a id="_idIndexMarker1578"/>preceding command, the <code>-t</code> option is used to tag the image with a name, which is separated from the tag with a colon.</p>
<p>To remove an image, use the <code>docker rmi &lt;container name or ID&gt;</code> command followed by the image name or image ID:</p>
<pre class="console">
docker rmi basicwebapidemo</pre> <p>Note that if the image is used by a container, you will need to stop the container first before removing the image.</p>
<p>We now have a Docker image for our ASP.NET Core application. All the necessary dependencies are included in <a id="_idTextAnchor605"/>the image. Next, let us run the Docker image.</p>
<h2 id="_idParaDest-317"><a id="_idTextAnchor606"/>Running a Docker container</h2>
<p>To run a <a id="_idIndexMarker1579"/>Docker image in the container, we can use the <code>docker run</code> command. The following command will run the <code>basicwebapidemo</code> image we just built:</p>
<pre class="console">
docker run -d -p 80:8080 --name basicwebapidemo basicwebapidemo</pre> <p>Let’s take a closer look at this:</p>
<ul>
<li>The <code>-d</code> option is used to run the container in detached mode, meaning the container will run in the background. You can omit this option and then the container will run in the foreground, which means if you exit the terminal, the container will stop.</li>
<li>The <code>-p</code> option is used to publish a container’s port(s) to the host. In this case, we are publishing port 8080 of the container to port 80 of the host.</li>
<li>The <code>--name</code> option is used to specify a name for the container. The last argument is the name of the image to run.</li>
<li>You can also use the <code>-it</code> option to run the container in interactive mode. This option allows you to run a command in the container.</li>
</ul>
<p>When we <a id="_idIndexMarker1580"/>wrote the Dockerfile, we explained that the <code>EXPOSE</code> instruction exposes ports 8080 and 8081 to the container only. To publish the internal container port to the host, we need to use the <code>-p</code> option. The first port number is the port of the host machine, and the second port number is the internal container port. In this example, we are exposing the container port 8080 to the host port 80. This may confuse some people. So, please check the port numbers carefully. Also, sometimes the port number of the host machine may be occupied by another process. In this case, you will need to use a different port number.</p>
<p>The output should return the container ID, which is a UID for the container, such as this:</p>
<pre class="source-code">
5529b0278e5a14452a7049a7c9922797b0c1171423970f99b4481c93cfdc6a38</pre> <p>Use the <code>docker ps</code> command to list all running containers:</p>
<pre class="console">
docker ps</pre> <p>The output should be similar to this:</p>
<pre class="console">
CONTAINER ID   IMAGE             COMMAND                  CREATED         STATUS         PORTS                                 NAMES403eb4952287   basicwebapidemo   "dotnet BasicWebApiD…"   5 minutes ago   Up 5 minutes   8081/tcp, 0.0.0.0:80-&gt;8080/tcp   basicwebapidemo</pre>
<p>In the output, we can see that port 8080 of the container has been mapped to port 80 of the host.</p>
<p>To list all containers in all states, just add a <code>-</code><code>a</code> option:</p>
<pre class="console">
docker ps -a</pre> <p>You can check the status of containers. If the container is running, the status should be <code>Up</code>.</p>
<p>We can use the following commands to manage containers:</p>
<ul>
<li>To pause a container: <code>docker pause &lt;container name </code><code>or ID&gt;</code></li>
<li>To restart a container: <code>docker restart &lt;container name </code><code>or ID&gt;</code></li>
<li>To stop a container: <code>docker stop &lt;container name </code><code>or ID&gt;</code></li>
<li>To remove a container: <code>docker rm &lt;container name </code><code>or ID&gt;</code></li>
</ul>
<p>If the container<a id="_idIndexMarker1581"/> is running, you can test the endpoint by sending a request to this URL: <code>http://localhost/weatherforecast</code>. You will see the response from the ASP.NET Core application. If you change the port number of the host machine, you will need to use the correct port number in the URL. For example, if you use <code>-p 5000:8080</code>, then you will need to use <a href="http://localhost:5000/weatherforecast">http://localhost:5000/weatherforecast</a> to access the endpoint.</p>
<p>We can use the <code>docker logs &lt;container name or ID&gt;</code> command to show logs from a container:</p>
<pre class="console">
docker logs basicwebapidemo</pre> <p>You will see logs such as these:</p>
<pre class="source-code">
info: Microsoft.Hosting.Lifetime[14]      Now listening on: http://[::]:8080
info: Microsoft.Hosting.Lifetime[0]
      Application started. Press Ctrl+C to shut down.
info: Microsoft.Hosting.Lifetime[0]
      Hosting environment: Production
info: Microsoft.Hosting.Lifetime[0]
      Content root path: /app</pre>
<p>To check the stats of a container, you can use the <code>docker stats &lt;container name or </code><code>ID&gt;</code> command:</p>
<pre class="console">
docker stats basicwebapidemo</pre> <p>You will see the stats of the container as follows:</p>
<pre class="source-code">
CONTAINER ID   NAME              CPU %     MEM USAGE / LIMIT     MEM %     NET I/O           BLOCK I/O   PIDS403eb4952287   basicwebapidemo   0.01%     24.24MiB / 15.49GiB   0.15%     23.8kB / 2.95kB   0B / 0B     25</pre>
<p>You can send a request to the <code>/weatherforecast</code> endpoint to get the response from the ASP.NET Core application. Note that the container is running in the production environment, so the Swagger UI is not available. This is because in the <code>Program.cs</code> file, we <a id="_idIndexMarker1582"/>enabled the Swagger UI only in the development environment. To enable the Swagger UI, we can stop and delete the current container, then create a new one in development environment. Alternatively, you can create a new container with a different name. For example, you can stop the container by running the following command:</p>
<pre class="console">
docker stop basicwebapidemo</pre> <p>Then remove the container by running the following command:</p>
<pre class="console">
docker rm basicwebapidemo</pre> <p>Next, add an environment variable to the <code>docker run</code> command to set the environment to development:</p>
<pre class="console">
docker run -d -p 80:8080 --name basicwebapidemo -e ASPNETCORE_ENVIRONMENT=Development basicwebapidemo</pre> <p>Now, you can view the Swagger UI by navigating to the <code>/swagger</code> endpoint in the browser.</p>
<p>So far, we have learned how to build and run Docker images. Docker has many other commands that can be used to manage Docker images and containers. To summarize, here are some of the most commonly used Docker commands from Docker official documents:</p>
<ul>
<li><code>docker build</code>: Build a Docker image</li>
<li><code>docker run</code>: Run a Docker image</li>
<li><code>docker images</code>: List all images</li>
<li><code>docker ps</code>: List all running containers</li>
<li><code>docker ps -a</code>: List all containers in all states</li>
<li><code>docker logs</code>: Show logs from a container</li>
<li><code>docker stats</code>: Show stats of a container</li>
<li><code>docker pause</code>: Pause a container</li>
<li><code>docker restart</code>: Restart a container</li>
<li><code>docker stop</code>: Stop a container</li>
<li><code>docker rm</code>: Remove a container</li>
<li><code>docker rmi</code>: Remove an image</li>
<li><code>docker exec</code>: Run a command in a running container</li>
<li><code>docker inspect</code>: Display detailed information on one or more containers or images</li>
<li><code>docker login</code>: Log in to a Docker registry</li>
<li><code>docker logout</code>: Log out from a Docker registry</li>
<li><code>docker pull</code>: Pull an image from a registry</li>
<li><code>docker push</code>: Push an image to a registry</li>
<li><code>docker tag</code>: Create a <code>TARGET_IMAGE</code> tag that refers to <code>SOURCE_IMAGE</code></li>
<li><code>docker volume</code>: Manage volumes</li>
<li><code>docker network</code>: Manage networks</li>
<li><code>docker system</code>: Manage Docker</li>
<li><code>docker version</code>: Show the Docker version information</li>
<li><code>docker info</code>: Show Docker system-wide information</li>
<li><code>docker port</code>: List port mappings or a specific mapping for a container</li>
</ul>
<p>You can<a id="_idIndexMarker1583"/> find more information about Docker commands<a id="_idIndexMarker1584"/> here: <a href="https://docs.docker.com/engine/reference/commandline/cli/">https://docs.docker.com/engine/reference/commandline/cli/</a>.</p>
<p>We have now learned how to build a Docker image for our ASP.NET Core application and run it in a container. Even though the container is running on our local machine, there is not much difference from running it in a production environment. The container is isolated from<a id="_idIndexMarker1585"/> the host machine. The portable nature of containers makes it easy to deploy the application to any environment.</p>
<p>We can also use Docker commands to push the image to a registry, such as Docker Hub, ACR, and so on. However, manual deployment is error-prone and time-consuming. That is why we need a CI/CD pipeline to automate the deployment process.</p>
<p>In the next section, we will discuss how to deploy the containerized application <a id="_idTextAnchor607"/>to the cloud using Azure DevOps and Azure Pipelines.</p>
<h1 id="_idParaDest-318"><a id="_idTextAnchor608"/>CI/CD using Azure DevOps and Azure Pipelines</h1>
<p>Azure DevOps<a id="_idIndexMarker1586"/> is a cloud-based service that provides a set of tools for managing the software development process. It includes the following services:</p>
<ul>
<li><strong class="bold">Azure Boards</strong>: A <a id="_idIndexMarker1587"/>service for managing work items, such as user stories, tasks, and bugs.</li>
<li><strong class="bold">Azure Repos</strong>: A<a id="_idIndexMarker1588"/> service for hosting code repositories. It supports Git<a id="_idIndexMarker1589"/> and <strong class="bold">Team Foundation Version Control</strong> (<strong class="bold">TFVC</strong>). The repositories can be public or private.</li>
<li><strong class="bold">Azure Pipelines</strong>: A <a id="_idIndexMarker1590"/>service for building, testing, and deploying applications with any language, platform, and cloud.</li>
<li><strong class="bold">Azure Test Plans</strong>: A<a id="_idIndexMarker1591"/> service for manual and exploratory testing tools.</li>
<li><code>Maven</code>, <code>npm</code>, <code>NuGet</code>, and <code>Python</code> packages.</li>
</ul>
<p>Azure DevOps is free for open-source projects and small teams. We will not cover all the features of Azure DevOps in this book. Let us focus on Azure Pipelines. In this section, we will discuss how to use Azure Pipelines to build and deploy our ASP.NET Core application to Azure App Service.</p>
<p>We will need these resources before we can deploy the application to Azure:</p>
<ul>
<li><strong class="bold">Azure DevOps </strong><strong class="bold">account</strong>: <a href="https://azure.microsoft.com/en-us/products/devops">https://azure.microsoft.com/en-us/products/devops</a>.</li>
<li><strong class="bold">Azure subscription</strong>: <a href="https://azure.microsoft.com/en-us/free/">https://azure.microsoft.com/en-us/free/</a>. You can sign up for a free account here. You will get some free credits to use Azure services.</li>
<li><strong class="bold">GitHub repository</strong>: You need a GitHub repository to host the source code. The pipeline will be t<a id="_idTextAnchor609"/>riggered when code changes are committed to the repository.</li>
</ul>
<h2 id="_idParaDest-319"><a id="_idTextAnchor610"/>Preparing the source code</h2>
<p>GitHub is one of the most popular source control solutions. It is free for public repositories. We suppose you already have a GitHub account.</p>
<p>Download<a id="_idIndexMarker1593"/> the example code from <a href="https://h/chapter14/MyBasicWebApiDemo">/chapter14/MyBasicWebApiDemo</a>. This is a simple ASP.NET Core web API application with its unit tests and integration tests. Create a new repository on GitHub, then push the source code to the repository. The directory structure of the repository should look like the following:</p>
<pre class="source-code">
MyAzurePipelinesDemo    ├── src
    │   └──MyBasicWebApiDemo
    ├── tests
    │   ├──MyBasicWebApiDemo.UnitTests
    │   └──MyBasicWebApiDemo.IntegrationTests
    ├── MyBasicWebApiDemo.sln
    ├── README.md
    ├── LICENSE
    └── .gitignore</pre>
<p>In the preceding directory structure, the main ASP.NET Core web API project is placed in the <code>src</code> folder, and the unit tests and integration tests are placed in the <code>tests</code> folder. This can better<a id="_idIndexMarker1594"/> organize the solution structure. But it is just a personal preference. You can also place the unit tests and integration tests in the same folder as the main project. If you use a different directory structure, please update the paths in the pipeline accordingly in the following sections.</p>
<p>We will use this repository for th<a id="_idTextAnchor611"/>e pipeline. Next, let us create the required Azure resources.</p>
<h2 id="_idParaDest-320"><a id="_idTextAnchor612"/>Creating Azure resources</h2>
<p>In today’s technology<a id="_idIndexMarker1595"/> landscape, cloud computing has become the backbone of modern software development. Cloud computing provides many benefits, such as scalability, <strong class="bold">high availability</strong> (<strong class="bold">HA</strong>), and <a id="_idIndexMarker1596"/>cost efficiency. Among the various cloud providers, such as AWS, GCP, and Alibaba Cloud, Microsoft Azure stands out as a robust and versatile platform for hosting and orchestrating your applications. Azure provides many<a id="_idIndexMarker1597"/> services for hosting applications, such as Azure App Service, <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>), <strong class="bold">Azure Container Instances</strong> (<strong class="bold">ACI</strong>), Azure VMs, and Azure Functions. In this book, we will use Azure as the cloud platform to<a id="_idIndexMarker1598"/> host our applications. For other cloud platforms, the concepts are similar.</p>
<p>We will need the following Azure resources:</p>
<ul>
<li><strong class="bold">Azure Container Registry</strong>: A <a id="_idIndexMarker1599"/>private registry for storing Docker images. You can create a new Azure container registry in the Azure portal. Please refer to the official documentation here: <a href="https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-portal">https://docs.microsoft.com/en-us/azure/container-registry/container-registry-get-started-portal</a>.</li>
<li><strong class="bold">Azure Web App for Containers</strong>: A <a id="_idIndexMarker1600"/>service for hosting containerized web applications. It provides a quick and easy way to build, deploy, and scale enterprise-grade web, mobile, and API apps on any platform. You can create a new Azure Web App for Containers instance in the Azure portal. Please refer to the official documentation here: <a href="https://learn.microsoft.com/en-us/azure/app-service/quickstart-custom-container?tabs=dotnet&amp;pivots=container-linux-azure-portal">https://learn.microsoft.com/en-us/azure/app-service/quickstart-custom-container?tabs=dotnet&amp;pivots=container-linux-azure-portal</a>. Please select <strong class="bold">Docker Container</strong> for the <strong class="bold">Publish</strong> option, and select <strong class="bold">Linux</strong> for the <strong class="bold">Operating System</strong> option when creating the Web App for Containers instance because we are using Linux containers in this chapter.</li>
</ul>
<p>Note that<a id="_idIndexMarker1601"/> you can also choose Azure App Service to host your application without containerization. Azure App Service supports many programming languages and frameworks, such as .NET, .NET Core, Java, Node.js, Python, and so on. It also supports containers. You can learn more about Azure App Service here: <a href="https://docs.microsoft.com/en-us/azure/app-service/overview">https://docs.microsoft.com/en-us/azure/app-service/overview</a>. In this section, we will explore how to deploy applications in containers, so we will use Azure Web App for Containers in the following example.</p>
<p>To better manage these resources, it is recommended to create a resource group to group these resources together. You can create a new resource group in the Azure portal or create a new resource group when you create a new resource. Here is key information on the resources we need to prepare for the pipelines:</p>
<p>Resource group</p>
<p class="list-inset">name: <code>devops-lab</code></p>
<p>Container registry</p>
<p class="list-inset">name: <code>devopscrlab</code></p>
<p>Web App for Containers instance:</p>
<p class="list-inset">name: <code>azure-pipeline-demo</code></p>
<p>You can use either the Azure portal or Azure CLI to create these resources. Defining the scripts to create the<a id="_idIndexMarker1602"/> resources in code is a good practice, which is called <strong class="bold">infrastructure as code</strong> (<strong class="bold">IaC</strong>). However, we will not cover IaC here because it is out of the scope of this book. You can learn more about IaC here: <a href="https://learn.microsoft.com/en-us/devops/deliver/what-is﻿-infrastructure-as-code">https://learn.microsoft.com/en-us/devops/deliver/what-is-infrastructure-as-code</a>.</p>
<p>Next, let us create an Azure DevOps project.</p>
<h2 id="_idParaDest-321"><a id="_idTextAnchor614"/>Creating an Azure DevOps project</h2>
<p>As the <a id="_idIndexMarker1603"/>official documentation provides detailed instructions on how to create an Azure DevOps project, we will not cover the details here. Please refer to the official documentation here: <a href="https://learn.microsoft.com/en-us/azure/devops/pipelines/get-started/pipelines-sign-up?view=azure-devops">https://learn.microsoft.com/en-us/azure/devops/pipelines/get-started/pipelines-sign-up?view=azure-devops</a>.</p>
<p>You need to follow the official documentation to create an Azure DevOps account. You can sign up with a Microsoft account or a GitHub account. Once you create an Azure DevOps account, you can create a new organization. An organization is a container for projects and teams. You can create multiple organizations with one Azure DevOps account.</p>
<p>Next, you can create a new project in Azure DevOps. Click the <strong class="bold">New project</strong> button on the home page, then follow the instructions to create a new project as follows:</p>
<div><div><img alt="Figure 14.5 – Creating a new project in Azure DevOps" src="img/B18971_14_05.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – Creating a new project in Azure DevOps</p>
<p>We will <a id="_idIndexMarker1604"/>create these pipelines in the project in the next sections:</p>
<ul>
<li><strong class="bold">Pull request build pipeline</strong>: A<a id="_idIndexMarker1605"/> pipeline for building the application and running tests when a pull request is created. This pipeline will be triggered when a pull request is created in the GitHub repository. If the build fails or the tests fail, the pull request cannot be merged.</li>
<li><code>main</code> branch.</li>
<li><strong class="bold">Release pipeline</strong>: A<a id="_idIndexMarker1607"/> pipeline for deploying the application to Azure Container Apps. This pipeline can be triggere<a id="_idTextAnchor615"/>d when a new image is published to ACR, or it can be triggered manually.</li>
</ul>
<h2 id="_idParaDest-322"><a id="_idTextAnchor616"/>Creating a pull request pipeline</h2>
<p>In this<a id="_idIndexMarker1608"/> section, we will create a pull request build pipeline. Follow the steps:</p>
<ol>
<li>Navigate to the Azure DevOps portal, click the <strong class="bold">Pipelines</strong> tab on the left side, and then click the <strong class="bold">Create Pipeline</strong> button. You will see a page like this:</li>
</ol>
<div><div><img alt="Figure 14.6 – Creating a new pipeline in Azure DevOps" src="img/B18971_14_06.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.6 – Creating a new pipeline in Azure DevOps</p>
<ol>
<li value="2">Azure DevOps Pipelines supports various sources, such as Azure Repos, GitHub, Bitbucket, and Subversion. We already have a GitHub repository, so we will use GitHub as the source. Click the <strong class="bold">GitHub</strong> button, then follow the instructions to authorize<a id="_idIndexMarker1609"/> Azure DevOps to access your GitHub account. Once you have authorized Azure DevOps to access your GitHub account, you will see a list of repositories in your GitHub account. Select the repository we created earlier; you will be navigated to GitHub and see a page where you can install Azure Pipelines to the repository. Click the <strong class="bold">Approve and install</strong> button to install Azure Pipelines to the repository. Then, you will be navigated back to Azure DevOps. You will see a page like this:</li>
</ol>
<div><div><img alt="Figure 14.7 – Configuring the pipeline" src="img/B18971_14_07.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.7 – Configuring the pipeline</p>
<ol>
<li value="3">Azure DevOps Pipelines can provide various templates for your project. In this case, you can choose the <strong class="bold">ASP.NET</strong> template to start with. Azure DevOps Pipelines can automatically detect the source code and generate a basic pipeline for you. The <a id="_idIndexMarker1610"/>default pipeline is a YAML file, which may look like this:<pre class="source-code">
trigger:- mainpool:  vmImage: 'windows-latest'variables:  solution: '**/*.sln'  buildPlatform: 'Any CPU'  buildConfiguration: 'Release'steps:- task: NuGetToolInstaller@1- task: NuGetCommand@2  inputs:    restoreSolution: '$(solution)'- task: VSBuild@1  inputs:    solution: '$(solution)'    msbuildArgs: '/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:PackageLocation="$(build.artifactStagingDirectory)"'    platform: '$(buildPlatform)'    configuration: '$(buildConfiguration)'- task: VSTest@2  inputs:    platform: '$(buildPlatform)'    configuration: '$(buildConfiguration)'</pre></li> <li>The <a id="_idIndexMarker1611"/>default pipeline is targeting Windows. We will run the application in a Linux container, so we need to make some changes to the pipeline. Delete the default content and we will start from scratch.</li>
<li>First, rename the pipeline to <code>pr-build-pipeline</code>. You can rename the pipeline by clicking the <code>.</code><code>yml</code> filename:</li>
</ol>
<div><div><img alt="Figure 14.8 – Renaming the pipeline" src="img/B18971_14_08.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.8 – Renaming the pipeline</p>
<ol>
<li value="6">Then, we need to update the trigger to make the pipeline run when a pull request is opened or updated for one of the target branches. Use the <code>pr</code> keyword to <a id="_idIndexMarker1612"/>indicate that the pipeline will be triggered by a pull request for the <code>main</code> branch:<pre class="source-code">
pr:  branches:    include:    - main</pre></li> <li>Next, set <code>pool</code> to use the <code>ubuntu-latest</code> image. The <code>ubuntu-latest</code> image is a Linux image, which is smaller than a Windows image. Also, the application is targeting Linux containers, so it is better to use a Linux image:<pre class="source-code">
pool:  vmImage: 'ubuntu-latest'</pre></li> <li>Next, create some variables for the solution path, build configuration, and so on:<pre class="source-code">
variables:  solution: '**/*.sln'  buildConfiguration: 'Release'</pre></li> <li>Then, we need to add some tasks. Add a <code>steps:</code> section, then add the following tasks:<pre class="source-code">
steps:- task: UseDotNet@2  displayName: 'use dotnet cli'  inputs:    packageType: 'sdk'    version: '8.0.x'    includePreviewVersions: true</pre><p class="list-inset">The <code>UseDotNet@2</code> task is used to install the .NET SDK so that we can use the .NET CLI to execute commands. In this case, we are installing the .NET 8.0 SDK. The <code>includePreviewVersions</code> option is used to include preview versions of the .NET SDK. We need to use the preview version because the .NET 8.0 SDK is still in <a id="_idIndexMarker1613"/>preview at the time of writing this book. If you are reading this book after the .NET 8.0 SDK is released, you can remove the <code>includePreviewVersions</code> option.</p><p class="list-inset">The online pipeline editor provides IntelliSense for the YAML file like this:</p></li> </ol>
<div><div><img alt="Figure 14.9 – IntelliSense for YAML file" src="img/B18971_14_09.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.9 – IntelliSense for YAML file</p>
<ol>
<li value="10">You can click the <strong class="bold">Settings</strong> link above the task to configure the task in a dialog box:</li>
</ol>
<div><div><img alt="Figure 14.10 – Configuring the task in a dialog box" src="img/B18971_14_10.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.10 – Configuring the task in a dialog box</p>
<ol>
<li value="11">Next, add a <code>DotNetCoreCLI@2</code> task to build the application:<pre class="source-code">
- task: DotNetCoreCLI@2  displayName: 'dotnet build'  inputs:    command: 'build'    arguments: '--configuration $(buildConfiguration)    projects: '$(solution)'</pre><p class="list-inset">The <code>DotNetCoreCLI@2</code> task is used to run dotnet CLI commands. In this case, we are running the <code>dotnet build</code> command to build the application. The <code>--configuration</code> option is used to specify the build configuration. The <code>--runtime</code> option is used to specify the target runtime. In this case, we are targeting the Linux runtime. The <code>projects</code> option is used to specify the path to the <code>.csproj</code> file or solution file. In this case, we are using the <code>$(solution)</code> variable we defined earlier.</p></li> <li>Next, add <a id="_idIndexMarker1614"/>tasks to run unit tests and integration tests:<pre class="source-code">
- task: DotNetCoreCLI@2  displayName: 'dotnet test - unit tests'  inputs:    command: 'test'    arguments: '--configuration $(buildConfiguration) --no-build --no-restore --logger trx --collect "Code coverage"'    projects: '**/*.UnitTests.csproj'- task: DotNetCoreCLI@2  displayName: 'dotnet test - integration tests'  inputs:    command: 'test'    arguments: '--configuration $(buildConfiguration) --no-build --no-restore --logger trx --collect "Code coverage"'    projects: '**/*.IntegrationTests.csproj'</pre><p class="list-inset">In the preceding tasks, we are running the <code>dotnet test</code> command to run unit tests and integration tests. The <code>--no-build</code> option is used to skip building the application. The <code>--no-restore</code> option is used to skip restoring the NuGet packages because we have already restored the packages and built the application in the previous tasks. The other options are used to specify the logger and collect code coverage.</p></li> <li>Click<a id="_idIndexMarker1615"/> the <strong class="bold">Save and run</strong> button to commit the changes and run the pipeline. You will see the pipeline is running. After a while, the pipeline will be completed:</li>
</ol>
<div><div><img alt="Figure 14.11 – The pipeline is successful" src="img/B18971_14_11.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.11 – The pipeline is successful</p>
<ol>
<li value="14">Click the <strong class="bold">Tests</strong> tab and you will then see the test results:</li>
</ol>
<div><div><img alt="Figure 14.12 – The test results" src="img/B18971_14_12.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.12 – The test results</p>
<ol>
<li value="15">You<a id="_idIndexMarker1616"/> can also check the code coverage as follows:</li>
</ol>
<div><div><img alt="Figure 14.13 – The code coverage" src="img/B18971_14_13.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.13 – The code coverage</p>
<ol>
<li value="16">We just manually triggered the first run of the pipeline. Next, let us create a pull request and see how the pipeline is triggered.</li>
<li>Create a <a id="_idIndexMarker1617"/>new branch and make some changes to the source code. For example, we can return 6 items instead of 5 items in <code>WeatherForecastController</code>:<pre class="source-code">
return Enumerable.Range(1, 6).Select(index =&gt; new WeatherForecast// Omitted for brevity</pre></li> <li>Then, commit the changes and push the changes to the remote repository. You will find the pipeline runs for the new branch as well. That is because YAML pipelines are enabled by default for all branches. You can disable this feature by using the <code>trigger none</code> option. Add the following line to the beginning of the YAML file:<pre class="source-code">
<strong class="bold">trigger: none</strong></pre><p class="list-inset">Then, this pipeline will not be triggered automatically for new branches but will be triggered by pull requests.</p></li> <li>Next, create a new pull request in the GitHub repository. You will see the pipeline is triggered automatically and then fails:</li>
</ol>
<div><div><img alt="Figure 14.14 – The pipeline is triggered by the pull request but fails" src="img/B18971_14_14.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.14 – The pipeline is triggered by the pull request but fails</p>
<ol>
<li value="20">In this case, we cannot merge the pull request because the build pipeline failed. You can check the logs to see what is wrong with the pipeline. In this case, the pipeline<a id="_idIndexMarker1618"/> failed because the unit tests failed:</li>
</ol>
<div><div><img alt="Figure 14.15 – The unit tests failed" src="img/B18971_14_15.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.15 – The unit tests failed</p>
<ol>
<li value="21">Click the <strong class="bold">Tests</strong> tab and you will then see the test results:</li>
</ol>
<div><div><img alt="Figure 14.16 – The unit tests results" src="img/B18971_14_16.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.16 – The unit tests results</p>
<p class="list-inset">The details of the failed test case can help us to identify the problem. Next, you can fix the error and push the changes to the remote repository. Then, the pipeline will be triggered again. If the pipeline is successful, you can merge the pull request.</p>
<p>The pull request build pipeline is used to ensure that code changes do not break the application. It is important to run the tests before merging the pull request. Next, let us cre<a id="_idTextAnchor617"/>ate a CI build pipeline to build the Docker image and publish it to ACR.</p>
<h2 id="_idParaDest-323"><a id="_idTextAnchor618"/>Publishing the Docker image to ACR</h2>
<p>In the <a id="_idIndexMarker1619"/>previous section, we created a pull request build pipeline to validate code changes in pull requests. The pipeline will be triggered when a pull request is created or updated. Once the pull request is merged to the <code>main</code> branch, we can automatically build the Docker image and publish it to ACR. To do that, we will create a CI build pipeline following these steps</p>
<ol>
<li>Create a new pipeline following the same steps as we did in the previous section. In the configure step, we can choose the <code>pr-build-pipeline.yml</code> file we created in the previous section:</li>
</ol>
<div><div><img alt="Figure 14.17 – Choosing an existing YAML file to start with" src="img/B18971_14_17.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.17 – Choosing an existing YAML file to start with</p>
<ol>
<li value="2">A better way is to choose the <strong class="bold">Docker - Build and push an image to Azure Container Registry</strong> template, which is exactly what we need. You will be prompted to configure your Azure subscription, ACR, and so on:</li>
</ol>
<div><div><img alt="Figure 14.18 – Configuring ACR, Dockerfile, and image name" src="img/B18971_14_18.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.18 – Configuring ACR, Dockerfile, and image name</p>
<ol>
<li value="3">Azure Pipelines <a id="_idIndexMarker1620"/>will automatically detect the Dockerfile and generate a pipeline for you. The default pipeline may look like this:<pre class="source-code">
trigger:- mainresources:- repo: selfvariables:  # Container registry service connection established during pipeline creation  dockerRegistryServiceConnection: 'deb345e0-7bdd-4420-ba08-538785d525cd'  imageRepository: 'myazurepipelinesdemo'  containerRegistry: 'devopscrlab.azurecr.io'  dockerfilePath: '$(Build.SourcesDirectory)/src/MyBasicWebApiDemo/Dockerfile'  tag: '$(Build.BuildId)'  # Agent VM image name  vmImageName: 'ubuntu-latest'stages:- stage: Build  displayName: Build and push stage  jobs:  - job: Build    displayName: Build    pool:      vmImage: $(vmImageName)    steps:    - task: Docker@2      displayName: Build and push an image to container registry      inputs:        command: buildAndPush        repository: $(imageRepository)        dockerfile: $(dockerfilePath)        containerRegistry: $(dockerRegistryServiceConnection)        tags: |          $(tag)          latest</pre><p class="list-inset">Azure Pipelines <a id="_idIndexMarker1621"/>has recognized the path of the Dockerfile in the preceding pipeline. Additionally, several variables must be configured, such as the image name and container registry. The <code>tag</code> variable is used to tag the image with the build ID. Note that we added a <code>latest</code> tag to the image. The <code>latest</code> tag is used to indicate the latest version of the image.</p></li> </ol>
<p class="callout-heading">Azure Pipelines predefined variables</p>
<p class="callout">Azure Pipelines provides many predefined variables that can be used in a pipeline. For example, the <code>$(Build.SourcesDirectory)</code> variable is used to obtain the local path on the agent where the source code files have been downloaded. You can find all the predefined variables here: <a href="https://learn.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&amp;tabs=yaml">https://learn.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&amp;tabs=yaml</a>.</p>
<p class="list-inset">The difference from a pull request build pipeline is that we have <strong class="bold">stages</strong> and <strong class="bold">jobs</strong> in the pipeline. <em class="italic">Figure 14</em><em class="italic">.19</em> shows the structure of a pipeline:</p>
<div><div><img alt="Figure 14.19 – The structure of a pipeline" src="img/B18971_14_19.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.19 – The structure of a pipeline</p>
<p class="list-inset">The<a id="_idIndexMarker1622"/> components in <em class="italic">Figure 14</em><em class="italic">.19</em> are explained as follows:</p>
<ul>
<li>A trigger is used to specify when the pipeline should run. It can be a schedule, a pull request, a commit to a specific branch, or a manual trigger.</li>
<li>A pipeline contains one or more stages. A stage is used to organize jobs. In the pull request build pipeline, the stage is omitted. You can have multiple stages in one pipeline for different purposes. For example, you can have a build stage, a test stage, and a deploy stage. The stage can be also used to set boundaries for security and approvals.</li>
<li>Each stage contains one or more jobs. A job is a container of steps. A job can run on one agent or without an agent. For example, you can have a job that runs on a Windows agent, and another job that runs on a Linux agent.</li>
<li>Each job contains one or more steps. A step is the smallest building block in a pipeline. A step is normally a task or a script. Azure Pipelines provides many built-in tasks, such as the <code>Docker@2</code> task we are using in this pipeline. A built-in task is a predefined packaged script that performs an action. You can also write your own custom tasks. A task can be a command-line tool, a script, or a compiled program. You can find all built-in tasks here: <a href="https://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/reference/?view=azure-pipelines">https://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/reference/?view=azure-pipelines</a>.</li>
</ul>
<p class="list-inset">In the preceding pipeline, we have one stage, one job, and one step. The step is the <code>Docker@2</code> task. The <code>Docker@2</code> task is used to build and push a Docker image to a container registry. Using this task simplifies the process of building and pushing a Docker image so that we do not need to write <code>docker build</code> commands manually.</p>
<ol>
<li value="4">Rename<a id="_idIndexMarker1623"/> this pipeline to <code>docker-build-pipeline</code>. Similarly to <code>pr-build-pipeline</code>, we need to exclude the <code>docker-build-pipeline</code> pipeline from running for new branches and pull requests. Add the following line to the beginning of the YAML file:<pre class="source-code">
pr: none</pre><p class="list-inset">So, when we create a new branch or a new pull request, the <code>docker-build-pipeline</code> will not be triggered automatically. We will trigger the pipeline manually or by merging a pull request.</p></li> <li>Click the <code>docker-build-pipeline</code> is triggered automatically.<p class="list-inset">If everything is fine, you will see the <code>docker-build-pipeline</code> pipeline is successful and the Docker image is published to ACR:</p></li>
</ol>
<div><div><img alt="Figure 14.20 – The Docker image is published to ACR" src="img/B18971_14_20.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.20 – The Docker image is published to ACR</p>
<p class="list-inset">A CI pipeline<a id="_idIndexMarker1624"/> is a good practice to ensure that code changes can be built successfully without breaking the application. However, some changes may not need running tests or rebuilding the Docker image. For example, if you only change the documentation, (for example, the <code>README</code> file), you do not need to run the tests or rebuild the Docker image. In this case, you have a few options:</p>
<ol>
<li value="6">You can exclude some files from the pipeline. For example, you can exclude the <code>README.md</code> file from the pipeline. You can use the <code>paths</code> option to specify paths to include or exclude, as follows:<pre class="source-code">
trigger:  branches:    include:    - main  paths:    exclude:    - README.md    - .gitignore    - .dockerignore    - *.yml</pre></li> <li>You can skip CI pipelines for some commits. Use <code>[skip ci]</code> in the commit message to skip CI pipelines. For example, you can use <code>[skip ci] update README</code> in the commit message to skip CI pipelines for this commit. Some variations include <code>[ci skip]</code>, <code>[skip azurepipelines]</code>, <code>[skip azpipelines]</code>, <code>[skip azp]</code>, and so on.</li>
</ol>
<p>You may <a id="_idIndexMarker1625"/>encounter some errors when creating pipelines. Here are some troubleshooting tips:</p>
<ul>
<li>Check the logs carefully. The logs can help you to identify the problem.</li>
<li>Check the variables. Make sure the variables are correct.</li>
<li>Check the permissions. Make sure the service connection has the correct permissions.</li>
<li>Check the YAML syntax. Make sure the YAML file is valid. YAML files use indentation to indicate the structure. Make sure the indentation is correct.</li>
<li>Check the pipeline structure. Make sure the pipeline structure is correct. For example, make sure the <code>steps</code> section is under the <code>jobs</code> section and the <code>jobs</code> section is under the <code>stages</code> section.</li>
<li>Check the pipeline triggers. Make sure the pipeline is triggered by the correct event. You can use <code>branches</code>, <code>paths</code>, <code>include</code>, and <code>exclude</code> to specify branches and paths to trigger the pipeline.</li>
<li>Note that if you edit the pipeline YAML file in the online editor, you will commit the changes to the <code>main</code> branch directly. Your local <code>feature</code> branch will not be updated automatically. When you push a change to your feature branch, whether the pipeline should be triggered depends on the settings in the YAML file in your feature branch, not the <code>main</code> branch. So, make sure your feature branch keeps synchronized with the <code>main</code> branch.</li>
<li>If you use VS to create the Dockerfile, double-check the paths in the Dockerfile. Sometimes, VS cannot detect the correct paths if you use a custom solution structure.</li>
</ul>
<p>We have now <a id="_idIndexMarker1626"/>pushed the Docker image to ACR. Next, let's create a<a id="_idTextAnchor619"/> release pipeline to deploy the application to Azure Web App for Containers.</p>
<h2 id="_idParaDest-324"><a id="_idTextAnchor620"/>Deploying the application to Azure Web App for Containers</h2>
<p>In the<a id="_idIndexMarker1627"/> previous section, we created a CI build pipeline to build the Docker image and publish it to ACR. In this section, we will create a release pipeline to pull the Docker image from ACR and deploy it to Azure Web App for Containers.</p>
<p>Follow the steps in the previous section to create a new pipeline. When we configure the pipeline, choose the <strong class="bold">Starter pipeline</strong> template because we will start from scratch. The default starter pipeline has two scripts as examples. Delete the scripts, and it should look like this:</p>
<pre class="source-code">
trigger: nonepr: none
pool:
  vmImage: ubuntu-latest</pre>
<p>We can disable the triggers for the pipeline because we will manually run the pipeline when we need to deploy the application. Rename the pipeline as <code>release-pipeline</code>.</p>
<p>Next, add some variables to the pipeline:</p>
<pre class="source-code">
variables:  containerRegistry: 'devopscrlab.azurecr.io'
  imageRepository: 'myazurepipelinesdemo'
  tag: 'latest'</pre>
<p>Next, we need to configure the username and password to authenticate the pipeline to pull the Docker image from ACR. You can find the username and password of your ACR instance in the Azure portal. Click the <strong class="bold">Access keys</strong> button on the left side, and you will then see the username and password.</p>
<p>As the<a id="_idIndexMarker1628"/> password is a secret, we cannot use it in the YAML file directly, otherwise the password will be exposed in the GitHub repository. Azure Pipelines provides a way to store secrets in the pipeline. Click the <strong class="bold">Variables</strong> button in the top-right corner, then click the <strong class="bold">New variable</strong> button to add a new variable:</p>
<div><div><img alt="Figure 14.21 – Adding a new variable to store the password" src="img/B18971_14_21.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.21 – Adding a new variable to store the password</p>
<p>Check the <code>$(acrpassword)</code> variable to refer to the password.</p>
<p>Next, add a <a id="_idIndexMarker1629"/>task to set up the Azure App Service settings. Choose the <strong class="bold">Azure App Service Settings</strong> task from the task assistant. We need to add the credentials to authenticate the Azure Web App to pull the Docker image from ACR. Azure Pipelines will prompt you to configure the task. Note that the <strong class="bold">App settings</strong> field is a JSON string. The tasks should look like this:</p>
<pre class="source-code">
- task: AzureAppServiceSettings@1  displayName: Update settings
  inputs:
    azureSubscription: '&lt;Your Azure subscription&gt;(&lt;guid&gt;)'
    appName: 'azure-pipeline-demo'
    resourceGroupName: 'devops-lab'
    appSettings: |
      [
        {
          "name": "DOCKER_REGISTRY_SERVER_URL",
          "value": "$(containerRegistry)",
          "slotSetting": false
        },
        {
          "name": "DOCKER_REGISTRY_SERVER_USERNAME",
          "value": "devopscrlab",
          "slotSetting": false
        },
        {
          "name": "DOCKER_REGISTRY_SERVER_PASSWORD",
          "value": "$(acrpassword)",
          "slotSetting": false
        }
      ]</pre>
<p>In the <code>appSettings</code> field, we use the <code>$(acrpassword)</code> variable to refer to the password we created earlier.</p>
<p>Next, click<a id="_idIndexMarker1630"/> the <strong class="bold">Show assistant</strong> button in the top-right corner to open the assistant. The assistant helps us to use the built-in tasks easily. Choose the <strong class="bold">Azure Web App for Containers</strong> task that is used to deploy the Docker image from ACR to Azure Web App for Containers. Azure Pipelines will prompt you to configure the task. Configure the task as follows:</p>
<pre class="source-code">
- task: AzureWebAppContainer@1  displayName: Deploy to Azure Web App for Container
  inputs:
    azureSubscription: '&lt;Your Azure subscription&gt;'
    appName: 'azure-pipeline-demo'
    containers: '$(containerRegistry)/$(imageRepository):$(tag)'
    containerCommand: 'dotnet MyBasicWebApiDemo.dll'</pre>
<p>Alternatively, you can use the <strong class="bold">Azure App Service Deploy</strong> task from the assistant. This task is used to deploy the application to Azure Web App that supports either native deployment or container deployment. You need to configure the Azure subscription, App Service type, and so on. When you choose the <strong class="bold">Web App for Containers (Linux)</strong> option for <strong class="bold">App Service type</strong>, you will be prompted to configure the ACR name, Docker image name, tag, and so on. The task should look like this:</p>
<pre class="source-code">
- task: AzureRmWebAppDeployment@4  displayName: Deploy to Web App for Container
  inputs:
    ConnectionType: 'AzureRM'
    azureSubscription: '&lt;Your Azure subscription&gt;'
    appType: 'webAppContainer'
    WebAppName: 'azure-pipeline-demo'
    DockerNamespace: 'devopscrlab.azurecr.io'
    DockerRepository: 'myazurepipelinesdemo'
    DockerImageTag: 'latest'
    StartupCommand: 'dotnet MyBasicWebApiDemo.dll'</pre>
<p>Note that we also need to specify a <code>StartupCommand</code> value. In this case, we use <code>dotnet MyBasicWebApiDemo.dll</code> to start the application.</p>
<p>Now, we can manually trigger the pipeline to deploy the application. If everything is fine, you will see the deployment is successful.</p>
<p>Check the <a id="_idIndexMarker1631"/>configuration of the Azure Web App. You will see the <strong class="bold">Application settings</strong> are updated:</p>
<div><div><img alt="Figure 14.22 – The application settings are updated" src="img/B18971_14_22.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.22 – The application settings are updated</p>
<p>Navigate to the Azure portal and check the details of the Azure Web App we created earlier. You <a id="_idIndexMarker1632"/>can find the URL of the Azure Web App, such as <code>azure-pipeline-demo.azurewebsites.net</code>. Open the URL in the browser and check the controller endpoint, such as <code>https://azure-pipeline-demo.azurewebsites.net/WeatherForecast</code>. You will see the response from the application.</p>
<p>So far, we have created three pipelines:</p>
<ul>
<li><strong class="bold">Pull request build pipeline</strong>: This<a id="_idIndexMarker1633"/> pipeline is to validate the code changes in pull requests. It will be triggered when a pull request is created or updated. If the build fails or the tests fail, the pull request cannot be merged. This pipeline does not produce any artifacts.</li>
<li><code>main</code> branch. This pipeline produces a Docker image as the artifact.</li>
<li><strong class="bold">Release pipeline</strong>: This <a id="_idIndexMarker1635"/>pipeline is to pull the Docker image from ACR and deploy it to Azure Web App for Containers. This pipeline can be triggered manually or automatically when a <a id="_idTextAnchor621"/>new Docker image is published to ACR. This pipeline does not produce any artifacts.</li>
</ul>
<h2 id="_idParaDest-325"><a id="_idTextAnchor622"/>Configuring settings and secrets</h2>
<p>In the<a id="_idIndexMarker1636"/> previous section, we created a release pipeline to deploy the application to Azure Web App for Containers. We may also need to deploy the application to other environments, such as staging. These different environments may have different settings, such as database connection strings, API keys, and so on. So, how can we configure the settings for different environments?</p>
<p>There are various ways to achieve this. A simple way is to configure variables for different environments. You can define variables in each pipeline directly. Azure Pipelines also provides a <strong class="bold">Library</strong> to manage variables. You can group variables into a variable group and then use the variable group in the pipeline.</p>
<p>Storing <a id="_idIndexMarker1637"/>confidential information securely is essential to any organization. To ensure the safety of your secrets, you can use a variety of key vaults, such as Azure Key Vault and AWS Secrets Manager. Azure Pipelines offers a Key Vault task to fetch secrets from the vault. With the Azure Key Vault task, you can easily retrieve secrets from the vault and use them in your pipeline. To learn more about the Key Vault task, please visit <a href="https://learn.microsoft.com/en-us/azure/devops/pipelines/release/key-vault-in-own-project">https://learn.microsoft.com/en-us/azure/devops/pipelines/release/key-vault-in-own-project</a>.</p>
<p>This chapter is not intended to cover all the details of Azure Pipelines, but you should now have a basic understanding of Azure Pipelines. Using CI/CD pipelines can help you to automate the build, test, and deployment process, which eliminates manual work and reduces the risk of human errors. It is more and more important to use CI/CD pipelines in modern software development. Every developer should learn how to use them.</p>
<p>In t<a id="_idTextAnchor623"/>he next section, we will explore GitHub Actions, which is another popular CI/CD tool.</p>
<h1 id="_idParaDest-326"><a id="_idTextAnchor624"/>GitHub Actions</h1>
<p>In the<a id="_idIndexMarker1638"/> previous section, we explored Azure Pipelines. Next, let us explore GitHub Actions. GitHub Actions is a CI/CD tool provided by GitHub. It is quite similar to Azure Pipelines. In this section, we will <a id="_idTextAnchor625"/>use GitHub Actions to build and test the application and push the Docker image to ACR.</p>
<h2 id="_idParaDest-327"><a id="_idTextAnchor626"/>Preparing the project</h2>
<p>To demonstrate <a id="_idIndexMarker1639"/>how to use GitHub Actions, we will use the same source code as we used in the previous section. You can download the source code from the GitHub repository here: <a href="https://github.com/PacktPublishing/Web-API-Development-with-ASP.NET-Core-8/tree/main/samples/chapter14/MyBasicWebApiDemo">https://github.com/PacktPublishing/Web-API-Development-with-ASP.NET-Core-8/tree/main/samples/chapter14/MyBasicWebApiDemo</a>. Create a new GitHub repository and push the source code to the repository. The directory structure of the source code is as follows:</p>
<pre class="source-code">
MyGitHubActionsDemo    ├── src
    │   └──MyBasicWebApiDemo
    ├── tests
    │   ├──MyBasicWebApiDemo.UnitTests
    │   └──MyBasicWebApiDemo.IntegrationTests
    ├── MyBasicWebApiDemo.sln
    ├── README.md
    ├── LICENSE
    └── .gitignore</pre>
<p>If you<a id="_idIndexMarker1640"/> use a different directory structure, please update the paths in the pipeline accordingly in the followi<a id="_idTextAnchor627"/>ng sections. We will use this repository to demonstrate how to configure GitHub Actions.</p>
<h2 id="_idParaDest-328"><a id="_idTextAnchor628"/>Creating GitHub Actions</h2>
<p>We will <a id="_idIndexMarker1641"/>reuse the Azure resources we created in the previous section. If you have not created the Azure resources, please refer to the <em class="italic">Creating Azure resources</em> section to create the resources.</p>
<p>On the GitHub repository page, click the <strong class="bold">Actions</strong> tab, and you can see many templates for different programming languages and frameworks:</p>
<div><div><img alt="Figure 14.23 – Choosing a template for GitHub Actions" src="img/B18971_14_23.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.23 – Choosing a template for GitHub Actions</p>
<p>In the <strong class="bold">Continuous integration</strong> section, you can find the <strong class="bold">.NET</strong> template. Click the <strong class="bold">Configure</strong> button<a id="_idIndexMarker1642"/> to create a new workflow. The workflow is a YAML file that defines the CI/CD pipeline. The default workflow may look like this:</p>
<pre class="source-code">
# This workflow will build a .NET project# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-net
name: .NET
on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Setup .NET
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: 6.0.x
    - name: Restore dependencies
      run: dotnet restore
    - name: Build
      run: dotnet build --no-restore
    - name: Test
      run: dotnet test --no-build --verbosity normal</pre>
<p>The syntax of the workflow is quite similar to Azure Pipelines. The workflow is triggered when a pull request is created or updated, or when a commit is pushed to the <code>main</code> branch.</p>
<p>On the <a id="_idIndexMarker1643"/>right side, you can find the <strong class="bold">Marketplace</strong> panel. The Marketplace is similar to the assistants of Azure DevOps Pipelines and provides many built-in actions that you can use in your workflow:</p>
<div><div><img alt="Figure 14.24 – The Marketplace panel" src="img/B18971_14_24.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.24 – The Marketplace panel</p>
<p>The sample application uses .NET 8. So, we need to update <code>dotnet-version</code> to <code>8.0.x</code>. Click the <code>dotnet.yml</code> file is <a id="_idIndexMarker1644"/>committed to the <code>/.github/workflows</code> directory. Make a change to the source code or create a new branch and push the changes to the remote repository. For example, you can change the controller to return six items instead of five items:</p>
<pre class="source-code">
public IEnumerable&lt;WeatherForecast&gt; Get(){
    return Enumerable.Range(1, 6).Select(index =&gt; new WeatherForecast
    // Omitted for brevity</pre>
<p>You can also create a pull request. You will see the workflow is triggered automatically and the test is failed:</p>
<div><div><img alt="Figure 14.25 – The workflow is triggered automatically and then fails" src="img/B18971_14_25.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.25 – The workflow is triggered automatically and then fails</p>
<p>Click the links in the logs to see details of the code that caused the test failure. It is handy to review code changes in the pull request. If everything is fine, you can merge the pull request.</p>
<p>To clarify that it <a id="_idIndexMarker1645"/>works for pull request builds, we can rename this file to <code>pr-build.yml</code> and update the <code>on</code> section to make the workflow run for pull requests:</p>
<pre class="source-code">
on:  pull_request:
    branches: [ "main" ]</pre>
<p>Next, let us build a Docker image and push it to ACR.</p>
<h2 id="_idParaDest-329"><a id="_idTextAnchor629"/>Pushing a Docker image to ACR</h2>
<p>Create a <a id="_idIndexMarker1646"/>new YAML file named <code>docker-build.yml</code> in the <code>.github\workflows</code> folder. Update the content of the file as follows:</p>
<pre class="source-code">
name: Pull Request buildon:
  push:
    branches: [ "main" ]</pre>
<p>This workflow is triggered when a commit is pushed to the <code>main</code> branch or a pull request is merged into the <code>main</code> branch.</p>
<p>To authenticate the action to access ACR, we need to configure the username and password of ACR in GitHub secrets. Find the username and password by clicking the <strong class="bold">Access keys</strong> menu of ACR in the Azure portal.</p>
<p>Go to <strong class="bold">Settings</strong> in the GitHub repository and click <strong class="bold">Secrets and variables</strong> in the <strong class="bold">Security</strong> category. Then, click <strong class="bold">Actions</strong>, and you will see the secrets and variables page. There are two types of secrets: environment secrets and repository secrets. You can store the username and password in repository secrets directly. To demonstrate how to use environment secrets, we will use environment secrets in this example. Click the <strong class="bold">Manage environments</strong> button to create a new environment named <strong class="bold">Production</strong>. Then, click the <strong class="bold">Add secret</strong> button to add a username and password:</p>
<ul>
<li>Name: <code>REGISTRY_USERNAME</code>. Value: The username of ACR.</li>
<li>Name: <code>REGISTRY_PASSWORD</code>. Value: The password of ACR.</li>
</ul>
<p>You can <a id="_idIndexMarker1647"/>change the environment secret names, but make sure you use the same names in the following workflow.</p>
<p>Now, the environment secrets should look like this:</p>
<div><div><img alt="Figure 14.26 – The Actions secrets and variables page" src="img/B18971_14_26.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.26 – The Actions secrets and variables page</p>
<p>Add the following content to the <code>docker-build.yml</code> file:</p>
<pre class="source-code">
jobs:  docker_build_and_push:
    runs-on: ubuntu-latest
    environment: Production
    steps:
    - uses: actions/checkout@v3
    - name: Setup .NET
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: 8.0.x
    - name: Restore dependencies
      run: dotnet restore
    - name: Build
      run: dotnet build --no-restore
    - name: Login to Azure Container Registry
      uses: azure/docker-login@v1
      with:
        login-server: devopscrlab.azurecr.io
        username: ${{ secrets.REGISTRY_USERNAME }}
        password: ${{ secrets.REGISTRY_PASSWORD }}
    - name: Push to Azure Container Registry
      run: |
        docker build -f ${{ github.workspace }}/src/MyBasicWebApiDemo/Dockerfile -t devopscrlab.azurecr.io/myazurepipelinesdemo:${{ github.run_id }} -t devopscrlab.azurecr.io/myazurepipelinesdemo:latest .
        docker push devopscrlab.azurecr.io/myazurepipelinesdemo:${{ github.run_id }}
        docker push devopscrlab.azurecr.io/myazurepipelinesdemo:latest</pre>
<p>The <a id="_idIndexMarker1648"/>preceding is similar to the <code>pr-build.yml</code> file, but we made some changes:</p>
<ul>
<li>We added an <code>environment</code> section to specify the environment so that we can refer to the environment secrets later.</li>
<li>We added a new <code>azure/docker-login@v1</code> step to log in to ACR. In this step, we specified the login server, username, and password using the environment secrets.</li>
<li>We<a id="_idIndexMarker1649"/> added a new step to build the Docker image and push it to ACR. In this step, we used the <code>github.run_id</code> variable to tag the image with the run ID. We also tagged the image with <code>latest</code>.</li>
</ul>
<p class="callout-heading">GitHub Actions context</p>
<p class="callout">GitHub Actions supports many built-in context variables, such as <code>github.run_id</code>, <code>github.run_number</code>, <code>github.sha</code>, <code>github.ref</code>, and so on. You can find all the context variables here: <a href="https://docs.github.com/en/actions/learn-github-actions/contexts">https://docs.github.com/en/actions/learn-github-actions/contexts</a>.</p>
<p>Commit the changes and push the changes to the remote repository. Next time you merge a pull request, you will see the workflow is triggered automatically and the Docker image is pushed to ACR:</p>
<div><div><img alt="Figure 14.27 – The GitHub Actions workflow is triggered automatically" src="img/B18971_14_27.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.27 – The GitHub Actions workflow is triggered automatically</p>
<p>As there are many similarities between Azure Pipelines and GitHub Actions, we will not cover all the details of GitHub Actions. Maybe it is your turn to create a GitHub Actions workflow to deploy the Docker image to Azure Web App for Containers? <a id="_idTextAnchor630"/>You can find more information about GitHub Actions here: <a href="https://docs.github.com/en/actions">https://docs.github.com/en/actions</a>.</p>
<h1 id="_idParaDest-330"><a id="_idTextAnchor631"/>Summary</h1>
<p>In this chapter, we explored the fundamentals of CI/CD. We discussed how to use Docker to containerize ASP.NET web API applications, including how to create a Dockerfile, build a Docker image, and run a Docker container locally. We then looked at Azure DevOps Pipelines, a powerful CI/CD platform from Microsoft, and how to create CI/CD pipelines in YAML files. We covered configuring triggers, using built-in tasks, and using variables. We created three pipelines for builds, Docker image builds, and releases. We also briefly discussed GitHub Actions, another popular CI/CD tool, and created a GitHub Actions workflow to build and test the application, then build the Docker image and push it to ACR. After reading this chapter, you should have a basic understanding of CI/CD and be able to use CI/CD pipelines to automate the build, test, and deployment process.</p>
<p>In the next chapter, we will examine some common practices for building ASP.NET web APIs, including caching, <code>HttpClient</code> factory, and so on.</p>
</div>
</body></html>