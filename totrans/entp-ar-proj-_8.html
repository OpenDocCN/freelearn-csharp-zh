<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">AR for Tourism with ARKit</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will explore ARKit, Apple's own AR SDK, which offers many features such as spatial tracking, image tracking, collaborative AR, and more. We will also learn how to exploit world tracking in order to create a different AR experience for the tourism sector.</p>
<p>The main goals of this chapter are to introduce you to ARKit and how it works by searching and tracking flat surfaces in the real world. Then, you will learn how to use these features to place elements in AR and anchor them in order to create a dimensional portal that will introduce the user to a 3D world. The second goal of this chapter is to present a different way of viewing tourism. You will learn how to take advantage of AR to create unique experiences that can be implemented in museums, landscapes, points of interest, and so on. By doing this, you will be able to modify and apply this project to your own interests.</p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Using AR for tourism</li>
<li>Exploring ARKit</li>
<li>Developing an ARKit app</li>
<li>Creating an AR portal</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>The technical requirements for this chapter are as follows:</p>
<ul>
<li>A Mac computer with macOS Sierra 10.12.4 or above (we used a Mac mini, Intel Core i5, 4 GB memory, with macOS Mojave in this book)</li>
<li>The latest version of Xcode (10.3 in this book)</li>
<li>An ARKit-compatible iPhone/iPad with iOS 11+ (we tested the project on an iPad Pro 10.5 with iOS 13.1.1)</li>
</ul>
<p>The code files and resources for this chapter can be found here: <a href="https://github.com/PacktPublishing/Enterprise-Augmented-Reality-Projects/tree/master/Chapter08">https://github.com/PacktPublishing/Enterprise-Augmented-Reality-Projects/tree/master/Chapter08</a></p>
<p>You can view the compatible devices at <a href="https://developer.apple.com/library/archive/documentation/DeviceInformation/Reference/iOSDeviceCompatibility/DeviceCompatibilityMatrix/DeviceCompatibilityMatrix.html">https://developer.apple.com/library/archive/documentation/DeviceInformation/Reference/iOSDeviceCompatibility/DeviceCompatibilityMatrix/DeviceCompatibilityMatrix.html</a></p>
<p>When we explore ARKit, we will explain the device requirements you'll need, depending on the ARKit features that you want to use, since not all devices can use them.</p>
<p>Finally, take into account that this chapter is dedicated to iOS devices. Therefore, you will need an Apple account (free or developer account) to compile the project on your iOS device. You can find more information here: <a href="https://developer.apple.com/support/compare-memberships/">https://developer.apple.com/support/compare-memberships/</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using AR for tourism</h1>
                </header>
            
            <article>
                
<p>AR is mainly a visual technology. Although it can combine other effects such as sounds to make the experience more realistic or vibrations on the phone when we are playing a game, its main attraction is the visual content it displays over the real world. That makes this technology perfect for enhancing traveling experiences, from showing skyline information to making animals in a museum come to life or even translating signs and guides in real time. </p>
<p><span>Back in the late 2000s/early 2010s, when smartphones started to become popular, some of the first AR apps that appeared were tourism-oriented. In 2010, </span><span class="hiddenSuggestion">for example</span><span>, the Museum of London released an iPhone app that showed historical photos of the city over the real places. This example has also been carried to other cities and scopes, such as in Navarra, Spain, where users can replay scenes of famous films shot in different locations of the region in AR by pointing their mobile devices to the panels that had been placed in said locations. In this case, the mobile devices use image recognition (the panel) to launch the AR experience. However, back in the early 2010s, the most stable and widespread AR technology was location-based and used a device's GPS, accelerometer, and compass. </span><span>AR engines and apps such as Layar and Wikitude were mostly used as they allowed developers to generate routes, gymkhanas, and even games based on</span> <strong>points of interest</strong> <span>(</span><strong>POIs</strong><span>) across cities.</span></p>
<p>Nowadays, some of the most common uses of AR in tourism are as follows:</p>
<ul>
<li>To serve as a live guide in the streets of a new city, where a user can go around the city while the AR app is showing them where the most interesting points to see are through the use of arrows.</li>
</ul>
<ul>
<li>To show attractions and POIs over a map. Here, when a user points at a map with the camera, the POIs pop up from it and they can interact with them to find out more.</li>
<li>To provide extra information about paintings, sculptures, or monuments. Here, when a user points at a painting, it can show a video about the artist and the place and time where it was painted, or even make it come to life as a 3D simulation.</li>
</ul>
<p>Apart from all these experiences, when AR is combined with other immersive technologies such as virtual worlds or 360º videos, the experience goes one step ahead, allowing users to visit several places at the same time (for example, in a museum network, while visiting one of them, to be able to virtually visit the others).</p>
<p>In this chapter, we will learn about how to mix these experiences using Apple's ARKit SDK to create an art experience. We will create an AR portal, and when users go through it, they will land on a painting represented in 3D. In our case, we will use a painting from Van Gogh (Bedroom in Arles) that's been downloaded from Sketchfab to give the users the illusion of being inside a 3D Van Gogh painting: <a href="https://sketchfab.com/3d-models/van-gogh-room-311d052a9f034ba8bce55a1a8296b6f9">https://sketchfab.com/3d-models/van-gogh-room-311d052a9f034ba8bce55a1a8296b6f9</a>.</p>
<p>To implement this, we will create an app oriented to the tourism field that can be displayed in museums, galleries, and more. Regarding the tool we are going to use, in the next section, we will explain how ARKit works and its main features.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploring ARKit</h1>
                </header>
            
            <article>
                
<p>Apple launched the first version of ARKit in 2017 along with Xcode 9 and iOS 11 to bring AR to iOS devices. The framework, which is included in Xcode, offered developers the possibility to produce AR experiences in their apps or games with software that's combined with an iOS device's motion features and camera tracking. It allows users to place virtual content in the real world. Months after its official release, it added new features such as 2D image detection and face detection. The main features that are available for iOS 11 and above are as follows:</p>
<ul>
<li class="mce-root">Tracking and visualizing planes <span>(iOS 11.3+)</span>, such as a table or the ground, in the physical environment</li>
<li class="mce-root">Tracking known 2D images <span>(iOS 11.3+)</span> in the real world and placing AR content over them (image recognition)</li>
</ul>
<ul>
<li class="mce-root">Tracking faces <span>(iOS 11.0+) </span>in the camera feed and laying virtual content over them (for example, a virtual avatar face) that react to facial expressions in real-time</li>
</ul>
<p class="mce-root">Apart from these features, the AR experience can also be enhanced by using sound effects attached to virtual objects or integrating other frameworks such as vision to add computer vision algorithms to the app, or Core ML, for machine learning models.</p>
<p class="mce-root"><span>In 2018, with the</span><span> </span><span class="hiddenSpellError">iOS</span><span> </span><span>12 release,</span><span> </span><span class="hiddenSpellError">ARKit</span><span> </span><span>2</span><span> </span><span class="hiddenGrammarError">was launched</span><span> </span><span>with new features:</span></p>
<ul>
<li>3D<span> </span>object tracking, where real-world objects are the ones that trigger the AR elements</li>
<li>Multiuser AR experiences, allowing users near each other to share the same AR environment</li>
<li>Adding realistic reflections to the AR objects<span> </span><span>to</span><span> </span><span class="hiddenGrammarError">make the experience</span><span> </span><span>more realistic</span></li>
<li>Saving the world-mapping data so that when a user places a virtual element in the real world, the next time the app restarts, the virtual elements will appear in the same place</li>
</ul>
<p>At the time of writing this book, iOS 13 with ARKit 3 has just been launched and promises a huge improvement to the current state since it's added a new way of interacting with virtual elements, such as hiding virtual objects when a person is detected in front of them. It also allows users to interact with 3D objects by gestures and captures not only facial expressions but the motions of a person.</p>
<p>Because of the changes that are made in each iOS launch, not all the features that we mentioned here are available on all devices. The developers' page at <a href="https://developer.apple.com/documentation/arkit">https://developer.apple.com/documentation/arkit</a> enumerates the current ARKit features and required minimum Xcode and iOS versions to develop and test with.</p>
<p>For this project, we will be using plane detection, which is a basic feature that can be run on iOS 11 and above. We will look at this in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Developing an ARKit app</h1>
                </header>
            
            <article>
                
<p>To start developing an app with ARKit, make sure you have the required hardware we discussed in the <em>Technical requirements</em> section, including an iOS device, since it's necessary to run the app. </p>
<p>You will also need an Apple account to build your project on a real device. If you don't have a paid account, you can also sign in with your regular free Apple ID. The current limits when using a free account are as follows: up to three installed apps on your device at the same time and the ability to create up to 10 different apps every seven days.</p>
<p>In this section, we will create an AR project using Xcode's template and go through its main components. Then, we will modify the basic app to visualize the detected surfaces and display important messages to users.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating a new AR project</h1>
                </header>
            
            <article>
                
<p>Let's create a new AR application using ARKit. We will start by creating the project in Xcode, the developer toolset for macOS that we can download freely from the Mac App Store, by following these steps:</p>
<ol>
<li>
<p>Create a new project, select <span class="packt_screen">Augmented Reality App</span>, and c<span>lic</span>k<span> </span><span class="packt_screen">Next</span>. This will give us the basic frame so that we can start working with AR:</p>
</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1220 image-border" src="assets/8b402154-364c-49ec-baf9-ae93b83c45b2.png" style="width:38.58em;height:28.00em;"/></p>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>Selecting the Augmented Reality App template</span></div>
<ol start="2">
<li>Fill in the <span class="packt_screen">Product Name</span>, <span class="packt_screen">Team</span> (here, you have to enter your Apple ID, and although you can leave it as <span class="packt_screen">None</span> (as shown in the following screenshot), you will have to fill it in later to deploy the project onto the device), and <span class="packt_screen">Organization Name</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1221 image-border" src="assets/7dd9290f-7072-4965-a964-19f21df413e4.png" style="width:39.08em;height:25.75em;"/></p>
<div style="color: black" class="packt_figref CDPAlignCenter CDPAlign">Filling in the main values of our project</div>
<ol start="3">
<li>Press <span class="packt_screen">Next</span>, select a location for the project, and press <span class="packt_screen">Create.</span></li>
<li>
<p>If you didn't enter your developer ID in <em>step 2</em>, the project's general window for the <span class="packt_screen">Signing</span> tab will show an error that will prevent the app from building on a device, as shown in the following screenshot. Fix it now to be able to run the app:</p>
</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1222 image-border" src="assets/efca0b52-6969-408c-9094-de5aa0229329.png" style="width:85.75em;height:39.50em;"/></p>
<div style="color: black" class="packt_figref CDPAlignCenter CDPAlign">The signing tab of the project shows an error when a team hasn't been selected</div>
<ol start="5">
<li>We already have an AR app ready to be executed. To test it, connect your device and select it from the top-left corner of the window, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1223 image-border" src="assets/d73d79c6-36d2-407c-84c3-6856757d4e43.png" style="width:22.50em;height:2.25em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting the device to run the app</div>
<ol start="6">
<li>Run the app by clicking on the play button in the top-left corner of the window (see the preceding screenshot). The first time you launch it, it will ask for the camera's permission, and as soon as the camera feed appears, it will anchor a spaceship to the middle of your environment:</li>
</ol>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="aligncenter size-full wp-image-1224 image-border" src="assets/7eb32643-e5e9-4b69-ad42-90d1439d9971.png" style="width:36.42em;height:47.83em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>The ship appears anchored to the real environment</span></div>
<ol start="7">
<li class="CDPAlignCenter CDPAlign">
<p>Since ARKit will be tracking your environment, try to move around the ship and get close to it or look at it from different angles<span>, as shown in the following screenshot</span>:</p>
</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1225 image-border" src="assets/d6eb9708-0bbc-4649-8f20-9944e543b52e.png" style="width:36.42em;height:47.83em;"/></p>
<p>Now, let's take a look at the main parts that form this project, that is, <kbd>Main.storyboard</kbd>, where the UI elements are, and <kbd>ViewController.swift</kbd>, where the logic of the app resides.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Main.storyboard</h1>
                </header>
            
            <article>
                
<p>Open the <kbd>Main.storyboard</kbd> file by clicking on it. This file contains the UI elements. At the moment, it only contains an <span class="packt_screen">ARSCNView</span>, which occupies the whole screen.</p>
<p>If you right-click on the scene view, you will see the <span class="packt_screen">Referencing Outlets</span> that are linked to the <span class="packt_screen">View Controller</span> with the <span class="packt_screen"><span class="packt_screen">sce</span><span class="packt_screen">neView</span></span> variable, as shown in the following screenshot:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1226 image-border" src="assets/0c927ebb-8c95-48eb-b1be-73a14a456178.png" style="width:69.25em;height:41.33em;"/></div>
<div class="mce-root packt_figref CDPAlignCenter CDPAlign">The UI element ScenView and its Referencing Outlets</div>
<p>Let's take a closer look at the view controller element.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ViewController.swift</h1>
                </header>
            
            <article>
                
<p>Now, click on <kbd>ViewController.swift</kbd>, which is where the main logic of our application lies.</p>
<p>The first thing you will see is that the class requires the <kbd>ARKit</kbd> library for the AR, the <kbd>UIKit</kbd> library for the interface, and the <kbd>SceneKit</kbd> library. This last one is a high-level 3D framework that Apple offers so that you can create, import, and manipulate 3D objects and scenes. We will be using it later in this chapter to import our external 3D models into the scene.</p>
<p>Our only variable at the moment is as follows:</p>
<pre>@IBOUtlet var sceneView: ARSCNView!</pre>
<p>This is the <kbd>ARSCNView</kbd> element from <kbd>Main.storyboard</kbd>. It will allow us to control <span><span>the</span></span> AR scene.</p>
<p>Our <kbd>ViewController</kbd> class inherits from <kbd>UIViewController</kbd>. From here, we have three <kbd>override</kbd> methods. The first one is <kbd>viewDidLoad</kbd>:</p>
<pre>override func viewDidLoad() {<br/>    super.viewDidLoad()<br/> <br/>    sceneView.delegate = self<br/>    sceneView.showsStatistics = true<br/> <br/>    let scene = SCNScene(named: "art.scnassets/ship.scn")!<br/>    sceneView.scene = scene <br/>}</pre>
<p>This method is called when the view is loaded in memory and is used to initialize elements. In this case, we attach the <kbd>sceneView</kbd> element's delegate to the class itself, we activate the statistics that will appear at the bottom of the app, we create a scene with the ship model, and we assign that scene to the scene from the <kbd>scenView</kbd> element. This will make the battleship appear as soon as the app is launched.</p>
<p>The second method is <kbd>viewWillAppear</kbd>:</p>
<pre>override func viewWillAppear(_ animated: Bool) {<br/>    super.viewWillAppear(animated)<br/>        <br/>    let configuration = ARWorldTrackingConfiguration()<br/>    sceneView.session.run(configuration)<br/>}</pre>
<p>This method is called when the device is ready to show the interface to the user. The AR session is launched from here. The <kbd>ARSession</kbd><strong> </strong>is the main element that controls the AR experience; it reads the data from the sensors of your device, controls the device's camera, and analyzes the image coming from it to create a correspondence between the real world and a virtual space where you place the AR objects.</p>
<p>Before running the session, we need to make use of the <kbd>ARConfiguration</kbd> class, which will determine the ARKit features that have been enabled for the session. In this case, it will track the device's position and orientation in relation to surfaces, people, images, or objects using the device's back camera and then run the session with that configuration. We could use a different configuration if we wanted to track only people's faces or only images, for example. (See <a href="https://developer.apple.com/documentation/arkit/arconfiguration">https://developer.apple.com/documentation/arkit/arconfiguration</a> for more information.)</p>
<p>The third override method is <kbd>viewWillDisappear</kbd>:</p>
<pre>override func viewWillDisappear(_ animated: Bool) {<br/>    super.viewWillDisappear(animated)<br/>    sceneView.session.pause()<br/>}</pre>
<p>This method is called when the view is about to be removed. When that happens, the view's session is paused.</p>
<p>These are the methods we have implemented at the moment. Now, we are going to start changing and adding code to see how ARKit tracks planes and find out about the different state changes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modifying the basic app</h1>
                </header>
            
            <article>
                
<p>Starting from the current code in <kbd>ViewController.swift</kbd>, we are going to modify it so that it only detects horizontal surfaces (not verticals, faces, or known images) and<span> displays those horizontal surfaces as they are being detected </span>to show extra information about the <kbd>ARSession</kbd>, such as whenever <kbd>ARTracking</kbd> is ready or if a new horizontal surface has been detected.</p>
<p>Before we do this, though, we will delete the ship model as we no longer need it. Follow these steps to delete the ship model:</p>
<ol>
<li>Delete the <kbd>art.scnassets</kbd> folder from the project.</li>
<li>In the <kbd>viewDidLoad()</kbd> method of <kbd>ViewController.swift</kbd>, delete the reference to the ship from the scene, leaving the <kbd>scene</kbd> line like so:</li>
</ol>
<pre style="padding-left: 60px">let scene = SCNScene()</pre>
<p>We are also going to enable an AR debug option that will let us see the feature points of our environment. As we have seen already in this book, feature points are unique points of an image that make it possible for that image to be identified and tracked. The more features we have, the more stable the tracking will be. We will activate this option for now so that we can see how well our environment is detected, and deactivate it for our final app. For that, in the <kbd>viewDidLoad()</kbd> method, after the <kbd>sceneView.showStatistics = true</kbd> line, add the following code:</p>
<pre>sceneView.debugOptions = ARSCNDebugOptions.showFeaturePoints</pre>
<p>And with this, we can proceed to plane detection.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Detecting and showing horizontal planes</h1>
                </header>
            
            <article>
                
<p>As we mentioned previously, <kbd>ARSession</kbd> is the main element of the AR app. Another essential element of ARKit is <kbd>ARAnchor</kbd>, which is the representation of an interesting point in the real world, along with its position and orientation. We can use anchors to place and track virtual elements in the real world that are relative to the camera. When we add those anchors to the session, ARKit optimizes the world-tracking accuracy around that anchor, meaning that we can walk around the virtual objects as if they were placed in the real world.</p>
<p>Apart from adding anchors manually, some ARKit features can automatically add their own special anchors to a session. For example, when we activate the plane detection feature in the <kbd>ARConfiguration</kbd> class, the <kbd>ARPlaneAnchor</kbd> elements are created automatically whenever a new plane is detected.</p>
<p>Let's make these plane anchors visible so that we can see how ARKit works. Let's get to it:</p>
<ol>
<li>In the <kbd>viewWillAppear</kbd> method, <em>after</em><strong> </strong>the <kbd>configuration</kbd> definition, add the following code:</li>
</ol>
<pre style="padding-left: 60px">let configuration = ARWorldTrackingConfiguration()<br/>configuration.planeDetection = .horizontal</pre>
<p style="padding-left: 60px">Now, ARKit will only look for horizontal surfaces to track.</p>
<ol start="2">
<li>Uncomment the <kbd>renderer</kbd> method that's already present in the class:</li>
</ol>
<pre style="padding-left: 60px">func renderer(_ renderer: SCNSceneRenderer, nodeFor anchor: ARAnchor) -&gt; SCNNode? {<br/>    let node = SCNNode()<br/>     <br/>    return node<br/>} </pre>
<p style="padding-left: 60px">This method is called when a new <kbd>ARAnchor</kbd> is added to the scene. It helps us create a <kbd>SceneKit</kbd> node called <kbd>SCNNode</kbd> for that anchor.</p>
<ol start="3">
<li>Now, to paint the planes, <em>between</em> the creation of the node and the <kbd>return</kbd> statement, add the following:</li>
</ol>
<pre style="padding-left: 60px">guard let planeAnchor = anchor as? ARPlaneAnchor else {return nil}<br/><br/>let plane = SCNPlane(width: CGFloat(planeAnchor.extent.x), height: CGFloat(planeAnchor.extent.z))<br/>plane.firstMaterial?.diffuse.contents = UIColor.orange<br/>plane.firstMaterial?.transparency = 0.4<br/><br/>let planeNode = SCNNode(geometry: plane)<br/>planeNode.position = SCNVector3(x: planeAnchor.center.x, y: planeAnchor.center.y, z: planeAnchor.center.z)<br/>planeNode.eulerAngles.x = -Float.pi/2<br/><br/>node.addChildNode(planeNode)</pre>
<p style="padding-left: 60px">Here, if our anchor is an <kbd>ARPlaneAnchor</kbd>, we create a new semi-transparent orange plane that's the same size as the <kbd>planeAnchor</kbd>. Then, we create a <kbd>SCNNode</kbd> with that plane and add it to the empty node that was already created. Finally, we return this parent node so that it's related to our current anchor and displayed in the scene.</p>
<div class="packt_tip">Instead of this method, we could also implement another method from <kbd>ARSCNViewDelegate</kbd>: <kbd>func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor){}</kbd>. Here, the empty node has already been created, so we would only have to add the same preceding code extract.</div>
<ol start="4">
<li>If you test the app now, you will see how it paints orange planes whenever it detects a flat surface. However, you will see that once a plane is painted, even if ARKit detects more points around it, the plane's size is not updated, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1227 image-border" src="assets/8d5c686b-1ad5-4ce4-99a0-3616ee5af2af.png" style="width:33.33em;height:44.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">ARKit detecting a flat surface and placing a plane</div>
<p style="padding-left: 60px">Let's add some more code to make the displayed plane change its size and position when more points are detected.</p>
<ol start="5">
<li>At the beginning of the class, after <kbd>sceneView</kbd>, create an array to save all the planes in the scene and their respective anchors:</li>
</ol>
<pre style="padding-left: 60px">var planes = [ARPlaneAnchor: SCNPlane]()</pre>
<ol start="6">
<li>Now, in the <kbd>renderer</kbd> method, <em>after</em> creating the plane, and <em>before</em> the <kbd>return</kbd> statement, add the following code:</li>
</ol>
<pre style="padding-left: 60px">planes[planeAnchor] = plane</pre>
<p style="padding-left: 60px">This will save our plane node and anchor for later.</p>
<ol start="7">
<li>Let's add a new method:</li>
</ol>
<pre style="padding-left: 60px">func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor)<br/>{<br/>    guard let planeAnchor = anchor as? ARPlaneAnchor else {return}<br/><br/>    if let plane = planes[planeAnchor]<br/>    {<br/>        plane.width = CGFloat(planeAnchor.extent.x)<br/>        plane.height = CGFloat(planeAnchor.extent.z)<br/><br/>        node.childNodes.first?.position = SCNVector3(planeAnchor.center.x, planeAnchor.center.y, planeAnchor.center.z)<br/>    }        <br/>}</pre>
<p style="padding-left: 60px">This method is called when the anchor is updated. First, we check that the anchor is an <kbd>ARPlaneAnchor</kbd>. Then, we take the plane that corresponds to that anchor from the array and change its <kbd>width</kbd> and <kbd>height</kbd>. Finally, we update the <kbd>position</kbd> of the <kbd>child</kbd> node (remember that we added our plane node to an empty node; we want to update our plane's position, not the empty node's position).</p>
<ol start="8">
<li>
<p>Run the app to see how the more you move the device around, the bigger the planes will become:</p>
</li>
</ol>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="aligncenter size-full wp-image-1228 image-border" src="assets/2d086147-7369-4893-ba00-c8e395bca86a.png" style="width:34.58em;height:45.25em;"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref"><span>The detected plane becomes bigger as ARKit detects more of its points</span></div>
<p>In this section, we have learned how plane anchors are created and how to visualize them.</p>
<p>When testing the app, you may have noticed that the device needs a little time before it starts showing the plane anchors. That's the time when ARKit is initializing. In the next section, we are going to create a track for the ARKit state changes so that the user knows when the app is ready.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding ARSessionDelegate to track state changes</h1>
                </header>
            
            <article>
                
<p>In our class, we already have three methods that can be used to notify session changes to the user when the session fails or is interrupted. We are also going to add two new methods, that is, for when an anchor is added to the session and when the camera changes its tracking state. But before we do any of this, we need to create a label in our UI to display all the messages.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding a label UI element</h1>
                </header>
            
            <article>
                
<p>Let's add a new UI element, that is, a label, to show notifications to users. For that, follow these steps:</p>
<ol>
<li>Open <kbd>Main.storyboard</kbd> and open the library button located in the top-right corner of the screen (the first button of its set, with a square inside a circle):</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1229 image-border" src="assets/5b903266-34ee-43ef-9e3c-21c4a7e1814d.png" style="width:14.83em;height:2.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Library button</div>
<ol start="2">
<li>Find and drag a <span class="packt_screen">Label</span> onto the view:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1230 image-border" src="assets/46f84b3d-49b1-4d12-b294-ae4df4aa3722.png" style="width:28.83em;height:23.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting the Label from the library</div>
<ol start="3">
<li>With the label selected, use <em>Ctrl</em> + mouse drag to create constraints for the label regarding the view, or in the toolbar <em>below</em> the phone view, click on the <span class="packt_screen">Add New Constraints</span> button. Constraints help us fix the elements on the screen so that they appear properly on any device screen and in any orientation.</li>
<li><span>Then, modify the values of t</span>he left, right, and bottom constraints <span>to</span> <kbd>20</kbd>, <kbd>20</kbd>, and <kbd>0</kbd>, <span>respectively (the icon of the constraint will turn a bright red). Check the <span class="packt_screen">Height</span> constraint box and set it to</span> <kbd>60</kbd><span>, as follows:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1231 image-border" src="assets/4be967d7-1d1f-4059-9e1d-3fa993424d9e.png" style="width:23.00em;height:30.33em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Adding constraints to the label</div>
<ol start="5">
<li>The new constraints will appear on the right-hand side window, under the Show the Size <span class="packt_screen">Inspector</span> tab, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1232 image-border" src="assets/57657991-3f36-40c0-b2bd-2b133ce38ed3.png" style="width:19.25em;height:48.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The four new constraints added at the bottom of the Show the Size tab</div>
<ol start="6">
<li>In the Show the Attributes <span class="packt_screen">Inspector</span> tab, <em>delete</em> the default <span class="packt_screen">Text</span>, set the label <span class="packt_screen">Color</span> to <em>green</em>, check the <span class="packt_screen">Dynamic Type</span> checkbox, and set the <span class="packt_screen">Alignment</span> of the text to centered, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1233 image-border" src="assets/518357cc-5622-4835-a711-2ea12e3cc48b.png" style="width:20.00em;height:36.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Changing the properties of the label</div>
<ol start="7">
<li>To connect the label to our <kbd>ViewController.swift</kbd> script and use it in our methods, click on the Show the Assistant Editor button in the top-right corner (two circles intersecting) to open the script:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1234 image-border" src="assets/a62ddb0d-00bf-4fae-b2c1-d308fb55a449.png" style="width:14.67em;height:2.58em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting the Assistant Editor</div>
<ol start="8">
<li>Press <em>Ctrl</em> + drag the label (you will see a blue line as you drag the mouse) from the hierarchical view to the code, below the <kbd>sceneView</kbd> variable. Release the mouse. Then, on the pop-up window shown in the following screenshot, enter the <span class="packt_screen">Name</span> of the variable, which will be <kbd>infoLabel</kbd> in this case, and click <span class="packt_screen">Connect</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1235 image-border" src="assets/52710e29-4e60-4d9b-bacf-6ea9a3091ce3.png" style="width:69.58em;height:41.58em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The label from the UI will be attached to the infoLabel variable</div>
<ol start="9">
<li>Open the <kbd>ViewController.swift</kbd> file to check that the new variable has been added correctly, as follows:</li>
</ol>
<pre style="padding-left: 60px">@IBOutlet weak var infoLabel: UILabel!</pre>
<p>Now, we can start sending messages to the user through the interface.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Sending notifications to the user</h1>
                </header>
            
            <article>
                
<p>Now that we have our label to display messages to the user, let's use the <kbd>session</kbd> methods we already have in our <kbd>ViewController</kbd> class and create new ones to display useful information, as shown in the following steps:</p>
<ol>
<li>In the <kbd>ViewController.swift</kbd> file, within the <kbd>didFailWithError</kbd> session, add a new message:</li>
</ol>
<pre style="padding-left: 60px">func session(_ session: ARSession, didFailWithError error: Error) {<br/>    infoLabel.text = "Session failed : \(error.localizedDescription)."<br/>}</pre>
<p style="padding-left: 60px">This message will appear when there is an error in the <kbd>ARSession</kbd>.</p>
<ol start="2">
<li>In the <kbd>sessionWasInterrupted</kbd> method, add the following message:</li>
</ol>
<pre style="padding-left: 60px">func sessionWasInterrupted(_ session: ARSession) {<br/>    infoLabel.text = "Session was interrupted."<br/>}</pre>
<p style="padding-left: 60px">This will be executed when the session is interrupted; for example, when the app is minimized.</p>
<ol start="3">
<li>In the <kbd>sessioInterruptionEnded</kbd> method, add the following message and code:</li>
</ol>
<pre style="padding-left: 60px">func sessionInterruptionEnded(_ session: ARSession) {<br/>    infoLabel.text = "Session interruption ended."<br/>    let configuration = ARWorldTrackingConfiguration()<br/>    configuration.planeDetection = .horizontal<br/>    sceneView.session.run(configuration, options: [.resetTracking, .removeExistingAnchors])<br/>}</pre>
<p style="padding-left: 60px">When the session interruption finishes, we have to reset the tracking. For that, we will create the configuration parameter again and run the session by removing the previously existing anchors.</p>
<ol start="4">
<li>Now, let's create a new method that will detect whenever the tracking state has changed:</li>
</ol>
<pre style="padding-left: 60px">func session(_ session: ARSession, cameraDidChangeTrackingState camera: ARCamera) {<br/>    let message: String<br/>        <br/>    switch camera.trackingState {<br/>    case .normal where session.currentFrame!.anchors.isEmpty:<br/>        message = "Move the device around to detect horizontal surfaces."   <br/>    case .notAvailable:<br/>        message = "Tracking unavailable."<br/>    case .limited(.excessiveMotion):<br/>         message = "Tracking limited - Move the device more slowly."<br/>    case .limited(.insufficientFeatures):<br/>        message = "Tracking limited - Point the device at an area with visible surface detail, or improve lighting conditions."<br/>    case .limited(.initializing):<br/>        message = "Initializing AR session."<br/>    default:<br/>        message = ""  <br/>    } <br/>    infoLabel.text = message<br/>}</pre>
<p>Your Xcode window will look like the following screenshot:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1651 image-border" src="assets/dbf9bedd-e177-4a9d-8f5d-35bf8f635b38.png" style="width:56.92em;height:26.17em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The new method in ViewController</div>
<p>This method checks the tracking state and displays messages when the session is initializing or there are problems. We also display a message when the tracking state is normal, but we haven't found a plane anchor yet, so the user keeps looking around.</p>
<ol start="5">
<li>Now, we have to notify the user when an anchor has been added so that they don't have to look around anymore. For that, we are going to use <kbd>ARSessionDelegateProtocol</kbd>. The first thing we will do is add the delegate to the class, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px">class ViewController: UIViewController, ARSCNViewDelegate, ARSessionDelegate {</pre>
<p style="padding-left: 60px">The <span><span>class declaration will look</span></span> as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1652 image-border" src="assets/61312d51-3339-4462-abef-7e4b3e1851e0.png" style="width:44.50em;height:4.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The ViewController class with the added delegate</div>
<ol start="6">
<li>In the <kbd>viewWillAppear</kbd> method, just after the <kbd>sceneView.session.run(configuration)</kbd> line, add the following code:</li>
</ol>
<pre style="padding-left: 60px">sceneView.session.delegate = self</pre>
<p style="padding-left: 60px">With this line, we assign the delegate to the class. The <kbd>viewWillAppear</kbd> method will now look as follows:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1653 image-border" src="assets/53c58d57-e002-4862-967c-c365228d0c79.png" style="width:33.00em;height:11.83em;"/><span> </span></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The viewWillAppear method</div>
<ol start="7">
<li>Now, create the new method to show the message when an anchor has been added:</li>
</ol>
<pre style="padding-left: 60px">func session(_ session: ARSession, didAdd anchors: [ARAnchor])<br/>{<br/>    infoLabel.text= "New anchor added."<br/>}</pre>
<ol start="8">
<li>Run the app to see how the label changes according to the state of the camera, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1236 image-border" src="assets/3e8b4532-5542-4e3a-a36f-db6ef3c36432.png" style="width:136.25em;height:14.17em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The label notifying the user that the AR session is initializing</div>
<p style="padding-left: 60px">After the AR has been initialized, the label changes to detecting the <span class="packt_screen">horizontal surfaces</span> message, as shown in the following screenshot:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1237 image-border" src="assets/a1e5f1fa-49d9-4a72-96d8-4daa0dabb0d5.png" style="width:136.25em;height:14.00em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The label asking the user to move the device to detect horizontal surfaces</div>
<div class="packt_infobox">The debugging messages of the <kbd>cameraDidChangeTrackingState</kbd> session method come from the <em>Tracking and Visualizing Planes</em> example, which is available at <a href="https://developer.apple.com/documentation/arkit/tracking_and_visualizing_planes">https://developer.apple.com/documentation/arkit/tracking_and_visualizing_planes</a>. This example project uses more methods to show planes and messages that we won't need for this project. You can download and test it if you want to learn about them.</div>
<p>Now that we have our app's base, let's create an AR portal where we will display a <em>door</em> to a virtual 3D painting. Once we physically go through that door, we will find ourselves immersed in that virtual painting.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an AR portal</h1>
                </header>
            
            <article>
                
<p>Currently, we have an app that detects horizontal planes and notifies us about the state of the tracking system. Now, we want to create an AR experience where users will tap on the screen to create a portal and, when going through it, see themselves inside a 3D representation of Van Gogh's <em>Bedroom in Arles</em> painting. The following diagram depicts the scene in SceneKit's coordinate system:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1238 image-border" src="assets/98445e9c-d3b8-40a1-8c31-31da4433b42c.png" style="width:30.58em;height:28.50em;"/> </div>
<div class="packt_figref CDPAlignCenter CDPAlign">The scene in the XYZ coordinates</div>
<p>From the user's perspective, we will have a portal with a hole in it, as shown in the previous diagram. The hole will let us see the model in the background, that is, the 3D painting. The portal will not be gray; it will be transparent so that we can see the camera feed instead of the whole 3D painting scene that hides behind it. In this section, we will learn how to make this possible.</p>
<p>For that, we need to add the 3D model, create the screen-tapping functionality, and create the actual portal, which only shows part of the painting from the outside.</p>
<div class="packt_tip">From this point on, you can specify whether you want the <span class="packt_screen">showFeaturePoints</span> option and the two <kbd>renderer</kbd> methods showing the planes. We will leave them until the end of the project because it's best if we understand how ARKit works first.</div>
<p>In the following subsections, we will do the following:</p>
<ul>
<li>Import a 3D model into our project and scene</li>
<li>Add the user interaction so that when a user touches the screen, the 3D model will appear over the touched anchor plane</li>
</ul>
<ul>
<li>Add the walls to the portal to make the model invisible from the outside, except for the door</li>
<li>Improve the app by adding textures to the walls and a compass image to help users find out where the portal will appear</li>
</ul>
<p>Now, let's start by adding the 3D model we want to show.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Importing the 3D model</h1>
                </header>
            
            <article>
                
<p>SceneKit's preferred 3D model type is Collada (<kbd>.dae</kbd> files). However, it can also read OBJ (<kbd>.obj</kbd>) files, and in this case, the downloaded model is in the latter format. We have slightly modified it using a 3D modeling program and put the pivot point on the floor, in the nearest edge away from us. This way, when we place it in the real world, we will see the model in front of us, instead of surrounding us. If you try this with another model or you don't know how to modify a pivot point, you can adjust the transform's position directly in the code (we will explain how later).</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding the model to the project</h1>
                </header>
            
            <article>
                
<p>To import the model and show it in our scene, download it from the resources of this project and follow these steps:</p>
<ol>
<li>Right-click on the project and select <span class="packt_screen">New Group</span>, as shown in the following screenshot. Call it <kbd>Models</kbd>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1874 image-border" src="assets/ab1a3672-02ee-48b6-91b4-697bf26913f8.png" style="width:19.42em;height:18.58em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Creating a New Group to contain our model</div>
<ol start="2">
<li>Right-click on the <kbd>Models</kbd> folder and select <span class="packt_screen">Add Files to "ARPortal"…</span>, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1830 image-border" src="assets/028756b0-d07d-4140-aebb-9c2529a1a9d2.png" style="width:22.08em;height:13.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Adding files to our folder</div>
<ol start="3">
<li>Navigate to the <kbd>vangogh_room</kbd> folder, which contains the model, material, and textures. Select it, make sure that it's added to our app in <span class="packt_screen">Add to targets</span>, and click <span class="packt_screen">Add</span>, as shown in the <span>following </span>screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1241 image-border" src="assets/7a74e69c-9b32-4193-a3c9-fcd1213c86b0.png" style="width:36.25em;height:22.67em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting the folder and adding it to the target app</div>
<ol start="4">
<li>If you unfold the <kbd>vangogh_room</kbd> folder, you will see all the files inside it. Click on the <kbd>vangogh_room.obj</kbd> file to visualize the 3D model on the screen. When we create the portal, we will enter the model from the open wall, as shown in the <span>following screenshot:</span></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1242 image-border" src="assets/f12fe0e6-64eb-40a7-8a49-9595e325f9f8.png" style="width:54.25em;height:26.92em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The .obj file displayed in 3D</div>
<p>Now, we can use our model in our code.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding the model to our scene</h1>
                </header>
            
            <article>
                
<p><span>Now that we have imported the model into our project, let's add it to our scene using code, </span>as follows:</p>
<ol>
<li>Create a new file by right-clicking on the <kbd>ARPortal</kbd> folder and selecting <span class="packt_screen">New File…</span>, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1831 image-border" src="assets/591f9573-6060-49de-8f3a-de014427a839.png" style="width:20.25em;height:16.67em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Creating a new file</div>
<ol start="2">
<li>Select <span class="packt_screen">Swift</span> <span class="packt_screen">File</span> and click <span class="packt_screen">Next</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1244 image-border" src="assets/0205cf66-b19d-42df-b7a2-2931706b9f16.png" style="width:42.50em;height:30.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting Swift File</div>
<ol start="3">
<li>
<p>Call it <kbd>Portal.swift</kbd> and click <span class="packt_screen">Create</span>. This will be the class where we will create our full portal, including the 3D model we imported previously.</p>
</li>
<li>
<p>Delete the code and add the <kbd>ARKit</kbd> library:</p>
</li>
</ol>
<pre style="padding-left: 60px">import ARKit</pre>
<ol start="5">
<li>Create a <kbd>class</kbd>:</li>
</ol>
<pre style="padding-left: 60px">class Portal: SCNNode {<br/>}</pre>
<p style="padding-left: 60px">Our portal will be of the <kbd>SCNNode</kbd> type.</p>
<ol start="6">
<li>Now, inside the class, we'll create a new method to load the 3D model. Add the following code:</li>
</ol>
<pre style="padding-left: 60px">func add3DModel() {<br/>    let modelScene = SCNScene(named: "vangogh_room.obj")!<br/>    let modelNode: SCNNode = modelScene.rootNode.childNodes[0]<br/>    self.addChildNode(modelNode)<br/>}</pre>
<p style="padding-left: 60px">Here, we load the scene from the <kbd>.obj</kbd> file and take the node out of it. Then, we attach the node as a child of our portal.</p>
<div class="packt_tip">If you use another model and it doesn't appear where you want it to be (displaced in one or more axes), you can adjust its position inside this method by adding the following before the <kbd>self.addChildNode(modelNode)</kbd> line: <kbd>modelNode.position = SCNVector3(x: YourValue, y: YourValue, z: YourValue)</kbd>. You can check how coordinates work in SceneKit by looking at the diagram at the beginning of this section.</div>
<ol start="7">
<li>Now, <kbd>override</kbd> the <kbd>init</kbd> method, as follows:</li>
</ol>
<pre style="padding-left: 60px">override init() {<br/>    super.init()<br/>    add3DModel()<br/>}<br/><br/>required init?(coder aDecoder: NSCoder) {<br/>    fatalError("init(coder:) has not been implemented")<br/>}</pre>
<p style="padding-left: 60px">In the first method, we initialize our portal by adding the 3D model. The second method is required for a subclass of <kbd>SCNNode</kbd>.</p>
<p>Now that we have added our 3D model, we want to show it in our scene.</p>
<p>We could just open <kbd>ViewController.swift</kbd> and add the following at the end of the <kbd>viewDidLoad()</kbd> method, as follows:</p>
<pre>portal = Portal()<br/>self.sceneView.scene.rootNode.addChildNode(portal!)</pre>
<p>The <kbd>viewDidLoad</kbd> method will now look as follows:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1654 image-border" src="assets/739265e0-4a5a-4d2e-9948-3e7b4c56148f.png" style="width:40.58em;height:24.67em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The viewDidLoad method with the Portal added</div>
<p>In this case, the 3D model will appear like the ship we saw at the beginning of this chapter, from the start of the session and in the middle of the screen (we would have to translate it downward for a better view). However, we want to add a twist and attach it to one of the plane anchors when the user taps on the screen, so delete those two lines. We'll learn how to do this in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Including user interaction</h1>
                </header>
            
            <article>
                
<p>Let's add some user interaction to the app. Instead of just making the virtual content appear in the scene from the beginning, we will make it appear when the user taps the screen. For that, follow these steps:</p>
<ol>
<li>In <kbd>Main.storyboard</kbd>, click on the library button (the square inside a circle button) and look for <span class="packt_screen">Tap Gesture Recognizer</span>. Drag it onto the view:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1245 image-border" src="assets/76088aa8-5eb7-442e-8f6d-e03af4963264.png" style="width:37.50em;height:9.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting Tap Gesture Recognizer from the library</div>
<ol start="2">
<li>It will appear on the hierarchy, as shown in the <span>following </span>screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1246 image-border" src="assets/d02d7268-ce13-4502-9ac6-1c0cafca5611.png" style="width:16.17em;height:19.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Tap Gesture Recognizer in the View Controller Scene hierarchy</div>
<ol start="3">
<li>Show the Assistant Editor (two circles intersecting button) and open <kbd>ViewController.swift</kbd> on the right-hand side. <em>Ctrl</em> + drag the <span class="packt_screen">Tap Gesture Recognizer</span> over to the code, as shown in the <span>following </span>screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1247 image-border" src="assets/e639ee1d-23e1-4a6f-8c94-724b5638c928.png" style="width:68.58em;height:41.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Dragging the Tap Gesture Recognizer to the code to create the connection</div>
<ol start="4">
<li>Fill in the box that appears with the following parameters:</li>
</ol>
<ul>
<li style="padding-left: 30px"><span class="packt_screen">Connection: </span><kbd>Action</kbd></li>
<li style="padding-left: 30px"><span class="packt_screen">Object: </span><kbd>View Controller</kbd></li>
<li style="padding-left: 30px"><span class="packt_screen">Name: </span><kbd>didTapOnScreen</kbd></li>
<li style="padding-left: 30px"><span class="packt_screen">Type: </span><kbd>UITapGestureRecognizer</kbd></li>
</ul>
<ol start="5">
<li>Open the <kbd>ViewController.swift</kbd> file to ensure the method has been created:</li>
</ol>
<pre style="padding-left: 60px">@IBAction func didTapOnScreen(_ sender: UITapGestureRecognizer){<br/>}</pre>
<ol start="6">
<li>Now, include the following variable at the beginning of the class, after the <kbd>planes</kbd> variable:</li>
</ol>
<pre style="padding-left: 60px">var portal: SCNNode? = nil</pre>
<p style="padding-left: 60px">We will use this variable to make sure we only have one portal in the view.</p>
<ol start="7">
<li>
<p>Modify the text of the session's <kbd>didAdd</kbd> method to instruct the user to place the portal when an anchor is detected, but no portal has been added yet. For that, modify <kbd>infoLabel.text</kbd>, as follows:</p>
</li>
</ol>
<pre style="padding-left: 60px"><span>func session(_ session: ARSession, didAdd anchors: [ARAnchor]) {<br/></span>   if portal == nil<br/>   {<br/>       infoLabel.text = "Tap on the floor to create the portal."<br/>   }<br/>}</pre>
<ol start="8">
<li>Now, go to the <kbd>didTapOnScreen</kbd><span> </span>method and add the following code:</li>
</ol>
<pre style="padding-left: 60px">let location = sender.location(in: sceneView)<br/>        <br/>let hitResults = sceneView.hitTest(location, types: ARHitTestResult.ResultType.existingPlaneUsingExtent)<br/>        <br/>guard let result = hitResults.first else {return}<br/>        <br/>if portal != nil {<br/>    portal?.removeFromParentNode()<br/>}<br/>        <br/>portal = Portal()<br/>portal?.position = SCNVector3(x: result.worldTransform.columns.3.x, y: result.worldTransform.columns.3.y, z: result.worldTransform.columns.3.z)<br/>        <br/>self.sceneView.scene.rootNode.addChildNode(portal!)<br/>        <br/>infoLabel.text = ""</pre>
<p style="padding-left: 60px">Here, we are taking out the location of the tap and checking whether the tap is hitting an existing plane. (You can check the options for the <kbd>ARHitTestResult</kbd> here:<span> </span><a href="https://developer.apple.com/documentation/arkit/arhittestresult">https://developer.apple.com/documentation/arkit/arhittestresult</a>.) We take the first plane of the hit results. If the portal already exists, we delete it to ensure we only have one portal in view. If the user taps in different places on the screen, the portal will appear to move from one place to the other. Then, we will apply the position from the plane to our portal object. Finally, we will add the portal to our scene and we'll clear the information label as we no longer need to tell our users to tap on the screen. The resulting method will look like this:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1655 image-border" src="assets/6eea8e1c-ac1f-455d-9546-7e7a21faac6c.png" style="width:49.33em;height:30.08em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The didTapOnScreen method</div>
<ol start="9">
<li>In the <kbd>sessionWasInterrupted</kbd> method, after <kbd>infoLabel.text</kbd>, we are going to delete the<span> portal so that it doesn't appear when the session is recovered. For that, add</span> <span>t</span>he following code:</li>
</ol>
<pre style="padding-left: 60px">func sessionWasInterrupted(_ session: ARSession) {<br/>    infoLabel.text = "Session was interrupted."<br/>    portal?.removeFromParentNode()<br/>    portal = nil<br/>}</pre>
<p style="padding-left: 60px">The <kbd>sessionWasInterrupted</kbd> method should look as follows:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1656 image-border" src="assets/f4a93b66-7582-4a9f-84d7-88fe4aef6029.png" style="width:35.33em;height:6.92em;"/><span>  </span></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The sessionWasInterrupted method</div>
<ol start="10">
<li>Run the app and tap the screen to place the 3D model. It will appear over the orange planes, as shown in the <span>following screenshot</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1248 image-border" src="assets/aeb20833-bbf8-4034-a4b6-11c71866e392.png" style="width:36.33em;height:47.50em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The 3D painting appearing in AR when tapping on the screen</div>
<p style="padding-left: 60px">If you enter the model and look back, you will see the real world from the open wall in the 3D model, as shown in the <span>following screenshot</span>:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1249 image-border" src="assets/e4bd540a-2240-4d92-99cf-8b7a1d67a4cc.png" style="width:34.92em;height:46.50em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The opening to the real world from the 3D room</div>
<p>M<span>ove around the room and explore the 3D space from different angles. You will see how you are immersed in the virtual environment while the real world is still on the other side.</span></p>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Now, it's time to actually create a portal that hides most of the model until the <em>door</em> is crossed. For that, we are going to create transparent walls and play with the rendering order property.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Adding the walls of the portal</h1>
                </header>
            
            <article>
                
<p>The main trick of an AR portal is based on two things: the transparency and the rendering order. We are going to create a wall with an opening (we will call it the <em>doo</em>r) in the middle, through which we will see the 3D painting. Open the <kbd>Portal.swift</kbd> file and follow these steps:</p>
<ol start="1">
<li>Create a new method called <kbd>createWall</kbd> with the following code:</li>
</ol>
<pre style="padding-left: 60px">func createWall(width: CGFloat, height: CGFloat, length: CGFloat)-&gt;SCNNode {<br/>    let node = SCNNode()<br/>        <br/>    let wall = SCNBox(width: width, height: height, length: length, chamferRadius: 0)<br/>    wall.firstMaterial?.diffuse.contents = UIColor.white<br/>    let wallNode = SCNNode(geometry: wall)<br/>        <br/>    node.addChildNode(wallNode)<br/>        <br/>    return node<br/>}</pre>
<p style="padding-left: 60px">Here, we created a parent node. Then, we created a box with the given size and set its material to white. We created a node with the box geometry that we attached to the parent node and returned it. This will be our base to create the portal walls:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1657 image-border" src="assets/5f1c4372-d514-4496-bac5-2a5727620054.png" style="width:42.50em;height:15.17em;"/><span> </span></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The new createWall method</div>
<p class="mce-root"/>
<ol start="2">
<li>Let's create another method called <kbd>createPortal</kbd>:</li>
</ol>
<pre style="padding-left: 60px">func createPortal() {<br/>}</pre>
<ol start="3">
<li>Inside it, let's define the variables for the sizes of the walls. Add the following code:</li>
</ol>
<pre style="padding-left: 60px">let wallWidth: CGFloat = 2<br/>let doorWidth: CGFloat = 0.8<br/>let topWidth = 2 * wallWidth + doorWidth<br/>let height: CGFloat = 2<br/>let length: CGFloat = 0.05</pre>
<p style="padding-left: 60px">We will have four walls, that is, on the left, right, top, and bottom of our portal door. The first three have to be big enough to hide the model from being displayed behind the portal. Their length will be the only thing that's displayed (thereby simulating a door to another dimension). The bottom wall will close that opening.</p>
<ol start="4">
<li>Now, create the main node and the four walls using the previous method <kbd>createWall</kbd>:</li>
</ol>
<pre style="padding-left: 60px">let portal = SCNNode()<br/>        <br/>let leftWall = createWall(width: wallWidth, height: height, length: length)<br/>leftWall.position = SCNVector3(x: Float(-(wallWidth + doorWidth)/2), y: Float(height/2), z: 0)<br/>        <br/>let rightWall = createWall(width: wallWidth, height: height, length: length)<br/>rightWall.position = SCNVector3(x: Float((wallWidth + doorWidth)/2), y: Float(height/2), z: 0)<br/>        <br/>let topWall = createWall(width: topWidth, height: height, length: length)<br/>topWall.position = SCNVector3(x: 0, y: Float(height*3/2), z: 0)<br/>        <br/>let bottomWall = createWall(width: topWidth, height: length, length: length)<br/>bottomWall.position = SCNVector3(x: 0, y: Float(-length/2), z: 0)<br/>          </pre>
<ol start="5">
<li>Add the walls to the portal node and then the portal itself to the class' node, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px">portal.addChildNode(leftWall)<br/>portal.addChildNode(rightWall)<br/>portal.addChildNode(topWall)<br/>portal.addChildNode(bottomWall)<br/>        <br/>self.addChildNode(portal)</pre>
<p style="padding-left: 60px">Our 3D portal is ready. Your code should appear as follows:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1658 image-border" src="assets/a2907acc-775e-4e63-b09d-bc9bbd7e0b66.png" style="width:67.33em;height:44.00em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The createPortal method</div>
<ol start="6">
<li>Now, let's call this method from <kbd>init</kbd>. After adding the 3D model, add the following code:</li>
</ol>
<pre style="padding-left: 60px">createPortal()</pre>
<ol start="7">
<li>If we run the app, when we tap on the floor, we will see a white wall, and through its gap, the 3D model. When we cross it, we will find ourselves in the 3D painting, as shown in the <span>following screenshot</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1250 image-border" src="assets/82486f5f-0d73-4962-923f-89d8e2f0eb07.png" style="width:185.00em;height:136.08em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The white wall covering most of the 3D painting</div>
<p style="padding-left: 60px">We can also see the walls so that we can go back to the real world:</p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1251 image-border" src="assets/37db3ab1-3198-4281-b976-ca8530bf32de.png" style="width:39.83em;height:52.33em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The view from inside the 3D painting</div>
<ol start="8">
<li>However, from the outside, we don't want to see a white wall; the portal should just be an opening in the air (the gap on the wall). To get that effect, let's add another box to the <kbd>createWall</kbd> method before the <kbd>return node</kbd> call. Add the following code:</li>
</ol>
<pre style="padding-left: 60px">let maskedWall = SCNBox(width: width, height: height, length: length, chamferRadius: 0)<br/>maskedWall.firstMaterial?.diffuse.contents = UIColor.white<br/>maskedWall.firstMaterial?.transparency = 0.000000001<br/>        <br/>let maskedWallNode = SCNNode(geometry: maskedWall)<br/>maskedWallNode.position = SCNVector3.init(0, 0, length)<br/>        <br/>node.addChildNode(maskedWallNode)</pre>
<p style="padding-left: 60px">This new wall, located before the other one, has a transparency of near 0 (if set to <kbd>0</kbd>, it is painted black) so that we can see the background. But this alone won't work.</p>
<ol start="9">
<li><span>Add a rendering order of</span> <kbd>100</kbd> <span>to </span><kbd>wallNode</kbd><span> and a rendering order of</span> <kbd>10</kbd> <span>to </span><kbd>maskedWallNode</kbd><span>, but leave the final code for the </span><kbd>createWall</kbd> <span>method like this:<br/></span></li>
</ol>
<pre style="padding-left: 60px">func createWall(width: CGFloat, height: CGFloat, length:<br/>CGFloat)-&gt;SCNNode {<br/>    ...<br/>    wallNode.renderingOrder = 100<br/>    node.addChildNode(wallNode)<br/>    ...<br/>    maskedWallNode.renderingOrder = 10<br/>    node.addChildNode(maskedWallNode)<br/>    return node<br/>}</pre>
<p style="padding-left: 60px"><span>The <kbd>createWall</kbd> method should now look as follows:</span></p>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1659 image-border" src="assets/d3d94cbd-181c-4ecd-a45e-0af78c299c9b.png" style="width:34.83em;height:20.00em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The createWall method with the final code</div>
<ol start="10">
<li>
<p>To finish this, add a rendering order of <kbd>200</kbd> to <kbd>modelNode</kbd>, which we created in the <kbd>add3DModel</kbd> method:</p>
</li>
</ol>
<pre style="padding-left: 60px">func add3DModel() {<br/>    ...<br/>    modelNode.renderingOrder = 200<br/>    self.addChildNode(modelNode)<br/>}</pre>
<p style="padding-left: 60px">The lower the rendering order, the faster the object will be rendered in the scene. This means that we will see <kbd>maskedWallNode</kbd> first, then <kbd>wallNode</kbd>, and finally <kbd>modelNode</kbd>. This way, whenever the masked wall is in view, the 3D elements behind its surface won't be rendered, leaving us with a transparent surface that will show the camera feed directly. The only part of the 3D painting that will be rendered will be the one that's not covered by the walls, that is, our portal door. Once we go through the portal, we will see the 3D painting in full, and when we look back, we will see our white wall.</p>
<ol start="11">
<li>Run the app to see how the portal appears by touching the screen. In the following screenshot, we can see how the masked wall shows us the camera feed hiding the rest of the elements. Here, we can only see the opening from the wall (since we have placed it behind the masked wall in the <em>z </em>axis) and the painting through the opening:</li>
</ol>
<div class="packt_infobox"><span>You can comment on the</span> <kbd>showFeaturePoints</kbd> <span>line and the</span> <kbd>renderer</kbd> <span>methods so that the feature points and anchor planes don't interfere with our 3D scene.</span></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1252 image-border" src="assets/aa05326a-34fc-4777-84f3-7e176824db18.png" style="width:32.58em;height:42.92em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"> The portal appearing in AR</div>
<p>Once inside the painting, if we look back, we will still see the white walls and the opening to go back to the real world, like before.</p>
<p>Now that the scene is ready, let's improve it by adding some texture to the walls.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Improving the portal</h1>
                </header>
            
            <article>
                
<p>We are going to improve our portal by adding some texture to the walls and a compass image that will show where the portal will appear. For that, we have to add the texture image and the compass image to our project. To do this, follow these steps:</p>
<ol>
<li>Right-click on the <span class="packt_screen">ARPortal</span> project and select <span class="packt_screen">New File...</span> In this case, select <span class="packt_screen">SceneKit Catalog</span> from the <span class="packt_screen">Resource</span> tab, as shown in the <span>following </span>screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1253 image-border" src="assets/b7a7b3e9-df78-487e-b35b-b45eb5c39717.png" style="width:59.75em;height:42.83em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">Selecting a new SceneKit Catalog</div>
<ol start="2">
<li>Name it <kbd>Media.scnassets</kbd> and create it, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1254 image-border" src="assets/d105107c-e110-4365-9352-ba39e3b7084c.png" style="width:15.92em;height:28.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The SceneKit catalog has been successfully created</div>
<ol start="3">
<li>Right-click on the newly created <kbd>Media.scnassets</kbd> and select <span class="packt_screen">Add Files to "Media.scnassets"...</span>. Now, select the <kbd>wood.jpg</kbd> image from the resources of this project and accept it. Our image is ready to be used. </li>
<li>Repeat <em>step 3</em> with the <kbd>compass.png</kbd> image.</li>
<li>Open <kbd>Portal.swift</kbd> and, in the <kbd>createWall</kbd> method, find the following line:</li>
</ol>
<pre style="padding-left: 60px">wall.firstMaterial?.diffuse.contents = UIColor.white </pre>
<p style="padding-left: 60px">Change it so that it reads like so:</p>
<pre style="padding-left: 60px">wall.firstMaterial?.diffuse.contents = UIImage(named: "Media.scnassets/wood.jpg")</pre>
<p style="padding-left: 60px">Here, we have added the wooden texture to our portal.</p>
<ol start="6">
<li>Now, we will paint the compass in <kbd>ViewController.swift</kbd>. For that, create the following variable after the portal variable:</li>
</ol>
<pre style="padding-left: 60px">var compass: SCNNode? = nil</pre>
<ol start="7">
<li>Now, uncomment the first <kbd>renderer</kbd> method, which is <span>where the anchor planes are added </span>(if you had it commented), and substitute the code inside it with the following:</li>
</ol>
<pre style="padding-left: 60px">if portal == nil &amp;&amp; compass == nil<br/>{<br/>    let node = SCNNode()<br/>    guard let planeAnchor = anchor as? ARPlaneAnchor else {return nil}<br/><br/>    let plane = SCNPlane(width: 0.8, height: 0.8)<br/>    plane.firstMaterial?.diffuse.contents = UIImage(named: "Media.scnassets/compass.png")<br/>    plane.firstMaterial?.transparency = 0.8<br/><br/>    let planeNode = SCNNode(geometry: plane)<br/>    planeNode.position = SCNVector3(x: planeAnchor.center.x, y: planeAnchor.center.y, z: planeAnchor.center.z)<br/>    planeNode.eulerAngles.x = -Float.pi/2<br/><br/>    node.addChildNode(planeNode)<br/><br/>    planes[planeAnchor] = plane<br/>    compass = node<br/><br/>    return node<br/>}<br/>return nil</pre>
<p style="padding-left: 60px">Here, when a plane anchor is detected, if there is no portal or compass in view (the first time a plane is detected), we will paint a semitransparent compass showing the user the place and orientation of the future portal. Then, we'll save the node as the anchor so that we can use it in <em>step 9</em>.</p>
<ol start="8">
<li>Comment the <kbd>didUpdate</kbd> renderer method if you haven't. We won't need it anymore.</li>
<li>In the <kbd>didTapOnScreen</kbd> method, remove the code between <kbd>portal = Portal()</kbd> and <kbd>self.sceneView.scene.rootNode.addChildNode(portal!)</kbd> and include the following code instead:</li>
</ol>
<pre style="padding-left: 60px">if (compass != nil)<br/>{<br/>    portal?.position = compass!.position<br/>    portal?.rotation = compass!.rotation<br/><br/>    compass?.removeFromParentNode()<br/>    compass = nil<br/>}<br/>else<br/>{<br/>    portal?.position = SCNVector3(x: result.worldTransform.columns.3.x, y: result.worldTransform.columns.3.y, z: result.worldTransform.columns.3.z)<br/>}</pre>
<p style="padding-left: 60px">Here, when the user taps on the screen for the first time (the compass is in view), we place the portal using the compass position and rotation, and we delete the compass as we no longer need it. From that moment on, if the user keeps tapping on the screen, the portal will move according to the taps and anchor plane position, like before.</p>
<ol start="10">
<li class="CDPAlignLeft CDPAlign">Run the app to see how the compass appears as soon as the device detects an anchor plane:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1663 image-border" src="assets/3595a725-8ac4-45a2-a992-a973fc70a4b1.png" style="width:27.83em;height:29.33em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The compass appearing on the screen, signaling the place and orientation of the future portal</div>
<ol start="11">
<li class="CDPAlignLeft CDPAlign">Now, tap the screen to see how the portal has a wooden frame. This can be seen in the <span>following screenshot</span>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1660 image-border" src="assets/f7a79db0-7ce4-411a-a4fe-5699e063428c.png" style="width:38.50em;height:49.75em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The portal now has a wooden frame</div>
<ol start="12">
<li class="CDPAlignLeft CDPAlign">From the inside, the texture of the walls has changed too, as shown in the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1255 image-border" src="assets/c2498a8b-33ee-46b7-82fe-1432036002f4.png" style="width:44.08em;height:32.42em;"/></p>
<div class="packt_figref CDPAlignCenter CDPAlign">The view from the inside of the 3D painting</div>
<p>And that's it. Now, you can place the portal wherever you want and play with different options such as changing the 3D painting or creating more than one portal at the same time. It's up to you!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we have learned what ARKit is and how it works. We have seen how the camera recognizes the feature points and how it creates anchor planes where you can place virtual elements. We have also learned to use SceneKit to insert 3D models into the scene and manipulate them to create an AR portal that leads the user to a 3D environment.</p>
<p>By now, you should have the basic skills to continue improving the current project and adapt it to your personal needs in the tourism sector or even other sectors. You could try to add buttons to the interface to change the 3D content of the portal, add particle effects when the portal first appears, or even try to use 360º videos instead of 3D models. AR is a transversal tool that can be used in several ways and applied to many different needs, so you could also create this portal for fields such as marketing or retail.</p>
<p>This is the last chapter of this book and it is dedicated to the use of AR in enterprises. By now, you should have a broader idea of how AR can be useful for many purposes, including tourism. Now, all you need to do is start playing around with the different frameworks and tools you have learned about and adapt them to your own needs and projects. Have fun!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p>If you want to explore ARKit, either to push the current project further or to try out new things, we recommend Apple's example projects, which can be found at <a href="https://developer.apple.com/documentation/arkit">https://developer.apple.com/documentation/arkit</a>. Some of these projects are as follows:</p>
<p class="mce-root"/>
<ul>
<li>The mentioned <a href="https://developer.apple.com/documentation/arkit/tracking_and_visualizing_planes">https://developer.apple.com/documentation/arkit/tracking_and_visualizing_planes</a> project, which you can use to track and visualize the plane anchors</li>
<li>The <a href="https://developer.apple.com/documentation/arkit/detecting_images_in_an_ar_experience">https://developer.apple.com/documentation/arkit/detecting_images_in_an_ar_experience</a> project, which you can use to detect 2D images (the portal could appear over a real painting instead of in the middle of the street, for example)</li>
<li>The <a href="https://developer.apple.com/documentation/arkit/tracking_and_visualizing_faces">https://developer.apple.com/documentation/arkit/tracking_and_visualizing_faces</a> project, which you can use to track faces and animate virtual avatars through real expressions</li>
</ul>
<p>With the launch of iOS 13, there are even more features and projects you can try out, such as occluding virtual objects when people move in front of them or interacting with the virtual content by using gestures.</p>


            </article>

            
        </section>
    </body></html>