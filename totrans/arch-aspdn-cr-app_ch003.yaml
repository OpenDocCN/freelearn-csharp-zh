- en: 2 Automated Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before you begin: Join our book community on Discord'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Give your feedback straight to the author himself and chat to other early readers
    on our Discord server (find the "architecting-aspnet-core-apps-3e" channel under
    EARLY ACCESS SUBSCRIPTION).
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/EarlyAccess](https://packt.link/EarlyAccess)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Qr code Description automatically generated](img/file2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This chapter focuses on automated testing and how helpful it can be for crafting
    better software. It also covers a few different types of tests and the foundation
    of **test-driven development** (**TDD**). We also outline how testable ASP.NET
    Core is and how much easier it is to test ASP.NET Core applications than old ASP.NET
    MVC applications. This chapter overviews automated testing, its principles, xUnit,
    ways to sample test values, and more. While other books cover this topic more
    in-depth, this chapter covers the foundational aspects of automated testing. We
    are using parts of this throughout the book, and this chapter ensures you have
    a strong enough base to understand the samples.In this chapter, we cover the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of automated testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing .NET applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important testing principles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to automated testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Testing is an integral part of the development process, and automated testing
    becomes crucial in the long run. You can always run your ASP.NET Core website,
    open a browser, and click everywhere to test your features. That’s a legitimate
    approach, but it is harder to test individual rules or more complex algorithms
    that way. Another downside is the lack of automation; when you first start with
    a small app containing a few pages, endpoints, or features, it may be fast to
    perform those tests manually. However, as your app grows, it becomes more tedious,
    takes longer, and increases the likelihood of making a mistake. Of course, you
    will always need real users to test your applications, but you want those tests
    to focus on the UX, the content, or some experimental features you are building
    instead of bug reports that automated tests could have caught early on.There are
    multiple types of tests and techniques in the testing space. Here is a list of
    three broad categories that represent how we can divide automated testing from
    a code correctness standpoint:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: End-to-end (E2E) tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, you want a mix of those tests, so you have fast unit tests testing
    your algorithms, slower tests that ensure the integrations between components
    are correct, and slow E2E tests that ensure the correctness of the system as a
    whole.The test pyramid is a good way of explaining a few concepts around automated
    testing. You want different granularity of tests and a different number of tests
    depending on their complexity and speed of execution. The following test pyramid
    shows the three types of tests stated above. However, we could add other types
    of tests in there as well. Moreover, that’s just an abstract guideline to give
    you an idea. The most important aspect is the **return on investment** (**ROI**)
    and execution speed. If you can write one integration test that covers a large
    surface and is fast enough, this might be worth doing instead of multiple unit
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.1: The test pyramid](img/file3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: The test pyramid'
  prefs: []
  type: TYPE_NORMAL
- en: I cannot stress this enough; the execution speed of your tests is essential
    to receive fast feedback and know immediately that you have broken something with
    your code changes. Layering different types of tests allows you to execute only
    the fastest subset often, the not-so-fast occasionally, and the very slow tests
    infrequently. If your test suite is fast-enough, you don’t even have to worry
    about it. However, if you have a lot of manual or E2E UI tests that take hours
    to run, that’s another story (that can cost a lot of money).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Finally, on top of running your tests using a test runner, like in Visual Studio,
    VS Code, or the CLI, a great way to ensure code quality and leverage your automated
    tests is to run them in a CI pipeline, validating code changes for issues.Tech-wise,
    back when .NET Core was in pre-release, I discovered that the .NET team was using
    xUnit to test their code and that it was the only testing framework available.
    xUnit has become my favorite testing framework since, and we use it throughout
    the book. Moreover, the ASP.NET Core team made our life easier by designing ASP.NET
    Core for testability; testing is easier than before.Why are we talking about tests
    in an architectural book? Because testability is a sign of a good design. It also
    allows us to use tests instead of words to prove some concepts. In many code samples,
    the test cases are the consumers, making the program lighter without building
    an entire user interface and focusing on the patterns we are exploring instead
    of getting our focus scattered over some boilerplate UI code.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure we do not deviate from the matter at hand, we use automated testing
    moderately in the book, but I strongly recommend that you continue to study it,
    as it will help improve your code and design
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that we have covered all that, let’s explore those three types of tests,
    starting with unit testing.
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unit tests focus on individual units, like testing the outcome of a method.
    Unit tests should be fast and not rely on any infrastructure, such as a database.
    Those are the kinds of tests you want the most because they run fast, and each
    one tests a precise code path. They should also help you design your application
    better because you use your code in the tests, so you become its first consumer,
    leading to you finding some design flaws and making your code better. If you don’t
    like using your code in your tests, that is a good indicator that nobody else
    will. Unit tests should focus on testing algorithms (the ins and outs) and domain
    logic, not the code itself; how you wrote the code should have no impact on the
    intent of the test. For example, you are testing that a `Purchase` method executes
    the logic required to purchase one or more items, not that you created the variable
    `X`, `Y`, or `Z` inside that method.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t discourage yourself if you find it challenging; writing a good test suite
    is not as easy as it sounds.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Integration testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Integration tests focus on the interaction between components, such as what
    happens when a component queries the database or what happens when two components
    interact with each other.Integration tests often require some infrastructure to
    interact with, which makes them slower to run. By following the classic testing
    model, you want integration tests, but you want fewer of them than unit tests.
    An integration test can be very close to an E2E test but without using a production-like
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: We will break the test pyramid rule later, so always be critical of rules and
    principles; sometimes, breaking or bending them can be better. For example, having
    one good integration test can be better than *N* unit tests; don’t discard that
    fact when writing your tests. See also Grey-box testing.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: End-to-end testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: End-to-end tests focus on application-wide behaviors, such as what happens when
    a user clicks on a specific button, navigates to a particular page, posts a form,
    or sends a `PUT` request to some web API endpoint. E2E tests are usually run on
    infrastructure to test your application and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Other types of tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are other types of automated tests. For example, we could do load testing,
    performance testing, regression testing, contract testing, penetration testing,
    functional testing, smoke testing, and more. You can automate tests for anything
    you want to validate, but some tests are more challenging to automate or more
    fragile than others, such as UI tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you can automate a test in a reasonable timeframe, think ROI: do it! In
    the long run, it should pay off.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One more thing; don’t blindly rely on metrics such as code coverage. Those metrics
    make for cute badges in your GitHub project’s `readme.md` file but can lead you
    off track, resulting in you writing useless tests. Don’t get me wrong, code coverage
    is a great metric when used correctly, but remember that one good test can be
    better than a lousy test suite covering 100% of your codebase. If you are using
    code coverage, ensure you and your team are not gaming the system.Writing good
    tests is not easy and comes with practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'One piece of advice: keep your test suite healthy by adding missing test cases
    and removing obsolete or useless tests. Think about use case coverage, not how
    many lines of code are covered by your tests.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Before moving forward to testing styles, let’s inspect a hypothetical system
    and explore a more efficient way to test it.
  prefs: []
  type: TYPE_NORMAL
- en: Picking the right test style
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Next is a dependency map of a hypothetical system. We use that diagram to pick
    the most meaningful type of test possible for each piece of the program. In real
    life, that diagram will most likely be in your head, but I drew it out in this
    case. Let’s inspect that diagram before I explain its content:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.2: Dependency map of a hypothetical system](img/file4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Dependency map of a hypothetical system'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the diagram, the **Actor** can be anything from a user to another system.
    **Presentation** is the piece of the system that the **Actor** interacts with
    and forwards the request to the system itself (this could be a user interface).
    **D1** is a component that has to decide what to do next based on the user input.
    **C1** to **C6** are other components of the system (could be classes, for example).
    **DB** is a database.D1 must choose between three code paths: interact with the
    components C1, C4, or C6\. This type of logic is usually a good subject for unit
    tests, ensuring the algorithm yields the correct result based on the input parameter.
    Why pick a unit test? We can quickly test multiple scenarios, edge cases, out-of-bound
    data cases, and more. We usually mock the dependencies away in this type of test
    and assert that the subject under test made the expected call on the desired component.Then,
    if we look at the other code paths, we could write one or more integration tests
    for component C1, testing the whole chain in one go (C1, C5, and C3) instead of
    writing multiple mock-heavy unit tests for each component. If there is any logic
    that we need to test in components C1, C5, or C3, we can always add a few unit
    tests; that’s what they are for.Finally, C4 and C6 are both using C2\. Depending
    on the code (that we don’t have here), we could write integration tests for C4
    and C6, testing C2 simultaneously. Another way would be to unit test C4 and C6,
    and then write integration tests between C2 and the DB. If C2 has no logic, the
    latter could be the best and the fastest, while the former will most likely yield
    results that give you more confidence in your test suite in a continuous delivery
    model.When it is an option, I recommend evaluating the possibility of writing
    fewer meaningful integration tests that assert the correctness of a use case over
    a suite of mock-heavy unit tests. Remember always to keep the execution speed
    in mind.That may seem to go “against” the test pyramid, but does it? If you spend
    less time (thus lower costs) testing more use cases (adding more value), that
    sounds like a win to me. Moreover, we must not forget that mocking dependencies
    tends to make you waste time fighting the framework or other libraries instead
    of testing something meaningful and can add up to a high maintenance cost over
    time.Now that we have explored the fundamentals of automated testing, it is time
    to explore testing approaches and TDD, which is a way to apply those testing concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are various approaches to testing, such as **behavior-driven development**
    (**BDD**), **acceptance test-driven development** (**ATDD**), and **test-driven
    development** (**TDD)**. The DevOps culture brings a mindset that embraces automated
    testing in line with its **continuous integration** (**CI**) and **continuous
    deployment** (**CD**) ideals. We can enable CD with a robust and healthy suite
    of tests that gives a high degree of confidence in our code, high enough to deploy
    the program when all tests pass without fear of introducing a bug.
  prefs: []
  type: TYPE_NORMAL
- en: TDD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'TDD is a software development method that states that you should write one
    or more tests before writing the actual code. In a nutshell, you invert your development
    flow by following the **Red-Green-Refactor** technique, which goes like this:'
  prefs: []
  type: TYPE_NORMAL
- en: You write a failing test (red).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You write just enough code to make your test pass (green).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You refactor that code to improve the design by ensuring all the tests pass.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We explore the meaning of **refactoring** next.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ATDD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ATDD is similar to TDD but focuses on acceptance (or functional) tests instead
    of software units and involves multiple parties like customers, developers, and
    testers.
  prefs: []
  type: TYPE_NORMAL
- en: BDD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'BDD is another complementary technique originating from TDD and ATDD. BDD focuses
    on formulating test cases around application behaviors using spoken language and
    involves multiple parties like customers, developers, and testers. Moreover, practitioners
    of BDD often leverage the *given–when–then* grammar to formalize their test cases.
    Because of that, BDD output is in a human-readable format allowing stakeholders
    to consult such artifacts.The given–when–then template defines the way to describe
    the behavior of a user story or acceptance test, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Given* one or more preconditions (context)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*When* something happens (behavior)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Then* one or more observable changes are expected (measurable side effects)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ATDD and BDD are great areas to dig deeper into and can help design better apps;
    defining precise user-centric specifications can help build only what is needed,
    prioritize better, and improve communication between parties. For the sake of
    simplicity, we stick to unit testing, integration testing, and a tad of TDD in
    the book. Nonetheless, let’s go back to the main track and define refactoring.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Refactoring is about (continually) improving the code without changing its behavior.An
    automated test suite should help you achieve that goal and should help you discover
    when you break something. No matter whether you do TDD or not, I do recommend
    refactoring as often as possible; this helps clean your codebase, and it should
    also help you get rid of some technical debt at the same time.Okay, but what is
    **technical debt**?
  prefs: []
  type: TYPE_NORMAL
- en: Technical debt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Technical debt** represents the corners you cut short while developing a
    feature or a system. That happens no matter how hard you try because life is life,
    and there are delays, deadlines, budgets, and people, including developers (yes,
    that’s you and me).The most crucial point is understanding that you cannot avoid
    technical debt altogether, so it’s better to embrace that fact and learn to live
    with it instead of fighting it. From that point forward, you can only try to limit
    the amount of technical debt you, or someone else, generate and ensure to always
    refactor some of it over time each sprint (or the unit of time that fits your
    projects/team/process).One way to limit the piling up of technical debt is to
    refactor the code often. So, factor the refactoring time into your time estimates.
    Another way is to improve collaboration between all the parties involved. Everyone
    must work toward the same goal if you want your projects to succeed.You will sometimes
    cut the usage of best practices short due to external forces like people or time
    constraints. The key is coming back at it as soon as possible to repay that technical
    debt, and automated tests are there to help you refactor that code and eliminate
    that debt elegantly. Depending on the size of your workplace, there will be more
    or less people between you and that decision.'
  prefs: []
  type: TYPE_NORMAL
- en: Some of these things might be out of your control, so you may have to live with
    more technical debt than you had hoped. However, even when things are out of your
    control, nothing stops you from becoming a pioneer and working toward improving
    the enterprise’s culture. Don’t be afraid to become an agent of change and lead
    the charge.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Nevertheless, don’t let the technical debt pile up too high, or you may not
    be able to pay it back, and at some point, that’s where a project begins to break
    and fail. Don’t be mistaken; a project in production can be a failure. Delivering
    a product does not guarantee success, and I’m talking about the quality of the
    code here, not the amount of generated revenue (I’ll leave that to other people
    to evaluate).Next, we look at different ways to write tests, requiring more or
    less knowledge of the inner working of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Testing techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here we look at different ways to approach our tests. Should we know the code?
    Should we test user inputs and compare them against the system results? How to
    identify a proper value sample? Let’s start with white-box testing.
  prefs: []
  type: TYPE_NORMAL
- en: White-box testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: White-box testing is a software testing technique that uses knowledge of the
    internal structure of the software to design tests. We can use white-box testing
    to find defects in the software’s logic, data structures, and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: This type of testing is also known as clear-box testing, open-box testing, transparent-box
    testing, glass-box testing, and code-based testing.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Another benefit of white-box testing is that it can help optimize the code.
    By reviewing the code to write tests, developers can identify and improve inefficient
    code structures, improving overall software performance. The developer can also
    improve the application design by finding architectural issues while testing the
    code.
  prefs: []
  type: TYPE_NORMAL
- en: White-box testing encompasses most unit and integration tests.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Next, we look at black-box testing, the opposite of white-box testing.
  prefs: []
  type: TYPE_NORMAL
- en: Black-box testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Black-box testing is a software testing method where a tester examines an application’s
    functionality without knowing the internal structure or implementation details.
    This form of testing focuses solely on the inputs and outputs of the system under
    test, treating the software as a “black box” that we can’t see into.The main goal
    of black-box testing is to evaluate the system’s behavior against expected results
    based on requirements or user stories. Developers writing the tests do not need
    to know the codebase or the technology stack used to build the software.We can
    use black-box testing to assess the correctness of several types of requirements,
    like:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Functional testing**: This type of testing is related to the software’s functional
    requirements, emphasizing what the system does, a.k.a. behavior verification.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Non-functional testing**: This type of testing is related to non-functional
    requirements such as performance, usability, reliability, and security, a.k.a.
    performance evaluation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Regression testing**: This type of testing ensures the new code does not
    break existing functionalities, a.k.a. change impact.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Next, let’s explore a hybrid between white-box and black-box testing.
  prefs: []
  type: TYPE_NORMAL
- en: Grey-box testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Grey-box testing is a blend between white-box and black-box testing. Testers
    need only partial knowledge of the application’s internal workings and use a combination
    of the software’s internal structure and external behavior to craft their tests.We
    implement grey-box testing use cases in *Chapter 16*, *Request-Endpoint-Response
    (REPR)*. Meanwhile, let’s compare the three techniques.
  prefs: []
  type: TYPE_NORMAL
- en: White-box vs. Black-box vs. Grey-box testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To start with a concise comparison, here’s a table that compares the three
    broad techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Feature** | **Whitebox Testing** | **Blackbox Testing** | **Gray-box Testing**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Definition | Testing based on the internal design of the software | Testing
    based on the behavior and functionality of the software | Testing that combines
    the internal design and behavior of the software |'
  prefs: []
  type: TYPE_TB
- en: '| Knowledge of code required | Yes | No | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Types of defects found | Logic, data structure, architecture, and performance
    issues | Functionality, usability, performance, and security issues | Most types
    of issues |'
  prefs: []
  type: TYPE_TB
- en: '| Coverage per test | Small; targeted on a unit | Large; targeted on a use
    case | Up to large; can vary in scope |'
  prefs: []
  type: TYPE_TB
- en: '| Testers | Usually performed by developers. | Testers can write the tests
    without specific technical knowledge of the application’s internal structure.
    | Developers can write the tests, while testers also can with some knowledge of
    the code. |'
  prefs: []
  type: TYPE_TB
- en: '| When to use each style? | Write unit tests to validate complex algorithms
    or code that yields multiple results based on many inputs. These tests are usually
    high-speed so you can have many of them. | Write if you have specific scenarios
    you want to test, like UI tests, or if testers and developers are two distinct
    roles in your organization. These usually run the slowest and require you to deploy
    the application to test it. You want as few as possible to improve the feedback
    time. | Write to avoid writing black-box or white-box tests. Layer the tests to
    cover as much as possible with as few tests as possible. Depending on the application’s
    architecture, this type of test can yield optimal results for many scenarios.
    |'
  prefs: []
  type: TYPE_TB
- en: Let’s conclude next and explore a few advantages and disadvantages of each technique.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: White-box testing includes unit and integration tests. Those tests run fast,
    and developers use them to improve the code and test complex algorithms. However,
    writing a large quantity of those tests takes time. Writing brittle tests that
    are tightly coupled with the code itself is easier due to the proximity to the
    code, increasing the maintenance cost of such test suites. It also makes it prone
    to overengineering your application in the name of testability.Black-box testing
    encompasses different types of tests that tend towards end-to-end testing. Since
    the tests target the external surface of the system, they are less likely to break
    when the system changes. Moreover, they are excellent at testing behaviors, and
    since each test tests an end-to-end use case, we need fewer of them, leading to
    a decrease in writing time and maintenance costs. Testing the whole system has
    drawbacks, including the slowness of executing each test, so combining black-box
    testing with other types of tests is very important to find the right balance
    between the number of tests, test case coverage, and speed of execution of the
    tests.Grey-box testing is a fantastic mix between the two others; you can treat
    any part of the software as a black box, leverage your inner-working knowledge
    to mock or stub parts of the test case (like to assert if the system persisted
    a record in the database), and test end-to-end scenarios more efficiently. It
    brings the best of both worlds, significantly reducing the number of tests while
    increasing the test surface considerably for each test case. However, doing grey-box
    testing on smaller units or heavily mocking the system may yield the same drawbacks
    as white-box testing. Integration tests or almost-E2E tests are good candidates
    for grey-box testing. We implement grey-box testing use cases in *Chapter 16*,
    *Request-Endpoint-Response (REPR)*. Meanwhile, let’s explore a few techniques
    to help optimize our test case creation by applying different techniques, like
    testing a small subset of values to assert the correctness of our programs by
    writing an optimal number of tests.
  prefs: []
  type: TYPE_NORMAL
- en: Test case creation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Multiple ways exist to break down and create test cases to help find software
    defects with a minimal test count. Here are some techniques to help minimize the
    number of tests while maximizing the test coverage:'
  prefs: []
  type: TYPE_NORMAL
- en: Equivalence Partitioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boundary Value Analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision Table Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: State Transition Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Case Testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I present the techniques theoretically. They apply to all sorts of tests and
    should help you write better test suites. Let’s have a quick look at each.
  prefs: []
  type: TYPE_NORMAL
- en: Equivalence Partitioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This technique divides the input data of the software into different equivalence
    data classes and then tests these classes rather than individual inputs. An equivalence
    data class means that all values in that partition set should lead to the same
    outcome or yield the same result. Doing this allows for limiting the number of
    tests considerably.For example, consider an application that accepts an integer
    value between 1 and 100 (inclusive). Using equivalence partitioning, we can divide
    the input data into two equivalence classes:'
  prefs: []
  type: TYPE_NORMAL
- en: Valid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invalid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To be more precise, we could further divide it into three equivalence classes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Class 1: Less than 1 (Invalid)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class 2: Between 1 and 100 (Valid)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class 3: Greater than 100 (Invalid)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we can write three tests, picking one representative from each class (e.g.,
    0, 50, and 101) to create our test cases. Doing so ensures a broad coverage with
    minimal test cases, making our testing process more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Boundary Value Analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This technique focuses on the values at the boundary of the input domain rather
    than the center. This technique is based on the principle that errors are most
    likely to occur at the boundaries of the input domain.The **input domain** represents
    the set of all possible inputs for a system. The **boundaries** are the edges
    of the input domain, representing minimum and maximum values.For example, if we
    expect a function to accept an integer between 1 and 100 (inclusive), the boundary
    values would be 1 and 100\. With Boundary Value Analysis, we would create test
    cases for these values, values just outside the boundaries (like 0 and 101), and
    values just inside the boundaries (like 2 and 99).Boundary Value Analysis is a
    very efficient testing technique that provides good coverage with a relatively
    small number of test cases. However, it’s unsuitable for finding errors within
    the boundaries or for complex logic errors. Boundary Value Analysis should be
    used on top of other testing methods, such as equivalence partitioning and decision
    table testing, to ensure the software is as defect-free as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Decision Table Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This technique uses a decision table to design test cases. A decision table
    is a table that shows all possible combinations of input values and their corresponding
    outputs.It’s handy for complex business rules that can be expressed in a table
    format, enabling testers to identify missing and extraneous test cases.For example,
    our system only allows access to a user with a valid username and password. Moreover,
    the system denies access to users when it is under maintenance. The decision table
    would have three conditions (username, password, and maintenance) and one action
    (allow access). The table would list all possible combinations of these conditions
    and the expected action for each combination. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Valid Username** | **Valid Password** | **System under Maintenance** |
    **Allow Access** |'
  prefs: []
  type: TYPE_TB
- en: '| True | True | False | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| True | True | True | No |'
  prefs: []
  type: TYPE_TB
- en: '| True | False | False | No |'
  prefs: []
  type: TYPE_TB
- en: '| True | False | True | No |'
  prefs: []
  type: TYPE_TB
- en: '| False | True | False | No |'
  prefs: []
  type: TYPE_TB
- en: '| False | True | True | No |'
  prefs: []
  type: TYPE_TB
- en: '| False | False | False | No |'
  prefs: []
  type: TYPE_TB
- en: '| False | False | True | No |'
  prefs: []
  type: TYPE_TB
- en: The main advantage of Decision Table Testing is that it ensures we test all
    possible input combinations. However, it can become complex and challenging to
    manage when systems have many input conditions, as the number of rules (and therefore
    test cases) increases exponentially with the number of conditions.
  prefs: []
  type: TYPE_NORMAL
- en: State Transition Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We usually use State Transition Testing to test software with a state machine
    since it tests the different system states and their transitions. It’s handy for
    systems where the system behavior can change based on its current state. For example,
    a program with states like “logged in” or “logged out”.To perform State Transition
    Testing, we need to identify the states of the system and then the possible transitions
    between the states. For each transition, we need to create a test case. The test
    case should test the software with the specified input values and verify that
    the software transitions to the correct state. For example, a user with the state
    “logged in” must transition to the state “logged out” after signing out.The main
    advantage of State Transition Testing is that it tests sequences of events, not
    just individual events, which could reveal defects not found by testing each event
    in isolation. However, State Transition Testing can become complex and time-consuming
    for systems with many states and transitions.
  prefs: []
  type: TYPE_NORMAL
- en: Use Case Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This technique validates that the system behaves as expected when used in a
    particular way by a user. Use cases could have formal descriptions, be user stories,
    or take any other form that fits your needs.A use case involves one or more actors
    executing steps or taking actions that should yield a particular result. A use
    case can include inputs and expected outputs. For example, when a user (actor)
    that is “signed in” (precondition) clicks the “sign out” button (action), then
    navigates to the profile page (action), the system denies access to the page and
    redirects the users to the sign in page, displaying an error message (expected
    behaviors).Use case testing is a systematic and structured approach to testing
    that helps identify defects in the software’s functionality. It is very user-centric,
    ensuring the software meets the users’ needs. However, creating test cases for
    complex use cases can be difficult. In the case of a user interface, the time
    to execute end-to-end tests of use cases can take a long time, especially as the
    number of tests grows.
  prefs: []
  type: TYPE_NORMAL
- en: It is an excellent approach to think of your test cases in terms of functionality
    to test, whether using a formal use case or just a line written on a napkin. The
    key is to test behaviors, not code.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that we have explored these techniques, it is time to introduce the xUnit
    library, ways to write tests, and how tests are written in the book. Let’s start
    by creating a test project.
  prefs: []
  type: TYPE_NORMAL
- en: How to create an xUnit test project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create a new xUnit test project, you can run the `dotnet new xunit` command,
    and the CLI does the job for you by creating a project containing a `UnitTest1`
    class. That command does the same as creating a new xUnit project from Visual
    Studio.For unit testing projects, name the project the same as the project you
    want to test and append `.Tests` to it. For example, `MyProject` would have a
    `MyProject.Tests` project associated with it. We explore more details in the *Organizing
    your tests* section below.The template already defines all the required NuGet
    packages, so you can start testing immediately after adding a reference to your
    project under test.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also add project references using the CLI with the `dotnet add reference`
    command. Assuming we are in the `./test/MyProject.Tests` directory and the project
    file we want to reference is in the `./src/MyProject` directory; we can execute
    the following command to add a reference:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, we explore some xUnit features that will allow us to write test cases.
  prefs: []
  type: TYPE_NORMAL
- en: Key xUnit features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In xUnit, the `[Fact]` attribute is the way to create unique test cases, while
    the `[Theory]` attribute is the way to make data-driven test cases. Let’s start
    with facts, the simplest way to write a test case.
  prefs: []
  type: TYPE_NORMAL
- en: Facts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Any method with no parameter can become a test method by decorating it with
    a `[Fact]` attribute, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also decorate asynchronous methods with the fact attribute when the
    code under test needs it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code, the highlighted line conceptually represents an asynchronous
    operation and does nothing more than allow using the `async`/`await` keywords.When
    we run the tests from Visual Studio’s Test Explorer, the test run result looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3: Test results in Visual Studio](img/file5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Test results in Visual Studio'
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed from the screenshot that the test classes are nested in
    the `xUnitFeaturesTest` class, part of the `MyApp` namespace, and under the `MyApp.Tests`
    project. We explore those details later in the chapter.Running the `dotnet test`
    CLI command should yield a result similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As we can read from the preceding output, all tests are passing, none have failed,
    and none were skipped. It is as simple as that to create test cases using xUnit.
  prefs: []
  type: TYPE_NORMAL
- en: Learning the CLI can be very helpful in creating and debugging CI/CD pipelines,
    and you can use them, like the `dotnet test` command, in any script (like bash
    and PowerShell).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Have you noticed the `Assert` keyword in the test code? If you are not familiar
    with it, we will explore assertions next.
  prefs: []
  type: TYPE_NORMAL
- en: Assertions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An assertion is a statement that checks whether a particular condition is `true`
    or `false`. If the condition is `true`, the test passes. If the condition is `false`,
    the test fails, indicating a problem with the subject under test.Let’s visit a
    few ways to assert correctness. We use barebone xUnit functionality in this section,
    but you can bring in the assertion library of your choice if you have one.
  prefs: []
  type: TYPE_NORMAL
- en: In xUnit, the assertion throws an exception when it fails, but you may never
    even realize that. You do not have to handle those; that’s the mechanism to propagate
    the failure result to the test runner.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We won’t explore all possibilities, but let’s start with the following shared
    pieces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The two preceding record classes, the `OperationThatThrows` method, and the
    variables are utilities used in the test to help us play with xUnit assertions.
    The variables are of type `object` for exploration purposes, but you can use any
    type in your test cases. I omitted the assertion code that we are about to see
    to keep the code leaner.The following two assertions are very explicit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The first compares whether the actual value equals the expected value, while
    the second compares if the two values are different. `Assert.Equal` is probably
    the most commonly used assertion method.
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, it is better to assert equality (`Equal`) than assert that
    the values are different (`NotEqual`). Except in a few rare cases, asserting equality
    will yield more consistent results and close the door to missing defects.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The next two assertions are very similar to the equality ones but assert that
    the objects are the same instance or not (the same instance means the same reference):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The next one validates that the two objects are equal. Since we are using record
    classes, it makes it super easy for us; `obj1` and `obj2` are not the same (two
    instances) but are equal (see *Appendix A* for more information on record classes):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The next two are very similar and assert that the value is `null` or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The next line asserts that `obj1` is of the `MyClass` type and then returns
    the argument (`obj1`) converted to the asserted type (`MyClass`). If the type
    is incorrect, the `IsType` method will throw an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we reuse the `Assert.Equal` method to validate that the value of the `Name`
    property is what we expect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code block asserts that the `testCode` argument throws an exception
    of the `SomeCustomException` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `testCode` argument executes the `OperationThatThrows` inline function we
    saw initially. The `Throws` method allows us to test some exception properties
    by returning the exception in the specified type. The same behavior as the `IsType`
    method happens here; if the exception is of the wrong type or no exception is
    thrown, the `Throws` method will fail the test.
  prefs: []
  type: TYPE_NORMAL
- en: It is a good idea to ensure that not only the proper exception type is thrown,
    but the exception carries the correct values as well.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The following line asserts that the value of the `Name` property is what we
    expect it to be, ensuring our program would propagate the proper exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We covered a few assertion methods, but many others are part of xUnit, like
    the `Collection`, `Contains`, `False`, and `True` methods. We use many assertions
    throughout the book, so if these are still unclear, you will learn more about
    them.Next, let’s look at data-driven test cases using theories.
  prefs: []
  type: TYPE_NORMAL
- en: Theories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For more complex test cases, we can use theories. A theory contains two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: A `[Theory]` attribute that marks the method as a theory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At least one data attribute that allows passing data to the test method: `[InlineData]`,
    `[MemberData]`, or `[ClassData]`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When writing a theory, your primary constraint is ensuring that the number of
    values matches the parameters defined in the test method. For example, a theory
    with one parameter must be fed one value. We look at some examples next.
  prefs: []
  type: TYPE_NORMAL
- en: You are not limited to only one type of data attribute; you can use as many
    as you need to suit your needs and feed a theory with the appropriate data.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The `[InlineData]` attribute is the most suitable for constant values or smaller
    sets of values. Inline data is the most straightforward way of the three because
    of the proximity of the test values and the test method.Here is an example of
    a theory using inline data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'That test method yields three test cases in the Test Explorer, where each can
    pass or fail individually. Of course, since 1 equals 1, 2 equals 2, and 5 equals
    5, all three test cases are passing, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4: Inline data theory test results](img/file6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Inline data theory test results'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also use the `[MemberData]` and `[ClassData]` attributes to simplify
    the test method’s declaration when we have a large set of data to tests. We can
    also do that when it is impossible to instantiate the data in the attribute. We
    can also reuse the data in multiple test methods or encapsulate the data away
    from the test class.Here is a medley of examples of the `[MemberData]` attribute
    usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding test case yields 12 results. If we break it down, the code starts
    by loading three sets of data from the `Data` property by decorating the test
    method with the `[MemberData(nameof(Data))]` attribute. This is how to load data
    from a member of the class the test method is declared in.Then, the second property
    is very similar to the `Data` property but replaces `IEnumerable<object[]>` with
    a `TheoryData<…>` class, making it more readable and type-safe. Like with the
    first attribute, we feed those three sets of data to the test method by decorating
    it with the `[MemberData(nameof(TypedData))]` attribute. Once again, it is part
    of the test class.
  prefs: []
  type: TYPE_NORMAL
- en: I strongly recommend using `TheoryData<…>` by default.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The third data feeds three more sets of data to the test method. However, that
    data originates from the `GetData` method of the `ExternalData` class, sending
    `10` as an argument during the execution (the `start` parameter). To do that,
    we must specify the `MemberType` instance where the method is located so xUnit
    knows where to look. In this case, we pass the argument `10` as the second parameter
    of the `MemberData` constructor. However, in other cases, you can pass zero or
    more arguments there.Finally, we are doing the same for the `ExternalData.TypedData`
    property, which is represented by the `[MemberData(nameof(ExternalData.TypedData),
    MemberType = typeof(ExternalData))]` attribute. Once again, the only difference
    is that the property is defined using `TheoryData` instead of `IEnumerable<object[]>`,
    which makes its intent clearer.When running the tests, the data provided by the
    `[MemberData]` attributes are combined, yielding the following result in the Test
    Explorer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: Member data theory test results](img/file7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Member data theory test results'
  prefs: []
  type: TYPE_NORMAL
- en: These are only a few examples of what we can do with the `[MemberData]` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: I understand that’s a lot of condensed information, but the goal is to cover
    just enough to get you started. I don’t expect you to become an expert in xUnit
    by reading this chapter.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Last but not least, the `[ClassData]` attribute gets its data from a class
    implementing `IEnumerable<object[]>` or inheriting from `TheoryData<…>`. The concept
    is the same as the other two. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'These are very similar to `[MemberData]`, but we point to a type instead of
    pointing to a member.In `TheoryDataClass`, implementing the `IEnumerable<object[]>`
    interface makes it easy to `yield return` the results. On the other hand, in the
    `TheoryTypedDataClass` class, by inheriting `TheoryData`, we can leverage a list-like
    `Add` method. Once again, I find inheriting from `TheoryData` more explicit, but
    either way works with xUnit. You have many options, so choose the best one for
    your use case.Here is the result in the Test Explorer, which is very similar to
    the other attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6: Test Explorer](img/file8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Test Explorer'
  prefs: []
  type: TYPE_NORMAL
- en: That’s it for the theories—next, a few last words before organizing our tests.
  prefs: []
  type: TYPE_NORMAL
- en: Closing words
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that facts, theories, and assertions are out of the way, xUnit offers other
    mechanics to allow developers to inject dependencies into their test classes.
    These are named fixtures. Fixtures allow dependencies to be reused by all test
    methods of a test class by implementing the `IClassFixture<T>` interface. Fixtures
    are very helpful for costly dependencies, like creating an in-memory database.
    With fixtures, you can create the dependency once and use it multiple times. The
    `ValuesControllerTest` class in the `MyApp.IntegrationTests` project shows that
    in action.It is important to note that xUnit creates an instance of the test class
    for every test run, so your dependencies are recreated every time if you are not
    using the fixtures.You can also share the dependency provided by the fixture between
    multiple test classes by using `ICollectionFixture<T>`, `[Collection]`, and `[CollectionDefinition]`
    instead. We won’t get into the details here, but at least you know it’s possible
    and know what types to look for when you need something similar.Finally, if you
    have worked with other testing frameworks, you might have encountered **setup**
    and **teardown** methods. In xUnit, there are no particular attributes or mechanisms
    for handling setup and teardown code. Instead, xUnit uses existing OOP concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: To set up your tests, use the class constructor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To tear down (clean up) your tests, implement `IDisposable` or `IAsyncDisposable`
    and dispose of your resources there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s it, xUnit is very simple and powerful, which is why I adopted it as my
    main testing framework several years ago and chose it for this book.Next, we learn
    to write readable test methods.
  prefs: []
  type: TYPE_NORMAL
- en: Arrange, Act, Assert
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Arrange, Act, Assert (AAA or 3A) is a well-known method for writing readable
    tests. This technique allows you to clearly define your setup (arrange), the operation
    under test (act), and your assertions (assert). One efficient way to use this
    technique is to start by writing the 3A as comments in your test case and then
    write the test code in between. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Of course, that test case cannot fail, but the three blocks are easily identifiable
    with the 3A comments.In general, **you want the Act block of your unit tests to
    be a single line**, making the test focus clear. If you need more than one line,
    the chances are that something is wrong in the test or the design.
  prefs: []
  type: TYPE_NORMAL
- en: When the tests are very small (only a few lines), removing the comments might
    help readability. Furthermore, when you have nothing to set up in your test case,
    delete the Arrange comment to improve its readability further.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Next, we learn how to organize tests into projects, directories, and files.
  prefs: []
  type: TYPE_NORMAL
- en: Organizing your tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are many ways of organizing test projects inside a solution, and I tend
    to create a unit test project for each project in the solution and one or more
    integration test projects.A unit test is directly related to a single unit of
    code, whether it’s a method or a class. It is straightforward to associate a unit
    test project with its respective code project (assembly), leading to a one-on-one
    relationship. One unit test project per assembly makes them portable, easier to
    navigate, and even more so when the solution grows.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a preferred way to organize yours that differs from what we are
    doing in the book, by all means, use that approach instead.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Integration tests, on the other hand, can span multiple projects, so having
    a single rule that fits all scenarios is challenging. One integration test project
    per solution is often enough. Sometimes we can need more than one, depending on
    the context.
  prefs: []
  type: TYPE_NORMAL
- en: I recommend starting with one integration test project and adding more as needed
    during development instead of overthinking it before getting started. Trust your
    judgment; you can always change the structure as your project evolves.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Folder-wise, at the solution level, creating the application and its related
    libraries in an `src` directory helps isolate the actual solution code from the
    test projects created under a `test` directory, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7: The Automated Testing Solution Explorer, displaying how the projects
    are organized](img/file9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: The Automated Testing Solution Explorer, displaying how the projects
    are organized'
  prefs: []
  type: TYPE_NORMAL
- en: That’s a well-known and effective way of organizing a solution in the .NET world.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it is not possible or unwanted to do that. One such use case would
    be multiple microservices written under a single solution. In that case, you might
    want the tests to live closer to your microservices and not split them between
    `src` and `test` folders. So you could organize your solution by microservice
    instead, like one directory per microservice that contains all the projects, including
    tests.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s now dig deeper into organizing unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: How you organize your test projects may make a big difference between searching
    for your tests or making it easy to find them. Let’s look at the different aspects,
    from the `namespace` to the test code itself.
  prefs: []
  type: TYPE_NORMAL
- en: Namespace
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'I find it convenient to create unit tests in the same namespace as the subject
    under test when creating unit tests. That helps get tests and code aligned without
    adding any additional using statements. To make it easier when creating files,
    you can change the default namespace used by Visual Studio when creating a new
    class in your test project by adding `<RootNamespace>[Project under test namespace]</RootNamespace>`
    to a `PropertyGroup` of the test project file (`*.csproj`), like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Test class name
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: By convention, I name test classes `[class under test]Test.cs` and create them
    in the same directory as in the original project. Finding tests is easy when following
    that simple rule since the test code is in the same location of the file tree
    as the code under test but in two distinct projects.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8: The Automated Testing Solution Explorer, displaying how tests
    are organized](img/file10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: The Automated Testing Solution Explorer, displaying how tests are
    organized'
  prefs: []
  type: TYPE_NORMAL
- en: Test code inside the test class
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For the test code itself, I follow a multi-level structure similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: One test class is named the same as the class under test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One nested test class per method to test from the class under test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One test method per test case of the method under test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This technique helps organize tests by test case while keeping a clear hierarchy,
    leading to the following hierarchy:'
  prefs: []
  type: TYPE_NORMAL
- en: Class under test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Method under test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test case using that method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In code, that translates to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This convention allows you to set up tests step by step. For example, by inheriting
    the outer class (the `ValuesControllerTest` class here) from the inner class (the
    `Get` nested class), you can create top-level private mocks or classes shared
    by all nested classes and test methods. Then, for each method to test, you can
    modify the setup or create other private test elements in the nested classes.
    Finally, you can do more configuration per test case inside the test method (the
    `Should_return_the_expected_strings` method here).
  prefs: []
  type: TYPE_NORMAL
- en: 'Don’t go too hard on reusability inside your test classes, as it can make tests
    harder to read from an external eye, such as a reviewer or another developer that
    needs to play there. Unit tests should remain focused, small, and easy to read:
    a unit of code testing another unit of code. Too much reusability may lead to
    a brittle test suite.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that we have explored organizing unit tests, let’s look at integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Integration tests are harder to organize because they depend on multiple units,
    can cross project boundaries, and interact with various dependencies.We can create
    one integration test project for most simple solutions or many for more complex
    scenarios.When creating one, you can name the project `IntegrationTests` or start
    with the entry point of your tests, like a REST API project, and name the project
    `[Name of the API project].IntegrationTests`. At this point, how to name the integration
    test project depends on your solution structure and intent.When you need multiple
    integration projects, you can follow a convention similar to unit tests and associate
    your integration projects one-to-one: `[Project under test].IntegrationTests`.Inside
    those projects, it depends on how you want to attack the problem and the structure
    of the solution itself. Start by identifying the features under test. Name the
    test classes in a way that mimics your requirements, organize those into sub-folders
    (maybe a category or group of requirements), and code test cases as methods. You
    can also leverage nested classes, as we did with unit tests.'
  prefs: []
  type: TYPE_NORMAL
- en: We write tests throughout the book, so you will have plenty of examples to make
    sense of all this if it’s not clear now.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Next, we implement an integration test by leveraging ASP.NET Core features.
  prefs: []
  type: TYPE_NORMAL
- en: Writing ASP.NET Core integration tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When Microsoft built ASP.NET Core from the ground up, they fixed and improved
    so many things that I cannot enumerate them all here, including testability.Nowadays,
    there are two ways to structure a .NET program:'
  prefs: []
  type: TYPE_NORMAL
- en: The classic ASP.NET Core `Program` and the `Startup` classes. This model might
    be found in existing projects (created before .NET 6).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The minimal hosting model introduced in .NET 6\. This may look familiar to you
    if you know Node.js, as this model encourages you to write the start-up code in
    the Program.cs file by leveraging top-level statements. You will most likely find
    this model in new projects (created after the release of .NET 6).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No matter how you write your program, that’s the place to define how the application’s
    composition and how it boots. Moreover, we can leverage the same testing tools
    more or less seamlessly.In the case of a web application, the scope of our integration
    tests is often to call the endpoint of a controller over HTTP and assert the response.
    Luckily, in .NET Core 2.1, the .NET team added the `WebApplicationFactory<TEntry>`
    class to make the integration testing of web applications easier. With that class,
    we can boot up an ASP.NET Core application in memory and query it using the supplied
    `HttpClient` in a few lines of code. The test classes also provide extension points
    to configure the server, such as replacing implementations with mocks, stubs,
    or other test-specific elements.Let’s start by booting up a classic web application
    test.
  prefs: []
  type: TYPE_NORMAL
- en: Classic web application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In a classic ASP.NET Core application, the `TEntry` generic parameter of the
    `WebApplicationFactory<TEntry>` class is usually the `Startup` or `Program` class
    of your project under test.
  prefs: []
  type: TYPE_NORMAL
- en: The test cases are in the `Automated Testing` solution under the `MyApp.IntegrationTests`
    project.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let’s start by looking at the test code structure before breaking it down:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The first piece of the preceding code that is relevant to us is how we get
    an instance of the `WebApplicationFactory<Startup>` class. We inject a `WebApplicationFactory<Startup>`
    object into the constructor by implementing the `IClassFixture<T>` interface (a
    xUnit feature). We can also use the factory to configure the test server, but
    we don’t need to here, so we can only keep a reference on the `HttpClient`, preconfigured
    to connect to the in-memory test server.Then, we may have noticed we have the
    nested `Get` class that inherits the `ValuesControllerTest` class. The `Get` class
    contains the test cases. By inheriting the `ValuesControllerTest` class, we can
    leverage the `_httpClient` field from the test cases we are about to see.In the
    first test case, we use `HttpClient` to query the `http://localhost/api/values`
    URI, accessible through the in-memory server. Then, we assert that the status
    code of the HTTP response was a success (`200 OK`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The second test case also sends an HTTP request to the in-memory server but
    deserializes the body’s content as a string[] to ensure the values are the same
    as expected instead of validating the status code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: As you may have noticed from the test cases, the `WebApplicationFactory` preconfigured
    the `BaseAddress` property for us, so we don’t need to prefix our requests with
    `http://localhost`.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: When running those tests, an in-memory web server starts. Then, HTTP requests
    are sent to that server, testing the complete application. The tests are simple
    in this case, but you can create more complex test cases in more complex programs.Next,
    we explore how to do the same for minimal APIs.
  prefs: []
  type: TYPE_NORMAL
- en: Minimal hosting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unfortunately, we must use a workaround to make the `Program` class discoverable
    when using minimal hosting. Let’s explore a few workarounds that leverage minimal
    APIs, allowing you to pick the one you prefer.
  prefs: []
  type: TYPE_NORMAL
- en: First workaround
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The **first workaround** is to use any other class in the assembly as the `TEntryPoint`
    of `WebApplicationFactory<TEntryPoint>` instead of the `Program` or `Startup`
    class. This makes what `WebApplicationFactory` does a little less explicit, but
    that’s all. Since I tend to prefer readable code, I do not recommend this.
  prefs: []
  type: TYPE_NORMAL
- en: Second workaround
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **second workaround** is to add a line at the bottom of the `Program.cs`
    file (or anywhere else in the project) to change the autogenerated `Program` class
    visibility from `internal` to `public`. Here is the complete `Program.cs` file
    with that added line (highlighted):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Then, the test cases are very similar to the ones of the classic web application
    explored previously. The only difference is the program itself, both programs
    don’t do the same thing.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The only change is the expected result as the endpoint returns the `text/plain`
    string `Hello World!` instead of a collection of strings serialized as JSON. The
    test cases would be identical if the two endpoints produced the same result.
  prefs: []
  type: TYPE_NORMAL
- en: Third workaround
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The **third workaround** is to instantiate `WebApplicationFactory` manually
    instead of leveraging a fixture. We can use the `Program` class, which requires
    changing its visibility by adding the following line to the `Program.cs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'However, instead of injecting the instance using the `IClassFixture` interface,
    we instantiate the factory manually. To ensure we dispose the `WebApplicationFactory`
    instance, we also implement the `IAsyncDisposable` interface.Here’s the complete
    example, which is very similar to the previous workaround:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'I omitted the test cases in the preceding code block because they are the same
    as the previous workarounds. The full source code is available on GitHub: [https://adpg.link/vzkr](https://adpg.link/vzkr).'
  prefs: []
  type: TYPE_NORMAL
- en: Using class fixtures is more performant since the factory and the server get
    created only once per test run instead of recreated for every test method.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Creating a test application
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Finally, we can create a dedicated class that instantiates `WebApplicationFactory`
    manually. It leverages the other workarounds but makes the test cases more readable.
    By encapsulating the setup of the test application in a class, you will improve
    the reusability and maintenance cost in most cases.First, we need to change the
    `Program` class visibility by adding the following line to the `Project.cs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we can access the Program class without the need to allow internal
    visibility to our test project, we can create our test application like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can reuse the same code to test our program but instantiate `MyTestApplication`
    instead of `WebApplicationFactory<Program>`, highlighted in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: You can also leverage fixtures, but for the sake of simplicity, I decided to
    show you how to instantiate our new test application manually.And that’s it. We
    have covered multiple ways to work around integration testing minimal APIs simplistically
    and elegantly. Next, we explore a few testing principles before moving to architectural
    principles in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Important testing principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One essential thing to remember when writing tests is to test use cases, not
    the code itself; we are testing features’ correctness, not code correctness. Of
    course, if the expected outcome of a feature is correct, that also means the codebase
    is correct. However, it is not always true the other way around; correct code
    may yield an incorrect outcome. Also, remember that code costs money to write,
    while features deliver value.To help with that, test requirements should revolve
    around **inputs and outputs**. When specific values go into your subject under
    test, you expect particular values to come out. Whether you are testing a simple
    `Add` method where the ins are two or more numbers, and the out is the sum of
    those numbers, or a more complex feature where the ins come from a form, and the
    out is the record getting persisted in a database, most of the time, we are testing
    that inputs produced an output or an outcome.Another concept is to divide those
    units as a query or a command. No matter how you organize your code, from a simple
    single-file application to a microservices architecture-base Netflix clone, all
    simple or compounded operations are queries or commands. Thinking about a system
    this way should help you test the ins and outs. We discuss queries and commands
    in several chapters, so keep reading to learn more.Now that we have laid this
    out, what if a unit must perform multiple operations, such as reading from a database,
    and then send multiple commands? You can create and test multiple smaller units
    (individual operations) and another unit that orchestrates those building blocks,
    allowing you to test each piece in isolation. We explore how to achieve this throughout
    the book.In a nutshell, when writing automated tests:'
  prefs: []
  type: TYPE_NORMAL
- en: In case of a query, we assert the output of the unit undergoing testing based
    on its input parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In case of a command, we assert the outcome of the unit undergoing testing based
    on its input parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We explore numerous techniques throughout the book to help you achieve that
    level of separation, starting with architectural principles in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This chapter covered automated testing, such as unit and integration tests.
    We also briefly covered end-to-end tests, but covering that in only a few pages
    is impossible. Nonetheless, how to write integration tests can also be used for
    end-to-end testing, especially in the REST API space.We explored different testing
    approaches from a bird’s eye view, tackled technical debt, and explored multiple
    testing techniques like black-box, white-box, and grey-box testing. We also peaked
    at a few formal ways to choose the values to test, like equivalence partitioning
    and boundary value analysis.We then looked at xUnit, the testing framework used
    throughout the book, and a way of organizing tests. We explored ways to pick the
    correct type of test and some guidelines about choosing the right quantity for
    each kind of test. Then we saw how easy it is to test our ASP.NET Core web applications
    by running it in memory. Finally, we explored high-level concepts that should
    guide you in writing testable, flexible, and reliable programs.Now that we have
    talked about testing, we are ready to explore a few architectural principles to
    help us increase programs’ testability. Those are a crucial part of modern software
    engineering and go hand in hand with automated testing.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s take a look at a few practice questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Is it true that in TDD, you write tests before the code to be tested?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of unit tests?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How big can a unit test be?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What type of test is usually used when the subject under test has to access
    a database?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is doing TDD required?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do you need to know the inner working of the application to do black-box testing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are some links to build upon what we have learned in the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'xUnit: [https://xunit.net/](https://xunit.net/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you use Visual Studio, I have a few handy snippets to help improve productivity.
    They are available on GitHub: [https://adpg.link/5TbY](https://adpg.link/5TbY)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
