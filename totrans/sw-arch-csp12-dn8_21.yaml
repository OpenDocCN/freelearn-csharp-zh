- en: '21'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Case Study
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned during the previous chapters, for this new edition, we reformulated
    the way we present the case study of the book – **World Wild Travel Club** (**WWTravelClub**).
    This case study will take you through the process of creating the software architecture
    for a travel agency.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of this case study is not to furnish a production-ready application,
    but just to help you understand the theory explained in each chapter and to provide
    an example of how to develop an enterprise application with Azure, Azure DevOps,
    C# 12, .NET 8, ASP.NET Core, and all other technologies introduced in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a description of what our case study application is. Then,
    we will gradually move to formal specifications.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing World Wild Travel Club
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: WWTravelClub is a travel agency that was created to revolutionize vacation planning
    and travel experiences globally. To do so, they are developing an online service,
    where each aspect of a trip is meticulously curated and supported by a dedicated
    team of destination-specific experts.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of this platform is that you can be both a visitor and a destination
    expert at the same time. The more you participate as an expert in a destination,
    the more points you score. These points can then be redeemed for tickets that
    people buy online using the platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'The responsible for the WWTravelClub project came with the following requirements
    list for the platform:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Common user view:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Promotional packages on the home page
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Get a recommendation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Search for packages
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Details for each package:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Buy a package
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Buy a package with a club of experts included
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Comment on your experience
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask an expert
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate an expert
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Register as a common user
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Destination expert view:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same view as the common user view
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Answer questions asking for your destination expertise
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage the points you scored by answering questions
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Exchange points for tickets
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Administrator view:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage packages
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage common users
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Manage destination experts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Besides the functionalities asked for on the platform, it is important to note
    that WWTravelClub intends to have more than 100 destination experts per package
    and will offer around 1,000 different packages all over the world.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to know that, in general, customers do not bring the requirements
    ready for development. That is why the process of gathering requirements is so
    important, as described in *Chapter 1, Understanding the Importance of Software
    Architecture*. This process will transform the list presented above into user
    needs and system requirements. Let’s check how this will work in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: User needs and system requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As presented in *Chapter 1, Understanding the Importance of Software Architecture*,
    to summarize the user needs, you may use the User Story pattern. We have used
    this approach here so that you can read the following user stories for WWTravelClub:'
  prefs: []
  type: TYPE_NORMAL
- en: '`US_001`: As a common user, I want to view promotional packages on the home
    page so that I can easily find my next vacation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_002`: As a common user, I want to search for packages I cannot find on
    the home page so that I can explore other trip opportunities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_003`: As a common user, I want to see the details of a package so that
    I can decide which package to buy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_004`: As a common user, I want to register myself so that I can start buying
    the package.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_005`: As a registered user, I want to process the payment so that I can
    buy a package.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_006`: As a registered user, I want to buy a package with an expert recommendation
    included so that I can have an exclusive trip experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_007`: As a registered user, I want to ask for an expert so that I can find
    out the best things to do on my trip.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_008`: As a registered user, I want to comment on my experience so that
    I can give feedback on my trip.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_009`: As a registered user, I want to review an expert who has helped me
    so that I can share with others how fantastic they were.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_010`: As a registered user, I want to register as a destination expert
    view so that I can help people who travel to my city.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_011`: As an expert user, I want to answer questions about my city so that
    I can score points to be exchanged in the future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_012`: As an expert user, I want to exchange points for tickets so that
    I can travel around the world more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_013`: As an administrator user, I want to manage packages so that users
    can have fantastic opportunities to travel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_014`: As an administrator user, I want to manage registered users so that
    WWTravelClub can guarantee good service quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_015`: As an administrator user, I want to manage expert users so that all
    the questions regarding our destinations are answered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_016`: As an administrator user, I want to offer more than 1,000 packages
    around the world so that different countries can experience the WWTravelClub service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_017`: As the CEO, I want to have more than 1,000 users simultaneously accessing
    the website so that the business can scale effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_018`: As a user, I want to access WWTravelClub in my native language so
    that I can easily understand the package offered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_019`: As a user, I want to access WWTravelClub in the Chrome, Firefox,
    and Edge web browsers so that I can use the web browser of my preference.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_020`: As a user, I want to know that my credit card information is stored
    securely, so I can buy packages safely.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`US_021`: As a user, I want to get a recommendation of a good place to visit
    according to other people from my city, so I can find out about new places that
    fit my style.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice that while writing the stories, information related to non-functional
    requirements such as security, environment, performance, and scalability can be
    included.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, some system requirements may be omitted when you write user stories
    and need to be included in the software specification. These requirements can
    be related to legal aspects, hardware, and software prerequisites, or even points
    of attention for the correct system delivery. We discussed them in *Chapter 2,
    Non-Functional Requirements*. So non-functional requirements need to be mapped
    and listed, as well as the user stories. The WWTravelClub system requirements
    are presented in the following list. Note that requirements are written in the
    future tense because the system does not exist yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SR_001`: The system shall use cloud computing components to deliver the scalability
    required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SR_002`: The system shall respect **General Data Protection Regulation** (**GDPR**)
    requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SR_003`: Any web page of this system shall respond within at least 2 seconds
    of 1,000 users accessing it concurrently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The idea of having this list of user stories and system requirements is to help
    you understand how complex the development of a platform might be if you think
    about it from an architectural perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the list of user stories for the platform, it is time to start
    selecting the .NET project types that will be used at WWTravelClub. Let’s check
    them in the next topic.
  prefs: []
  type: TYPE_NORMAL
- en: Main types of .NET projects used at WWTravelClub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The development of this book’s use case will be based on various kinds of .NET
    Core Visual Studio projects. This section describes all of them. Let us select
    **New project** in the Visual Studio **File** menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, you can filter **.NET Core** project types by typing them into
    the search engine as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.1: Searching types of .NET Core projects in Visual Studio'
  prefs: []
  type: TYPE_NORMAL
- en: 'There, you will find common C# projects (console, a class library, Windows
    Forms, and WPF), and various types of test projects, each based on a different
    test framework: xUnit, NUnit, and MSTest. Choosing among the various testing frameworks
    is just a matter of preference since they all offer comparable features. Adding
    tests to each piece of software that composes a solution is a common practice
    and allows the software to be modified frequently without jeopardizing its reliability.'
  prefs: []
  type: TYPE_NORMAL
- en: You may also want to define your class library projects under **.NET Standard**,
    which was discussed in *Chapter 5*, *Implementing Code Reusability in C# 12*.
    These class libraries are based on standards that make them compatible with several
    .NET versions. For instance, libraries based on 2.0 standards are compatible with
    all .NET Core versions greater than or equal to 2.0, with all .NET versions greater
    than 5, and with all .NET Framework versions greater than 4.6\. This compatibility
    advantage comes at the price of having fewer available features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides filtering **project types** to the **cloud**, we have several more
    project types. Some of them will enable us to define microservices. Microservice-based
    architectures allow an application to be split into several independent microservices.
    Several instances of the same microservice can be created and distributed across
    several machines to fine-tune the performance of each application part. If you
    want to learn about microservices, we have talked about them in the following
    chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 11*, *Applying a Microservice Architecture to Your Enterprise Application*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 14*, *Implementing Microservices with .NET*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chapter 20*, *Kubernetes*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In *Chapter 2*, *Non-Functional Requirements*, we described an ASP.NET Core
    application project in the subsection *Creating a scalable web app with .NET 8*.
    There, we defined an ASP.NET Core application, but Visual Studio also contains
    project templates for projects based on RESTful APIs and the most important single-page
    application frameworks, such as Angular, React, Vue.js, and the Blazor framework
    based on WebAssembly, which was discussed in *Chapter 19*, *Client Frameworks:
    Blazor*. Some of them are available with the standard Visual Studio installation,
    while others require the installation of an SPA package, called **ASP.NET and
    web development** workload.'
  prefs: []
  type: TYPE_NORMAL
- en: To finish, testing projects were discussed in detail in *Chapter 9*, *Testing
    Your Enterprise Application*. We suggest you, as a software architect, try all
    the templates available at Visual Studio by creating proofs of concept that may
    help you define the best project types for your solution.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have checked these different project types, let’s have a look at
    Azure DevOps and how it can be helpful in managing WWTravelClub is requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Managing WWTravelClub’s requirements using Azure DevOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As discussed in *Chapter 3, Managing Requirements*, an important step for a
    software development project is where and how the team will organize the user
    stories mapped from the user needs. There, as described in the *Managing system
    requirements in Azure DevOps* section, Azure DevOps enables you to document system
    requirements using work items, which are mainly tasks or actions that need to
    be completed to deliver a product or service.
  prefs: []
  type: TYPE_NORMAL
- en: It is also important to remember that the work items available depend on the
    *work item process* you select while creating the Azure DevOps project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the scenario described for WWTravelClub, we decided to use the
    Agile process and have defined three Epic work items as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.2: User case Epics'
  prefs: []
  type: TYPE_NORMAL
- en: 'The creation of these work items is quite simple:'
  prefs: []
  type: TYPE_NORMAL
- en: Inside each work item, we link the different types of work items, as you can
    see in *Figure 21.3*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It is important to determine that the connections between work items are useful
    during software development. Hence, as a software architect, you must provide
    this knowledge to your team, and, more than that, you must incentivize them to
    make these connections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19820_21_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.3: Defining a Feature link to the Epic selected'
  prefs: []
  type: TYPE_NORMAL
- en: 'As soon as you create a **Feature** work item, you will be able to connect
    it to several User Story work items that detail its specifications. The following
    screenshot shows the details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19820_21_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.4: Product Backlog work item'
  prefs: []
  type: TYPE_NORMAL
- en: After that, Task and Test Case work items can be created for each User Story
    work item. The user interface provided by Azure DevOps is efficacious because
    it enables you to track the chain of functionalities and the relationships between
    them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19820_21_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.5: Board view'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering we are using Scrum as the basis for the Agile process, as soon
    as you complete the input for the User Story and Task work items, you will be
    able to plan the project sprints together with your team. The plan view enables
    you to drag and drop User Story work items to each planned sprint/iteration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19820_21_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.6: Backlogs view'
  prefs: []
  type: TYPE_NORMAL
- en: By clicking on a specific sprint on the right, you will see just the work items
    assigned to that sprint. Each sprint page is quite like the backlog page but contains
    more tabs, where you can define **Sprint Period** and **Team Capacity**, for instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Interface gráfica do usuário, Aplicativo  Descrição gerada automaticamente](img/B19820_21_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.7: Planning view'
  prefs: []
  type: TYPE_NORMAL
- en: Also useful is the **Sprints** menu on the left, which enables each user to
    jump immediately to the current sprints of all the projects they are engaged in.
  prefs: []
  type: TYPE_NORMAL
- en: This is how these work items are created. Once you understand this mechanism,
    you will be able to create and plan any software project. It is worth mentioning
    that the tool itself will not solve problems related to team management. However,
    the tool is a great way to incentivize the team to update the project status,
    so you can maintain a clear perspective of how the project is evolving.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have defined how we will manage WWTravelClub requirements, it is
    time to start thinking about the code standard that will be followed by the developers.
    Let’s check this out in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Code standard for WWTravelClub – Dos and don’ts when writing code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In *Chapter 4, Best Practices in Coding C# 12*, we learned that, as a software
    architect, you must define a code standard that matches the needs of the company
    you are working for.
  prefs: []
  type: TYPE_NORMAL
- en: In the sample project of this book, this is no different. The way we decided
    to present the standard for it is by describing a list of dos and don’ts. We have
    followed this list while writing the samples we produced. It is worth mentioning
    that the list is a good way to start your standard and, as a software architect,
    you should discuss this list with the developers you have in the team so that
    you can develop it in a practical and good manner.
  prefs: []
  type: TYPE_NORMAL
- en: It is also important to remember that, in the *Understanding and applying tools
    that can evaluate C# code* section of *Chapter 4, Best Practices in Coding C#12*,
    we have discussed some good tools that can help you define a *coding style* for
    your team*.*
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the statements below are designed to clarify the communication
    between team members and improve the performance and maintenance of the software
    you are developing.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may consider the list below a waste of space in the book since we have
    great C# community coding standards without the need to enforce a standard. However,
    how can you guarantee maintainability without it? If defining coding standards
    was not necessary, we wouldn’t have so many projects with maintenance issues.
    So, let’s check the list of dos and don’ts defined for the WWTravelClub project:'
  prefs: []
  type: TYPE_NORMAL
- en: DO write your code in English.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DO use PascalCasing for all public member, type, and namespace names consisting
    of multiple words.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DO use camelCasing for parameter names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DO write classes, methods, and variables with understandable names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DO comment public classes, methods, and properties.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DO use the `using` statement whenever possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DO use `async` implementation whenever possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DON’T write empty `try-catch` statements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DON’T write methods with a cyclomatic complexity score of more than 10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DON’T use `break` and `continue` inside `for/while/do-while/foreach` statements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These dos and don’ts are simple to follow and, better than that, will yield
    great results for the code your team produces. It is worth mentioning that these
    DOs and DON’Ts are a guide, not a set of hard-and-fast rules to be followed by
    every team. They can be adapted as needed for the specific needs of a team before
    they are sent out to the team members. As a software architect, it is essential
    that all team members follow the same DOs and DON’Ts.
  prefs: []
  type: TYPE_NORMAL
- en: Considering we now have a coding standard defined, let’s learn how to apply
    SonarCloud as a tool for helping us in code analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Applying SonarCloud to WWTravelClub APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have already created the WWTravelClub repository, we can Improve
    the code quality, as discussed in *Chapter 4, Best Practices in Coding C# 12*.
    As we saw in that chapter, Azure DevOps enables continuous integration, and this
    can be useful. In this section, we will discuss more reasons why the DevOps concept
    and the Azure DevOps platform are so useful.
  prefs: []
  type: TYPE_NORMAL
- en: For now, the only thing we would like to introduce is the possibility of analyzing
    code after it is committed by the developers but before it has been published.
    Nowadays, in a SaaS world for application life cycle tools, this is only possible
    because of some of the SaaS code analysis platforms that we have. This use case
    will use SonarCloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'SonarCloud is the SaaS version provided by Sonar. Also, it might be worth noting
    that SonarCloud is exceptionally easy to self-host; this way, sensitive security
    information may be kept within an enterprise. It is free for open-source code
    and can analyze code stored in GitHub, Bitbucket, and Azure DevOps. The user needs
    a registration for these platforms. As soon as you log in, assuming your code
    is stored in Azure DevOps, you can follow the steps described in the following
    article to create a connection between your Azure DevOps and SonarCloud: [https://docs.sonarcloud.io/](https://docs.sonarcloud.io/).'
  prefs: []
  type: TYPE_NORMAL
- en: Sonar also provides a self-managed edition that can be useful for scenarios
    where SonarCloud cannot be used. Please check [https://www.sonarsource.com/](https://www.sonarsource.com/)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 'After setting up the connection between your project in Azure DevOps and SonarCloud,
    you will have a build pipeline like the one that follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.8: SonarCloud configuration in the Azure build pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worth mentioning that C# projects do not have a GUID number, and this
    is required by SonarCloud. You can easily generate one using this link: [https://www.guidgenerator.com/](https://www.guidgenerator.com/),
    or using the **Create GUID** tool in Visual Studio (**Tools** -> **Create GUID**).
    The GUID will need to be placed as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.9: SonarCloud project GUID'
  prefs: []
  type: TYPE_NORMAL
- en: 'As soon as you finish the build, the result of the code analysis will be presented
    in SonarCloud, as can be seen in the following screenshot. If you want to navigate
    to this project, you can visit [https://sonarcloud.io/summary/overall?id=gabrielbaptista_wwtravelclub-4th](https://sonarcloud.io/summary/overall?id=gabrielbaptista_wwtravelclub-4th):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Tela de computador com jogo  Descrição gerada automaticamente](img/B19820_21_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.10: SonarCloud results'
  prefs: []
  type: TYPE_NORMAL
- en: Also, by this time, the code analyzed is not yet in the release, so this can
    be useful for getting the next step of quality before releasing your system. You
    can use this approach as a reference for automating code analysis during committal.
  prefs: []
  type: TYPE_NORMAL
- en: Considering we have implemented a way to continuously evaluate code quality,
    it is time to design reusable software. Let’s look at this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Reusing code as a fast way to deliver good and safe software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we checked in *Chapter 5, Implementing Code Reusability in C# 12*, a good
    approach for accelerating the delivery of good software is creating reusable components.
    The final design of the solution for evaluating content for WWTravelClub can be
    checked in the diagram below. This approach consists of using many topics that
    were discussed in that chapter. First, all the code is placed in a .NET 8 class
    library. This means that you can add this code to different types of solutions,
    such as ASP.NET Core web apps and Xamarin apps for the Android and iOS platforms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagrama  Descrição gerada automaticamente](img/B19820_21_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.11: WWTravelClub reuse approach'
  prefs: []
  type: TYPE_NORMAL
- en: This design makes use of object-oriented principles such as inheritance, so
    you do not need to write properties and methods more than once that can be used
    in many classes. The design also makes use of the polymorphism principle so that
    you can change the behavior of the code without changing the name of the method.
  prefs: []
  type: TYPE_NORMAL
- en: To finish, the design abstracts the idea of the content by introducing generics
    as a tool that can facilitate the manipulation of similar classes, such as the
    ones we have in WWTravelClub, to evaluate content regarding cities, comments,
    destination experts, and travel packages.
  prefs: []
  type: TYPE_NORMAL
- en: The big difference between a team that incentivizes code reuse and one that
    does not is the velocity of delivering good software to end users. Of course,
    beginning this approach is not easy, but rest assured that you will get good results
    after some time working with it.
  prefs: []
  type: TYPE_NORMAL
- en: Since we have covered the possibilities of code reuse using object-oriented
    principles, what about organizing the application using domains created by **domain-driven
    design** (**DDD**)? We will check it in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the domains of the WWTravelClub application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section we will perform the DDD analysis of the WWTravelClub system,
    trying to identify all its domains (also called **bounded contexts**), that is,
    the subsystems characterized by different languages used by the experts. Once
    identified, each domain might be assigned to a different development team and
    will give rise to a different microservice.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the requirements listed in the *Introducing World Wild Travel Club* and
    *U**ser needs and system requirements* sections, we know that the WWTravelClub
    system is composed of the following parts:'
  prefs: []
  type: TYPE_NORMAL
- en: Information about the available destinations and packages.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reservation/purchase orders subsystem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communication with the experts/review subsystem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Payment subsystem. We briefly analyzed the features of this subsystem and its
    relationship with the reservation purchase subsystem at the beginning of *Chapter
    7*, in the *Understanding DDD* section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User accounts subsystem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistics reporting subsystem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Do the preceding subsystems represent different bounded contexts? Can some
    subsystems be split into different bounded contexts? The answers to these questions
    are given by the languages that are spoken in each subsystem:'
  prefs: []
  type: TYPE_NORMAL
- en: The language that’s spoken in subsystem 1 is the language of **travel agencies**.
    There is no concept of a customer, just of locations, packages, and their features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The language that’s spoken in subsystem 2 is common to all service purchases,
    such as the available resources, reservations, and purchase orders. This is a
    separate bounded context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The language that’s spoken in subsystem 3 has a lot in common with subsystem
    1’s language. However, there are also typical **social media** concepts, such
    as ratings, chats, post sharing, media sharing, and so on. This subsystem can
    be split into two parts: a social media subsystem that has a new Bounded Context
    and an available information subsystem that is part of the Bounded Context of
    subsystem 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we pointed out in the *Understanding DDD* section in *Chapter 7*, in subsystem
    4, we speak the language of **banking**. This subsystem communicates with the
    reservation purchase subsystem and executes tasks that are needed to carry out
    a purchase. From these observations, we can see that it is a different Bounded
    Context and has a customer/supplier relationship with the purchase/reservation
    system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subsystem 5 is a separate Bounded Context (as in almost all web applications).
    It has a relationship with all the bounded contexts that have either the concept
    of a user or the concept of a customer because the concept of user accounts always
    maps to these concepts. You must be wondering how. Well, it’s quite simple—the
    currently logged-in user is assumed to be the social media user of the social
    media bounded context, the customer of the reservation/purchase bounded context,
    and the payer of the payment Bounded Context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The query-only subsystem (that is, 6) speaks the language of analytics and statistics
    and differs a lot from the languages that are spoken in the other subsystems.
    However, it has a connection with almost all the bounded contexts since it takes
    all its input from them. The preceding constraints force us to adopt CQRS in its
    strong form, thereby considering it a query-only separated Bounded Context.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, each of the listed subsystems defines a different Bounded Context,
    but part of the communication with the experts/review subsystem must be included
    in the information about the available destinations, and the package’s Bounded
    Context.
  prefs: []
  type: TYPE_NORMAL
- en: As the analysis continues and a prototype is implemented, some bounded contexts
    may split and some others may be added, but it is fundamental to immediately start
    modeling the system and to immediately start analyzing the relationships among
    the bounded contexts with the partial information we have since this will drive
    further investigations and will help us define the communication protocols and
    ubiquitous languages that are needed so that we can interact with the domain experts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a basic first sketch of the domain map:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.12: WWTravelClub domain map. Thin black arrows represent data exchanged
    between bounded contexts, while thick blue arrows represent the relationships
    between bounded contexts (conformist, customer/supplier, and so on)'
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we’ve omitted the **Statistics reporting** bounded context.
    We say just that it collects statistics on the daily purchases of each package.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we’re assuming that the **User accounts** and **Social** bounded contexts
    have a **conformist** relationship with all the other counded contexts that communicate
    with them because they are implemented with already existing software, so all
    the other components must adapt to them.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, the relationship between **Reservation** and **Payments**
    is **customer/supplier** because **Payments** provides services that are used
    to execute the tasks of **Reservation**. All the other relationships are classified
    as **partners**. The various concepts of customer/user that most bounded contexts
    have are coordinated by the **User accounts** **Authorization token** arrow, which
    indirectly takes care of mapping these concepts between all the counded contexts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Packages/locations** subsystem communicates the following information
    to **Reservation**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Chosen package info**, which contains the package information that’s needed
    to carry out a reservation/purchase'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Price changes**, which takes care of informing pending purchase orders of
    possible price changes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social interactions are started from an existing review provided by users (the
    **Reviews** arrow between **Packages/locations** and **Social**) and are supported
    by **Location/review info** communications from **Packages/locations** to **Social**.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, **Reservation** communicates purchase codes, descriptions, and prices
    to **Payments** through the **Prices/codes/descriptions** arrow.
  prefs: []
  type: TYPE_NORMAL
- en: Having identified our application’s bounded contexts, we are in a position to
    organize the application DevOps cycle.
  prefs: []
  type: TYPE_NORMAL
- en: The WWTravelClub DevOps approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During *Chapter 8, Understanding DevOps Principles and CI/CD*, screenshots from
    the WWTravelClub project showed the steps needed to implement a good DevOps cycle.
    The WWTravelClub team has decided to use Azure DevOps because they understand
    that the tool is essential for getting the best DevOps experience for the whole
    cycle. In fact, it appears the most complete of the tools offered by GitHub, since
    it covers the whole CI/CD cycle from requirements collection to deployment in
    staging and production. Moreover, all team members already know it very well.
  prefs: []
  type: TYPE_NORMAL
- en: The requirements were written using user stories, which can be found in the
    **Work items** section of Azure DevOps. The code is placed in the repository of
    the Azure DevOps project. Both concepts were explained in *Chapter 3*, *Managing
    Requirements*.
  prefs: []
  type: TYPE_NORMAL
- en: The management life cycle used for getting things done is Scrum, presented in
    *Chapter 1*, *Understanding the Importance of Software Architecture*. This approach
    divides the implementation into sprints, which forces value to be delivered by
    the end of each cycle. Using the CI facilities we learned in this chapter, code
    will be compiled each time the team merges new code into the master branch of
    the repository.
  prefs: []
  type: TYPE_NORMAL
- en: Once the code is compiled and tested, the first stage of the deployment is done.
    The first stage is normally named development/test because you enable it for internal
    tests. Both Application Insights and Test and Feedback can be used to get the
    first feedback on the new release.
  prefs: []
  type: TYPE_NORMAL
- en: If the tests and the feedback of the new release pass, it is time to go to the
    second stage, quality assurance. Application Insights and Test and Feedback can
    be used again, but now in a more stable environment.
  prefs: []
  type: TYPE_NORMAL
- en: The cycle ends with the authorization to deploy in the production stage. This
    certainly is a tough decision, but DevOps indicates that you must do it continuously
    so you can get better feedback from customers. Application Insights keeps being
    a useful tool since you can monitor the evolution of the new release in production,
    even comparing it to past releases.
  prefs: []
  type: TYPE_NORMAL
- en: The WWTravelClub project approach described here can be used in many other modern
    application development life cycles. As a software architect, you must oversee
    the process. The tools are ready to go, and it depends on you to make things right!
  prefs: []
  type: TYPE_NORMAL
- en: 'For this reason, even considering WWTravelClub as a hypothetical scenario,
    some concerns were considered while building it:'
  prefs: []
  type: TYPE_NORMAL
- en: CI is enabled, but a multi-stage scenario is enabled too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even with a multi-stage scenario, the **PR** (**Pull Request**) is a way to
    guarantee that only good-quality code will be presented in the first stage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To do a good job in the PR, peer reviews are undertaken.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The peer reviews check, for instance, the presence of a feature flag while creating
    a new feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The peer reviews check both unit and functional tests developed during the creation
    of the new feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding steps are not exclusively for WWTravelClub. You, as a software
    architect, will need to define the approach to guarantee a safe CI/CD scenario.
    You may use this as a starting point. It is worth pointing out that both in Azure
    DevOps and GitHub, we can completely disable pushing on the master branch, thus
    forcing the usage of PR for merging modifications on the master branch.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will start with the actual code, by showing how to choose
    among various data storage options.
  prefs: []
  type: TYPE_NORMAL
- en: How to choose your data storage in the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In *Chapter 12*, *Choosing Your Data Storage in the Cloud,* we learned how
    to use NoSQL. Now we must decide whether NoSQL databases are adequate for our
    book use case WWTravelClub application. We need to store the following families
    of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Information about available destinations and packages**: Relevant operations
    for these data are reads since packages and destinations do not change very often.
    However, they must be accessed as fast as possible from all over the world to
    ensure a pleasant user experience when users browse the available options. Therefore,
    a distributed relational database with geographically distributed replicas is
    possible but not necessary since packages can be stored inside their destinations
    in a cheaper NoSQL database.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Destination reviews**: In this case, distributed write operations have a
    non-negligible impact. Moreover, most writes are additions since reviews are not
    usually updated. Additions benefit a lot from sharding and do not cause consistency
    issues like updates do. Accordingly, the best option for this data is a NoSQL
    collection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reservations**: In this case, consistency errors are not acceptable because
    they may cause overbooking. Reads and writes have a comparable impact, but we
    need reliable transactions and good consistency checks. Luckily, data can be organized
    in a multi-tenant database where tenants are destinations since reservation information
    belonging to different destinations is completely unrelated. Accordingly, we may
    use sharded Azure SQL Database instances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, the best option for data in the first and second bullet points
    is Cosmos DB, while the best option for the third point is Azure SQL Server. Actual
    applications may require a more detailed analysis of all data operations and their
    frequencies. In some cases, it is worth implementing prototypes for various possible
    options and executing performance tests with typical workloads on all of them.
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this section, we will migrate the destinations/packages
    data layer we looked at in *Chapter 13*, *Interacting with Data in C# – Entity
    Framework Core*, to Cosmos DB.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the destinations/packages database with Cosmos DB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s move on to the database example we built in *Chapter 13*, *Interacting
    with Data in C# – Entity Framework Core*, and implement this database with Cosmos
    DB by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to make a copy of the WWTravelClubDB project and rename its root
    folder as `WWTravelClubDBCosmo`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the project and delete the `Migrations` folder since migrations are not
    required anymore.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We need to replace the SQL Server Entity Framework provider with the Cosmos
    DB provider. To do this, go to **Manage NuGet Packages** and uninstall the `Microsoft.EntityFrameworkCore.SqlServer`
    NuGet package. Then, install the `Microsoft.EntityFrameworkCore.Cosmos` NuGet
    package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, do the following on the `Destination` and `Package` entities:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Remove all data annotations.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Add the `[Key]` attribute to their `Id` properties since this is obligatory
    for Cosmos DB providers.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Transform the type of the `Id` properties of both `Package` and `Destination`
    and the `PackagesListDTO` classes from `int` to `string`. We also need to turn
    the `DestinationId` external references in `Package` and in the `PackagesListDTO`
    classes into `string`. In fact, the best option for keys in distributed databases
    is a string generated from a GUID, because it is hard to maintain an identity
    counter when table data is distributed among several servers.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the `MainDBContext` file, we need to specify that packages related to a
    destination must be stored inside the destination document itself. This can be
    achieved by replacing the **Destination-Package** relation configuration in the
    `OnModelCreating` method with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we must replace `HasMany` with `OwnsMany`. There is no equivalent to `WithOne`
    since once an entity is owned, it must have just one owner, and the fact that
    the `MyDestination` property contains a pointer to the father entity is evident
    from its type. Cosmos DB also allows the use of `HasMany`, but in this case, the
    two entities are not nested one in the other. There is also an `OwnOne` configuration
    method for nesting single entities inside other entities.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both `OwnsMany` and `OwnsOne` are available for relational databases, but in
    this case, the difference between `HasMany` and `HasOne` is that children entities
    are automatically included in all queries that return their father entities, with
    no need to specify an `Include` LINQ clause. However, child entities are still
    stored in separate tables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`LibraryDesignTimeDbContextFactory` must be modified to use Cosmos DB connection
    data, as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, in our test console, we must explicitly create all entity principal
    keys using GUIDs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we call `context.Database.EnsureCreated()` instead of applying migrations
    since we only need to create the database. Once the database and collections have
    been created, we can fine-tune their settings from the Azure portal. Hopefully,
    future versions of the Cosmos DB Entity Framework Core provider will allow us
    to specify all collection options.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, the final query (which starts with `context.Packages.Where...`) must
    be modified since queries can’t start with entities that are nested in other documents
    (in our case, `Packages` entities). Therefore, we must start our query from the
    unique root `DbSet<T>` property we have in our `DBContext`, that is, `Destinations`.
    We can move from listing the external collection to listing all the internal collections
    with the help of the `SelectMany` method, which performs a logical merge of all
    nested `Packages` collections. However, since Cosmos DB SQL doesn’t support `SelectMany`,
    we must force `SelectMany` to be simulated on the client with `AsEnumerable()`,
    as shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The remainder of the query remains unchanged. If you run the project now, you
    should see the same outputs that were received in the case of SQL Server (except
    for the primary key values).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After executing the program, go to your Cosmos DB account. You should see something
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing table  Description automatically generated](img/B19820_21_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.13: Execution results'
  prefs: []
  type: TYPE_NORMAL
- en: The packages have been nested inside their destinations as required and Entity
    Framework Core creates a unique collection that has the same name as the `DBContext`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you would like to continue experimenting with Cosmos DB development without
    wasting all your free Azure portal credit, you can install the Cosmos DB emulator,
    available at this link: [https://aka.ms/cosmosdb-emulator](https://aka.ms/cosmosdb-emulator).'
  prefs: []
  type: TYPE_NORMAL
- en: Having learned how to choose the best options for data storage, we are in a
    position to start coding our first microservice.
  prefs: []
  type: TYPE_NORMAL
- en: A worker microservice with ASP.NET Core
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will show you how to implement a microservice that receives
    communications through gRPC and an internal queue based on a database table. The
    first subsection briefly describes the microservice specifications and the overall
    architecture. You are encouraged to review *Chapter 14*, *Implementing Microservices
    with .NET,* which contains all the theory behind this example.
  prefs: []
  type: TYPE_NORMAL
- en: The specifications and architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our example microservice is required to compute the daily sums of all purchases.
    According to the data-driven approach, we suppose that all daily sums are pre-computed
    by receiving messages that are sent as soon as a new purchase is finalized. The
    purpose of the microservice is to maintain a database of all purchases and all
    daily sums that can be queried by an administrative user. We will implement just
    the functionalities needed to fill the two database tables.
  prefs: []
  type: TYPE_NORMAL
- en: The implementation described in this section is based on an ASP.NET Core application
    that hosts a gRPC service. The gRPC service simply fills a messages queue and
    immediately returns to avoid the sender remaining blocked for the whole time of
    the computation.
  prefs: []
  type: TYPE_NORMAL
- en: The actual processing is performed by an ASP.NET Core-hosted service declared
    in the dependency injection engine associated with the application host. The worker-hosted
    service executes an endless loop where it extracts `N` messages from the queue
    and passes them to `N` parallel threads that process them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.14: gRPC microservice architecture'
  prefs: []
  type: TYPE_NORMAL
- en: When the `N` messages are taken from the queue, they are not immediately removed
    but are simply marked with the extraction time. Since messages can only be extracted
    from the queue if their last extraction time is far enough ahead (say, a time
    `T`), no other worker thread can extract them again while they are being processed.
    When message processing is successfully completed, the message is removed from
    the queue. If the processing fails, no action is taken on the message, so the
    message remains blocked in the queue till the `T` interval expires, and then it
    can be picked up again by the worker thread.
  prefs: []
  type: TYPE_NORMAL
- en: The microservice can be scaled vertically by increasing the processor cores
    and the number `N` of threads. It can be scaled horizontally, too, by using a
    load balancer that splits the loads into several identical copies of the ASP.NET
    Core application. This kind of horizontal scaling increases the number of threads
    that can receive messages and the number of worker threads, but since all ASP.NET
    Core applications share the same database, it is limited by database performance.
  prefs: []
  type: TYPE_NORMAL
- en: The database layer is implemented in a separate **DLL** (**Dynamic Link Library)**
    and all functionalities are abstracted in two interfaces, one for interacting
    with the queue and another for adding a new purchase to the database.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection briefly describes the database layer. We will not give all
    the details since the main focus of the example is the microservice architecture
    and the communication technique. However, the full code is available in the `ch15/GrpcMicroService`
    folder of the GitHub repository associated with the book.
  prefs: []
  type: TYPE_NORMAL
- en: Having defined the overall architecture, let’s start with the storage layer
    code.
  prefs: []
  type: TYPE_NORMAL
- en: The storage layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The storage layer is based on a database. It uses Entity Framework Core and
    is based on three entities with their associated tables:'
  prefs: []
  type: TYPE_NORMAL
- en: A `QueueItem` entity that represents a queue item
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `Purchase` entity that represents a single purchase
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A `DayTotal` entity that represents the total of all purchases performed in
    a given day
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Below is a definition of the interface that manipulates the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`Top` extracts the `N` messages to pass to a maximum of `N` different threads.
    `Enqueue` adds a new message to the queue. Finally, `Dequeue` removes the items
    that have been successfully processed from the queue.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The interface that updates the purchase data is defined as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '`Add` adds a new purchase to the database. It returns the input queue item
    if the addition is successful, and `null` otherwise. `DayTotal` is a query method
    that returns a single day total.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The application layer communicates with the database layer through these two
    interfaces, through the three database entities, through the `IUnitOfWork` interface
    (which, as explained in the *How data and domain layers communicate with other
    layers* section of *Chapter 13*, *Interacting with Data in C# – Entity Framework
    Core* abstracts the `DbContext`), and through a dependency injection extension
    method like the one below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This method, which will be called in the application layer dependency injection
    definition, receives as input the database connection string and adds the `DbContext`
    abstracted with `IUnitOfWork`, with the two interfaces we defined before.
  prefs: []
  type: TYPE_NORMAL
- en: 'The database project, called `GrpcMicroServiceStore`, is contained in the `ch15/GrpcMicroService`
    folder of the GitHub repository associated with the book. It already contains
    all the necessary database migrations, so you can create the needed database with
    the steps below:'
  prefs: []
  type: TYPE_NORMAL
- en: In the Visual Studio **Package Manager Console**, select the **GrpcMicroServiceStore**
    project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In Visual Studio **Solution Explorer**, right-click on the **GrpcMicroServiceStore**
    project and set it as the startup project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Visual Studio **Package Manager Console**, issue the `Update-Database`
    command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Having a working storage layer, we can proceed with the microservices application
    layer.
  prefs: []
  type: TYPE_NORMAL
- en: The application layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The application layer is an **ASP.NET Core gRPC service** project called `GrpcMicroService`.
    When the project is scaffolded by Visual Studio, it contains a `.proto` file in
    its `Protos` folder. This file needs to be deleted and replaced by a file called
    `counting.proto`, whose content must be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The above code defines the gRPC service with its input and output messages and
    the .NET namespace where you place them. We import the `google/protobuf/timestamp.proto`
    predefined `.proto` file because we need the `TimeStamp` type. The request contains
    purchase data, the `time` when the request message was created, and a unique message
    `id` that is used to force message idempotency.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the database layer, the implementation of the `IDayStatistics.Add` method
    uses this `id` to verify if a purchase with the same `id` has already been processed,
    in which case it returns immediately:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Automatic code generation for this file is enabled by replacing the existing
    `protobuf` XML tag with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `Grpc` attribute set to `"Server"` enables server-side code generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `Services` project folder, the predefined gRPC service scaffolded by
    Visual Studio must be replaced with a file named `CounterService.cs` with the
    content below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The actual service that receives the purchase messages inherits from the `Counter.CounterBase`
    abstract class created by the code generator from the `counting.proto` file. It
    receives the database layer interface `IMessageQueue` using dependency injection
    and overrides the abstract `Count` method inherited from `Counter.CounterBase`.
    Then, `Count` uses `IMessageQueue` to enqueue each received message.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before compiling, a few other steps are necessary:'
  prefs: []
  type: TYPE_NORMAL
- en: We must add a reference to the database-layer `GrpcMicroServiceStore` project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We must add the database connection string to the `appsettings.json` setting
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We must add all the necessary database-layer interfaces to the dependency injection
    by calling the `AddStorage` database layer extension method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In `Program.cs`, we must remove the declaration of the gRPC service scaffolded
    by Visual Studio, and we must replace it with:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: At this point, compilation should succeed. Having completed the application-layer
    infrastructure, we can move to the hosted service that performs the actual queue
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: Processing the queued requests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The actual request processing is performed by a worker-hosted service that
    runs in parallel with the ASP.NET Core pipeline. It is implemented with the hosted
    services we discussed in the *Using generic hosts* section of *Chapter 11*, *Applying
    a Microservice Architecture to Your Enterprise Application*. It is worth recalling
    that hosted services are implementations of the `IHostedService` interface defined
    in the dependency injection engine as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We already described how to implement hosted services for the implementation
    of ASP.NET Core-based worker microservices in the *Implementing worker microservices
    with ASP.NET Core* section of *Chapter 14, Implementing Microservices with .NET*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below, we repeat the whole code with all details that are specific to our example.
    The hosted service is defined in the `ProcessPurchases.cs` file placed in the
    `HostedServices` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Below is the content of the inner loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The above code was already explained in the *Implementing worker microservices
    with ASP.NET Core* section of *Chapter 14, Implementing Microservices with .NET*.
    Therefore, here, we will analyze just the `toExecute` lambda that is specific
    to our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Each task creates a different session scope so it can have a private copy of
    `IDayStatistics`, and then processes its request with `statistics.Add`.
  prefs: []
  type: TYPE_NORMAL
- en: That’s all! Now we need a source of purchase data to test our code. In the next
    subsection, we will create a fake microservice that randomly creates purchase
    data and passes it to the `Counter` `gRPC` service.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the GrpcMicroservice project with a fake purchase requests generator
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s implement another microservice that feeds the previous microservice with
    randomly generated requests. The right project for a worker service that is not
    based on ASP.NET Core is the **Worker Service** project template. This project
    template automatically scaffolds a host containing a unique hosted service called
    `Worker`. We called this project `FakeSource`. In order to enable gRPC client
    usage, we must add the following NuGet packages: `Google.Protobuf`, `Grpc.NET.Client`,
    and `Grpc.Tools`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we must add the same `counting.proto` file as was added to the previous
    project. However, this time, we must require client code generation by placing
    the code below in the `FakeSource` project file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The `GrpcServices` attribute set to `Client` is what enables client code generation
    instead of server code generation. The `link` tag appears since we added the same
    `counting.proto` file of the `GrpcMicroService` project as a link instead of copying
    it into the new project.
  prefs: []
  type: TYPE_NORMAL
- en: 'The hosted service is defined with the usual endless loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The `locations` array contains locations that will be randomly selected. As
    soon as the `ExecuteAsync` method starts, it creates the `Random` instance that
    will be used in all random generations.
  prefs: []
  type: TYPE_NORMAL
- en: Each loop is enclosed in a `try`/`catch`; if an `OperationCanceledException`
    is generated, the method exits, since a similar exception is created when the
    application is being shut down and the thread is killed. In the case of other
    exceptions, the code tries to recover by simply moving to the next loop. In an
    actual production application, the final `catch` should contain instructions to
    log the intercepted exception and/or instructions for a better recovery strategy.
    In the next example, we will see more sophisticated exception handling that is
    adequate for actual production applications.
  prefs: []
  type: TYPE_NORMAL
- en: Inside the `try`, the code creates a purchase message, sends it to the `Counter`
    service, and then sleeps for 2 seconds.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below is the code that sends the requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The code just prepares the message with random data; then, it creates a communication
    channel for the gRPC server address and passes it to the constructor of the `Counter`
    service proxy. Finally, the `Count` method is called on the proxy. The call is
    enclosed in a `try`/`catch`, and in the case of an error, the error is simply
    ignored, since we are just sending random data. Instead, an actual production
    application should use **Polly** to retry the communication with predefined strategies.
    **Polly** was described in the *Resilient task execution* section of *Chapter
    11*, *Applying a Microservice Architecture to Your Enterprise Application*. We
    will show you how to use **Polly** in the example in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: And there you have it! Now it is time to test everything. Right-click on the
    solution and select **Set Startup Projects**, then set both `FakeSource` and `GrpcMicroService`
    to start. This way, both projects will be launched simultaneously when the solution
    is run.
  prefs: []
  type: TYPE_NORMAL
- en: Launch Visual Studio and then let both processes run for a couple of minutes,
    then go to **SQL Server Object Explorer** and look for a database called `grpcmicroservice`.
    If the **SQL Server Object Explorer** window is not available in the left menu
    of Visual Studio, go to the top **Window** menu and select it.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have located the database, show the content of the `DayTotals` and
    `Purchases` tables. You should see all computed daily sums and all processed purchases.
  prefs: []
  type: TYPE_NORMAL
- en: You can also inspect what happens in the server project by opening the `HostedServices/ProcessPurchases.cs`
    file and placing breakpoints on the `queue.Top(10)` and `await` `queue.Dequeue(...)`
    instructions.
  prefs: []
  type: TYPE_NORMAL
- en: You can also move `FakeSource` into a different Visual Studio solution so that
    you can simultaneously run several copies of `FakeSource` each in a different
    Visual Studio instance. It is also possible to double-click on the `FakeSource`
    project, which gives the option to save a new Visual Studio solution containing
    just a reference to the `FakeSource` project.
  prefs: []
  type: TYPE_NORMAL
- en: The full code is in the `GrpcMicroService` subfolder of the `ch15` folder of
    the book’s GitHub repository. The next section shows you how to solve the same
    problem with queued communication using the RabbitMQ message broker.
  prefs: []
  type: TYPE_NORMAL
- en: A worker microservice based on RabbitMQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section explains the modifications needed to use a message broker instead
    of gRPC communication with an internal queue. This kind of solution is usually
    more difficult to test and design but allows for better horizontal scaling, and
    also enables extra features at almost no cost since they are offered by the message
    broker itself.
  prefs: []
  type: TYPE_NORMAL
- en: We assume that RabbitMQ has already been installed and adequately prepared,
    as explained in the *Installing RabbitMQ core* subsection of *Chapter 14, Implementing
    Microservices with .NET*.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the ASP.NET Core project must be replaced by another **Worker Service**
    project. Also, this project must add the connection string to its configuration
    file and must call the `AddStorage` extension method to add all the database services
    to the dependency injection engine. Below is the full content of the `Program.cs`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We don’t need the gRPC services and service proxies anymore, just ProtoBuf
    for the binary messages, so both the `FakeSource` process and the `GrpcMicroService`
    projects must add just the `Google.Protobuf` and `Grpc.Tools` NuGet packages.
    Both projects need the following `messages.proto` file, which defines just the
    purchase message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The automatic generation of the message classes is enabled in both projects
    with the same XML declaration in their project files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Both projects need to specify `Client` code generation since no service needs
    to be created.
  prefs: []
  type: TYPE_NORMAL
- en: To communicate with the RabbitMQ server, both projects must add the `RabbitMQ.Client`
    NuGet package.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `FakeSource` also adds the `Polly` `NuGet` package because we will
    use Polly to define reliable communication strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ExecuteAsync` method of the client project is a little bit different:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Communication requires the creation of a connection factory, then the creation
    factory generates a connection, and the connection generates a channel. The connection
    factory is created outside of the main loop since it can be reused several times,
    and it is not invalidated by communication errors.
  prefs: []
  type: TYPE_NORMAL
- en: For the connection and channel, outside of the main loop, we just define the
    variables and where to place them since they are invalidated in the case of communication
    exceptions, so we must dispose of them and recreate them from scratch after each
    exception.
  prefs: []
  type: TYPE_NORMAL
- en: The main loop is enclosed in `try`/`finally` to ensure that any channel/connection
    pair is disposed of before leaving the method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the main loop, as a first step, we create the purchase message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the message is serialized:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Before executing the communication, we define a Polly policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The above policy is an exponential retry, which, in the case of an exception,
    waits for an exponentially growing amount of time. So, if six attempts are made,
    then the second attempt is made after 2 seconds, the third after 4 seconds, the
    fourth after 8 seconds, and so on. If all attempts fail, the exception is rethrown
    and causes the message to be lost. If it’s important that messages can’t be lost,
    we can combine this strategy with a circuit break strategy (see *Resilient task
    execution* in *Chapter 11*, *Applying a Microservice Architecture to Your Enterprise
    Application*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have defined the retry policy, we can execute all the communication
    steps in the context of this policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If there are no valid connections or channels, they are created. `channel.ConfirmSelect()`
    declares that we need confirmation that the message was safely received and stored
    on disk. In the case that an exception is thrown, both the channel and the connection
    are disposed of, since they might have been corrupted by the exception. This way,
    the next communication attempt will use fresh communication and a new channel.
    After the disposal, the exception is rethrown so it can be handled by the Polly
    policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, here are the actual communication steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, if the queue doesn’t already exist, it is created. The queue
    is created as `durable`; that is, it must be stored on disk and not be `exclusive`
    so that several servers can extract messages from the queue in parallel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, each message is declared as persistent; that is, it must be stored on
    disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, the message is sent through the default exchange, which sends it to
    a specific named queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As a final step, we wait until the message is safely stored on disk:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If a confirmation doesn’t arrive within the specified timeout, an exception
    is thrown that triggers the Polly retry policy. When messages are taken from a
    local database queue, we can also use a non-blocking confirmation that triggers
    the removal of the message from the local queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ExecuteAsync` method of the server-hosted process is defined in the `HostedServices/ProcessPurchase.cs`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Inside the main loop, if an exception is thrown, it is intercepted by the empty
    `catch`. Since the two `using` statements are left, both the connection and channel
    are disposed of. Therefore, after the exception, a new loop is executed that creates
    a new fresh connection and a new channel.
  prefs: []
  type: TYPE_NORMAL
- en: In the `using` statement body, we ensure that our queue exists, and then set
    `prefetch` to `1`. This means that each server must extract just one message at
    a time, which ensures a fair distribution of the load among all servers. However,
    setting `prefetch` to `1` might not be convenient when servers are based on several
    parallel threads since it sacrifices thread usage optimization in favor of fair
    distribution among servers. As a consequence, threads that could successfully
    process further messages (after the first) might remain idle.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we define a `message received` event handler. `BasicConsume` starts the
    actual message reception. With `autoAck` set to `false`, when a message is read
    from the queue, it is not removed but just blocked so it is not available to other
    servers that read from the same queue. The message is actually removed when a
    confirmation that it has been successfully processed is sent to RabbitMQ. We can
    also send a failure confirmation, in which case, the message is unblocked and
    becomes available for processing again.
  prefs: []
  type: TYPE_NORMAL
- en: If no confirmation is received, the message remains blocked till the connection
    and channel are disposed of.
  prefs: []
  type: TYPE_NORMAL
- en: '`BasicConsume` is non-blocking, so the `Task.Delay` after it blocks till the
    cancelation token is signaled. In any case, after 1 second, `Task.Delay` unblocks
    and both the connection and the channel are replaced with fresh ones. This prevents
    non-confirmed messages from remaining blocked forever.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to the code inside the *message received* event. This is the place
    where the actual message processing takes place.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, the code verifies if the application is being shut down, in
    which case it disposes of the channel and connection and returns without performing
    any further operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, a session scope is created to access all session-scoped dependency injection
    services:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: When an exception is thrown during the message processing, a `Nack` message
    is sent to RabbitMQ to inform it that the message processing failed. `ea.DeliveryTag`
    is a tag that uniquely identifies the message. The second argument set to `false`
    informs RabbitMQ that the `Nack` is just for the message identified by `ea.DeliveryTag`
    that doesn’t also involve all other messages waiting for confirmation from this
    server. Finally, the last argument set to `true` asks RabbitMQ to requeue the
    message whose processing failed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the `try` block, we get an instance of `IDayStatistics`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we deserialize the message body to get a `PurchaseMessage` instance and
    add it to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If the operation fails, the `Add` operation returns `null`, so we must send
    a `Nack`; otherwise, we must send an `Ack`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: That’s all! The full code is in the `GrpcMicroServiceRabbitProto` subfolder
    of the `ch15` folder in the GitHub repository of this book. You can test the code
    by setting both the client and server projects as the start project and running
    the solution. After 1–2 minutes, the database should be populated with new purchases
    and new daily totals. In a staging/production environment, you can run several
    copies of both the client and server.
  prefs: []
  type: TYPE_NORMAL
- en: The `GrpcMicroServiceRabbit` subfolder in the `ch15` folder of the GitHub repository
    contains another version of the same application that uses the *Binaron* NuGet
    package for serialization. It is faster than ProtoBuf, but being .NET-specific,
    it is not interoperable. Moreover, it has no features to facilitate message versioning.
    It is useful when performance is critical and versioning and interoperability
    are not a priority.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *Binaron* version differs in that it has no `.proto` files or other ProtoBuf
    stuff, but it explicitly defines a `PurchaseMessage` .NET class. Moreover, ProtoBuf
    serialization and deserialization instructions are replaced by the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Together with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have created a microservice connected to a message broker, it is
    also important to learn how to expose packages from WWTravelClub using web APIs.
    Let’s see this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing WWTravelClub packages using Web APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will implement an ASP.NET REST service that lists all the
    packages that are available for a given vacation’s start and end dates. For didactic
    purposes, we will not structure the application according to the best practices
    we have described previously; instead, we will simply generate the results with
    a LINQ query that will be directly placed in the controller action method. A well-structured
    ASP.NET Core application has been presented in *Chapter 18*, *Implementing Frontend
    Microservices with ASP.NET Core*.
  prefs: []
  type: TYPE_NORMAL
- en: Let us make a copy of the `WWTravelClubDB` solution folder and rename the new
    folder `WWTravelClubWebAPI80`. The WWTravelClubDB project was built step by step
    in the various sections of *Chapter 13*, *Interacting with Data in C# – Entity
    Framework Core*. Let us open the new solution and add a new ASP.NET Core API project
    to it named `WWTravelClubWebAPI80` (the same name as the new solution folder).
    For simplicity, select **No Authentication**. Right-click on the newly created
    project and select **Set as StartUp project** to make it the default project that
    is launched when the solution is run.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we need to add a reference to the WWTravelClubDB project.
  prefs: []
  type: TYPE_NORMAL
- en: 'ASP.NET Core projects store configuration constants in the `appsettings.json`
    file. Let’s open this file and add the database connection string for the database
    we created in the WWTravelClubDB project to it, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we must add the WWTravelClubDB entity framework database context to `Program.cs`,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The option object settings that are passed to `AddDbContext` specify the usage
    of SQL Server with a connection string that is extracted from the `ConnectionStrings`
    section of the `appsettings.json` configuration file with the `Configuration.GetConnectionString("DefaultConnection")`
    method. The `b =>b.MigrationsAssembly("WWTravelClubDB")` lambda function declares
    the name of the assembly that contains the database migrations (see *Chapter 13*,
    *Interacting with Data in C# – Entity Framework Core*), which, in our case, is
    the DLL that was generated by the WWTravelClubDB project. For the preceding code
    to compile, you should add the `Microsoft.EntityFrameworkCore` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we want to enrich our REST service with OpenAPI documentation, let’s
    add a reference to the `Swashbuckle.AspNetCore` NuGet package. Now, we can add
    the following very basic configuration to `Program.cs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to encode our service. Let’s delete `WeatherForecastController`,
    which is automatically scaffolded by Visual Studio. Then, right-click on the `Controllers`
    folder and select **Add | Controller**. Now, choose an empty API controller called
    `PackagesController`. First, let’s modify the code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Route` attribute declares that the basic path for our service will be
    `api/packages`. The unique action method that we implement is `GetPackagesByDate`,
    which is invoked on `HttpGet` requests on paths of the `bydate/{start}/{stop}`
    type, where `start` and `stop` are the `DateTime` parameters that are passed as
    input to `GetPackagesByDate`. The `ProduceResponseType` attributes declare the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: When a request is successful, a 200 code is returned, and the body contains
    an `IEnumerable` of the `PackagesListDTO` type (which we will soon define) containing
    the required package information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the request is ill formed, a 400 code is returned. We don’t specify the
    type returned since bad requests are automatically handled by the ASP.NET Core
    framework through the `ApiController` attribute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of unexpected errors, a 500 code is returned with the exception
    error message.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let’s define the `PackagesListDTO` class in a new `DTOs` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s add the following `using` clauses to our controller code so
    that we can easily refer to our DTO and Entity Framework LINQ methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Now, we are ready to fill the body of the `GetPackagesByDate` method with the
    following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: It is important to remember that we are focusing only on presenting the results
    of an API exposed using the `Swashbuckle.AspNetCore` NuGet package. It is not
    a good practice to make use of the `DbContext` in a `Controller` class, and as
    a software architect, you may define the best architectural design for your application
    (multi-tier, hexagonal, onion, clean, DDD, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: The LINQ query is like the one contained in the `WWTravelClubDBTest` project
    we tested in *Chapter 13*, *Interacting with Data in C# – Entity Framework Core*.
    Once the result has been computed, it is returned with an `OK` call. The method’s
    code handles internal server errors by catching exceptions and returning a 500
    status code since bad requests are automatically handled before the `Controller`
    method is called by the `ApiController` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s run the solution. When the browser opens, it is unable to receive any
    result from our ASP.NET Core website. Let’s modify the browser URL so that it
    is `https://localhost:<previous port>/swagger`. It is worth mentioning that you
    can also configure your local settings file to either launch and go to the Swagger
    URL automatically, or have Swagger live under the root.
  prefs: []
  type: TYPE_NORMAL
- en: 'The user interface of the OpenAPI documentation will look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.15: Swagger output'
  prefs: []
  type: TYPE_NORMAL
- en: '**PackagesListDTO** is the model we defined to list the packages, while **ProblemDetails**
    is the model that is used to report errors in the event of bad requests. By clicking
    the **GET** button, we can get more details about our `GET` method and we can
    also test it, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interface gráfica do usuário, Aplicativo  Descrição gerada automaticamente](img/B19820_21_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.16: GET method details'
  prefs: []
  type: TYPE_NORMAL
- en: Pay attention when it comes to inserting dates that are covered by packages
    in the database; otherwise, an empty list will be returned. The ones shown in
    the preceding screenshot should work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Dates must be entered in a correct JSON format; otherwise, a 400 Bad Request
    error is returned, like the one shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: If you insert the correct input parameters, the Swagger UI returns the packages
    that satisfy the query in JSON format.
  prefs: []
  type: TYPE_NORMAL
- en: That is all! You have implemented your first API with OpenAPI documentation!
    Now let’s check how easy it can be to implement a serverless solution using Azure
    Functions.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Azure Functions to send emails
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here, we will use a subset of the Azure components. The use case from WWTravelClub
    proposes a worldwide implementation of the service, and there is a chance that
    this service will need different architecture designs to achieve all the key performance
    points that we described in *Chapter 1*, *Understanding the Importance of Software
    Architecture*.
  prefs: []
  type: TYPE_NORMAL
- en: If you go back to the user stories that were described in this chapter, you
    will find that many needs are related to communication. Because of this, it is
    common to have some alerts provided by emails in the solution. This implementation
    will focus on how to send emails. The architecture will be totally serverless.
    The benefits of using an architecture like that are explained below.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the basic structure of the architecture. To give
    users a great experience, all the emails that are sent by the application will
    be queued asynchronously, thereby preventing significant delays in the system’s
    responses:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19820_21_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.17: Architectural design for sending emails'
  prefs: []
  type: TYPE_NORMAL
- en: Basically, when a user does any action that requires sending an alert (1), the
    alert is posted in a **send email request function** (2), which stores the request
    in Azure Queue Storage (3). So, for the user, the alert is already performed at
    this moment, and they can keep working. However, since we have a queue, no matter
    the number of alerts sent, they will be processed by the **send email function**
    that is triggered (4) as soon as a request is made, respecting the time needed
    to process the requests, but guaranteeing that the receiver will get the alert
    (5). Note that there are no dedicated servers that manage Azure Functions for
    enqueuing or dequeuing messages from Azure Queue Storage. This is exactly what
    we call serverless, as described in *Chapter 16, Working with Serverless - Azure
    Functions*. It is worth mentioning that this architecture is not restricted to
    only sending emails – it can also be used to process any HTTP `POST` request.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will learn, in three steps, how to set up security in the API so that
    only authorized applications can use the given solution.
  prefs: []
  type: TYPE_NORMAL
- en: First step — creating an Azure queue storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is quite simple to create storage in the Azure portal. Let us learn how.
    First, you will need to create a storage account by clicking on **Create a resource**
    on the main page of the Azure portal and searching for **Storage account**. Then,
    you will be able to set up its basic information, such as **Storage account name**
    and **Location**. Information about **Networking** and **Data protection**, as
    shown in the following screenshot, can be checked in this wizard, too. There are
    default values for these settings that we will cover the demo:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.18: Creating an Azure storage account'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have the storage account in place, you will be able to set up a queue.
    You will find this option by clicking on the **Overview** link in the storage
    account and selecting the **Queue service** option or by selecting **Queues**
    via the **Storage account** menu. Then, you will find an option to add the queue
    (**+ Queue**), where you just need to provide its name:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interface gráfica do usuário, Texto, Aplicativo  Descrição gerada automaticamente](img/B19820_21_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.19: Defining a queue to monitor emails'
  prefs: []
  type: TYPE_NORMAL
- en: 'The created queue will give you an overview of the Azure portal. There, you
    will find your queue’s URL and be able to use Storage Explorer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.20: Queue created'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that you will also be able to connect to this storage using Microsoft
    Azure Storage Explorer ([https://azure.microsoft.com/en-us/features/storage-explorer/](https://azure.microsoft.com/en-us/features/storage-explorer/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.21: Monitoring the queue using Microsoft Azure Storage Explorer'
  prefs: []
  type: TYPE_NORMAL
- en: This tool is especially useful if you are not connected to the Azure portal.
    Let’s move to the second step, where we will create the function that receives
    the requests to send emails.
  prefs: []
  type: TYPE_NORMAL
- en: Second step — creating the function to send emails
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, you can start programming in earnest, informing the queue that an email
    is waiting to be sent. Here, we need to use an HTTP trigger. Note that the function
    is a static class that runs asynchronously. The following code, written in Visual
    Studio, gathers the request data coming from the HTTP trigger and inserts the
    data into a queue that will be processed later. It is worth mentioning that the
    environment variable `EmailQueueConnectionString` is set in the function app settings,
    and it contains the information provided by the Azure Queue Storage connection
    string.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have below a code snippet from the function available in the GitHub repository
    of the book:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In some scenarios, you may try to avoid the queue setup indicated in the preceding
    code by using a queue output binding. Check out the details at [https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue-output?tabs=csharp](https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue-output?tabs=csharp).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use a tool such as Postman to test your function. Before that, you
    just need to run the app in Visual Studio, which will launch Azure Functions Core
    Tools and its emulator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interface gráfica do usuário, Texto, Aplicativo  Descrição gerada automaticamente](img/B19820_21_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.22: Postman function test'
  prefs: []
  type: TYPE_NORMAL
- en: 'The result will appear in Microsoft Azure Storage Explorer and the Azure portal.
    In the Azure portal, you can manage each message and dequeue each of them or even
    clear the queue storage:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Interface gráfica do usuário, Texto, Aplicativo, Email  Descrição gerada
    automaticamente](img/B19820_21_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.23: HTTP trigger and queue storage test'
  prefs: []
  type: TYPE_NORMAL
- en: To finish this topic, let’s move on to the final third step, where we will create
    the function that will process the requests for sending emails.
  prefs: []
  type: TYPE_NORMAL
- en: Third step — creating the queue trigger function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After this, you can create a second function by right-clicking the project
    and selecting **Add -> New Azure Function**. This one will be triggered by data
    entering your queue. It is worth mentioning that, for Azure Functions v4, you
    will have the `Microsoft.Azure.WebJobs.Extensions.Storage` library added as a
    NuGet reference automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B19820_21_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.24: Creating a queue trigger'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have set the connection string inside `local.settings.json`, you will
    be able to run both functions and test them with Postman. The difference is that,
    with the second function running, if you set a breakpoint at the start of it,
    you will be able to check whether the message has been sent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Tela de computador com texto preto sobre fundo branco  Descrição gerada automaticamente](img/B19820_21_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.25: Queue triggered in Visual Studio 2022'
  prefs: []
  type: TYPE_NORMAL
- en: From this point, the way to send emails will depend on the email options you
    have. You may decide to use a proxy or connect directly to your email server.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several advantages to creating an email service this way:'
  prefs: []
  type: TYPE_NORMAL
- en: Once your service has been coded and tested, you can use it to send emails from
    any of your applications. This means that your code can always be reused.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apps that use this service will not be stopped from sending emails due to the
    asynchronous advantages of posting in an HTTP service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You do not need to pool the queue to check whether data is ready for processing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the queue process runs concurrently, which delivers a better experience
    in most cases. It is possible to turn it off by setting some properties in `host.json`.
    All the options for this can be found in the *Further reading* section at the
    end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In this part of the case study, we checked an example of an architecture where
    you connect multiple functions to avoid pooling data and enable concurrent processing.
    We have seen with this demo how great the fit between serverless and event-driven
    architecture is.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s change the subject a bit, and discuss how to implement a frontend
    microservice.
  prefs: []
  type: TYPE_NORMAL
- en: A frontend microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, as an example of an ASP.NET Core MVC frontend microservice
    described in *Chapter 18, Implementing Frontend Microservices with ASP.NET Core*,
    we will implement the administrative panel for managing the destinations and packages
    of the `WWTravelClub` book use case. The application will be implemented with
    theDDDapproach and associated patterns described in *Chapter 7*, *Understanding
    the Different Domains in Software Solutions*. So, having a good understanding
    of that chapter is a fundamental prerequisite to reading this chapter. The subsections
    that follow describe the overall application specifications and organization.
    The full code of the example can be found in the `ch19` folder of the GitHub repository
    associated with the book.
  prefs: []
  type: TYPE_NORMAL
- en: As usual, let’s start by stating clearly our frontend microservice specifications.
  prefs: []
  type: TYPE_NORMAL
- en: Defining application specifications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The destinations and packages were described in *Chapter 13*, *Interacting
    with Data in C# – Entity Framework Core*. Here, we will use the same data model,
    with the necessary modifications to adapt it to the DDD approach. The administrative
    panel must allow packages, a destination listing, and CRUD operations on it. To
    simplify the application, the two listings will be quite simple: the application
    will show all destinations sorted according to their names, while all packages
    will be sorted starting from the ones with a later validity date.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, we make the following assumptions:'
  prefs: []
  type: TYPE_NORMAL
- en: The application that shows destinations and packages to the user shares the
    same database used by the administrative panel. Since only the administrative
    panel application needs to modify data, there will be just one write copy of the
    database with several read-only replicas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Price modifications and package deletions are immediately used to update the
    user’s shopping carts. For this reason, the administrative application must send
    asynchronous communications about price changes and package removals. We will
    not implement all the communication logic here, but we will just add all such
    events to an event table, which should be used as input to a parallel thread that’s
    in charge of sending these events to all relevant microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, we will give the full code for just package management; most of the code
    for destination management is designed as an exercise for you. The full code is
    available in the `ch16` folder of the GitHub repository associated with this book.
    In the remainder of this section, we will describe the application’s overall organization
    and discuss some relevant samples of code. We start with an overall description
    of the application architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the application architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The application is organized based on the guidelines described in *Chapter
    7*, *Understanding the Different Domains in Software Solutions*, while considering
    the DDD approach and related patterns. That is, the application is organized into
    three layers, each implemented as a different project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s a domain implementation layer, which contains the repository’s implementation
    and the classes describing database entities. It is a .NET library project. However,
    since it needs some interfaces, like `IServiceCollection`, which are defined in
    `Microsoft.NET.Sdk.web`, and since the layer `DBContext` must inherit from the
    identity framework in order to also handle the application authentication and
    authorization database tables, we must add a reference not only to the .NET SDK
    but also to the ASP.NET Core SDK. This can be done as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Right-click on the project icon in Solution Explorer and select **Edit project
    file**, or just double-click the project name.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the **Edit** window, add:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
- en: There’s also a domain layer abstraction, which contains repository specifications
    – that is, interfaces that describe repository implementations and DDD aggregates.
    In our implementation, we decided to implement aggregates by hiding the forbidden
    operations/properties of root data entities behind interfaces. Hence, for instance,
    the `Package` entity class, which is an aggregate root, has a corresponding `IPackage`
    interface in the domain layer abstraction that hides all the property setters
    of the `Package` entity. The domain layer abstraction also contains the definitions
    of all the domain events, while the event handlers that will subscribe to these
    events are defined in the application layer. `IPackage` has also the associated
    `IPackageRepository` repository interface.
  prefs: []
  type: TYPE_NORMAL
- en: All repository interfaces inherit from the empty `IRepository` interface.
  prefs: []
  type: TYPE_NORMAL
- en: This way, they declare it as a repository interface, and all repository interfaces
    can be automatically discovered with reflection and added to the dependency injection
    engine together with their implementations.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, there’s the application layer – that is, the ASP.NET Core MVC application
    – where we define DDD queries, commands, command handlers, and event handlers.
    Controllers fill query objects and execute them to get ViewModels they can pass
    to Views. They update storage by filling command objects and executing their associated
    command handlers. In turn, command handlers use `IRepository` interfaces (that
    is, interfaces that inherit from the empty `IRepository` interface) and `IUnitOfWork`
    instances coming from the domain layer to manage and coordinate transactions.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth pointing out that, in more complex microservices, the application
    layer may be implemented as a separate library project and would contain just
    DDD queries, commands, command handlers, and event handlers. While, the MVC project
    would contain just controllers, UIs, and dependency injection.
  prefs: []
  type: TYPE_NORMAL
- en: The application uses the **Command Query Responsibility Segregation** (**CQRS**)
    pattern; therefore, it uses command objects to modify the storage and the query
    object to query it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The query is simple to use and implement: controllers fill their parameters
    and then call their execution methods. In turn, query objects have direct LINQ
    implementations that project results directly onto the ViewModels used by the
    controller Views with `Select` LINQ methods. You may also decide to hide the LINQ
    implementation behind the same repository classes used for the storage update
    operations, but this would turn the definition and modification of simple queries
    into very time-consuming tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: In any case, it can be beneficial to encapsulate query objects behind interfaces
    so that their implementations can be replaced by fake implementations when you
    test controllers.
  prefs: []
  type: TYPE_NORMAL
- en: However, the chain of objects and calls involved in the execution of commands
    is more complex. This is because it requires the construction and modification
    of aggregates (as well as a definition of the interaction between several aggregates
    and between aggregates and other applications through domain events) to be provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram is a sketch of how storage update operations are performed.
    The circles are data being exchanged between the various layers, while rectangles
    are the procedures that process them. Moreover, dotted arrows connect interfaces
    with types that implement them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.26: Diagram of command execution'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the flow of action through *Figure 21.26* as a list of steps:'
  prefs: []
  type: TYPE_NORMAL
- en: A controller’s action method receives one or more ViewModels and performs validation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One or more ViewModels containing changes to apply are hidden behind interfaces
    (`IMyUpdate`) defined in the domain layer. They are used to fill the properties
    of a command object. These interfaces must be defined in the domain layer since
    they will be used as arguments of the repository aggregate methods defined there.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A command handler matching the previous command is retrieved via **Dependency
    Injection** (**DI**) in the controller action method (through the `[FromServices]`
    parameter attribute we described in the *Defining controllers and views* subsection).
    Then, the handler is executed. During its execution, the handler interacts with
    various repository interface methods and with the aggregates they return.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When creating the command handler discussed in *step 3*, the ASP.NET Core DI
    engine automatically injects all parameters declared in its constructor. In particular,
    it injects all repository implementations needed to perform all command handler
    transactions. The command handler performs its job by calling the methods of these
    `IRepository` implementations received in its constructor to build aggregates
    and modify the built aggregates. Aggregates either represent already-existing
    entities or newly created ones. Handlers use the `IUnitOfWork` interface contained
    in each repository interface, as well as the concurrency exceptions returned by
    the data layer, to organize their operations as transactions. It is worth pointing
    out that each aggregate has its own repository implementation, and that the whole
    logic for updating each aggregate is defined in the aggregate itself, not in its
    associated repository implementation, to keep the code more modular.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Behind the scenes, in the domain layer implementation, repository implementations
    use Entity Framework to perform their job. Aggregates are implemented by root
    data entities hidden behind interfaces defined in the domain layer, while `IUnitOfWork`
    methods, which handle transactions and pass changes to the database, are implemented
    with `DbContext` methods. In other words, `IUnitOfWork` is implemented with the
    application’s `DbContext`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Domain events are generated during each aggregate process and are added to the
    aggregates themselves by calling their `AddDomainEvent` methods. However, they
    are not triggered immediately. Usually, they are triggered at the end of all the
    aggregates’ processing and before changes are passed to the database; however,
    this is not a general rule.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application handles errors by throwing exceptions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A more efficient approach would be to define a request-scoped object in the
    dependency engine, where each application subpart may add its errors as domain
    events. However, while this approach is more efficient, it increases the complexity
    of the code and the application development time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The Visual Studio solution is composed of three projects:'
  prefs: []
  type: TYPE_NORMAL
- en: There’s a project containing the domain layer abstraction called `PackagesManagementDomain`,
    which is a .NET Standard 2.1 library. When a library doesn’t use features or NuGet
    packages that are specific to a .NET version, it is a good practice to implement
    it as a .NET Standard library because, this way, it doesn’t need modifications
    when the application is moved to a newer .NET version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s a project containing the whole domain layer implementation called `PackagesManagementDB`,
    which is a .NET 8.0 library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, there’s an ASP.NET Core MVC 8.0 project called `PackagesManagement`
    that contains both the application and presentation layers. When you define this
    project, select **No Authentication**; otherwise, the user database will be added
    directly to the ASP.NET Core MVC project instead of to the database layer. We
    will add the user database manually in the data layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start by creating the `PackagesManagement` ASP.NET Core MVC project so
    that the whole solution has the same name as the ASP.NET Core MVC project. Then,
    we’ll add the other two library projects to the same solution.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, let the ASP.NET Core MVC project reference both projects, while `PackagesManagementDB`
    references `PackagesManagementDomain`. We suggest you define your own projects
    and then copy the code of this book’s GitHub repository into them as you read
    this section.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection describes the code of the `PackagesManagementDomain` domain
    layer abstraction project.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the domain layer abstraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the `PackagesManagementDomain` Standard 2.1 library project has been added
    to the solution, we’ll add a `Tools` folder to the project root. Then, we’ll place
    all the `DomainLayer` tools contained in the code associated with `ch11`. Since
    the code contained in this folder uses data annotations and defines DI extension
    methods, we must also add references to the `System.ComponentModel.Annotations`
    and `Microsoft.Extensions.DependencyInjection.Abstration` NuGet packages.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we need an `Aggregates` folder containing all the aggregate definitions
    (remember, we implemented aggregates as interfaces) – namely, `IDestination`,
    `IPackage`, and `IPackageEvent`. Here, `IPackageEvent` is the aggregate associated
    with the table where we will place events to be propagated to other applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s analyze `IPackage`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'It contains the same properties as the `Package` entity, which we saw in *Chapter
    13*, *Interacting with Data in C# – Entity Framework Core*. The only differences
    are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It inherits from `IEntity<int>`, which furnishes all basic functionalities of
    aggregates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has no `Id` property since it is inherited from `IEntity<int>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All properties are read-only, and it has a `FullUpdate` method since all aggregates
    can only be modified through update operations defined in the user domain (in
    our case, the `FullUpdate` method)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s also add a `DTOs` folder. Here, we place all interfaces used to pass
    updates to the aggregates. Such interfaces are implemented by the application
    layer ViewModels used to define such updates. In our case, it contains `IPackageFullEditDTO`,
    which we can use to update existing packages. If you would like to add the logic
    to manage destinations, you must define an analogous interface for the `IDestination`
    aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: 'An `IRepositories` folder contains all repository specifications – namely,
    `IDestinationRepository`, `IPackageRepository`, and `IPackageEventRepository`.
    Here, `IPackageEventRepository` is the repository associated with the `IPackageEvent`
    aggregate. As an example, let’s have a look at the `IPackageRepository` repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Repositories always contain just a few methods since all business logic should
    be represented as aggregate methods – in our case, just the methods to create
    a new package, to retrieve an existing package, and to delete an existing package.
    The logic to modify an existing package is included in the `FullUpdate` method
    of `IPackage`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, as with all domain layer projects, `PackagesManagementDomain` contains
    an `Events` folder containing all domain event definitions. In our case, the folder
    is named `Events` and contains the package-deleted event and the price-changed
    event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: When an aggregate sends all its changes to another application, it should have
    a version property. The application that receives the changes uses this version
    property to apply all changes in the right order. An explicit version number is
    necessary because changes are sent asynchronously, so the order in which they
    are received may differ from the order in which they were sent. For this purpose,
    events that are used to publish changes outside of the application have both `OldVersion`
    (the version before the change) and `NewVersion` (the version after the change)
    properties. Events associated with delete events have no `NewVersion` since, after
    being deleted, an entity can’t store any versions.
  prefs: []
  type: TYPE_NORMAL
- en: For more details on how to use and process version information to restore the
    right order of incoming messages, please refer to the *A worker microservice with
    ASP.NET Core* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection explains how all interfaces defined in the domain layer
    abstraction are implemented in the domain layer implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the domain layer implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The data layer project contains references to the `Microsoft.AspNetCore.Identity.EntityFrameworkCore`
    and `Microsoft.EntityFrameworkCore.SqlServer` NuGet packages, since we are using
    Entity Framework Core with SQL Server. It references `Microsoft.EntityFrameworkCore.Tools`
    and `Microsoft.EntityFrameworkCore.Design`, which are needed to generate database
    migrations, as explained in the *Entity Framework Core migrations* section of
    *Chapter 13*, *Interacting with Data in C# – Entity Framework Core*.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a `Models` folder that contains all database entities. They are similar
    to the ones in *Chapter 13*, *Interacting with Data in C# – Entity Framework Core*.
    The only differences are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: They inherit from `Entity<T>`, which contains all the basic features of aggregates.
    Please note that inheriting from `Entity<T>` is only needed for aggregate roots;
    all other entities must be defined as explained in *Chapter 7*, *Understanding
    the Different Domains in Software Solutions.* In our example, all entities are
    aggregate roots.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They have no `Id` since it is inherited from `Entity<T>`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of them have an `EntityVersion` property that is decorated with the `[ConcurrencyCheck]`
    attribute. It contains the entity version, which is essential for propagating
    all entity changes to other applications. The `ConcurrencyCheck` attribute is
    needed to prevent concurrency errors while updating the entity version. This prevents
    suffering the performance penalty implied by a transaction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More specifically, when saving entity changes, if the value of a field marked
    with the `ConcurrencyCheck` attribute is different from the one that was read
    when the entity was loaded in memory, a concurrency exception is thrown to inform
    the calling method that someone else modified this value after the entity was
    read but before we attempted to save its changes. This way, the calling method
    can repeat the whole operation with the hope that this time, no one will write
    the same entity in the database during its execution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only alternative to the `ConcurrencyCheck` attribute would be:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a transaction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read the interested aggregate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment its `EntityVersion` property.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the aggregate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save all changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Close the transaction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The transaction duration would be unacceptably long since the transaction should
    be maintained for the time of various database commands – namely, from the initial
    read to the final update – thus, preventing other requests from accessing the
    involved tables/records for too long a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the contrary, by using the `ConcurrencyCheck` attribute, we open just a
    very short single-command transaction when the aggregate is saved to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: Read the interested aggregate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment the value of the `EntityVersion` property.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the aggregate.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save all changes with a fast single-command transaction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It is worth analyzing the code of the `Package` entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The `FullUpdate` method is the only way to update the `IPackage` aggregate.
    When the price changes, add `PackagePriceChangedEvent` to the entity list of events.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `MainDBContext.cs` file contains the database context definition. It doesn’t
    inherit from `DbContext` but from the following predefined context class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: This context defines the user’s tables needed for the authentication. In our
    case, we opted for the `IdentityUser<T>` standard and `IdentityRole<S>` for users
    and roles, respectively, and used integers for both the `T` and `S` entity keys.
    However, we may also use classes that inherit from `IdentityUser` and `IdentityRole`
    and then add further properties.
  prefs: []
  type: TYPE_NORMAL
- en: In the `OnModelCreating` method, we must call `base.OnModelCreating(builder)`
    in order to apply the configuration defined in `IdentityDbContext`.
  prefs: []
  type: TYPE_NORMAL
- en: '`MainDBContext` implements `IUnitOfWork`. The following code shows the implementation
    of all methods that start, roll back, and commit a transaction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: However, they are rarely used by command classes in a distributed environment.
    This is because retrying the same operation until no concurrency exception is
    returned usually ensures better performance than transactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worth analyzing the implementation of the method that passes all changes
    applied to `DbContext` to the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: The preceding implementation just calls the `SaveChangesAsync` `DbContext` context
    method, which saves all changes to the database, but then it intercepts all concurrency
    exceptions and detaches all the entities involved in the concurrency error from
    the context. This way, the next time a command retries the whole failed operation,
    their updated versions will be reloaded from the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Repositories` folder contains all repository implementations. It is worth
    analyzing the implementation of the `IPackageRepository.Delete` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: It reads the entity from the database and formally removes it from the `Packages`
    dataset. This will force the entity to be deleted from the database when changes
    are saved to the database. Moreover, it adds `PackageDeleteEvent` to the aggregate
    list of events.
  prefs: []
  type: TYPE_NORMAL
- en: The `Extensions` folder contains the `DBExtensions` static class, which, in
    turn, defines two extension methods to be added to the application DI engine and
    the ASP.NET Core pipeline, respectively. Once added to the pipeline, these two
    methods will connect the database layer to the application layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `IServiceCollection` extension of `AddDbLayer` accepts (as its input parameters)
    the database connection string and the name of the `.dll` file that contains all
    migrations. Then, it does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: That is, it adds the database context to the DI engine and defines its options
    – namely, that it uses SQL Server, the database connection string, and the name
    of the `.dll` file that contains all migrations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, it does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: That is, it adds and configures all the types needed to handle database-based
    authentication and authorization. It adds `UserManager`, which the application
    layer can use to manage users. `AddDefaultTokenProviders` adds the provider that
    creates the authentication tokens using data contained in the database when users
    log in.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, it discovers and adds to the DI engine all repository implementations
    by calling the `AddAllRepositories` method, which is defined in the DDD tools
    we added to the domain layer project.
  prefs: []
  type: TYPE_NORMAL
- en: The `UseDBLayer` extension method ensures migrations are applied to the database
    by calling `context.Database.Migrate()`, and then it populates the database with
    some initial objects. In our case, it uses `RoleManager` and `UserManager` to
    create an administrative role and an initial administrator, respectively. Then,
    it creates some sample destinations and packages.
  prefs: []
  type: TYPE_NORMAL
- en: '`context.Database.Migrate()` is useful to quickly set up and update staging
    and test environments. When deploying in production, if we don’t have the credentials
    for creating a new database or for modifying its structure, we can also produce
    an SQL script from the migrations using the migration tools. Then, this script
    should be examined before being applied by the person in charge of maintaining
    the database and, finally, applied with their credentials.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create migrations, we must add the aforementioned extension methods to the
    ASP.NET Core MVC `Program.cs` file, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Please be sure that both the authorization and authentication middleware have
    been added to the ASP.NET Core pipeline in the right order; otherwise, the authentication/authorization
    engine will not work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we must add the connection string to the `appsettings.json` file, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Finally, let’s add `Microsoft.EntityFrameworkCore.Design` to the ASP.NET Core
    project.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, let’s open the Visual Studio Package Manager Console, select
    `PackageManagementDB` as the default project, and then launch the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command will scaffold the first migration. We may apply it to
    the database with the `Update-Database` command. Please note that if you copy
    the project from GitHub, you don’t need to scaffold migrations since they have
    already been created, but you still need to update the database.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will define the application layer that contains the
    business logic for manipulating the aggregates.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the application layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a first step, for simplicity, let’s freeze the application culture to `en-US`
    by adding the following code to the ASP.NET Core pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, let’s create a `Tools` folder and place the `ApplicationLayer` code there,
    which you can find in the `ch11` code of the GitHub repository associated with
    this book. With these tools in place, we can add the code that automatically discovers
    and adds all queries, command handlers, and event handlers to the DI engine, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we must add a `Queries` folder to place all queries and their associated
    interfaces. As an example, let’s have a look at the query that lists all packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The query object is automatically injected into the application DB context.
    The `GetAllPackages` method uses LINQ to project all of the required information
    into `PackageInfosViewModel` and sorts all results in descending order on the
    `EndValidityDate` property.
  prefs: []
  type: TYPE_NORMAL
- en: Projections that involve several properties are time-wasting and error-prone;
    that’s why there are mapping libraries that automatically generate these projections
    using naming conventions and configuration settings. Mapping libraries helps also
    in copying data from one object to another, such as, for example, from a ViewModel
    to a DTO, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: Among all mapping software, it is worth at least mentioning AutoMapper ([https://www.nuget.org/packages/AutoMapper](https://www.nuget.org/packages/AutoMapper)).
  prefs: []
  type: TYPE_NORMAL
- en: '`PackageInfosViewModel` is placed in the `Models` folder together with all
    other ViewModels. It is common practice to organize ViewModels into folders by
    defining a different folder for each controller. It is worth analyzing the ViewModel
    used for editing packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: It has a constructor that accepts an `IPackage` aggregate. This way, package
    data is copied into the ViewModel that is used to populate the edit view. It implements
    the `IPackageFullEditDTO` DTO interface defined in the domain layer. This way,
    it can be directly used to send `IPackage` updates to the domain layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'All properties contain validation attributes that are automatically used by
    client-side and server-side validation engines. Each property contains a `Display`
    attribute that defines the label to give to the input field that will be used
    to edit the property. It is better to place the field labels in the ViewModels
    than it is to place them directly into the views since, this way, the same names
    are automatically used in all views that use the same ViewModel. The following
    code block lists all its properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Commands` folder contains all commands. As an example, let’s have a look
    at the command used to modify packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Its constructor must be invoked with an implementation of the `IPackageFullEditDTO`
    DTO interface, which, in our case, is the edit ViewModel we described previously.
    Command handlers are placed in the `Handlers` folder. It is worth analyzing the
    command that updates packages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Its principal constructor has automatically injected the `IPackageRepository`
    repository and an `IEventMediator` instance needed to trigger event handlers.
    The following code also shows the implementation of the standard `HandleAsync`
    command handler method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: '`HandleAsync` uses the repository to get an instance of the entity to modify.
    If the entity is not found (it has been deleted), the commands stop its execution.
    Otherwise, all changes are passed to the retrieved aggregate. Immediately after
    the update, all events contained in the aggregate are triggered. In particular,
    if the price has changed, the event handler associated with the price change is
    executed. The concurrency check declared with the `[ConcurrencyCheck]` attribute
    on the `EntityVersion` property of the `Package` entity ensures that the package
    version is updated properly (by incrementing its previous version number by 1),
    as well as that the price-changed event is passed the right version numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, event handlers are placed in the `Handlers` folder. As an example, let’s
    have a look at the price-changed event handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The principal constructor has automatically injected the `IPackageEventRepository`
    repository, which handles the database table and all the events to send to other
    applications. The `HandleAsync` implementation simply calls the repository method,
    which adds a new `IPackageEvent` to a queue of events to be sent to other microservices.
  prefs: []
  type: TYPE_NORMAL
- en: The `IPackageEvent` records should be extracted by the above queue and sent
    to all interested microservices by a parallel task, which is not implemented in
    the GitHub code associated with this section. It can be implemented as a hosted
    service (thus inheriting from the `BackgroundService` class) and then added to
    the DI engine with a call such as `builder.Services.AddHostedService<MyHostedService>()`,
    as detailed in the *Using generic hosts* subsection of *Chapter 11*, *Applying
    a Microservice Architecture to Your Enterprise Application*.
  prefs: []
  type: TYPE_NORMAL
- en: We are almost finished! Just the presentation layer is missing, which, in the
    case of an MVC-based application, consists of controllers and views. The next
    subsection defines both controllers and views needed by our microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Defining controllers and views
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to add two more controllers to the one automatically scaffolded by Visual
    Studio – namely, `AccountController`, which takes care of user login/logout and
    registration, and `ManagePackageController`, which handles all package-related
    operations. It is enough to right-click on the `Controllers` folder and then select
    **Add | Controller**. Then, choose the controller name and select the empty MVC
    controller to avoid the possibility of Visual Studio scaffolding code you don’t
    need.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.27: Adding AccountController'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worth pointing out that Visual Studio can automatically scaffold all
    of the UI for managing users if one selects to automatically add authentication
    when the MVC project is created. However, scaffolded code doesn’t respect any
    layer or onions architecture: it inserts everything in the MVC project. That’s
    why we decided to proceed manually.'
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, our implementation of `AccountController` just has login and
    logout methods, so you can log in just with the initial administrator user. However,
    you can add further action methods that use the `UserManager` class to define,
    update, and delete users.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_21_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.28: Login, logout, and authentication'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `UserManager` class can be provided through DI, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '`SignInManager` takes care of login/logout operations. The `Logout` action
    method is quite simple and is shown here (for more information on authentication
    in ASP.NET Core, please refer to the *Defining the ASP.NET Core pipeline* section
    of *Chapter 17*, *Presenting ASP.NET Core*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: It just calls the `signInManager.SignOutAsync` method and then redirects the
    browser to the home page. To avoid it being called by clicking a link, it is decorated
    with `HttpPost`, so it can only be invoked via a form submit.
  prefs: []
  type: TYPE_NORMAL
- en: All requests that cause modifications must never use a `GET` verb; otherwise,
    someone might erroneously trigger those actions either by clicking a link or by
    writing the wrong URL in the browser. An action triggered by GET might also be
    exploited by a phishing website that might adequately “camouflage” a link that
    triggers a dangerous GET action. The GET verb should be used just for retrieving
    information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Login, on the other hand, requires two action methods. The first one is invoked
    via `GET` and shows the login form, where the user must place their username and
    password. It is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: It receives `returnUrl` as its parameter when the browser is automatically redirected
    to the login page by the authorization module. This happens when an unlogged-in
    user tries to access a protected page. `returnUrl` is stored in the `ViewState`
    dictionary that is passed to the login view.
  prefs: []
  type: TYPE_NORMAL
- en: 'The form in the login view passes it back to the controller, together with
    the username and password when it is submitted, as shown in this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The form post is intercepted by an action method with the same `Login` name
    but decorated with the `[HttpPost]` attribute, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The preceding method receives the `Login` model used by the login view, together
    with the `returnUrl` query string parameter. The `ValidateAntiForgeryToken` attribute
    verifies a token (called an anti-forgery token) that MVC forms automatically.
    This is then added to a hidden field to prevent XSRF/CSRF attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Forgery attacks exploit authentication cookies stored in the victim’s browser
    to submit a legitimate authenticated request to a web application. They do this
    by inducing the user to click a button on a phishing website that causes a submit
    to the target web application. The fraudulent request is accepted since, once
    a form is submitted, the authentication cookies for the target URL are automatically
    sent by the browser. There are just two defenses against this kind of attack:'
  prefs: []
  type: TYPE_NORMAL
- en: Authentication cookies are defined as same-origin – that is, they are sent from
    other domains just in case of GET requests. Thus, when a form is submitted from
    a phishing website to the target application, they are not sent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anti-forgery tokens added to forms. In this case, if authentication cookies
    are sent together with the submitted form, the application understands that the
    request comes from a different website and blocks it since it is missing a valid
    anti-forgery token.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As a first step, the action method logs the user out if they are already logged
    in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, it verifies whether there are validation errors, in which case,
    it shows the same view filled with the data of the ViewModel to let the user correct
    their errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'If the model is valid, `signInManager` is used to log the user in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'If the result returned by the operation is successful, the action method redirects
    the browser to `returnUrl` if it’s not null; otherwise, it redirects the browser
    to the home page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: If the login fails, it adds an error to `ModelState` and shows the same form
    to let the user try again.
  prefs: []
  type: TYPE_NORMAL
- en: '`ManagePackagesController` contains an `Index` method that shows all packages
    in table format (for more details on controllers, views, and the MVC pattern in
    general, please refer to the *The MVC pattern* section of *Chapter 17*, *Presenting
    ASP.NET Core*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: The query object is injected into the action method by DI. Then, the action
    method invokes it and inserts the resulting `IEnumerable` into the `Items` property
    of a `PackagesListViewModel` instance. It is a good practice to include `IEnumerables`
    in ViewModels instead of passing them directly to the views so that, if necessary,
    other properties can be added without the need to modify the existing view code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, it is good practice to define enumerable properties of ViewModels
    as `IReadOnlyCollection<T>` if the enumerables are read-only or as `IList<T>`
    if the enumerables can be modified or if they are involved in model binding. In
    fact, `ICollection<T>` has a `Count` property, which may be very useful when rendering
    ViewModels in views, while `IList<T`> also has indexers that are necessary for
    rendering all items with appropriate names for model binding to succeed (see this
    Phil Haack post: [http://haacked.com/archive/2008/10/23/model-binding-to-a-list.aspx](http://haacked.com/archive/2008/10/23/model-binding-to-a-list.aspx)).
    `IEnumerable<T>` should be preferred only in the case that one needs the typical
    lazy evaluation of `IEnumerable<T>.`'
  prefs: []
  type: TYPE_NORMAL
- en: The results are shown in a Bootstrap table since Bootstrap CSS is automatically
    scaffolded by Visual Studio. Bootstrap is a good choice for a CSS framework, since
    it is quite simple and extensible, and is not connected to any particular company
    but is handled by an independent team.
  prefs: []
  type: TYPE_NORMAL
- en: 'The result is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B19820_21_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.29: Application packages handling page'
  prefs: []
  type: TYPE_NORMAL
- en: The **New package** link (it is shaped like a **Bootstrap** button, but it is
    a link) invokes a controller `Create` action method, while the **delete** and
    **edit** links in each row invoke a `Delete` and `Edit` action method, respectively,
    and pass them the ID of the package shown in the row.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the implementation of the two row links:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'It is worth describing the code of the `HttpGet` and `HttpPost` `Edit` action
    methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: The `Edit` method of `HttpGet` uses `IPackageRepository` to retrieve the existing
    package. If the package is not found, that means it has been deleted by some other
    user, and the browser is redirected again to the list page to show the updated
    list of packages. Otherwise, the aggregate is passed to the `PackageFullEditViewModel`
    ViewModel, which is rendered by the `Edit` view.
  prefs: []
  type: TYPE_NORMAL
- en: 'The view used to render the package must render an HTML `select` with all possible
    package destinations, so it needs an instance of the `IDestinationListQuery` query
    that was implemented to assist with the destination selection HTML logic. This
    query is injected directly into the view since it is the view’s responsibility
    to decide how to enable the user to select a destination. The code that injects
    the query and uses it is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The action method that processes the post of the view form is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: If `ModelState` is valid, `UpdatePackageCommand` is created and its associated
    handler is invoked; otherwise, the View is displayed again to the user to enable
    them to correct all the errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'The new links to the package list page and login page must be added to the
    main menu, which is in the `_Layout` view, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: '`logoutForm` is an empty form whose only purpose is to send a post to the `Logout`
    action method. It has been added to the end of the body, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Now, the application is ready! You can run it, log in, and start to manage packages.
  prefs: []
  type: TYPE_NORMAL
- en: After having learned how to implement, in practice, a presentation layer with
    server-side technologies in this section, we now just need to learn how to implement
    it also with client-side technologies. We will do this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Using client technologies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will implement a package search application for the WWTravelClub
    book use case. The first subsection explains how to set up the solution exploiting
    the domain layer and data layer of the MVC application we implemented in the previous
    section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will modify the `PackagesManagement` project both to save coding time and
    to show how to transform a solution based on server-side MVC technology into a
    solution based on the Blazor client-side technology.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, create a copy of the `PackagesManagement` solution folder we created
    in the previous section and rename it `PackagesManagementBlazor`.
  prefs: []
  type: TYPE_NORMAL
- en: To open the solution, right-click on the web project (the one named `PackagesManagement`)
    and remove it (the `Remove` menu item). Then, go to the solution folder and delete
    the whole web project folder (the one named `PackagesManagement`).
  prefs: []
  type: TYPE_NORMAL
- en: Now, right-click on the solution and select **Add New Project**. Add a new **Blazor
    WebAssembly Standalone App** project called `PackagesManagementBlazor.Client`.
    Select **None** for the authentication type, **Configure for https**, and **Include
    Sample Pages**. We don’t need authentication since the search-by-location feature
    we are going to implement must also be available to unregistered users.
  prefs: []
  type: TYPE_NORMAL
- en: Now, add a `PackagesManagementBlazor.Server` **ASP.NET Core Web API** project.
    Select **None** for the authentication type, **Configure for https**, **Enable
    OpenAPI Support**, and **Use Controllers**.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, add a `PackagesManagementBlazor.Shared` **Class Library** project,
    delete the default `Class1` class created by Visual Studio, and add this project
    to both `PackagesManagementBlazor.Client` and `PackagesManagementBlazor.Server`
    as reference.
  prefs: []
  type: TYPE_NORMAL
- en: The server project needs to reference both the domain implementation (`PackagesManagementDB`)
    and the domain abstraction (`PackagesManagementDomain`) projects, so please add
    them as references.
  prefs: []
  type: TYPE_NORMAL
- en: Both `PackagesManagementBlazor.Client` and `PackagesManagementBlazor.Server`
    must start simultaneously, so define them as starting projects by right-clicking
    on the solutions, selecting **Configure Startup Projects**, and choosing them
    as startup projects.
  prefs: []
  type: TYPE_NORMAL
- en: Now, launch the solution to verify that everything works properly. Two browser
    windows should open, one for testing the REST API project and the other containing
    a Blazor application.
  prefs: []
  type: TYPE_NORMAL
- en: Take note of the Blazor application URL (`https://localhost:7027/` in my case)
    since we will need it.
  prefs: []
  type: TYPE_NORMAL
- en: The Blazor website will exchange data with the REST API website, which runs
    on a different domain (a domain is identified by both hostname and port number).
    REST API calls coming from browsers running on different domains are clues of
    potential phishing attacks; therefore, the receiving server only accepts them
    if they come from well-known domains (this way, they are sure they don’t come
    from phishing websites).
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, when a browser application tries to communicate with a different
    URL, the browser detects it and issues the call with a different protocol called
    CORS. Therefore, as soon as it detects the CORS protocol, the receiving server
    understands it is dealing with a request coming from a different website, and
    serves the request only if the other domain has been registered with a so-called
    CORS policy.
  prefs: []
  type: TYPE_NORMAL
- en: In ASP.NET Core, CORS policies are registered with the `builder.Services.AddCors`
    extension method in `Program.cs`.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, in our case, we need to register a CORS policy for the domain of
    the `PackagesManagementBlazor.Client` web application in the `PackagesManagementBlazor.Server`
    web application, since all REST API calls of `PackagesManagementBlazor.Client`
    will be issued to `PackagesManagementBlazor.Server`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Accordingly, let’s open `Program.cs` of the `PackagesManagementBlazor.Server`
    project and enable it for CORS by adding this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: Also, add `app.UseCors();` in the ASP.NET Core pipeline, immediately before
    `app.UseAuthorization();` .
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we must enable the Blazor application to communicate with this server.
    Launch the solution again and take note of the REST API URL (in my case, `https://localhost:7269/`),
    and then replace the URL in the `HttpClient` configuration in the `Program.cs`
    file of the Blazor application with this URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s also copy the same connection string of the old web project into the
    `PackagesManagementBlazor.Server` `appsettings.json` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: This way, we can reuse the database we have created. We also need to add the
    same DDD tools we added to the old web project. Add a folder named `Tools` in
    the project root and copy the contents of the `ch07` -> `ApplicationLayer` folder
    of the GitHub repository associated with the book there.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to finish the solution setup, we just need to connect `PackagesManagementBlazor.Server`
    with the domain layer by adding the following code at the end of the services
    configuration code in the `Program.cs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'It is the same method we added to the old web project. Finally, we can also
    add the `AddAllQueries` extension method, which discovers all queries in the web
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: We don’t need other automatic discovery tools since this is a query-only application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to a bug in Entity Framework Core 8, you also need to change a setting
    in the server project that prevents the usage of .NET culture. You must change
    the `InvariantGlobalization` project setting to `false`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: At this point, we have the project completely configured. We just need to implement
    server-side code and client-side code that implements our package search.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection explains how to design the server-side REST API.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the required ASP.NET Core REST APIs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the first step, let’s define the ViewModels used in the communication between
    the server and the client applications. They must be defined in the `PackagesManagementBlazor.Shared`
    project that is referenced by both applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the `PackageInfosViewModel` ViewModel, which will be the data
    structure used by the Blazor application to exchange package info with the server-side
    REST API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, add the ViewModel that encloses all packages to return to the Blazor
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can also add our query that searches packages by location. Let’s add
    a `Queries` folder in the root of the `PackagesManagementBlazor.Server` project
    and then add the interface that defines our query, `IPackagesListByLocationQuery`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s also add the query implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'We are finally ready to define our `PackagesController`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: The server-side code is finished! Let’s move on to the definition of the Blazor
    service that communicates with the server.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the business logic in a service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s add a `ViewModels` and a `Services` folder to the `PackagesManagementBlazor.Client`
    project. Most of the ViewModels we need were defined in the **PackagesManagementBlazor.Shared**
    project. We only need a ViewModel for the search form. Let’s add it to the `ViewModels`
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s call our service `PackagesClient`, and let’s add it to the `Services`
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: The code is straightforward! The `Uri.EscapeDataString` method URL-encodes the
    parameter so it can be safely appended to the URL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let’s register the service in the dependency injection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: It is worth pointing out that in a commercial application, we should have registered
    the service through an `IPackagesClient` interface in order to be able to mock
    it in the tests (`.AddScoped<IPackagesClient, PackagesClient>()`).
  prefs: []
  type: TYPE_NORMAL
- en: With everything in place, we just need to build the UI.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the user interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the first step, let’s delete the application pages we don’t need – namely,
    `Pages->Counter.razor` and `Pages->Weather.razor`. Let’s also remove their links
    from the side menu in `Shared` -> `NavMenu.razor`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will put our code in the `Pages` -> `Home.razor` page. Let’s replace the
    code of this page with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code adds the needed `@using` statements, injects our `PackagesClient`
    service into the page, and defines the search form. When the form is successfully
    submitted, it invokes the `Search` callback, where we will place the code that
    retrieves all the results.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is time to add the logic to display all the results and to complete the
    `@code` block. The following code must be placed immediately after the search
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: The omitted code in the `if` block is responsible for rendering a table with
    all the results. We will show it after having commented on the preceding code.
  prefs: []
  type: TYPE_NORMAL
- en: Before retrieving the results with the `PackagesClient` service, we remove all
    previous results and set the `loading` field so the Razor code selects the `else
    if` path that replaces the previous table with a loading message. Once we’ve set
    these variables, we are forced to call `StateHasChanged` to trigger change detection
    and refresh the page. After all the results have been retrieved and the callback
    returns, there is no need to call `StateHasChanged` again because the termination
    of the callback itself triggers change detection and causes the required page
    refresh.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code that renders the table with all the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: Run the project and write the initial characters of Florence. Since we inserted
    Florence as a location in the same database in previous chapters (see the *Querying
    and updating data with Entity Framework Core* section of *Chapter 13*, *Interacting
    with Data in C# – Entity Framework Core*), some results should appear. If you
    inserted different data, please try with different starting words.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, together with web-based clients, all applications also furnish mobile-native
    applications to get a better performance with possibly slow mobile devices. So,
    let’s also design a mobile-native client application!
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Blazor MAUI version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we explain how to add a Blazor MAUI version to the application
    of the previous solution.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, right-click on the solution icon in Solution Explorer and add
    a new project to the solution. Select a MAUI Blazor application and call it `PackagesManagementMAUIBlazor`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `PackagesManagementMAUIBlazor` project file and remove all the platforms
    you don’t want to support (I removed Android, iOS, and Mac Catalyst, and kept
    only Windows):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: Then, add a reference to the `PackagesManagementBlazor.Shared` project.
  prefs: []
  type: TYPE_NORMAL
- en: Now, right-click on the client WebAssembly project and select **Open Folder
    in File Explorer**. Then, copy the `ViewModels` and `Services` folders, and paste
    them in Visual Studio Solution Explorer under the newly created `PackagesManagementMAUIBlazor`
    node.
  prefs: []
  type: TYPE_NORMAL
- en: Then, change the namespaces of the files contained in these folders to be, respectively,
    `PackagesManagementMAUIBlazor.ViewModels` and `PackagesManagementMAUIBlazor.Services`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, replace the content of the `Shared` and `Pages` folders of the newly created
    project with the content of the `Layout` and `Pages` folders of the client Blazor
    WebAssembly project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Edit the newly copied `Home.razor` file and replace its header with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, add the same `HttpClient` and `PackagesClient` configurations of the
    WebAssembly project to `MAUIProgram.cs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: With this, you must add `PackagesManagementMAUIBlazor` to the projects to start.
    Right-click on the solution and select **Configure Startup Projects**.
  prefs: []
  type: TYPE_NORMAL
- en: In the windows that open, select also the newly created MAUI Blazor project.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can launch the application. Three windows should open (two browser
    windows and a Windows window) but both client project windows should show exactly
    the same application.
  prefs: []
  type: TYPE_NORMAL
- en: After having discussed all the components of our WWTravelClub application, we
    need just to describe how to test it.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the WWTravelClub application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we add some unit and functional test projects to the `PackagesManagement`
    frontend microservice we described in the *A frontend microservice* section of
    this chapter. If you don’t have it, you can download it from the section of the
    GitHub repository associated with the book in the `ch19` folder. It is worth pointing
    out that in real-world projects, unit test batteries are enhanced by integration
    tests, and acceptance tests would include not only functional tests but also various
    kinds of performance tests.
  prefs: []
  type: TYPE_NORMAL
- en: You are encouraged to review *Chapter 9*, *Testing Your Enterprise Application*,
    before continuing with this section.
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, let’s make a new copy of the solution folder and name it `PackagesManagementWithTests`.
    Then, open the solution and add it to an xUnit .NET C# test project named `PackagesManagementTest`.
    Finally, add a reference to the ASP.NET Core project (`PackagesManagement`), since
    we will test it, and a reference to the latest version of the `Moq` `NuGet` package,
    since we require mocking capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth remembering that `Moq` is a mocking library and that the purpose
    of mocking is to decouple dependencies between classes by replacing actual classes
    with mocked classes whose behavior is under the complete control of the test code.
    This way, each class can be unit tested independently from the behavior of other
    classes it references. For more details about `Moq`, please refer to *Chapter
    9*, *Testing Your Enterprise Application*.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we are ready to write our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, we will write unit tests for the `Edit` method decorated with
    `[HttpPost]` of the `ManagePackagesController` controller, which is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: Before writing our test methods, let’s rename the test class that was automatically
    included in the test project as `ManagePackagesControllerTests`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first test verifies that if there are errors in `ModelState`, the action
    method renders a view with the same model it received as an argument so that the
    user can correct all errors. We need to test all possibilities. Let’s delete the
    existing test method and write an empty `DeletePostValidationFailedTest` method,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'The method must be `async` and the return type must be `Task` since the `Edit`
    method that we have to test is `async`. In this test, we don’t need mocked objects
    since no injected object will be used. Thus, as a preparation for the test, we
    just need to create a controller instance, and we must add an error to `ModelState`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we invoke the method, injecting `ViewModel` and a `null` command handler
    as its arguments, since the command handler will not be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'In the verification stage, we verify that the result is `ViewResult` and that
    it contains the same model that was injected into the controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we also need a test to verify that if there are no errors, the command
    handler is called, and then the browser is redirected to the `Index` controller
    action method. We call the `DeletePostSuccessTest` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the preparation code must include the preparation of a command handler
    mock, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the handler `HandleAsync` method returns no `async` value, we can’t use
    `ReturnsAsync`, but we have to return just a completed `Task (Task.Complete)`
    with the `Returns` method. The method to test is called with both `ViewModel`
    and the mocked handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the verification code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: As the first step, we verify that the command handler has actually been invoked
    once. A better verification should also include a check that it was invoked with
    a command that includes `ViewModel` passed to the action method. We will take
    it up as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Then we verify that the action method returns `RedirectToActionResult` with
    the right action method name and with no controller name specified.
  prefs: []
  type: TYPE_NORMAL
- en: Once all the tests are ready, if the test window does not appear on the left
    bar of Visual Studio, we may simply select the **Run all tests** item from the
    Visual Studio **Test** menu. Once the test window appears, further invocations
    can be launched from within this window.
  prefs: []
  type: TYPE_NORMAL
- en: If a test fails, we can add a breakpoint to its code, so we can launch a debug
    session on it by right-clicking on it in the test window and then selecting **Debug
    selected tests**. It is worth remembering that failures do not depend necessarily
    on errors in the code under test but might also depend on errors in the testing
    code itself.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will show how to upload our code to a shared Azure
    DevOps repository and how to automatize our tests with an Azure DevOps pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to an Azure DevOps repository
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tests play a fundamental role in the application CI/CD cycle, specifically in
    CI. They must be executed at least each time the master branch of the application
    repository is modified to verify that changes don’t introduce bugs.
  prefs: []
  type: TYPE_NORMAL
- en: The following steps show how to connect our solution to an Azure DevOps repository,
    where we will define an Azure DevOps pipeline that builds the project, and that
    also launches all the unit tests we defined in the `PackagesManagementTest` project
    at each build.
  prefs: []
  type: TYPE_NORMAL
- en: However, the functional tests that we defined in the `PackagesManagementFTest`
    project must be executed only before a sprint is released. Therefore, they must
    be placed in a different pipeline that takes care of delivering the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this way, every day after all developers have pushed their changes, we can
    launch the pipeline to verify that the repository code compiles and passes all
    the unit tests:'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, we need a free DevOps subscription. If you don’t already have
    one, please create one by clicking the **Start free** button on this page: [https://azure.microsoft.com/en-us/services/devops/](https://azure.microsoft.com/en-us/services/devops/).
    Here, let’s follow the wizard to define an organization and then a project.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the project page, select the **Files** menu, click on the **Repos** menu
    item, and then copy the repository URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated with medium
    confidence](img/B19820_21_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.30: Copying the repository URL'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensure you are logged in to Visual Studio with your Azure account (the same
    one used in the creation of the DevOps account). In the **Git Changes** tab, click
    the **Create Git Repository...** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B19820_21_31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.31: Opening the connection window'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the window that opens, select **Existing remote** from the left menu and
    copy and paste the remote repository URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B19820_21_32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.32: Connection window'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, click the **Create and Push** button and wait until the ready icon in
    the bottom-left corner of Visual Studio is checked:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, application, Teams  Description automatically generated](img/B19820_21_33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.33: Operation completed'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, the repository has been created locally, connected with the selected
    remote repository, and all changes have been committed and pushed to the remote
    repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, click the **Pipelines** menu item to create a DevOps pipeline to build
    and test your project. In the window that appears, click the button to create
    a new pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B19820_21_34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.34: Pipeline page'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will be prompted to select where your repository is located:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B19820_21_35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.35: Repository selection'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select **Azure Repos Git** and then your repository. Then, you will be prompted
    about the nature of the project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B19820_21_36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.36: Pipeline configuration'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select **ASP.NET Core**. A pipeline for building and testing your project will
    be automatically created for you. Save it by committing the newly created `.yaml`
    file to your repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B19820_21_37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.37: Pipeline properties'
  prefs: []
  type: TYPE_NORMAL
- en: 'The pipeline can be run by selecting the **Queue** button, but since the standard
    pipeline scaffolded by DevOps has a trigger on the master branch of the repository,
    it is automatically launched each time changes to this branch are committed and
    each time the pipeline is modified. The pipeline can be modified by clicking the
    **Edit** button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email, Teams  Description automatically
    generated](img/B19820_21_38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.38: Pipeline code'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once in edit mode, all pipeline steps can be edited by clicking the **Settings**
    link that appears above each of them. New pipeline steps can be added as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write `- task:` where the new step must be added and then accept one of the
    suggestions that appear while you are typing the task name.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have written a valid task name, a **Settings** link appears above the
    new step. Click it.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the desired task parameters in the window that appears and then save.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To have our test working, we need to specify the criteria to locate all assemblies
    that contain tests. In our case, since we have to execute just the tests contained
    in `PackagesManagementTest.dll` and not the ones contained in `PackagesManagementFTest.dll`,
    we must specify the exact .`ddl` name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click the **Settings** link of the `VSTest@2` test task and replace the content
    that is automatically suggested for the **Test files** field with the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, click **Add** to modify the actual pipeline content. As soon as you confirm
    your changes in the **Save and run** dialog, the pipeline is launched and, if
    there are no errors, test results are computed. The results of tests launched
    during a specific build can be analyzed by selecting the specific build in the
    pipeline **Runs** tab and by clicking the **Tests** tab on the page that appears.
    In our case, we should see something like the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B19820_21_39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21.39: Test results'
  prefs: []
  type: TYPE_NORMAL
- en: Summing up, we created a new Azure DevOps repository, published the solution
    to the new repository, and then created a build pipeline that executes our tests
    after each build. The build pipeline is executed as soon as we save it and will
    be executed each time someone commits to the master branch.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main purpose of this chapter was to deliver pieces of implementations that
    can be useful to begin the challenge of delivering a software solution for an
    enterprise. Although we have not shown the complete implemention of the WWTravelClub
    application, we are confident that the microservices and code provided here can
    help you in your professional projects; this is in line with what we understand
    to be the main purpose of a software architect―to help the team in developing
    software that meets the users’ needs exactly as required.
  prefs: []
  type: TYPE_NORMAL
- en: Leave a review!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enjoyed this book? Help readers like you by leaving an Amazon review. Scan the
    QR code below for a 20% discount code.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Leave_a_review_QR.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Limited Offer*'
  prefs: []
  type: TYPE_NORMAL
