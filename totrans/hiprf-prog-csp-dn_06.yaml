- en: '*Chapter 5*: Application Profiling and Tracing'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Application profiling is the internal examination of the inner workings of a
    computer program. We use application profiling to measure the performance of a
    program's internals. This helps us to identify any performance bottlenecks and
    memory issues. Then, we can use this information to refactor and improve the performance
    of the program.
  prefs: []
  type: TYPE_NORMAL
- en: Application tracing is used to monitor the internal performance of a computer
    program as it is running. You can trace the execution of your computer program
    during development, testing, and when released into production.
  prefs: []
  type: TYPE_NORMAL
- en: When used together, application profiling and application tracing can be very
    powerful and useful in identifying why computer programs are slow.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn how to profile your applications to identify
    any poor areas of performance. You will come to understand code metrics and how
    to perform static code analysis. In your drive to write more performant code,
    you will learn how to make use of memory dumps, the loaded modules viewer, debugging,
    tracing, and `dotnet-counters`. By the time you have completed this chapter, you
    will have the necessary skills and experience you need to profile and trace your
    own applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will be covering the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Understanding code metrics**: In this section, we will be looking at what
    application, assembly, namespace, type, method, and field metrics various tools
    can offer us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performing static code analysis**: In this section, we will look at performing
    static code analysis with Visual Studio 2022\. And we will be generating metrics
    for our software that consist of the maintainability index, cyclomatic complex,
    the depth of inheritance, class coupling, units of source code, and lines of executable
    code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generating and viewing memory dumps**: In this section, we will look at how
    to generate and view memory dumps when a breakpoint is hit in code or when an
    application is encountered.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Viewing loaded modules**: In this section, we will display the **Modules**
    window in Visual Studio so that we can view the modules that are loaded into memory
    by our application and view information about those modules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Debugging your applications**: This section highlights the various debugging
    options that are available to us.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using tracing and diagnostics tools**: In this section, we will introduce
    tools that can help us to perform tracing and diagnostics on our software applications.
    Specifically, we will consider Visual Studio 2022, JetBrains dotMemory, and JetBrains
    dotTrace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dotnet-counters` and use them to list .NET processes that can be monitored,
    list the available counters that we can use to gather performance data, monitor
    a .NET process, and collect data for that process in a CSV file for post-processing
    analysis in Excel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tracking down and fixing a memory leak with dotMemory**: In this section,
    we will use dotMemory to hunt down a memory leak in a WPF application and fix
    it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finding the cause of a UI freeze with dotTrace**: In this section, we will
    use dotTrace to hunt down the cause of a UI freeze in a WPF application and fix
    it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimizing application performance and memory traffic**: In this section,
    we will use dotTrace to identify opportunities to improve performance and memory
    traffic for a WPF application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'After completing this chapter, you will be skilled in the following things:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding code metrics and being able to use them to improve code quality
    and performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing static code analysis to improve code quality and performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using loaded modules to identify what modules your code uses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effectively debugging software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effectively tracing software
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `dotnet-counters` to perform first-level performance investigations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using JetBrains dotMemory to track down memory leaks and fix them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using JetBrains dotTrace to track down the cause of UI freezes and fix them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using JetBrains dotTrace to track down performance and memory traffic issues
    and fix them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Don't be alarmed if you are asked to access code from previous chapters for
    some of the examples. Due to the page limitation for chapters, adding code examples
    for those exercises would have exceeded the count limit for this chapter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The technical requirements to follow along with this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2022 or higher
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JetBrains dotMemory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JetBrains dotTrace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Source code: [https://github.com/PacktPublishing/High-Performance-Programming-in-CSharp-and-.NET/tree/master/CH05](https://github.com/PacktPublishing/High-Performance-Programming-in-CSharp-and-.NET/tree/master/CH05)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Optional: Microsoft Excel or some other CSV file viewer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding code metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will be looking at the code metrics that can be gathered
    using various tools that are paid for, free, and open source. Source code metrics
    are extracted from source code and are used to measure the quality and performance
    of our source code.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Different tools have different metrics that they can measure and calculate.
    Since each tool is different, it is a good idea for you to see what tools and
    metrics are available that satisfy your own project's requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming subsections, we will learn about the different code metrics
    that we can use to measure our code and improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: Application metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Application metrics cover your application's complete source code across assemblies.
    They give you the big picture regarding how many lines of code your application
    has, along with how many lines are covered by tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will cover, from a high level, the various metrics that
    certain tools such as the *ndepends* tool offer. As part of your own studies,
    identify different application metrics gathering tools. Then, see what metrics
    they offer. Choose the tool that best fits your needs. In the next section, the
    generation of code metrics will be demonstrated using Visual Studio''s built-in
    static code analysis tool to generate the following metrics: the maintainability
    index, cyclomatic complexity, the depth of inheritance, class coupling, the lines
    of source code, and the lines of executing code. These and other metrics are described
    next.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Although metrics are different between tool vendors, available application
    metrics might include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lines of Code** (**LOC**): There are two types of LOC measurements. They
    include logical LOC and physical LOC. A logical LOC refers to those lines of code
    that can span one or more lines and are terminated by either a closing curly brace
    or a semicolon. A physical LOC refers to actual lines of code including comments
    and whitespace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines of comment**: The number of lines used for comments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Percentage comment**: This metric identifies the percentage of code that
    is made up of comments. It is calculated using this formula: *100 x Lines of Comment/(Lines
    of Comment + Lines of Code)*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IL instructions**: When your code compiles, it is converted into **Intermediate
    Language** (**IL**) code. Depending on how you code your C# code, this can lead
    to the generation of a large or small number of IL instructions. It makes sense
    to measure the number of IL instructions generated by your code. That''s because
    even if the code is small, it could generate many IL instructions. And conversely,
    a method can be large but generate smaller lines of code compared to the smaller
    version of the code. The smaller number of IL instructions, the easier the method
    is to maintain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The company *ndepend* has a recommendation on their documentation code-metrics
    page that states methods that produce IL instructions higher than 100 are hard
    to understand and maintain. Additionally, they state that unless the methods are
    autogenerated by code generation tools, methods that produce 200 lines or more
    of IL instructions are extremely complex and should be split into smaller methods.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Application assemblies**: The application assembly count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application namespaces**: The application namespace count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application methods**: The application method count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application fields**: The application field count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines of code covered**: The number of lines covered by tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines of code not covered**: The number of lines not covered by tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we will cover what assembly metrics are and what types of metrics can be
    gathered.
  prefs: []
  type: TYPE_NORMAL
- en: Assembly metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assembly metrics are more focused on measuring the quality and stability of
    individual assemblies. Since an application can consist of many assemblies, problems
    can arise in any one or more of those assemblies. If multiple assemblies rely
    on one poorly performing assembly, then the whole application will be affected.
    Additionally, it is good to be able to reuse assemblies in different projects,
    so coupling should be kept to an absolute minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gathering assembly metrics enables you to understand how your assemblies are
    coupled together, and you can also see how abstract and stable or unstable they
    are. Additionally, you can determine whether they are reusable in their current
    form based on those metrics. The various metrics that are available to measure
    assembly source code include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Afferent coupling**: This is the count of classes in other assemblies that
    rely on classes within the current assembly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efferent coupling**: This is the count of classes in the current assembly
    that depend upon classes in other packages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Relational cohesion**: The average count of internal relationships per type
    within an assembly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instability**: The ratio of efferent coupling to total coupling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Abstractness**: The ratio of internal abstract classes and interfaces to
    internal types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Distance from the main sequence**: A number that indicates the balance between
    abstractness and stability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's look at what namespace metrics are and what kind of metrics can be
    gathered.
  prefs: []
  type: TYPE_NORMAL
- en: Namespace metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Namespaces are an important part of any professional quality API. Correctly
    partitioning your code into relevantly named namespaces helps programmers understand
    your API and find what they are looking for more easily. Namespace metrics help
    you to understand whether you have dependency cycles and whether your assemblies
    are high-level, mid-level, or low-level.
  prefs: []
  type: TYPE_NORMAL
- en: 'The metrics that are available concerning the code quality of namespaces include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Afferent coupling**: The count of namespaces that directly depend on the
    current namespace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efferent coupling**: The count of different namespaces that the current namespace
    depends on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Level**: The level value of a namespace. This metric can help you identify
    dependency cycles. Additionally, it helps you objectively classify your assemblies,
    namespaces, methods, and types as high-level, mid-level, or low-level.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's time to look at what type metrics are and the type of metrics that can
    be gathered.
  prefs: []
  type: TYPE_NORMAL
- en: Type metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Type refers to class types, interface types, array types, value types, enumeration
    types, type parameters, generic type definitions, and open or closed constructed
    generic types.
  prefs: []
  type: TYPE_NORMAL
- en: Types and how they are coded and used are behind all the problems we experience
    as programmers and end users. Understanding how they are used in our programs
    is an effective way of identifying a variety of issues with our code. When problems
    are identified, they can be rectified.
  prefs: []
  type: TYPE_NORMAL
- en: 'Type code quality metrics include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Type rank**: A computed value that is computed based on the application of
    a ranking algorithm, similar to Google''s PageRank algorithm, on types dependencies
    graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Afferent coupling**: The count of types that depend upon the current type.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efferent coupling**: The count of types that the current type directly depends
    on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lack of cohesion methods**: For the code to adhere to the **single responsibility
    principle** (**SRP**), it will have only one reason to change, and no more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cyclomatic complexity**: The count of pathways through a method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IL cyclomatic complexity**: The count of pathways through IL code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Size of instance**: The size, in bytes, of the instances of the specified
    type.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Interfaces implemented**: The count of interfaces implemented.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Association between classes**: The count of members from other types that
    are directly used in the body of the methods of the current type.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The number of children**: The count of subclasses for a class, or the count
    of types that implement an interface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Depth of inheritance tree**: The count of base classes for a class or structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we will look at what method metrics are and the types of method metrics
    that can be gathered.
  prefs: []
  type: TYPE_NORMAL
- en: Method metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Normally, methods are behind most performance issues. It is the method within
    a class that executes instructions that can cause any number of issues for your
    customers. These problems can include runtime errors, data errors, and performance
    issues. Being able to see and understand how a method interacts with other methods
    can be a real big help in solving various issues including performance issues.
    The method metrics that are available for analyzing the code quality of methods
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Method rank**: A computed value based on the application of a ranking algorithm,
    similar to Google''s PageRank algorithm, on the method dependencies graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Afferent coupling**: The count of methods that directly depend upon the current
    method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efferent coupling**: The count of methods that the current method directly
    depends on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IL nesting depth**: The maximum count of encapsulated scopes inside a method
    body computed from the IL code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parameters**: The number of parameters used in the method signature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Variables**: The method body variable count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Overloads**: The method overload count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Percentage branch coverage**: The percentage of branches covered by tests
    generated from opcodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final metrics that we will look at are field metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Field metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The metrics available for measuring coupling at the field level is **afferent
    coupling**. This refers to the count of methods that directly uses a variable.
    The higher the count, the more unstable the software becomes. So, this metric
    can be useful for improving the stability of the software.
  prefs: []
  type: TYPE_NORMAL
- en: The size of instance metric measures the size, in bytes, of the instances of
    a specified type.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how to improve the architecture and code
    quality by performing static code analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Performing static code analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The purpose of static code analysis is to help you improve your overall architectural
    quality, code quality, and performance by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing software architecture and its software dependencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enforcing the designated architectural rules regarding laying, subsystems, calling
    rules, and more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying code that has been cloned and modified using cut, copy, and paste
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying dead code that can be removed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating various software metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing code style checks and flagging violations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Many companies employ static code analysis as part of their **Continuous Integration**
    (**CI**) process. There are various stages at which problems can come to light.
    These stages are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: When compiling source code in the IDE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When running unit tests and end-to-end system tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When pushing source code to version control and issuing a pull request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a pull request has been issued and the code is issued to the build pipeline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing static code analysis during the coding phase helps to prevent issues
    from being flagged further down the development and release processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Visual Studio via the **Project Properties** | **Code Analysis** page, you
    can run analyzers on the build and live analyses. You can enable .NET analyzers
    and set the analysis level to **preview**, **latest**, **5.0**, and **none**.
    Additionally, you can enforce CodeStyle on build. *Figure 5.1* shows the **Code
    Analysis** page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – The Visual Studio Code Analysis page on the Project Properties
    tab'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.01_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 – The Visual Studio Code Analysis page on the Project Properties
    tab
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Code Metrics Results** window is available from the **View** menu by
    selecting **View** | **Other Windows – Code Metrics Results**. The **Code Metrics
    Results** window is displayed in *Figure 5.2*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – The Code Metrics Results window'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.02_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 – The Code Metrics Results window
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click on the `CH04_Finalization` project and select **Analyze** and **Code
    Cleanup** | **Calculate Code Metrics** from the context pop-up menu. The **Code
    Metrics Results** window will be updated with the results of the analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Visual Studio 2022 Code Metrics Results for the CH04_WeakReference
    project'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.03_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Visual Studio 2022 Code Metrics Results for the CH04_WeakReference
    project
  prefs: []
  type: TYPE_NORMAL
- en: The `CH04_Finalization`.
  prefs: []
  type: TYPE_NORMAL
- en: Learn About the Metrics in Detail
  prefs: []
  type: TYPE_NORMAL
- en: If you want to learn more about the metrics (**Maintainability Index**, **Cyclomatic
    Complexity**, **Depth of Inheritance**, **Class Coupling**, **Lines of Source
    Code**, and **Lines of Executable code**), then you can find a dedicated chapter
    ([*Chapter 12*](B16617_12_Final_SB_Epub.xhtml#_idTextAnchor215)) in my other book,
    *Clean Code in C#* ([https://www.packtpub.com/product/clean-code-in-c/9781838982973](https://www.packtpub.com/product/clean-code-in-c/9781838982973)),
    which is published by Packt.
  prefs: []
  type: TYPE_NORMAL
- en: From the traffic-light indicators of the **Maintainability Index** column, you
    can see that our project has green lights all the way. This means that our project
    is maintainable.
  prefs: []
  type: TYPE_NORMAL
- en: The cyclomatic complexity of our methods is between **1** and **2**, so our
    individual method code contains no risk. However, the overall cyclomatic complexity
    of our project is **31**, which is medium risk. This value is the summation of
    the overall cyclomatic complexity of each of the classes within our project. The
    cyclomatic complexity of each of our classes is the summation of the cyclomatic
    complexity of each of the methods. Since none of the classes have a cyclomatic
    complexity of more than **13**, our code is complex but only poses a low risk
    to our project. Because the overall complexity of the project is **31**, we should
    look to see whether the code can be refactored to lower the cyclomatic complexity.
    Sometimes, you will find that code is as simple as you can make it and that it
    is not possible to reduce cyclomatic complexity. That is okay. Just use your common
    sense and better judgment when you encounter such code.
  prefs: []
  type: TYPE_NORMAL
- en: The maximum depth of inheritance in our project is `FreeAllocateMemory` class
    inherits from our `DisposableBase` class, which inherits from the `System.Object`
    class. If we study what the `DisposableBase` class does, we can see that it will
    not cause us any issues.
  prefs: []
  type: TYPE_NORMAL
- en: The total number of lines of code in our project is about **200**. There are
    **50** lines of executable code. That's because we are making effective use of
    whitespace so that our code is easy to read. Easy-to-read code is easier to understand,
    extend, and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `CH06_Collections`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – The Visual Studio 2022 code analysis results for the CH04_Finalization
    project'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.04_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.4 – The Visual Studio 2022 code analysis results for the CH04_Finalization
    project
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, we can see that we have 0 errors, 4 warnings, and
    62 messages. The three informational messages inform us that three different methods
    do not access instance data and can be marked as static.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `CH04_Finalization.DisposableBase` class, we implement the `IDisposable`
    interface. In this class, code analysis raises two informational messages for
    code analysis rule CA1816\. This code analysis rule informs us that the `Dispose`
    methods should call `SuppressFinalize`. Despite calling `GC.SuppressFinalize`,
    we are receiving this code analysis rule as an informational message. Therefore,
    to remove (suppress) the warning, we wrap the code in `#pragma` compiler directives.
    This can be done manually or by right-clicking on the message and selecting `DisposableBase`
    source file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now that the `DisposableBase` class has been updated with these `#pragma` warning
    disable CA1816 statements, notice that the messages are no longer displayed in
    the error list.
  prefs: []
  type: TYPE_NORMAL
- en: Well, we have had a look at how to generate code metrics and run code analysis
    on our `CH04_Finalization` project using Visual Studio 2022\. Now, let's move
    on to look at how to generate memory dumps and analyze them.
  prefs: []
  type: TYPE_NORMAL
- en: Generating and viewing memory dumps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When debugging in Visual Studio, if your program has stopped on a breakpoint
    or an exception, then the **Save Dump As** menu option becomes available in the
    **Debug** menu.
  prefs: []
  type: TYPE_NORMAL
- en: A minidump with a heap file provides a snapshot of an application's memory,
    shows the process that was running, and lists the modules that were loaded at
    a point in time. Dump files enable you to examine the stack, threads, and variables
    as they were within the application and memory at the point in time when the dump
    was saved.
  prefs: []
  type: TYPE_NORMAL
- en: You would save a minidump with heap files when testing software and a crash
    is encountered, and when a customer program crash cannot be replicated on your
    computer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s go through the process of saving and loading a minidump with a heap
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using our `CH04_WeakReferences` project, put a breakpoint on the following
    line in the `program.cs` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the project to the breakpoint. Then, when the breakpoint is hit, select
    `CH04_WeakReference.dmp`. This file is a minidump with a heap file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To read the file, select **File** | **Open** | **File**. Then, select the file
    you just saved. You should see the following window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.5 – A minidump with a heap file loaded in Visual Studio 2022'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.05_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.5 – A minidump with a heap file loaded in Visual Studio 2022
  prefs: []
  type: TYPE_NORMAL
- en: The preceding screenshot shows us that we can see the time at which the file
    was last updated, the process name, the computer architecture, the exception code
    and information, the heap information, and the error information. Then, we have
    the CLR and OS versions. Finally, there is a list of modules, including their
    names, versions, and paths.
  prefs: []
  type: TYPE_NORMAL
- en: You have just learned how to generate and read memory dumps in Visual Studio
    2022\. Now we will look at using the **Modules** window in Visual Studio 2022
    to view what modules have been loaded by our projects.
  prefs: []
  type: TYPE_NORMAL
- en: Viewing loaded modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To identify what might be causing performance issues such as excessive memory
    load, or that might be generating runtime errors, it can be useful to see what
    modules have been loaded into memory. In this section, you will learn how to view
    loaded modules and understand the items of information provided regarding those
    modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you are debugging in Visual Studio 2022, the **Debug** | **Windows** menu
    contains the menus, as shown in *Figure 5.6*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – The Windows menu during a debugging session'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.06_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.6 – The Windows menu during a debugging session
  prefs: []
  type: TYPE_NORMAL
- en: 'From the preceding menu, as shown in *Figure 5.6*, you can select **Modules**
    during a debugging session. This will load the **Modules** window, as shown in
    *Figure 5.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – The Modules window showing the loaded modules for the current
    process'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.07_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.7 – The Modules window showing the loaded modules for the current process
  prefs: []
  type: TYPE_NORMAL
- en: 'As *Figure 5.7* shows, the `CH04_WeakReferences.exe` process runs in the **clrhost**
    AppDomain, and loads the following modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '`System.Private.CoreLib.dll`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CH04_WeakReference.dll`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`System.Runtime.dll`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`System.Console.dll`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The list of fields that are displayed in the **Modules** window is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Name**: The name of the loaded assembly (loaded module)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Path**: The path to the loaded module'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimized**: Yes/no'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User Code**: Yes/no'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Symbol Status**: Skipped loading symbols/symbols loaded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Symbol File**: The path and filename of the loaded symbol file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Order**: The order of assembly loading'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version**: The assembly version'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Address**: The memory address of the loaded module'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process**: The process identifier and executable name responsible for causing
    the modules to be loaded into memory'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AppDomain**: The name of the application domain that the module is running
    under. This doesn''t have any meaning in .NET Core and .NET 5 or higher. It is
    displayed because the debugger UI does not make the distinction between the .NET
    Framework and .NET Core.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use this information to see what modules are loaded, whereabouts they
    reside in memory, whether the symbols have been loaded, whether the code is system
    code or user code, and whether the code is optimized or not optimized. If you
    find user code that has not been optimized, then you can apply optimizations to
    improve performance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how to further debug your applications
    by briefly covering the tools available to you that you should already be familiar
    with.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging your applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is assumed that you know how to debug your code by running through your
    code, stepping out and stepping over the code, running to the cursor, and setting
    breakpoints. However, there are other useful tools available when using the debugger.
    These include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – The Debug | Windows menu'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.08_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.8 – The Debug | Windows menu
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are a good number of different windows available to help
    debug your applications. The **Immediate** window is very good for executing commands
    when your program is paused. The **Locals** window is good for seeing the present
    state of your variables, and the call stack is useful for finding where an exception
    occurred, especially if it is in close code that is not yours! Take the time to
    run through your source code with these windows open. Different windows such as
    **XAML Binding Failures** are only used when working on the XAML-based code. But
    other windows, such as **Immediate**, **Locals**, **Output**, **Autos**, and **Call
    Stack,** can be used with all project types. The best way to get the most out
    of these tools is to use them for yourself and get to know them as you work through
    your code. Next, we will look at using tracing and diagnostics tools.
  prefs: []
  type: TYPE_NORMAL
- en: Using tracing and diagnostics tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look at some profiling tools to help you trace and
    diagnose any issues with your code. By tracing and diagnosing your program, you
    can identify areas of performance concern and address them. Such concerns might
    be the number of memory allocations and the number of bytes they are using and
    identifying the number of objects surviving garbage collection. Such information
    can be useful in improving memory usage and performance and in preventing and
    removing memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: We will look at two offerings from JetBrains, called **dotMemory** and **dotTrace**,
    that are valuable tools in this respect. But first, we will start by looking at
    the built-in profiler that comes with Visual Studio 2022 called **Performance
    Profiler**.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Visual Studio 2022 Performance Profiler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now we are going to view the performance profile for our project. This will
    show us the number of objects over time and the way garbage collection is being
    utilized in our project, along with the number of objects that survive garbage
    collection. We can drill down on this profile to the assembly and method levels.
    This enables us to see the number of object allocations within a method and the
    total number of bytes those allocations use up. And because of this information,
    we can identify the areas of our program that generate the most memory usage.
    With such information, we can consider heavy allocation code for refactoring to
    improve memory performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the Visual Studio 2022 Performance Profile, select **Performance
    Profiler** from the Visual Studio 2022 **Debug** menu. This will bring up a tab,
    as shown in *Figure 5.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – The Visual Studio 2022 Performance Profiler'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.09_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.9 – The Visual Studio 2022 Performance Profiler
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will run an analysis on the `CH04_Finalization` project:'
  prefs: []
  type: TYPE_NORMAL
- en: Select your startup project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, select the tool that you want to use. In our case, we have selected `CH04_Finalization`.
    And the tool we have selected is the tool for tracking .NET object allocations.
    This enables us to see where the .NET objects are allocated and when they are
    reclaimed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the **Start** button to start profiling the application. The profiler
    will run and then stop when the code stops. You will see a report similar to the
    one in *Figure 5.10*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.10 – The complete Visual Studio 2022 Performance Profiler report'
  prefs: []
  type: TYPE_NORMAL
- en: showing live objects over time
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.10_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.10 – The complete Visual Studio 2022 Performance Profiler report showing
    live objects over time
  prefs: []
  type: TYPE_NORMAL
- en: The main chart area shows the number of live objects over time. There are also
    four tabs that contain **Allocations**, **Call Tree**, **Functions**, and **Collections**
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Allocations** tab, you can see the types used and the number of their
    allocations. Clicking on a type brings up the **Backtrace** for that type. You
    can see the number of allocations for that type and the number of bytes allocated
    in your functions, as shown in *Figure 5.11*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.11 – The Visual Studio 2022 Performance Profiler allocations of
    System.Sbyte[]'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image87475.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.11 – The Visual Studio 2022 Performance Profiler allocations of System.Sbyte[]
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 5.11*, we can see that in our `Main` method, there are 19 allocations
    of the `System.Sbyte[]` type with an allocation size of **952** bytes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the `DisplayGeneration(Product product)` method, there is one `System.Int32`
    allocation that is **24** bytes in size, as shown in *Figure 5.12*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.12 – The Visual Studio 2022 Performance Profiler Call Tree tab'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.12_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.12 – The Visual Studio 2022 Performance Profiler Call Tree tab
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the `Main` method has a total of **347** allocations, **27** self-allocations,
    and is a total of **1,438** bytes in size, as shown in *Figure 5.13*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.13 – Visual Studio 2022 Performance Profiler Functions tab showing
    allocations and sizes for various methods'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.13_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.13 – Visual Studio 2022 Performance Profiler Functions tab showing
    allocations and sizes for various methods
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Collections** tab. Then, click on a row. You will see two pie
    charts for the top collected types and top survived types, as shown in *Figure
    5.14*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Visual Studio 2022 Performance Profiler showing a breakdown
    of the garbage collection'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.14_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.14 – Visual Studio 2022 Performance Profiler showing a breakdown of
    the garbage collection
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 5.14*, we can see the number of live objects over time along with
    the object delta (% change). Additionally, we can see the top collected types
    and top survived types in the two pie charts.
  prefs: []
  type: TYPE_NORMAL
- en: The Visual Studio 2022 Performance Profiler is a very useful tool that enables
    you to view allocations, byte sizes, and garbage collected and survived objects.
    You can also see the number of live objects over time. Now that you have been
    introduced to the profiler and know what it is capable of, let's move our attention
    to the JetBrains tool called **dotMemory**.
  prefs: []
  type: TYPE_NORMAL
- en: Using JetBrains dotMemory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We use dotMemory to profile and optimize memory and to help us identify memory
    leaks and other memory-related issues. In this section, we will be discussing
    the JetBrains dotMemory memory profiler.
  prefs: []
  type: TYPE_NORMAL
- en: 'The memory profiler will provide a chart with milliseconds on the *x* axis
    and megabytes on the *y* axis, which shows your application''s memory usage over
    time. The following list of items is displayed on the chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Total used**: The total amount of memory used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unmanaged memory**: The total amount of memory placed on the stack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heap generation 0**: The amount of memory taken up by new objects. These
    objects will be less than 80,000 bytes in size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heap generation 1**: The objects that survive generation 0 garbage collection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Heap generation 2**: Long-lived objects that survive level 1 garbage collection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Large object heap (LOH)**: The amount of memory used by objects that are
    80,000 bytes or larger in size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Allocated in LOH since GC**: The amount of memory used on the LOH after garbage
    collection has taken place.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see the dotMemory memory profiler in action. If you have not already
    done so, download and install dotMemory from JetBrains and the code for `chapter
    4` from the GitHub page. Open dotMemory, and you will be presented with a screen
    similar to the one shown in *Figure 5.15*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – The dotMemory Memory Profiler ready to profile .NET Core Application'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.15_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.15 – The dotMemory Memory Profiler ready to profile .NET Core Application
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Figure 5.15*, we have selected to profile `CH04_PreventingMemoryLeaks.dll`.
    Click on the **Run** button. This will enable the profiler to start running and
    profiling your application. Once the application has been profiled, a report will
    be displayed showing the results in graphical form, as shown in *Figure 5.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.16 – The profile report for CH04_PreventingMemoryLeaks.dll'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.16_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.16 – The profile report for CH04_PreventingMemoryLeaks.dll
  prefs: []
  type: TYPE_NORMAL
- en: As you can see from the preceding screenshot, our application uses a total of
    **8.16 MB** of memory. This is not that much. Most of the memory is placed on
    the stack, as shown by the unmanaged memory usage at **8.06 MB**. The rest of
    the memory is on the heap. On the heap, **24 KB** has been allocated on generation
    **0**, **77.6 KB** has been allocated on generation **1**, and **1.3 KB** has
    been allocated on generation **2**. The most heap memory, **19.2 KB**, was placed
    on the LOH and did not remain after garbage collection.
  prefs: []
  type: TYPE_NORMAL
- en: Having seen the dotMemory tool in action, we can now turn our attention to what
    the JetBrains dotTrace tool has to offer us in terms of tracing and profiling.
  prefs: []
  type: TYPE_NORMAL
- en: Using JetBrains dotTrace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will be looking at JetBrains dotTrace. You will learn how
    to use the JetBrains dotTrace tool to perform application tracing at runtime on
    your programs. This will help you to identify bottlenecks and memory issues in
    your executable programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The profiler options available in dotTrace include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling**: An accurate measurement of call time. This is optimal for most
    use cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tracing**: An accurate measurement of call number. This is optimal for analyzing
    algorithm complexity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line-byline**: Advanced use cases only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timeline**: The measurement of temporal performance data. This is optimal
    for most use cases, including the analysis of multithreaded applications:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.17 – JetBrains dotTrace ready to profile our application'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.17_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.17 – JetBrains dotTrace ready to profile our application
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.17* shows the initial state of dotTrace. We have selected **CH03_PassByValueAndReference.exe**
    as our application to profile. And for our profiling option, we have selected
    to go with the default **Sampling** setting. Make sure that **Collect profiling
    data from start** is selected. Then, click on the **Run** button to start tracing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When the tracing has been completed, the dotTrace Performance Viewer will automatically
    open, as shown in *Figure 5.18*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.18 – JetBrains dotTrace Performance Viewer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.18_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.18 – JetBrains dotTrace Performance Viewer
  prefs: []
  type: TYPE_NORMAL
- en: 'The outcome of profiling the `CH03_PassByValueAndReference.exe` file is shown
    in the default view of *Figure 5.18*. If you click on the `Main` line, you will
    see the program code. The breakdown of the `Main` method shows that 19 ms (43.20%)
    of time was spent executing system code, 13 ms (29.56%) of time was spent performing
    File I/O, and 12 ms (27.24%) of time was executing the **String** subsystem, as
    shown in *Figure 5.19*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Breakdown of the main method'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.19_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.19 – Breakdown of the main method
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.19* shows the `Main` method source code and the fact that between
    `Main` and `InParameterModifier`, the `Main` method takes the most time to process.
    This information can be helpful to identify and work with bottlenecks.'
  prefs: []
  type: TYPE_NORMAL
- en: We have seen two tools for memory profiling and tracing that can be used to
    measure performance and identify bottlenecks and problems. Now, let's move our
    attention to installing and using `dotnet-counters`.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and using dotnet-counters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will install and use `dotnet-counters`. These counters are
    very useful data-gathering tools that help us to monitor the health of our programs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open Developer Command Prompt for Visual Studio 2022\. Then, type in the following
    command and press *Enter*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This will download and install dotnet-tools. A successful installation will
    be presented, as shown in *Figure 5.20*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.20 – The successful installation of dotnet-tools version 3.1.141901
    using'
  prefs: []
  type: TYPE_NORMAL
- en: Developer Command Prompt
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.20_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.20 – The successful installation of dotnet-tools version 3.1.141901
    using Developer Command Prompt
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of using `dotnet-counters` is to perform health monitoring and
    a first-level performance investigation of your applications. If when using this
    program, potential performance problems are identified, then you can perform a
    more serious performance investigation using tools such as PerfView or dotnet-trace:'
  prefs: []
  type: TYPE_NORMAL
- en: To periodically collect selected counter values and export them to a file for
    post-processing, use the `dotnet-counters collect` command.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `dotnet-counters list` command displays a list of the counter names and
    descriptions that are grouped by the provider.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And to display a list of .NET processes that can be monitored, you can use the
    `dotnet-counters ps` command.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the `dotnet-counters monitor` command, you can display periodically refreshed
    values for selected counters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To get a list of the available options for each command, append `-h` or `–help`.
    Let''s put each of those commands to use. And before we do, add the following
    lines to the end of the `CH04_WeakRefereces` `Main` method in the `Program` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Run the program. It will pause and wait for you to press a key before it continues.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting data and saving it to a file for post-analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we will use `dotnet-counters` to save data to a file that we can analyze
    once our program has finished running:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove the breakpoint of `CH04_WeakReferences` in the `Program` class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Update the `ProcessReferences()` method in the `Program` class as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Add a breakpoint to the `while (x < 10000)` loop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, run the program. Running the program will require some time – approximately
    10,000 iterations x 2 seconds = 5.5h.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the program stops on the breakpoint added in *step 3*, open Command Prompt
    as an admin and type in `dotnet-counters ps` followed by *Enter*. If you don't
    run as an admin, you will encounter counter access errors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obtain the process ID for the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the directory in Command Prompt to point to `C:\Temp`. Create the directory
    if it does not exist.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the `dotnet-counters collect --process-id 1234` command (replace **1234**
    with the ID of your .NET process) followed by *Enter*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The performance data will now be collected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Remove the breakpoint added in *step 3* and continue the program. When you
    have let the program run a little while, press the *q* key. Your Command Prompt
    screen should look similar to *Figure 5.21*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.21 – The Developer Command Prompt having completed a collection'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.21_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.21 – The Developer Command Prompt having completed a collection
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the file called `C:\Temp\counter.csv` in **Excel**. *Figure 5.22* shows
    an excerpt of the data contained within the spreadsheet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.22 – An excerpt from counter.csv'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.22_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.22 – An excerpt from counter.csv
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are various items that are recorded by the `dotnet-counters`
    collect process. These items include CPU usage, garbage collection data, heap
    information, exception information, the number of loaded assemblies, and JIT compilation
    information.
  prefs: []
  type: TYPE_NORMAL
- en: Listing .NET processes that can be monitored
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To list .NET processes that can be monitored, open the Developer Command Prompt
    screen and type in the `dotnet-counters ps` command. You should see an output
    similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23 – The list of .NET processes that can be monitored'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.23_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.23 – The list of .NET processes that can be monitored
  prefs: []
  type: TYPE_NORMAL
- en: As *Figure 5.23* shows, the only process that can be monitored is process **5364**.
    Process **5364** is the program that we are currently debugging. If more .NET
    programs were running, then more would appear on this list.
  prefs: []
  type: TYPE_NORMAL
- en: Listing the available list of well-known .NET counters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To list the available .NET counters, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see a list of counters and their descriptions output to the console.
    For `Microsoft.AspNetCore.Hosting`, the available counters are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**requests-per-second**: The request rate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**total-requests**: The total number of requests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**current-requests**: The current number of requests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**failed-requests**: The failed number of requests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The available well-known counters for `System.Runtime` are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**cpu-usage**: The amount of time the process has utilized the CPU in milliseconds'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**working-set**: The amount of working set used by the process in megabytes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gc-heap-size**: The total heap reported by the garbage collector in megabytes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gen-0-gc-count**: The number of generation 0 garbage collections per minute'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gen-1-gc-count**: The number of generation 1 garbage collections per minute'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gen-2-gc-count**: The number of generation 2 garbage collections per minute'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**loh size**: Large object heap size'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**alloc-rate**: The number of bytes allocated in the managed heap per second'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**assembly-count**: The number of assemblies loaded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**exception-count**: The number of exceptions per second'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**threadpool-thread-count**: The number of thread pool threads'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**monitor-lock-contention-count**: The number of times there were contentions
    when trying to take the monitor lock per second'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**threadpool-queue-length**: The number of work items in the thread pool queue'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**threadpool-completed-items-count**: The number of completed work items in
    the thread pool'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**active-timer-count**: The number of timers that are currently active'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring a .NET process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are going to run our `CH04_WeakReferences` project. Once you have the project
    running, run the following command to get the process ID:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, once you have the process ID for your .NET program, run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'For me, the process has an ID of **6719**. Replace **6719** with whatever your
    process ID is. The result should be that you see the .NET counters being displayed
    and updated in real time, as shown in *Figure 5.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24 – The dotnet-counters being listed and updated in real time for
    our'
  prefs: []
  type: TYPE_NORMAL
- en: CH04_WeakReferences project
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.24_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.24 – The dotnet-counters being listed and updated in real time for
    our CH04_WeakReferences project
  prefs: []
  type: TYPE_NORMAL
- en: Press *q* to quit. As you can see, we have **19.042%** garbage collection fragmentation.
    There are **19,640** bytes on the LOH, and **80,864** bytes are assigned to generation
    **2**. We have **9** assemblies loaded and **24** bytes allocated to generation
    **0** and generation **1**. We have observed that memory fragmentation has occurred
    at **19.042%**, so this can be investigated further to see why we have fragmentation
    and to see whether we can avoid this.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we are going to look at an example that tracks down a memory
    leak in a WPF application.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking down and fixing a memory leak with dotMemory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to run through an example of how to track down
    and fix memory leaks. A `OutOfMemoryException` exception being thrown by the application.
  prefs: []
  type: TYPE_NORMAL
- en: Our example will be a WPF application called `CH05_GameOfLife`. To save time
    and space, download the source code for the WPF application. This will help you
    to focus on the task at hand, which is to track down the memory leak and fix it.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: When profiling and tracing, you are better off building your projects using
    **Release** mode. The reason for this is that **Debug** builds contain compiler
    instructions that might affect profiling results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download and compile the `CH05_GameOfLife` project in **Release** mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open **dotMemory**. The version used in this example is **2020.3.4**
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Under **New Session**, select **Local**. Then, under **Profile Application**,
    select **.NET Core Application**. Select the **CH05_GameOfLife.exe** file under
    **.NET Core Application**, and for the **Profiler Options**, select **Collect
    memory allocation and traffic data from the start**. *Figure 5.25* shows dotMemory
    prepared to profile our application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.25 – dotMemory ready to profile our .NET 6.0 application CH05_GameOfLife.exe'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.25_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.25 – dotMemory ready to profile our .NET 6.0 application CH05_GameOfLife.exe
  prefs: []
  type: TYPE_NORMAL
- en: 'Click **Run** to start profiling our application. You will see a new **Analysis**
    tab appear in dotMemory, as shown in *Figure 5.26*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.26 – dotMemory displaying the Analysis tab during the profiling
    of our app'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.26 – dotMemory displaying the Analysis tab during the profiling of
    our app
  prefs: []
  type: TYPE_NORMAL
- en: 'When the profiler starts, it also starts our application. Click on the **Start**
    button of our application, as shown in *Figure 5.27*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.27 – Running CH05_GameOfLife'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Image87625.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.27 – Running CH05_GameOfLife
  prefs: []
  type: TYPE_NORMAL
- en: After *Game of Life* has been running for a while, click on the **Get Snapshot**
    button to take a memory snapshot. This will capture the application's managed
    heap at that moment in time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Close the advert.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Take another snapshot so that we have two snapshots. Then, close the *Game
    of Life* application to stop the profiler. *Figure 5.28* shows the dotMemory **Analysis**
    tab with both snapshots taken:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.28 – The dotMemory Analysis tab displaying both memory snapshots'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.28 – The dotMemory Analysis tab displaying both memory snapshots
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is for us to compare the two different snapshots. *Figure 5.29*
    shows a close-up of the two snapshots side by side:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.29 – dotMemory snapshots 1 and 2'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.29 – dotMemory snapshots 1 and 2
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Compare** to open the detailed side-by-side comparison of the two
    snapshots. You should see the comparison, as shown in *Figure 5.30*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.30 – The side-by-side snapshot comparison screen'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.30_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.30 – The side-by-side snapshot comparison screen
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this view shows the number of new objects created, the number
    of objects that have been collected (dead objects) by the garbage collector, and
    the number of objects that have survived garbage collection. This is a good source
    of information that can be used to identify memory leaks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Namespace** column. Then, expand the **CH05_GameOfLife** namespace
    and highlight the **AdWindow** entry, as shown in *Figure 5.31*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.31 – The analysis by Namespace with CH05_GameOfLife highlighted'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.31_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.31 – The analysis by Namespace with CH05_GameOfLife highlighted
  prefs: []
  type: TYPE_NORMAL
- en: 'In the **Survived objects** column, click on number **1** in the **AdWindow**
    row. This will bring up the dialog, as shown in *Figure 5.32*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.32 – dotMemory dialog prompting the opening of a snapshot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.32_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.32 – dotMemory dialog prompting the opening of a snapshot
  prefs: []
  type: TYPE_NORMAL
- en: Select the newer snapshot option.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, click on the **Key Retention Paths** tab. The JetBrains dotMemory view
    will change to a view that is similar to *Figure 5.33*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.33 – The Key Retention Paths tab'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.33_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.33 – The Key Retention Paths tab
  prefs: []
  type: TYPE_NORMAL
- en: You can see that `EventHandler` is keeping `AdWindow` alive, and `EventHandler`
    is referenced by the `DispatcherTimer` class. The `DispatcherTimer` class is referenced
    by the `Tick` event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the `DispatcherTimer` box. This will take you to the `DispatcherTimer`
    class, as shown in *Figure 3.34*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.34 – The Outgoing References table displaying the details of DispatcherTimeruse'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.34_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.34 – The Outgoing References table displaying the details of DispatcherTimeruse
  prefs: []
  type: TYPE_NORMAL
- en: This tab certainly shows that `Tick EventHandler` is retaining bytes, which
    is leading to our `DispatcherTimer` object being kept alive in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the `EventHandler` creation. The method appears at the top, as shown
    in *Figure 3.35*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 3.35 – The Creation Stack Trace tab showing the AdWindow constructor
    that creates the timer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.35_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.35 – The Creation Stack Trace tab showing the AdWindow constructor
    that creates the timer
  prefs: []
  type: TYPE_NORMAL
- en: 'Locate the `AdWindow` constructor in the `AdWindow` class of the **CH05_GameOfLife**
    project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see from the preceding code snippet, we are subscribing to the `Tick`
    event, which is handled by the `ChangeAds` method. But the one thing we are not
    doing is unsubscribing from the event when we no longer require it. This is the
    reason for the memory leak.
  prefs: []
  type: TYPE_NORMAL
- en: 'To rectify our memory leak, all we have to do is unsubscribe from the event
    when we no longer need it. And to do this, we update the `OnClosed` method, as
    shown in the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We have now rectified our memory leak by unsubscribing from the `Tick` event
    when we close the `AdWindow` constructor. Repeat the steps to profile this memory
    leak, and you will see that it has now been fixed, as shown in *Figure 5.36*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.36 – dotMemory showing that the memory leak has been fixed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.36.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.36 – dotMemory showing that the memory leak has been fixed
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We have effectively tracked down and fixed a memory leak with dotMemory. The
    memory leak was because we did not unsubscribe from an event we were subscribed
    to. This is a very common source of memory leaks in C#. To learn more about dotMemory
    and how to use it in various scenarios, please visit the official How-To documentation
    by JetBrains at [https://www.jetbrains.com/help/dotmemory/Examples.html](https://www.jetbrains.com/help/dotmemory/Examples.html).
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how to track down and fix a UI freeze using
    dotTrace.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the cause of a UI freeze with dotTrace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will be using dotTrace to hunt down the reason for a UI
    freeze so that we can fix it. Again, to save time, we will use a project that
    has already been provided for you. Obtain the book's source code from the URL
    specified in the *Technical requirements* section. In the source code for `CH05`,
    you will find a project called `CH05_BatchFileProcessing`.
  prefs: []
  type: TYPE_NORMAL
- en: This project opens a number of text files specified by the user and then reverses
    each of the strings it finds. When the user clicks on the `BackgroundWorker` thread
    is started that runs on a separate thread. In the left-hand corner, the progress
    of file processing is displayed. This changes to **All files were successfully
    processed when done**. However, a problem exists whereby the UI freezes while
    the files are being processed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find the source of this UI freeze and fix it, we are going to use timeline
    profiling, which is available using dotTrace:'
  prefs: []
  type: TYPE_NORMAL
- en: Build the **CH05_BatchFileProcessing** project in **Release** mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open dotTrace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select **Profile Local App** | **.NET Core Application** | **Timeline**, and
    select the executable you just compiled. Make sure to tick **Collect profiling
    data from start**. *Figure 5.37* shows dotTrace being configured before we start
    running it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.37 – dotTrace prior to us running the Timeline profiler'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.37_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.37 – dotTrace prior to us running the Timeline profiler
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Run** button to begin the timeline profiling. The profiler will
    be opened, as shown in *Figure 5.38*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.38 – The dotTrace Timeline profiler'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.38_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.38 – The dotTrace Timeline profiler
  prefs: []
  type: TYPE_NORMAL
- en: 'The profiler will start the **CH05_BatchFileProcessor** program, as shown in
    *Figure 5.39*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.39 – The batch file processor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.39_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.39 – The batch file processor
  prefs: []
  type: TYPE_NORMAL
- en: 'When the application has finished processing the files, the UI will be displayed,
    as shown in *Figure 5.40*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.40 – CH05_BatchFileProcessor'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.40_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.40 – CH05_BatchFileProcessor
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Get Snapshot** and **Wait** buttons on the timeline profiler.
    This will save the snapshot and open it in the dotTrace **Timeline Viewer** application,
    as shown in *Figure 5.41*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.41 – The dotTrace Timeline Viewer application with a loaded timeline
    snapshot'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.41.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.41 – The dotTrace Timeline Viewer application with a loaded timeline
    snapshot
  prefs: []
  type: TYPE_NORMAL
- en: You can close the **CH05_BatchFileProcessor** and dotTrace profiler applications
    down. But keep the dotTrace **Timeline Viewer** application open.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All filter values are calculated for all currently visible threads. We are only
    interested in threads that have activity on them. So, hide all threads that have
    no activity on them by selecting them, right-clicking, and selecting **Hide**
    selected threads.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Our **BackgroundWorker** thread is the **.NET ThreadPoolWorker** thread with
    an ID of **12764**, as shown in *Figure 5.42*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.42 – The dotTrace Timeline Viewer application with our'
  prefs: []
  type: TYPE_NORMAL
- en: BackgroundWorker thread highlighted
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.42.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.42 – The dotTrace Timeline Viewer application with our BackgroundWorker
    thread highlighted
  prefs: []
  type: TYPE_NORMAL
- en: 'Zoom into the timeline for the **.NET ThreadPool Worker**. You can see that
    the timeline consists of three states. These states are **Running**, **Waiting
    for CPU**, and **Waiting**. You can see our thread''s timeline in *Figure 5.43*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.43 – Our thread''s activity within the timeline trace'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.43_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.43 – Our thread's activity within the timeline trace
  prefs: []
  type: TYPE_NORMAL
- en: 'On the left-hand side of the screen, you will see the **Thread State** section
    within the **Filters** panel. Select each of the states in turn, and you will
    see the timeline highlighted accordingly. Have a play with all of the different
    filters available. Investigate what each option provides you. This is a good way
    to learn. The collapsed **Filters** panel is displayed in *Figure 5.44*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.44 – The collapsed dotTrace Filters panel'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.44_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.44 – The collapsed dotTrace Filters panel
  prefs: []
  type: TYPE_NORMAL
- en: 'On the right-hand side of the screen, you will see the **Call Stack** panel
    and the **Source View** panel. If you click anywhere on the thread''s timeline,
    you will see the call stack at that point in time. The call tree will be displayed
    for that stack trace. If you click on an entry in the call stack, the code will
    be decompiled and displayed within the **Source View** tab. This functionality
    enables you to see what code is running at what point in time. Also, this view
    displays the full assembly''s name, namespace, and class name for the code you
    are looking at. *Figure 5.45* displays the **Call Stack** panel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.45 – The dotTrace Call Stack panel with the Backtraces tab displayed'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.45_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.45 – The dotTrace Call Stack panel with the Backtraces tab displayed
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5.46* displays the **Source View** panel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.46 – The dotTrace Source View screen showing decompiled C# and IL
    source code'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.46_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.46 – The dotTrace Source View screen showing decompiled C# and IL source
    code
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The colored bar that runs across the `String`. Depending on what is happening
    at a particular point in time, this line might be multicolored if multiple subsystems
    are in use. This bar is also useful for showing thread locks, among other things.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we are ready to investigate why our UI is freezing. The purple lines in
    *Figure 5.47* represent moments in time when our UI is freezing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.47 – The dotTrace filtered view displaying our thread and highlighting
    UI freezes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.47_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.47 – The dotTrace filtered view displaying our thread and highlighting
    UI freezes
  prefs: []
  type: TYPE_NORMAL
- en: The purple line that we are interested in is the last very long one.
  prefs: []
  type: TYPE_NORMAL
- en: In the **Filters** section, select **Events** | **.NET Memory Allocation**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, select **Thread State** | **Running**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select **Subsystems** | **User code**, and deselect everything else. You should
    see the following under **Methods and Subsystems**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.48 – The dotTrace Methods and Subsystems screen highlighting problematic
    user code'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.48_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.48 – The dotTrace Methods and Subsystems screen highlighting problematic
    user code
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the preceding highlighted method called `ProcessInProgress`, we
    are calling it 100% of the time during the time period when the UI freeze occurs.
    Clicking on `ProcessInProgress` will display the contents of the `MainWindow.xaml.cs`
    file. Our offending code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Our code is updating the progress label with the value passed into the method,
    which is of the `ProgressChangedEventArgs` type. So, what is calling this method?
    It is the `ProcessFiles` method in the `FileProcessor` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This method iterates through the files that the user has selected. Each file
    is read along with each line, line by line. Each line has its text reversed. The
    problem is that we are calling this method far too often. So, the solution is
    to change `(j % 5 == 0)` to `(j% 1000 == 0)`.
  prefs: []
  type: TYPE_NORMAL
- en: Make the change to the code recompile and rerun the profiler. This time, there
    will be no lag. And you will see that the UI freeze has been fixed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now you have used dotTrace and the Timeline profile to track down and fix a
    UI freeze. In the final section, we will look at using dotTrace to optimize application
    performance and memory traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing application performance and memory traffic with dotTrace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we are going to continue tracing our `CH05_BatchFileProcessing`
    project. We have fixed the UI freeze and will be running another trace to see
    whether we can identify any further issues. When analyzing the trace, we will
    see that a lot of memory traffic is being generated that is affecting the performance
    of our application. So, we will address this issue and fix it:'
  prefs: []
  type: TYPE_NORMAL
- en: Open dotTrace. Your previous session should be saved. Select it, and click on
    the **Run** button to start tracing. The sample application will then be started.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the text files, and click on the **Process Files** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the files have been processed, kill the application. This will flush the
    data and load our trace in the trace viewer. Then, close dotTrace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the trace snapshot has been loaded into **Timeline Viewer**, click on the
    button to **Show Snapshot**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Filters** view, select **Events** | **.NET Memory Allocations and Thread
    State** | **Running**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hide all threads except our **.NET ThreadPool Worker** thread.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `System.String` class. This will be the result of our `CH05_BatchFileProcessing.StringReverse.Reverse()`
    call. *Figure 5.49* shows the results of our trace in which we can see our methods
    and the percentages of memory traffic they generate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.49 – The dotTrace Timeline Viewer Call Stack screen showing our
    methods and memory traffic percentage'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.49_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.49 – The dotTrace Timeline Viewer Call Stack screen showing our methods
    and memory traffic percentage
  prefs: []
  type: TYPE_NORMAL
- en: The two different MB sizes are our own memory allocation in this method excluding
    memory allocations in the child method calls from this method/the amount of memory
    allocated by this method or any child methods called from this method. As you
    can see, the memory allocation is `Reverse()` method and `ProcessFiles()` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open this class in Visual Studio. The code for the `Reverse()` method is as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, this method reverses a string by assigning it to an array. The
    array is then iterated backward, with each character assigned to a string using
    string concatenation. And herein lies the problem with our application's performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is well documented that the most performant way to build up a string is
    to use the `StringBuilder` class. And we could do that here. However, there is
    another way to improve the performance of this method. Replace the existing `Reverse()`
    string method with the following version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In our revised code, we reverse the array and return a new string from the reverse
    array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Build your project in **Release** mode and then run a new trace. *Figure 5.50*
    shows the results of the new trace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.50 – The new trace showing our improved performance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/Figure_5.50_B16617.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.50 – The new trace showing our improved performance
  prefs: []
  type: TYPE_NORMAL
- en: We can see from our trace that the memory allocation for the `ProcessFiles`
    method went from **2.9 MB**/**255 MB**, generating **1.2%** of the memory traffic,
    to **3.8 MB**/**37 MB** of memory allocation, generating **10.1%** of the memory
    traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Plus, our `Reverse()` method went from allocating **73 MB**/**252 MB**, and
    generating **28.5%** of the memory traffic, to allocating **0 MB**/**19 MB** of
    memory, generating **0%** of the memory traffic.
  prefs: []
  type: TYPE_NORMAL
- en: That is a good performance improvement!
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have covered various methods of measuring and analyzing
    code. With the data we obtained, we have managed to fix a memory leak caused by
    not unsubscribing to event handlers, fix a UI freeze caused by too frequent UI
    updates, and improve the application performance and memory traffic caused by
    the way we were batch processing string reversal. Now, it is time to summarize
    what we have learned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We started with application profiling and tracing by looking at the various
    code metrics that are available to us. Various tools have different metrics available.
    These metrics cover the application, assemblies, namespaces, types, methods, and
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we moved on to look at how we can perform static code analysis. We demonstrated
    static code analysis using Visual Studio 2022''s built-in code analysis tool.
    We saw how to generate the following metrics: the maintainability index, cyclomatic
    complexity, the depth of inheritance, class coupling, lines of source code, and
    lines of executable code.'
  prefs: []
  type: TYPE_NORMAL
- en: The next thing we looked at was the generation of memory dumps and how to view
    them from within Visual Studio 2022\. We can view the dump time, the dump's location,
    the name of the process, the processor architecture, any exception information,
    the OS version, and the CLR version. Additionally, we can view loaded module names
    and their versions and physical paths.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we looked at how to open the **Modules** window during a debugging session.
    The **Modules** window shows us the name and path of the module, whether the module
    is optimized, whether it is user code or system code, its symbol status, order,
    version, process, and AppDomain. We also saw the other options available in the
    **Debug** | **Windows** menu that add to our debugging capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we looked at the tracing and diagnostics tools called Visual Studio 2022,
    JetBrains dotMemory, and JetBrains dotTrace. These tools provide an overall excellent
    debugging experience that provides all the information we need to track down any
    type of bug, including those that cause memory leakages and other memory-related
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we looked at `dotnet-counters` and how to use this. We learned how to
    list the .NET processes that can be monitored. Then, we saw how to list the available
    well-known .NET counters. And our concluding section saw us collecting data and
    saving data to a file for post-analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we worked through three examples of using JetBrains dotMemory and JetBrains
    dotTrace to fix a memory leak and UI freeze, improve performance, and reduce memory
    traffic.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will be taking a detailed look at the **Collections**
    framework. However, before then, take the time to further your reading and answer
    the following questions to reinforce what you have learned.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What aspects of our computer programs are covered by code metrics?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What metrics does the Visual Studio 2022 static code analysis produce?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What kinds of things can we view from the Visual Studio-generated minidumps
    with heap?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What columns are available in the **Modules** window?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the names of the four debugging, profiling, and tracing tools for performing
    the various diagnostic operations that we mentioned earlier?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What operations did we carry out using .NET counters?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Debugging Visual Studio 2019: [https://docs.microsoft.com/en-us/visualstudio/get-started/csharp/tutorial-debugger?view=vs-2019](https://docs.microsoft.com/en-us/visualstudio/get-started/csharp/tutorial-debugger?view=vs-2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dump files in the Visual Studio debugger: https://docs.microsoft.com/visualstudio/debugger/using-dump-files?view=vs-2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dotnet-counters`: https://docs.microsoft.com/en-us/dotnet/core/diagnostics/dotnet-counters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*.NET Core Counters internals: how to integrate counters in your monitoring
    pipeline*: [https://medium.com/criteo-engineering/net-core-counters-internals-how-to-integrate-counters-in-your-monitoring-pipeline-5354cd61b42e#:~:text=dotnet-counters%3A%20collect%20the%20metrics%20corresponding%20to%20some%20performance,how%20to%20fetch%20them%20via%20the%20EventPipe%20infrastructure](https://medium.com/criteo-engineering/net-core-counters-internals-how-to-integrate-counters-in-your-monitoring-pipeline-5354cd61b42e#:~:text=dotnet-counters%3A%20collect%20the%20metrics%20corresponding%20to%20some%20performance,how%20to%20fetch%20them%20v).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*JetBrains dotTrace*: https://www.jetbrains.com/profiler/.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*JetBrains dotMemory*: [https://www.jetbrains.com/dotmemory/](https://www.jetbrains.com/dotmemory/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ndepend*: [https://www.ndepend.com/](https://www.ndepend.com/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Overview of .NET source code analysis*: [https://docs.microsoft.com/dotnet/fundamentals/code-analysis/overview](https://docs.microsoft.com/dotnet/fundamentals/code-analysis/overview).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
