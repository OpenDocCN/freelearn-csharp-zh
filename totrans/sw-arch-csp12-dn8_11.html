<html><head></head><body>
<div><h1 class="chapterNumber">11</h1>
<h1 class="chapterTitle" id="_idParaDest-216">Applying a Microservice Architecture to Your Enterprise Application</h1>
<p class="normal">This chapter is dedicated to describing highly scalable architectures based on small modules called microservices. The microservice architecture allows for fine-grained scaling operations where every single module can be scaled as required without affecting the remainder of the system. Moreover, they allow for better <strong class="keyWord">Continuous Integration/Continuous Deployment</strong> (<strong class="keyWord">CI/CD</strong>) by permitting every system subpart to evolve and be deployed<a id="_idIndexMarker748"/> independently of the others.</p>
<p class="normal">In this chapter, we will cover the following topics:</p>
<ul>
<li class="bulletList">What are microservices?</li>
<li class="bulletList">When do microservices help?</li>
<li class="bulletList">How does .NET deal with microservices?</li>
<li class="bulletList">Which tools are needed to manage microservices?</li>
</ul>
<p class="normal">By the end of this chapter, you will have learned how to implement a single microservice in .NET. <em class="chapterRef">Chapter 20</em>, <em class="italic">Kubernetes</em>, also explains how to deploy, debug, and manage a whole microservices-based application. <em class="chapterRef">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET</em>, and <em class="chapterRef">Chapter 18</em>, <em class="italic">Implementing Frontend Microservices with ASP.NET Core,</em> are step-by-step guides to the practical implementation of microservices with .NET.</p>
<h1 class="heading-1" id="_idParaDest-217">Technical requirements</h1>
<p class="normal">The code for this chapter is available at <a href="https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E">https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E</a>.</p>
<p class="normal">In this chapter, you will require the following:</p>
<ul>
<li class="bulletList">Visual Studio 2022 free Community Edition or better with all the database tools installed.</li>
<li class="bulletList">A free Azure account. The <em class="italic">Creating an Azure account</em> section in <em class="chapterRef">Chapter 1</em>, <em class="italic">Understanding the Importance of Software Architecture</em>, explains how to create one.</li>
<li class="bulletList"><strong class="keyWord">Docker Desktop for Windows</strong> if you want to debug Docker containerized microservices in Visual Studio (<a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a>).</li>
</ul>
<p class="normal">In turn, <strong class="keyWord">Docker Desktop for Windows</strong> requires at least Windows 10 with either <strong class="keyWord">Windows Subsystem for Linux </strong>(<strong class="keyWord">WSL</strong>) or <strong class="keyWord">Windows Containers</strong> installed.</p>
<p class="normal"><strong class="keyWord">WSL</strong> enables Docker containers to run on a Linux virtual machine and can be installed as follows (see also <a href="https://learn.microsoft.com/en-us/windows/wsl/install">https://learn.microsoft.com/en-us/windows/wsl/install</a>):</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Type <code class="inlineCode">powershell</code> in the Windows 10/11 search bar.</li>
<li class="numberedList">When <strong class="screenText">Windows PowerShell</strong> is proposed as a search result, click on <strong class="screenText">Run as an administrator</strong>.</li>
<li class="numberedList">In the Windows PowerShell administrative console that appears, run the command <code class="inlineCode">wsl --install</code>.</li>
</ol>
<p class="normal"><strong class="keyWord">Windows Containers</strong> enable Docker containers to run directly on Windows, but they require at least the Windows Professional edition. They can be installed as follows:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Type <code class="inlineCode">Windows features</code> in the Windows 10/11 search bar.</li>
<li class="numberedList">The search results will propose running the panel to enable/disable Windows features.</li>
<li class="numberedList">Click on it, and in the window that opens, select <strong class="screenText">Containers</strong>.</li>
</ol>
<h1 class="heading-1" id="_idParaDest-218">What are microservices?</h1>
<p class="normal">Microservices are essentially<a id="_idIndexMarker749"/> small, independent units that make up a larger software application, each with its specific role and functionality. Splitting a software application into independent microservices allows each module that makes up a solution to be scaled independently from the others to achieve the maximum throughput with minimal cost. In fact, scaling whole systems instead of their current bottlenecks inevitably results in a remarkable waste of resources, so fine-grained control of subsystem scaling has a considerable impact on the system’s overall cost.</p>
<p class="normal">However, microservices<a id="_idIndexMarker750"/> are more than scalable components – they are software building blocks that can be developed, maintained, and deployed independently of each other. Splitting development and maintenance among modules that can be independently developed, maintained, and deployed improves the overall system’s CI/CD cycle (CI/CD was described in detail in <em class="chapterRef">Chapter 8</em>, <em class="italic">Understanding DevOps Principles and CI/CD</em>).</p>
<p class="normal">The CI/CD improvement<a id="_idIndexMarker751"/> is due to microservice <em class="italic">independence</em> because it enables the following:</p>
<ul>
<li class="bulletList">Scaling and distributing microservices on different types of hardware.</li>
<li class="bulletList">Since each microservice is deployed independently from the others, there can’t be binary compatibility or database structure compatibility constraints. Therefore, there is no need to align the versions of the different microservices that compose the system. This means that each of them can evolve as needed without being constrained by the others.
    <p class="normal">However, attention must be paid to the choice of communication protocols and messages and to their versions, which must be supported by all involved microservices. Protocols that are widely supported and that facilitate backward compatibility with previous versions of messages should be preferred.</p></li>
</ul>
<ul>
<li class="bulletList">Assigning their development to completely separate smaller teams, thus simplifying job organization and reducing all the inevitable coordination inefficiencies that arise when handling large teams.</li>
<li class="bulletList">Implementing each microservice with more adequate technologies and in a more adequate environment since each microservice is an independent deployment unit. This means choosing tools that best fit your requirements and an environment that minimizes development efforts and/or maximizes performance.</li>
<li class="bulletList">Since each microservice can be implemented with different technologies, programming languages, tools, and operating systems, enterprises can use all available human resources by matching environments with developers’ competencies. For instance, all available Java and .NET developers can cooperate in the same application, thus exploiting all available resources.</li>
<li class="bulletList">Legacy subsystems can be embedded in independent microservices, thus enabling them to cooperate with newer subsystems. This way, companies may reduce the time to market new system versions. Moreover, in this way, legacy systems can evolve slowly toward more modern systems with an acceptable impact on costs<a id="_idIndexMarker752"/> and the organization.</li>
</ul>
<p class="normal">The next subsection explains how the concept of microservices was conceived. Then, we will continue this introductory section<a id="_idIndexMarker753"/> by exploring basic microservice design principles and analyzing why microservices are often designed as Docker containers.</p>
<h2 class="heading-2" id="_idParaDest-219">Microservices and the evolution of the concept of modules</h2>
<p class="normal">For a better understanding of the advantages<a id="_idIndexMarker754"/> of microservices, as well as their design techniques, we must keep the two-fold nature of software modularity and software modules in mind:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Code modularity</strong> refers to code organization that makes<a id="_idIndexMarker755"/> it easy for us to modify a chunk of code without affecting the remainder of the application. It is usually enforced with object-oriented design, where modules can be identified with classes.</li>
<li class="bulletList"><strong class="keyWord">Deployment modularity</strong> depends on what your deployment<a id="_idIndexMarker756"/> units are and which properties they have. The simplest deployment units are executable files and libraries. Thus, for instance, <strong class="keyWord">dynamic link libraries</strong> (<strong class="keyWord">DLLs</strong>) are, for sure, more modular than static libraries since<a id="_idIndexMarker757"/> they must not be linked with the main executable before being deployed.</li>
</ul>
<p class="normal">While the fundamental concepts of code modularity have reached stasis, the concept of deployment modularity is still evolving, and microservices are currently state-of-the-art along this evolution path.</p>
<p class="normal">As a short review of the main milestones on the path that led to microservices, we can say that, first, monolithic executables were broken into static libraries. Later on, DLLs replaced static libraries.</p>
<p class="normal">A great change took place when .NET (and other analogous frameworks, such as Java) improved the modularity of executables and libraries. In fact, with .NET, they can be deployed on different hardware and different operating systems since they are deployed in an intermediary language that is compiled when the library is executed for the first time. Moreover, they overcome some versioning issues of previous DLLs since any executable can bring with it a DLL with a version that differs from the version of the same DLL that is installed on the operating system.</p>
<p class="normal">However, .NET can’t accept two referenced DLLs – let’s say, <em class="italic">A</em> and <em class="italic">B</em> – using two different versions of a common dependency – let’s say, <em class="italic">C</em>. For instance, suppose there is a newer version of <em class="italic">A</em> with many new features we would like to use that, in turn, relies on a newer version of <em class="italic">C</em> that is not supported by <em class="italic">B</em>. In this situation, we should renounce the newer version of <em class="italic">A</em> because of the incompatibility of <em class="italic">C</em> with <em class="italic">B</em>. This difficulty has led to two important changes:</p>
<ul>
<li class="bulletList">Packages: The development world moved<a id="_idIndexMarker758"/> from using single DLLs and/or single files as deployment units to using packages composed of both DLLs and metadata as deployment units. Packages are handled by <em class="italic">package management systems</em> such as NuGet and npm, which use package metadata to automatically check version compatibility with the help of semantic versioning.</li>
<li class="bulletList"><strong class="keyWord">Service-Oriented Architecture</strong> (<strong class="keyWord">SOA</strong>): Deployment units started being implemented as SOAP-based<a id="_idIndexMarker759"/> web services and later transition to REST web services. This solves the version compatibility problem since each web service runs in a different process and can use the most adequate version of each library with no risk of causing incompatibilities with other web services. Moreover, the interface that is exposed by each web service is platform-agnostic; that is, web services can connect with applications using any framework and run on any operating system since web service protocols are based on universally accepted standards. SOAs and protocols will be discussed in more detail in <em class="chapterRef">Chapter 15</em>, <em class="italic">Applying Service-Oriented Architectures with .NET.</em></li>
</ul>
<p class="normal">Microservices are an evolution<a id="_idIndexMarker760"/> of SOA and add more features and more constraints that improve the scalability and the modularity of services to improve the overall CI/CD cycle. It’s sometimes said that microservices are SOA done well. Moreover, as we will see in the next section, microservices are strictly tied with the DDD methodology described in <em class="chapterRef">Chapter 7</em>, <em class="italic">Understanding the Different Domains in Software Solutions</em>.</p>
<p class="normal">To sum things up, the microservice<a id="_idIndexMarker761"/> architecture is an SOA that maximizes independence and fine-grained scaling. Now that we’ve clarified all the advantages of microservice independence and fine-grained scaling, as well as the very nature of independence, we are in a position to look at microservice design principles.</p>
<h2 class="heading-2" id="_idParaDest-220">Microservice design principles</h2>
<p class="normal">In this section, you will learn about<a id="_idIndexMarker762"/> the microservices’ basic design principles. These principles are the basis for designing each microservice’s code and architecture, and for designing the whole application architecture.</p>
<p class="normal">Let’s start with principles that arise from the independence constraint. We will discuss them each in a separate subsection.</p>
<h3 class="heading-3" id="_idParaDest-221">The independence of design choices</h3>
<p class="normal">A fundamental design<a id="_idIndexMarker763"/> principle is the <em class="italic">independence of design choices</em>, which can be stated as follows:</p>
<div><p class="normal">The design of each microservice must not depend on the design choices that were made in the implementation of other microservices.</p>
</div>
<p class="normal">This principle enables the full independence of each microservice CI/CD cycle and leaves us with more technological choices on how to implement each microservice. This way, we can choose the best available technology to implement each microservice.</p>
<p class="normal">Another consequence of this principle is that different microservices can’t connect to the same shared storage (database or filesystem) since sharing the same storage also means sharing all the design choices that determine the structure of the storage subsystem (database table design, database engine, and so on). Thus, either a microservice has its own data storage, or it has no storage at all and communicates with other microservices that take care of handling storage.</p>
<p class="normal">Dedicated data storage can be implemented either by physically including the database service within the boundary of the microservice or with an external database that the microservice has exclusive access to. Both are acceptable design choices. However, external databases are usually adopted because, for performance reasons, database engines are better run on dedicated hardware and with OS and hardware features that are optimized for their storage functionalities.</p>
<p class="normal">Usually, the <em class="italic">independence of design choices</em> is interpreted in a lighter form by distinguishing between logical and physical microservices. More specifically, logical microservices are the result of splitting the application into logical independent modules. If the application is designed with a <strong class="keyWord">domain-driven design</strong> (<strong class="keyWord">DDD</strong>) methodology, logical microservices correspond to DDD-bounded contexts, which we discussed in detail in <em class="chapterRef">Chapter 7</em>, <em class="italic">Understanding the Different Domains in Software Solutions</em>.</p>
<p class="normal">In turn, each logical microservice may be split into various physical microservices that use the same data storage but that are load-balanced independently to achieve a better load balance.</p>
<p class="normal">For instance, in the book case study, travel payments<a id="_idIndexMarker764"/> are handled by the Payments Bounded Context described in the Understanding the domains of the WWTravelClub application section of <em class="chapterRef">Chapter 21</em>, <em class="italic">Case Study</em>, which gives rise to a unique logical microservice. However, its practical implementation requires two main submodules:</p>
<ul>
<li class="bulletList">A customer credit card verification and authorization module, which takes care of all credit card verifications</li>
<li class="bulletList">A user credits management module, which handles credits that the user already purchased, card information already loaded in the platform, and new credit card info loading</li>
</ul>
<p class="normal">Since the process of credit card verification and authorization might be very time-consuming, it is convenient to implement the two submodules above as independent physical microservices, so they can be load-balanced separately.</p>
<h3 class="heading-3" id="_idParaDest-222">Independence from the deployment environment</h3>
<p class="normal">During load-balancing, microservices <a id="_idIndexMarker765"/>can be moved from very busy hardware nodes to more idle nodes. However, dependencies of each microservice on other software/files of the destination hardware nodes constrain the possible destination nodes.</p>
<p class="normal">Therefore, the more we reduce microservice dependencies, the more we have the freedom to move them from busy nodes to idle nodes, achieve a better load balance, and exploit the available hardware nodes.</p>
<p class="normal">This is the reason microservices are often containerized and use Docker. Containers will be discussed in more detail in the <em class="italic">Containers and Docker</em> subsection of this chapter, but basically, containerization is a technique that allows each microservice to bring its dependencies with it so that it can run anywhere. However, this is not a must because, in some applications, one might verify that all dependencies requirements of all microservices can be easily satisfied by all available nodes.</p>
<p class="normal">As we explore how microservices <a id="_idIndexMarker766"/>operate within their containerized environments, another key architectural principle comes into play – the concept of loose coupling.</p>
<h3 class="heading-3" id="_idParaDest-223">Loose coupling</h3>
<p class="normal">Each microservice must be loosely coupled<a id="_idIndexMarker767"/> with all the other microservices. This principle has a two-fold nature. On the one hand, this means that, according to object-oriented programming principles, the interface that’s exposed by each microservice must not be too specific but as general as possible. However, it also means that communications among microservices must be minimized in order to reduce communication costs since microservices don’t share the same address space and run on different hardware nodes.</p>
<p class="normal">For instance, suppose we are implementing a distributed web video game with a microservice architecture. Each microservice might take care of different functionalities, like collisions, visibility, user input handling, and so on. Some modules, like the collision and visibility modules, must know the whole game state, such as places where the user avatars are, the state of each avatar, and also the state of each reactive object that is in the game (such as obstacles, bullets shot by avatars, and so on). Therefore, either all the modules with a hard dependency on the whole game state are collapsed into a unique microservice or we must find an efficient way to share the overall game state between them with just a few message exchanges.</p>
<p class="normal">Both options have advantages and disadvantages and are actually adopted by real-world video games. Fewer messages might cause temporary incongruences, but melting too many modules into a unique microservice might impact the overall game performance so that the game might appear too “slow” to the users.</p>
<p class="normal">This concept of minimal inter-service communication naturally leads us to another consideration: the avoidance<a id="_idIndexMarker768"/> of chained requests/responses in a microservice architecture</p>
<h3 class="heading-3" id="_idParaDest-224">No chained requests/responses</h3>
<p class="normal">When a request reaches<a id="_idIndexMarker769"/> a microservice, it must not cause a recursive chain of nested requests/responses to other microservices since a similar chain would result in an unacceptable response time.</p>
<p class="normal">For instance, suppose that microservice A issues a request to microservice B and then waits for B to answer, and B does the same with C, and C does the same with D, and so on. As a result, A remains blocked waiting for its answer for the whole time the request propagates first to B, then to C, and then to D, and then the answer propagates back from D to C, then from C to B, and finally reaches A. That is, four request propagation times sum to the other four answer propagation times to get the overall A wait time. This way, the time a user waits to get an answer from the application might easily become unacceptable.</p>
<p class="normal">Chained requests/responses can be avoided if the private data models of all the microservices synchronize with push events each time they change. In other words, as soon as the data that is handled by a microservice changes, those changes are sent to all the microservices that may need them to serve their requests. This way, each microservice has all the data it needs to serve all its incoming requests in its private data storage, with no need to ask other microservices for the data that it lacks.</p>
<p class="normal"><em class="italic">Figure 11.1</em> shows how updates are sent to all interested microservices as soon as they are produced and how each microservice combines all received updates in a local database. This way, each query microservice has all the data it needs to answer queries in its local database.</p>
<figure class="mediaobject"><img alt="Diagram  Description automatically generated" src="img/B19820_11_01.png"/></figure>
<p class="packt_figref">Figure 11.1: Push events</p>
<p class="normal">In conclusion, every microservice must contain all the data it needs to serve incoming requests and ensure fast responses. To keep their data models up to date and ready for incoming requests, microservices must communicate their data changes as soon as they take place. These data changes<a id="_idIndexMarker770"/> should be communicated through asynchronous messages since synchronous nested messages cause unacceptable performance because they block all the threads involved in the call tree until a result is returned.</p>
<p class="normal">It is worth pointing out that the <em class="italic">independence of design choices</em> principle is substantially the bounded context principle of DDD, which we discussed in detail in <em class="chapterRef">Chapter 7</em>, <em class="italic">Understanding the Different Domains in Software Solutions</em>. In this chapter, we have seen that, often, a full DDD approach is useful for the <em class="italic">update</em> subsystem of each microservice.</p>
<p class="normal">It’s not trivial that, in general, all systems that have been developed according to the bounded context principle are better implemented with a microservice architecture. In fact, once a system has been decomposed into several completely independent and loosely coupled parts, it is very likely that these different parts will need to be scaled independently because of different traffic and different resource requirements.</p>
<p class="normal">At the preceding constraints, we must also add some best practices for building a reusable SOA. More details on these best practices will be given in <em class="chapterRef">Chapter 15</em>, <em class="italic">Applying Service-Oriented Architectures with .NET</em>, but nowadays, most SOA best practices are automatically enforced by tools and frameworks that are used to implement web services.</p>
<p class="normal">Fine-grained scaling is a key aspect<a id="_idIndexMarker771"/> of microservices architecture, involving several critical software and infrastructure requirements:</p>
<ul>
<li class="bulletList">First of all, microservices must be small enough to isolate well-defined functionalities.</li>
<li class="bulletList">We also need a complex infrastructure that takes care of automatically instantiating microservices and allocating<a id="_idIndexMarker772"/> instances on various hardware computational resources, commonly called <strong class="keyWord">nodes</strong>.</li>
<li class="bulletList">The same infrastructure must take care of scaling microservices and load-balancing them on the available nodes.</li>
</ul>
<p class="normal">These kinds of structures will be introduced in the <em class="italic">Which tools are needed to manage microservices?</em> section of this chapter, and discussed in detail in <em class="chapterRef">Chapter 20</em>, <em class="italic">Kubernetes</em>.</p>
<p class="normal">Moreover, fine-grained scaling<a id="_idIndexMarker773"/> of distributed microservices that communicate through asynchronous communication requires each microservice to be resilient. In fact, communication that’s directed to a specific microservice instance may fail due to a hardware fault or for the simple reason that the target instance was killed or moved to another node during a load-balancing operation.</p>
<p class="normal">Temporary failures can be overcome with exponential retries. This is where we retry the same operation after each failure with a delay that increases exponentially until a maximum number of attempts is reached. For instance, first, we would retry after 10 milliseconds, and if this retry operation results in a failure, a new attempt is made after 20 milliseconds, then after 40 milliseconds, and so on.</p>
<p class="normal">On the other hand, long-term failures often cause an explosion of retry operations that may saturate all system resources in a way that is similar to a denial-of-service attack. Therefore, usually, exponential retries are used together with a <em class="italic">circuit break strategy</em>: after a given number of failures, a long-term failure is assumed, and access to the resource is prevented for a given time by returning an immediate failure without attempting the communication operation.</p>
<p class="normal">It is also fundamental that the congestion of some subsystems, due to either failure or a request peak, does not propagate to other system parts in order to prevent overall system congestion. <em class="italic">Bulkhead isolation</em> prevents congestion propagation in the following ways:</p>
<ul>
<li class="bulletList">Only a maximum number of similar simultaneous outbound requests are allowed; let’s say, 10. This is similar to putting an upper bound on thread creation.</li>
<li class="bulletList">Requests exceeding the previous bound are queued.</li>
<li class="bulletList">If the maximum queue length is reached, any further requests result in exceptions being thrown to abort them.</li>
</ul>
<p class="normal">The practical .NET implementation of exponential retries, circuit break, and bulkhead isolation is described in the <em class="italic">Resilient task execution subsection</em> of this chapter.</p>
<p class="normal">Retry policies may make it so that the same message is received and processed several times because the sender has received no confirmation that the message has been received, or simply because it has timed out the operation while the receiver actually received the message. The only possible solution to this problem is designing all messages so that they’re idempotent – that is, designing messages in such a way that processing the same message several times has the same effect as processing it once.</p>
<p class="normal">Updating a database<a id="_idIndexMarker774"/> table field to a value, for instance, is an idempotent operation since repeating it once or twice has exactly the same effect. However, incrementing a decimal field is not an idempotent operation. Microservice designers should make an effort to design the overall application with as many idempotent messages as possible.</p>
<p class="normal">An idempotent message is also a message that, if processed twice, doesn’t cause malfunctions. For instance, a message that modifies the price of travel is idempotent because if we process it another time, we just set again the price to the same price as before. However, a message whose purpose is to add a new travel booking is not idempotent since if we process it twice, we add two travel bookings instead of one.</p>
<p class="normal">The remaining non-idempotent messages must be transformed into idempotent in the following way or with other similar techniques:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Attach both a time and some identifier that uniquely identifies each message.</li>
<li class="numberedList">Store all the messages that have been received in a dictionary that’s been indexed by the unique identifier attached to the message mentioned in the previous point.</li>
<li class="numberedList">Reject old messages.</li>
<li class="numberedList">When a message that may be a duplicate is received, verify whether it’s contained in the dictionary. If it is, then it has already been processed, so reject it.</li>
<li class="numberedList">Since old messages are rejected, they can be periodically removed from the dictionary to prevent it from growing exponentially.</li>
</ol>
<p class="normal">In <em class="chapterRef">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET</em>, we will use this technique in practice and discuss communication and coordination problems in more detail.</p>
<p class="normal">It is worth pointing out that some message brokers, such as Azure Service Bus, offer facilities for implementing the technique described previously. However, the receiver must always be able to recognize duplicate messages since, due to time-outs in the reception of acknowledgments, messages<a id="_idIndexMarker775"/> might be resent. Azure Service Bus is discussed in the <em class="italic">.NET communication facilities</em> subsection.</p>
<p class="normal">In the next subsection, we will talk about microservice containerization based on Docker.</p>
<h2 class="heading-2" id="_idParaDest-225">Containers and Docker</h2>
<p class="normal">We’ve already discussed the advantages<a id="_idIndexMarker776"/> of having microservices<a id="_idIndexMarker777"/> that don’t depend<a id="_idIndexMarker778"/> on the environment where they run; microservices can be moved from busy nodes to idle nodes without constraints, thus achieving a better load balance and, consequently, better usage of the available hardware.</p>
<p class="normal">However, if we need to mix legacy software with newer modules, the ability to mix several development stacks in order to use the best stack for each module implementation, and so on, we are faced with the problem that the various microservices have different hardware/software prerequisites. In these cases, the independence of each microservice from the hosting environment can be restored by deploying each microservice with all its dependencies on a private virtual machine.</p>
<p class="normal">However, starting a virtual machine with its private copy of the operating system takes a lot of time, and microservices must be started and stopped quickly to reduce load-balancing and fault recovery costs. In fact, new microservices may be started either to replace faulty ones or because they were moved from one hardware node to another to perform load-balancing. Moreover, adding a whole copy of the operating system to each microservice instance would be an excessive overhead.</p>
<p class="normal">Luckily, microservices can rely on a lighter form of technology: containers. Containers provide a lightweight, efficient form of virtualization. Unlike traditional virtual machines that virtualize an entire machine, including the operating system, containers virtualize at the OS filesystem level, sitting on top of the host OS kernel. They use the operating system of the hosting machine (kernel, DLLs, and drivers) and use the OS’s native features to isolate processes and resources, creating an isolated environment for the images they run.</p>
<p class="normal">As a consequence, containers are tied to a specific OS, but they don’t suffer the overhead of copying and starting a whole OS in each container instance.</p>
<p class="normal">On each host machine, containers are handled by a runtime that takes care of creating them from <em class="italic">images</em> and creating an isolated environment for each of them. The most popular container image format is Docker, which is a <em class="italic">de facto</em> standard for container images.</p>
<p class="normal">Images contain files needed<a id="_idIndexMarker779"/> to create each container<a id="_idIndexMarker780"/> and specify which container<a id="_idIndexMarker781"/> resources, such as communication ports, to expose outside of the container. However, they need not explicitly contain all involved files since they can be layered. This way, each image is built by adding new files and configuration information on top of another existing image that is referenced from inside the newly defined image.</p>
<p class="normal">For instance, if you want to deploy a .NET application as a Docker image, it is enough to just add your software and files to your Docker image and then reference an already existing .NET Docker image.</p>
<p class="normal">To allow for easy image referencing, images are grouped into registries that may be either public or private. They are similar to NuGet<a id="_idIndexMarker782"/> or npm registries. Docker offers a public registry (<a href="https://hub.docker.com/_/registry">https://hub.docker.com/_/registry</a>) where you can find most of the public images you may need to reference in your own images. However, each company can define private registries. For instance, Microsoft offers Azure Container Registry, where you can define your private<a id="_idIndexMarker783"/> container registry service: <a href="https://azure.microsoft.com/en-us/services/container-registry/">https://azure.microsoft.com/en-us/services/container-registry/</a>. There, you can also find most of the .NET-related images you might need to reference in your code.</p>
<p class="normal">Before instantiating each container, the Docker runtime must solve all the recursive references. This cumbersome job is not performed each time a new container is created since the Docker runtime has a cache where it stores the fully assembled images that correspond to each input image and that it has already processed.</p>
<p class="normal">Since each application is usually composed of several modules<a id="_idIndexMarker784"/> to be run in different containers, a tool called <strong class="keyWord">Docker Compose</strong> also allows <code class="inlineCode">.yml</code> files, known as <strong class="keyWord">composition files</strong>, that specify the following<a id="_idIndexMarker785"/> information:</p>
<ul>
<li class="bulletList">Which images to deploy.</li>
<li class="bulletList">How the internal resources that are exposed by each image must be mapped to the physical resources of the host machine. For instance, how communication ports that are exposed by Docker images must be mapped to the ports of the physical machine.</li>
</ul>
<p class="normal">We will analyze Docker images and <code class="inlineCode">.yml</code> files in the <em class="italic">How does .NET deal with microservices?</em> section of this chapter.</p>
<p class="normal">The Docker runtime handles images and containers on a single machine, but usually, containerized microservices are deployed and load-balanced on clusters that are composed of several<a id="_idIndexMarker786"/> machines. Clusters are handled by pieces of software called <strong class="keyWord">orchestrators</strong>. Orchestrators will be introduced in the <em class="italic">Which tools are needed to manage microservices?</em> section of this chapter, and described in detail in <em class="italic">Chapter 20,</em> <em class="italic">Kubernetes</em>.</p>
<p class="normal">Now that we understand <a id="_idIndexMarker787"/>what microservices are, what problems<a id="_idIndexMarker788"/> they can solve, and their<a id="_idIndexMarker789"/> basic design principles, we are ready to analyze when and how to use them in our system architecture. The next section analyzes when we should use them.</p>
<h1 class="heading-1" id="_idParaDest-226">When do microservices help?</h1>
<p class="normal">The answer to this question requires<a id="_idIndexMarker790"/> us to understand the roles microservices play in modern software architectures. We will look at this in the following two subsections:</p>
<ul>
<li class="bulletList">Layered architectures and microservices</li>
<li class="bulletList">When is it worth considering microservice architectures?</li>
</ul>
<p class="normal">Let’s start with a detailed look at layered architectures and microservices.</p>
<h2 class="heading-2" id="_idParaDest-227">Layered architectures and microservices</h2>
<p class="normal">As discussed in <em class="italic">Chapter 7, Understanding the Different Domains in Software Solutions</em>, enterprise systems are usually<a id="_idIndexMarker791"/> organized in logical independent layers. The outermost<a id="_idIndexMarker792"/> layer is the one that interacts<a id="_idIndexMarker793"/> with the user and is called the presentation layer (in the onion architecture, the outermost layer also contains drivers and test suites), while the last layer (the innermost layer in the onion architecture) takes care of application permanent<a id="_idIndexMarker794"/> data handling and is called the data layer (the domain layer in the onion architecture). Requests originate in the presentation layer and pass through all the layers until they reach the data layer (and then come back, traversing all the layers in reverse until they reach the outermost layer again).</p>
<p class="normal">In the case of classical layered architecture (the onion architecture is quite different, as discussed in <em class="italic">Chapter 7</em>, <em class="italic">Understanding the Different Domains in Software Solutions</em>), each layer takes data from the previous layer, processes it, and passes it to the next layer. Then, it receives the results from its next layer and sends them back to its previous layer. Also, thrown exceptions can’t jump layers – each layer must take care of intercepting all the exceptions and either <em class="italic">solve them</em> somehow or transform them into other exceptions that are expressed in the language of its previous layer. The layered architecture ensures the complete independence of the functionalities of each layer from the functionalities of all the other layers.</p>
<p class="normal">For instance, we can change the <strong class="keyWord">Object-Relational Mapping</strong> (<strong class="keyWord">ORM</strong>) software that interfaces the database without<a id="_idIndexMarker795"/> affecting all the layers that are above the data layer (ORM software is discussed in <em class="chapterRef">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>). In the same way, we can completely change the user interface (that is, the presentation layer) without affecting the remainder of the system.</p>
<p class="normal">Moreover, each layer implements a different kind of system specification. The data layer takes care of what the system <em class="italic">must remember</em>, the presentation layer takes care of the system-user interaction protocol, and all the layers that are in the middle implement the domain rules, which specify how data must be processed (for instance, how an employee paycheck must be computed). Typically, the data<a id="_idIndexMarker796"/> and presentation layers are separated<a id="_idIndexMarker797"/> by just one domain rule layer, called the business or application layer.</p>
<figure class="mediaobject"><img alt="Diagram  Description automatically generated" src="img/B19820_11_02.png"/></figure>
<p class="packt_figref">Figure 11.2: Layers of classic architectures</p>
<p class="normal">Each layer <em class="italic">speaks</em> a different language: the data layer<a id="_idIndexMarker798"/> speaks the language of relation<a id="_idIndexMarker799"/> among entities, the business layer speaks the language of domain experts, and the presentation layer speaks the language of users. So, when data and exceptions pass from one layer to another, they must be translated into the language of the destination layer.</p>
<p class="normal">That being said, how do microservices fit into a layered architecture? Are they adequate for the functionalities of all the layers or just some layers? Can a single microservice span several layers?</p>
<p class="normal">The last question is the easiest to answer: yes! In fact, we’ve already stated that microservices should store the data they need within their logical boundaries. Therefore, there are microservices that span the business and data layers, for sure.</p>
<p class="normal">However, since we said that each logical microservice can be implemented with several physical microservices for pure load-balancing reasons, one microservice might take care of encapsulating data used by another microservice that might remain confined in the data layer.</p>
<p class="normal">Moreover, we said also that while each microservice must have its exclusive storage, it can use also external storage engines. This is shown in the diagram below:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_11_03.png"/></figure>
<p class="packt_figref">Figure 11.3: External or internal storage</p>
<p class="normal">It is worth pointing out that the storage<a id="_idIndexMarker800"/> engine itself can be implemented<a id="_idIndexMarker801"/> as a set of physical microservices that are associated with no logical microservice since they may be considered part of the infrastructure.</p>
<p class="normal">This is the case, for instance, for storage engines based on the distributed Redis in-memory cache, where we use microservice facilities offered by the infrastructure to implement scalable one-master/many-read-only replicas, or sophisticated many-master/many-read-only replicas distributed in memory storage. Redis and Redis Cloud services are described in the <em class="italic">Redis</em> section <em class="italic">of </em><em class="chapterRef">Chapter 12</em>, <em class="italic">Choosing Your Data Storage in the Cloud</em>, while many-master/many-read-only replicas architectures are described in <em class="chapterRef">Chapter 20</em>, <em class="italic">Kubernetes</em>. The diagram below shows how microservice-based many-master/many-read-only replicas storage engines work.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_11_04.png"/></figure>
<p class="packt_figref">Figure 11.4: Many-master/many-read-only replicas storage engine</p>
<p class="normal">Each master has its associated read-only replicas. Storage updates can be passed just to masters that replicate their data to all their associated read-only replicas.</p>
<p class="normal">Each master takes care of a portion of the storage space, for instance, all products whose name starts with “A,” and so on. In this way, the load is balanced between all masters.</p>
<p class="normal">Thus, we may have business<a id="_idIndexMarker802"/> layer microservices, data layer <a id="_idIndexMarker803"/>microservices, and microservices that span both layers. So, what about the presentation layer?</p>
<h3 class="heading-3" id="_idParaDest-228">The presentation layer</h3>
<p class="normal">This layer can also fit into a microservice<a id="_idIndexMarker804"/> architecture if it is implemented<a id="_idIndexMarker805"/> on the server side – that is, if the whole graphic that interacts with the user is built on the server side and not in the user client machine (mobile device, desktop, etc.).</p>
<p class="normal">When there are microservices that interact directly with the user, we speak of server-side implementation of the presentation layer since the HTML and/or all elements of the user interface are created by the frontend, which sends the response to the user.</p>
<p class="normal">These kinds of microservices<a id="_idIndexMarker806"/> are called frontend microservices, while microservices<a id="_idIndexMarker807"/> that do back-office work without interacting<a id="_idIndexMarker808"/> with the <a id="_idIndexMarker809"/>user are called worker microservices. The diagram below summarizes the frontend/worker organization.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_11_05.png"/></figure>
<p class="packt_figref">Figure 11.5: Frontend and worker microservices</p>
<p class="normal">When, instead, the HTML and/or all elements of the user interface are generated on the user machine, we speak of client-side implementation of the presentation layer. The so-called single-page applications and mobile applications run the presentation<a id="_idIndexMarker810"/> layer on the client<a id="_idIndexMarker811"/> machine and interact with the application through communication interfaces exposed by dedicated microservices. These dedicated microservices<a id="_idIndexMarker812"/> are completely analogous to the frontend microservices depicted in <em class="italic">Figure 11.5</em> and are called <em class="italic">API gateways,</em> to underline their role of exposing a public API for connecting client devices with the whole microservices infrastructure. Also, API gateways interact with worker microservices in a way that is completely analogous to frontend microservices.</p>
<p class="normal">Single-page applications and mobile/desktop client applications are discussed in <em class="chapterRef">Chapter 19</em>, <em class="italic">Client Frameworks: Blazor</em>.</p>
<p class="normal">In a microservice architecture, when the presentation layer is a website, it can be implemented with a set of several microservices. However, if it requires heavy web servers and/or heavy frameworks, containerizing them may not be convenient. This decision must also consider the loss of performance that happens when containerizing the web server and the possible need for hardware firewalls between the web server and the remainder of the system.</p>
<p class="normal">ASP.NET Core is a lightweight<a id="_idIndexMarker813"/> framework that runs on the Kestrel<a id="_idIndexMarker814"/> web server, so it can be containerized efficiently and used as is in the worker microservices. The usage of ASP:NET Core in the implementation of worker microservices is described in great detail in <em class="chapterRef">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET</em>.</p>
<p class="normal">Instead, frontend and/or high-traffic websites have more compelling security and load-balancing requirements that can be satisfied just with fully-featured web servers. Accordingly, architectures based on microservices usually offer specialized components that take care of interfacing with the outside world. For instance, in <em class="chapterRef">Chapter 20</em>, <em class="italic">Kubernetes</em>, we will see that<a id="_idIndexMarker815"/> in microservices-dedicated infrastructures like <strong class="keyWord">Kubernetes</strong> clusters, this role is played by so-called <strong class="keyWord">ingresses</strong>. These are fully-featured<a id="_idIndexMarker816"/> web servers interfaced with the microservices infrastructure. Thanks to the integration with the microservices infrastructure, the whole web server traffic is automatically routed to the interested microservices. More details on this will be given in <em class="chapterRef">Chapter 20</em>, <em class="italic">Kubernetes</em>. The diagram below shows the role of Ingresses.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_11_06.png"/></figure>
<p class="packt_figref">Figure 11.6: Ingresses based on load-balanced web servers</p>
<p class="normal">Monolithic websites can be easily broken into load-balanced smaller subsites without microservice-specific technologies, but a microservice architecture can bring all the advantages of microservices into the construction of a single HTML page. More specifically, different microservices may take care of different areas of each HTML page. Microservices that cooperate in the construction of the HTML of application pages, and, in general, in the construction of any kind of user interface, are named micro-frontends.</p>
<p class="normal">When the HTML is created on the server side, the various micro-frontends create HTML chunks that are combined either on the server side or directly in the browser.</p>
<p class="normal">When, instead, the HTML is created directly on the client, each micro-frontend provides a different chunk of code to the client. These code chunks are run on the client machine, and each of them takes care of different pages/page areas. We will speak more of this kind of micro-frontend in <em class="chapterRef">Chapter 18</em>, <em class="italic">Implementing Frontend Microservices with ASP.NET Core</em>.</p>
<p class="normal">Now that we’ve clarified<a id="_idIndexMarker817"/> which parts of a system<a id="_idIndexMarker818"/> can benefit from the adoption of microservices, we are ready to state the rules when it comes to deciding how they’re adopted.</p>
<h2 class="heading-2" id="_idParaDest-229">When is it worth considering microservice architectures?</h2>
<p class="normal">Microservices can improve the implementation of both the business and data layers, but their adoption<a id="_idIndexMarker819"/> has some costs:</p>
<ul>
<li class="bulletList">Allocating instances to nodes and scaling them has a cost in terms of cloud fees or internal infrastructures and licenses.</li>
<li class="bulletList">Splitting a unique process into smaller communication processes increases communication costs and hardware needs, especially if the microservices are containerized.</li>
<li class="bulletList">Designing and testing software for a microservice requires more time and increases engineering costs, both in time and complexity. In particular, making microservices resilient and ensuring that they adequately handle all possible failures, as well as verifying these features with integration tests, can increase the development time by more than one order of magnitude (that is, about 10 times).</li>
</ul>
<p class="normal">So, when are microservices worth the cost of using them? Are there functionalities that must be implemented as microservices?</p>
<p class="normal">A rough answer to the second question is yes when the application is big enough in terms of traffic and/or software complexity. In fact, as an application grows in complexity and its traffic increases, it’s recommended that we pay the costs associated with scaling it since this allows for more scaling optimization and better handling when it comes to the development team. The costs we pay for these would soon exceed the cost of microservice adoption.</p>
<p class="normal">Thus, if fine-grained scaling makes sense for our application, and if we can estimate the savings that fine-grained scaling and development give us, we can easily compute an overall application throughput limit that makes the adoption of microservices convenient.</p>
<p class="normal">Microservice costs can also be justified by an increase in the market value of our products/services. Since the microservice architecture allows us to implement each microservice with a technology that has been optimized for its use, the quality that’s added to our software may justify all or part of the microservice costs.</p>
<p class="normal">However, scaling and technology optimizations are not the only parameters to consider. Sometimes, we are forced to adopt a microservice architecture without being able to perform a detailed cost analysis.</p>
<p class="normal">If the size of the team that takes care of the CI/CD of the overall system grows too much, the organization and coordination of this big team cause difficulties and inefficiencies. In this type of situation, it is desirable to move to an architecture that breaks the whole CI/CD cycle into independent parts that can be taken care of by smaller teams.</p>
<p class="normal">Moreover, since these development costs<a id="_idIndexMarker820"/> are only justified by a high volume of requests, we probably have high traffic being processed by independent modules that have been developed by different teams. Therefore, scaling optimizations and the need to reduce interaction between development teams make the adoption of a microservice architecture very convenient.</p>
<p class="normal">From this, we may conclude that if the system and the development team grow too much, it is necessary to split the development team into smaller teams, each working on an efficient bounded context subsystem. It is very likely that, in a similar situation, a microservice architecture is the only possible option.</p>
<p class="normal">Another situation that forces the adoption of a microservice architecture is the integration of newer subparts with legacy subsystems based on different technologies, as containerized microservices are the only way to implement an efficient interaction between the legacy system and the new subparts in order to gradually replace the legacy subparts with newer ones. Similarly, if our team is composed of developers with experience in different development stacks, an architecture based on containerized microservices may become a <em class="italic">must</em>.</p>
<p class="normal">In the next section, we will analyze the building blocks and tools that are available for the implementation of .NET-based microservices.</p>
<h1 class="heading-1" id="_idParaDest-230">How does .NET deal with microservices?</h1>
<p class="normal">The new .NET, which evolved<a id="_idIndexMarker821"/> from .NET Core, was conceived as a multi-platform framework that was light and fast enough to implement efficient microservices. In particular, ASP.NET Core is the ideal tool for implementing text REST and binary gRPC APIs to communicate with a microservice since it can run efficiently with lightweight web servers such as Kestrel and is itself light and modular.</p>
<p class="normal">The whole .NET stack evolved with microservices as a strategic deployment platform in mind and has facilities and packages for building efficient and light HTTP and gRPC communication to ensure service resiliency and to handle long-running tasks. The following subsections describe some of the different tools or solutions that we can use to implement a .NET-based microservice<a id="_idIndexMarker822"/> architecture.</p>
<h2 class="heading-2" id="_idParaDest-231">.NET communication facilities</h2>
<p class="normal">Microservices need two kinds of communication channels.</p>
<p class="normal">The first communication channel<a id="_idIndexMarker823"/> receives external requests, either directly or through an API gateway. HTTP is the usual protocol for external communication due to available web service standards and tools. .NET’s main HTTP/gRPC communication facility is ASP.NET Core since it’s a lightweight HTTP/gRPC framework, which makes it ideal for implementing web APIs in small microservices. We will describe ASP.NET REST API apps in detail in <em class="chapterRef">Chapter 15</em>, <em class="italic">Applying Service-Oriented Architectures with .NET</em>, and we will describe gRPC services in <em class="chapterRef">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET</em>. .NET also offers an efficient and modular HTTP client solution that is able to pool and reuse heavy connection objects. Also, the <code class="inlineCode">HttpClient</code> class will be described in more detail in <em class="chapterRef">Chapter 15</em>.</p>
<p class="normal">The second channel is a different type of communication channel to push updates to other microservices. In fact, we have already mentioned that intra-microservice communication cannot be triggered by an ongoing request since a complex tree of blocking calls to other microservices would increase request latency to an unacceptable level. As a consequence, updates must not be requested immediately before they’re used and should be pushed whenever state changes take place. Ideally, this kind of communication should be asynchronous to achieve acceptable performance. In fact, synchronous calls would block the sender while they are waiting for the result, thus increasing the idle time of each microservice. However, synchronous communication that just puts the request in a processing queue and then returns confirmation of the successful communication instead of the final result is acceptable if communication is fast enough (low communication latency and high bandwidth). A publisher/subscriber communication would be preferable since, in this case, the sender and receiver don’t need to know each other, thus increasing the microservices’ independence. In fact, all the receivers that are interested in a certain type of communication merely need to register to receive a specific <em class="italic">event</em>, while senders just need to publish those events. All the wiring is performed by a service that takes care of queuing events and dispatching them to all the subscribers. The publisher/subscriber pattern was described in <em class="chapterRef">Chapter 6</em>, <em class="italic">Design Patterns and .NET 8 Implementation</em>, along with other useful patterns.</p>
<p class="normal">While .NET doesn’t directly offer tools that may help in asynchronous communication or client/server tools that implement<a id="_idIndexMarker824"/> publisher/subscriber communication, Azure offers a similar service with <em class="italic">Azure Service Bus</em> (<a href="https://docs.microsoft.com/en-us/azure/service-bus-messaging/">https://docs.microsoft.com/en-us/azure/service-bus-messaging/</a>). Azure Service Bus handles both queued asynchronous communication through Azure Service Bus <em class="italic">queues</em> and publisher/subscriber communication through Azure Service Bus <em class="italic">topics</em>.</p>
<p class="normal">Once you’ve configured the Azure Service Bus on the Azure portal, you can connect to it in order to send messages/events and receive messages/events through a client contained in <code class="inlineCode">Microsoft.Azure.ServiceBus</code> NuGet package.</p>
<p class="normal">Azure Service Bus has two types<a id="_idIndexMarker825"/> of communication: queue-based and topic-based. In queue-based communication, each message that’s placed in the queue by a sender is removed from the queue by the first receiver that pulls it from the queue. Topic-based communication, on the other hand, is an implementation of the publisher/subscriber pattern. Each topic has several subscriptions, and a different copy of each message sent to a topic can be pulled from each topic subscription.</p>
<p class="normal">The design flow is as follows:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Define an Azure Service Bus private namespace.</li>
<li class="numberedList">Get the root connection strings that were created by the Azure portal and/or define new connection strings with fewer privileges.</li>
<li class="numberedList">Define queues and/or topics where the sender will send their messages in binary format.</li>
<li class="numberedList">For each topic, define names for all the required subscriptions.</li>
<li class="numberedList">In the case of queue-based communication, the sender sends messages to a queue, and the receivers pull messages from the same queue. Each message is delivered to one receiver. That is, once a receiver gains access to the queue, it reads and removes one or more messages.</li>
<li class="numberedList">In the case of topic-based communication, each sender sends messages to a topic while each receiver pulls messages from its private subscription associated with that topic.</li>
</ol>
<p class="normal">There are also other commercial <a id="_idIndexMarker826"/>and free open-source alternatives to Azure Service Bus, such as NServiceBus (<a href="https://particular.net/nservicebus">https://particular.net/nservicebus</a>), MassTransit (<a href="https://masstransit-project.com/">https://masstransit-project.com/</a>), and Brighter (<a href="https://www.goparamore.io/">https://www.goparamore.io/</a>). They enhance existing<a id="_idIndexMarker827"/> brokers (like Azure Service Bus itself) with<a id="_idIndexMarker828"/> higher-level functionalities.</p>
<p class="normal">There is also a completely independent option that can be used on on-premises platforms: RabbitMQ. It is free and open source and can be installed locally, on a virtual machine, or in a Docker container. Then, you can connect with it through the client contained in the <code class="inlineCode">RabbitMQ.Client</code> NuGet package.</p>
<p class="normal">The functionalities of RabbitMQ<a id="_idIndexMarker829"/> are similar to the ones offered by Azure Service Bus, but you have to take care of more implementation details, like serialization, reliable messages, and error handling, while Azure Service Bus takes care of all the low-level operations and offers you a simpler interface. However, there are clients that build a more powerful abstraction on top of RabbitMQ, like, for instance, EasyNetQ. The publisher/subscriber-based communication pattern used by both Azure Service Bus and RabbitMQ was described in <em class="chapterRef">Chapter 6</em>, <em class="italic">Design Patterns and .NET 8 Implementation</em>. RabbitMQ will be described in more detail in <em class="chapterRef">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET</em>.</p>
<h2 class="heading-2" id="_idParaDest-232">Resilient task execution</h2>
<p class="normal">Resilient communication<a id="_idIndexMarker830"/> and, in general, resilient task execution <a id="_idIndexMarker831"/>can be implemented easily with the help of a .NET library called Polly, whose project is a member of the .NET Foundation. Polly is available through the <code class="inlineCode">Polly</code> NuGet package.</p>
<p class="normal">In Polly, you define policies and then execute tasks in the context of those policies, as follows:</p>
<pre class="programlisting code"><code class="hljs-code">var myPolicy = Policy
  .Handle&lt;HttpRequestException&gt;()
  .Or&lt;OperationCanceledException&gt;()
  .RetryAsync(3);
....
....
await myPolicy.ExecuteAsync(()=&gt;{
    //your code here
});
</code></pre>
<p class="normal">The first part of each policy specifies the exceptions that must be handled. Then, you specify what to do when one of those exceptions is captured. In the preceding code, the <code class="inlineCode">Execute</code> method is retried up to three times if a failure is reported either by an <code class="inlineCode">HttpRequestException</code> exception or by an <code class="inlineCode">OperationCanceledException</code> exception.</p>
<p class="normal">The following is the implementation of an exponential retry policy:</p>
<pre class="programlisting code"><code class="hljs-code">var retryPolicy= Policy
    ...
    //Exceptions to handle here
    .WaitAndRetryAsync(6,
        retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2,
            retryAttempt)));
</code></pre>
<p class="normal">The first argument of <code class="inlineCode">WaitAndRetryAsync</code> specifies that a maximum of six retries is performed in the event<a id="_idIndexMarker832"/> of failure. The lambda function passed as the second argument specifies how much time to wait before the next attempt. In this specific example, this time grows exponentially with the number of attempts by a power of 2 (2 seconds for the first retry, 4 seconds for the second retry, and so on).</p>
<p class="normal">The following is a simple circuit breaker policy:</p>
<pre class="programlisting code"><code class="hljs-code">var breakerPolicy =Policy
    .Handle&lt;SomeExceptionType&gt;()
    .CircuitBreakerAsync (6, TimeSpan.FromMinutes(1));
</code></pre>
<p class="normal">After six failures, the task can’t be executed for one minute since an exception is returned.</p>
<p class="normal">The following is the implementation of the Bulkhead Isolation policy (see the <em class="italic">Microservices design principles</em> section for more information):</p>
<pre class="programlisting code"><code class="hljs-code">Policy
  .BulkheadAsync(10, 15)
</code></pre>
<p class="normal">A maximum of 10 parallel executions is allowed in the <code class="inlineCode">Execute</code> method. Further tasks are inserted in an execution queue. This has a limit of 15 tasks. If the queue limit is exceeded, an exception is thrown.</p>
<p class="normal">For the Bulkhead Isolation policy to work properly and, in general, for every strategy to work properly, task executions must be triggered through the same policy instance; otherwise, Polly is unable to count how many executions of a specific task are active.</p>
<p class="normal">Policies can be combined with the <code class="inlineCode">Wrap</code> method:</p>
<pre class="programlisting code"><code class="hljs-code">var combinedPolicy = Policy
  .Wrap(retryPolicy, breakerPolicy);
</code></pre>
<p class="normal">Polly offers several more options, such as generic methods for tasks that return a specific type, timeout policies, task result caching, the ability to define custom policies, and so on. It is also possible to configure Polly as part of an <code class="inlineCode">HttpClient</code> definition in the dependency injection section of any ASP.NET Core and .NET application. This way, it is quite immediate to define resilient clients.</p>
<p class="normal">Polly’s official documentation can be found in its GitHub repository here: <a href="https://github.com/App-vNext/Polly">https://github.com/App-vNext/Polly</a>.</p>
<p class="normal">The practical usage of Polly is explained in the <em class="italic">A worker microservice with ASP.NET Core</em> section of <em class="chapterRef">Chapter 21</em>, <em class="italic">Case Study</em>.</p>
<p class="normal">The resilience and robustness<a id="_idIndexMarker833"/> provided by tools like Polly are crucial components of microservice architecture, particularly when managing complex tasks and processes.</p>
<p class="normal">This brings us to another fundamental aspect of microservices: the implementation of generic hosts.</p>
<h2 class="heading-2" id="_idParaDest-233">Using generic hosts</h2>
<p class="normal">Each microservice may need to run several<a id="_idIndexMarker834"/> independent threads, with each performing a different operation on requests received. Such threads need several resources, such as database connections, communication channels, specialized modules that perform complex operations, and so on. Moreover, all processing threads must be adequately initialized when the microservice is started and gracefully stopped when the microservice is stopped as a consequence of either load-balancing or errors.</p>
<p class="normal">All of these needs led the .NET team to conceive and implement <em class="italic">hosted services</em> and <em class="italic">hosts</em>. A host creates<a id="_idIndexMarker835"/> an adequate environment for running several tasks, known as <strong class="keyWord">hosted services</strong>, and provides them with resources, common settings, and a graceful start/stop.</p>
<p class="normal">The concept of a web host was initially conceived to implement the ASP.NET Core web framework, but, with effect from .NET Core 2.1, the host concept was extended to all .NET applications.</p>
<p class="normal">At the time of writing this book, a <code class="inlineCode">Host</code> is automatically created for you in any ASP.NET Core, Blazor, and Worker Service project. The simplest way to test .NET Host features is to select a <strong class="screenText">Service -&gt; Worker Service</strong> project.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_11_07.png"/></figure>
<p class="packt_figref">Figure 11.7: Creating a Worker Service project in Visual Studio</p>
<p class="normal">All features related to the concept<a id="_idIndexMarker836"/> of a <code class="inlineCode">Host</code> are contained in the <code class="inlineCode">Microsoft.Extensions.Hosting</code> NuGet package.</p>
<p class="normal"><code class="inlineCode">Program.cs</code> contains some skeleton code for configuring the host with a fluent interface, starting with the <code class="inlineCode">CreateDefaultBuilder</code> method of the <code class="inlineCode">Host</code> class. The final step of this configuration is calling the <code class="inlineCode">Build</code> method, which assembles the actual host with all the configuration information we provided:</p>
<pre class="programlisting code"><code class="hljs-code">...
var myHost=Host.CreateDefaultBuilder(args)
 .ConfigureServices(services =&gt;
    {
        //some configuration
        ...
    })
    .Build();
...
</code></pre>
<p class="normal">Host configuration includes<a id="_idIndexMarker837"/> defining the common resources, defining the default folder for files, loading the configuration parameters from several sources (JSON files, environment variables, and any arguments that are passed to the application), and declaring all the hosted services.</p>
<p class="normal">It is worth pointing out that ASP.NET Core and Blazor projects use methods that perform pre-configuration of the <code class="inlineCode">Host</code>, including several of the tasks listed previously.</p>
<p class="normal">Then, the host is started, which causes all the hosted services to be started:</p>
<pre class="programlisting code"><code class="hljs-code">await host.RunAsync();
</code></pre>
<p class="normal">The program remains blocked on the preceding instruction until the host is shut down. The host is automatically shut down when the operating system kills the process. However, the host can also be shut down manually either by one of the hosted services or externally by calling <code class="inlineCode">await host.StopAsync(timeout)</code>. Here, <code class="inlineCode">timeout</code> is a time span defining the maximum time to wait for the hosted services to stop gracefully. After this time, all the hosted services are aborted if they haven’t been terminated. We will explain how a hosted service can shut down the host later on in this subsection.</p>
<p class="normal">When the thread contains a <code class="inlineCode">host.RunAsync</code> is launched from within another thread instead of <code class="inlineCode">Program.cs</code>. The fact that the host thread is being shut down can be signaled by a <code class="inlineCode">cancellationToken</code> passed to <code class="inlineCode">RunAsync</code>:</p>
<pre class="programlisting code"><code class="hljs-code">await host.RunAsync(cancellationToken)
</code></pre>
<p class="normal">This way of shutting down is triggered as soon as the <code class="inlineCode">cancellationToken</code> enters a canceled state by another thread.</p>
<p class="normal">By default, the host has a 5-second timeout for shutting down; that is, it waits 5 seconds before exiting once a shutdown has been requested. This time can be changed within the <code class="inlineCode">ConfigureServices</code> method, which is used to declare <em class="italic">hosted services</em> and other resources:</p>
<pre class="programlisting code"><code class="hljs-code">var myHost = Host.CreateDefaultBuilder(args)
    .ConfigureServices(services =&gt;
    {
        services.Configure&lt;HostOptions&gt;(option =&gt;
        {
            option.ShutdownTimeout = System.TimeSpan.FromSeconds(10);
        });
        ....
        ....
        //further configuration
    })
    .Build();
</code></pre>
<p class="normal">However, increasing the host<a id="_idIndexMarker838"/> timeout doesn’t increase the orchestrator timeout, so if the host waits too long, the whole microservice is killed by the orchestrator.</p>
<p class="normal">If no cancellation token is explicitly passed to <code class="inlineCode">Run</code> or <code class="inlineCode">RunAsync</code>, a cancellation token is automatically generated and is automatically signaled when the operating system informs the application it is going to kill it. This cancellation token is passed to all hosted services to give them the opportunity to stop gracefully.</p>
<p class="normal">Hosted services are implementations of the <code class="inlineCode">IHostedService</code> interface, whose only methods are <code class="inlineCode">StartAsync(cancellationToken)</code> and <code class="inlineCode">StopAsync(cancellationToken)</code>.</p>
<p class="normal">Both methods are passed a <code class="inlineCode">cancellationToken</code>. The <code class="inlineCode">cancellationToken</code> in the <code class="inlineCode">StartAsync</code> method signals that a shutdown was requested. The <code class="inlineCode">StartAsync</code> method periodically checks this <code class="inlineCode">cancellationToken</code> while performing all operations needed to start the host, and if it is signaled, the host start process is aborted. On the other hand, the <code class="inlineCode">cancellationToken</code> in the <code class="inlineCode">StopAsync</code> method signals that the shutdown timeout expired.</p>
<p class="normal">Hosted services can be declared in the same <code class="inlineCode">ConfigureServices</code> method that’s used to define host options, as follows:</p>
<pre class="programlisting code"><code class="hljs-code">services.AddHostedService&lt;MyHostedService&gt;();
</code></pre>
<p class="normal">Most declarations inside <code class="inlineCode">ConfigureServices</code> require the addition of the following namespace:</p>
<pre class="programlisting code"><code class="hljs-code">using Microsoft.Extensions.DependencyInjection;
</code></pre>
<p class="normal">Usually, the <code class="inlineCode">IHostedService</code> interface<a id="_idIndexMarker839"/> isn’t implemented directly but can be inherited from the <code class="inlineCode">BackgroundService</code> abstract class, which exposes the easier-to-implement <code class="inlineCode">ExecuteAsync(CancellationToken)</code> method, which is where we can place the whole logic of the service. A shutdown is signaled by passing <code class="inlineCode">cancellationToken</code> as an argument, which is easier to handle. We will look in more detail at an implementation of <code class="inlineCode">IHostedService</code> in <em class="chapterRef">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET</em>.</p>
<p class="normal">To allow a hosted service to shut down the whole host, we need to declare an <code class="inlineCode">IApplicationLifetime</code> interface as its constructor parameter:</p>
<pre class="programlisting code"><code class="hljs-code">public class MyHostedService: BackgroundService
{
    private readonly IHostApplicationLifetime _applicationLifetime;
    public MyHostedService(IHostApplicationLifetime applicationLifetime)
    {
        _applicationLifetime=applicationLifetime;
    }
    protected Task ExecuteAsync(CancellationToken token)
    {
        ...
        _applicationLifetime.StopApplication();
        ...
    }
}
</code></pre>
<p class="normal">When the hosted service is created, it is automatically passed an implementation of <code class="inlineCode">IHostApplicationLifetime</code>, whose <code class="inlineCode">StopApplication</code> method will trigger the host shutdown. This implementation is handled automatically, but we can also declare custom resources whose instances will be automatically passed to all the host service constructors that declare them as parameters. Therefore, say we define a constructor like this one:</p>
<pre class="programlisting code"><code class="hljs-code">Public MyClass(MyResource x, IResourceInterface1 y)
{
    ...
}
</code></pre>
<p class="normal">There are several ways to define the resources needed by the preceding constructor:</p>
<pre class="programlisting code"><code class="hljs-code">services.AddTransient&lt;MyResource&gt;();
services.AddTransient&lt;IResourceInterface1, MyResource1&gt;();
services.AddSingleton&lt;MyResource&gt;();
services.AddSingleton&lt;IResourceInterface1, MyResource1&gt;();
</code></pre>
<p class="normal">When we use <code class="inlineCode">AddTransient</code>, a different instance is created and passed to all the constructors that require an instance of that type. On the other hand, with <code class="inlineCode">AddSingleton</code>, a unique instance is created and passed to all the constructors that require the declared type. The overload with two generic types allows you to pass an interface and a type that implements that interface. This way, a constructor requires the interface and is decoupled from the specific implementation of that interface.</p>
<p class="normal">If resource constructors contain parameters, they will be automatically instantiated with the types declared in <code class="inlineCode">ConfigureServices</code> in a recursive<a id="_idIndexMarker840"/> fashion. This pattern of interaction, called <strong class="keyWord">dependency injection</strong> (<strong class="keyWord">DI</strong>), has already been discussed in detail in <em class="chapterRef">Chapter 6</em>, <em class="italic">Design Patterns and .NET 8 Implementation</em>.</p>
<p class="normal"><code class="inlineCode">IHostBuilder</code> also has a method<a id="_idIndexMarker841"/> we can use to define the default folder – that is, the folder used to resolve all relative paths mentioned in all .NET methods:</p>
<pre class="programlisting code"><code class="hljs-code">.UseContentRoot("c:\\&lt;deault path&gt;")
</code></pre>
<p class="normal">It also has methods that we can use to add logging targets:</p>
<pre class="programlisting code"><code class="hljs-code">.ConfigureLogging((hostContext, configLogging) =&gt;
    {
        configLogging.AddConsole();
        configLogging.AddDebug();
    })
</code></pre>
<p class="normal">The previous example shows a console-based logging source, but we can also log in to Azure targets with adequate providers. The <em class="italic">Further reading</em> section contains links to some Azure logging providers that can work with microservices that have been deployed in Azure. Once you’ve configured logging, you can enable your hosted services and log custom messages by adding an <code class="inlineCode">ILogger&lt;T&gt;</code> parameter in their constructors. <code class="inlineCode">ILogger&lt;T&gt; </code>has methods for logging messages with several severity levels: Trace, Debug (lowest), Information, Warning, Error, Critical, and None (highest). In turn, the application configuration specifies the minimum severity level needed to actually output log messages. All messages that pass the severity filter are simultaneously sent to all configured targets.</p>
<p class="normal">The only purpose of the type <code class="inlineCode">T</code> is to classify the message through its full name.</p>
<p class="normal">The developer can specify the minimum severity level in a configuration file. We may have different severity levels for each type of <code class="inlineCode">T</code>.</p>
<p class="normal">For instance:</p>
<pre class="programlisting code"><code class="hljs-code">{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  }
}
</code></pre>
<p class="normal">In the above configuration file, the default severity<a id="_idIndexMarker842"/> level is “<code class="inlineCode">Information</code>”, but all types whose name starts with “<code class="inlineCode">Microsoft.AspNetCore</code>” have a “<code class="inlineCode">Warning</code>” severity level.</p>
<p class="normal">Finally, <code class="inlineCode">IHostBuilder</code> has methods we can use to read configuration parameters from various sources:</p>
<pre class="programlisting code"><code class="hljs-code">.ConfigureAppConfiguration(configHost =&gt;
    {
        configHost.AddJsonFile("settings.json", optional: true);
        configHost.AddEnvironmentVariables(prefix: "PREFIX_");
        configHost.AddCommandLine(args);
    })
</code></pre>
<p class="normal">The way parameters defined in configuration streams can be used from inside the application will be explained in more detail in <em class="chapterRef">Chapter 17</em>, <em class="italic">Presenting ASP.NET Core</em>, which is dedicated to ASP.NET.</p>
<p class="normal">As we transition from the specificities of ASP.NET Core to the broader realm of application deployment and environment setup, an important tool comes into play – Visual Studio Docker support.</p>
<h2 class="heading-2" id="_idParaDest-234">Visual Studio support for Docker</h2>
<p class="normal">Visual Studio offers support<a id="_idIndexMarker843"/> for creating, debugging, and deploying<a id="_idIndexMarker844"/> Docker images. Docker deployment requires us to install <em class="italic">Docker Desktop for Windows</em> on our development machine so that we can run Docker images. </p>
<p class="normal">The download link can be found in the <em class="italic">Technical requirements</em> section at the beginning of this chapter. Before we start any development activity, we must ensure it is installed and running (you should see a Docker icon in the window notification bar when the Docker runtime is running).</p>
<p class="normal">Docker support will be described with a simple ASP.NET Core MVC project. Let’s create one. To do so, follow these steps:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Name the project <code class="inlineCode">MvcDockerTest</code>.</li>
<li class="numberedList">For simplicity, disable authentication if it is not already disabled.</li>
<li class="numberedList">You are given the option to add Docker support when you create the project, but please don’t check the <strong class="screenText">Docker support</strong> checkbox. You can test how Docker support can be added to any project after it has been created.</li>
<li class="numberedList">Once you have your ASP.NET MVC application scaffolded and running, right-click on its project icon in <strong class="screenText">Solution Explorer</strong>, select <strong class="screenText">Add</strong>, and then select <strong class="screenText">Container Orchestrator Support | Docker Compose</strong>. If you installed both <strong class="screenText">WSL</strong> and <strong class="screenText">Windows Containers</strong>, a dialog for choosing between <strong class="screenText">Linux</strong> and <strong class="screenText">Windows</strong> will appear. Otherwise, <strong class="screenText">Linux</strong><strong class="keyWord"> </strong>will be automatically chosen if you installed just <strong class="screenText">WSL</strong>, and <strong class="screenText">Windows</strong> if you installed just <strong class="screenText">Windows Containers</strong>.</li>
<li class="numberedList">If you installed <strong class="screenText">WSL</strong><strong class="keyWord">,</strong> please select <strong class="screenText">Linux</strong>, since it is the default used by the Docker server when WSL is available.</li>
</ol>
<p class="normal">The advantage of enabling Docker Compose instead of just Docker is that you can manually configure how the image is run on the development machine, as well as how Docker image ports are mapped to external ports by editing the Docker Compose files that are added to the solution.</p>
<p class="normal">If your Docker runtime has been installed properly and is running, you should be able to run the Docker image from Visual Studio. Please try it!</p>
<p class="normal">Now that we have explored how to configure and run Docker images, let’s delve deeper into the structure and composition of these images. Understanding the Docker file created by Visual Studio is key to grasping how it orchestrates the creation and management of these images.</p>
<h3 class="heading-3" id="_idParaDest-235">Analyzing the Docker file</h3>
<p class="normal">Let’s analyze the Docker file<a id="_idIndexMarker845"/> that was created by Visual Studio. It is a sequence of image creation steps. Each step enriches an existing image with something else with the help of the <code class="inlineCode">From</code> instruction, which is a reference to an already existing image. The following is the first step:</p>
<pre class="programlisting code"><code class="hljs-code">FROM mcr.microsoft.com/dotnet/aspnet:x.x AS base
WORKDIR /app
EXPOSE 80
EXPOSE 443
</code></pre>
<p class="normal">The first step uses the <code class="inlineCode">mcr.microsoft.com/dotnet/aspnet:x.x</code> ASP.NET (Core) runtime that was published by Microsoft in the Docker public repository (where <code class="inlineCode">x.x</code> is the ASP.NET (Core) version that was selected in your project).</p>
<p class="normal">The <code class="inlineCode">WORKDIR</code> command creates the directory that follows the command within the image that is going to be created. The two <code class="inlineCode">EXPOSE</code> commands declare which ports will be exposed outside the image and mapped to ports of the actual hosting machine. Mapped ports are decided in the deployment stage either as command-line arguments of a Docker command or within a Docker Compose file. In our case, there are two ports: one for HTTP (80) and another for HTTPS (443).</p>
<p class="normal">This intermediate image is cached by Docker, which doesn’t need to recompute since it doesn’t depend on the code we write but only on the selected version of the ASP.NET (Core) runtime.</p>
<p class="normal">The second step produces a different image that will not be used to deploy. Instead, it will be used to create application-specific files that will be deployed:</p>
<pre class="programlisting code"><code class="hljs-code">FROM mcr.microsoft.com/dotnet/core/sdk:x.x  AS build
WORKDIR /src
COPY ["MvcDockerTest/MvcDockerTest.csproj", "MvcDockerTest/"]
RUN dotnet restore MvcDockerTest/MvcDockerTest.csproj
COPY . .
WORKDIR /src/MvcDockerTest
RUN dotnet build MvcDockerTest.csproj -c Release -o /app/build
FROM build AS publish
RUN dotnet publish MvcDockerTest.csproj -c Release -o /app/publish
</code></pre>
<p class="normal">This step starts from the ASP.NET SDK image, which contains parts we don’t need to add for deployment; these are needed to process the project code. The new <code class="inlineCode">src</code> directory is created in the <code class="inlineCode">build</code> image and made the current image directory. Then, the project file is copied into <code class="inlineCode">/src/MvcDockerTest</code>.</p>
<p class="normal">The <code class="inlineCode">RUN</code> command executes an operating system command on the image. In this case, it calls the <code class="inlineCode">dotnet</code> runtime, asking it to restore the NuGet packages that were referenced by the previously copied project file.</p>
<p class="normal">Then, the <code class="inlineCode">COPY..</code> command copies<a id="_idIndexMarker846"/> the whole project file tree into the <code class="inlineCode">src</code> image directory. Finally, the project directory is made the current directory, and the <code class="inlineCode">dotnet</code> runtime is asked to build the project in release mode and copy all the output files into the new <code class="inlineCode">/app/build</code> directory. Finally, the <code class="inlineCode">dotnet publish</code> task is executed in a new image called <code class="inlineCode">publish</code>, outputting the published binaries into <code class="inlineCode">/app/publish</code>.</p>
<p class="normal">The final step starts from the image that we created in the first step, which contains the ASP.NET (Core) runtime and adds all the files that were published in the previous step:</p>
<pre class="programlisting code"><code class="hljs-code">FROM base AS final
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT ["dotnet", "MvcDockerTest.dll"]
</code></pre>
<p class="normal">The <code class="inlineCode">ENTRYPOINT</code> command specifies the operating system command that’s needed to execute the image. It accepts an array of strings. In our case, it accepts the <code class="inlineCode">dotnet</code> command and its first command-line argument – that is, the DLL we need to execute. With that out of the way, let’s now publish our little project!</p>
<h3 class="heading-3" id="_idParaDest-236">Publishing the project</h3>
<p class="normal">If we right-click on our project<a id="_idIndexMarker847"/> and click <strong class="keyWord">Publish</strong>, we are presented with several options:</p>
<ul>
<li class="bulletList">Publish the image to an existing or new web app (automatically created by Visual Studio)</li>
<li class="bulletList">Publish to one of several Docker registries, including a private registry in Azure Container Registry that, if it doesn’t already exist, can be created from within Visual Studio</li>
</ul>
<p class="normal">Docker Compose support allows you to run and publish a multi-container application and add further images, such as a containerized database that is available everywhere.</p>
<p class="normal">The following Docker Compose file instructs the Docker server to run two containerized ASP.NET applications:</p>
<pre class="programlisting code"><code class="hljs-code">version: '3.4'
services:
  mvcdockertest:
    image: ${DOCKER_REGISTRY-}mvcdockertest
    build:
      context: .
      dockerfile: MvcDockerTest/Dockerfile
  mvcdockertest1:
    image: ${DOCKER_REGISTRY-}mvcdockertest1
    build:
      context: .
      dockerfile: MvcDockerTest1/Dockerfile
</code></pre>
<p class="normal">You can add another ASP:NET Core MVC application<a id="_idIndexMarker848"/> to our previous docker-compose file by just adding another ASP:NET Core MVC application named MvcDockerTest 1 to the solution and by enabling docker-compose on it. However, you must pay attention to the fact that the newly created project folder is placed inside the same solution folder as MvcDockerTest.</p>
<p class="normal">The preceding code references existing Docker files. Any environment-dependent information is placed in the <code class="inlineCode">docker-compose.override.yml</code> file, which is merged with the <code class="inlineCode">docker-compose.yml</code> file when the application is launched from Visual Studio:</p>
<pre class="programlisting code"><code class="hljs-code">version: '3.4'
services:
  mvcdockertest:
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=https://+:443;http://+:80
    ports:
      - "80"
      - "443"
    volumes:
      -${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro
      - ${APPDATA}/ASP.NET/Https:/root/.aspnet/https:ro
  mvcdockertest1:
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=https://+:443;http://+:80
    ports:
      - "80"
      - "443"
    volumes:
      - ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro
      - ${APPDATA}/ASP.NET/Https:/root/.aspnet/https:ro
</code></pre>
<p class="normal">For each image, the file specifies some environment variables (which will be defined in the image when the application is launched), the port mappings, and some host files.</p>
<p class="normal">The files in the host are directly mapped into the images. Each declaration contains the path in the host, how the path is mapped in the image, and the desired access rights. In our case, <code class="inlineCode">volumes</code> are used to map the machine key used for all encryption needs of the application and the self-signed HTTPS certificate that’s used by Visual Studio.</p>
<p class="normal">When you launch the application in Visual Studio, just the browser window opens and shows the <strong class="screenText">MvcDockerTest</strong> application. However, both applications are launched, so you just need to discover which port <strong class="screenText">MvcDockerTest1</strong> is running on and open another browser window. You can discover the port by clicking on <strong class="screenText">MvcDockerTest1</strong> in the Containers tab in Visual Studio<a id="_idIndexMarker849"/> and looking at its HTTPS <strong class="screenText">Host Port</strong> (<strong class="screenText">60072</strong>), as shown in the figure below:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_11_08.png"/></figure>
<p class="packt_figref">Figure 11.8: Discovering the MvcDockerTest1 host port</p>
<p class="normal">Now, suppose we want to add a containerized SQL Server instance. We would need something like the following instructions split between <code class="inlineCode">docker-compose.yml</code> and <code class="inlineCode">docker-compose.override.yml</code>:</p>
<pre class="programlisting code"><code class="hljs-code">sql.data:
  image: mcr.microsoft.com/mssql/server:2022-latest
  environment:
  - SA_PASSWORD=Pass@word
  - ACCEPT_EULA=Y
  - MSSQL_PID=Express
  ports:
  - "5433:1433"
</code></pre>
<p class="normal">Here, the preceding code specifies the properties of the SQL Server container, as well as the SQL Server configuration and installation parameters. More specifically, the preceding code contains the following information:</p>
<ul>
<li class="bulletList"><code class="inlineCode">sql.data</code> is the name that’s given to the container.</li>
<li class="bulletList"><code class="inlineCode">image</code> specifies where to take the image from. In our case, the image is contained in a public Docker registry.</li>
<li class="bulletList"><code class="inlineCode">environment</code> specifies the environment<a id="_idIndexMarker850"/> variables that are needed by SQL Server – that is, the administrator password, the acceptance of a SQL Server license, and the SQL Server edition.</li>
<li class="bulletList">As usual, <code class="inlineCode">ports</code> specify the port mappings.</li>
<li class="bulletList"><code class="inlineCode">docker-compose.override.yml</code> is used to run the images from within Visual Studio.</li>
</ul>
<p class="normal">If you need to specify parameters for either the production environment or the testing environment, you can add further <code class="inlineCode">docker-compose-xxx.override.yml</code> files, such as <code class="inlineCode">docker-compose-staging.override.yml</code> and <code class="inlineCode">docker-compose-production.override.yml</code>, and then launch them manually in the target environment with something like the following code:</p>
<pre class="programlisting con"><code class="hljs-con">docker-compose -f docker-compose.yml -f docker-compose-staging.override.yml up
</code></pre>
<p class="normal">Then, you can destroy all the containers with the following code:</p>
<pre class="programlisting con"><code class="hljs-con">docker-compose -f docker-compose.yml -f docker-compose.staging.yml down
</code></pre>
<p class="normal">While <code class="inlineCode">docker-compose</code> has a limited capability when it comes to handling node clusters, it is mainly used in testing and development<a id="_idIndexMarker851"/> environments. For production environments, more sophisticated tools, called orchestrators, are needed. A de facto standard for the production<a id="_idIndexMarker852"/> environment is Kubernetes, which will be analyzed in detail in <em class="chapterRef">Chapter 20</em>, <em class="italic">Kubernetes</em>.</p>
<h2 class="heading-2" id="_idParaDest-237">Azure and Visual Studio support for microservice orchestration</h2>
<p class="normal">Visual Studio has extensions for debugging<a id="_idIndexMarker853"/> a single microservice while <a id="_idIndexMarker854"/>it communicates with other<a id="_idIndexMarker855"/> microservices deployed<a id="_idIndexMarker856"/> in Kubernetes.</p>
<p class="normal">Also available are tools for testing and debugging several communicating microservices in the development machine and for deploying them automatically on Azure Kubernetes Service with just minimal configuration information.</p>
<p class="normal">All Visual Studio tools for Kubernetes and the whole process of developing for Kubernetes with Visual Studio will be described in the practical example in <em class="chapterRef">Chapter 22</em>, <em class="italic">Developing .NET Microservices for Kubernetes</em>.</p>
<p class="normal">Moving on from Visual Studio’s features for Kubernetes, let’s dive into the key tools offered, in general, by all microservices orchestrators like Kubernetes.</p>
<h1 class="heading-1" id="_idParaDest-238">Which tools are needed to manage microservices?</h1>
<p class="normal">Effectively handling microservices<a id="_idIndexMarker857"/> in your CI/CD cycles requires both a private Docker image registry and a state-of-the-art microservice orchestrator that’s capable of doing the following:</p>
<ul>
<li class="bulletList">Allocating and load-balancing microservices on available hardware nodes</li>
<li class="bulletList">Monitoring the health state of services and replacing faulty services if hardware/software failures occur</li>
<li class="bulletList">Logging and presenting analytics</li>
<li class="bulletList">Allowing the designer to dynamically change requirements such as hardware nodes allocated to a cluster, the number of service instances, and so on</li>
</ul>
<p class="normal">The following subsection describes the Azure facilities we can use to store Docker images. The microservices orchestrators available in Azure are described in a dedicated chapter – namely, <em class="chapterRef">Chapter 20</em>, <em class="italic">Kubernetes</em>.</p>
<p class="normal">Having learned about the essential functionalities offered by microservices orchestration, let’s now turn<a id="_idIndexMarker858"/> our attention to how Azure facilitates these processes, starting with the setup of a private Docker registry.</p>
<h2 class="heading-2" id="_idParaDest-239">Defining your private Docker registry in Azure</h2>
<p class="normal">Defining your private Docker registry <a id="_idIndexMarker859"/>in Azure is easy. Just type <code class="inlineCode">Container registries</code> into the Azure<a id="_idIndexMarker860"/> search bar and select <strong class="screenText">Container registries</strong>. On the page that appears, click on the <strong class="screenText">Create</strong> button.</p>
<p class="normal">The following form will appear:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" src="img/B19820_11_09.png"/></figure>
<p class="packt_figref">Figure 11.9: Creating an Azure private Docker registry</p>
<p class="normal">The name you select is used<a id="_idIndexMarker861"/> to compose the overall<a id="_idIndexMarker862"/> registry URI: <code class="inlineCode">&lt;name&gt;.azurecr.io</code>. As usual, you can specify the subscription, resource group, and location. The <strong class="screenText">SKU</strong> dropdown lets you choose from various levels of offerings that differ in terms of performance, available memory, and a few other auxiliary features.</p>
<p class="normal">Whenever you mention image names in Docker commands or in a Visual Studio publish form, you must prefix them with the registry URI: <code class="inlineCode">&lt;name&gt;.azurecr.io/&lt;my imagename&gt;</code>.</p>
<p class="normal">If images are created with Visual Studio, then they can be published by following the instructions that appear once you publish the project. Otherwise, you must use Docker commands to push them into your registry.</p>
<p class="normal">The easiest way to use Docker<a id="_idIndexMarker863"/> commands that interact<a id="_idIndexMarker864"/> with the Azure registry is by installing the Azure CLI on your computer. Download the installer from <a href="https://aka.ms/installazurecliwindows">https://aka.ms/installazurecliwindows</a> and execute it. Once the Azure CLI has been installed, you can use the <code class="inlineCode">az</code> command from Windows Command Prompt or PowerShell. In order to connect with your Azure account, you must execute the following <code class="inlineCode">login</code> command:</p>
<pre class="programlisting con"><code class="hljs-con">az login
</code></pre>
<p class="normal">This command should start your default browser and should drive you through the manual login procedure.</p>
<p class="normal">Once logged in to your Azure account, you can log in to your private registry by typing the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az acr login --name {registryname}
</code></pre>
<p class="normal">Now, let’s say you have a Docker image in another registry. As a first step, let’s pull the image on your local computer:</p>
<pre class="programlisting con"><code class="hljs-con">docker pull other.registry.io/samples/myimage
</code></pre>
<p class="normal">If there are several versions of the preceding image, the latest will be pulled since no version was specified. The version of the image can be specified as follows:</p>
<pre class="programlisting con"><code class="hljs-con">docker pull other.registry.io/samples/myimage:version1.0
</code></pre>
<p class="normal">Using the following command, you should see <code class="inlineCode">myimage</code> within the list of local images:</p>
<pre class="programlisting con"><code class="hljs-con">docker images
</code></pre>
<p class="normal">Then, tag the image with the path you want to assign in the Azure registry:</p>
<pre class="programlisting con"><code class="hljs-con">docker tag myimage myregistry.azurecr.io/testpath/myimage
</code></pre>
<p class="normal">Both the name and destination tag may have versions (<code class="inlineCode">:&lt;version name&gt;</code>).</p>
<p class="normal">Finally, push it to your registry with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">docker push myregistry.azurecr.io/testpath/myimage
</code></pre>
<p class="normal">In this case, you can specify a version; otherwise, the latest version is pushed.</p>
<p class="normal">By doing this, you can remove<a id="_idIndexMarker865"/> the image from your local computer <a id="_idIndexMarker866"/>using the following command:</p>
<pre class="programlisting con"><code class="hljs-con">docker rmi myregistry.azurecr.io/testpath/myimage
</code></pre>
<h1 class="heading-1" id="_idParaDest-240">Summary</h1>
<p class="normal">In this chapter, we described what microservices are and how they have evolved from the concept of a module. Then, we talked about the advantages of microservices and when it is worth using them, as well as general criteria for their design. We also explained what Docker containers are and analyzed the strong connection between containers and microservice architectures.</p>
<p class="normal">Then, we took on a more practical implementation by describing all the tools that are available in .NET so that we can implement microservice-based architectures. We also described infrastructures that are needed by microservices and how Azure offers both container registries and container orchestrators.</p>
<p class="normal">This chapter was just a general introduction to microservices. Further chapters will discuss most of the subjects introduced here in more detail while showing practical implementation techniques and code examples.</p>
<p class="normal">This ends the first part of the book dedicated to fundamentals. The next chapter, <em class="italic">Choosing Your Data Storage in the Cloud</em>, starts the second part of the book, which is dedicated to specific technologies.</p>
<h1 class="heading-1" id="_idParaDest-241">Questions</h1>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">What is the two-fold nature of the module concept?</li>
<li class="numberedList">Is scaling optimization the only advantage of microservices? If not, list some further advantages.</li>
<li class="numberedList">What is Polly?</li>
<li class="numberedList">What Docker support is offered by Visual Studio?</li>
<li class="numberedList">What is an orchestrator, and what orchestrators are available on Azure?</li>
<li class="numberedList">Why is publisher/subscriber-based communication so important in microservices?</li>
<li class="numberedList">What is RabbitMQ?</li>
<li class="numberedList">Why are idempotent messages so important?</li>
</ol>
<h1 class="heading-1" id="_idParaDest-242">Further reading</h1>
<p class="normal">The following are links to the official documentation for Azure Service Bus, RabbitMQ, and other event bus technologies:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Azure Service Bus</strong>: <a href="https://docs.microsoft.com/en-us/azure/service-bus-messaging/">https://docs.microsoft.com/en-us/azure/service-bus-messaging/</a></li>
<li class="bulletList"><strong class="keyWord">NServiceBus</strong>: <a href="https://particular.net/nservicebus">https://particular.net/nservicebus</a></li>
<li class="bulletList"><strong class="keyWord">MassTransit</strong>: <a href="https://masstransit-project.com/">https://masstransit-project.com/</a></li>
<li class="bulletList"><strong class="keyWord">Brighter</strong>: <a href="https://www.goparamore.io/">https://www.goparamore.io/</a></li>
<li class="bulletList"><strong class="keyWord">RabbitMQ</strong>: <a href="https://www.rabbitmq.com/getstarted.html">https://www.rabbitmq.com/getstarted.html</a></li>
<li class="bulletList"><strong class="keyWord">EasyNetQ</strong>: <a href="https://easynetq.com/">https://easynetq.com/</a></li>
<li class="bulletList">The following are also links for Polly and Docker:<ul>
<li class="bulletList">The documentation for Polly, a tool for reliable communication/tasks, can be found here: <a href="https://github.com/App-vNext/Polly">https://github.com/App-vNext/Polly</a></li>
<li class="bulletList">More information on Docker can be found on Docker’s official website: <a href="https://docs.docker.com/">https://docs.docker.com/</a></li>
</ul>
</li>
</ul>
<h1 class="heading-1">Learn more on Discord</h1>
<p class="normal">To join the Discord community for this book – where you can share feedback, ask questions to the authors, and learn about new releases – follow the QR code below:</p>
<p class="normal"><a href="https://packt.link/SoftwareArchitectureCSharp12Dotnet8">https://packt.link/SoftwareArchitectureCSharp12Dotnet8</a></p>
<p class="normal"><img alt="" role="presentation" src="img/QR_Code175081751210902046.png"/></p>
</div>
</body></html>