- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Applying a Microservice Architecture to Your Enterprise Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is dedicated to describing highly scalable architectures based
    on small modules called microservices. The microservice architecture allows for
    fine-grained scaling operations where every single module can be scaled as required
    without affecting the remainder of the system. Moreover, they allow for better
    **Continuous Integration/Continuous Deployment** (**CI/CD**) by permitting every
    system subpart to evolve and be deployed independently of the others.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What are microservices?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When do microservices help?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does .NET deal with microservices?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which tools are needed to manage microservices?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned how to implement a single
    microservice in .NET. *Chapter 20*, *Kubernetes*, also explains how to deploy,
    debug, and manage a whole microservices-based application. *Chapter 14*, *Implementing
    Microservices with .NET*, and *Chapter 18*, *Implementing Frontend Microservices
    with ASP.NET Core,* are step-by-step guides to the practical implementation of
    microservices with .NET.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code for this chapter is available at [https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E](https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will require the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2022 free Community Edition or better with all the database tools
    installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A free Azure account. The *Creating an Azure account* section in *Chapter 1*,
    *Understanding the Importance of Software Architecture*, explains how to create
    one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Docker Desktop for Windows** if you want to debug Docker containerized microservices
    in Visual Studio ([https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In turn, **Docker Desktop for Windows** requires at least Windows 10 with either
    **Windows Subsystem for Linux** (**WSL**) or **Windows Containers** installed.
  prefs: []
  type: TYPE_NORMAL
- en: '**WSL** enables Docker containers to run on a Linux virtual machine and can
    be installed as follows (see also [https://learn.microsoft.com/en-us/windows/wsl/install](https://learn.microsoft.com/en-us/windows/wsl/install)):'
  prefs: []
  type: TYPE_NORMAL
- en: Type `powershell` in the Windows 10/11 search bar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When **Windows PowerShell** is proposed as a search result, click on **Run as
    an administrator**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Windows PowerShell administrative console that appears, run the command
    `wsl --install`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Windows Containers** enable Docker containers to run directly on Windows,
    but they require at least the Windows Professional edition. They can be installed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Type `Windows features` in the Windows 10/11 search bar.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The search results will propose running the panel to enable/disable Windows
    features.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on it, and in the window that opens, select **Containers**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are microservices?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices are essentially small, independent units that make up a larger
    software application, each with its specific role and functionality. Splitting
    a software application into independent microservices allows each module that
    makes up a solution to be scaled independently from the others to achieve the
    maximum throughput with minimal cost. In fact, scaling whole systems instead of
    their current bottlenecks inevitably results in a remarkable waste of resources,
    so fine-grained control of subsystem scaling has a considerable impact on the
    system’s overall cost.
  prefs: []
  type: TYPE_NORMAL
- en: However, microservices are more than scalable components – they are software
    building blocks that can be developed, maintained, and deployed independently
    of each other. Splitting development and maintenance among modules that can be
    independently developed, maintained, and deployed improves the overall system’s
    CI/CD cycle (CI/CD was described in detail in *Chapter 8*, *Understanding DevOps
    Principles and CI/CD*).
  prefs: []
  type: TYPE_NORMAL
- en: 'The CI/CD improvement is due to microservice *independence* because it enables
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Scaling and distributing microservices on different types of hardware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since each microservice is deployed independently from the others, there can’t
    be binary compatibility or database structure compatibility constraints. Therefore,
    there is no need to align the versions of the different microservices that compose
    the system. This means that each of them can evolve as needed without being constrained
    by the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, attention must be paid to the choice of communication protocols and
    messages and to their versions, which must be supported by all involved microservices.
    Protocols that are widely supported and that facilitate backward compatibility
    with previous versions of messages should be preferred.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Assigning their development to completely separate smaller teams, thus simplifying
    job organization and reducing all the inevitable coordination inefficiencies that
    arise when handling large teams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing each microservice with more adequate technologies and in a more
    adequate environment since each microservice is an independent deployment unit.
    This means choosing tools that best fit your requirements and an environment that
    minimizes development efforts and/or maximizes performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since each microservice can be implemented with different technologies, programming
    languages, tools, and operating systems, enterprises can use all available human
    resources by matching environments with developers’ competencies. For instance,
    all available Java and .NET developers can cooperate in the same application,
    thus exploiting all available resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Legacy subsystems can be embedded in independent microservices, thus enabling
    them to cooperate with newer subsystems. This way, companies may reduce the time
    to market new system versions. Moreover, in this way, legacy systems can evolve
    slowly toward more modern systems with an acceptable impact on costs and the organization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next subsection explains how the concept of microservices was conceived.
    Then, we will continue this introductory section by exploring basic microservice
    design principles and analyzing why microservices are often designed as Docker
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices and the evolution of the concept of modules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For a better understanding of the advantages of microservices, as well as their
    design techniques, we must keep the two-fold nature of software modularity and
    software modules in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code modularity** refers to code organization that makes it easy for us to
    modify a chunk of code without affecting the remainder of the application. It
    is usually enforced with object-oriented design, where modules can be identified
    with classes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment modularity** depends on what your deployment units are and which
    properties they have. The simplest deployment units are executable files and libraries.
    Thus, for instance, **dynamic link libraries** (**DLLs**) are, for sure, more
    modular than static libraries since they must not be linked with the main executable
    before being deployed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the fundamental concepts of code modularity have reached stasis, the concept
    of deployment modularity is still evolving, and microservices are currently state-of-the-art
    along this evolution path.
  prefs: []
  type: TYPE_NORMAL
- en: As a short review of the main milestones on the path that led to microservices,
    we can say that, first, monolithic executables were broken into static libraries.
    Later on, DLLs replaced static libraries.
  prefs: []
  type: TYPE_NORMAL
- en: A great change took place when .NET (and other analogous frameworks, such as
    Java) improved the modularity of executables and libraries. In fact, with .NET,
    they can be deployed on different hardware and different operating systems since
    they are deployed in an intermediary language that is compiled when the library
    is executed for the first time. Moreover, they overcome some versioning issues
    of previous DLLs since any executable can bring with it a DLL with a version that
    differs from the version of the same DLL that is installed on the operating system.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, .NET can’t accept two referenced DLLs – let’s say, *A* and *B* – using
    two different versions of a common dependency – let’s say, *C*. For instance,
    suppose there is a newer version of *A* with many new features we would like to
    use that, in turn, relies on a newer version of *C* that is not supported by *B*.
    In this situation, we should renounce the newer version of *A* because of the
    incompatibility of *C* with *B*. This difficulty has led to two important changes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Packages: The development world moved from using single DLLs and/or single
    files as deployment units to using packages composed of both DLLs and metadata
    as deployment units. Packages are handled by *package management systems* such
    as NuGet and npm, which use package metadata to automatically check version compatibility
    with the help of semantic versioning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service-Oriented Architecture** (**SOA**): Deployment units started being
    implemented as SOAP-based web services and later transition to REST web services.
    This solves the version compatibility problem since each web service runs in a
    different process and can use the most adequate version of each library with no
    risk of causing incompatibilities with other web services. Moreover, the interface
    that is exposed by each web service is platform-agnostic; that is, web services
    can connect with applications using any framework and run on any operating system
    since web service protocols are based on universally accepted standards. SOAs
    and protocols will be discussed in more detail in *Chapter 15*, *Applying Service-Oriented
    Architectures with .NET.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices are an evolution of SOA and add more features and more constraints
    that improve the scalability and the modularity of services to improve the overall
    CI/CD cycle. It’s sometimes said that microservices are SOA done well. Moreover,
    as we will see in the next section, microservices are strictly tied with the DDD
    methodology described in *Chapter 7*, *Understanding the Different Domains in
    Software Solutions*.
  prefs: []
  type: TYPE_NORMAL
- en: To sum things up, the microservice architecture is an SOA that maximizes independence
    and fine-grained scaling. Now that we’ve clarified all the advantages of microservice
    independence and fine-grained scaling, as well as the very nature of independence,
    we are in a position to look at microservice design principles.
  prefs: []
  type: TYPE_NORMAL
- en: Microservice design principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will learn about the microservices’ basic design principles.
    These principles are the basis for designing each microservice’s code and architecture,
    and for designing the whole application architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with principles that arise from the independence constraint. We
    will discuss them each in a separate subsection.
  prefs: []
  type: TYPE_NORMAL
- en: The independence of design choices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A fundamental design principle is the *independence of design choices*, which
    can be stated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The design of each microservice must not depend on the design choices that were
    made in the implementation of other microservices.
  prefs: []
  type: TYPE_NORMAL
- en: This principle enables the full independence of each microservice CI/CD cycle
    and leaves us with more technological choices on how to implement each microservice.
    This way, we can choose the best available technology to implement each microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Another consequence of this principle is that different microservices can’t
    connect to the same shared storage (database or filesystem) since sharing the
    same storage also means sharing all the design choices that determine the structure
    of the storage subsystem (database table design, database engine, and so on).
    Thus, either a microservice has its own data storage, or it has no storage at
    all and communicates with other microservices that take care of handling storage.
  prefs: []
  type: TYPE_NORMAL
- en: Dedicated data storage can be implemented either by physically including the
    database service within the boundary of the microservice or with an external database
    that the microservice has exclusive access to. Both are acceptable design choices.
    However, external databases are usually adopted because, for performance reasons,
    database engines are better run on dedicated hardware and with OS and hardware
    features that are optimized for their storage functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, the *independence of design choices* is interpreted in a lighter form
    by distinguishing between logical and physical microservices. More specifically,
    logical microservices are the result of splitting the application into logical
    independent modules. If the application is designed with a **domain-driven design**
    (**DDD**) methodology, logical microservices correspond to DDD-bounded contexts,
    which we discussed in detail in *Chapter 7*, *Understanding the Different Domains
    in Software Solutions*.
  prefs: []
  type: TYPE_NORMAL
- en: In turn, each logical microservice may be split into various physical microservices
    that use the same data storage but that are load-balanced independently to achieve
    a better load balance.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, in the book case study, travel payments are handled by the Payments
    Bounded Context described in the Understanding the domains of the WWTravelClub
    application section of *Chapter 21*, *Case Study*, which gives rise to a unique
    logical microservice. However, its practical implementation requires two main
    submodules:'
  prefs: []
  type: TYPE_NORMAL
- en: A customer credit card verification and authorization module, which takes care
    of all credit card verifications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A user credits management module, which handles credits that the user already
    purchased, card information already loaded in the platform, and new credit card
    info loading
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the process of credit card verification and authorization might be very
    time-consuming, it is convenient to implement the two submodules above as independent
    physical microservices, so they can be load-balanced separately.
  prefs: []
  type: TYPE_NORMAL
- en: Independence from the deployment environment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: During load-balancing, microservices can be moved from very busy hardware nodes
    to more idle nodes. However, dependencies of each microservice on other software/files
    of the destination hardware nodes constrain the possible destination nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the more we reduce microservice dependencies, the more we have the
    freedom to move them from busy nodes to idle nodes, achieve a better load balance,
    and exploit the available hardware nodes.
  prefs: []
  type: TYPE_NORMAL
- en: This is the reason microservices are often containerized and use Docker. Containers
    will be discussed in more detail in the *Containers and Docker* subsection of
    this chapter, but basically, containerization is a technique that allows each
    microservice to bring its dependencies with it so that it can run anywhere. However,
    this is not a must because, in some applications, one might verify that all dependencies
    requirements of all microservices can be easily satisfied by all available nodes.
  prefs: []
  type: TYPE_NORMAL
- en: As we explore how microservices operate within their containerized environments,
    another key architectural principle comes into play – the concept of loose coupling.
  prefs: []
  type: TYPE_NORMAL
- en: Loose coupling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each microservice must be loosely coupled with all the other microservices.
    This principle has a two-fold nature. On the one hand, this means that, according
    to object-oriented programming principles, the interface that’s exposed by each
    microservice must not be too specific but as general as possible. However, it
    also means that communications among microservices must be minimized in order
    to reduce communication costs since microservices don’t share the same address
    space and run on different hardware nodes.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, suppose we are implementing a distributed web video game with
    a microservice architecture. Each microservice might take care of different functionalities,
    like collisions, visibility, user input handling, and so on. Some modules, like
    the collision and visibility modules, must know the whole game state, such as
    places where the user avatars are, the state of each avatar, and also the state
    of each reactive object that is in the game (such as obstacles, bullets shot by
    avatars, and so on). Therefore, either all the modules with a hard dependency
    on the whole game state are collapsed into a unique microservice or we must find
    an efficient way to share the overall game state between them with just a few
    message exchanges.
  prefs: []
  type: TYPE_NORMAL
- en: Both options have advantages and disadvantages and are actually adopted by real-world
    video games. Fewer messages might cause temporary incongruences, but melting too
    many modules into a unique microservice might impact the overall game performance
    so that the game might appear too “slow” to the users.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concept of minimal inter-service communication naturally leads us to another
    consideration: the avoidance of chained requests/responses in a microservice architecture'
  prefs: []
  type: TYPE_NORMAL
- en: No chained requests/responses
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When a request reaches a microservice, it must not cause a recursive chain of
    nested requests/responses to other microservices since a similar chain would result
    in an unacceptable response time.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, suppose that microservice A issues a request to microservice B
    and then waits for B to answer, and B does the same with C, and C does the same
    with D, and so on. As a result, A remains blocked waiting for its answer for the
    whole time the request propagates first to B, then to C, and then to D, and then
    the answer propagates back from D to C, then from C to B, and finally reaches
    A. That is, four request propagation times sum to the other four answer propagation
    times to get the overall A wait time. This way, the time a user waits to get an
    answer from the application might easily become unacceptable.
  prefs: []
  type: TYPE_NORMAL
- en: Chained requests/responses can be avoided if the private data models of all
    the microservices synchronize with push events each time they change. In other
    words, as soon as the data that is handled by a microservice changes, those changes
    are sent to all the microservices that may need them to serve their requests.
    This way, each microservice has all the data it needs to serve all its incoming
    requests in its private data storage, with no need to ask other microservices
    for the data that it lacks.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 11.1* shows how updates are sent to all interested microservices as
    soon as they are produced and how each microservice combines all received updates
    in a local database. This way, each query microservice has all the data it needs
    to answer queries in its local database.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19820_11_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Push events'
  prefs: []
  type: TYPE_NORMAL
- en: In conclusion, every microservice must contain all the data it needs to serve
    incoming requests and ensure fast responses. To keep their data models up to date
    and ready for incoming requests, microservices must communicate their data changes
    as soon as they take place. These data changes should be communicated through
    asynchronous messages since synchronous nested messages cause unacceptable performance
    because they block all the threads involved in the call tree until a result is
    returned.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth pointing out that the *independence of design choices* principle
    is substantially the bounded context principle of DDD, which we discussed in detail
    in *Chapter 7*, *Understanding the Different Domains in Software Solutions*. In
    this chapter, we have seen that, often, a full DDD approach is useful for the
    *update* subsystem of each microservice.
  prefs: []
  type: TYPE_NORMAL
- en: It’s not trivial that, in general, all systems that have been developed according
    to the bounded context principle are better implemented with a microservice architecture.
    In fact, once a system has been decomposed into several completely independent
    and loosely coupled parts, it is very likely that these different parts will need
    to be scaled independently because of different traffic and different resource
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: At the preceding constraints, we must also add some best practices for building
    a reusable SOA. More details on these best practices will be given in *Chapter
    15*, *Applying Service-Oriented Architectures with .NET*, but nowadays, most SOA
    best practices are automatically enforced by tools and frameworks that are used
    to implement web services.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fine-grained scaling is a key aspect of microservices architecture, involving
    several critical software and infrastructure requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: First of all, microservices must be small enough to isolate well-defined functionalities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also need a complex infrastructure that takes care of automatically instantiating
    microservices and allocating instances on various hardware computational resources,
    commonly called **nodes**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The same infrastructure must take care of scaling microservices and load-balancing
    them on the available nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These kinds of structures will be introduced in the *Which tools are needed
    to manage microservices?* section of this chapter, and discussed in detail in
    *Chapter 20*, *Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, fine-grained scaling of distributed microservices that communicate
    through asynchronous communication requires each microservice to be resilient.
    In fact, communication that’s directed to a specific microservice instance may
    fail due to a hardware fault or for the simple reason that the target instance
    was killed or moved to another node during a load-balancing operation.
  prefs: []
  type: TYPE_NORMAL
- en: Temporary failures can be overcome with exponential retries. This is where we
    retry the same operation after each failure with a delay that increases exponentially
    until a maximum number of attempts is reached. For instance, first, we would retry
    after 10 milliseconds, and if this retry operation results in a failure, a new
    attempt is made after 20 milliseconds, then after 40 milliseconds, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, long-term failures often cause an explosion of retry operations
    that may saturate all system resources in a way that is similar to a denial-of-service
    attack. Therefore, usually, exponential retries are used together with a *circuit
    break strategy*: after a given number of failures, a long-term failure is assumed,
    and access to the resource is prevented for a given time by returning an immediate
    failure without attempting the communication operation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also fundamental that the congestion of some subsystems, due to either
    failure or a request peak, does not propagate to other system parts in order to
    prevent overall system congestion. *Bulkhead isolation* prevents congestion propagation
    in the following ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Only a maximum number of similar simultaneous outbound requests are allowed;
    let’s say, 10\. This is similar to putting an upper bound on thread creation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requests exceeding the previous bound are queued.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the maximum queue length is reached, any further requests result in exceptions
    being thrown to abort them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The practical .NET implementation of exponential retries, circuit break, and
    bulkhead isolation is described in the *Resilient task execution subsection* of
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Retry policies may make it so that the same message is received and processed
    several times because the sender has received no confirmation that the message
    has been received, or simply because it has timed out the operation while the
    receiver actually received the message. The only possible solution to this problem
    is designing all messages so that they’re idempotent – that is, designing messages
    in such a way that processing the same message several times has the same effect
    as processing it once.
  prefs: []
  type: TYPE_NORMAL
- en: Updating a database table field to a value, for instance, is an idempotent operation
    since repeating it once or twice has exactly the same effect. However, incrementing
    a decimal field is not an idempotent operation. Microservice designers should
    make an effort to design the overall application with as many idempotent messages
    as possible.
  prefs: []
  type: TYPE_NORMAL
- en: An idempotent message is also a message that, if processed twice, doesn’t cause
    malfunctions. For instance, a message that modifies the price of travel is idempotent
    because if we process it another time, we just set again the price to the same
    price as before. However, a message whose purpose is to add a new travel booking
    is not idempotent since if we process it twice, we add two travel bookings instead
    of one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remaining non-idempotent messages must be transformed into idempotent in
    the following way or with other similar techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: Attach both a time and some identifier that uniquely identifies each message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Store all the messages that have been received in a dictionary that’s been indexed
    by the unique identifier attached to the message mentioned in the previous point.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reject old messages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When a message that may be a duplicate is received, verify whether it’s contained
    in the dictionary. If it is, then it has already been processed, so reject it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since old messages are rejected, they can be periodically removed from the dictionary
    to prevent it from growing exponentially.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In *Chapter 14*, *Implementing Microservices with .NET*, we will use this technique
    in practice and discuss communication and coordination problems in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth pointing out that some message brokers, such as Azure Service Bus,
    offer facilities for implementing the technique described previously. However,
    the receiver must always be able to recognize duplicate messages since, due to
    time-outs in the reception of acknowledgments, messages might be resent. Azure
    Service Bus is discussed in the *.NET communication facilities* subsection.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will talk about microservice containerization based
    on Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Containers and Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve already discussed the advantages of having microservices that don’t depend
    on the environment where they run; microservices can be moved from busy nodes
    to idle nodes without constraints, thus achieving a better load balance and, consequently,
    better usage of the available hardware.
  prefs: []
  type: TYPE_NORMAL
- en: However, if we need to mix legacy software with newer modules, the ability to
    mix several development stacks in order to use the best stack for each module
    implementation, and so on, we are faced with the problem that the various microservices
    have different hardware/software prerequisites. In these cases, the independence
    of each microservice from the hosting environment can be restored by deploying
    each microservice with all its dependencies on a private virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: However, starting a virtual machine with its private copy of the operating system
    takes a lot of time, and microservices must be started and stopped quickly to
    reduce load-balancing and fault recovery costs. In fact, new microservices may
    be started either to replace faulty ones or because they were moved from one hardware
    node to another to perform load-balancing. Moreover, adding a whole copy of the
    operating system to each microservice instance would be an excessive overhead.
  prefs: []
  type: TYPE_NORMAL
- en: 'Luckily, microservices can rely on a lighter form of technology: containers.
    Containers provide a lightweight, efficient form of virtualization. Unlike traditional
    virtual machines that virtualize an entire machine, including the operating system,
    containers virtualize at the OS filesystem level, sitting on top of the host OS
    kernel. They use the operating system of the hosting machine (kernel, DLLs, and
    drivers) and use the OS’s native features to isolate processes and resources,
    creating an isolated environment for the images they run.'
  prefs: []
  type: TYPE_NORMAL
- en: As a consequence, containers are tied to a specific OS, but they don’t suffer
    the overhead of copying and starting a whole OS in each container instance.
  prefs: []
  type: TYPE_NORMAL
- en: On each host machine, containers are handled by a runtime that takes care of
    creating them from *images* and creating an isolated environment for each of them.
    The most popular container image format is Docker, which is a *de facto* standard
    for container images.
  prefs: []
  type: TYPE_NORMAL
- en: Images contain files needed to create each container and specify which container
    resources, such as communication ports, to expose outside of the container. However,
    they need not explicitly contain all involved files since they can be layered.
    This way, each image is built by adding new files and configuration information
    on top of another existing image that is referenced from inside the newly defined
    image.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if you want to deploy a .NET application as a Docker image, it
    is enough to just add your software and files to your Docker image and then reference
    an already existing .NET Docker image.
  prefs: []
  type: TYPE_NORMAL
- en: 'To allow for easy image referencing, images are grouped into registries that
    may be either public or private. They are similar to NuGet or npm registries.
    Docker offers a public registry ([https://hub.docker.com/_/registry](https://hub.docker.com/_/registry))
    where you can find most of the public images you may need to reference in your
    own images. However, each company can define private registries. For instance,
    Microsoft offers Azure Container Registry, where you can define your private container
    registry service: [https://azure.microsoft.com/en-us/services/container-registry/](https://azure.microsoft.com/en-us/services/container-registry/).
    There, you can also find most of the .NET-related images you might need to reference
    in your code.'
  prefs: []
  type: TYPE_NORMAL
- en: Before instantiating each container, the Docker runtime must solve all the recursive
    references. This cumbersome job is not performed each time a new container is
    created since the Docker runtime has a cache where it stores the fully assembled
    images that correspond to each input image and that it has already processed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since each application is usually composed of several modules to be run in
    different containers, a tool called **Docker Compose** also allows `.yml` files,
    known as **composition files**, that specify the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: Which images to deploy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How the internal resources that are exposed by each image must be mapped to
    the physical resources of the host machine. For instance, how communication ports
    that are exposed by Docker images must be mapped to the ports of the physical
    machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will analyze Docker images and `.yml` files in the *How does .NET deal with
    microservices?* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The Docker runtime handles images and containers on a single machine, but usually,
    containerized microservices are deployed and load-balanced on clusters that are
    composed of several machines. Clusters are handled by pieces of software called
    **orchestrators**. Orchestrators will be introduced in the *Which tools are needed
    to manage microservices?* section of this chapter, and described in detail in
    *Chapter 20,* *Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand what microservices are, what problems they can solve,
    and their basic design principles, we are ready to analyze when and how to use
    them in our system architecture. The next section analyzes when we should use
    them.
  prefs: []
  type: TYPE_NORMAL
- en: When do microservices help?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The answer to this question requires us to understand the roles microservices
    play in modern software architectures. We will look at this in the following two
    subsections:'
  prefs: []
  type: TYPE_NORMAL
- en: Layered architectures and microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When is it worth considering microservice architectures?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with a detailed look at layered architectures and microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Layered architectures and microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed in *Chapter 7, Understanding the Different Domains in Software
    Solutions*, enterprise systems are usually organized in logical independent layers.
    The outermost layer is the one that interacts with the user and is called the
    presentation layer (in the onion architecture, the outermost layer also contains
    drivers and test suites), while the last layer (the innermost layer in the onion
    architecture) takes care of application permanent data handling and is called
    the data layer (the domain layer in the onion architecture). Requests originate
    in the presentation layer and pass through all the layers until they reach the
    data layer (and then come back, traversing all the layers in reverse until they
    reach the outermost layer again).
  prefs: []
  type: TYPE_NORMAL
- en: In the case of classical layered architecture (the onion architecture is quite
    different, as discussed in *Chapter 7*, *Understanding the Different Domains in
    Software Solutions*), each layer takes data from the previous layer, processes
    it, and passes it to the next layer. Then, it receives the results from its next
    layer and sends them back to its previous layer. Also, thrown exceptions can’t
    jump layers – each layer must take care of intercepting all the exceptions and
    either *solve them* somehow or transform them into other exceptions that are expressed
    in the language of its previous layer. The layered architecture ensures the complete
    independence of the functionalities of each layer from the functionalities of
    all the other layers.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, we can change the **Object-Relational Mapping** (**ORM**) software
    that interfaces the database without affecting all the layers that are above the
    data layer (ORM software is discussed in *Chapter 13*, *Interacting with Data
    in C# – Entity Framework Core*). In the same way, we can completely change the
    user interface (that is, the presentation layer) without affecting the remainder
    of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, each layer implements a different kind of system specification. The
    data layer takes care of what the system *must remember*, the presentation layer
    takes care of the system-user interaction protocol, and all the layers that are
    in the middle implement the domain rules, which specify how data must be processed
    (for instance, how an employee paycheck must be computed). Typically, the data
    and presentation layers are separated by just one domain rule layer, called the
    business or application layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19820_11_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Layers of classic architectures'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each layer *speaks* a different language: the data layer speaks the language
    of relation among entities, the business layer speaks the language of domain experts,
    and the presentation layer speaks the language of users. So, when data and exceptions
    pass from one layer to another, they must be translated into the language of the
    destination layer.'
  prefs: []
  type: TYPE_NORMAL
- en: That being said, how do microservices fit into a layered architecture? Are they
    adequate for the functionalities of all the layers or just some layers? Can a
    single microservice span several layers?
  prefs: []
  type: TYPE_NORMAL
- en: 'The last question is the easiest to answer: yes! In fact, we’ve already stated
    that microservices should store the data they need within their logical boundaries.
    Therefore, there are microservices that span the business and data layers, for
    sure.'
  prefs: []
  type: TYPE_NORMAL
- en: However, since we said that each logical microservice can be implemented with
    several physical microservices for pure load-balancing reasons, one microservice
    might take care of encapsulating data used by another microservice that might
    remain confined in the data layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, we said also that while each microservice must have its exclusive
    storage, it can use also external storage engines. This is shown in the diagram
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_11_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: External or internal storage'
  prefs: []
  type: TYPE_NORMAL
- en: It is worth pointing out that the storage engine itself can be implemented as
    a set of physical microservices that are associated with no logical microservice
    since they may be considered part of the infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: This is the case, for instance, for storage engines based on the distributed
    Redis in-memory cache, where we use microservice facilities offered by the infrastructure
    to implement scalable one-master/many-read-only replicas, or sophisticated many-master/many-read-only
    replicas distributed in memory storage. Redis and Redis Cloud services are described
    in the *Redis* section *of* *Chapter 12*, *Choosing Your Data Storage in the Cloud*,
    while many-master/many-read-only replicas architectures are described in *Chapter
    20*, *Kubernetes*. The diagram below shows how microservice-based many-master/many-read-only
    replicas storage engines work.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_11_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Many-master/many-read-only replicas storage engine'
  prefs: []
  type: TYPE_NORMAL
- en: Each master has its associated read-only replicas. Storage updates can be passed
    just to masters that replicate their data to all their associated read-only replicas.
  prefs: []
  type: TYPE_NORMAL
- en: Each master takes care of a portion of the storage space, for instance, all
    products whose name starts with “A,” and so on. In this way, the load is balanced
    between all masters.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we may have business layer microservices, data layer microservices, and
    microservices that span both layers. So, what about the presentation layer?
  prefs: []
  type: TYPE_NORMAL
- en: The presentation layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This layer can also fit into a microservice architecture if it is implemented
    on the server side – that is, if the whole graphic that interacts with the user
    is built on the server side and not in the user client machine (mobile device,
    desktop, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: When there are microservices that interact directly with the user, we speak
    of server-side implementation of the presentation layer since the HTML and/or
    all elements of the user interface are created by the frontend, which sends the
    response to the user.
  prefs: []
  type: TYPE_NORMAL
- en: These kinds of microservices are called frontend microservices, while microservices
    that do back-office work without interacting with the user are called worker microservices.
    The diagram below summarizes the frontend/worker organization.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_11_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: Frontend and worker microservices'
  prefs: []
  type: TYPE_NORMAL
- en: When, instead, the HTML and/or all elements of the user interface are generated
    on the user machine, we speak of client-side implementation of the presentation
    layer. The so-called single-page applications and mobile applications run the
    presentation layer on the client machine and interact with the application through
    communication interfaces exposed by dedicated microservices. These dedicated microservices
    are completely analogous to the frontend microservices depicted in *Figure 11.5*
    and are called *API gateways,* to underline their role of exposing a public API
    for connecting client devices with the whole microservices infrastructure. Also,
    API gateways interact with worker microservices in a way that is completely analogous
    to frontend microservices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Single-page applications and mobile/desktop client applications are discussed
    in *Chapter 19*, *Client Frameworks: Blazor*.'
  prefs: []
  type: TYPE_NORMAL
- en: In a microservice architecture, when the presentation layer is a website, it
    can be implemented with a set of several microservices. However, if it requires
    heavy web servers and/or heavy frameworks, containerizing them may not be convenient.
    This decision must also consider the loss of performance that happens when containerizing
    the web server and the possible need for hardware firewalls between the web server
    and the remainder of the system.
  prefs: []
  type: TYPE_NORMAL
- en: ASP.NET Core is a lightweight framework that runs on the Kestrel web server,
    so it can be containerized efficiently and used as is in the worker microservices.
    The usage of ASP:NET Core in the implementation of worker microservices is described
    in great detail in *Chapter 14*, *Implementing Microservices with .NET*.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, frontend and/or high-traffic websites have more compelling security
    and load-balancing requirements that can be satisfied just with fully-featured
    web servers. Accordingly, architectures based on microservices usually offer specialized
    components that take care of interfacing with the outside world. For instance,
    in *Chapter 20*, *Kubernetes*, we will see that in microservices-dedicated infrastructures
    like **Kubernetes** clusters, this role is played by so-called **ingresses**.
    These are fully-featured web servers interfaced with the microservices infrastructure.
    Thanks to the integration with the microservices infrastructure, the whole web
    server traffic is automatically routed to the interested microservices. More details
    on this will be given in *Chapter 20*, *Kubernetes*. The diagram below shows the
    role of Ingresses.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_11_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.6: Ingresses based on load-balanced web servers'
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic websites can be easily broken into load-balanced smaller subsites
    without microservice-specific technologies, but a microservice architecture can
    bring all the advantages of microservices into the construction of a single HTML
    page. More specifically, different microservices may take care of different areas
    of each HTML page. Microservices that cooperate in the construction of the HTML
    of application pages, and, in general, in the construction of any kind of user
    interface, are named micro-frontends.
  prefs: []
  type: TYPE_NORMAL
- en: When the HTML is created on the server side, the various micro-frontends create
    HTML chunks that are combined either on the server side or directly in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: When, instead, the HTML is created directly on the client, each micro-frontend
    provides a different chunk of code to the client. These code chunks are run on
    the client machine, and each of them takes care of different pages/page areas.
    We will speak more of this kind of micro-frontend in *Chapter 18*, *Implementing
    Frontend Microservices with ASP.NET Core*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve clarified which parts of a system can benefit from the adoption
    of microservices, we are ready to state the rules when it comes to deciding how
    they’re adopted.
  prefs: []
  type: TYPE_NORMAL
- en: When is it worth considering microservice architectures?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Microservices can improve the implementation of both the business and data
    layers, but their adoption has some costs:'
  prefs: []
  type: TYPE_NORMAL
- en: Allocating instances to nodes and scaling them has a cost in terms of cloud
    fees or internal infrastructures and licenses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Splitting a unique process into smaller communication processes increases communication
    costs and hardware needs, especially if the microservices are containerized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing and testing software for a microservice requires more time and increases
    engineering costs, both in time and complexity. In particular, making microservices
    resilient and ensuring that they adequately handle all possible failures, as well
    as verifying these features with integration tests, can increase the development
    time by more than one order of magnitude (that is, about 10 times).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, when are microservices worth the cost of using them? Are there functionalities
    that must be implemented as microservices?
  prefs: []
  type: TYPE_NORMAL
- en: A rough answer to the second question is yes when the application is big enough
    in terms of traffic and/or software complexity. In fact, as an application grows
    in complexity and its traffic increases, it’s recommended that we pay the costs
    associated with scaling it since this allows for more scaling optimization and
    better handling when it comes to the development team. The costs we pay for these
    would soon exceed the cost of microservice adoption.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, if fine-grained scaling makes sense for our application, and if we can
    estimate the savings that fine-grained scaling and development give us, we can
    easily compute an overall application throughput limit that makes the adoption
    of microservices convenient.
  prefs: []
  type: TYPE_NORMAL
- en: Microservice costs can also be justified by an increase in the market value
    of our products/services. Since the microservice architecture allows us to implement
    each microservice with a technology that has been optimized for its use, the quality
    that’s added to our software may justify all or part of the microservice costs.
  prefs: []
  type: TYPE_NORMAL
- en: However, scaling and technology optimizations are not the only parameters to
    consider. Sometimes, we are forced to adopt a microservice architecture without
    being able to perform a detailed cost analysis.
  prefs: []
  type: TYPE_NORMAL
- en: If the size of the team that takes care of the CI/CD of the overall system grows
    too much, the organization and coordination of this big team cause difficulties
    and inefficiencies. In this type of situation, it is desirable to move to an architecture
    that breaks the whole CI/CD cycle into independent parts that can be taken care
    of by smaller teams.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, since these development costs are only justified by a high volume
    of requests, we probably have high traffic being processed by independent modules
    that have been developed by different teams. Therefore, scaling optimizations
    and the need to reduce interaction between development teams make the adoption
    of a microservice architecture very convenient.
  prefs: []
  type: TYPE_NORMAL
- en: From this, we may conclude that if the system and the development team grow
    too much, it is necessary to split the development team into smaller teams, each
    working on an efficient bounded context subsystem. It is very likely that, in
    a similar situation, a microservice architecture is the only possible option.
  prefs: []
  type: TYPE_NORMAL
- en: Another situation that forces the adoption of a microservice architecture is
    the integration of newer subparts with legacy subsystems based on different technologies,
    as containerized microservices are the only way to implement an efficient interaction
    between the legacy system and the new subparts in order to gradually replace the
    legacy subparts with newer ones. Similarly, if our team is composed of developers
    with experience in different development stacks, an architecture based on containerized
    microservices may become a *must*.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will analyze the building blocks and tools that are
    available for the implementation of .NET-based microservices.
  prefs: []
  type: TYPE_NORMAL
- en: How does .NET deal with microservices?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The new .NET, which evolved from .NET Core, was conceived as a multi-platform
    framework that was light and fast enough to implement efficient microservices.
    In particular, ASP.NET Core is the ideal tool for implementing text REST and binary
    gRPC APIs to communicate with a microservice since it can run efficiently with
    lightweight web servers such as Kestrel and is itself light and modular.
  prefs: []
  type: TYPE_NORMAL
- en: The whole .NET stack evolved with microservices as a strategic deployment platform
    in mind and has facilities and packages for building efficient and light HTTP
    and gRPC communication to ensure service resiliency and to handle long-running
    tasks. The following subsections describe some of the different tools or solutions
    that we can use to implement a .NET-based microservice architecture.
  prefs: []
  type: TYPE_NORMAL
- en: .NET communication facilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microservices need two kinds of communication channels.
  prefs: []
  type: TYPE_NORMAL
- en: The first communication channel receives external requests, either directly
    or through an API gateway. HTTP is the usual protocol for external communication
    due to available web service standards and tools. .NET’s main HTTP/gRPC communication
    facility is ASP.NET Core since it’s a lightweight HTTP/gRPC framework, which makes
    it ideal for implementing web APIs in small microservices. We will describe ASP.NET
    REST API apps in detail in *Chapter 15*, *Applying Service-Oriented Architectures
    with .NET*, and we will describe gRPC services in *Chapter 14*, *Implementing
    Microservices with .NET*. .NET also offers an efficient and modular HTTP client
    solution that is able to pool and reuse heavy connection objects. Also, the `HttpClient`
    class will be described in more detail in *Chapter 15*.
  prefs: []
  type: TYPE_NORMAL
- en: The second channel is a different type of communication channel to push updates
    to other microservices. In fact, we have already mentioned that intra-microservice
    communication cannot be triggered by an ongoing request since a complex tree of
    blocking calls to other microservices would increase request latency to an unacceptable
    level. As a consequence, updates must not be requested immediately before they’re
    used and should be pushed whenever state changes take place. Ideally, this kind
    of communication should be asynchronous to achieve acceptable performance. In
    fact, synchronous calls would block the sender while they are waiting for the
    result, thus increasing the idle time of each microservice. However, synchronous
    communication that just puts the request in a processing queue and then returns
    confirmation of the successful communication instead of the final result is acceptable
    if communication is fast enough (low communication latency and high bandwidth).
    A publisher/subscriber communication would be preferable since, in this case,
    the sender and receiver don’t need to know each other, thus increasing the microservices’
    independence. In fact, all the receivers that are interested in a certain type
    of communication merely need to register to receive a specific *event*, while
    senders just need to publish those events. All the wiring is performed by a service
    that takes care of queuing events and dispatching them to all the subscribers.
    The publisher/subscriber pattern was described in *Chapter 6*, *Design Patterns
    and .NET 8 Implementation*, along with other useful patterns.
  prefs: []
  type: TYPE_NORMAL
- en: While .NET doesn’t directly offer tools that may help in asynchronous communication
    or client/server tools that implement publisher/subscriber communication, Azure
    offers a similar service with *Azure Service Bus* ([https://docs.microsoft.com/en-us/azure/service-bus-messaging/](https://docs.microsoft.com/en-us/azure/service-bus-messaging/)).
    Azure Service Bus handles both queued asynchronous communication through Azure
    Service Bus *queues* and publisher/subscriber communication through Azure Service
    Bus *topics*.
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve configured the Azure Service Bus on the Azure portal, you can connect
    to it in order to send messages/events and receive messages/events through a client
    contained in `Microsoft.Azure.ServiceBus` NuGet package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure Service Bus has two types of communication: queue-based and topic-based.
    In queue-based communication, each message that’s placed in the queue by a sender
    is removed from the queue by the first receiver that pulls it from the queue.
    Topic-based communication, on the other hand, is an implementation of the publisher/subscriber
    pattern. Each topic has several subscriptions, and a different copy of each message
    sent to a topic can be pulled from each topic subscription.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The design flow is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Define an Azure Service Bus private namespace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get the root connection strings that were created by the Azure portal and/or
    define new connection strings with fewer privileges.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define queues and/or topics where the sender will send their messages in binary
    format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each topic, define names for all the required subscriptions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the case of queue-based communication, the sender sends messages to a queue,
    and the receivers pull messages from the same queue. Each message is delivered
    to one receiver. That is, once a receiver gains access to the queue, it reads
    and removes one or more messages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the case of topic-based communication, each sender sends messages to a topic
    while each receiver pulls messages from its private subscription associated with
    that topic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are also other commercial and free open-source alternatives to Azure Service
    Bus, such as NServiceBus ([https://particular.net/nservicebus](https://particular.net/nservicebus)),
    MassTransit ([https://masstransit-project.com/](https://masstransit-project.com/)),
    and Brighter ([https://www.goparamore.io/](https://www.goparamore.io/)). They
    enhance existing brokers (like Azure Service Bus itself) with higher-level functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is also a completely independent option that can be used on on-premises
    platforms: RabbitMQ. It is free and open source and can be installed locally,
    on a virtual machine, or in a Docker container. Then, you can connect with it
    through the client contained in the `RabbitMQ.Client` NuGet package.'
  prefs: []
  type: TYPE_NORMAL
- en: The functionalities of RabbitMQ are similar to the ones offered by Azure Service
    Bus, but you have to take care of more implementation details, like serialization,
    reliable messages, and error handling, while Azure Service Bus takes care of all
    the low-level operations and offers you a simpler interface. However, there are
    clients that build a more powerful abstraction on top of RabbitMQ, like, for instance,
    EasyNetQ. The publisher/subscriber-based communication pattern used by both Azure
    Service Bus and RabbitMQ was described in *Chapter 6*, *Design Patterns and .NET
    8 Implementation*. RabbitMQ will be described in more detail in *Chapter 14*,
    *Implementing Microservices with .NET*.
  prefs: []
  type: TYPE_NORMAL
- en: Resilient task execution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Resilient communication and, in general, resilient task execution can be implemented
    easily with the help of a .NET library called Polly, whose project is a member
    of the .NET Foundation. Polly is available through the `Polly` NuGet package.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Polly, you define policies and then execute tasks in the context of those
    policies, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first part of each policy specifies the exceptions that must be handled.
    Then, you specify what to do when one of those exceptions is captured. In the
    preceding code, the `Execute` method is retried up to three times if a failure
    is reported either by an `HttpRequestException` exception or by an `OperationCanceledException`
    exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the implementation of an exponential retry policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The first argument of `WaitAndRetryAsync` specifies that a maximum of six retries
    is performed in the event of failure. The lambda function passed as the second
    argument specifies how much time to wait before the next attempt. In this specific
    example, this time grows exponentially with the number of attempts by a power
    of 2 (2 seconds for the first retry, 4 seconds for the second retry, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a simple circuit breaker policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: After six failures, the task can’t be executed for one minute since an exception
    is returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the implementation of the Bulkhead Isolation policy (see the
    *Microservices design principles* section for more information):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: A maximum of 10 parallel executions is allowed in the `Execute` method. Further
    tasks are inserted in an execution queue. This has a limit of 15 tasks. If the
    queue limit is exceeded, an exception is thrown.
  prefs: []
  type: TYPE_NORMAL
- en: For the Bulkhead Isolation policy to work properly and, in general, for every
    strategy to work properly, task executions must be triggered through the same
    policy instance; otherwise, Polly is unable to count how many executions of a
    specific task are active.
  prefs: []
  type: TYPE_NORMAL
- en: 'Policies can be combined with the `Wrap` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Polly offers several more options, such as generic methods for tasks that return
    a specific type, timeout policies, task result caching, the ability to define
    custom policies, and so on. It is also possible to configure Polly as part of
    an `HttpClient` definition in the dependency injection section of any ASP.NET
    Core and .NET application. This way, it is quite immediate to define resilient
    clients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Polly’s official documentation can be found in its GitHub repository here:
    [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).'
  prefs: []
  type: TYPE_NORMAL
- en: The practical usage of Polly is explained in the *A worker microservice with
    ASP.NET Core* section of *Chapter 21*, *Case Study*.
  prefs: []
  type: TYPE_NORMAL
- en: The resilience and robustness provided by tools like Polly are crucial components
    of microservice architecture, particularly when managing complex tasks and processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings us to another fundamental aspect of microservices: the implementation
    of generic hosts.'
  prefs: []
  type: TYPE_NORMAL
- en: Using generic hosts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each microservice may need to run several independent threads, with each performing
    a different operation on requests received. Such threads need several resources,
    such as database connections, communication channels, specialized modules that
    perform complex operations, and so on. Moreover, all processing threads must be
    adequately initialized when the microservice is started and gracefully stopped
    when the microservice is stopped as a consequence of either load-balancing or
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: All of these needs led the .NET team to conceive and implement *hosted services*
    and *hosts*. A host creates an adequate environment for running several tasks,
    known as **hosted services**, and provides them with resources, common settings,
    and a graceful start/stop.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of a web host was initially conceived to implement the ASP.NET Core
    web framework, but, with effect from .NET Core 2.1, the host concept was extended
    to all .NET applications.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing this book, a `Host` is automatically created for you
    in any ASP.NET Core, Blazor, and Worker Service project. The simplest way to test
    .NET Host features is to select a **Service -> Worker Service** project.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_11_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.7: Creating a Worker Service project in Visual Studio'
  prefs: []
  type: TYPE_NORMAL
- en: All features related to the concept of a `Host` are contained in the `Microsoft.Extensions.Hosting`
    NuGet package.
  prefs: []
  type: TYPE_NORMAL
- en: '`Program.cs` contains some skeleton code for configuring the host with a fluent
    interface, starting with the `CreateDefaultBuilder` method of the `Host` class.
    The final step of this configuration is calling the `Build` method, which assembles
    the actual host with all the configuration information we provided:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Host configuration includes defining the common resources, defining the default
    folder for files, loading the configuration parameters from several sources (JSON
    files, environment variables, and any arguments that are passed to the application),
    and declaring all the hosted services.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth pointing out that ASP.NET Core and Blazor projects use methods that
    perform pre-configuration of the `Host`, including several of the tasks listed
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the host is started, which causes all the hosted services to be started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The program remains blocked on the preceding instruction until the host is shut
    down. The host is automatically shut down when the operating system kills the
    process. However, the host can also be shut down manually either by one of the
    hosted services or externally by calling `await host.StopAsync(timeout)`. Here,
    `timeout` is a time span defining the maximum time to wait for the hosted services
    to stop gracefully. After this time, all the hosted services are aborted if they
    haven’t been terminated. We will explain how a hosted service can shut down the
    host later on in this subsection.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the thread contains a `host.RunAsync` is launched from within another
    thread instead of `Program.cs`. The fact that the host thread is being shut down
    can be signaled by a `cancellationToken` passed to `RunAsync`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This way of shutting down is triggered as soon as the `cancellationToken` enters
    a canceled state by another thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, the host has a 5-second timeout for shutting down; that is, it
    waits 5 seconds before exiting once a shutdown has been requested. This time can
    be changed within the `ConfigureServices` method, which is used to declare *hosted
    services* and other resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: However, increasing the host timeout doesn’t increase the orchestrator timeout,
    so if the host waits too long, the whole microservice is killed by the orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: If no cancellation token is explicitly passed to `Run` or `RunAsync`, a cancellation
    token is automatically generated and is automatically signaled when the operating
    system informs the application it is going to kill it. This cancellation token
    is passed to all hosted services to give them the opportunity to stop gracefully.
  prefs: []
  type: TYPE_NORMAL
- en: Hosted services are implementations of the `IHostedService` interface, whose
    only methods are `StartAsync(cancellationToken)` and `StopAsync(cancellationToken)`.
  prefs: []
  type: TYPE_NORMAL
- en: Both methods are passed a `cancellationToken`. The `cancellationToken` in the
    `StartAsync` method signals that a shutdown was requested. The `StartAsync` method
    periodically checks this `cancellationToken` while performing all operations needed
    to start the host, and if it is signaled, the host start process is aborted. On
    the other hand, the `cancellationToken` in the `StopAsync` method signals that
    the shutdown timeout expired.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hosted services can be declared in the same `ConfigureServices` method that’s
    used to define host options, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Most declarations inside `ConfigureServices` require the addition of the following
    namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Usually, the `IHostedService` interface isn’t implemented directly but can be
    inherited from the `BackgroundService` abstract class, which exposes the easier-to-implement
    `ExecuteAsync(CancellationToken)` method, which is where we can place the whole
    logic of the service. A shutdown is signaled by passing `cancellationToken` as
    an argument, which is easier to handle. We will look in more detail at an implementation
    of `IHostedService` in *Chapter 14*, *Implementing Microservices with .NET*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To allow a hosted service to shut down the whole host, we need to declare an
    `IApplicationLifetime` interface as its constructor parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'When the hosted service is created, it is automatically passed an implementation
    of `IHostApplicationLifetime`, whose `StopApplication` method will trigger the
    host shutdown. This implementation is handled automatically, but we can also declare
    custom resources whose instances will be automatically passed to all the host
    service constructors that declare them as parameters. Therefore, say we define
    a constructor like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several ways to define the resources needed by the preceding constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: When we use `AddTransient`, a different instance is created and passed to all
    the constructors that require an instance of that type. On the other hand, with
    `AddSingleton`, a unique instance is created and passed to all the constructors
    that require the declared type. The overload with two generic types allows you
    to pass an interface and a type that implements that interface. This way, a constructor
    requires the interface and is decoupled from the specific implementation of that
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: If resource constructors contain parameters, they will be automatically instantiated
    with the types declared in `ConfigureServices` in a recursive fashion. This pattern
    of interaction, called **dependency injection** (**DI**), has already been discussed
    in detail in *Chapter 6*, *Design Patterns and .NET 8 Implementation*.
  prefs: []
  type: TYPE_NORMAL
- en: '`IHostBuilder` also has a method we can use to define the default folder –
    that is, the folder used to resolve all relative paths mentioned in all .NET methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'It also has methods that we can use to add logging targets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The previous example shows a console-based logging source, but we can also
    log in to Azure targets with adequate providers. The *Further reading* section
    contains links to some Azure logging providers that can work with microservices
    that have been deployed in Azure. Once you’ve configured logging, you can enable
    your hosted services and log custom messages by adding an `ILogger<T>` parameter
    in their constructors. `ILogger<T>` has methods for logging messages with several
    severity levels: Trace, Debug (lowest), Information, Warning, Error, Critical,
    and None (highest). In turn, the application configuration specifies the minimum
    severity level needed to actually output log messages. All messages that pass
    the severity filter are simultaneously sent to all configured targets.'
  prefs: []
  type: TYPE_NORMAL
- en: The only purpose of the type `T` is to classify the message through its full
    name.
  prefs: []
  type: TYPE_NORMAL
- en: The developer can specify the minimum severity level in a configuration file.
    We may have different severity levels for each type of `T`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the above configuration file, the default severity level is “`Information`”,
    but all types whose name starts with “`Microsoft.AspNetCore`” have a “`Warning`”
    severity level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, `IHostBuilder` has methods we can use to read configuration parameters
    from various sources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The way parameters defined in configuration streams can be used from inside
    the application will be explained in more detail in *Chapter 17*, *Presenting
    ASP.NET Core*, which is dedicated to ASP.NET.
  prefs: []
  type: TYPE_NORMAL
- en: As we transition from the specificities of ASP.NET Core to the broader realm
    of application deployment and environment setup, an important tool comes into
    play – Visual Studio Docker support.
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio support for Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Visual Studio offers support for creating, debugging, and deploying Docker images.
    Docker deployment requires us to install *Docker Desktop for Windows* on our development
    machine so that we can run Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: The download link can be found in the *Technical requirements* section at the
    beginning of this chapter. Before we start any development activity, we must ensure
    it is installed and running (you should see a Docker icon in the window notification
    bar when the Docker runtime is running).
  prefs: []
  type: TYPE_NORMAL
- en: 'Docker support will be described with a simple ASP.NET Core MVC project. Let’s
    create one. To do so, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Name the project `MvcDockerTest`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For simplicity, disable authentication if it is not already disabled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You are given the option to add Docker support when you create the project,
    but please don’t check the **Docker support** checkbox. You can test how Docker
    support can be added to any project after it has been created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have your ASP.NET MVC application scaffolded and running, right-click
    on its project icon in **Solution Explorer**, select **Add**, and then select
    **Container Orchestrator Support | Docker Compose**. If you installed both **WSL**
    and **Windows Containers**, a dialog for choosing between **Linux** and **Windows**
    will appear. Otherwise, **Linux**will be automatically chosen if you installed
    just **WSL**, and **Windows** if you installed just **Windows Containers**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you installed **WSL****,** please select **Linux**, since it is the default
    used by the Docker server when WSL is available.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The advantage of enabling Docker Compose instead of just Docker is that you
    can manually configure how the image is run on the development machine, as well
    as how Docker image ports are mapped to external ports by editing the Docker Compose
    files that are added to the solution.
  prefs: []
  type: TYPE_NORMAL
- en: If your Docker runtime has been installed properly and is running, you should
    be able to run the Docker image from Visual Studio. Please try it!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have explored how to configure and run Docker images, let’s delve
    deeper into the structure and composition of these images. Understanding the Docker
    file created by Visual Studio is key to grasping how it orchestrates the creation
    and management of these images.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the Docker file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s analyze the Docker file that was created by Visual Studio. It is a sequence
    of image creation steps. Each step enriches an existing image with something else
    with the help of the `From` instruction, which is a reference to an already existing
    image. The following is the first step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The first step uses the `mcr.microsoft.com/dotnet/aspnet:x.x` ASP.NET (Core)
    runtime that was published by Microsoft in the Docker public repository (where
    `x.x` is the ASP.NET (Core) version that was selected in your project).
  prefs: []
  type: TYPE_NORMAL
- en: 'The `WORKDIR` command creates the directory that follows the command within
    the image that is going to be created. The two `EXPOSE` commands declare which
    ports will be exposed outside the image and mapped to ports of the actual hosting
    machine. Mapped ports are decided in the deployment stage either as command-line
    arguments of a Docker command or within a Docker Compose file. In our case, there
    are two ports: one for HTTP (80) and another for HTTPS (443).'
  prefs: []
  type: TYPE_NORMAL
- en: This intermediate image is cached by Docker, which doesn’t need to recompute
    since it doesn’t depend on the code we write but only on the selected version
    of the ASP.NET (Core) runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second step produces a different image that will not be used to deploy.
    Instead, it will be used to create application-specific files that will be deployed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This step starts from the ASP.NET SDK image, which contains parts we don’t need
    to add for deployment; these are needed to process the project code. The new `src`
    directory is created in the `build` image and made the current image directory.
    Then, the project file is copied into `/src/MvcDockerTest`.
  prefs: []
  type: TYPE_NORMAL
- en: The `RUN` command executes an operating system command on the image. In this
    case, it calls the `dotnet` runtime, asking it to restore the NuGet packages that
    were referenced by the previously copied project file.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the `COPY..` command copies the whole project file tree into the `src`
    image directory. Finally, the project directory is made the current directory,
    and the `dotnet` runtime is asked to build the project in release mode and copy
    all the output files into the new `/app/build` directory. Finally, the `dotnet
    publish` task is executed in a new image called `publish`, outputting the published
    binaries into `/app/publish`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final step starts from the image that we created in the first step, which
    contains the ASP.NET (Core) runtime and adds all the files that were published
    in the previous step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `ENTRYPOINT` command specifies the operating system command that’s needed
    to execute the image. It accepts an array of strings. In our case, it accepts
    the `dotnet` command and its first command-line argument – that is, the DLL we
    need to execute. With that out of the way, let’s now publish our little project!
  prefs: []
  type: TYPE_NORMAL
- en: Publishing the project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If we right-click on our project and click **Publish**, we are presented with
    several options:'
  prefs: []
  type: TYPE_NORMAL
- en: Publish the image to an existing or new web app (automatically created by Visual
    Studio)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publish to one of several Docker registries, including a private registry in
    Azure Container Registry that, if it doesn’t already exist, can be created from
    within Visual Studio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose support allows you to run and publish a multi-container application
    and add further images, such as a containerized database that is available everywhere.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Docker Compose file instructs the Docker server to run two containerized
    ASP.NET applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: You can add another ASP:NET Core MVC application to our previous docker-compose
    file by just adding another ASP:NET Core MVC application named MvcDockerTest 1
    to the solution and by enabling docker-compose on it. However, you must pay attention
    to the fact that the newly created project folder is placed inside the same solution
    folder as MvcDockerTest.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code references existing Docker files. Any environment-dependent
    information is placed in the `docker-compose.override.yml` file, which is merged
    with the `docker-compose.yml` file when the application is launched from Visual
    Studio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: For each image, the file specifies some environment variables (which will be
    defined in the image when the application is launched), the port mappings, and
    some host files.
  prefs: []
  type: TYPE_NORMAL
- en: The files in the host are directly mapped into the images. Each declaration
    contains the path in the host, how the path is mapped in the image, and the desired
    access rights. In our case, `volumes` are used to map the machine key used for
    all encryption needs of the application and the self-signed HTTPS certificate
    that’s used by Visual Studio.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you launch the application in Visual Studio, just the browser window opens
    and shows the **MvcDockerTest** application. However, both applications are launched,
    so you just need to discover which port **MvcDockerTest1** is running on and open
    another browser window. You can discover the port by clicking on **MvcDockerTest1**
    in the Containers tab in Visual Studio and looking at its HTTPS **Host Port**
    (**60072**), as shown in the figure below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_11_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.8: Discovering the MvcDockerTest1 host port'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, suppose we want to add a containerized SQL Server instance. We would need
    something like the following instructions split between `docker-compose.yml` and
    `docker-compose.override.yml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the preceding code specifies the properties of the SQL Server container,
    as well as the SQL Server configuration and installation parameters. More specifically,
    the preceding code contains the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sql.data` is the name that’s given to the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`image` specifies where to take the image from. In our case, the image is contained
    in a public Docker registry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`environment` specifies the environment variables that are needed by SQL Server
    – that is, the administrator password, the acceptance of a SQL Server license,
    and the SQL Server edition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As usual, `ports` specify the port mappings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker-compose.override.yml` is used to run the images from within Visual
    Studio.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you need to specify parameters for either the production environment or
    the testing environment, you can add further `docker-compose-xxx.override.yml`
    files, such as `docker-compose-staging.override.yml` and `docker-compose-production.override.yml`,
    and then launch them manually in the target environment with something like the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can destroy all the containers with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: While `docker-compose` has a limited capability when it comes to handling node
    clusters, it is mainly used in testing and development environments. For production
    environments, more sophisticated tools, called orchestrators, are needed. A de
    facto standard for the production environment is Kubernetes, which will be analyzed
    in detail in *Chapter 20*, *Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Azure and Visual Studio support for microservice orchestration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Visual Studio has extensions for debugging a single microservice while it communicates
    with other microservices deployed in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Also available are tools for testing and debugging several communicating microservices
    in the development machine and for deploying them automatically on Azure Kubernetes
    Service with just minimal configuration information.
  prefs: []
  type: TYPE_NORMAL
- en: All Visual Studio tools for Kubernetes and the whole process of developing for
    Kubernetes with Visual Studio will be described in the practical example in *Chapter
    22*, *Developing .NET Microservices for Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on from Visual Studio’s features for Kubernetes, let’s dive into the
    key tools offered, in general, by all microservices orchestrators like Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Which tools are needed to manage microservices?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Effectively handling microservices in your CI/CD cycles requires both a private
    Docker image registry and a state-of-the-art microservice orchestrator that’s
    capable of doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Allocating and load-balancing microservices on available hardware nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring the health state of services and replacing faulty services if hardware/software
    failures occur
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging and presenting analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allowing the designer to dynamically change requirements such as hardware nodes
    allocated to a cluster, the number of service instances, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following subsection describes the Azure facilities we can use to store
    Docker images. The microservices orchestrators available in Azure are described
    in a dedicated chapter – namely, *Chapter 20*, *Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Having learned about the essential functionalities offered by microservices
    orchestration, let’s now turn our attention to how Azure facilitates these processes,
    starting with the setup of a private Docker registry.
  prefs: []
  type: TYPE_NORMAL
- en: Defining your private Docker registry in Azure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Defining your private Docker registry in Azure is easy. Just type `Container
    registries` into the Azure search bar and select **Container registries**. On
    the page that appears, click on the **Create** button.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following form will appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B19820_11_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.9: Creating an Azure private Docker registry'
  prefs: []
  type: TYPE_NORMAL
- en: 'The name you select is used to compose the overall registry URI: `<name>.azurecr.io`.
    As usual, you can specify the subscription, resource group, and location. The
    **SKU** dropdown lets you choose from various levels of offerings that differ
    in terms of performance, available memory, and a few other auxiliary features.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever you mention image names in Docker commands or in a Visual Studio publish
    form, you must prefix them with the registry URI: `<name>.azurecr.io/<my imagename>`.'
  prefs: []
  type: TYPE_NORMAL
- en: If images are created with Visual Studio, then they can be published by following
    the instructions that appear once you publish the project. Otherwise, you must
    use Docker commands to push them into your registry.
  prefs: []
  type: TYPE_NORMAL
- en: 'The easiest way to use Docker commands that interact with the Azure registry
    is by installing the Azure CLI on your computer. Download the installer from [https://aka.ms/installazurecliwindows](https://aka.ms/installazurecliwindows)
    and execute it. Once the Azure CLI has been installed, you can use the `az` command
    from Windows Command Prompt or PowerShell. In order to connect with your Azure
    account, you must execute the following `login` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This command should start your default browser and should drive you through
    the manual login procedure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once logged in to your Azure account, you can log in to your private registry
    by typing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s say you have a Docker image in another registry. As a first step,
    let’s pull the image on your local computer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'If there are several versions of the preceding image, the latest will be pulled
    since no version was specified. The version of the image can be specified as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the following command, you should see `myimage` within the list of local
    images:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, tag the image with the path you want to assign in the Azure registry:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Both the name and destination tag may have versions (`:<version name>`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, push it to your registry with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In this case, you can specify a version; otherwise, the latest version is pushed.
  prefs: []
  type: TYPE_NORMAL
- en: 'By doing this, you can remove the image from your local computer using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described what microservices are and how they have evolved
    from the concept of a module. Then, we talked about the advantages of microservices
    and when it is worth using them, as well as general criteria for their design.
    We also explained what Docker containers are and analyzed the strong connection
    between containers and microservice architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we took on a more practical implementation by describing all the tools
    that are available in .NET so that we can implement microservice-based architectures.
    We also described infrastructures that are needed by microservices and how Azure
    offers both container registries and container orchestrators.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter was just a general introduction to microservices. Further chapters
    will discuss most of the subjects introduced here in more detail while showing
    practical implementation techniques and code examples.
  prefs: []
  type: TYPE_NORMAL
- en: This ends the first part of the book dedicated to fundamentals. The next chapter,
    *Choosing Your Data Storage in the Cloud*, starts the second part of the book,
    which is dedicated to specific technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the two-fold nature of the module concept?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is scaling optimization the only advantage of microservices? If not, list some
    further advantages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is Polly?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What Docker support is offered by Visual Studio?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an orchestrator, and what orchestrators are available on Azure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is publisher/subscriber-based communication so important in microservices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is RabbitMQ?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are idempotent messages so important?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are links to the official documentation for Azure Service Bus,
    RabbitMQ, and other event bus technologies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Service Bus**: [https://docs.microsoft.com/en-us/azure/service-bus-messaging/](https://docs.microsoft.com/en-us/azure/service-bus-messaging/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NServiceBus**: [https://particular.net/nservicebus](https://particular.net/nservicebus)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MassTransit**: [https://masstransit-project.com/](https://masstransit-project.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Brighter**: [https://www.goparamore.io/](https://www.goparamore.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RabbitMQ**: [https://www.rabbitmq.com/getstarted.html](https://www.rabbitmq.com/getstarted.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**EasyNetQ**: [https://easynetq.com/](https://easynetq.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following are also links for Polly and Docker:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The documentation for Polly, a tool for reliable communication/tasks, can be
    found here: [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More information on Docker can be found on Docker’s official website: [https://docs.docker.com/](https://docs.docker.com/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask questions to the authors, and learn about new releases – follow the QR code
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/SoftwareArchitectureCSharp12Dotnet8](https://packt.link/SoftwareArchitectureCSharp12Dotnet8)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code175081751210902046.png)'
  prefs: []
  type: TYPE_IMG
