- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Utilizing Asynchronous Programming for Scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whenever we execute a function, we expect a result, but what happens between
    the request and the outputted result?
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you’re in town, and you have a bunch of errands to run, but you’re also
    hungry and need to eat lunch. You walk into a pizza shop, situated within a shopping
    mall. The shop cooks fresh pizza to order. It takes around fifteen minutes for
    the pizza to be prepped and then cooked. You can wait around in the shop until
    the pizza is done, but you need to go to the bank, which has a branch across the
    road. The pizza store owner is a friend of yours and agrees to text you when your
    pizza is ready to pick up. You have an opportunity to get something else done
    while your pizza is cooking; that’s a much better use of your time.
  prefs: []
  type: TYPE_NORMAL
- en: This is a simple analogy for an **asynchronous** function. The act of walking
    into the pizza shop is the function starting, and you running over to the bank
    while it is cooking is the function running. When your phone beeps with a text
    to say the pizza is ready, that is the function returning its output.
  prefs: []
  type: TYPE_NORMAL
- en: This example demonstrates the benefits of an asynchronous function, which allows
    for the execution of other tasks while waiting for a specific operation to complete.
    Cooking your pizza doesn’t block your overall goal, which is to run your errands.
  prefs: []
  type: TYPE_NORMAL
- en: If the pizza shop owner was a lot less friendly and demanded that you wait in
    the shop until the pizza was done, that would be an example of a **synchronous**
    operation, the opposite of asynchronous. Synchronous operations block the progression
    of your overall goal (running your errands) until the current operation is complete.
  prefs: []
  type: TYPE_NORMAL
- en: Where possible, we want to reap the benefits of asynchronous programming for
    operations that are executing as part of minimal APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and implementing asynchronous patterns in a minimal API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common pitfalls and challenges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The code for this chapter is available in the GitHub repository at: [https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9](https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9)
    . Visual Studio with the .NET 9 SDK is required to run the code.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and implementing asynchronous patterns in a minimal API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The opening pizza analogy is hopefully a good, high-level illustration of the
    difference between asynchronous and synchronous programming. Asynchronous programming
    is significant in minimal APIs because it provides a lot of flexibility for managing
    the conversations between client and server. It is particularly beneficial to
    long-running operations, where the overall performance of a request would be compromised
    by operations running in a linear fashion, with each operation blocking the other.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous programming also provides scalability benefits, allowing APIs to
    cope with high demand. This is achieved by ensuring that threads are not blocked.
    Operations in an asynchronous endpoint can register callbacks to ensure that the
    execution thread can continue running other tasks until that callback is resolved.
    This brings with it other resource benefits such as better management of the thread
    pool, lower CPU consumption, and decreased memory footprint. All of these things
    are crucial for minimal APIs, which are designed to be as straightforward and
    efficient as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Task-based asynchronous pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '.NET has seen the use of several different asynchronous programming patterns
    on its journey from .NET Framework to .NET core. In the .NET Framework days, the
    **Task-based Asynchronous Pattern** ( **TAP** ) was the preferred method for managing
    asynchronous execution. Introduced in the Task Parallel Library in .NET 4, it
    uses **Task** and **Task<T>** to represent asynchronous operations and to provide
    a way to handle their results or exceptions. The explicit implementation of the
    TAP is now obsolete in .NET 9, but the example is effective at demonstrating asynchronous
    operations. If we were to use it in a minimal API, it would be situated in the
    body of an endpoint, with the establishment of a **Task<T>** , which would execute
    a long-running task. We would then start the **Task** while at the same time telling
    it what logic it should call back to once it has finished. We can see this in
    this example, which runs a task to grab data from another API and then continues
    by checking the result before returning a response to the client:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: While this code can demonstrate asynchronous execution in an API endpoint, it
    could be a lot more readable. Fortunately, back in .NET Framework 4.5 and .NET
    5, the **async/await** keywords were introduced.
  prefs: []
  type: TYPE_NORMAL
- en: TAP with async/await
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **async/await** keywords made asynchronous programming more accessible by
    allowing us to write asynchronous code that resembles synchronous code. This went
    a long way toward making asynchronous code more readable and therefore understandable.
    In a minimal API, where we’re aiming to be economical with the real estate in
    our IDE, this is very valuable.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what the endpoint from the last example looks like when using **async/await**
    instead of using the original Task-based syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: It’s hopefully clear to see that the section of code in the second example,
    which starts the asynchronous call to the other API, is much cleaner and shorter
    than its counterpart in the first example.
  prefs: []
  type: TYPE_NORMAL
- en: In minimal APIs, we don’t need to do much to make an API endpoint compatible
    with **async/await** . Notice how, in the second example that uses **async/await**
    , the endpoint has the **async** keyword preceding the lambda expression defined
    after the route. This, like in regular .NET functions and methods, allows for
    the use of the **await** keyword in the body of the function. Without the **async**
    keyword, **await** is not supported.
  prefs: []
  type: TYPE_NORMAL
- en: The first example did not use the **async** keyword, but it was ultimately still
    able to create an asynchronous operation. This may look like a contradiction until
    we consider that as well as **async** , **await** is notably absent from the first
    example. So, it’s important to remember that the **async** keyword is not a pre-requisite
    for any asynchronous code in a minimal API, but it allows for the use of **await**
    , and therefore a simpler implementation of asynchronous operations that resemble
    synchronous ones.
  prefs: []
  type: TYPE_NORMAL
- en: By using **async/await** , we can implement the TAP in a streamlined fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous processing pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is another well defined pattern that achieved asynchronous execution known
    as the **Asynchronous** **Processing Pattern** .
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes referred to as **deferred processing** , this pattern can be somewhat
    complex compared to the TAP, but the principle is the same. The flow of control
    is returned to the consumer of the function while other long-running operations
    are completed. However, in this pattern, the consumer of the function is not the
    API application’s main thread, but the client making the request to the API endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 1* *.1* demonstrates execution via deferred processing:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1: Deferred processing spanning two client requests](img/B20968_11_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Deferred processing spanning two client requests'
  prefs: []
  type: TYPE_NORMAL
- en: We can turn the current example into a version that uses deferred processing
    relatively easily. First, we would need to make an endpoint that starts execution
    of the long-running task, but then immediately acknowledges the caller by returning
    a status code. However, a status code on its own will not suffice. We must return
    a callback URL for the client. This URL will route to another endpoint, which
    will check to see whether our long-running operation has completed. If it has,
    it will retrieve the relevant data before returning it to the client as a response.
    If the operation has not been completed, it will still respond to the client,
    indicating that the operation is still running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by creating the first endpoint, which will acknowledge the client’s
    request for the long-running operation to start. We’ll also create a dictionary
    to hold responses waiting to be collected by clients via callbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The dictionary has been added as a **ConcurrentDictionary** because it is thread-safe,
    meaning that .NET will automatically manage scenarios where it is accessed by
    multiple concurrent threads. An example would be if there are multiple requests
    to the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, inside the body of the **POST** endpoint, we generate a **GUID** to represent
    the pending request, as well as a string version of the **GUID** that can be referenced
    in the callback response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'All that remains now is to start the long-running task, before returning the
    **GUID** to the client so that they can use it in the callback request to see
    whether their result is ready for retrieval:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now that the client has a unique identifier in the form of the returned **GUID**
    , it can be used in a second request to get the result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a **GET** endpoint for this purpose. The endpoint will be a lot
    simpler than the first. It will simply attempt to find an entry in the dictionary
    that has a key matching the passed-in **GUID** parameter. If the dictionary contains
    the requested key-value pair, the original long-running operation is completed.
    Otherwise, it must still be running or was never initiated. The **GET** endpoint
    must handle both of these scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Go ahead and try calling these two endpoints, one after the other. If you request
    the second endpoint within less than ten seconds of the first one, you should
    get a **404 NOTFOUND** result with the **Result not found or not yet completed**
    message and then get the expected **GUID** result after ten seconds. This will
    have demonstrated deferred processing in a simple way.
  prefs: []
  type: TYPE_NORMAL
- en: To expand your practice of this execution pattern, you should attempt more elaborate
    use cases, such as running complicated mathematical calculations or making database
    or network requests in the background.
  prefs: []
  type: TYPE_NORMAL
- en: Common pitfalls and challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Asynchronous programming brings with it a series of pitfalls and challenges.
    Let’s go through some examples of things that you should be vigilant about when
    writing asynchronous code in a minimal API:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deadlocks** : A deadlock occurs when concurrent operations cannot complete
    due to blocking. In a minimal API, this can be seen when the main thread is blocked.
    In the following example, the use of **Task.Run** can cause a deadlock because
    it blocks the main thread:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The way to avoid deadlocks would simply be to use **await** when running the
    task, to ensure that the call does not block the main thread:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Resource Management** : Where possible, minimal API code that manages resources
    such as database connections or file handles should be disposed of appropriately
    in an asynchronous context.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Any resource that implements **IDisposable** can make use of a **using** statement
    to automatically dispose of the resource when no longer in use. However, when
    writing asynchronous code for resources, try to use **IDisposableAsync** where
    available. This means you use **await** in conjunction with a **using** statement:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Race conditions** : A race condition is the result of multiple threads accessing
    and modifying shared data concurrently. For example, if you have a static field
    in your minimal API, and an endpoint that accesses it for modification, you must
    remember that requests can execute concurrently, with multiple clients potentially
    running the endpoint logic at the same time. This would cause the static field
    in your API to become inconsistent and therefore inaccurate. You must ensure that
    each operation against shared data is *atomic* – a single operation must complete
    before another occurs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, multiple requests to **IncrementCounter** can lead to an inconsistent
    state of **_counter** .
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The solution to this problem is to use a synchronization mechanism to manage
    the state of a shared value. The most common synchronization mechanism is **lock**
    , which uses an **object** to block execution against a particular value while
    a thread is accessing it. This means *locking* it from access by other threads,
    forcing them to wait their turn:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This example shows the establishment and execution of a **lock** to ensure that
    **_counter** is updated by one thread at a time, eliminating the possibility of
    race conditions occurring within the API.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Asynchronous programming can add a new layer of complexity to any minimal API
    project, but we’ve demonstrated in this chapter that with careful attention, it
    can be a powerful tool in optimizing API efficiency. Let’s recap the areas covered
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We opened this chapter with the pizza store analogy. We introduced asynchronous
    programming by likening it to a takeout food order that you don’t simply wait
    for, but instead continue your ongoing tasks until the pizza is ready for you
    to collect.
  prefs: []
  type: TYPE_NORMAL
- en: We then laid the foundations for understanding how asynchronous code can benefit
    a minimal API, with its optimal use of hardware resources and scope for application
    scalability.
  prefs: []
  type: TYPE_NORMAL
- en: We explored some common asynchronous programming patterns, namely the TAP and
    deferred execution patterns, with examples of how the use of **async/await** can
    make asynchronous code more readable by making it look more like synchronous code.
    We explored how Deferred Execution can make an API asynchronous at the client
    level, allowing the client to receive an acknowledgment that their request has
    been received, along with a unique identifier for them to reference, stretching
    the overall end-to-end execution across multiple API requests.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we addressed the common challenges asynchronous programming presents,
    particularly in minimal APIs, with three common examples. The first was deadlocks,
    in which execution can no longer be continued on a global scale due to contention
    between multiple threads or operations. Next was poor resource management, in
    which the code does not account for the asynchronous context when disposing of
    connections to external resources. Lastly, we looked at race conditions, the classic
    example of multiple operations competing to update the state of a shared value
    or resource, causing inconsistent behavior and the creation of inaccurate data.
  prefs: []
  type: TYPE_NORMAL
- en: No software developer can easily escape the need to manage asynchronous execution,
    especially in a .NET minimal API. Thus, practicing vigilance, combined with good
    testing and the profiling techniques learned earlier in the book, can go a long
    way to making the experience as painless as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will explore a critical method for optimizing the performance of any
    minimal API – caching.
  prefs: []
  type: TYPE_NORMAL
