- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices in Practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is dedicated to the practical implementation of each microservice
    that exists after the design of the general application architecture and after
    that all interfaces of all Microservices have been defined. The interaction between,
    and orchestration of, microservices will be detailed in the remaining chapters
    of this book.
  prefs: []
  type: TYPE_NORMAL
- en: All concepts will be illustrated with the example of a worker microservice taken
    from the book’s case study application that we introduced in the *Car-sharing
    example* subsection of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying
    Microservices Applications*.
  prefs: []
  type: TYPE_NORMAL
- en: After a short description of the example worker microservice specifications,
    we will describe how to design microservices’ input and output communication subsystems,
    and how to organize the microservice request-serving logic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will discuss the details of how to implement a microservice with
    the Onion Architecture project templates introduced in the *A solution template
    based on the Onion Architecture* section of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, this chapter covers the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The route-planning microservice of the car-sharing application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice basic design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring resilient communication with Polly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From abstraction to implementation details
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter requires the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2022, at least the free *Community* edition.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A SQL instance that accepts TCP/IP requests and user/password authentication
    since it must communicate with clients running inside Docker containers. Please
    note that the SQL instance that comes with the Visual Studio installation doesn’t
    support TCP/IP, so you need to either install SQL Express or use a cloud instance.
    For local installation, both the installer and instructions are available here:
    [https://www.microsoft.com/en-US/download/details.aspx?id=104781](https://www.microsoft.com/en-US/download/details.aspx?id=104781).
    You may also run the SQL Server Developer edition as a Docker image with the following
    code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The username corresponding to the chosen password will be `sa`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Docker Desktop for Windows ([https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Docker Desktop, in turn, requires **Windows Subsystem for Linux (WSL)**, which
    can be installed by following these steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Type `powershell` in the Windows 10/11 search bar.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When **Windows PowerShell** is proposed as a search result, click on **Run as
    an administrator**.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Windows PowerShell administrative console that appears, run the `wsl
    --install` command.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You can find the sample code for this chapter at [https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp).
  prefs: []
  type: TYPE_NORMAL
- en: The route-planning microservice of the car-sharing application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we describe our example microservice, how to handle security,
    and how to prepare the solution for its implementation into three separate subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Microservice specifications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The route-planning microservice stores and matches pending requests to move
    from one town to another with existing routes that are still open to other participants.
  prefs: []
  type: TYPE_NORMAL
- en: When an opened route of a car owner is created, it is matched with requests
    whose start and end towns are close to the car owner’s route and whose date constraints
    are compatible. If matches are found, a proposal to modify the route to include
    them is created and sent to other interested microservices. A symmetric operation
    is also done when a new request is inserted.
  prefs: []
  type: TYPE_NORMAL
- en: When a proposal to extend the route is accepted, the original route is extended.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the initial match attempt, both requests and routes are stored for possible
    future matches. Requests and routes are removed or modified under the following
    circumstances:'
  prefs: []
  type: TYPE_NORMAL
- en: A route is removed from possible matches when it is closed to new participants
    or aborted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A route is extended when it is merged with some requests. No new matches are
    attempted as a consequence of this operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A request is removed from possible matches when it is merged with a route.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A request becomes available again when the route it was merged with is aborted.
    After this operation, new matches are attempted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both requests and routes are deleted *N* days after their maximum travel day
    expires, where *N* is a parameter to be provided.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Matches between routes and requests are done when the following circumstances
    are met:'
  prefs: []
  type: TYPE_NORMAL
- en: The route date falls between the minimum and maximum dates associated with the
    request.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Both the request start and end towns are close enough to the route.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will implement most microservice-to-microservice communication with the publisher/subscriber
    pattern in order to maximize microservice decoupling. This choice will also minimize
    the overall communication-related code, since message handlers and their client
    libraries take care of most of the asynchronous communication problems. Please
    refer to the *Event-based communications* subsection of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038),
    *Demystifying Microservices Applications*, for more details on event-based communication.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, in order to maximize application portability, we will use the **RabbitMQ**
    message broker, which is not tied to a specific platform or cloud but can be installed
    in any Kubernetes-based network with an adjustable number of replicas. **RabbitMQ**
    will be described in a dedicated subsection of the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Since the car-sharing application doesn’t exchange heavy messages, we may avoid
    non-standard binary serializations such as **gRPC Protobuf** and opt for a simple
    **JSON** message serialization.
  prefs: []
  type: TYPE_NORMAL
- en: Most web servers and communication libraries can be configured to automatically
    compress JSON data. Web servers negotiate compression with the client.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, since our worker microservice in-out communication is based on message
    brokers and not on the usual **HTTP** and **gRPC** ASP.NET Core protocols, we
    might consider the ad hoc **Worker service** project template based on the so-called
    **hosted services** (**hosted services** will be discussed in the next section).
    However, microservices best practices prescribe that each microservice should
    expose an HTTP endpoint to verify its health status, so we will adopt a minimal
    API-based ASP.NET Core Web APIproject since it also supports the hosted services
    that we need for receiving message-broker-based communication.
  prefs: []
  type: TYPE_NORMAL
- en: Having clarified the microservice responsibilities, we can move on to security
    considerations.
  prefs: []
  type: TYPE_NORMAL
- en: Handling security and authorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The authorization of requests coming from actual users is handled with the usual
    ASP.NET Web API techniques, that is, with web tokens (typically a **JSON bearer
    token**) and `Authorize` attributes. Web tokens are provided by the login and
    token-renew endpoints of a specialized microservice that acts as the authorization
    server.
  prefs: []
  type: TYPE_NORMAL
- en: Requests coming from other services instead are usually secured with mTLS, that
    is, with certificate-based client authentication. Client certificates are handled
    by the lower-level TCP/IP protocol together with the server certificate used for
    encrypting the HTTPS communication. Then, the information extracted by the client
    certificate is passed to the ASP.NET Core authentication middleware to create
    a `ClaimsPrincipal` (the usual ASP.NET Core **User** object). When the application
    runs within an orchestrator, it is also possible to use orchestrator-specific
    authorization, and when the application runs in the cloud, it is possible to use
    cloud-specific authorization.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, if both communicating microservices are exposed in a private network,
    or better, in a private network handled by a microservices orchestrator, we may
    replace user authentication with firewall rules and/or with other communication-securing
    facilities offered by the orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: We will analyze the Kubernetes orchestrator in [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205),
    *Practical Microservices Organization with Kubernetes*, and its communication-securing
    facilities in [*Chapter 10*](Chapter_10.xhtml#_idTextAnchor297), *Security and
    Observability for Serverless and Microservices Applications*. Even in a private
    network, it is recommended to encrypt internal communication using mTLS or other
    encryption methods to mitigate insider threats and network attacks, but for the
    sake of simplicity in this book, we will only secure communication with the outside
    world.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if we adequately organize our private network, we need to secure
    just communication with the outside world, that is, communication with frontend
    microservices. However, as discussed in the *Interfacing the external world* subsection
    of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying Microservices
    Applications*, microservices-based applications use API gateways to communicate
    with the external world. In the simplest case, the interface with the external
    world is just a load-balanced web server that performs HTTPS termination, that
    is, that receives HTTPS communications from the external world. While some architectures
    terminate HTTPS at the API gateway and use HTTP internally, it is recommended
    to maintain encryption within the private network using mTLS or re-encryption
    to ensure security within the microservices ecosystem. This way, we may use just
    a single HTTPS certificate for the whole application, thus avoiding the whole
    certificate issuing and renewal procedure for all microservices that compose the
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Summing up, if we use any kind of HTTPS-termination interface to access the
    microservice application, we may avoid using HTTPS communication in all microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are ready to prepare the Visual Studio solution that will host the route-planning
    microservice!
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Visual Studio solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since we decided to implement the outermost layer of our worker microservice
    with an ASP.NET Core Web API project, let’s create a `CarSharing` Visual Studio
    solution containing an ASP.NET Core Web APIproject called `RoutesPlanning`. The
    **ASP.NET Core Web API** project can be easily found by selecting **C#**, **All
    platforms**, and **Web API** from the dropdowns of the Visual Studio project selection
    window, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31916_07_1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: Project selection'
  prefs: []
  type: TYPE_NORMAL
- en: As discussed previously, we may avoid HTTPS communication, and worker microservices
    do not need authentication. However, we need Docker support since microservices
    are usually containerized.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we don’t need controllers but just a minimal API since we need to
    expose just a couple of trivial endpoints for health checks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2: Project settings](img/B31916_07_2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: Project settings'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the Onion Architecture, so we need to also add a project for the
    application services and domain layer. Therefore, let’s add two more **Class Library**
    projects, called `RoutesPlanningApplicationServices` and `RoutesPlanningDomainLayer`.
    We will adapt the Onion Architecture template introduced in the *A solution template
    based on the Onion Architecture* section of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s open the `OnionArchitectureComplete` project template, which you can find
    in the `ch03` folder of the book’s GitHub repository. In the `RoutesPlanningDomainLayer`
    project, delete the **Class1.cs** file, select the three folders in the `DomainLayer`
    project of the `ch03` project template, copy them, and paste them into the `RoutesPlanningDomainLayer`
    project. If you have the latest Visual Studio 2022 version installed, you should
    be able to perform the copy operation from within Visual Studio Solution Explorer.
    Also, add a reference to the `Microsoft.Extensions.DependencyInjection.Abstractions`
    NuGet package to the `RoutesPlanningDomainLayer` project.
  prefs: []
  type: TYPE_NORMAL
- en: Then, perform the analogous operations on the `RoutesPlanningApplicationServices`
    and `ApplicationServices` projects.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have all the Onion Architecture files in place, you need to add
    just a reference to `RoutesPlanningDomainLayer` in `RoutesPlanningApplicationServices`
    and a reference to `RoutesPlanningApplicationServices` in `RoutesPlanning`.
  prefs: []
  type: TYPE_NORMAL
- en: After the last operation, your solution should compile, but we have not finished
    preparing our solution yet. We need to also add an **Entity Framework Core**-based
    library in order to provide an implementation driver for our domain layer.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s add a new class library project and call it `RoutesPlanningDBDriver`.
    Add references to the `Microsoft.EntityFrameworkCore.SqlServer` and `Microsoft.EntityFrameworkCore.Tools`
    Nuget packages, and to the `RoutesPlanningDomainLayer` project.
  prefs: []
  type: TYPE_NORMAL
- en: After that, delete the **Class1.cs** file and replace it with all code files
    and folders from the `DBDriver` project of the `ch03` project template.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`RoutesPlanning` needs a reference to `RoutesPlanningDBDriver` because the
    outermost layer of an Onion Architecture must reference all implementation-specific
    drivers. `AddApplicationServices` adds all queries, commands, and event handlers
    to the dependency injection engine, while `AddDbDtiver` adds all repository implementations
    and the `IUnitOfWork` implementation to the dependency injection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For more information on the Onion Architecture project template that we used
    to prepare our solution, please refer to the *A solution template based on the
    Onion Architecture* section of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, our solution is finally ready! We can start designing our worker microservice!
  prefs: []
  type: TYPE_NORMAL
- en: Microservice basic design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will define all the main microservice abstractions, that
    is, the overall communication strategy, all Onion Architecture commands and events,
    and the top-level loops of the required hosted services. We will start with a
    description of the chosen message broker: **RabbitMQ**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The message broker: RabbitMQ'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Natively, RabbitMQ supports the **AMQP** asynchronous message protocol, which
    is one of the most used asynchronous protocols, the other being **MQTT**, which
    has a specific syntax for the publisher/subscriber pattern. Support for **MQTT**
    can be added with a plugin, but RabbitMQ has facilities for easily implementing
    a publisher/subscriber pattern on top of **AMQP**. Moreover, RabbitMQ offers several
    tools to support scalability, disaster recovery, and redundancy, so it fulfills
    all requirements to be a first-class actor in cloud and microservices environments.
    More specifically, by defining a RabbitMQ cluster, we may achieve both load balancing
    and data replication which is required in most SQL and NoSQL databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will just describe RabbitMQ’s basic operation, while the
    installation and usage of RabbitMQ clusters in Kubernetes will be discussed in
    [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205), *Practical Microservices Organization
    with Kubernetes*. You can find more details in the tutorials and documentation
    on the RabbitMQ official website: [https://www.rabbitmq.com/](https://www.rabbitmq.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ messages must be prepared in binary format, since RabbitMQ messages
    must be just an array of bytes. However, we will use the **EasyNetQ** client,
    which takes care of object serialization and of most of the client-server wiring
    and error recovery. **EasyNetQ** is a NuGet package built on top of RabbitMQ’s
    low-level **RabbitMQ.Client** NuGet client, which makes the usage of RabbitMQ
    easy while reducing the communication-code overhead and enhancing its modularity
    and modifiability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once sent to RabbitMQ, messages are placed in **queues**. More specifically,
    they are placed in one or more **queues** by passing through other entities, called
    **exchanges**. The exchanges route the messages to **queues** using a routing
    strategy that depends on the **exchange** type. Exchanges are an **AMQP**-specific
    concept, and they are the RabbitMQ way to configure complex communication protocols
    like the publishing/subscriber protocol, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3: RabbitMQ exchanges](img/B31916_07_3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: RabbitMQ exchanges'
  prefs: []
  type: TYPE_NORMAL
- en: 'By adequately defining the exchange routing strategy, we can implement several
    patterns. More specifically, the following apply:'
  prefs: []
  type: TYPE_NORMAL
- en: When we use a **default exchange**, the message is sent to a single queue and
    we can implement asynchronous direct calls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we use a **fanout exchange**, the exchange will send the messages to all
    queues that subscribe to that exchange. This way, we can implement the publisher/subscriber
    pattern.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is also a **topic exchange**, which enhances the publisher/subscriber
    pattern by enabling the matching of named event subclasses called topics. Matching
    between receivers and topics also supports wildcard chars. We will describe its
    practical usage with enterprise microservices in the *Ensuring that messages are
    processed in the proper order* subsection.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever several receivers are attached to the same queue, messages are equally
    distributed among them according to a round-robin pattern. This is the case of
    *N* identical replicas of the same microservice. Therefore, replicas are automatically
    load-balanced by RabbitMQ.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, **EasyNetQ** directly exposes the publish/subscribe protocol (possibly
    enriched with topics) and the direct call protocol, together with a request/response
    asynchronous RPC protocol, taking care of creating and connecting all needed queues
    and exchanges. Details on how to use **EasyNetQ** will be provided when describing
    the code of our route-planning microservice.
  prefs: []
  type: TYPE_NORMAL
- en: The easiest way to install RabbitMQ is by using its Docker image. We will adopt
    this option since all our microservices will also be containerized, and since
    in the final Kubernetes version of the overall application, we will use containerized
    RabbitMQ clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can just run the following command in a Linux shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we provided the `-it` flags, after the image is downloaded and the container
    is created and started, the Linux shell remains blocked in the container filesystem.
    Moreover, since we also added the `–-rm` option, the container is destroyed as
    soon as it is stopped with the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In order to verify that RabbitMQ is working properly, please navigate to [http://localhost:15672](http://localhost:15672).
    The RabbitMQ management console should appear. You can log in with the startup
    credentials, which are `guest`for both the username and password.
  prefs: []
  type: TYPE_NORMAL
- en: You don’t need to leave the container running; you can stop it and re-execute
    the `run` command when you need RabbitMQ to test the microservice code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The disk space needed by RabbitMQ is mounted as a Docker volume with the following
    volume statement directly inserted in the `Dockerfile` image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This means that the disk content is reset when the container is destroyed and
    run again. Therefore, if you want to keep the disk content, avoid running the
    container with the `–-rm` option, so it will not be destroyed when it is stopped.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you need customized credentials, please add the following environment variables
    to the `run` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This is necessary when RabbitMQ is accessed outside of `localhost`, because
    in this case, the default username and password are not accepted for security
    reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can move on to designing the input and output messages of our worker
    microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Input communication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since classes that represent intra-microservices messages must be known to both
    clients and servers, the best option is defining them during the initial microservices
    external interfaces design and placing them in one or more shared libraries. Since
    our project contains a reasonably small number of microservices, we may assume
    that all messages are visible to all microservices, so we can use a single shared
    library.
  prefs: []
  type: TYPE_NORMAL
- en: However, in more complex scenarios containing hundreds or thousands of microservices,
    their organization must be hierarchical, so we will have level 0 messages, known
    to all microservices; level 1 messages, known just within level 1 groups of microservices,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s add a new **Class Library** project called `SharedMessages` to our solution,
    and we’ll select **standard 2.1** for its version. Then, let’s add a reference
    to this new project to the `RoutesPlanningApplicationServices` project. We will
    place all application messages here.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the specifications of the route-planning microservice, we have just four
    messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**New request**: It will contain a unique request identifier, an interval of
    acceptable travel dates, and two unique identifiers for the start and arrival
    towns, their display names, and their latitude and longitude. Moreover, it will
    contain a unique identifier representing the user that issued the request and
    their display name.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**New route**: It will contain a unique route identifier, a travel date, and
    two unique identifiers representing the start and arrival towns, their display
    names, and their latitude and longitude. Moreover, it will contain a unique identifier
    representing the car owner that issued the route proposal and their display name.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Route closed/aborted**: It will contain just the unique route identifier
    and a flag specifying whether the route was successfully closed or aborted.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Route extension**: It informs that the car owner accepted extending the route
    with the start and ending towns of other requests. It contains the same information
    contained in the new route message as well as new request messages.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It also contains a flag that specifies whether, after the extension, the route
    has been closed to other participants.
  prefs: []
  type: TYPE_NORMAL
- en: The message content might appear redundant for the route-planning microservice.
    For instance, most of the information contained in the route extension message
    is already known to the route-planning microservice. As a matter of fact, the
    route-planning microservice needs just the unique identifiers of the request and
    route to join.
  prefs: []
  type: TYPE_NORMAL
- en: However, messages sent with the publisher/subscriber pattern are used by several
    potentially unknown subscribers, so they can’t assume specific a priori knowledge
    of the subscribers. For instance, the route extension message will also be subscribed
    by the microservice that handles all requests that don’t contain information about
    all existing route proposals, so all information needed on the merged route must
    be received through this message.
  prefs: []
  type: TYPE_NORMAL
- en: On the contrary, the route closed/aborted message doesn’t need to convey the
    whole route information, since any service interested in the event must already
    know of this route and must already have all the data it needs about it. It might
    lack this data if it has never interacted with this route, but in this case, the
    event represented by the message can’t modify its state and must simply be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'An important question we must always ask about all microservices input is:
    what happens if the messages arrive in the wrong order, that is, in a different
    order than they were sent? If the message order matters, we either ensure that
    all messages arrive and are processed in the right order or we reorder messages
    with the technique explained in the *Efficacious handling of asynchronous communication*
    subsection of [*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying Microservices
    Applications*. Unfortunately, reordering input messages is not enough; we must
    also process them in the right order.'
  prefs: []
  type: TYPE_NORMAL
- en: This is not a trivial task if several replicas of the same microservice process
    these input messages concurrently. Luckily, no application needs a fixed ordering
    for all input messages. But some *related messages*, for instance, all messages
    that contain the same route, must be processed in the right order. Therefore,
    we can avoid *just* concurrent processing of *related messages* by passing all
    related messages to the same replica. We will analyze techniques for achieving
    a similar load-balancing strategy of all replicas in the *Ensuring that messages
    are processed in the proper order* section.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, the order in which new route offers and route requests arrive is
    not an issue, since we can correctly process out-of-order messages with simple
    tricks. We just need to add an update version number to detect past updates. Update
    version numbers must be unique and must correspond to the real order in which
    updates were applied to a given entity. When the entity is created, it starts
    with version 0, and then this number is incremented at each new update.
  prefs: []
  type: TYPE_NORMAL
- en: As a general rule, if all modification and creation messages contain the entire
    entity data, and if all deletes are logical, that is, entities are just marked
    as deleted, then messages don’t need to be ordered.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, we can recognize and apply an incoming modification only if it is more
    recent than the one already applied. Moreover, we can always verify whether the
    entity mentioned in a modification message has already been deleted and discard
    the modification. Finally, if an entity mentioned in a modification has not already
    been created, we can always create it with the data contained in the modification
    message, since each modification contains the entire entity data.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, the order of the route extension messages doesn’t matter, because
    request merged to a route simply sum up and it is enough to select the more recent
    list of towns of the one stored in the route and the one contained in the message.
  prefs: []
  type: TYPE_NORMAL
- en: Inversions of route extensions and route closed/aborted messages do not cause
    problems, too, since it is enough to ignore extensions of aborted routes, and
    to merge previous requests that arrived after the closure.
  prefs: []
  type: TYPE_NORMAL
- en: Inversions of route creations and extensions can never take place, since only
    successfully created routes can cause request-route matches that can subsequently
    cause route extensions.
  prefs: []
  type: TYPE_NORMAL
- en: Deleted routes do not cause problems since both route aborted and closed messages
    are de facto logical deletes. We can delete them after the travel day has expired
    by *N* days, since at that point, previous delayed messages can’t arrive (messages
    can be delayed by some hours or even a day in the case of severe failures). This
    can be done with cron jobs.
  prefs: []
  type: TYPE_NORMAL
- en: Possible duplication of messages due to timeouts and resends also do not cause
    problems since they can always be recognized and ignored. As an exercise, you
    can analyze all possibilities in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'All required messages can be easily defined in terms of some basic types that
    we will place in a `BasicTypes` folder of the `SharedMessages` project. They are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Moreover, since all messages must contain an update time, we may let all of
    them inherit from the following class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Let’s place this class in the `BasicTypes` folder, too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, all messages can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**New request**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**New route**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Route closed/aborted**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Route extension**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Place them in a `SharedMessages` project folder called `RouteNegotiation`.
  prefs: []
  type: TYPE_NORMAL
- en: We have just finished with the microservice input design! Let’s move on to the
    output.
  prefs: []
  type: TYPE_NORMAL
- en: Output communication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The output of the route-planning microservice consists of proposals to augment
    routes with matching requests. These proposals must be accepted by the users that
    own the routes. A single route extension message contains the unique identifier
    of the route and all its newly discovered matching requests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let’s place this class in the `RouteNegotiation` folder of the `SharedMessages`
    project.
  prefs: []
  type: TYPE_NORMAL
- en: Please notice that the timestamp associated with this message is the more recent
    timestamp associated with the route that this worker microservice received. In
    fact, this microservice doesn’t perform actual route updates, but just computes
    update proposals, which might be turned intoactual updates by another microservice.
  prefs: []
  type: TYPE_NORMAL
- en: As a rule of thumb, all updates to an entity must be performed on a single database
    replica. This way, computing entity versions becomes a feasible task that requires
    just a simple database transaction. Otherwise, each update should be coordinated
    among *N* different microservices with a complex distributed transaction. Therefore,
    if several microservices have different views of the same conceptual entity in
    their databases, each of them can change the entity private data it uses without
    needing to version them. But there should be a single microservice that is in
    charge of updating all shared properties of the entity, versioning them, and sending
    them to all interested microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, sometimes distributed transactions are unavoidable, but still,
    in these cases, a single microservice replica proposes a new version number that
    is accepted by all microservices involved in the transaction if the transaction
    succeeds.
  prefs: []
  type: TYPE_NORMAL
- en: Output messages can be placed in an internal queue implemented with permanent
    storage immediately after their creation, as explained in the *Efficacious handling
    of asynchronous communication* section of [*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038),
    *Demystifying Microservices Applications*. However, if we use a broker, that strategy
    needs to be modified a little bit. There, we applied an exponential retry strategy,
    by retrying the failed messages after an exponentially increasing time, while
    continuing to send other messages from the internal queue. When messages are not
    mediated by a message broker, this strategy makes sense, since the failure is
    connected either to the destination or to some component in the path between the
    source and destination. So, if the next message has a different destination, it
    would probably succeed.
  prefs: []
  type: TYPE_NORMAL
- en: If we use a message broker, the failure depends on the message broker itself
    since the confirmation simply states that the message broker successfully received
    the message, not that the message was received and confirmed by the destination.
    Therefore, immediately attempting a new message transmission would probably result
    in another failure.
  prefs: []
  type: TYPE_NORMAL
- en: We may conclude that when communication is mediated by a message broker, we
    don’t need to delay the single faulty message; instead, we must stop sending messages
    to the message broker applying both exponential retry and circuit break strategies.
    Moreover, since keeping too many threads waiting for confirmations might congest
    the system, we must also apply a Bulkhead Isolation strategy to limit the number
    of pending tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you might ask: why do we need an internal queue if we already
    have the message broker external queue? There are two reasons; the first one,
    in particular, is quite compelling:'
  prefs: []
  type: TYPE_NORMAL
- en: The internal queue is implemented with a database table, so it is populated
    in the same database transaction as the database update that triggered the output
    event. Therefore, if something goes wrong, the whole transaction is aborted, thus
    giving the possibility to retry it at a later time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The performance cost for achieving the same result directly with the message
    broker queue is higher: we should keep the database transaction open until we
    receive a confirmation, an error, or a timeout from the message transmission to
    the message broker. This time becomes several orders of magnitude higher if we
    use exponential retry.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the message is in the internal queue, in case of failures, we don’t need
    to undo the database update but we need simply to retry the message transmission
    at a later time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Due to the different ways databases and message brokers are implemented, and
    due to the fact that the database is shared just by the microservice replicas,
    the confirmation of the successful execution of the whole database transaction
    (required update plus registration of the output message in the internal queue)
    is faster than the message broker confirmation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we have clarified how to handle both input and output messages, in
    general and for our route-planning microservice, we can discuss how to recover
    and maintain the proper message-processing order.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring that messages are processed in the proper order
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed in the previous subsections, our route-planning microservice doesn’t
    need to enforce the correct message-processing order. However, there are cases
    where processing all messages in the right order is unavoidable, so in this subsection,
    we will discuss how they are usually handled.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth pointing out that strategies for enforcing the right message-processing
    order have a non-negligible impact on performance and scalability, so any trick
    to avoid their usage is welcome.
  prefs: []
  type: TYPE_NORMAL
- en: 'Usually, order constraints must be enforced just within the same group of related
    messages, so it is enough to ensure the following:'
  prefs: []
  type: TYPE_NORMAL
- en: All messages belonging to the same group of related messages are processed by
    the same microservice replica, so concurrence between replicas can’t shuffle the
    message-processing order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each replica processes a message only after all previous messages have been
    successfully processed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Proper operation of the preceding technique requires that each message contains
    its sequence number in its group.
  prefs: []
  type: TYPE_NORMAL
- en: Often, groups coincide with database entities, or better, with database aggregates.
    That is, two messages belong to the same group if they represent different operations
    performed on the same entity. Thus, in the case of our route-planning service,
    we might have a group for each request and for each route.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now suppose that that there are *N* microservice replicas, indexed by the integers
    from 1 to *N*. We can define a hash function that, given a group identifier, returns
    a number between 1 and *N*. This way, if we route each message to the replica
    indexed by the result of the hash function applied to the group of the message,
    all messages in the same group will be processed by the same replica. The following
    figure exemplifies the message-routing strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4: Message sharding](img/B31916_07_4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: Message sharding'
  prefs: []
  type: TYPE_NORMAL
- en: This technique is called **sharding**, and if the hash function is fair, each
    replica will receive the same *average* load.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, if we have no order constraints, we achieve exact load-balancing with
    a round-robin strategy, while with order constraints, we can just achieve *average*
    load-balancing with sharding. This means that probabilistic balancing fluctuations
    will for sure cause temporary congestion.
  prefs: []
  type: TYPE_NORMAL
- en: Sharding will also cause a loss of flexibility in scaling the number of replicas.
    In fact, changing the number of replicas changes both the hash function and the
    group of messages received by each replica. For these reasons, scaling operations
    will have a higher cost and consequently can be performed less frequently. In
    practice, most orchestrators automatically scale non-indexed replicas according
    to customizable criteria, but don’t offer the same service for replicas that need
    to be indexed. We will analyze in more detail the difference between these different
    sets of replicas and automating scaling in [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205),
    *Practical Microservices Organization with Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Sharding can be implemented with a single-replica microservice that receives
    all messages from the message broker and routes them to the appropriate replicas
    by sending them to a replica-specific message broker queue. This technique is
    more complex and requires more coding, but it is more flexible. In fact, for instance,
    if it is informed by changes in the number of replicas, it can dynamically adapt
    its behavior to the number of replicas.
  prefs: []
  type: TYPE_NORMAL
- en: Sharding can also be achieved with RabbitMQ topics. Basically, a topic is a
    string attached to a message, and event subscribers can be enabled just for some
    topics. Therefore, if we attach the result of the hash function to each message
    as a topic, then each replica can subscribe just to the topic equal to its index,
    thus implementing sharding with no need for an extra component.
  prefs: []
  type: TYPE_NORMAL
- en: The disadvantage of the topic-based sharding technique is that the number of
    replicas must be known to all senders and can be changed just by restarting the
    whole application. Moreover, since the topic to assign to each message depends
    on both how the destination microservice defines message groups and the destination
    microservice, the number of replicas technique can’t be used with the publisher/subscriber
    pattern where messages are received by several heterogeneous microservices.
  prefs: []
  type: TYPE_NORMAL
- en: RabbitMQ also has a sharding plugin ([https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding))
    that computes a modulo *N* hash. This plugin defines a new type of exchange with
    a sharding-based routing strategy that we can attach immediately before each separate
    subscriber queue. Moreover, the plugin takes care of splitting the unique subscriber
    queue into *N* different sharded queues and distributing all subscribers among
    the *N* sharded queue. This technique is completely analogous to the single-replica
    routing microservice technique, but being integrated inside the message broker
    requires trading reduced flexibility for better performance. This technique solves
    all the problems of the topics-based technique but is not supported by the high-level
    **EasyNetQ** interface, so it increases the code complexity and maintainability.
    Moreover, it requires a broker configuration that depends on the exact topology
    of all subscribers, thus undermining the application’s extensibility.
  prefs: []
  type: TYPE_NORMAL
- en: Summing up, when using publisher/subscriber communication, the best option is
    almost always the single-replica routing microservice technique.
  prefs: []
  type: TYPE_NORMAL
- en: Having discussed microservices input and output, we can now move on to the design
    of the microservice container input parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Designing Docker image environment parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As already hinted at in the *A few more Docker commands and options* subsection
    of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067), *Setup and Theory: Docker and
    Onion Architecture*, containers usually adapt to their deployment environment
    by being passed as environment variables of the container’s virtual filesystem.
    In a .NET environment, parameters are available through the `IConfiguration` interface
    together with all parameters defined in the .NET configuration files, such as
    `appsettings.json`. Nested JSON paths are represented in the `IConfiguration`
    dictionary arguments by separating all segments with colons, as is the case for
    `IConfiguration[“ConnectionStrings:DefaultConnection”]`, which represents the
    usual default database connection string. When nested paths are represented by
    environment variables, colons are replaced with double underscores, in order to
    get valid environment variables names. Therefore, `ConnectionStrings:DefaultConnection`
    must be defined with an environment variable named `ConnectionStrings__DefaultConnection`.
    If environment variable names are prefixed with `ASPNETCORE_` or `DOTNET_`, these
    prefixes are removed; therefore, `ASPNETCORE_ENVIRONMENT` can be accessed with
    `IConfiguration[“ENVIRONMENT”]`. These prefixes are used to pass ASP.NET Core-
    and .NET-specific settings, such as staging, production, or development environment,
    and `ASPNETCORE_HTTP_PORTS` is also used, which contains a semicolon-separated
    list of all ports that Kestrel must listen on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also define your own custom prefix to apply to all your environment
    variables to avoid name collisions. However, since each microservice has a private
    container, collisions between environment variables used by different applications
    are impossible. Anyway, a new environment variable’s custom prefix can be defined
    inside the application services definition section with code analogous to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: As we will see in [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205), *Practical
    Microservices Organization with Kubernetes*, defining configuration settings with
    environment variables allows the easy specification of their values in the code
    files for the chosen orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: 'During development, environment variable values can be specified in the `Properties
    -> launchSettings.json` file of the top-level project of the Onion Architecture,
    which, in our case, is the `RoutesPlanning` project. The following snippet shows
    where to place your environment variable values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, we need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The database connection string
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The RabbitMQ connection string.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The maximum distance for proposing a match between a request and a route, and
    the maximum number of best matches to retrieve from the database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The subscription ID prefix for all our microservice replicas. This string is
    used as a prefix for all subscription queue names in our microservice replicas.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You don’t need to discover all the settings you need at this stage, just the
    ones that play a fundamental role in your microservice. Further settings can be
    easily added at a later time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, let’s define all settings in the `launchSettings.json` file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: We left the database connection string empty. We will fill it once we have defined
    the SQL Server development database.
  prefs: []
  type: TYPE_NORMAL
- en: The RabbitMQ connection string contains the server URL and the default credential.
    Note that the default credentials are accepted just when RabbitMQ is accessed
    from `localhost`, so you are encouraged to change them once you have installed
    the server. `publisherConfirms=true` informs RabbitMQ that it must confirm that
    the message was safely received, and `timeout=10` specifies the connection timeout
    in seconds.
  prefs: []
  type: TYPE_NORMAL
- en: The microservice main service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All modern .NET applications based on a host allow the definition of the so-called
    **hosted services**, which are services similar to Windows services running for
    the entire application lifetime. They can be defined by implementing the `IHostedService`
    interface and adding them to the services definition section of the application
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: In practice, hosted services are defined by inheriting from `BackgroundService`,
    which contains a partial implementation of the service and exposes a single `ExecuteAsync`
    method that we must override.
  prefs: []
  type: TYPE_NORMAL
- en: Our microservice needs three hosted services. The main one listens to all input
    messages arriving from the message broker and processes them. Another hosted service
    extracts messages from the output internal queue and sends them to the message
    broker. Finally, the third hosted service performs housekeeping jobs, such as
    deleting expired requests and routes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This subsection describes the main hosted service. The job of this hosted service
    is quite simple it listens for all four input messages we defined, and once it
    has received a message, it will create a command specific to that message and
    invoke the command handler associated with that command. Commands and command
    handlers are Onion Architecture building blocks that were discussed in the *Commands*
    subsection of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067), *Setup and Theory:
    Docker and Onion Architecture*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a `HostedServices` folder in the `RoutesPlanning` project. Then,
    add a class named `MainService` that inherits from `BackgroundService` to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The class name is followed by a couple of parentheses since it is the principal
    constructor where we will add parameters. In fact, all parameters of a hosted
    service constructor are automatically taken from the dependency engine container,
    so we can put all services it needs to perform its job there: an `IConfiguration`
    parameter, and an `IServiceProvider` interface that we will use to get scoped
    services. In fact, command handlers are scoped services, so we need to create
    a request scope before requiring them for the dependency injection container.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summing up our principal constructor, it looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Before proceeding, let’s add this hosted service to the dependency injection
    container, so it will be immediately executed at the start of the program. We
    just need to add the following instruction to `Program.cs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case of the worker microservice, there is a one-to-one mapping between
    messages and commands, and all input needed by the command is contained in the
    message, so a unique generic command called `MessageCommand<T>` suffices. Let’s
    define it in the `Commands` folder of the `RoutesPlanningApplicationServices`
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s define a method that given a message of type `T` creates a scope,
    requires the appropriate command handler, and executes it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Errors, that is, exceptions thrown during a `ProcessMessage<T>` execution, are
    handled by counting the number of consecutive errors and then rethrowing the exception.
    As we will see, rethrowing the exception basically undoes the extraction of the
    messages from the message broker queue so it can be processed again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Error counting can be performed with a thread-safe critical region, as shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Consecutive error counts can be used to define the microservice health state.
    Now, we can define an error-protected wrapper of `ProcessMessage<T>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s also define a small method that computes the subscription ID to use for
    each message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to define our main `ExecuteAsync` method; but before doing
    that, we must add a reference to the EasyNetQ NuGet package. Please select a version
    greater than or equal to 8, also if it is a prerelease. Once we have installed
    this package, we need to add its services to dependency injection in `Program.cs`
    by calling the `AddEasyNetQ` extension method and passing it the RabbitMQ connection
    string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The chained call defines how to handle errors in the received message handlers.
    We decided to requeue faulty messages so that they can be retried. If a microservice
    replica is faulty and generates an error on all messages, the message will eventually
    be processed by a healthy replica, while the unhealthy replica will eventually
    be discovered thanks to the consecutive error count that we will expose on a health
    endpoint. Unhealthy replicas are killed and recreated by all microservice orchestrators.
  prefs: []
  type: TYPE_NORMAL
- en: The requeue strategy is usually the best error-handling strategy for enterprise
    microservices. Anyway, there are other strategies available. If no strategy is
    specified, faulty messages, that is, messages whose handlers throw exceptions,
    are enqueued in a special error queue where they can be handled manually with
    administrative tools (see [https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe](https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Access to all EasyNetQ communication facilities is done through an `IBus` interface.
    Let’s add it to our hosted service main constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `IBus` interface handles all communication with three properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PubSub`: This contains all methods for sending and receiving messages with
    the publisher/subscriber pattern'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SendReceive`: This contains all methods for sending and receiving messages
    with direct communication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Rpc`: This contains all methods for issuing asynchronous remote procedure
    calls and returning their responses'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here, we will describe `PubSub`, but `SendReceive` is completely analogous.
    The only difference is that the `Send` method explicitly specifies the name of
    the destination queue, while `Publish` does not. The `Publish` RabbitMQ exchange
    name is implicitly defined through the type of the message.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the publish methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The second overload lets you specify a message topic, while the third lets you
    specify various configuration settings that may also include the message topic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the subscribe methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The returned value must be disposed of to unsubscribe. The second overload
    accepts a `CancelationToken` in the message handler, and also accepts a configuration
    action. The configuration of the receiver contains more useful settings, among
    them the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`conf => conf.WithTopic(“mytopic”).WithTopic(“anothertopic”)`: The consumer
    will receive just the messages tagged with one of the selected topics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`conf => conf.WithPrefetchCount(N)`: `N` is the maximum number of messages
    extracted from the queue by the consumer and waiting to be processed. *N* defaults
    to 20.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Conf => conf.WithDurable(durable)`: If `durable` is `true`, all consumer queue
    messages are recorded on disk by RabbitMQ. The default is `true`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If messages must be processed in the same order that they were inserted in the
    queue, the prefetch count must be set to `1` and we must also apply one of the
    strategies described in the *Ensuring that messages are processed in the proper
    order* subsection.
  prefs: []
  type: TYPE_NORMAL
- en: If we use `Subscribe`, all prefetched messages are put in an internal in-memory
    queue and processed in a unique thread. However, there is also a completely analogous
    `SubscribeAsync` that creates several parallel threads. Moreover, `SubscribeAsync`,
    as usual, returns `Task<SubscriptionResult>`.
  prefs: []
  type: TYPE_NORMAL
- en: We will use `SubscribeAsync` to better exploit processor cores, and parallelism
    between disk/database operations and processor operations, but the simple fact
    of using several microservice replicas already exploits parallelism. The advantage
    of using several threads is that creating a thread costs less than creating another
    replica, so each replica should use several threads to optimize performance.
  prefs: []
  type: TYPE_NORMAL
- en: When the message handler successfully completes the task, a confirmation is
    automatically sent to RabbitMQ that deletes the message from the queue.
  prefs: []
  type: TYPE_NORMAL
- en: On the contrary, if the message handler throws an unhandled exception, the configured
    consumer error strategy is applied. In our case, we requeue the message.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are finally ready to write the main `ExecuteAsync` method. After our
    configuration and preparation methods, it became straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: We just subscribe to all messages using our unique generic message handler,
    and then wait for the replica termination on the wait handle `stoppingToken.WaitHandle`.
    As soon as we receive notification that the replica is being terminated through
    `WaitOne()`, the wait handle is unblocked and we unsubscribe all messages by calling
    the `Dispose` methods of all `SubscriptionResult`.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on to the implementation of the two remaining hosted services,
    for completeness, we will also describe the EasyNetQ RPC facilities.
  prefs: []
  type: TYPE_NORMAL
- en: EasyNetQ’s RPC facilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An RPC request can be issued with the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Once the request is issued, the returned task will eventually provide the response.
    We can wait it with `await` or specify a callback by calling `Task<T>.ContinueWith`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The recipient can listen for requests and provide responses with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The recipient can stop handling requests by disposing of the `IDisposable` returned
    by the preceding methods.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s move on to the remaining hosted services.
  prefs: []
  type: TYPE_NORMAL
- en: Other required hosted services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will start with the housekeeping hosted service. Let’s call it `HouseKeepingService`
    and place it in the `HostedServices` folder together with `MainService`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Before proceeding, let’s add the new hosted service to the dependency injection
    container, so it will be immediately executed at program start. We just need to
    add the following instruction to `Program.cs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'We need a `HouseKeepingCommand` whose constructor specifies the number of days
    to wait after a route or request expiration before deleting it. As usual, let’s
    define it in the `Commands` folder of `RoutesPlanningApplicationServices`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to define the `Timing__HousekeepingIntervalHours` and `Timing__HousekeepingDelayDays`
    environment variables in `launchSettings.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ExecuteAsync` method must execute a loop until the application signals
    termination. Inside this loop, it executes the handler and then sleeps for the
    time specified by `Timing__HousekeepingIntervalHours` or until the replica terminates:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: In case of errors, we simply do nothing and repeat the operation at the next
    iteration. The `Task.Delay` instruction at the end of the iteration leaves the
    thread sleeping until either the configured interval expires or `stoppingToken`
    signals the replica termination.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s move on to the last hosted service. Let’s repeat the same steps to create
    it and call it `OutputSendingService`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'As usual, let’s add the new hosted service to the dependency injection container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This time, we need a command that accepts `Func<RouteExtensionProposalsMessage,Task>`
    as input. This input action wraps the code for sending `RouteExtensionProposalsMessage`
    to RabbitMQ because commands can contain code that depends on a specific driver,
    which in our case is the RabbitMQ client. It also needs a `batchCount` parameter,
    which specifies how many output messages are simultaneously extracted from the
    output queue, and a `requeueDelay` parameter, which specifies the overall timeout
    after which a message is requeued if it is not successfully received by the message
    broker.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can define a generic command that receives just `Func<T,Task>`, so we can
    reuse it with other output messages; let’s call it `OutputSendingCommand`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The command contains a flag where its handler will signal whether the output
    queue was found empty. We will use this flag to put the hosted service thread
    to sleep for a certain interval to avoid wasting resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we need a `Timing__OutputEmptyDelayMS` environment variable to configure
    the time to wait when the output queue is empty. Let add it to `launchSettings.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'We need also the `batchCount` and `requeueDelay` values to pass to the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Suppose we have a `SafeInvokeCommand` we need to implement that also returns
    whether the output queue is empty:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, the `ExetuteAsync` method can be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: An outermost loop that exits only when the replica is going to be terminated,
    and an inner loop that reads the internal output queue and sends messages to the
    messages broker until the output queue is empty. When the output queue is empty,
    the service sleeps to wait for new messages being inserted in the internal output
    queue.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before implementing `SafeInvokeCommand`, we must code the `Func<T,Task>` wrapper
    to pass to the command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the implementation is analogous to the command invoker of `MainService`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: In case of exceptions, we simply return `true` to put the thread to sleep for
    some time. In the next section, we will use the Polly library to define retry
    strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring resilient task execution with Polly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Message sending should always be protected with at least exponential retry and
    the circuit break strategies that we analyzed in the *Resilient task execution*
    subsection of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying Microservices
    Applications*. In this section, we will first describe the Polly library, which
    became a kind of standard for handling resilient task execution, and then we will
    apply it to the `SendMessage` method of `OutputSendingService`.
  prefs: []
  type: TYPE_NORMAL
- en: The Polly library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Resilient communication and, in general, resilient task execution can be implemented
    easily with the help of a .NET library called **Polly**, whose project is a member
    of the .NET Foundation. Polly is available through the `Polly` NuGet package.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Polly, you define policies and then execute tasks in the context of those
    policies, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The first part of each policy specifies the exceptions that must be handled.
    Then, you specify what to do when one of those exceptions is captured. In the
    preceding code, the `Execute` method is retried up to three times if a failure
    is reported by either an `HttpRequestException` exception or an `OperationCanceledException`
    exception.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the implementation of an exponential retry policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The first argument of `WaitAndRetryAsync` specifies that a maximum of six retries
    is performed in the event of failure. The lambda function passed as the second
    argument specifies how much time to wait before the next attempt. In this specific
    example, this time grows exponentially with the number of attempts by a power
    of 2 (two seconds for the first retry, four seconds for the second retry, and
    so on). The following is a simple circuit breaker policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: After six failures, the task can’t be executed for one minute since an exception
    is returned.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is the implementation of the Bulkhead Isolation policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: A maximum of 10 parallel executions is allowed in the `Execute` method. Further
    tasks are inserted in an execution queue. This has a limit of 15 tasks. If the
    queue limit is exceeded, an exception is thrown. For the Bulkhead Isolation policy
    to work properly and, in general, for every strategy to work properly, task executions
    must be triggered through the same policy instance; otherwise, Polly is unable
    to count how many executions of a specific task are active.
  prefs: []
  type: TYPE_NORMAL
- en: 'Policies can be combined with the `Wrap` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Polly offers several more options, such as generic methods for tasks that return
    a specific type, timeout policies, task result caching, the ability to define
    custom policies, and so on. It is also possible to configure Polly as part of
    an `HttpClient` definition in the dependency injection section of any ASP. NET
    Core and .NET application. This way, it is quite immediate to define resilient
    HTTP clients. Finally, version 8 also introduced a new API based on creating pipelines
    of strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Polly’s official documentation can be found in its GitHub repository here:
    [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).'
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will install and use Polly for a resilient transmission
    of the microservices output messages to the message broker.
  prefs: []
  type: TYPE_NORMAL
- en: Adding Polly to our project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using Polly in our project is straightforward. First of all, you must add a
    reference to the last version of the Polly NuGet package in the `RoutesPlanning`
    project. Then, you must modify the `SendMessage` method of the `OutputSendingService`
    class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: We first define an exponential retry policy, then a circuit breaker policy,
    and finally combine them and execute the message sending inside `combinedPolicy.ExecuteAsync`.
  prefs: []
  type: TYPE_NORMAL
- en: All strategies’ parameters could be specified with environment variables, but
    for simplicity, we left constant all values but `circuitBreakDelay`, that is,
    the time a circuit break should last. In fact, this is the only critical parameter
    that might need to be tuned.
  prefs: []
  type: TYPE_NORMAL
- en: '`circuitBreakDelay` can be configured in an environment variable in `launchSettings.json`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, it can be defined as an `OutputSendingService` field with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: From abstraction to implementation details
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we defined the overall organization of the route-planning
    microservice. In this final section, we will fill in all the details by first
    defining the domain layer and the database driver, and then defining all commands.
  prefs: []
  type: TYPE_NORMAL
- en: The domain layer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will define each aggregate in a separate folder that will contain the aggregate,
    the interface that defines the aggregate state, and the repository interface associated
    with the aggregate.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, before starting the definition of all aggregates, we need to add a
    famous library for handling both geometric and GIS calculations: `NetTopologySuite`.
    It is available in both Java and .NET and all its types conform to a standard
    recognized by all main databases.'
  prefs: []
  type: TYPE_NORMAL
- en: The .NET version is available through the `NetTopologySuite` NuGet package.
    Therefore, let’s add this package to the `RoutesPlanningDomainLayer` project.
    The meaning of GIS object coordinates is defined in documents classified with
    integers called **Spatial Reference Identifiers** (**SRIDs**). Each document specifies
    the meaning of the *x* and *y* coordinates, how to compute the distance between
    two points, and the part of the Earth’s surface it applies to. Each GIS object
    must specify the SRID used by its coordinates, and only objects with the same
    SRID can be used in the same computation.
  prefs: []
  type: TYPE_NORMAL
- en: We will use SRID 4326, which applies to the entire surface of the Earth. `X`
    is the longitude in degrees and `Y` is the latitude in degrees; the distance is
    computed in meters by approximating the Earth’s surface with an ellipsoid. More
    precise results can be obtained with SRIDs that apply to smaller portions of the
    Earth’s surface, but SRID 4326 is supported by all main databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s define our overall default SRID in a static class defined in the root
    of the `RoutesPlanningDomainLayer` project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the case of messages, we need intermediate types. Let’s define them in
    a `RoutesPlanningDomainLayer -> Models -> BasicTypes` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Route status**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Time interval**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Town info:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'User info:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`Point` is a `NetTopologySuite` type that specifies a point on the Earth’s
    surface. Please note that all of the preceding types are what we called value
    objects in the *The domain layer* subsection of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*. Therefore, as suggested there,
    we defined them as .NET record types.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can start defining our aggregates. For each of them, we will first define
    its status interface, then the aggregate, and finally, the associated repository
    interface. Usually, the definition of all these data types is iterative; that
    is, we start with a first draft, and then, when we realize we need another property
    or method, we add it.
  prefs: []
  type: TYPE_NORMAL
- en: The route request aggregate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s create a `Models -> Request` folder for all types related to a user request.
    The status of a user request can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: All properties that cannot be changed by aggregates have been defined as get-only
    properties. `Id` uniquely identifies each request in the overall application.
    `Source` and `Destination` are, respectively, the desired departure and arrival
    towns, while `WhenStart` and `WhenEnd` define the acceptable days for travel.
    Then, we have information on the user that issued the request and the current
    timestamp associated with the request. Finally, `RouteId` is the unique identifier
    of the route that the request has been added to, if any. If the request is still
    open, this property is `null`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The aggregate can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: It is worth pointing out that once a request has been created, only its `state.RouteId`
    can be changed. This is because once issued, each request cannot be modified but
    just matched with existing routes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The repository interface is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: The `New` method creates a new instance of the aggregate and its database-attached
    state. Then, we have methods for getting a single or more existing aggregates
    from their `Id`, and all aggregates that are served by the same route.
  prefs: []
  type: TYPE_NORMAL
- en: The `GetMatch` method returns all aggregates that are the best match with a
    route. The route is specified by the coordinates of the towns it passes through
    (`geometry`), and by its date (`When`). `Coordinate` is a `NetTopologySuite` type
    that contains just the *X* and *Y* coordinates of a location without its SRID
    (the default SRID defined before is implicit). `distance` specifies the maximum
    distance between the request and a route for a match to occur. All results are
    ordered according to their distance from the route, and a maximum of `maxResults`
    requests is returned.
  prefs: []
  type: TYPE_NORMAL
- en: The `DeleteBefore` method is used to perform some housekeeping by deleting old,
    expired requests.
  prefs: []
  type: TYPE_NORMAL
- en: The route offer aggregate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s create a `Models -> Route` folder for all types related to a user route
    offer. The status of a user request can be represented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '`LineString` is a `NetTopologySuite` type that represents a path made of consecutive
    segments on the Earth’s surface. Basically, it is a sequence of coordinates with
    an attached SRID. `Status` is the status of the route (open to other participants,
    closed, or aborted).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The aggregate can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Here, dots have been added in place of methods we will analyze shortly. The
    `LineString` path contained in the aggregate state is exposed as an immutable
    list of its coordinates so that it can’t be modified directly, and can’t have
    its SRID changed.
  prefs: []
  type: TYPE_NORMAL
- en: 'It contains an `Extend` method that is called when a message requiring the
    extension of the route is received. The data contained in the message is passed
    as its parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The path is updated only if it is more recent than the path stored in the aggregate,
    while the requests contained in the extension message are always attached to the
    route offer, because each message doesn’t contain all matched requests but just
    the newly added ones, so they must also be added if we received an old message.
    The only case when the requests must not be added is when the route has already
    been aborted, because aborted routes release all their attached requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The task of attaching the requests to the aggregate is left to an event handler
    for better modularity. Thus, the `Extend` method adds an `AttachedRequestEvent`
    event to the aggregate list of events. The event definition must be placed in
    the `Events` folder and is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, if the extension message declares the route closed, the `Extend` method
    closes it by calling the `Close()` method, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'There is also an `Abort` method, which declares the route aborted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'It sets the aggregate status to aborted and then leaves the task of releasing
    all attached requests to an event handler for better modularity, with the `ReleasedRequestsEvent`
    event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s move on to the repository interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: The `New` method creates a new aggregate, then we have a method to get an aggregate
    from its unique identifier. The `GetMatch` and `DeleteBefore` methods are completely
    analogous to the one of requests, but in this case, `GetMatch` returns all route
    offers matching a given request.
  prefs: []
  type: TYPE_NORMAL
- en: The output queue item aggregate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This aggregate represents a generic output queue item. Files will be placed
    in a `Models -> OutputQueue` folder. The aggregate state can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Each queue item has a unique ID and a message code that specifies which message
    type is stored in the item. While the message content is the JSON representation
    of the output messages. The aggregate is trivial:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The `GetMessage` method deserializes the message contained in the item.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the repository interface is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Each queue item has a time attached to it, and an item can be extracted by the
    queue only after this time expires. Moreover, queue items are extracted in increasing
    time order.
  prefs: []
  type: TYPE_NORMAL
- en: The `Take` method extracts the first `N` items from the queue and then immediately
    requeues them by replacing their time with the time of their extraction plus the
    `requeueAfter` `TimeSpan`. This way, if messages are successfully sent before
    `requeueAfter`, they are removed from the queue; otherwise, they become available
    for extraction from the queue again, and their transmission is retried.
  prefs: []
  type: TYPE_NORMAL
- en: The `Confirm` method deletes all successfully sent messages, while the `New`
    method adds a new item to the output queue.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can move on to the implementation of all aggregate states with Entity
    Framework entities and to the implementation of all repositories.
  prefs: []
  type: TYPE_NORMAL
- en: The database driver
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before getting started with the implementation of the `RoutesPlanningDBDriver`
    driver, we must add a reference to the `Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite`
    NuGet package, which adds support for all `NetTopolgySuite` types to Entity Framework
    Core. Then, we must declare the usage of `NetTopolgySuite` in the `Extensions
    -> DBExtensions.cs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can define all the entities we need in the `Entities` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Route offer:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Route request:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Queue item:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, in the `MainDBContext.cs` file, we must add the corresponding collections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, in the `OnModelCreating` method of the same file, we must declare
    the relationship between `RouteOffer` and `RouteRequest`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'We must also declare some indices and the usage of value objects (with their
    indices) with `OwnsOne`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Let’s now move on to the implementation of all repositories.
  prefs: []
  type: TYPE_NORMAL
- en: The IOutputQueueRepository implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'All repository implementations follow the same basic pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: They take `IUnitOfWork` from their main constructor and cast it to the database
    context.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `New` method implementation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of `Confirm` is straightforward, too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: It uses the changes tracker to get all already-loaded entities with the given
    IDs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Take` implementation is a little bit more complex, because it requires
    a transaction to handle the competition between the various microservice replicas,
    since they all use the same database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Once all entities are extracted, `ReadyTime` is moved to a future time to prevent
    their usage from other replicas till `requeueAfter` expires and they become available
    again if they were not removed by `Confirm`. This way, if all retry and circuit
    break strategies fail in getting a successful transmission, the same operation
    can be retried after `requeueAfter`. Both read and update must be part of the
    same serializable transaction to prevent interferences from other replicas.
  prefs: []
  type: TYPE_NORMAL
- en: The IRouteRequestRepositoryimplementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The repository structure is completely analogous to the one of the previous
    repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'The `DeleteBefore` method is easily implemented with the recent `ExecuteDeleteAsync`
    Entity Framework Core extension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following code blocks, we can see the `New` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'It creates an Entity Framework Core entity, adds it to `ctx.RouteRequests`,
    and uses it as the state to create `RouteRequestAggregate`. It adds also a `NewMatchCandidateEvent<RouteRequestAggregate>`
    event to the aggregate. The associated event handler will take care of finding
    all routes that match the request and creating an output message for each of them.
    `NewMatchCandidateEvent<T>` is defined in the `Events` folder of the `RoutesPlanningDomainLayer`
    project, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'All other methods contain quite standard Entity Framework Core code, so we
    will describe here just the `GetMatch` method since it uses the Entity Framework
    special queries extensions. The code of all other methods is available in the
    `ch07` folder of the book’s GitHub repository ([https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: First of all, we create a `LineString` geometry from the route path, and then
    we start the query. The `Where` clause first restricts the search to requests
    that are not already attached to other routes. Then, it verifies time compatibility
    and, finally, distance compatibility by using the `LineString.Distance` method.
    All geometry objects have a `Distance` method, so we can perform geometric queries
    involving any kind of geometric object.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we return an anonymous object with both the distance and the retrieved
    entity. This way, we can sort data by distance and extract the best `maxResults`
    matches.
  prefs: []
  type: TYPE_NORMAL
- en: The IRouteOfferRepository implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Again, the repository structure is the same as the one of all previous repositories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'The `DeleteBefore` method is analogous to the one of the previous repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: The `New` method is also the same as the one of the requests repository, but
    it generates the `NewMatchCandidateEvent<` `RouteOfferAggregate>` event, whose
    handler looks for matching requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we describe just the `GetMatch` method since all other methods are quite
    standard:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: The `Where` clause first restricts the search just to all open routes. Then,
    it verifies time and distance constraints as in the same `GetMatch` method of
    the previous repository. Also, sorting is the same as that in the previous repository.
  prefs: []
  type: TYPE_NORMAL
- en: Having defined everything, we can now move on to migration.
  prefs: []
  type: TYPE_NORMAL
- en: Creating migrations and databases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before generating database migrations, we must implement the `IDesignTimeDbContextFactory<MainDbContext>`
    interface inside the database driver. All migration tools look for this implementation
    to create the instance of `MainDbContext` needed to get information on both the
    database configuration and the database connection string. Therefore, let’s add
    a `LibraryDesignTimeDbContextFactory` class to the root of the `RoutesPlanningDBDriver`
    project:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: Please replace the placeholders I left in the string with your SQL Server instance
    name and password. The simplest way to get a connection string is by connecting
    to the database from within Visual Studio and then by copying the connection strings
    from the properties tab. Please don’t forget you can’t use the SQL database installed
    with Visual Studio since it is not able to listen to TCP/IP connections, so it
    cannot be accessed from within Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can also add the SQL Server connection string we left empty in `launchSettings.json`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: Again, please add your password. `host.docker.internal` is the network name
    of your development computer that hosts Docker or a local Kubernetes simulator.
    Use it if you performed a direct installation on your machine or if you ran a
    SQL Server Docker image on your computer. Replace it with the appropriate name
    if you are using a cloud or other network instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s make `RoutesPlanningDBDriver` our Visual Studio startup project,
    and select it in the Visual Studio **Package Manager Console**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B31916_07_5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.5: Selecting the project in Package Manager Console'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are ready to issue our first migration in **Package Manager Console**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: Please note that if you copied the project from the GitHub repository associated
    with the book, you don’t need to execute the preceding command since migrations
    have already been created there. You just need to create the database with the
    following command.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the previous command was successful, you can create the database with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Done! We can now move on to the implementation of all command and event handlers.
  prefs: []
  type: TYPE_NORMAL
- en: 'The application services: Defining all command and event handlers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will define all the required command and event handlers.
    Before starting, we need to add a reference to the `Microsoft.Extensions.Configuration.Abstractions`
    and `Microsoft.Extensions.Configuration.Binder` NuGet packages in the `RoutesPlanningApplicationServices`
    project. This way, we enable all handlers to receive configuration data from the
    dependency injection engine through the `IConfiguration` interface.
  prefs: []
  type: TYPE_NORMAL
- en: All command handler constructors require some repository interfaces, `IUnitofWork`
    for finalizing modifications and handling transactions, and an `EventMediator`
    instance for triggering all events added to the aggregates.
  prefs: []
  type: TYPE_NORMAL
- en: We will not describe all handlers, just the ones with a didactic added value.
    You can find the entire code in the `ch07` folder of the book’s GitHub repository
    ([https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp)).
  prefs: []
  type: TYPE_NORMAL
- en: We will place all command handlers that process messages in a `CommandHandlers
    -> Messages` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the `RouterOfferMessage` handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: The handler extracts all data needed to create a new aggregate from the message
    and then passes it to the `New` repository method. Then, it verifies whether the
    created aggregate contains events and uses the `EventMediator` instances to trigger
    all associated event handlers. `ConstraintViolationException` is created by the
    `IUnitOdWork` implementation in case of unique key violations. In our case, this
    exception can be thrown just when we receive a duplicate `RouterOfferMessage`.
    Therefore, we simply capture it and do nothing, since duplicate messages must
    be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: '`RouteRequestMessageHandler` is completely analogous, so we will not describe
    it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s move on to the `RouteClosedAbortedMessage` handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: The whole operation is enclosed in a serializable transaction to avoid interferences
    with other microservice replicas that might receive older or future messages concerning
    the same route offer. In fact, they might modify the same entity after it has
    been read but before it has been modified. The serializable transaction prevents
    this possibility.
  prefs: []
  type: TYPE_NORMAL
- en: If we don’t find the entity, we do nothing and simply abort the transaction.
    In fact, this eventuality might take place only if the route expires and is deleted.
    However, if entities are deleted after enough time has passed since they expired,
    this should be a substantially impossible event.
  prefs: []
  type: TYPE_NORMAL
- en: If the message specifies that the route must be closed, we put the aggregate
    in the closed state by calling `Close()` only if the aggregate is still open.
    In fact, if it is either already closed or aborted, this will be an old message
    or a duplicate that must be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, if the message specifies that the route should be aborted, it is
    processed only if the aggregate is not already in an aborted state.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in case of errors, we abort the transaction and rethrow the exception,
    so the message will not be confirmed and the message will be processed again at
    a later time, possibly by a different replica.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s move on to the `RouteExtendedMessage` handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: Also, in this case, since the command handler performs both a read and a modification,
    we need an explicit transaction.
  prefs: []
  type: TYPE_NORMAL
- en: Again, if no entity is found, we do nothing for the same reasons explained for
    the previous handler. We also do nothing if the message timestamp is identical
    to the one contained in the entity, because in this case, the message is a duplicate.
    Otherwise, we simply call the aggregate `Extend` method, and then trigger possible
    events generated by the `Extend` method.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now move on to handlers that are not related to messages. They are placed
    in the root of the `CommandHandlers` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with `HouseKeepingCommandHandler`, which deletes old expired requests
    and routes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: It is very simple, since it just subtracts the delay or the deletion of all
    expired entities from the current time and then calls the repository methods for
    deleting routes and requests. It doesn’t need to save changes since each of these
    methods already interacts with the database.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `OutputSendingCommandHandler` that handles the output queue is a little
    bit more complex:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: It tries to take `command.BatchCount` items from the output queue. If no item
    is found, it informs the command that the queue is empty, which, in turn, informs
    the queue-handling hosted service that it can sleep for a little while.
  prefs: []
  type: TYPE_NORMAL
- en: Then, it deserializes all messages and passes them to the `Sender` delegate.
    However, instead of awaiting each task returned by this method, it collects all
    of them, puts them in an array, and awaits the whole array with `Task.WhenAll`.
    This way, all messages are sent concurrently, thus improving performance. In case
    of exceptions, it simply does nothing, because unsent messages are detected in
    the LINQ instruction inside `repo.Confirm` and their associated queue items are
    excluded from the array of all items to confirm, so they will be retried at a
    later time.
  prefs: []
  type: TYPE_NORMAL
- en: We are done with all the command handlers. Let’s move on to the event handlers.
  prefs: []
  type: TYPE_NORMAL
- en: Coding all event handlers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Usually, event handlers do not create transactions and do not attempt to store
    modifications in the database, since they are invoked by command handlers, which
    do this task for them; so, their code tends to be a little bit simpler. We have
    four event handlers, which are all placed in the root of the `EventHandlers` folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with the `AttachedRequestEvent` handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'This handler is responsible for attaching requests to a route. Its code is
    trivial: it just retrieves all aggregates from their keys and then attaches them
    to the route referenced in the event.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ReleasedRequestsEvent` handler is responsible for releasing all requests
    attached to an aborted route. Its code is trivial, too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: It retrieves all requests attached to the route and simply detaches each of
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we have two event handlers that discover route-request matches and
    add them to the microservice output queue. The first one is triggered when a new
    request is added, while the second one is triggered when a new offer is added.
    Since they are very similar, we will describe just the first one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: The `PrepareMessage` method just fills a `RouteRequestMessage` using data contained
    in the corresponding `RouteRequest\regate`. We will not describe it, since it
    is trivial.
  prefs: []
  type: TYPE_NORMAL
- en: The `HandleAsync` method first extracts the parameters needed for the search
    from configuration data. Then, it calls the repository `GetMatch` method to find
    all matches. Finally, for each route retrieved, it creates an output message and
    adds it to the internal queue. The request is turned into a singleton list since
    the output message requires a list.
  prefs: []
  type: TYPE_NORMAL
- en: The code of our microservice is finished! We will test it in the next chapter
    after connecting it with message sources and message receivers. There, we will
    also implement the microservice health check endpoints and connect them to the
    orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter described in detail how to design and code a **Dockerized** microservice.
    In particular, it described how to design its input and output messages and endpoints,
    as well as how to use a message broker to implement event-based communication.
    It also described how to handle out-of-order and duplicated messages, concurrent
    output production with several microservice replicas, and transactional outputs
    with a database internal queue.
  prefs: []
  type: TYPE_NORMAL
- en: Then, it described how the organization of worker services is based on hosted
    services and how in this case, commands are carried out in one-to-one correspondence
    with all input messages. Finally, it described how to code all of the Onion Architecture
    levels of any microservice.
  prefs: []
  type: TYPE_NORMAL
- en: All concepts were explained through the practical example of the route-planning
    worker microservice of the book’s case study application. You should now understand
    the practical usage of the RabbitMQ message broker and the `NetTopologySuite`
    library for implementing spatial calculations and queries.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter describes orchestrators with a specific focus on Kubernetes.
    There, we will test the microservice coded in this chapter by connecting it with
    other microservices, and by using an orchestrator to manage all microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do worker microservices typically need authentication and authorization? What
    about encrypted communication protocols?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They don’t need authentication because their processing is not connected to
    a specific application user. Encrypted communication is advised but not always
    necessary since they run in an isolated environment.
  prefs: []
  type: TYPE_NORMAL
- en: Where is it advised to place all microservices’ input and output messages?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In some kind of queues.
  prefs: []
  type: TYPE_NORMAL
- en: What is the name of the technique for maintaining the right processing order
    of messages while using several microservice replicas?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sharding.
  prefs: []
  type: TYPE_NORMAL
- en: Is it true that if modification messages contain the whole updated entities,
    and if deletes are logical, then the order of messages doesn’t matter?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes, it is true.
  prefs: []
  type: TYPE_NORMAL
- en: Which library is typically used in .NET for handling failures with retry policies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Polly is used in .NET for handling failures with retry policies.
  prefs: []
  type: TYPE_NORMAL
- en: Where are domain events created? Where are they before their handlers are fired?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a list contained in the aggregates that created them.
  prefs: []
  type: TYPE_NORMAL
- en: Why do event handlers typically not use transactions and `IUnitOfWork.SaveEntitiesAsync`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Because transactions are created and handled by the Command Handlers that caused
    the events.
  prefs: []
  type: TYPE_NORMAL
- en: When sending several concurrent output messages, how can we discover which ones
    succeeded, which ones failed, and which ones were canceled?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Through acknowledgments.
  prefs: []
  type: TYPE_NORMAL
- en: What is an SRID?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Spatial Reference Identifiers. They name geographic coordinate systems.
  prefs: []
  type: TYPE_NORMAL
- en: Can the `Distance` method of all `NetTopologySuite` geometric objects be used
    in LINQ queries to a SQL Server database?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Yes.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'RabbitMQ official documentation: [https://www.rabbitmq.com/](https://www.rabbitmq.com/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'EasyNetQ official documentation: [https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction](https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Polly documentation: [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RabbitMQ sharding plugin: [https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spatial data extensions for Entity Framework Core: [https://learn.microsoft.com/en-us/ef/core/modeling/spatial](https://learn.microsoft.com/en-us/ef/core/modeling/spatial).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NetTopologySuite: [https://nettopologysuite.github.io/NetTopologySuite/](https://nettopologysuite.github.io/NetTopologySuite/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/PSMCSharp](https://packt.link/PSMCSharp)'
  prefs: []
  type: TYPE_NORMAL
- en: '![A qr code with black squares  AI-generated content may be incorrect.](img/B31916_Discord-QR-Code.png)'
  prefs: []
  type: TYPE_IMG
