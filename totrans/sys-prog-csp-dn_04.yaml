- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The One with the Thread Tangles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Concurrency* *and threading*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Threading** and **concurrency** are things that most developers think they
    know all about. The theory sounds so simple, yet in practice, threading is where
    a lot of mistakes are made and where all those frustrating bugs originate. Threading
    can be quite complex, but the people of the BCL and CLR teams have done their
    best to help us as much as they can to make things simpler.'
  prefs: []
  type: TYPE_NORMAL
- en: Once you get the hang of it, threading is a great addition to your skills and
    can make a major difference in your systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will look at the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What is concurrency and threading?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do threads work internally in .NET and Windows?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does the CLR help us?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is async/await?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do we synchronize threads and make them work together?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I make sure my code behaves nicely when working with threads?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I use collections over threads?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look into this fascinating topic!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All the source code and samples in this chapter can be downloaded from this
    book’s GitHub repository at [https://github.com/PacktPublishing/Systems-Programming-with-C-Sharp-and-.NET/tree/main/SystemsProgrammingWithCSharpAndNet/Chapter04](https://github.com/PacktPublishing/Systems-Programming-with-C-Sharp-and-.NET/tree/main/SystemsProgrammingWithCSharpAndNet/Chapter04).
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency and threading – the basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This morning, I woke up as I do every day. I got out of bed, took a shower,
    and got dressed. Then I walked the dog for 30 minutes (it’s a Sunday today). I
    returned home, made some coffee, and then sat down to write this.
  prefs: []
  type: TYPE_NORMAL
- en: I am sure that your day looks the same in general. You do something, then you
    do the next thing. Things are done in order. Sometimes, I make a phone call to
    people in other time zones when I walk the dog, but most of the time, I do the
    things I do one at a time. It is more efficient that way. If I were to sit down
    to write this chapter but stop to walk the dog a bit after five minutes, then
    leave him standing near a tree while I run back to the house to write for five
    more minutes, followed by me running back to the dog to walk another 500 meters,
    things would never get done. I would get a workout with all the running back and
    forth, but it would be inefficient.
  prefs: []
  type: TYPE_NORMAL
- en: That is a silly way to lead your life (no judgment; if this is what you do,
    I am okay with it, it just doesn’t work for me).
  prefs: []
  type: TYPE_NORMAL
- en: However, in the case of computers, we tend to assume that this way of working
    enables work to get done quicker. Why do we think that?
  prefs: []
  type: TYPE_NORMAL
- en: Computers cannot do two things at the same time. No, wait. Let me rephrase that.
    CPU cores cannot do two things at the same time. In the old days, before AMD released
    the **Athlon 64 X2 processor** in 2005 and before Intel released the Pentium D
    in the same year, regular computers were all single-core. That means that computers,
    before 2005, could generally only do one thing at a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'These days, most devices have multiple cores. Your computer, laptop, and phone
    all have a multi-core processor. However, as a system programmer, you might encounter
    devices with only one core. Think of IoT devices: they need to be cheap and very
    low in power consumption. Those systems often have a single core. Systems programmers
    run into single-core devices more often than people writing other software.'
  prefs: []
  type: TYPE_NORMAL
- en: However, in the end, that doesn’t really matter. My primary development machine
    has 16 cores. That sounds like a lot. However, if I look at my Task Manager, I
    can see many things running simultaneously, much more than those 16 cores can
    handle. So, even in a multi-core environment, machines must do something to enable
    all those tasks. As systems programmers, we have to be aware of how to write our
    software to get the most benefit out of those cores.
  prefs: []
  type: TYPE_NORMAL
- en: We are thus dealing with two separate topics here. One is concurrency; the other
    is threading.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency is the concept whereby the system executes several sequences of
    operations in overlapping periods. It is not really simultaneous execution; that
    is called parallelism. It is all about tasks running at what seems to be the same
    time without waiting for other tasks. It is a concept, not a programming technique.
  prefs: []
  type: TYPE_NORMAL
- en: Threads, on the other hand, are a programmer’s construct. Threading is one of
    the ways to achieve concurrency.
  prefs: []
  type: TYPE_NORMAL
- en: Nice to know
  prefs: []
  type: TYPE_NORMAL
- en: Threads can be hardware threads or software threads. The CPU handles the first
    type; the second is handled in our software. The **Operating System** (**OS**)
    can assign threads to actual hardware threads, but as a developer, you are almost
    always going to be working with software threads. I will mostly be talking about
    software threads here, but I will point it out when I mean hardware threads instead.
  prefs: []
  type: TYPE_NORMAL
- en: The beginnings of concurrency – the IRQ
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For now, let us ignore the fact that computers cannot multitask aside from spreading
    the load across the physical cores a CPU might have. To make life easier, we will
    assume that a computer can do two things at once.
  prefs: []
  type: TYPE_NORMAL
- en: This has not always been the case. In the early days, a computer did one thing
    at a time. That meant that if you wrote some software for a computer, you had
    complete control over all available hardware. Everything was yours and yours alone.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, when I say that it was yours, I mean that it was mainly yours. Sometimes,
    something would happen that would need the attention of the CPU. In those days,
    we had something called an **Interrupt Request** (**IRQ**). An IRQ is a hardware
    feature that is usually tied to other hardware. An external device, such as a
    floppy disk drive or a modem, could signal the CPU (by putting a voltage on a
    particular connection to the CPU). When this happened, the CPU finished the instruction
    it was doing, stored all of its state in memory, looked up the address belonging
    to that IRQ (there could be more than one), and started the code in that address.
    When that function finished, the whole thing would be reversed: the CPU would
    load the previous stored state and continue executing the original code as if
    nothing had happened.'
  prefs: []
  type: TYPE_NORMAL
- en: This mechanism worked reasonably well, but there were a lot of potential issues.
    For instance, there were only a handful of IRQ lines available. If your code overwrote
    the registration of another piece of code attached to some hardware, that hardware
    would fail to work.
  prefs: []
  type: TYPE_NORMAL
- en: To make things worse, if you made a silly mistake and your code never returned
    from the IRQ, you could bring the whole machine to a halt. It would simply never
    return from your code and the running program would be on hold indefinitely. So
    you had to be very careful to ensure that you had no such bugs in your code!
  prefs: []
  type: TYPE_NORMAL
- en: IRQs are still used today, especially in low-power devices such as Raspberry
    Pi. We will encounter those later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Cooperative and preemptive multitasking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: IRQs work okay, but they should be used by hardware devices. Since there aren’t
    that many IRQs, and since they have the potential to kill running processes, we
    have moved away from using them in normal software.
  prefs: []
  type: TYPE_NORMAL
- en: However, having a computer and only being able to do one thing at a time with
    it seemed like a waste of resources. Computers became more and more powerful.
    They could soon do more things than we asked them to do. That was when multitasking
    OSs came into play.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, the versions of Windows before Windows 95, such as Windows 3.1,
    used something called **cooperative multitasking**. The principle was reasonably
    straightforward. A piece of code would do something, and when it thought it could
    use a break, it would just tell the OS: “Hey, I am on a break; if you need me
    to do something, just let me know.” It would then halt execution. This meant that
    the OS could allocate CPU time to another process.'
  prefs: []
  type: TYPE_NORMAL
- en: We called this cooperative multitasking because we expected the software to
    cooperate and share the resources fairly.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, if a program misbehaved, it could still claim all the CPU time, thus
    stopping other software from running as intended.
  prefs: []
  type: TYPE_NORMAL
- en: 'A better way was needed. Windows NT 3.1 and later Windows 95 did much better:
    they introduced **preemptive multitasking**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea is straightforward: allocate some time for a process to run, and when
    that time is out, store the state of that process, park it somewhere, and move
    on to the next process. When the time comes for the original process to do something
    again, the OS loads the program back into memory and restores the state, then
    the process can continue. The process was utterly oblivious to the time it had
    been dormant unless it kept track of the clock.'
  prefs: []
  type: TYPE_NORMAL
- en: Processes could no longer claim all of the available CPU time. The OS would
    pause the process if its time had run out.
  prefs: []
  type: TYPE_NORMAL
- en: Preemptive multitasking is still the way modern OSs work today.
  prefs: []
  type: TYPE_NORMAL
- en: However, all of this deals with multiple processes on a computer running simultaneously.
    How can we have one process doing multiple things at the same time? Well, one
    solution would be to use threads.
  prefs: []
  type: TYPE_NORMAL
- en: Threads in C#
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Threads are a concept that allows computers to seem to be doing more than one
    thing at once in your program. Just as an OS allows multiple programs to run simultaneously,
    threads allow your program to run multiple flows in your application concurrently.
    A thread is nothing more than an **execution flow** in your program. You always
    have at least one thread: the one that got started when the program began its
    execution. We call this the main thread. The runtime manages this thread and you
    have little control over it. All the other threads, however, are yours, and you
    can do whatever you want with them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Threads are nothing magical. The basic principle is quite easy:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a method, function, or any other piece of code you want to run.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a thread, giving it the address of the method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start the thread.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The OS or runtime executes that method or function while running the main thread
    simultaneously.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can monitor the progress of that thread. You can wait for it to end, or
    you can use a fire-and-forget strategy by just letting it do its work.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How you do these steps depends on which version you want to use. Do you choose
    the .NET way or go down the rabbit hole we know as the Win32 API?
  prefs: []
  type: TYPE_NORMAL
- en: In .NET, threads are represented by an actual class (or, more precisely, an
    instance of a class). In Win32, they are just something created by the Win32 API.
  prefs: []
  type: TYPE_NORMAL
- en: Win32 threads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Win32, you use the `CreateThread` API to create a thread. I want to show
    you how this works, but I must be honest: you will probably never do this in your
    code. There are better ways to create threads than using the Win32 API. Still,
    there might be circumstances when having complete control of the Win32 threads
    might be necessary.'
  prefs: []
  type: TYPE_NORMAL
- en: Let me show you how to do this in the Win32 API.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by declaring a `delegate`. This `delegate` is the form of the
    function that contains the work that the thread executes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are calling Win32 APIs, we need to import them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We will import three APIs: `CreateThread`, `CloseHandle`, and `WaitForSingleObject`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can use these APIs, we have to write the code that does something
    useful. In this case, it is not really useful, but this is the code that will
    be executed in the thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This `MyThreadFunction` function matches the delegate that we defined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'With all of that out of our way, we can create the threads and have our program
    do something. Or rather, it can do lots of somethings simultaneously. Here we
    go:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The `DoWork()` method creates a thread by calling the `CreateThread` Win32
    API. This API has some parameters. Let me explain what they do with the help of
    *Table 4.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameter** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| IntPtr lpThreadAttributes | A pointer to the security attributes struct |'
  prefs: []
  type: TYPE_TB
- en: '| uint dwStackSize | The size of the stack required for this thread |'
  prefs: []
  type: TYPE_TB
- en: '| ThreadProc lpStartAddress | A pointer to the function that the thread runs
    |'
  prefs: []
  type: TYPE_TB
- en: '| IntPtr lpParameter | A pointer to a variable that is passed to the thread
    |'
  prefs: []
  type: TYPE_TB
- en: '| uint dwCreationFlags | Additional flags determining how the thread is created
    |'
  prefs: []
  type: TYPE_TB
- en: '| out uint lpThreadId | An out parameter with the ID of the thread |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4.1: Parameters for the CreateThread Win32 API'
  prefs: []
  type: TYPE_NORMAL
- en: The security attributes define who or what has access to the thread and what
    this thread can use. The security attributes are rather complex. I will not be
    diving into them here, mainly because with threads they are not often used. Here,
    we have set the security attribute to `IntPtr.Zero`.
  prefs: []
  type: TYPE_NORMAL
- en: The `dwStackSize` parameter defines the stack size that the thread uses. As
    discussed before, each thread gets its own stack, where it can store its value
    types. This stack is reclaimed when the thread is done.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we get the function pointer that the thread will execute as soon as that
    thread starts. In C#, we can pass the method’s name and let the compiler do the
    hard work of figuring out the memory address.
  prefs: []
  type: TYPE_NORMAL
- en: 'After supplying the start address of the method, we get something more interesting:
    we can pass data into the thread method. The `lpParameter` parameter is a pointer
    to the memory where that data is located. To get data into the thread is quite
    a lot of work unless you want to use a simple `Int32`. After all, an `IntPtr`
    is a 32-bit value, so you can take an int and cast it back and forth to get that
    data in the thread function. I am not passing anything here, but will I show you
    how to do that a little later in this chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: Next are the flags that define how the system creates the thread. There are
    two flags that we can use, not counting the default `0`, which means “do nothing
    special.” These flags are explained in *Table 4.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flag** | **Value** | **Meaning** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0x00000000 | Do nothing special |'
  prefs: []
  type: TYPE_TB
- en: '| `CREATE_SUSPENDED` | 0x00000004 | Create the thread, but suspend it immediately
    instead of starting it. |'
  prefs: []
  type: TYPE_TB
- en: '| `STACK_SIZE_PARAM_IS_A_RESERVATION` | 0x00010000 | If this is set, the stack
    size is a reservation. If not, the stack size is committed. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4.2: Thread creation options'
  prefs: []
  type: TYPE_NORMAL
- en: '`CREATE_SUSPENDED` creates the thread but puts it in a suspended state when
    it is created. The default behavior is to run the code that `lpStartAddress` points
    to immediately.'
  prefs: []
  type: TYPE_NORMAL
- en: '`STACK_SIZE_PARAM_IS_A_RESERVATION` is an interesting one. This flag is one
    of the main reasons you might want to use the Win32 version of creating threads
    instead of the .NET one. Each thread has its own stack. You can specify how big
    that stack should be, but when you do that, all that happens is that the system
    reserves that memory. This reserving is a quick operation. Reservation only tells
    the system that you want to use this amount of memory at some point. You will
    get an error if the system doesn’t have enough memory to fulfill your request.'
  prefs: []
  type: TYPE_NORMAL
- en: However, the memory is not yet committed. Committed means that the OS reserves
    the memory you requested and marks it as being used by a process. Reservation
    is just telling it that you want the memory to be available later.
  prefs: []
  type: TYPE_NORMAL
- en: Page faults
  prefs: []
  type: TYPE_NORMAL
- en: When your application requests memory or tries to access memory from the system,
    certain things can happen.
  prefs: []
  type: TYPE_NORMAL
- en: The first instance happens when the memory is available in your stack or heap.
    You get the pointer to that memory; it’s all yours now.
  prefs: []
  type: TYPE_NORMAL
- en: The next happens if the memory is *not* in your stack or heap yet but it is
    available on the system. This results in a soft page fault. The system will add
    the new memory to the current stack or heap.
  prefs: []
  type: TYPE_NORMAL
- en: Next, it’s possible that the memory you want to reach is not in your computer’s
    memory chips. In this case, it has probably been swapped to disk. This is a hard
    page fault. The OS will load the memory from the disk and add it to your working
    set.
  prefs: []
  type: TYPE_NORMAL
- en: Page faults are great for adding flexibility to the system. However, they come
    with a big performance hit.
  prefs: []
  type: TYPE_NORMAL
- en: A page fault might occur when you reserve memory and want to access it. When
    this happens, your application’s performance will degrade.
  prefs: []
  type: TYPE_NORMAL
- en: If you commit memory, it is guaranteed to be available when it is needed. This
    makes your memory footprint larger and faster since you will not get a page fault.
  prefs: []
  type: TYPE_NORMAL
- en: 'You must choose here: which of the two scenarios do you prefer? You can control
    that for the stack with the `STACK_SIZE_PARAM_IS_A_RESERVATION` flag.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The code sample ends with two statements: `WaitForSingleObject()` and `CloseHandle()`.
    The *Synchronizing threads* section in this chapter explains `WaitForSingleObject()`
    in much more detail. Still, the short description is as follows: wait for the
    thread to finish before continuing on the main thread.'
  prefs: []
  type: TYPE_NORMAL
- en: '`CloseHandle` clears up all used resources. Yes, this is an unmanaged resource.
    This would be a great place to use the `IDisposable` pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: .NET threads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Threads in the .NET BCL are much simpler to use. Of course, when something is
    simplified, you usually sacrifice flexibility as a result.
  prefs: []
  type: TYPE_NORMAL
- en: The following sample shows how to do the same work as we did with the Win32
    thread using the .NET constructs.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin with the thread function, which runs on the new thread. It is
    almost the same as the Win32 sample. The following snippet shows the code that
    we want to run inside the thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'In the main body of our code, we create the thread, give it the function to
    run, and start it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We create a new instance of the `Thread` class and pass the method we want to
    use in the constructor. Then we start it. Then, we use `Join()` to wait for it,
    effectively pausing the main thread until our new thread is done doing whatever
    it is doing.
  prefs: []
  type: TYPE_NORMAL
- en: That’s it. If you compare this with the Win32 version, I am sure that you will
    appreciate this simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, do not be fooled: this simplicity does not mean that you cannot control
    your threads. You can control them and you can do much more than what I have just
    shown you. For instance, you can also specify the stack size you want to use for
    your thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here, we allocate 8 MB for the stack for our new thread.
  prefs: []
  type: TYPE_NORMAL
- en: Nice to know
  prefs: []
  type: TYPE_NORMAL
- en: The default stack size for a 32-bit application is 1 MB; for a 64-bit application,
    it is 4 MB. You will rarely need more than that. Requesting a big stack should
    only be done if you have tested your application and found that you really need
    it.
  prefs: []
  type: TYPE_NORMAL
- en: In the Win32 sample, we had to explicitly state that we wanted to create a thread
    in a suspended state. If we did not do that, it would have started immediately.
    In .NET, things work differently. A newly created thread in .NET is considered
    *unstarted*. This means that it will not be starting immediately. It is also not
    yet suspended; there is quite a difference in behavior.
  prefs: []
  type: TYPE_NORMAL
- en: A suspended thread is fully formed and placed on the OS’s scheduler list. Its
    stack is allocated and all resources are present.
  prefs: []
  type: TYPE_NORMAL
- en: An `Thread` class. The stack is not yet allocated and it has not yet been given
    to the OS, so it is not yet on the scheduler, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: When we call `Start()` on that .NET thread, the runtime does all that work.
    Creating a thread is much faster than the `CreateThread()` call in Win32, but
    that performance gain is lost when you start the thread. Think of it as lazy initialization.
  prefs: []
  type: TYPE_NORMAL
- en: The designers of the CLR took advantage of this. If it is relatively cheap to
    create threads and only becomes expensive when we use them, why not move that
    burden of creation to the beginning of the program? Starting an application takes
    time; if we extend that a bit, it does not matter. However, that would mean that
    we have a faster system when it is in use. We can have a pool of threads available
    when we need one or two. That is precisely what they did.
  prefs: []
  type: TYPE_NORMAL
- en: An example will probably make this clearer. However, before I can show you that,
    we must make some modifications. We want to create many threads that run simultaneously.
    To distinguish the output from each thread, we need to pass some data to that
    thread so that it can display it. Thus, we need to have something to store data
    in.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need immutable data for reasons that will become clear when we discuss thread
    safety later in this chapter. The `record`, which was added to C# 9, is a great
    way to do this::'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now work on our method that executes in that thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The thread gets a parameter of the `Nullable<object>` type. We cannot declare
    it as any other type, as this is what the runtime expects.
  prefs: []
  type: TYPE_NORMAL
- en: To use this data, we need to cast it to the right type.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we will get the ID of the current thread. Each thread has a unique ID,
    so we can interact with it, although we will only display it here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us create some threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We will create one hundred threads and start them immediately after creation.
    We will give them some data to see where in the loop we are.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the loop, I added the `Console.ReadKey()` so the program does not exit
    before all threads are done. The main thread that starts when running your program
    is special: if that ends, the CLR ends the whole program and unloads all memory.
    So, keeping your main thread alive is crucial until you are sure that all work
    is done. In a real-world scenario, you wouldn’t use `Console.ReadLine()` for this,
    but for this demo, it works just fine.'
  prefs: []
  type: TYPE_NORMAL
- en: If you run this, you will probably see the thread ID increasing in line with
    the loop counter. They are not equal. The CLR already created a dozen or so threads
    before you ran your loop.
  prefs: []
  type: TYPE_NORMAL
- en: If you increase the loop to do a much higher number of iterations, you will
    eventually see the same thread ID now and then. The CLR reuses threads to avoid
    thread starvation.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, I promised to show you the thread pool. Replace the part of the code
    where we had the for-loop with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We will use the thread pool here to pull threads out of the pool when needed.
    If you run this, you repeatedly see the same thread IDs. Threads are pulled out
    of the pool and started with the correct data. When the thread is done, it is
    winded down, its resources are de-allocated, and it is placed back in the pool,
    ready to be used again if needed.
  prefs: []
  type: TYPE_NORMAL
- en: The overhead is minimal and the advantages are enormous. Systems using this
    are much more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: '`ThreadPool` hides many more secrets and tricks that you can use, but its usage
    has largely been replaced by the **Task Parallel Library** (**TPL**), which handles
    most of this for you. Let us have a look.'
  prefs: []
  type: TYPE_NORMAL
- en: Tasks and Parallel Library – the TPL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TPL has been around for quite some time. It was introduced back in 2010
    with the release of .NET 4.0.
  prefs: []
  type: TYPE_NORMAL
- en: The TPL simplifies many of the things we used to do with threads. Threads still
    have their place, especially when dealing with third-party libraries. However,
    in most cases, we can let the TPL figure things out.
  prefs: []
  type: TYPE_NORMAL
- en: In the TPL, the `Task` class is the main class to work with. `Task` is a class
    that handles the instantiation of threads when needed. It does much more, but
    we will deal with that later.
  prefs: []
  type: TYPE_NORMAL
- en: I said “when needed” because it is smart enough to determine when a new thread
    is needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us begin with a straightforward example and then work from there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '`Task` is just another C# class that handles much of the concurrency for us.
    In this case, we call `static method Run()`, which takes a delegate that it performs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can rewrite this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This code snippet does the same, but we call the method instead of using the
    lambda expression.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can more or less do the same thing in a slightly different way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: I have omitted the `Console` stuff and the actual method; they will remain the
    same (until I say that I have changed them).
  prefs: []
  type: TYPE_NORMAL
- en: This code does more or less the same thing as the previous sample. The difference
    is that the `Task` does not start unless we explicitly call `Start()`.
  prefs: []
  type: TYPE_NORMAL
- en: The second example gives you more control over the `Task`. You can set properties
    and change the task’s behavior before starting it. `Task.Run()` is mostly designed
    for fire-and-forget scenarios. `Start()` is more flexible; it allows us to change
    the scheduling and, for instance, tell it to run on a specific thread. You can
    also specify the priority of the `Task` this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'This example is not very exciting. Let us try to make it a bit more exhilarating.
    We can change our method to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: We will add a parameter to our method to identify who calls the method. Since
    we now have a parameter, we must also change how we pass this to the `Task` constructor.
    Let’s not stop there. Imagine that we want to chain method calls. After the `Task`
    has finished with `DoWork` with `Id 1`, we want it to call that method again but
    with `Id 2` this time. In real life, you would probably chain two completely different
    methods, but the way of working is the same.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We have changed the parameter in the constructor so that we can pass that `1`
    integer to the method. The following line is more interesting. It says: “When
    you finish the first step, call `DoWork` again, but this time with `Id 2`.” The
    `prevTask` parameter is the previous `Task` that has finished its work. This triggered
    the start of the second `Task`.'
  prefs: []
  type: TYPE_NORMAL
- en: If you run this, you will see the lines printed to the console in the correct
    order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us rewrite the method that gets called one more time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We added the `id` of the thread this method runs on to the output. I also want
    to see that `id` thread before we start the tasks. Our calling code now looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If you run this, you will probably see that the tasks run on a different thread
    rather than the main one. If you repeat this a few times, it might even happen
    that the second task runs on a different thread from the first one. It is impossible
    to predict when this will happen; the scheduler picks whatever works best given
    the current conditions. We do not have to worry about this. It just works. Neat,
    isn’t it?
  prefs: []
  type: TYPE_NORMAL
- en: Another nice class that is available in the TPL is the `Parallel` class. It
    allows us to do stuff in parallel. Let’s see that
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: First, we will print the `id` of the current thread. Then we will create an
    array of integers from `1` to `10`; nothing special here. After that, we will
    call the static `ForEach` method on the `Parallel` class and give it the array
    and the lambda to call. The method iterates through the array and calls the lambda
    with the correct parameter. It does that in parallel, not sequentially, as with
    a standard `ForEach` loop.
  prefs: []
  type: TYPE_NORMAL
- en: When you run this, you will see some exciting results. The order in which the
    program prints the IDs is entirely random. You will see that the runtime uses
    multiple threads, but sometimes it reuses some of these threads.
  prefs: []
  type: TYPE_NORMAL
- en: Again, the TPL determines the best way to do this and handles all the threads’
    creation and scheduling for you.
  prefs: []
  type: TYPE_NORMAL
- en: TPL is extremely powerful. It is also the backbone of the async await pattern.
    This is a pattern that simplifies working with concurrency so much that most users
    do not realize what is happening behind the scenes. With your newfound knowledge,
    you should have no problem following what is happening. So, let’s have a look
    at async/await.
  prefs: []
  type: TYPE_NORMAL
- en: Async/await
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software hardly ever runs in isolation. Most software needs to reach outside
    of its boundaries and access something that is not part of the code block at some
    point. Examples include reading and writing files, reading data from a network,
    sending something to a printer, and so on. Suppose that a typical machine can
    access a byte in memory in about 10 nanoseconds. Reading that same byte from an
    SSD takes approximately 1,000,000 nanoseconds or even longer. Reading data from
    external devices is usually about 100,000 to 1,000,0000 times slower than reading
    local data from memory. Think about that when you try to optimize your code if
    you know that your software transfers data to and from external hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take this one step further. Let us assume that you have a decent machine
    that can quickly process data. You need to read data from an external website.
    Your program must wait very long before that data is available. It can take milliseconds
    before that data reaches us. For us mere humans, that is pretty fast, but the
    computer could have done a million other tasks in the meantime. That seems like
    a colossal waste of our expensive resources, right?
  prefs: []
  type: TYPE_NORMAL
- en: Threading can help, of course. You can create a thread to call the external
    website and wait for that to finish, doing other things in the meantime. However,
    as we have seen, threads can be quite cumbersome. The TPL helps, but still, things
    can get complicated. Reading data from external sources or writing data to external
    targets is so common that the CLR designers decided to help us by introducing
    async/await.
  prefs: []
  type: TYPE_NORMAL
- en: 'The top-down approach is simple: anything that takes more time than simple
    operations should be done asynchronously. However, we do not want to deal with
    the threads themselves. Async/await, which uses the TPL internally, is a pattern
    that can help.'
  prefs: []
  type: TYPE_NORMAL
- en: 'What it does is this: as soon as you have code that needs to be run asynchronously,
    the compiler injects code that wraps our code into a state machine. This state
    machine tracks the threads and the progress of our code and switches back and
    forth between the blocks of code that need attention.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Does that sound complicated? Well, it is. The usage, however, is straightforward.
    However, before I show it to you, I want to introduce a little piece of helper
    code I often use when discussing async/await. This code is just an extension method
    on the `string` class and outputs a `string` to the console and adds the `ManagedThreadId`.
    It even allows for coloring the output, making it easier to distinguish between
    the different threads. If you want to use this, go ahead. If you would rather
    use `Console.WriteLine()` everywhere yourself instead, be my guest. However, using
    this makes the critical part of the code more readable. Here is my extension method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: You can also find this code in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, I want to show you the most simple example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Imagine that we want do something that takes a long time, such as reading a
    file from storage, in our `DoWork()` method. I have simulated that here by pausing
    the current thread for a second. Our entire program is paused while we call this
    in our main method. Our costly and powerful CPU is left to do nothing (at least
    not for our program). That seems wasteful! We’ve seen that we can use threads
    or the TPL to improve that. However, that code is also wrapped in the async/await
    pattern, so why not use this?
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, I replaced `Thread.Sleep()` with a call to `Task.Delay()`. That
    more or less does the same thing but allows us to improve on our code. Remember:
    this `Thread.Sleep()` and the new `Task.Delay()` method are just a stand-in for
    the real work your application should be doing. Having a `Sleep()` or `Delay()`
    method in your code is usually a bad idea.'
  prefs: []
  type: TYPE_NORMAL
- en: If you have to call an async method, you must wait for it. So, we will add the
    `await` keyword before the call to `Task.Delay()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have done that replacement, I will also prefix our method with the
    `async` keyword. This keyword tells the compiler that it should wrap this method
    in the state machine I mentioned earlier. However, any async method should never
    return void for reasons that will become clear later. We need to return a `Task`
    or a `Task<>` if you actually return something. So, we changed our void to `Task`.
    Again, any async method needs to be called with the `await` keyword. So, the result
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Run this and see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will probably see that the program starts on one thread and then carries
    out the `DoWork()` method on that same thread, but that it switches to a new thread
    when that is done. That is because the compiler sees our `Task.Delay()` await
    and decides to free up the CPU to do other things. The runtime puts our current
    thread on hold and stores its state in memory, leaving our main code free to do
    other things. Only when `Task.Delay()` finishes is our main thread revived. However,
    since the main thread is no longer associated with our code here, we need a new
    thread. That one is pulled from the `ThreadPool` (remember: that is fast since
    the threads there were created at startup) and populated with the state we had.
    Then the system can continue on that thread. The program ends on that new thread
    as well!'
  prefs: []
  type: TYPE_NORMAL
- en: I mentioned that all async methods need the async modifier and should return
    a `Task` instead of a void. There is a simple reason for this. If you do not do
    this, your code will work but not as expected. The **Async all the way to the
    top** rule is simple but very important.
  prefs: []
  type: TYPE_NORMAL
- en: Async all the way to the top!
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have a method containing an `await` keyword, the method needs to be
    async and return a `Task`. However, since you will probably call that method yourself
    somewhere, the calling code must also be async and return some form of `Task`
    or `Task<>`. Since that method is also called… well, you get the idea. The rule
    is: async all the way to the top! Every method in that chain needs to have that
    async!'
  prefs: []
  type: TYPE_NORMAL
- en: Another rule, which is not as strict as the “Async all the way to the top” rule,
    is that all async methods should be named as such. Our `DoWork()` method should
    be renamed to `DoWorkAsync()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, before we do that, let us see what happens if we are sloppy and do
    not return a `Task`. Try it yourself: replace the `Task` return type with a void
    and remove the await before `DoWork()` (you cannot await a void, so you will get
    an error if you do not remove that).'
  prefs: []
  type: TYPE_NORMAL
- en: Run it. It works just fine, right? Okay, there is no new thread created, but
    who cares? The software does what it needs to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s change our `DoWork()` method a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: I also temporarily removed the `ReadLine()` to make the program more lifelike.
    The main thread finishes when everything is done.
  prefs: []
  type: TYPE_NORMAL
- en: Run it. See that we do not get the `“We’re done with the hard work”` message.
    That makes sense; there is an exception in front of it. However, please notice
    that we also do not see that exception.
  prefs: []
  type: TYPE_NORMAL
- en: Why is this? It’s complicated, but the simplified explanation is that the state
    machine is still created since `DoWork` is still an async method. The exception
    is raised on a different thread (after the `Task.Delay()` await). However, since
    the state machine is not configured to wait for all results (because we omitted
    the `await` keywords), it just ignores that thread. If you move that “We’re done
    with the hard work” `Dump()` line to the line before the exception, you will see
    that it is not called. In reality, it *is* called; you just don’t see it. This
    thread has become a fire-and-forget thread. You lost all control over it.
  prefs: []
  type: TYPE_NORMAL
- en: Can you imagine a complex piece of software where something goes wrong deep
    in the bowels of your code? Can you imagine not getting the exception? Can you
    imagine the horror of debugging that?
  prefs: []
  type: TYPE_NORMAL
- en: You will get that exception if you use async/await all the way up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Oh, before I forget: the reason that I removed the `Console.ReadKey()` line
    is that by doing so, I forced the main thread to quit as soon as possible, resulting
    in unloading the application from memory. If you restore that line, you will see
    the exception, since the main thread is paused there. Now other things will be
    allowed to happen.'
  prefs: []
  type: TYPE_NORMAL
- en: However, that is not really a solution to our problem. You do not want to wait
    for the main thread to become idle before you get exceptions. It could take ages
    for that to happen.
  prefs: []
  type: TYPE_NORMAL
- en: Please restore the async/await keywords, replace the void in `DoWork()` with
    `Task`, and run it. The exception is thrown precisely where you would expect it
    to be.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is really important, so I like to repeat it once more: async all the way
    to the top!'
  prefs: []
  type: TYPE_NORMAL
- en: Task.Wait() and Task.Result
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many blog posts and articles about why you should not use `Task.Wait()`
    or `Task.Result`. The reason for this is pretty simple: these calls block the
    current thread. Using them removes the scheduler’s ability to resume work on the
    calling thread and return to the execution flow when the `Task` is done. If you
    do this, why use async/await in the first place? Async/await also allows for thread
    synchronization, so there is no need to use `Wait()` and `Result`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hold on. There are some situations where you might decide to use them anyway:'
  prefs: []
  type: TYPE_NORMAL
- en: You may want to use them if you are working on legacy code that you are modernizing.
    The rule is “Async all the way to the top,” which might require extensive code
    refactoring. That is not always feasible. In those cases, you might use `Wait()`
    and `Result` instead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In unit tests, you can mock or stub async methods. However, sometimes it might
    be better for the unit test to use `Wait()` and `Result`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might not care about the main thread staying responsive in systems programming.
    There is no user interface, after all. So, blocking the main thread may not be
    a big problem. I still think that it is bad form not to use async/await, but in
    these cases, you can get away with using `Wait()` and `Result`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As with all rules in software development, be vigilant about these rules and
    apply them as much as possible, only breaking them if you have a good reason and
    have thought about it well. Also, please do your future self a favor and document
    why you chose to deviate from the usual way of working in the source code.
  prefs: []
  type: TYPE_NORMAL
- en: So, now you know how to use async/await. Although they do not always result
    in multiple threads, they are a great way to balance the load in your application.
    They help tremendously in keeping your code organized. You are relieved of the
    burden to do all synchronization between threads. However, that doesn’t mean that
    you never have to care about synchronization at all. There is no avoiding that,
    so I think we should talk about it right now.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronizing threads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The async/await pattern has made life easier for us developers. If you have
    a long-running task (and remember: anything that uses devices outside the CPU
    is long-running), you can call that method asynchronously. Then you can sit back
    and wait for it to finish without blocking the execution of your app in other
    places. The TPL takes care of the thread management.'
  prefs: []
  type: TYPE_NORMAL
- en: However, sometimes you may want to have a bit more control. You might have a
    situation where you must wait for a method to finish before you can continue.
    Imagine that you have your main thread and call the `A()` method. That method
    is long-running, so you make it async (rename it to something ending with ‘async’)
    and change the return type to `Task` or `Task<>`. Now you can wait for it. However,
    another thread might have to wait until your `Aasync()` method is finished. How
    do you do that?
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the wonderful world of thread synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization – how do we do that?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the old days, when we still used threads and the `ThreadPool`, synchronization
    could be a hassle. However, with `Task` and async/await, things have become much
    easier without having real downsides. Before I show you that, I want to show you
    how to synchronize threads instead of tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me start with the base program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This sample should be obvious now. I have two methods that do something that
    takes a long time to finish. I pull some threads out of the `ThreadPool` and run
    all of this simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: If you run this, the `Console.ReadKey()` in place. What could we do if we want
    to wait for the two methods to be finished before we move on?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is to use a synchronization mechanism. This means that we have an
    object that we can use to flag certain states. We can write it ourselves, but
    we must take care of a lot of synchronization and thread safety. Luckily, we do
    not have to. The Win32 API provides tools that are neatly wrapped in BCL classes.
  prefs: []
  type: TYPE_NORMAL
- en: One of these is the `CountdownEvent` class. As the name suggests, it allows
    us to count down events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Change your main method to look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: We will create a new instance of the `CountdownEvent` class and initialize it
    to `2`.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we will get the threads and allow them to do their work.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the code in the methods, I have added one line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: At the bottom of the method, you will see the `.Signal()` countdown. Since that
    instance is reachable in this method, I can use it. `Signal()` tells the countdown
    to decrease the number of events to wait for.
  prefs: []
  type: TYPE_NORMAL
- en: I did the same to the `DoSomethingForTwoSeconds()` method.
  prefs: []
  type: TYPE_NORMAL
- en: That means that when both methods are done, they call `Signal()` on the countdown.
    In the main method, I added `countdown.Wait()` after the `ThreadPool` code, telling
    the main thread to pause until the countdown reaches zero.
  prefs: []
  type: TYPE_NORMAL
- en: If you run this, you will see it works wonderfully and that the rest of the
    main thread is perfectly synchronized with the threads.
  prefs: []
  type: TYPE_NORMAL
- en: However, what if I want the `DoSomethingForTwoSeconds` method to start when
    `DoSomethingForOneSecond` is finished?
  prefs: []
  type: TYPE_NORMAL
- en: That is almost as easy. We can use one of the other synchronization classes
    to help us out. Let me show you how to do this using the `ManualResetEvent`. This
    class does more or less the same as the `CountdownEvent`. The difference is that
    the `ManualResetEvent` class does not count; it just waits for a signal.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the main method, before calling the `ThreadPool`, I have added this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: I have set it in the initial `False` state. Doing so results in any thread waiting
    for the event to be set.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `DoSomethingForOneSecond()`, I have added one line right at the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The call to `Set` tells the `ManalResetEvent` that any waiting thread can continue.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `DoSomethingForTwoSeconds()`, I have added the following to the beginning
    of the method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '`WaitOne()` tells the code to pause the thread until the `mre` gets a signal
    (which happens at the end of `DoSomethingForOneSecond()`).'
  prefs: []
  type: TYPE_NORMAL
- en: If you run your program now, you will notice that everything is nicely synchronized
    and waiting for other stuff to finish.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, you might have achieved precisely the same result by not using threads.
    We have basically removed all multitasking from our application. If you need to
    synchronize threads, now you know how. However, be careful: you might introduce
    weird errors if you make mistakes. Trust me: debugging multithreaded applications
    is no walk in the park.'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization with async/await
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might have guessed by now that using async/await dramatically reduces the
    complexity of working with threads and synchronizing between them.
  prefs: []
  type: TYPE_NORMAL
- en: Let us return to our example of the `DoSomethingForOneSecond` and `DoSomethingForTwoSeconds`
    methods. This time, we will rewrite them to use async/await.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your `DoSomethingForOneSecond` should be like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: I renamed the function to end with async, as I should have done much earlier.
  prefs: []
  type: TYPE_NORMAL
- en: The `DoSomethingForTwoSecondsAsync()` should get the same treatment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calling the methods in the main method now looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The results are identical to those from the example where we did all the synchronization
    ourselves, with the only difference being that we have no blocking threads anymore.
    So this is not only easier to do but it is also much better.
  prefs: []
  type: TYPE_NORMAL
- en: However, what happens if we do not want to do the methods sequentially? What
    if we want them to run simultaneously?
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, that is easy enough. Since our methods return a `Task`, we can work with
    that. Instead of waiting for them individually, we can simultaneously wait for
    them. Let me show you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We will take advantage of the fact that we get tasks back. The `Task` class
    has a static method called `WaitAll()` that only returns when all tasks are finished.
  prefs: []
  type: TYPE_NORMAL
- en: There are other methods, such as `WaitAny` (only continue when any of the tasks
    finish), WhenAll (do something when they are all done), and WhenAny (you can figure
    this out by yourself).
  prefs: []
  type: TYPE_NORMAL
- en: The difference between `WaitAll` or `WaitAny` and `WhenAll` or `WhenAny` is
    that `WaitXXX` is a blocking call. It blocks the current thread until the condition
    has been met`. WhenXXX` returns a Task itself that you can await and thus does
    not block the thread.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, there is a bigger difference: `WhenAll` allows you to capture the
    return result. If any tasks that you want to wait for return a result, you can
    get that with `WhenAll`. `WhenAll` returns the results to you in an array. You
    can get at them, which is something you cannot do with `WaitAll` or `WaitAny`.'
  prefs: []
  type: TYPE_NORMAL
- en: In case you were wondering, `WhenAny` returns a `Task<T>`. That `Task<T>` has
    a property called `Result`; you can read that property to get access to the result
    of that Task. This is one example when using `Result` is actually a good thing!
  prefs: []
  type: TYPE_NORMAL
- en: Canceling a thread
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes, you want to stop a thread from running. There might be several good
    reasons to do this, but whatever your reason, be sure to clean up after yourself.
    Threads are expensive to use and leaving them in an unknown state is a horrible
    practice: you shoot yourself in the foot one day.'
  prefs: []
  type: TYPE_NORMAL
- en: In the days of.NET Framework, the `Thread` class had a method called `Abort()`.
    However, it turned out that the method did more harm than good, so the BCL and
    CLR people decided to get rid of it. If you try to abort a thread, you will get
    a `PlatformNotSupportedException`. I guess they really do not want us to use that
    anymore.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best way to stop a running thread is the same way you should stop a running
    `Task`: using something we call **cooperative cancellation**. A calling thread
    can request another thread to stop. It is up to that second thread to honor that
    request – or not. There is no guarantee.'
  prefs: []
  type: TYPE_NORMAL
- en: The standard way of doing this is by using a `CancellationToken`. A `CancellationToken`
    is an object we use to signal that we want to cancel something.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you can write this class yourself. There is not much going on besides
    some thread safety. However, having a `CancellationToken` in your threads or tasks
    makes it clear to the user that it can be canceled.
  prefs: []
  type: TYPE_NORMAL
- en: 'I am going to rewrite our `DoSomethingForOneSecondAsyncMethod()` a bit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Instead of having the `Task.Delay(1000)` call, I do `1000` await `Task.Delay1)`.
    In theory, that would result in a one-second delay. However, when you run this,
    it takes considerably longer. The await call itself takes up some time as well.
  prefs: []
  type: TYPE_NORMAL
- en: I could measure how long it takes and then recalculate the number of iterations,
    or I could simply rename the method to `DoSomethingForSomeUnderterminedAmountOfTimeAsync()`.
    I will leave that decision up to you.
  prefs: []
  type: TYPE_NORMAL
- en: Assume that we get bored after 500 milliseconds after waiting in our main method
    and decide to stop this thread. How would we achieve that?
  prefs: []
  type: TYPE_NORMAL
- en: This is where the `CancellationToken` steps in. Again, a `CancellationToken`
    is a simple class. You can create one if you want to, but it is better to use
    a specialized class. This `CancellationTokenSource` class is created specifically
    for this and works in all sorts of weird conditions. It is inherently thread-safe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us create one right at the beginning of the main method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: I use `WaitAny` here because we want to cancel that task after the moment when
    we create it and before it has finished. Also, note the `using` statement. `CancellationTokenSource`
    implements `IDisposable`, so we must honor that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Canceling is simple. Between the `var task1` and `Task.WaitAny()` lines, add
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We will wait a bit, then get bored and call `cts.Cancel()`.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you run this, nothing will happen. That’s not entirely true; many
    things will happen. To be precise, the entire loop in `DoSomethingForOneSecondAsync`
    happens.
  prefs: []
  type: TYPE_NORMAL
- en: '`CancellationToken` is not a magic way to cancel running tasks. You have to
    check for that token yourself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to add a parameter to our method of the `CancellationToken` type. The
    method signature will now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We have to pass in that token when we call it. In our main method, change the
    line calling this method to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We will take our `CancellationTokenSource` and get its token. That is what we
    will pass on to our method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside our method, we must check to see whether we need to cancel. Yes, that
    is why I added the loop around the `Delay`. The full method will now look like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: If someone calls `Cancel` on the `CancellationTokenSource`, the `IsCancellationRequested`
    flag on the token will be set to `True`. We have to honor that. I do that by breaking
    out of the `for` loop. I have also set a `hasBeenCancelled` variable to `True`
    so I can inform our users that we have canceled this loop and tell them after
    how many iterations it was canceled.
  prefs: []
  type: TYPE_NORMAL
- en: We could have skipped this boolean and used `IsCancellationRequested` again.
    However, there might have been a risk of the request coming in right after the
    loop was done but before the printing of the message. In that case, the loop was
    not interrupted. But we said it was anyway, which is incorrect. This way we avoid
    printing the wrong message.
  prefs: []
  type: TYPE_NORMAL
- en: Run it and see what happens. On my machine, I get about 40 iterations before
    it cancels.
  prefs: []
  type: TYPE_NORMAL
- en: There is one bug in this code. It is good practice to pass on the `CancellationToken`
    to any method that accepts it. In our case, that would be `Task.Delay()`. There
    is an overload that accepts a `CancellationToken`.
  prefs: []
  type: TYPE_NORMAL
- en: 'I deliberately left that out here. Since the code would be in that line almost
    100% of the time, awaiting the Delay, we would cancel that and never see any printed
    messages. However, let’s now add it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Rerun it and see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: You might notice that we are missing a lot of screen output. The reason is simple.
    `Task.Delay()` throws an `OperationCancelledException` when it is canceled. However,
    we are not using `await` on our `Task` in the main method, so we will miss the
    exception. Remember when I said it was all too easy to miss exceptions when not
    everything is done right?
  prefs: []
  type: TYPE_NORMAL
- en: Synchronization helps to prevent errors from happening. However, there are a
    lot of techniques to make sure our code is thread-safe. Let’s dive into those
    now.
  prefs: []
  type: TYPE_NORMAL
- en: Thread-safe programming techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Look at this piece of code. Run it and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: We have a `Task` that counts down from 100 to 0\. Since we `await` this, the
    main part of the code waits nicely for this to finish before continuing. However,
    we also have a second thread that waits for 500 milliseconds and then sets the
    counter to `0`. The result is that the loop finishes prematurely.
  prefs: []
  type: TYPE_NORMAL
- en: What we see here is easy to debug. Every line of code is one screen, so I imagine
    that you will be able to spot the bug quite easily.
  prefs: []
  type: TYPE_NORMAL
- en: However, what if the integer used here is a member of a class? As you know,
    instances of classes are reference types. Reference types get passed on by reference,
    not by value. So if the Task has access to that instance, it can alter the members
    in that instance. However, every other task, thread, or piece of code sees the
    effects of that.
  prefs: []
  type: TYPE_NORMAL
- en: Thread safety is all about avoiding these kinds of things.
  prefs: []
  type: TYPE_NORMAL
- en: Value types are inherently safe. You will have no issues if you pass a value
    type such as integer to your `Task`. The value of the integer is copied and you
    are not changing the original value.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you need to access more complex types, you will need to think about
    this. The good news is that the runtime offers us several tools to mitigate this
    issue.
  prefs: []
  type: TYPE_NORMAL
- en: One of the tools you get is the `Lock()` keyword.
  prefs: []
  type: TYPE_NORMAL
- en: Lock()
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The simplest way to safeguard your data is to have a lock around it. A lock
    is an object that more or less works as a moat around a piece of code. A lock
    ensures that only one thread can simultaneously be in that code block. The syntax
    is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: The lock takes one argument. It uses this to identify the area to lock. It doesn’t
    do anything with this object; this is just something to hook the lock to. So,
    having a new `object()` will suffice.
  prefs: []
  type: TYPE_NORMAL
- en: Any code in this code block is safe, meaning that only one thread can decrement
    the `iterationCount` simultaneously. When another thread tries to do the same
    thing simultaneously, it blocks as soon as it reaches the lock statement. That
    thread remains blocked until the previous threat exits the code block.
  prefs: []
  type: TYPE_NORMAL
- en: 'Yes, this means that if the other thread crashes in that code (not very likely
    in this example: crashing on a `--` operator happens very infrequently), the rest
    of the system can never enter that code block.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Lock()` is syntactic sugar around a monitor object. The compiler actually
    uses `Monitor`s. So, the following code results in the same IL (Intermediate language):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: I do not know about you, but the `lock()` statement looks much more effortless
    to me.
  prefs: []
  type: TYPE_NORMAL
- en: Records
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The best way to ensure that data is not accidentally overridden is to ensure
    that the data cannot be altered. Immutable types are designed to do just that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me create a record first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: A record is a reference type, so its memory is allocated on the heap. However,
    records are meant to be immutable. You can create records that are not immutable,
    but that does not help us here.
  prefs: []
  type: TYPE_NORMAL
- en: Right now, I have a record with one member, `InitialValue`. I have to set the
    value for that when constructing the `Counter`, but I can never change it after
    that. So, no thread can come along and mess with that value anymore.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, since I cannot change it anywhere, I also have to change the code
    in the `Task`. It will now look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: I have made a copy of the value to decrement that in the loop. If you are a
    bit like me, you might say, “Wait a minute. Why didn’t I just copy that original
    `iterationCount` to a local variable and use that instead of this record?”
  prefs: []
  type: TYPE_NORMAL
- en: I see many people doing that. However, that is not guaranteed to work. What
    if a separate thread changes the value of `iterationCount` before you can make
    a copy? You would start with the wrong initial value.
  prefs: []
  type: TYPE_NORMAL
- en: Immutable records guarantee that the values inside it do not change, ever. Period.
    You are safe.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid static members and classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I know that it can be a nuisance to create instances of classes. Sometimes,
    it seems easier to create a static class filled with static members and use those
    instead. They certainly do have some use cases. However, remember this: static
    classes are not thread-safe out of the box. Static members are shared across threads
    so that anybody can change them.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the volatile keyword
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Sometimes, code seems straightforward, but it might not be. Look at this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: We know how this works. This integer is on the stack. If we change the value,
    the value at that memory address changes. Simple, right? Wrong. The compiler does
    all sorts of tricks to optimize our code, especially when you build it in Release
    mode. Building in Release mode means that the compiler might cache the value of
    even a simple integer to speed things up. It might even decide to move that line
    to another place in the code if it thinks it will not make a difference in the
    execution.
  prefs: []
  type: TYPE_NORMAL
- en: That is not a problem until multiple threads or tasks deal with that code. The
    compiler might make mistakes. It cannot determine which tasks can access that
    variable simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Yes, even simple writing to an integer can go wrong in a multithreaded system.
  prefs: []
  type: TYPE_NORMAL
- en: If we use `lock()`, we can guarantee that only one thread can access that code
    block, but that still does not mitigate the issue of the compiler optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem, we can use the `volatile` keyword. It looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Instead of using a cached value, the compiler ensures that we always go directly
    to the memory address and stored value. That means that all threads will go to
    the same place and work with the same integer, thus eliminating the risk of working
    on old, stale, or cached data.
  prefs: []
  type: TYPE_NORMAL
- en: You might be tempted to add that `volatile` keyword everywhere, but I suggest
    that you refrain. It does mess with the compiler’s optimization techniques. You
    should only use it if you suspect that there might be an issue with that particular
    piece of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, now you know how to be more safe when dealing with threads. This is very
    important: if you mess things up you can get horrible and hard-to-debug bugs in
    your code. This is especially true if you are dealing with collections in multiple
    threads. How do you keep them synchronized? We’re in luck though; the BCL has
    got us covered there. Let’s talk about concurrent collections.'
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent collections in .NET
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Collections are the backbone of many programs. Arrays, lists, dictionaries
    – we use them all the time. However, are they thread-safe? Let us find out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: We have a `List<string>`. Then we added 1000 strings to that list We have a
    task that iterates through them, displays them on the screen, and waits a bit.
  prefs: []
  type: TYPE_NORMAL
- en: We also have a separate thread that clears the list after waiting for a second.
  prefs: []
  type: TYPE_NORMAL
- en: If you have read the previous section in this chapter, you might expect the
    loop in the task to abort prematurely. It should not print all items, since the
    list is suddenly empty and thus the `ForEach()` stops.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you run it, you will see a different result. You will get a nice
    `InvalidOperationException` telling you that the collection was modified, which
    messed up the `ForEach` code.
  prefs: []
  type: TYPE_NORMAL
- en: Collections in the BCL are not thread-safe. If one thread works with them and
    another decides it needs to deal with that collection, things go wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following collections are not thread-safe and should be avoided when working
    with tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '`List<T>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Dictionary<TKey` and `TValue>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Queue<T>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Stack<T>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`HashSet<T>`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ArrayList`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`HashTable`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SortedList<TKey`, `TValue>`, and `TSortedList`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not use these in multiple threads or tasks simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some collections are thread-safe. This is what they are and what they do:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Collection name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `ConcurrentDictionary<TKey, TValue>` | A thread-safe collection of key-value
    pairs. It allows for concurrent adds, updates, and removals. |'
  prefs: []
  type: TYPE_TB
- en: '| `ConcurrentQueue<T>` | A thread-safe version of a **First-in, First-out**
    (**FIFO**) collection. |'
  prefs: []
  type: TYPE_TB
- en: '| `ConcurrentStack<T>` | A thread-safe version of a **Last-in, First-out**
    (**LIFO**) collection. |'
  prefs: []
  type: TYPE_TB
- en: '| `ConcurrentBag<T>` | A thread-safe, unordered collection of objects. It is
    suitable for scenarios where the order is not important. |'
  prefs: []
  type: TYPE_TB
- en: '| `BlockingCollection<T>` | Represents a thread-safe collection that can be
    bounded in size. It provides blocking and non-blocking `add` and `take` operations.
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4.3: Thread-safe collections'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first four collections are just thread-safe versions of the collections
    that we already know. Most people, however, would not recognize the last one:
    the `BlockingCollection<T>` collection.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This collection is, first of all, thread-safe. It also allows for blocking.
    Let me give you an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: A lot is happening here, so let me walk you through it.
  prefs: []
  type: TYPE_NORMAL
- en: First, we created an instance of the `BlockingCollection`. This class has a
    nice overloaded constructor that only allows this number of items to be added.
    If there are more, block the thread. I do not need that functionality here, but
    I found adding it funny.
  prefs: []
  type: TYPE_NORMAL
- en: Then we spun up a new thread that adds items to this collection. We can try
    to add 10, but again, it only allows five items. So, when the fifth item is added,
    this thread blocks until we have removed one of those items.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the loop, we told the collection that we had nothing left to add.
    We did this by calling `CompleteAdding()`.
  prefs: []
  type: TYPE_NORMAL
- en: Before we read the data in the second thread, we waited for a few seconds so
    the first one had time to fill the collection.
  prefs: []
  type: TYPE_NORMAL
- en: The second thread (third if you also count the main thread) took that collection
    and took an item from it. It is a FIFO collection, so the first item we could
    take was the first item added to the list. We displayed what we took and waited
    a bit. We needed to catch the `InvalidOperationException`. If the `CompleteAdding`
    was called due to timings by the time we had already taken all the items from
    the collection, an exception would have occurred. We need to catch that.
  prefs: []
  type: TYPE_NORMAL
- en: Due to our timings and `Thread.Sleep()` calls, we will see a fascinating effect.
    The first thread fills up the collection with five items. Then it waits. This
    operation takes five seconds in total. Six seconds after the start of the program,
    we will start taking items. Since there are plenty of them (five to be exact),
    the program will print these items on the screen quickly. When we take one item,
    the first thread gets permission to add a new item. However, since it takes a
    second to add an item, the second thread has to wait until it has been added.
    `Take()` will also block if there is nothing to take yet.
  prefs: []
  type: TYPE_NORMAL
- en: Only when the first thread calls the `CompleteAdding()` method does the second
    thread know it is done (since we checked the `IsCompleted` property). Then, we
    can exit the threads.
  prefs: []
  type: TYPE_NORMAL
- en: There is much synchronization behind the scenes, but it works amazingly well.
    This is undoubtedly an excellent addition to your toolbox!
  prefs: []
  type: TYPE_NORMAL
- en: Next steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That was quite a ride. Threading can be complicated, but we got through it all
    right.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at many different things in this chapter. We described what multitasking
    is, starting with old-fashioned IRQs, walking through cooperative multitasking,
    and arriving at the modern style of pre-emptive multitasking.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we investigated Win32 threads and their .NET counterparts. We saw how
    to create threads but quickly found that the `Threadpool` offers a better way
    of doing so in most cases. However, we learned that most of that is moot, since
    the TPL handles many details for us.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, we learned that async/await hides much complexity and makes writing
    multithreaded code a breeze. As with all tools, we learned that async/await comes
    with risks. You have to know what happens and where bad things can happen. Luckily,
    we covered those situations as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We looked at collections and how to make your code thread-safe. We also learned
    something fundamental regarding async/await: async all the way to the top!'
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous programming is imperative when dealing with devices outside the
    CPU. One of the areas where we need to use these techniques extensively is in
    the file system. However, file systems have a lot of other things that you need
    to know about. So, it’s great that the next chapter deals with that topic!
  prefs: []
  type: TYPE_NORMAL
