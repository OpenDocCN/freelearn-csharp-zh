<html><head></head><body>
<div><div><h1 class="chapterNumber">12</h1>
<h1 class="chapterTitle" id="_idParaDest-287">Finishing Touches</h1>
<p class="normal">Welcome to the <em class="italic">Finishing Touches</em> chapter! There is a misconception about how long games take to make and the overall difficulty of game development. This chapter will act as a toolbox to guide you in finishing your projects. This isn’t a straightforward next step, but rather an open box for you to see what we’re using to polish up our vertical slice. An interesting feature of the polishing process is that it covers a good 80% of game development. This might sound unintuitive; however, if you’ve been paying attention to the screenshots during the development, you will have noticed that we don’t have a complete game by any stretch of the imagination at this point from a consumer’s point of view. The mechanics work and the game is an experience by now, just not a complete one.</p>
<p class="normal">This chapter will go over:</p>
<ul>
<li class="bulletList">Overview</li>
<li class="bulletList">Asset finalization</li>
<li class="bulletList">Lighting</li>
<li class="bulletList">Sound polish</li>
</ul>
<h1 class="heading-1" id="_idParaDest-288">Overview</h1>
<p class="normal">Finishing touches are extremely important to a complete experience. We need to take what we have and tighten up all the stitches. This is done in several ways. </p>
<p class="normal">Lighting and sound<a id="_idIndexMarker805"/> are very difficult to finalize<a id="_idIndexMarker806"/> prior to this point. There can be <strong class="keyWord">research and development </strong>(<strong class="keyWord">R&amp;D</strong>), but unless the game’s focus is one of those two topics, you won’t be getting finalized lighting or sound until there are finalized assets in the game, as seen in the list in the following section. You’re correct in wondering why we had a chapter on sound before this. We wanted to go over the basics of sound<a id="_idIndexMarker807"/> in general and get you familiar with the concept of sound design and its implementation within Unity.</p>
<p class="normal">Lighting could be worked<a id="_idIndexMarker808"/> on early to set a mood but will need to be finalized after environments and light pools are well defined and firm in place. Again, if lighting and mood are going to be in the experience, then heavy lighting R&amp;D will need to take place even in the blocking-in stages of development. All the conversations here about lighting will guide you during that stage too if it’s needed.</p>
<p class="normal">The way this will work is that there will be specific actions that we will cover in all three of the major sections in this chapter. These actions are specific to our project but could help you with your future projects all the same. Think of them as tools instead of a tutorial. Some of them may need programming, and some of them may not. </p>
<p class="normal">As most of the mechanics have been programmed to a certain degree, we will focus first on asset finalization. Remember, as we said, it’s hard to get lighting and sound if the assets aren’t done. Let’s start there!</p>
<h1 class="heading-1" id="_idParaDest-289">Asset finalization</h1>
<p class="normal">This section will be awesome. There are so many great art assets<a id="_idIndexMarker809"/> and finishing touches that we can go over. Here is a list of tools we used that may help you in your projects in the future:</p>
<ul>
<li class="bulletList">Stylized pass on assets</li>
<li class="bulletList">Detail normals</li>
<li class="bulletList">Architecture cleanup</li>
<li class="bulletList">Texture blending</li>
<li class="bulletList">Environment clutter</li>
<li class="bulletList">Detail meshes</li>
<li class="bulletList">Effects</li>
<li class="bulletList">Cinematics</li>
<li class="bulletList">Secondary animation</li>
</ul>
<p class="normal">The way we will go through these sections is that we will have an explanation of why we will be doing this for our project, which may help you decide if you need to perform these polishing touches on your own projects in the future. After that, we will cover the literal steps that we took so that you can see how they are done. Interestingly, the actual steps we are taking<a id="_idIndexMarker810"/> may not be the only way to achieve these finishing touches. The best way to take these actions is as a concept or a starting point as the needs will be different for your project. We will begin our finishing touches with a stylized pass on our assets.</p>
<h2 class="heading-2" id="_idParaDest-290">Stylized pass on assets</h2>
<p class="normal">When defining an art style, we begin<a id="_idIndexMarker811"/> with broad strokes. Even if you take the time to outline the art direction, once you get to the polishing phase, you will need to make a pass on it to get the finishing touches in place. In our case, we found that our assets didn’t have enough of a stylized look to them to fit our art direction. The word stylized is used very often and it has the right to be used often for games as it means to just not look realistic. In our case, we want the stylizing to make everything feel more illustrative in nature. This means we need to push all our contrasting silhouettes and colors into the textures. We also need broader line weights in our textures.</p>
<p class="normal">A good example within our project is Myvari’s necklace. This art piece needs to stand out as it is the primary focus of Myvari’s telekinesis. We also know that we will be seeing it up close during cinematics, so we need to ensure that we put time into designing this piece.</p>
<figure class="mediaobject"><img alt="A picture containing indoor, chair, desk, blue  Description automatically generated" height="265" src="img/B17304_12_01.png" width="825"/></figure>
<p class="packt_figref">Figure 12.1: Stylized passes for Myvari’s necklace</p>
<p class="normal">This needs to happen throughout all the art pieces to have as much consistency as possible within the character and the world. Once the stylized pass is completed, some models may need to have small details<a id="_idIndexMarker812"/> added. We call them “detail normals.” Let’s go over them now!</p>
<h2 class="heading-2" id="_idParaDest-291">Detail normals</h2>
<p class="normal">A detail normal<a id="_idIndexMarker813"/> can sometimes be considered<a id="_idIndexMarker814"/> part of the stylized pass. In our case, we wanted this to be a standout part of the art direction overall, so we pulled it out of the stylized pass. We want to drive home the stylized nature of the silhouettes in the models; however, we want to give the materials themselves a sense of realism. Leather will need to look like leather, and bark should look like bark. Below in <em class="italic">Figure 12.2</em>, we have a detail normal on the mushroom to give a bit of extra nuance to it. The left image has base normals and texture. The right image has detail normals layered on top.</p>
<figure class="mediaobject"><img alt="A picture containing coelenterate, blue, colorful, hydrozoan  Description automatically generated" height="350" src="img/B17304_12_02.png" width="755"/></figure>
<p class="packt_figref">Figure 12.2: Left, no detail normal; Right, detail normal added</p>
<p class="normal">Detail textures are also interesting as they are generally smaller details from a tileable texture that won’t fit nicely on the texture itself due to the sizing of the model’s texture. To gain the small details, we layered them in the shader.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="239" src="img/B17304_12_03.png" width="826"/></figure>
<p class="packt_figref">Figure 12.3: Detail normals </p>
<p class="normal">Above is the shader we are using<a id="_idIndexMarker815"/> for our detail normal in <em class="italic">Figure 12.3</em>. The way we will break<a id="_idIndexMarker816"/> this down is by following the data connection points and explaining the reasoning per node. To start off, we begin with a UV node.</p>
<p class="normal"><strong class="keyWord">UV node</strong> – This node sets the UV space<a id="_idIndexMarker817"/> you will be manipulating. The dropdown allows you to choose which UV map to manipulate. Since we are using the main UV channel, we will keep it at <code class="inlineCode">UV0</code>. We will take the output of the UV node and input it into a Swizzle node.</p>
<p class="normal"><strong class="keyWord">Swizzle node </strong>– The Swizzle node allows users to take<a id="_idIndexMarker818"/> an input and mix the channels to create an output with the data amount that is needed. You’ll notice that we have set <code class="inlineCode">xy</code> as the output. Our input is a pin line, which refers to a <code class="inlineCode">Vector4</code>, which is shown in the input of the Swizzle as well. We only need the red and green channels in this case, so we just request the <code class="inlineCode">xy</code> or <code class="inlineCode">rg</code> channel and we get a <code class="inlineCode">Vector2</code> output green line. Unity’s <code class="inlineCode">Shader Graph</code> already culls the rest of the channels, so we do not specifically need this, but it’s a good habit to only use the channels that you need to work with. We take this output into a Multiply node.</p>
<p class="normal"><strong class="keyWord">Multiply node</strong> – We use a float parameter<a id="_idIndexMarker819"/> here for the customizability of the UVs down the line alongside the Swizzle input. The <strong class="screenText">Detail Normal Scale</strong> parameter is exposed so we can make a change in the inspector later on, tweaking it to our needs. The output of this will go into the UV channel of a Sample Texture 2D node.</p>
<p class="normal"><strong class="keyWord">Sample Texture 2D node </strong>– Another input to this node<a id="_idIndexMarker820"/> is our texture 2D parameter detail normal. We need to make sure that the <strong class="screenText">Space</strong> option is set to <strong class="screenText">Tangent</strong> as we will be affecting the tangents to reconstruct the normal later on. We will be taking the output and getting to a <code class="inlineCode">Vector2</code> once again, but with a different<a id="_idIndexMarker821"/> method than Swizzle. We will be using a Combine node from the individual channels on the Sample Texture 2D node.</p>
<p class="normal"><strong class="keyWord">Combine node</strong> – Taking in the R and G from the Sample Texture 2D node<a id="_idIndexMarker822"/> output, we combine it to make a <code class="inlineCode">Vector2</code> that is sampling<a id="_idIndexMarker823"/> the texture we want and following the UVs we’re setting. Now we need to take this <code class="inlineCode">Vector2</code> into a scale and bias it into a different range.</p>
<p class="normal"><strong class="keyWord">Scale and Bias nodes (using multiply and subtract)</strong> – The next two nodes are a basic math function<a id="_idIndexMarker824"/> to transform the <code class="inlineCode">(0 to 1)</code> range to a <code class="inlineCode">(-1 to 1)</code> range. We do this by multiplying by 2 and then subtracting 1 on both the X and Y vectors. This is important to us as we may want the normal to appear as concave, or going into the model. After we finish this function, we will take the output into a Normal Reconstruct Z node.</p>
<p class="normal"><strong class="keyWord">Normal Reconstruct Z node </strong>– This node’s purpose is to derive<a id="_idIndexMarker825"/> the correct Z values for the input of R and G from the normal map we chose in the Sample Texture 2D node. </p>
<p class="normal">After this there are three more steps. We will be following individual figures for these next steps. We will take the output of this node and move it into a Normal Strength node.</p>
<p class="normal"><strong class="keyWord">Normal Strength node – </strong>Plugging into the Normal Strength node<a id="_idIndexMarker826"/> are the normals we had as an output from the Normal Reconstruct Z node. There is also a float value for which we created a parameter named <strong class="screenText">Detail Normal Strength</strong>. This can be seen below in <em class="italic">Figure 12.4</em>. We’re using this node so that if the normal map seems like it might have too much detail or is not visually appealing, we can tone it down a little. The parameter we set in the <strong class="screenText">Strength</strong> input allows us to dynamically set the Detail Normal Strength per material.</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated with medium confidence" height="231" src="img/B17304_12_04.png" width="530"/></figure>
<p class="packt_figref">Figure 12.4: Normal Strength node</p>
<p class="normal">We take the output of this and put it into a Normal Blend node.</p>
<p class="normal"><strong class="keyWord">Normal Blend node – </strong>We ultimately want these detail normals<a id="_idIndexMarker827"/> to be layered with the normal of the mesh itself. This is the node that we will be doing this with. </p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="222" src="img/B17304_12_05.png" width="270"/></figure>
<p class="packt_figref">Figure 12.5: Normal Blend node</p>
<p class="normal">It will output a normal map with both normals inside the data. We will then place the output into a Boolean keyword parameter, which we named <code class="inlineCode">Detail Normal?</code>.</p>
<p class="normal"><strong class="keyWord">Boolean keyword </strong>– This Boolean keyword<a id="_idIndexMarker828"/> is designed in a way to allow us to either use a detail normal or not. Since this shader is being used across many materials, we need a way to exclude a detail normal from being needed if a mesh may not have one. We’ve done this by having the input for <code class="inlineCode">On</code> be the blended normals of the mesh and the detail normal. If it’s set to <code class="inlineCode">Off</code> then just the mesh normal will be accepted.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="176" src="img/B17304_12_06.png" width="242"/></figure>
<p class="packt_figref">Figure 12.6: Detail normal Boolean keyword</p>
<p class="normal">The output of this will then<a id="_idIndexMarker829"/> go into the <strong class="screenText">Master Stack Normal</strong> input. When you create a material, if you want to have a detail normal, all you need to do is select <code class="inlineCode">On</code> with the checkbox of the <code class="inlineCode">Detail Normal?</code> parameter.</p>
<p class="normal">Next, we will work through cleaning up the architecture.</p>
<h2 class="heading-2" id="_idParaDest-292">Architecture cleanup</h2>
<p class="normal">The silhouettes of the current buildings<a id="_idIndexMarker830"/> may look good, but does the architecture make sense? This is an interesting design issue with building shapes. We need to ensure that the architecture looks like something that might be built by a living creature. This is a difficult task to get right as the creatures we’re looking to emulate don’t exist! They are fictional creatures, which means we need to be very clear on the path we take when architecting for them. </p>
<p class="normal">We know that they are focused on celestial bodies and time concepts. The shapes of space, planets, and the concept of time need to take part in the silhouettes of the buildings and materials. This may not mean an entire remodel of the pieces but more pushing the shapes so the language stands out enough to fit the culture we’re designing for. </p>
<p class="normal">We also need to get rid of some geometry that won’t ever be seen. This is in order to optimize the game and is important. In games, if you cannot<a id="_idIndexMarker831"/> see it, then it doesn’t need to render. Therefore, we do something called <strong class="keyWord">backface culling</strong>. This means that if you were to look at the back half of a sphere from the inside it would be invisible. </p>
<p class="normal">The backside of an object isn’t rendered as it’s not seen. If you didn’t do that then the sphere would have to render all the inside faces, which would be a waste of precious computer time; we need to render everything else.</p>
<h2 class="heading-2" id="_idParaDest-293">Texture blending</h2>
<p class="normal">When building terrain<a id="_idIndexMarker832"/> or larger objects that need to connect, there<a id="_idIndexMarker833"/> is always a bit of a line that shows that the objects are 3D meshes. This is a common problem, and it can hurt immersion or break the experience if not worked with closely. There are several ways to make this better. You may add another mesh on top of the split. You could also layer or overlap the meshes to make a break in the model to let the player think that it was meant to be slightly broken. You could also perform something called <strong class="keyWord">texture blending</strong>. </p>
<p class="normal">One way that we have done this is through Y-up materials. They may have other names as well, but I call them<a id="_idIndexMarker834"/> that due to using the Y-up axis to blend in materials. What we do is ask the shader to blend in positive Y of the world normal values. We use this value at the Lerp value in our shader where the base texture is on the A channel and B is the moss or snow texture. Let’s look at <em class="italic">Figures 12.7</em> through <em class="italic">12.9</em> below for screenshots of the Shadergraph imagery. In <em class="italic">Figure 12.7</em>, we’re showing some rocks that have a single UV set with a rock texture. These rocks are exactly the same except we’ve duplicated them and rotated them to show<a id="_idIndexMarker835"/> the shader that we put together that places the texture on the world normals.</p>
<figure class="mediaobject"><img alt="A picture containing indoor  Description automatically generated" height="416" src="img/B17304_12_07.png" width="572"/></figure>
<p class="packt_figref">Figure 12.7: Rocks with our Y-up shader applied</p>
<p class="normal">The textures applied to this aren’t final moss textures, but they are designed to be contrasted to the rock to show the textures separately. This allows us to work through the differences easily with visuals. You’ll notice that the rocks are the same, but scaled and rotated. This is a strong<a id="_idIndexMarker836"/> way to provide reuse within your meshes in your scene so you don’t have to model so many rocks! Let’s look at the <code class="inlineCode">Shadergraph</code> on how this works next.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="183" src="img/B17304_12_08.png" width="824"/></figure>
<p class="packt_figref">Figure 12.8: World normal Y-up for T value of Lerp</p>
<p class="normal">We need to plan out how<a id="_idIndexMarker837"/> we will split the rendering of the texture on the mesh. The interesting thing is that we need to make the texture always appear on the top of the mesh regardless of how it’s rotated. We decided to take the normal vector of the world space and then multiply it by a <code class="inlineCode">Vector3</code> that we named <code class="inlineCode">Offset</code>. We want the positive Y, so the default value of our <code class="inlineCode">Offset</code> parameter will be<code class="inlineCode"> (0, 1, 0)</code>. We have two more blending parameters. They are <code class="inlineCode">Blend</code> and <code class="inlineCode">Level</code> and they are both floats. The <strong class="screenText">Blend</strong> parameter is a hard value from 0 to 1. With 0 there is no blending and the rock is the only texture, and with 1 there is no blending where the other texture has a hard line. This is complemented with the <code class="inlineCode">Level</code> parameter. The <code class="inlineCode">Level</code> parameter should be set to <strong class="screenText">Slider</strong> with the min value set to 0 and the max to 100, and the <strong class="screenText">Default</strong> set to 1; these can be set in the <strong class="screenText">Node Settings </strong>in the<strong class="screenText"> Graph Inspector</strong>. We added it in this shader to show that you can add more tools for your artists per material. At the end of this line of data is a saturate. </p>
<p class="normal">This ensures that the data sticks to the 0-1 range, which is what we need to be the T value of the Lerp, which we will go over next.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="576" src="img/B17304_12_09.png" width="716"/></figure>
<p class="packt_figref">Figure 12.9: Texture lookups and Lerp</p>
<p class="normal">Above in <em class="italic">Figure 12.9</em> is our Lerp. Value<a id="_idIndexMarker838"/> is the base texture, and B is the Y-up texture. T is the output<a id="_idIndexMarker839"/> of our saturate in <em class="italic">Figure 12.8</em>. The output of the Lerp is going into our base color. This is only the beginning and you can bolster this by using normal maps and height maps to help mix the channels to make them even more seamless. We currently aren’t using extra maps in this shader, but the concept uses the exact same nodes, just with the additional maps as inputs.</p>
<h2 class="heading-2" id="_idParaDest-294">Environment clutter</h2>
<p class="normal">This is a job all on its own. Those who<a id="_idIndexMarker840"/> work with environment clutter are known in the industry as clutter artists. Their job is to place items to make the environment feel lived in. Currently, we have an environment that is mechanically designed. We know where Myvari needs to be to trigger cinematics. We know how she will work with the physics puzzles. What we don’t know is how the people lived in this space previously. </p>
<p class="normal">What were these spaces used for before there were puzzles to open the doors? Should there be broken things around or did it all break down a long time ago? Should there be spiderwebs or plants growing over some pieces?</p>
<p class="normal">The clutter artists will have a set of small items to place around to make it feel like there was something going on here<a id="_idIndexMarker841"/> at one point in time. This is where we have an opportunity to tell small stories in every section. </p>
<h2 class="heading-2" id="_idParaDest-295">Detail meshes</h2>
<p class="normal">Unity terrain can house detail meshes<a id="_idIndexMarker842"/> to place simple meshes, such as grass or small rocks. We explained this in <em class="chapterRef">Chapter 5</em>, <em class="italic">Environment</em>, in the <em class="italic">Painting details</em> section briefly. The primary reason it’s in this chapter is to explain that there is more work to be done with the details. This is very similar to the clutter artist’s work; however, this isn’t specific to how the space was lived in but to develop the nature. In our case, we are using it for grass and rocks. We need to make sure that the grass and rocks are in a spot that makes sense. </p>
<p class="normal">This is primarily working through the finer details of cleaning up the scene in regard to the detail meshes.</p>
<h2 class="heading-2" id="_idParaDest-296">Effects</h2>
<p class="normal">Polishing effects are similar <a id="_idIndexMarker843"/>to polishing animations. They need to be finessed<a id="_idIndexMarker844"/> to ensure that it is stimulating the correct emotions of the viewer. Most of the effects in this vertical slice are meant to be ambient. We will be covering two effects. The first one will be the blocker to the stairs in the first portion of the cave. The second one will be Myvari’s telekinesis. We chose these two effects to cover in the book as they are quite unique from each other.</p>
<h3 class="heading-3" id="_idParaDest-297">Stair blocker</h3>
<p class="normal">The stair blocker<a id="_idIndexMarker845"/> is there to create an obstacle<a id="_idIndexMarker846"/> for the player in going up the stairs. They need to find a way to disable this so they can progress. We decided to go with arcane energy moving upward in front of the stairs. This will be done purely through a shader, which means we will cover some simple techniques in the Shader Graph. </p>
<p class="normal">The image shown here, in <em class="italic">Figure 12.10</em>, of the effect is static, so jump into the project and look at the first puzzle area in front of the stairs. </p>
<figure class="mediaobject"><img alt="" height="376" src="img/B17304_12_10.png" width="491"/></figure>
<p class="packt_figref">Figure 12.10: Stair blocking effect</p>
<p class="normal">This effect is made by utilizing<a id="_idIndexMarker847"/> a channel-packed texture with three unique cloud <a id="_idIndexMarker848"/>textures. The cloud textures are a grayscale perlin noise in Adobe Photoshop. We took each layer and placed it in the Red, Green, and Blue channels to have three textures in one image. This allows us to use multiple different clouds to build our own noise pattern when animating its UVs. To make this effect work, we needed a way to animate these UVs in multiple ways. We chose an A set and a B set, which we created in our parameters. Let’s go through all of our parameters to make sure we are on the same page. We will explain why we have each parameter as we grow out of this effect as seen in <em class="italic">Figure 12.11</em> below.</p>
<p class="normal">We have <strong class="screenText">Color</strong>, which will be setting the overall color of the arcane magic. <strong class="screenText">Cloud Tex</strong> will be the texture you can use for this shader. We then have <strong class="screenText">Offset</strong> and <strong class="screenText">Tiling</strong> with both an A and B version. We will cover the two parameters soon. Then we have two edges that are used for a Smoothstep node.</p>
<p class="normal">We need to first figure out how to make our texture animate. We will be using <strong class="screenText">Tiling</strong>, <strong class="screenText">Offset</strong>, and <strong class="screenText">Cloud Tex</strong> to perform this initial section of the shader.</p>
<figure class="mediaobject"><img alt="A screenshot of a phone  Description automatically generated with medium confidence" height="307" src="img/B17304_12_11.png" width="197"/></figure>
<p class="packt_figref">Figure 12.11: StairShield parameters from Blackboard</p>
<p class="normal">Looking at <em class="italic">Figure 12.12</em> below, we’ve previously<a id="_idIndexMarker849"/> seen the Sample Texture<a id="_idIndexMarker850"/> 2D and <strong class="screenText">Multiply</strong> nodes. Let’s go over the <strong class="keyWord">Time</strong> node. This node gives you access<a id="_idIndexMarker851"/> to the game time, the sin and cos of the game time, the delta time, and a smoothed delta. We will be using game time and multiplying it by a constant value for our speed. The next node<a id="_idIndexMarker852"/> that is new is the <strong class="keyWord">Tiling And Offset</strong> node. This node is a utility node to help deal with tiling and offsetting the UVs on a mesh that the material will be applied to. We assign the offset <code class="inlineCode">Vector2</code> to the multiplication of time. This will provide a moving value for our offset. This will animate the UVs in the direction you want them to move.</p>
<p class="normal">The last part is to plug the Tiling And Offset node into the UV input of the Sample Texture 2D node. You aren’t seeing the Offset and Tiling B set in this image as it’s the same nodes with different parameters. The reason we want to have multiple sets is that we want to have independent textures with different speeds and UV tiling scales. This makes a dynamic texture in the output.</p>
<figure class="mediaobject"><img alt="A screenshot of a video game  Description automatically generated" height="315" src="img/B17304_12_12.png" width="828"/></figure>
<p class="packt_figref">Figure 12.12: Offset and Tiling for our cloud texture</p>
<p class="normal">We need to put together<a id="_idIndexMarker853"/> a seemingly never-ending tiling pattern. All of these noise patterns <a id="_idIndexMarker854"/>are tiling in both horizontal and vertical<a id="_idIndexMarker855"/> directions. Sometimes this is called a four-way tiling texture. We had planned to move Offset A up in the Y axis by a faster amount and then Offset B a bit slower. We would also tile the B set somewhere between .5 and .75. This would give us a totally different set of noise to layer on top of the other. </p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated with medium confidence" height="578" src="img/B17304_12_13.png" width="476"/></figure>
<p class="packt_figref">Figure 12.13: Crossing the channels</p>
<p class="normal">In <em class="italic">Figure 12.13</em> above we are making three dynamic images<a id="_idIndexMarker856"/> to put together. Both Sample<a id="_idIndexMarker857"/> Texture 2D nodes have different tiling settings and different offsets moving in time. Putting them together with a multiply will inevitably create a living cloud structure as they cross paths. We’re doing that with all three channels <code class="inlineCode">(R, G, B)</code>. Next, we will multiply each of these by 5 to force the entire image channels higher than their original. Then we add together the three channels into one output by adding the first two multiplied nodes, then adding the third one to that, as seen below in <em class="italic">Figure 12.14</em>.</p>
<figure class="mediaobject"><img alt="A screenshot of a video game  Description automatically generated" height="466" src="img/B17304_12_14.png" width="624"/></figure>
<p class="packt_figref">Figure 12.14: Multiply and Add</p>
<p class="normal">Now that we have a single data<a id="_idIndexMarker858"/> stream with movement, we can push values<a id="_idIndexMarker859"/> to make a more interesting effect. We like to smoothstep data to push anything that is close to 0 to 0 and what is close to 1 to 1. This makes the layered data make interesting shapes as seen in <em class="italic">Figure 12.15</em> below. The problem with this is the overall cloudiness is lost in that process, so we want to add in the previous <strong class="screenText">Add</strong> and then saturate it to make sure it’s within the range 0-1 and then multiply it by a color parameter so we change the color in the inspector.</p>
<figure class="mediaobject"><img alt="A screenshot of a video game  Description automatically generated" height="316" src="img/B17304_12_15.png" width="825"/></figure>
<p class="packt_figref">Figure 12.15: Smoothstep and color</p>
<p class="normal">The output of the color<a id="_idIndexMarker860"/> node will go into the base color. We then make a material<a id="_idIndexMarker861"/> that uses the <code class="inlineCode">SH_StairShield</code> shader, then apply it to a plane in the scene where we wanted to show there is something blocking the stairs.</p>
<h3 class="heading-3" id="_idParaDest-298">Shuriken system – stair blocker particles layer</h3>
<p class="normal">We like the way the stair block<a id="_idIndexMarker862"/> feels, but the effects need layers<a id="_idIndexMarker863"/> to feel like well-made art. We also needed to spend a bit of time going over Shuriken itself. This effect will go over some basic portions of Shuriken for producing simple effects to layer into your world. What we will be creating is a stretched sprite moving upward to give more energy to the stair blocker.</p>
<p class="normal">To begin, we wanted to make something with a default item to show the power of particle systems. We are using the <code class="inlineCode">ParticlesUnlit</code> material, which is a simple radial gradient from the center. We sometimes call these “math dots” as they can be created without a texture. We want to spawn particles that have a lot of energy upward but get slowed down near the end of their life and fade out. We will go through the settings below to make this happen; however, we encourage you to look in the project at the particle system and play with the settings. Make some changes to see if you can make something you feel looks better. Share it on Discord!</p>
<p class="normal">The Shuriken system has a large number of parameters inside the modules. We will only be going over the ones we modified and needed to enable for this simple system. We implore you to look through the Unity documentation for an explanation of all the parameters and modules. Let’s look at the main module first, below in <em class="italic">Figure 12.16</em>.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated with medium confidence" height="498" src="img/B17304_12_16.png" width="497"/></figure>
<p class="packt_figref">Figure 12.16: Shuriken main module</p>
<p class="normal">The only parameters<a id="_idIndexMarker864"/> we made changes to here<a id="_idIndexMarker865"/> were <strong class="screenText">Start Lifetime</strong>, changing it to 1.4, and <strong class="screenText">Start Speed</strong>, setting it to 0. We made the lifetime change after making all of the other changes as we didn’t know exactly how long we wanted this particle system to live. The <strong class="screenText">Start Speed</strong> we put to 0 because we knew we wanted to control the velocity. We also modified the color but we’ll override the color in the <strong class="screenText">Color Over Life</strong> module later on. The next module we will go over is <strong class="screenText">Emission</strong>. </p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="173" src="img/B17304_12_17.png" width="487"/></figure>
<p class="packt_figref">Figure 12.17: Emission module</p>
<p class="normal">As seen above in <em class="italic">Figure 12.17</em>, this is the <strong class="screenText">Emission</strong> module. We changed <strong class="screenText">Rate over Time</strong> to 30 to make sure we have plenty<a id="_idIndexMarker866"/> of particles spawning. The emission of your particles<a id="_idIndexMarker867"/> is highly dependent on what you need to convey. For us, we wanted to have enough to add to the stair barrier shader, but not too much that we overpower it. </p>
<p class="normal">We now have a bunch of particles spawning, but we know we want it to be spawning near the bottom of the stair blocker. We will use the <strong class="screenText">Shape</strong> module to restrict the spawning to a location that makes sense to the purpose of the effect.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="295" src="img/B17304_12_18.png" width="547"/></figure>
<figure class="mediaobject"><img alt="A screenshot of a video game  Description automatically generated" height="145" src="img/B17304_12_19.png" width="550"/></figure>
<p class="packt_figref">Figure 12.18: Shape module and shape placed in game</p>
<p class="normal">We chose the shape to be a box as we wanted the particles to spawn from the bottom of the stair blocker and move up from there to follow the flow of the movement. We then needed to get these particles moving. We know we wanted them moving upward quickly, thus setting 100 in <strong class="screenText">Linear Z</strong>, shown in <em class="italic">Figure 12.19</em> below. This blasts them off to space, but we want to add a drag component to our velocity to slow them down near the top. This comes from the limit <strong class="screenText">Velocity over Lifetime</strong>.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="176" src="img/B17304_12_20.png" width="606"/></figure>
<p class="packt_figref">Figure 12.19: Velocity over Lifetime module</p>
<p class="normal"><em class="italic">Figure 12.20</em> below<a id="_idIndexMarker868"/> shows where we will add drag<a id="_idIndexMarker869"/> to our particles. We’re keeping the drag at a constant value and setting it to 5. This value gave it a nice drag. This value wasn’t known beforehand; we just play around with it until it feels like what we’re looking for.</p>
<figure class="mediaobject"><img alt="A picture containing text, electronics, screenshot  Description automatically generated" height="175" src="img/B17304_12_21.png" width="608"/></figure>
<p class="packt_figref">Figure 12.20: Limit Velocity over Lifetime module</p>
<p class="normal">Next, we need to colorize these particles as they are just white math dots going upward. Enabling the <strong class="screenText">Color over Lifetime</strong> module, seen below in <em class="italic">Figure 12.21</em>, allows you to define a gradient where the left side is the beginning of the particle’s life, and the right side is the end of the particle’s life, including the alpha of the particle if your material is set up to accept alpha.</p>
<figure class="mediaobject"><img alt="" height="51" src="img/B17304_12_22.png" width="561"/></figure>
<p class="packt_figref">Figure 12.21: Color over Lifetime</p>
<p class="normal">Clicking on the gradient will pop up a gradient editor, which is seen below in <em class="italic">Figure 12.22</em>. The top of the gradient is the alpha and the bottom is for the color. Try to change the color on them to see it change the particles!</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="207" src="img/B17304_12_23.png" width="547"/></figure>
<p class="packt_figref">Figure 12.22: Gradient Editor</p>
<p class="normal">Now we set the render<a id="_idIndexMarker870"/> mode from the <strong class="screenText">Renderer</strong> module. Since <a id="_idIndexMarker871"/>we knew that we wanted the particles from the beginning to be stretched from the velocity, we changed this setting to <strong class="screenText">Stretched Billboard</strong> very early. If you decided to follow along with this particle creation, your particles would look like colored dots instead of streaks. </p>
<p class="normal">Changing the <strong class="screenText">Render Mode</strong> to <strong class="screenText">Stretched Billboard</strong> will fix that, as shown below in <em class="italic">Figure 12.23</em>. We also set <strong class="screenText">Speed Scale</strong> to 0.1 as they are moving very fast, which makes them stretch very far if you go much higher than 0.1. </p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="247" src="img/B17304_12_24.png" width="609"/></figure>
<p class="packt_figref">Figure 12.23: Renderer module</p>
<p class="normal">By going through these, we have just shown a simple example of a stretched particle to show some of the systems available. The power comes into play when you add shaders to the particles. A well-designed visual effect can trigger the emotion of an action happening. Though this may seem daunting at first, if you break down what you need, it becomes more of a fun time playing with the settings to get the right feel for your need. You will see other Shuriken effects around the level when you get into the project. Feel free to break them apart and put them back together to learn about the differences in the settings and how they play a part in the role of the visual effect.</p>
<p class="normal">We will be going over VFX Graph<a id="_idIndexMarker872"/> in the next section. This is another particle system<a id="_idIndexMarker873"/> creator that allows us to create GPU particles. This is a different way of working as it has its own system design and UI outside of the inspector. Let’s get into an example we are using in the project.</p>
<h3 class="heading-3" id="_idParaDest-299">VFX Graph – Myvari’s telekinesis</h3>
<p class="normal">Telekinesis can look like anything. We want<a id="_idIndexMarker874"/> it to seem as though Myvari<a id="_idIndexMarker875"/> is harnessing celestial energy that is flowing from her toward the object she is controlling. For this portion, we will cover how we set up the entire VFX Graph, shader, and a bit of code for implementation. </p>
<p class="normal">We will assume that you have the VFX Graph package installed already and have opened up the <code class="inlineCode">FX_BeamSetup</code> <strong class="screenText">Visual Effect Asset</strong>.</p>
<p class="normal">The <strong class="screenText">Spawn</strong> context starts out by default with a constant spawn rate block in this context. We want to just burst one time with 32 particles that we want to manipulate as long as the strip is up. We deleted the constant spawn and put in place a <strong class="screenText">Single Burst</strong> block instead, as seen in <em class="italic">Figure 12.24</em> below.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="362" src="img/B17304_12_25.png" width="527"/></figure>
<p class="packt_figref">Figure 12.24: Spawn context</p>
<p class="normal">The number 32 wasn’t a special number from the beginning. We weren’t sure how many we would need, but it’s easy enough to add more during the process of creating the strip. Below in <em class="italic">Figure 12.25</em> is our <strong class="screenText">Initialize</strong> context. We need to set <strong class="screenText">Particle Per Strip Count </strong>to the same number as the spawn in the burst above. We want a <strong class="screenText">Set Size</strong> block and a <strong class="screenText">Set Custom Attribute </strong>block. This attribute block<a id="_idIndexMarker876"/> will be a float data type and we called it <code class="inlineCode">InterpolatedPosition</code>. </p>
<p class="normal">The reason<a id="_idIndexMarker877"/> we called it this is that we want to have an index of every particle so we can individually place them where we want them. </p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="521" src="img/B17304_12_26.png" width="546"/></figure>
<p class="packt_figref">Figure 12.25: Initialize context</p>
<p class="normal">We can see in <em class="italic">Figure 12.26</em> below that we are getting the particle index and then dividing it by one less than the total amount. The index starts at 0, so we need to start from one below the number we spawned. This gives us a value that we can work with and is stored in the float custom attribute we made.</p>
<figure class="mediaobject"><img alt="A screenshot of a video game  Description automatically generated" height="261" src="img/B17304_12_27.png" width="540"/></figure>
<p class="packt_figref">Figure 12.26: Particle Index nodes</p>
<p class="normal">Now we have a particle strip<a id="_idIndexMarker878"/> that needs to have a position to go to. We will make two transform parameters in the blackboard<a id="_idIndexMarker879"/> just like we do in the Shader Graph. We named them <code class="inlineCode">BeamStart</code> and <code class="inlineCode">BeamEnd</code>. We will Lerp the particles’ positions from the beam start to the beam end according to the interpolated position float we initialized with. Looking at <em class="italic">Figure 12.27</em> below, you can see how we connect them together. The output of the Lerp will go to the <strong class="screenText">Update Context</strong>.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="336" src="img/B17304_12_28.png" width="633"/></figure>
<p class="packt_figref">Figure 12.27: Positioning the beam</p>
<p class="normal">In the update context we have two blocks as seen below in <em class="italic">Figure 12.28</em>: <strong class="screenText">Set Position</strong> and <strong class="screenText">Add Position</strong>. We will be adding the output of the Lerp for their position into this block. There is one trick that will make some strange movement happen. On the <strong class="screenText">Set Position</strong> block there is a small <em class="italic">w</em> in the middle. If it is an <em class="italic">L,</em> then that means it’s moving the local position. This will cause double transforms when moving around the GameObjects. If you click on the <em class="italic">L</em> it will change to <em class="italic">w</em>, which stands for world space. It is fine to leave <strong class="screenText">Add Position</strong> in local space.</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated with medium confidence" height="241" src="img/B17304_12_29.png" width="485"/></figure>
<p class="packt_figref">Figure 12.28: Update context</p>
<p class="normal">Currently we have a straight<a id="_idIndexMarker880"/> beam from start to end. This is fine for testing, but we need something<a id="_idIndexMarker881"/> a bit more fun. Let’s add some turbulence so it isn’t so rigid. We will use the Add Position block and the input for that will be some manipulations of 3D noise. This has a few more nodes to make the right data for nice turbulence, but we will walk through them.</p>
<p class="normal">Looking at <em class="italic">Figure 12.29</em> below, these five nodes are all we need. We want to get our current position, then add that to time. We have a <strong class="screenText">Multiply</strong> node in between there so we could speed up or slow down the time value. This could be a variable that’s tunable as well. After <strong class="screenText">Add</strong> is a <strong class="screenText">Perlin Noise 3D</strong>. The values here are purely subjective. Place your coordinates in the <strong class="screenText">Coordinate</strong> slot and then place the output derivates into the <strong class="screenText">Add Position</strong> block input in the <strong class="screenText">Update</strong> context. From there, play around with the values until it gives you the nice turbulence you want. There is a problem with this approach. This will update every particle, including the beam start and beam end. This feels odd as we wanted it to come from our character’s hand. </p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="303" src="img/B17304_12_30.png" width="775"/></figure>
<p class="packt_figref">Figure 12.29: 3D Perlin Noise for turbulence</p>
<p class="normal">To ensure that the beam start and end are independent of this, we went with a simple gradient to tell the position whether or not it should be using the turbulence. Looking at <em class="italic">Figure 12.30</em>, we see that we take the interpolated position value and sample it across that interpolation with time. The gradient now acts as a transfer to which particle will be affected. The 0 value at the beginning and end of the strip will make 0 values multiplied with the derivatives from the noise generator. Now we plug this into the <strong class="screenText">Add Position</strong> block.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="164" src="img/B17304_12_31.png" width="825"/></figure>
<p class="packt_figref">Figure 12.30: Mask for the turbulence</p>
<p class="normal">We’re in the home stretch<a id="_idIndexMarker882"/> for setting up the VFX Graph portion. The <strong class="screenText">Output</strong> context<a id="_idIndexMarker883"/> is shown in <em class="italic">Figure 12.31</em>. By default this will be an <strong class="screenText">Output Particle Quad</strong>. This won’t do us any good, so delete it if you have it on your VFX Graph and press the spacebar to make a new node. Then type <code class="inlineCode">particlestrip</code>. You’re looking for the <strong class="screenText">Output ParticleStrip Quad</strong>. The one below has unlit in the name; this is due to the material being used. </p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="430" src="img/B17304_12_32.png" width="498"/></figure>
<p class="packt_figref">Figure 12.31: Output ParticleStrip Quad context</p>
<p class="normal">The shader is a duplicate of <code class="inlineCode">SH_StairShield</code> with<a id="_idIndexMarker884"/> one change. In the <strong class="screenText">Graph</strong> inspector, the <strong class="screenText">Support VFX Graph</strong> Boolean is set to true. This shader has enough versatility to get the job done for now. We may change the texture before its final use, but for now it has what we need to get it going. We then assign<a id="_idIndexMarker885"/> it to the Shadergraph attribute in the output context. This will expose the parameters in the shader.</p>
<p class="normal">There are two more steps to finalize this effect. We need to create the GameObject’s beam start and beam end, and then implement this effect by placing the locations of the GameObjects during gameplay.</p>
<p class="normal">To start, let’s make our prefab. Below in <em class="italic">Figure 12.32</em> we made an empty GameObject and named it <code class="inlineCode">Telekinesis</code>. Then we placed the beam setup object as a child and set its position at <code class="inlineCode">0, 0, 0</code>. Then we created two more empty GameObjects and named them <code class="inlineCode">BeamStart</code> and <code class="inlineCode">BeamEnd</code>. We also set these positions at <code class="inlineCode">0, 0, 0</code>. </p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="109" src="img/B17304_12_33.png" width="215"/></figure>
<p class="packt_figref">Figure 12.32: Telekinesis prefab</p>
<p class="normal">There is a component you can add to VFX Graph<a id="_idIndexMarker886"/> assets called <strong class="screenText">VFX Property Binder</strong>. Add this component to the <code class="inlineCode">FX_BeamSetup</code> GameObject. We then create two bound properties to the transform and name them the same as the properties in the VFX Graph (<code class="inlineCode">BeamStart</code> and <code class="inlineCode">BeamEnd</code>). Drag the GameObject into the <strong class="screenText">Target</strong> slot to reference the GameObject’s transform. Do the same for <code class="inlineCode">BeamEnd</code>. This will look like <em class="italic">Figure 12.33</em> below. </p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="301" src="img/B17304_12_34.png" width="566"/></figure>
<p class="packt_figref">Figure 12.33: VFX Property Binder component</p>
<p class="normal">We now need to go over the implementation. The considerations<a id="_idIndexMarker887"/> here are that the start of the beam needed to come from our character’s left hand. We also know we need the end to be attached to the item we are controlling with physics. We also need to turn on and off the visual effect only when the interact button is interacting with a physics puzzle item. We will be working with <code class="inlineCode">DragRigidBody.cs</code>.</p>
<p class="normal">This script takes the center of the screen as a point of reference and if you are within range of the physics item that you can interact with, it will give Myvari control of that Rigidbody from the use of the physics puzzle pieces scripts we went over in <em class="chapterRef">Chapter 6</em>, <em class="italic">Interactions and Mechanics</em>.</p>
<p class="normal">Fields to add:</p>
<pre class="programlisting code"><code class="hljs-code">public VisualEffect telekinesis;
public Transform leftWristLoc;
public Transform beamStart;
public Transform beamEnd;
</code></pre>
<p class="normal">These will be assigned in the editor and should be self-explanatory except possibly the <code class="inlineCode">leftWristLoc</code>. This transform<a id="_idIndexMarker888"/> is from Myvari’s joints in her hierarchy. Expand her hierarchy and drag the left wrist onto this slot in the inspector.</p>
<p class="normal">In the update, we want to turn off the beam if the interact button is released.</p>
<pre class="programlisting code"><code class="hljs-code">if (control.wasReleasedThisFrame)
    {
        //Release selected Rigidbody if there any
        selectedRigidbody = null;
        telekinesis.enabled = false;
    }
</code></pre>
<p class="normal">After this we need to work with the <code class="inlineCode">FixedUpdate</code>. We are working with physics, so we need to ask the program to check if we have a Rigidbody, and on the <code class="inlineCode">FixedUpdate</code>, we will turn on the beam if true and set the positions of the <code class="inlineCode">beamStart</code> and <code class="inlineCode">beamEnd</code> at every <code class="inlineCode">FixedUpdate</code> loop with the physics.</p>
<pre class="programlisting code"><code class="hljs-code">if (selectedRigidbody)
    {
        telekinesis.enabled = true;
        …
        beamStart.position = leftWristLoc.position;
        beamEnd.position = selectedRigidbody.gameObject.transform.position;
    }
</code></pre>
<p class="normal">This is it! Save your files, get back<a id="_idIndexMarker889"/> in the editor, and assign the transforms and visual effects to the script. This script is located in <code class="inlineCode">Main Camera</code>. <em class="italic">Figure 12.34</em> below shows the selected object with the script.</p>
<figure class="mediaobject"><img alt="Text  Description automatically generated" height="440" src="img/B17304_12_35.png" width="457"/></figure>
<p class="packt_figref">Figure 12.34: Main Camera location for telekinesis scripting</p>
<p class="normal">Particle effects and shader work are always interesting problems to be handled with care. Too much of a good thing ends up not feeling good. When working through a level, take a moment to think about the tiny details and see if it makes sense to add small movements to sell the experience. </p>
<p class="normal">From the above two effects, there<a id="_idIndexMarker890"/> is quite a bit of thought put into each visual effect<a id="_idIndexMarker891"/> no matter the size of the effect. Take your time going through each effect in the game to break down the parts.</p>
<h2 class="heading-2" id="_idParaDest-300">Cinematics</h2>
<p class="normal">In our project, we’re using cinematics<a id="_idIndexMarker892"/> for three purposes. The first one is to explain<a id="_idIndexMarker893"/> that the area has been around a long time, so the areas are fragile. The second one is showing the player that Myvari has innate powers by her defending herself against a falling boulder. The third cinematic is the ending scene when she puts on her tiara and goes through the portal after finishing the final puzzle. </p>
<p class="normal">The way that we work through cinematics is we export the models while they are in place in the environment. This allows us to make sure that our cinematics match with the environment with as much <a id="_idIndexMarker894"/>precision as possible.</p>
<h2 class="heading-2" id="_idParaDest-301">Secondary animation</h2>
<p class="normal">Sometimes there needs<a id="_idIndexMarker895"/> to be additional animation that is easier to simulate than it is to rig and hand-key. Hair is a good example of this. The actions that hair takes are a secondary animation after momentum is gained. Hand-keying this is possible but takes a lot of patience and can be done instead with physics. We will be using Unity’s Spring Joint component for this. There are also several assets in Unity’s Asset Store that have been made to make this process more robust. If you need just simple physics for your secondary animation, it can be done through the Unity physics Rigidbody component, the Spring Joint component, and capsule colliders.</p>
<h1 class="heading-1" id="_idParaDest-302">Lighting</h1>
<p class="normal">We’ve decided to put lighting<a id="_idIndexMarker896"/> in the finishing touches, but this could have had its own book. This is one of those topics that are a massive rabbit hole. We wanted to go over some basics of lighting here and the reason why it’s important to pay attention to lighting, as well as highlighting a few polishing tools and how to use lighting in Unity.</p>
<p class="normal">First, we need to explain that lighting is an art. The purpose of lighting includes defining 3D form, providing mood, and designing methods for gameplay. After we go through a few design thoughts on lighting, we will take a tour of the Unity mixed lighting, lightmaps, reflection, and light probes.</p>
<h2 class="heading-2" id="_idParaDest-303">3D form</h2>
<p class="normal">Without lighting, a 3D form<a id="_idIndexMarker897"/> is flat. In fact, we use unlit shaders for most effects. One reason is that we don’t need to add shadowing and lighting for small shiny effects that will only be on screen for a short time. They are flat and don’t need lighting to help define them; their texture shape does that work for it. </p>
<h2 class="heading-2" id="_idParaDest-304">Providing mood</h2>
<p class="normal">This goes along with the design<a id="_idIndexMarker898"/> of the areas but is focused specifically on the lighting. Is the alleyway getting darker as you walk down it? This could push a sense of danger or nervousness in your player. Do you want unnatural lighting colors around certain areas to give an arcane feeling inside a mage’s house? Completely possible! All of these decisions should be thought about when placing lighting. In the same vein as mood, we could want our lights to define the gameplay.</p>
<h2 class="heading-2" id="_idParaDest-305">Gameplay design</h2>
<p class="normal">Gameplay can be defined<a id="_idIndexMarker899"/> through light in many ways. In fact, your entire game could be designed around light. </p>
<p class="normal">Horror games often use light sources as a way to push away enemies, but it’s limited to a small timer as your batteries are inevitably running out! Taking a unique route, an older game named Boktai used a light sensor peripheral for the Game Boy to charge up your weapons, and if you played it in the dark the game was more difficult.</p>
<p class="normal">These concepts are a bit on the edge of gameplay elements. We could just use light to give the player an idea of where to go, or where to stay away from. We probably have a good idea now about general concepts of lighting design and how it can influence the player’s experience. Let’s dig into Unity lighting.</p>
<h2 class="heading-2" id="_idParaDest-306">Unity lighting</h2>
<p class="normal">To get to a polished <a id="_idIndexMarker900"/>state we need to go over<a id="_idIndexMarker901"/> the basics first. This will be an overview of what you are capable of doing in Unity for lighting, and then we will be going over what settings and uses we have for our project. Built-in renderer, URP, and HDRP lighting are all different from each other. We will be talking about URP lighting specifically. We will also be pushing for a certain feel and explaining features that helped us achieve the desired look that we aimed for in our vertical slice. Each lighting asset can be configured in different ways, which means that these steps will only give as much help as needed to get your feet wet with lighting. After you go through this and play around with what we explain, we highly recommend reading the documentation for other lighting objects for different rendering pipelines depending on the needs of your project. Now that we’ve gone over the construct of lighting here, we will begin by talking about mixed lighting.</p>
<h3 class="heading-3" id="_idParaDest-307">Mixed lighting</h3>
<p class="normal">We’re taking a slight shortcut<a id="_idIndexMarker902"/> here by going into mixed lighting from the start. To utilize mixed lighting properly, you need to be using indirect baked lighting and dynamic lighting. We will touch on both right now, then get back to mixed lighting.</p>
<h4 class="heading-4">Indirect baked lighting</h4>
<p class="normal">Real-time lights, that are casting<a id="_idIndexMarker903"/> light rays onto static GameObjects bouncing off geometry in the world, will be baked onto a lightmap. Those terms are new! Static game objects are defined by selecting the <strong class="screenText">Static</strong> checkbox in the inspector, as seen in <em class="italic">Figure 12.35</em> below.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="321" src="img/B17304_12_36.png" width="427"/></figure>
<p class="packt_figref">Figure 12.35: Static checkbox</p>
<p class="normal">hen this is selected, when the game is baking its lightmaps into the Lightmap UVs, it will know to add this to the items to bake. You would only choose this to be static if you know for certain you will never move the GameObject that you would make static. We are fairly certain this concrete fence will remain solid the entire game, so we selected it as static. The next term is lightmap. This is a secondary set of UVs that are not allowed to overlap with the object that you want to bake the lighting onto. When you import a model, you can let Unity generate the lightmap UVs for you, and it does a decent job at taking care of this. You can do this by selecting the FBX for the 3D model and choosing <strong class="screenText">Generate Lightmap UVs</strong>, as in <em class="italic">Figure 12.36 </em>below.</p>
<p class="normal">When you select the checkbox, Lightmap UV settings will show up. These values are the average per object<a id="_idIndexMarker904"/> you have in your scene. These settings will do a decent job of setting up the basics but you may need to look into each attribute to make sure each object receives light the way you would expect it to.</p>
<figure class="mediaobject"><img alt="A screenshot of a computer  Description automatically generated with medium confidence" height="256" src="img/B17304_12_37.png" width="515"/></figure>
<p class="packt_figref">Figure 12.36: Generate Lightmap UVs option</p>
<p class="normal">That is for the objects that receive light. As for the lights, you can set any available light to be a baked light. Directional, spot, point, and area light are all available to be added to lightmaps when generating or baking lighting.</p>
<h4 class="heading-4">Dynamic lighting</h4>
<p class="normal">This is also referred<a id="_idIndexMarker905"/> to as real-time lighting. Real-time lighting<a id="_idIndexMarker906"/> has to deal with real-time shadows and many settings involved with this. Real-time lighting is applied to any item that wasn’t chosen as static. Skeletal meshes are always real time as they cannot be static. Their nature is to move!</p>
<p class="normal">In our URP asset we can see that in the <strong class="screenText">Shadows</strong> settings, we can set the distance to where the quality of shadows goes down. Below in <em class="italic">Figure 12.37</em> you can see this range in the <strong class="screenText">Shadows</strong> section.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="501" src="img/B17304_12_38.png" width="482"/></figure>
<p class="packt_figref">Figure 12.37: URP Shadows settings</p>
<p class="normal">Each real-time light <a id="_idIndexMarker907"/>will use these settings<a id="_idIndexMarker908"/> for the shadows. <strong class="screenText">Cascades</strong> are how many times the light quality goes down. It’s set in meters by default. This can help us design the limits as we know how tall our characters should be in general. 1 Unity unit is by default 1 meter. You could set up a test scene to see what the shadows would look like for the distance of each cascade to help make these decisions.</p>
<p class="normal">Something that’s unique to real-time lights is the four lights that are available. </p>
<p class="normal">The directional, point, and spot lights are available for real-time lighting information. Area lights cannot create real-time shadows.</p>
<p class="normal">Now that we’ve gone over the basics of real-time and indirect lighting, we need to get back into mixed lighting mode. First, we need to let you know how to put lights on the scene. In <em class="italic">Figure 12.38</em> below you can see the list of lights. You can access this menu just as you create any GameObject, by right-clicking in the hierarchy or going to the GameObject menu and hovering over the <strong class="screenText">Light</strong> option to get the submenu seen in <em class="italic">Figure 12.38</em>.</p>
<figure class="mediaobject"><img alt="A picture containing graphical user interface  Description automatically generated" height="200" src="img/B17304_12_39.png" width="525"/></figure>
<p class="packt_figref">Figure 12.38: Light options</p>
<p class="normal">Now we need to get back<a id="_idIndexMarker909"/> to mixed lighting. We’ve talked about both lighting modes. Some games may only use baked lighting while some games might only use real-time lighting. The majority will use both in URP. When you select any light that you make, the inspector has an option to choose real-time, mixed, or baked. Remember, baked means baked indirect light. The best part of mixed is that it allows the light to be baked where it is, but acts as dynamic when introduced to a non-static GameObject. This is useful for the directional light. This light acts like the sun, so we want it to bake for the static items, but be dynamic for the character or anything non-static. You can see this selected within the inspector in <em class="italic">Figure 12.39</em> below.</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="229" src="img/B17304_12_40.png" width="487"/></figure>
<p class="packt_figref">Figure 12.39: Directional light set to mixed</p>
<p class="normal">Even after you’ve set all the meshes to static that you need to, and placed lights and set them to either real-time, baked, or mixed, you still need to set up your lighting settings within the lighting window. To get there, use the screenshot below, in <em class="italic">Figure 12.40</em>.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="442" src="img/B17304_12_41.png" width="520"/></figure>
<p class="packt_figref">Figure 12.40: Path to the lighting window</p>
<p class="normal">Within the window <a id="_idIndexMarker910"/>that pops up, you will have several tunable settings. These settings are going to be unique for every project. We know that we want some nice shadow fidelity. This means we need more samples and higher resolution for our lightmaps. We’re also going to be fairly close to the character in the game and during cinematics, which is still real time. These factors need to be considered when thinking about your settings. You could potentially crank up the settings and have nice shadows with a huge light bake, but then your real-time shadows might not be able to handle it and will be blocky, which will cause the game to have a strange feel to it. It’s good to consider the system your game will be played on and thoroughly test the performance again after adding more lights and lightmaps.</p>
<p class="normal">There is another tool to use to gain more accurate real-time lighting information inside Unity without needing to have a lot of real-time lights. It is called light probes. Let’s take a look at that tool.</p>
<h3 class="heading-3" id="_idParaDest-308">Light probes</h3>
<p class="normal">Creating light probes<a id="_idIndexMarker911"/> is as easy as going to your <strong class="screenText">Light</strong> GameObject group<a id="_idIndexMarker912"/> and selecting <strong class="screenText">Light Probe Group</strong>. </p>
<p class="normal">You can see this in the options three figures above in <em class="italic">Figure 12.38</em>. What this tool does is sample the lighting information at points in 3D which are shown in <em class="italic">Figure 12.42</em>. That information is then used in real time even if the lighting is baked information only. This is very helpful if you want to use the coloration<a id="_idIndexMarker913"/> from an area light (which is only baked) and add it to a character. Think about a light on a wall where you don’t need to cast a shadow<a id="_idIndexMarker914"/> or for it to be real time. Instead of being resource-intensive, you can just use light probes around that area and it will help pick up on non-static geometry in real time. </p>
<p class="normal">To set this up though, you need to place light probes by hand. There are assets on the Asset Store to automatically place them but keep in mind that anything automated in the entertainment industry needs to have an artist’s input to achieve what the experience needs.</p>
<p class="normal"><strong class="screenText">Light Probe Group</strong> when editing the group looks like <em class="italic">Figure 12.41</em> below in the inspector.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="217" src="img/B17304_12_42.png" width="538"/></figure>
<p class="packt_figref">Figure 12.41: Light Probe Group component in inspector</p>
<p class="normal">You can add, delete, select all, and duplicate selected. When you’re placing Light Probes, just know that they are averages of multiple color locations. These aren’t a perfect representation of the light in one area, but more of an approximation to give a bit of extra boost to ensure the mood is kept for the real-time actors in the game. With that being said, add probes until they form a nice lattice. The more you have, the more computational power it will take. For each project, as usual, it will depend on the system to know how many light probes will be allowed for performance.</p>
<p class="normal">After you’ve placed them, you can either press play and walk around, or just drag your non-static GameObjects around the scene to see the lighting shift slightly. </p>
<p class="normal">Here is an example of the initial hallway of our vertical slice’s light probe lattice in <em class="italic">Figure 12.42</em>.</p>
<figure class="mediaobject"><img alt="A picture containing indoor, athletic game, tennis  Description automatically generated" height="296" src="img/B17304_12_43.png" width="596"/></figure>
<p class="packt_figref">Figure 12.42: Light Probe lattice</p>
<p class="normal">This can take some time<a id="_idIndexMarker915"/> and will be done after placing your lights. If you change<a id="_idIndexMarker916"/> up your lighting configuration, make sure to rethink your light probes as well afterward. There is just one last thing before we get to polishing sound. We want to go over reflections.</p>
<h3 class="heading-3" id="_idParaDest-309">Reflection probe</h3>
<p class="normal">There are materials in the world<a id="_idIndexMarker917"/> that reflect the color of the environment. These are metallic and/or glossy materials. The problem is, what do they reflect? I’m happy you asked that because Unity initially will create a reflection map of just the skybox so there is something reflected in those materials. There is another tool you can add to your scene, which is a reflection probe that will allow you to designate a volume that has the reflection data in that area. You can also have overlapping volumes.</p>
<p class="normal">This is an interesting issue as it’s not a perfect representation as the probe’s reflection position is from the center of the position of that probe. If you have a large area, and you need to be very close to the reflections while also needing that reflection to be accurate, you will need multiple reflection probes, with each probe’s volumes only as large as you need them. The smaller the volume, the crisper the reflection image. These types of things won’t be very clear until you have run around the world and looked for this or worked through the cinematics of your game and seen a strange-looking reflection. There is a small caveat here; you can create real-time reflections, but they are very expensive. These should be used with caution. That is until we all have quantum computers in our houses.</p>
<p class="normal">To create a reflection<a id="_idIndexMarker918"/> probe, the option is in the same place as all the rest of the lighting, in the GameObject menu under <strong class="screenText">Lighting</strong>. </p>
<p class="normal">When you create the probe and place it in the location you want to reflect around, you will have to then use the inspector to edit the volume, which looks like the below <em class="italic">Figure 12.43</em>.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="344" src="img/B17304_12_44.png" width="477"/></figure>
<p class="packt_figref">Figure 12.43: Reflection Probe component in the inspector</p>
<p class="normal">The top-center two icons are for editing and moving the volume. Selecting the points icon gives you access to the volume’s shape to shrink and grow it to your needs. The type can be <strong class="screenText">Baked</strong>, <strong class="screenText">Real-time</strong>, or <strong class="screenText">Custom</strong>. <strong class="screenText">Baked</strong> will only be baked once and cannot change during runtime. <strong class="screenText">Real-time</strong> changes as the game is running every frame. <strong class="screenText">Custom</strong> allows you to place your own custom cubemap instead of sampling the environment. This could be useful if you want to distort the environment in the reflections! The cubemap settings are to tweak the cubemap’s scale and parameters to increase the needed fidelity at a performance cost. </p>
<p class="normal">One of the most important settings is the <strong class="screenText">Importance</strong> setting! This setting is an integer that you set to tell the game which reflection probe is being displayed when there are overlapping reflection volumes.</p>
<p class="normal">The way this works is that the higher the number, the higher the importance. If you have two overlapping volumes, such as inside the entrance to a cave versus right outside of it, you would then set the hallway to importance level 2. This way when you enter the volume that is of higher importance, the reflection probe will switch to it. This can cause some popping on very close reflection surfaces. Play through your game and pay attention to reflections when they transition.</p>
<p class="normal">Adding lighting<a id="_idIndexMarker919"/> overall is a fun task. It can greatly improve the graphical quality of your game and there are some great tricks to set that up. Next up is sound polish.</p>
<h1 class="heading-1" id="_idParaDest-310">Sound polish</h1>
<p class="normal">We have a few things<a id="_idIndexMarker920"/> we can do to make sounds in our game more believable. Sound polish comes down to tweaking the volume of sounds, changing the minimum and maximum attenuation distances, and even replacing sounds that you feel don’t sound good.</p>
<p class="normal">These are all things we’ve adjusted throughout the project already. For example, on one of our first ambiences, we can adjust the volume or pitch to see what feels right. Or we can change the minimum or maximum distances on the attenuation, add sounds that we may have missed, make sure that certain sounds that are more important are louder than others, etc.</p>
<p class="normal">Overall, mixing and sound polish is a very iterative process of just manipulating the values and replacing sounds with other sounds to get a feel for what’s best. You never know how a sound will fit with the rest of the sounds until you place it in the game.</p>
<h3 class="heading-3" id="_idParaDest-311">Triggering sound through animation events</h3>
<p class="normal">We wanted to show<a id="_idIndexMarker921"/> you how to add sound <a id="_idIndexMarker922"/>to an animation event. It’s quite an easy process as we already know how to add animation events, and how to trigger sounds using <code class="inlineCode">AudioSource</code> components. We’ll be adding footstep sounds to our character walking.</p>
<p class="normal">First let’s select our character, the <code class="inlineCode">MyvariWithCameraRig</code>:</p>
<figure class="mediaobject"><img alt="" height="378" src="img/B17304_12_45.png" width="750"/></figure>
<p class="packt_figref">Figure 12.44: MyvariWithCameraRig</p>
<p class="normal">Then let’s drop down<a id="_idIndexMarker923"/> into its child objects<a id="_idIndexMarker924"/> to find the <code class="inlineCode">SM_Myvari</code> GameObject. Here you will see the animator component! We only need a few things here. </p>
<p class="normal">First, let’s create a new script and call it <code class="inlineCode">AnimationSounds</code>, then we’ll put this right below our <strong class="screenText">Animator Component</strong>. After this, we’ll add our <code class="inlineCode">AudioSource</code> component. It should all look something like <em class="italic">Figure 12.45</em> below:</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="865" src="img/B17304_12_46.png" width="475"/></figure>
<p class="packt_figref">Figure 12.45: SM_Myvari inspector window</p>
<p class="normal">Before we continue forward, let’s add a function<a id="_idIndexMarker925"/> to our <code class="inlineCode">AnimationSounds</code> script. Remove<a id="_idIndexMarker926"/> the <strong class="screenText">Start</strong> and <strong class="screenText">Update</strong> functions and add a new one called <code class="inlineCode">PlaySound()</code>. Above this new function, declare a new public variable called <code class="inlineCode">public AudioSource</code> <code class="inlineCode">AnimSound</code>.</p>
<figure class="mediaobject"><img alt="Text  Description automatically generated" height="218" src="img/B17304_12_47.png" width="459"/></figure>
<p class="packt_figref">Figure 12.46: Our new AnimationSounds.cs</p>
<p class="normal">Now, inside of our <code class="inlineCode">PlaySound()</code> function, let’s add <code class="inlineCode">AnimSound.Play()</code>.</p>
<p class="normal">Next, in the inspector, we can<a id="_idIndexMarker927"/> add the <code class="inlineCode">AudioSource</code> component<a id="_idIndexMarker928"/> to the serialized field in the <code class="inlineCode">AnimationSounds.cs</code> component and add a footstep sound effect!</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="125" src="img/B17304_12_48.png" width="673"/></figure>
<p class="packt_figref">Figure 12.47: AnimationSounds.cs script in the inspector</p>
<p class="normal">Awesome! Now we can move on to tagging our animation with events.</p>
<h2 class="heading-2" id="_idParaDest-312">Tagging animations with events for sound</h2>
<p class="normal">One big problem that we have<a id="_idIndexMarker929"/> with adding animation events<a id="_idIndexMarker930"/> is that we can’t add events<a id="_idIndexMarker931"/> directly through the animation window, so we’ll have to open up the FBX file inside of Unity. </p>
<p class="normal">The best way to do this is to go into <strong class="screenText">Assets</strong> &gt; <strong class="screenText">Animations</strong> and select the <code class="inlineCode">Myvari_Walk_Basic</code> FBX.</p>
<figure class="mediaobject"><img alt="Application, icon  Description automatically generated" height="234" src="img/B17304_12_49.png" width="667"/></figure>
<p class="packt_figref">Figure 12.48: The project explorer in Unity in the Assets &gt; Animations folder</p>
<p class="normal">Next we’ll scroll down<a id="_idIndexMarker932"/> on the inspector<a id="_idIndexMarker933"/> until we<a id="_idIndexMarker934"/> reach the <strong class="screenText">Events</strong> dropdown.</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" height="810" src="img/B17304_12_50.png" width="650"/></figure>
<p class="packt_figref">Figure 12.49: Animation clip inspector window</p>
<p class="normal">Open up that <strong class="screenText">Events</strong> dropdown, and also<a id="_idIndexMarker935"/> open up the <strong class="screenText">Preview</strong> window<a id="_idIndexMarker936"/> at the bottom<a id="_idIndexMarker937"/> of the inspector. </p>
<p class="normal">It might be hidden at the bottom of the inspector, but you can click and drag from the bottom to bring it up! It should look something like <em class="italic">Figure 12.50</em>:</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="784" src="img/B17304_12_51.png" width="694"/></figure>
<p class="packt_figref">Figure 12.50: Animation Clip inspector window preview</p>
<p class="normal">Next, using the timeline above the preview, we can cycle to different parts of the animation. In particular, we are trying to find places for footsteps, so we’ll want to find spots like this, where the foot is meeting the ground:</p>
<figure class="mediaobject"><img alt="A picture containing graphical user interface  Description automatically generated" height="420" src="img/B17304_12_52.png" width="750"/></figure>
<p class="packt_figref">Figure 12.51: Animation Clip inspector window preview</p>
<p class="normal">Once your timeline<a id="_idIndexMarker938"/> is lined up, go ahead<a id="_idIndexMarker939"/> and add an animation<a id="_idIndexMarker940"/> event. And in the spot that says <strong class="screenText">Function</strong>, type in <code class="inlineCode">PlaySound</code> — <em class="italic">do not</em> include the parentheses you’ve seen previously (in <code class="inlineCode">PlaySound()</code>)! For some reason, including the parentheses won’t trigger our function properly.</p>
<p class="normal">Here is where we placed our events.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="197" src="img/B17304_12_53.png" width="750"/></figure>
<p class="packt_figref">Figure 12.52: Animation Clip inspector window timeline with events</p>
<p class="normal">Now, when you go into the game and walk around, you’ll hear sound! Congrats! We now have footstep sounds!</p>
<h3 class="heading-3" id="_idParaDest-313">Randomized sounds</h3>
<p class="normal">You’ll probably notice that our footstep sound is fairly repetitive. This is why we often like to add randomized sounds<a id="_idIndexMarker941"/> to a game!</p>
<p class="normal">This is a process of randomly playing from a pool of sound effects so that sounds will be less repetitive! In this instance, we have five different footstep sound effects to choose from, which can be found in <code class="inlineCode">/Assets/Sounds</code>:</p>
<p class="normal"><code class="inlineCode">MainFS_01.wav</code> – <code class="inlineCode">MainFS_05.wav</code></p>
<p class="normal">Next, let’s open up our <code class="inlineCode">AnimationSounds.cs</code> script and check out how we can add randomized sounds. So in this instance, we’re going to use a list of <code class="inlineCode">AudioClips</code>, like this:</p>
<figure class="mediaobject"><img alt="" height="40" src="img/B17304_12_54.png" width="570"/></figure>
<p class="packt_figref">Figure 12.53: Animation.cs public list soundPool</p>
<p class="normal">Then, inside of <code class="inlineCode">PlaySound</code> we’re going to select a random clip from this, and load it into our <code class="inlineCode">AudioSource</code> component. We’ll use <code class="inlineCode">Random.Range</code> to accomplish this:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text  Description automatically generated" height="158" src="img/B17304_12_55.png" width="651"/></figure>
<p class="packt_figref">Figure 12.54: Animation.cs PlaySound() function</p>
<p class="normal">Next, let’s open up the inspector where our <code class="inlineCode">AnimationSounds.cs</code> script lies, highlight all of our <code class="inlineCode">MainFS.wav</code> sounds, and click and drag them directly into our sound pool serialized field:</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated" height="342" src="img/B17304_12_56.png" width="668"/></figure>
<p class="packt_figref">Figure 12.55: Animation.cs in the inspector</p>
<p class="normal">And that’s all! We now are playing from a pool of random sounds!</p>
<h3 class="heading-3" id="_idParaDest-314">Randomized pitch</h3>
<p class="normal">Sometimes adding even<a id="_idIndexMarker942"/> more variation can be accomplished through randomizing the pitch. This is a very simple process as well. The first thing we have to do is define the range of pitch that we will affect.</p>
<p class="normal">I like to just play the sound and play around with the pitch to see where it sounds good. Open up the <code class="inlineCode">AudioSource</code> component that holds our footstep sound and toggle the <strong class="screenText">Pitch</strong> slider! This will update in real time.</p>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" height="198" src="img/B17304_12_57.png" width="750"/></figure>
<p class="packt_figref">Figure 12.56: AudioSource component</p>
<p class="normal">You’ll hear that going too high or too low makes a fairly unrealistic sound. So I like to stick to a range of 0.3 and -0.3. In our code, let’s just add a simple <code class="inlineCode">Random.Range()</code> while targeting the pitch of our <code class="inlineCode">AudioSource</code> component.</p>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated with medium confidence" height="42" src="img/B17304_12_58.png" width="634"/></figure>
<p class="packt_figref">Figure 12.57: AudioSource component showing how random pitch is achieved</p>
<p class="normal">This is all we need! One of the most<a id="_idIndexMarker943"/> important ways to create depth in the soundscape of our game is to add as many sources as possible. And adding things like random variation, sound to small details in animations, and dynamic audio can go a long way! Go ahead and play the game to hear your changes.</p>
<h1 class="heading-1" id="_idParaDest-315">Summary</h1>
<p class="normal">This chapter went over many different tools that we have worked through within our project. We took some time to go over our process for finalizing the art and assets. We focused not only on the models and textures but also on checking in on the design to make sure that each asset fits within the world as expected. Within this, we also went over adding effects from the Shuriken and VFX Graph particle systems. This included the implementation of effects to show telekinesis. </p>
<p class="normal">We then went over the lighting design. We broke down Unity lighting with lightmaps, reflection, light probes, and baking. Lighting can add so much to a game, so this part shouldn’t be taken lightly!</p>
<p class="normal">Then to round up our game polish we went through sound polishing to trigger sounds through animations and add randomness to the sounds to bring more life to the gameplay.</p>
<p class="normal">This is it for the book! Thank you so much for reading all the way through and we hope it provided you with lots of knowledge. Please consider joining the Discord server, where we will be able to answer questions and go over the project in more detail. </p>
<p class="normal">There is a bonus chapter after this that goes over some more Unity tools that can be used for different projects as well as some products that Unity has to offer for multiplayer, XR, and visual scripting. Let us know if you would like a book on those topics as well!</p>
</div>
</div></body></html>