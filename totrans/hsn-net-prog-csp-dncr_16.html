<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">The Internet Protocol</h1>
                </header>
            
            <article>
                
<p class="Normal1">In the previous chapter, we got a comprehensive understanding of two of the most common and robust protocols in the transport layer of the <strong>Open Systems Interconnection</strong> (<strong>OSI</strong>) network stack, with the <strong>Transmission Control Protocol</strong> (<strong>TCP</strong>) and <strong>User Datagram Protocol</strong> (<strong>UDP</strong>). In this chapter, we'll look at the network layer protocol that enables each of those two transport layer services. In this chapter, we'll be learning about the <strong>Internet Protocol</strong> (<strong>IP</strong>). We'll look at how the IP standard has evolved to support a global network of billions of devices, allowing each of them to reliably communicate with one another. We'll consider the earlier, and more common IPv4, looking at what problems IPv4 was designed to solve, and discussing the limitations that it has reached. Next, we'll examine how IPv6 aims to solve those limitations. Finally, we'll take a closer look at the <kbd>IPAddress</kbd> class, and look closely at how the core libraries implement IPv4 and IPv6. We'll take the opportunity to discuss and consider how IP addresses map to domain names and learn how <strong>Domain Name System </strong>(<strong>DNS</strong>) servers will map an address to a resource, and we'll look at some code samples that will allow us to implement those mappings on our own.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>What an IP address is composed of and how it is used, along with network masks, local addressing, and DNS servers, to identify physical devices</li>
<li>How IP addresses are assigned using the IPv4 standard, identifying the limitations of IPv4</li>
<li>The specifics of the IPv6 standard, enumerating the strengths of leveraging IPv6, and the costs of implementing it at the scale of the internet</li>
<li>The hostname to IP address resolution at the DNS level</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>In this chapter, we'll be writing sample software to resolve IP addresses configured from our hosts file to simulate a DNS server. You'll need your .NET Core <span><strong>integrated development environment</strong> (</span><strong>IDE</strong>) or a code editor. You can access the sample code at <span><a href="https://github.com/PacktPublishing/Hands-On-Network-Programming-with-C-and-.NET-Core/tree/master/Chapter%2012">https://github.com/PacktPublishing/Hands-On-Network-Programming-with-C-and-.NET-Core/tree/master/Chapter 12</a></span>. <span>Check out the following video to see the code in action: <a href="http://bit.ly/2HYmyi9"/><a href="http://bit.ly/2HYmyi9"/><a href="http://bit.ly/2HYmyi9">http://bit.ly/2HYmyi9</a>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The IP standard</h1>
                </header>
            
            <article>
                
<p>Before we start looking at how the IP standard has evolved from its inception to the widely adopted IPv4, and now on to IPv6, we first have to understand what the standard is and how it's distinct from the transport layer protocols that we've looked at. This is critical to cementing our understanding of the OSI network stack, as IP is fundamental to the operation of transport layer protocols that operate over the internet. So, let's figure out just what IP is designed for, how it accomplishes its design goals, and what sort of features it enables for network <span>software and hardware</span><span>.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The origins of IP</h1>
                </header>
            
            <article>
                
<p class="mce-root">Originally implemented as a packet transmission mechanism in the earliest version of the TCP, IP was first formally described in 1974. Still early in the history of modern computing, computational networks were very much in their infancy. Those networks grew in scope, however, and began to encapsulate multiple sub-networks with various interaction mechanisms. And as those networks grew, the need for a standard across network-connected devices quickly became apparent.</p>
<p>To satisfy this need for a standard, the <strong>Advanced Research Projects Agency</strong> (<strong>ARPA</strong>) of the US government sponsored a series of experiments to define a protocol that could support a wide-scale interconnected network. With this sponsorship, the members of the <strong>Institute of Electrical and Electronic Engineers</strong> (<strong>IEEE</strong>) wrote a paper that described an inter-networking protocol that leveraged packet switching to share resources across and between hosts in a network. Beginning in 1977, the organization began experimenting with various drafts of the protocol described in this paper. Between 1977 and 1979, there were four experimental versions of IP described by <strong>Internet Experiment Notes</strong> (<strong>IEN</strong>), and labeled IPv0 through to IPv3. Each of these versions tackled some major deficiency in the previous iteration of the protocol until the team was certain their protocol was sufficiently robust for use by the wider public.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IPv0 – a network layer protocol for TCP</h1>
                </header>
            
            <article>
                
<p>The first of these experiments, IEN 2, was written in August 1977. It explicitly states that engineers had been screwing up in their design of IPs by violating the principle of layering. In its initial draft, TCP was responsible for the abstraction of both the host-to-host transmission of application layer packets, and for negotiating the hops between network devices along the route between the two connected hosts. By over-engineering TCP in this way, engineers created a single protocol that spanned both the transport and network layers of the OSI network stack. This violation of boundaries between OSI layers was almost immediately recognized as a bad design, and a bad practice. So, with IEN 2, the authors proposed a new and distinct internetwork protocol, and that TCP be used strictly as a host level end-to-end protocol. And with this experiment, IP was born.</p>
<p>The protocols and interfaces described in IEN 2 described two primary operations that had previously both been performed by TCP. First, there was the <strong>Internet Host-Hop Protocol</strong>, which would become TCP. This was meant to describe the interface for complete end-to-end interactions between hosts, with no concern for how to navigate between those two hosts. It described a rudimentary process for payload fragmentation and many of the headers that are still used in TCP today.</p>
<p>The second protocol described was the <strong>Internet Hop Interface</strong>. It's this part of the IEN that described what would eventually become IP. The hops in this context are hops along a single edge in the network diagram between two nodes, or hosts. The goal of this section of the IEN was to define the minimum amount of information necessary to bundle with a packet to allow any step on the path to route it accordingly, without routing multiple instances of the same packet to the destination, and to allow fragmentation in such a way that the packet can be reassembled at the destination gateway.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IPv1 to IPv3 – formalizing a header format</h1>
                </header>
            
            <article>
                
<p class="mce-root">Over the course of the two years that followed, several more IENs were written to describe an evolving IP interface. Each of these, in their own way, formalized some detail of IP that would eventually become the broadly-released and universally supported IPv4. Beginning with IPv1, as described by IEN 26, the first task engineers set to accomplish was defining the minimum necessary headers, along with their minimum necessary size specifications, to successfully route packets across an arbitrarily large and arbitrarily organized network.</p>
<p class="mce-root">Without universal acceptance of some sort of header, there could ultimately be no internet as we know it today. However, until there was universal acceptance of some interface, members of the <span><strong>Internet Engineering Task Force</strong> (</span><strong>IETF</strong>) knew that their work would be subject to feedback and changes. As such, one of the primary tasks of the first IP header description was to allow for the support of multiple versions and multiple kinds of services exposed over those networks. Thus, the header described in IEN 26 introduced fields such as the IP version header, and the <strong>type of service</strong> (<strong>TOS</strong>) header.</p>
<p>Shortly after, in IEN 28, the team defined IPv2, which further crystallized the interface's header, as well as the process of fragmentation of packets over a network. This was also the first IEN to posit a mechanism for detecting packet corruption, though it provided no guidance on how that could be accomplished. Finally, it described a rudimentary addressing component of a packet, and the addressing mechanism for hosts on a network. However, it's worth noting that the mechanism described was not quite what was ultimately released to the broader public.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IPv4 – establishing the IP</h1>
                </header>
            
            <article>
                
<p>Over the course of several iterations on the protocol, the team worked through their design issues until, with IEN 54, they finalized the header definition that would be standardized by <strong>Request for Comment</strong> (<strong>RFC</strong>) 791, as IPv4. With RFC 791, the IETF finally established the details of the operation and implementation of the IP standard. This version of the protocol has been in use across the globe since 1981, and even today, this interface specification is used on almost 80% of all datagrams sent between hosts on the internet.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The functions of IP</h1>
                </header>
            
            <article>
                
<p>As described in RCF 791, there are three primary functions that the IP is designed to provide for networks. In section 1.2 of that specification, the scope of the protocol is explicitly limited to just the functions necessary to deliver a package of bits (an internet datagram) from a source to a destination over an interconnected system of networks.</p>
<p>You'll note that nowhere in this definition do the authors mention reliability, ordered delivery, or connection negotiation. This is very much an intentional omission on their part. As they stated in IEN 2, attempting to account for those functions with a network layer protocol will be violating the boundaries of the OSI network stack. And that's not simply speculation on my part; in the definition of the scope of IP, the authors explicitly state that there are no mechanisms to augment end-to-end data reliability, flow control, sequencing, or other services found in host-to-host protocols. Here, by host-to-host protocols, the authors are referring to the responsibilities of transport layer protocols and interfaces.</p>
<p>So, if reliable delivery, flow control, and sequencing are all outside the scope of IP, you may well be wondering what functions it is responsible for, and how it implements them. Well, according to the standard, IP is responsible for precisely two functions: addressing and fragmentation. The protocol provides these functions for the transport layer protocol above it, and it does so by leveraging the local network protocols of the data link layer below it.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Addressing for IP</h1>
                </header>
            
            <article>
                
<p>Addressing is used to uniquely identify a host (or set of hosts) that can service requests over a network. Any device that must be located by other hosts on a network to which it's connected must have an address associated with it. This is the only mechanism by which the IP can request routing information from the data link layer.</p>
<p>Here, it's worth distinguishing between an address and a name, hostname, or domain name. Names, or hostnames, are the human-readable <span><strong>Uniform Resource Identifier</strong> (</span><strong>URI</strong>) structures, while an address is a unique, semantically structured key that indicates where the owner of a hostname resides. According to the IP standard, transport layer protocols are responsible for resolving a hostname to its specific address before passing the addressing information to the network layer to be transmitted to the next device in the route.</p>
<p>And here, a further distinction should be made between addressing, or identifying the sub-network and specific location of the target host, and routing, or finding the complete path from the source host to the destination host. Once a datagram is received by a host's IP interface, the destination address is validated, and the packet is fragmented, with all IP headers applied. Then, the datagram is passed along, and it is the responsibility of the data link layer to actually perform the task of routing along links and nodes in the network to find a connected path between the two hosts.</p>
<p>So, addressing functions of an IP implementation revolves around assigning addresses to new nodes on a network, and parsing and interpreting addresses attached to packets. When assigning new addresses, they are done with a fixed-length, semantically significant data key. A semantically significant data key is simply one in which meaning can be inferred from the structure of the key.</p>
<p>In the case of IP addresses, different segments of the address contain details about the specific location of the host that the IP address identifies. For example, in an early specification for address resolution, the first 8 bits of a 32-bit addressing scheme were used to locate the specific subnet in which the target host resided. The next 24 bits in the address serve as the address of the host within the local network's addressing scheme.</p>
<p class="mce-root"/>
<p>The standards of the IP addressing scheme have grown and changed over the years to adapt to ever broadening networks and ever wider address spaces, but the principle of a well-formed, semantic key used as a host's address has remained unchanged since IPv4 was introduced in 1981.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The fragmentation of packets</h1>
                </header>
            
            <article>
                
<p>The fact that IP is designed to facilitate hops between nodes in a network is why a specification for packet fragmentation (over the fragmentation that may already be performed at the transport layer) becomes necessary. Since each connected sub-network in the larger internet is free to specify its own constraints for packet size and delivery, there could be inconsistencies in the size and format requirements for a datagram as it moves across the network. It may well be the case that a datagram that is considered small enough by the sub-network of the originating host is actually too large for the sub-network of the target host. As such, it might be necessary for the IP implementation running on a router or bridge between two sub-networks to have to decompose or reassemble datagrams as they move between the two subnets.</p>
<div class="packt_infobox">The specification does provide a mechanism for indicating that a datagram should not be fragmented under any circumstances. However, if the specifications of the data link layer prevent a datagram from being delivered without being fragmented, and the datagram is marked as do not fragment, then it is simply discarded instead.</div>
<p>The actual process of fragmenting is defined by the standard as a general system for decomposing a longer datagram into some number, <em>n</em>, of smaller datagrams. The datagrams are broken up into smaller frames of binary data, with additional headers added incorporated to allow for the reconstruction of the smaller datagrams into an appropriate recreation of the original, larger datagram. Those additional fields added to the smaller datagrams are as follows:</p>
<ul>
<li><strong>Offset</strong>: The position in the datagram that the new fragment came from. This allows for the proper reordering of datagram fragments that may have been delivered out of order.</li>
<li><strong>Length</strong>: This specifies the length of the content that was pulled out of the original datagram and stored in the payload of the current fragment.</li>
<li><strong>Identification field</strong>: The new, smaller fragments also use an identification number to specify which larger datagram they belong to. This helps ensure that smaller fragments from different parent datagrams are not mixed up during recomposition.</li>
<li><strong>More-fragments flag</strong>: Finally, there is a more-fragments flag field used to indicate whether or not there are additional smaller fragments that need to be added to the reconstructed parent datagram.</li>
</ul>
<p>These fields taken together – offset, length, identification, and more-fragments – are sufficient to reconstruct a datagram from an arbitrary number of fragments on the destination host. The generalized nature of the description in the RFC that we've seen here allows for reliable fragmentation and recomposition in almost any use case across any network gateway, router, or subnet interface. Now that we understand what the protocol was designed to accomplish, let's look at how it has been implemented and deployed since its inception.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IPv4 and its limits</h1>
                </header>
            
            <article>
                
<p>First defined in 1981, and widely deployed in 1983, IPv4 has been the standard for network layer interactions across the whole of the internet, and almost every local area network, for over three decades now. As I mentioned before, nearly 80% of all internet traffic is done using the IPv4 specification of the IP interface. Its stability, scalability, and reliability have been well-proven at this point. So, what is it about IPv4 that made its implementation of network layer responsibilities so successful? And what was it about the IPv4 specification that precipitated the need, after such a long and successful lifespan, to define and deploy a new protocol with IPv6?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The addressing standard of IPv4</h1>
                </header>
            
            <article>
                
<p>As I mentioned in the previous section on the addressing functions of IP, the address of IPv4 is designed with a semantic structure, as opposed to simply having an arbitrary key allocated for each new device on a network. So, provided you understand how to parse the semantic meaning of an address, determining the specific location of a host can be done through a hierarchical analysis of each segment of an address.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The IPv4 address syntax</h1>
                </header>
            
            <article>
                
<p>Addresses in IPv4 are 32-bits long, and are typically divided into four octets (bytes), separated by a decimal, with each byte expressed in its base-10 notation. However, the underlying structure of the address is flexible enough to be expressed as anything from the dot-decimal notation, to a raw base-10 integer representation of the 32-bit value, to hexadecimal, to a dotted hexadecimal format. Each of these representations is merely a different way of expressing the same binary value. In this way, the syntactical representation of a given IP address is unimportant, since the semantic meaning is preserved by the underlying 32-bit representation.</p>
<p>So, let's consider the following IPv4 address:</p>
<pre><span>11000000</span><span>101010000000000110110101</span></pre>
<p>This probably doesn't seem familiar to you as an IP address,  at least, not in that representation. So, let's look at how we can express this in a way we'd more easily recognize as an IP address. We'll start by separating the binary representation into four octets:</p>
<pre>11000000.10101000.00000001.10110101</pre>
<p>Next, we'll convert each of the dot-delimited bytes and convert their values to the corresponding base-10 representation:</p>
<pre>192.168.1.181</pre>
<p>And, just like that, we have an IP address format that we're more familiar with. However, we could have just as easily converted the string to its hexadecimal-dot notation, and gotten the following:</p>
<pre>C0.<span>A8.01.B5</span></pre>
<p>As long as we preserve the ordering of the octets, the meaning remains true, and can provide us with useful information for routing requests to the given address.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Classful IP addressing</h1>
                </header>
            
            <article>
                
<p>With IPv4, the value of each octet in an address can carry with it hierarchical routing information about the host at that address. When the protocol version was first defined, there was a specification that the first octet of an address value would designate the subnet to which the host belonged. This was dubbed the network field. The remaining three octets were then left to designate the address within that subnet at which the host could be found. These octets, together, were commonly called the <strong>rest field</strong>, short for the <strong>rest of the address</strong>.</p>
<p>Now, if you're on top of your binary math, you will have already recognized the issue with the structure that I just described. With only a single octet to designate a subnet, there could only be, at most, <kbd>255</kbd> subnets on the whole of the internet. Such a limitation was almost immediately recognized as infeasible, and so the standards document included a provision for different classes of addressing schemes. Described in RFC 791, there were three specific classes of IP addresses, each of which used a different number of bits to specify the subnet of a host, and with each having their own unique limits on the maximum number of hosts on a given subnet.</p>
<p>At the time that the RFC was drafted, there were only about <kbd>64</kbd> subnets in existence, meaning at most, that only the six least significant bits of the network field had been used to designate a known subnet, up to that point. Not wanting to reassign widely used subnet addresses, the most significant bits of the network field were set for use as the class flags for a given IP address. In the original RFC, there were three well-defined classes of IP structure, with a fourth left open for future specification as need demanded. These original three classes were defined as follows:</p>
<ul>
<li><strong>Class A</strong>: In a <strong>Class A</strong> address, the most significant bit is zero, and the next seven bits are to be used for subnet identification. This leaves the remaining three octets as the rest field, allowing for up to <kbd>16,777,215</kbd> possible unique host addresses within a subnet identified by a <strong>Class A</strong> address.</li>
<li><strong>Class B</strong>: In a <strong>Class B</strong> address, the most significant bit of the address has a value of <kbd>1</kbd>, and the second most significant bit has a value of <kbd>0</kbd>. The next 14 bits of the address are used for subnet identification, leaving the two least significant octets available for unique host addresses within the subnet.</li>
<li><strong>Class C</strong>: Finally, in a <strong>Class C</strong> address, the first two most significant bits of the address have a value of <kbd>1</kbd>, while the third most significant bit has a value of <kbd>0</kbd>. With these values in the three most significant bits, the next 21 bits are to be used for subnet identification, allowing for <kbd>2,097,151</kbd> unique possible subnets. This leaves only the final octet for host addressing, leaving at most <kbd>255</kbd> host addresses available in a <strong>Class C</strong> IP address.</li>
</ul>
<p>To further illustrate how these classes are semantically parsed, consider the following three IP addresses:</p>
<pre>38.117.181.90<br/>183.174.61.12<br/>192.168.1.181</pre>
<p>Now, by converting each address to their dot-binary representation, we can examine the most significant digits to determine the class of IP address under which each of them falls:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f7dc5ef3-ae5c-4849-a973-ad47c7d670ef.png" style="width:33.17em;height:18.58em;"/><br/></p>
<p class="mce-root">However, restricting use of the three most significant bits to indicate the class of a network was an untenable long-term solution. Soon enough, the IETF devised a new mechanism for determining the network field of an IP address.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Subnet masking</h1>
                </header>
            
            <article>
                
<p>By 1993, the available pool of IP addresses under the classful address architecture was depleting at an untenable rate (a problem that we'll discuss more later). To mitigate this challenge, the IETF did away with the classful architecture described by RFC 791, and introduced the <strong>Classless Inter-Domain Routing (CIDR)</strong> address syntax. The CIDR syntax applies an additional, optional suffix to an IP address that is used to indicate precisely how many bits of the address are dedicated to the network field. The suffix is delimited with a leading <kbd>/</kbd> character, and then an integer that denotes how many leading 1s are in the subnet mask.</p>
<p>If the term <strong>subnet mask</strong> sounds familiar, you've likely seen it in the diagnostic output when you've run the <kbd>ipconfig</kbd> command in your terminal. The term <strong>mask</strong> in this context specifically refers to a bitwise mask. Basically, when you apply a mask to another binary number, the result is a <kbd>1</kbd> value in any position in which at least one of the two numbers has a <kbd>1</kbd> value. Consider the following IP address:</p>
<pre>11000000.10101000.00000001.10110101</pre>
<p>And then the following subnet mask:</p>
<pre>11111111.11111111.11111111.00000000</pre>
<p>The result of applying the mask to the IP address will be as follows:</p>
<pre>11111111.11111111.11111111.10110101</pre>
<p>So, in this example, if we convert our binary to its dot-<span>decimal</span> notation, we've got an IP address as follows:</p>
<pre>192.168.1.181</pre>
<p>And we also have the following subnet mask:</p>
<pre>255.255.255.0</pre>
<p>What this subnet mask does is indicate to a routing device what bits of the IP address are to be used for network identification. So, since the subnet mask we just looked at had all <kbd>1</kbd> values for the first 24 most significant bits, this means those first 24 bits should be used as the network identifier.</p>
<div class="packt_infobox"><span>This specific subnet mask will likely look pretty familiar to you since it's the default local subnet and subnet mask for most modern routers. The sub-network identified by this IP address is the one created by your home router, which serves as a gateway between the wider internet and your home network. What this means, though, is that for any given household with a single router, there is a maximum number of devices that can be connected to the network.</span></div>
<p>Using the notation of CIDR, that same IP address and subnet mask combination is expressed as follows:</p>
<pre>192.168.1.181/24</pre>
<p>This gives us what's called <strong>variable-length subnet masking</strong> (<strong>VLSM</strong>). It allows us to use any arbitrary number of bits for network identification without having to reserve the most significant bits as flag values. This means that IP addresses could be used to identify a much larger set of unique sub-networks, and those networks could have a wider variety of maximum sizes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Address space exhaustion</h1>
                </header>
            
            <article>
                
<p>All of this work of adapting the standard to allow for a broader flexibility in the address syntax was done primarily to mitigate perhaps the greatest limitation of IPv4. I've alluded to it before, but the address specification for IPv4 allows for a maximum of 32 bits for an address. This means that the maximum number of unique IP addresses, no matter how you structure your network field and rest field, will always be at most <kbd>4,294,967,296</kbd> unique addresses.</p>
<p>In 1983, when IPv4 was standardized, the internet remained nothing more than an experiment. Certainly, the engineers working on the IETF had the foresight to expect their network experiment would eventually grow to the span the world. But the development of IPv4 was done on the assumption that their specific networking experiment wouldn't extend beyond the computer networks of ARPA. However, even as they saw the widespread adoption of their standard on hosts across the nascent internet, there was still an assumption that 4.3 billion unique addresses would provide ample time to devise a workable alternative before the address space was exhausted.</p>
<p>What they didn't predict though, was the rate at which computers would increase in power, and decrease in cost. This combination resulted in an explosion in the consumer computer market, and with it, an explosion in networked hosts in need of addresses. As the new millennium approached, so too did the assignment of the last available IPv4 address. And so, in 1998, a draft standard for the next IP version was released.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IPv6 – the future of the protocol</h1>
                </header>
            
            <article>
                
<p class="mce-root">Designed to overcome an insufficient number of valid addresses for network hosts, IPv6 was first introduced in 1998, though it was only accepted as a formal standard in 2017 (which goes to show how diligent engineers can be about defining standards). The new specification was written to deal with a small number of issues presented by IPv4, including the limited address space. The standard also has native support for multicast transmission, as well as <span><strong>IP security</strong> (</span><strong>IPSec</strong>) security features.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The IPv6 addressing scheme</h1>
                </header>
            
            <article>
                
<p>Where IPv4 had a 32-bit addressing mechanism, allowing for a maximum of about 4.3 billion unique addresses, the IPv6 standard provides a 128-bit addressing scheme, allowing for 3.4 x 10<sup>38</sup> unique addresses. That's 340 billion addresses! For a bit of context, the scheme allows for more addresses than there are meters from the surface of the earth to the edge of the observable universe. With such a large addressing space, the IPv6 scheme allows for simpler address allocation, route aggregation, and unique addressing features that we'll look at later.</p>
<p>These 128 bits are organized into eight groups of 16 bits each. These groups are typically written as four hexadecimal digits (as opposed to the integral representation typical in IPv4), with each grouping separated by a colon. However, for the sake of minimizing the size of a packet header, there is a standard for abbreviating IPv6 addresses without the loss of meaningful information. The two steps to follow for address abbreviation are as follows:</p>
<ol>
<li>Remove any leading zeros in any 16-bit (or four hexadecimal) segment of the route</li>
<li>Eliminate exactly one consecutive string of remaining zeros, and replace the removed segments with <kbd><strong>:</strong></kbd></li>
</ol>
<p>To see this in action, let's start with the following address:</p>
<pre><span class="ipaddr"><span>fe08:0000:0000:0000:5584:7902:0028:6f0e</span></span></pre>
<p>Now, after applying step 1, we have the following:</p>
<pre><span class="ipaddr"><span>fe08:0:0:0:5584:7902:28:6f0e</span></span></pre>
<p>Now, removing the longest string of consecutive zeros, we have the following:</p>
<pre><span class="ipaddr"><span>fe08::5584:7902:28:6f0e</span></span></pre>
<p>While this representation is substantially smaller, it's only really used as a convenience. The packet header for an IPv6 packet is configured to use the full 128-bit address for the source and destination of the packet, so, prior to transmission, the full address is applied to the packet regardless of how short it can be abbreviated.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Network fields and routing efficiency</h1>
                </header>
            
            <article>
                
<p>With IPv4, a considerable amount of work was put into allocating sufficient space for a subnet identifier within the limited 32-bit addresses. However, since IPv6 is designed with such a vast address space, network identification is greatly simplified. All IPv6 addresses allocate the most significant 64 bits to subnet addressing, and the remaining 64 bits to host, or interface identification.</p>
<p>One of the simplest things this enables is more efficient processing by routers and network switches. Because the network identifier and host addresses are always of a fixed length, and those lengths are well-aligned with word length in 32- and 64-bit hardware, routers can parse the structure of the address with much greater efficiency.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fragmentation in IPv6</h1>
                </header>
            
            <article>
                
<p>Another major change between IPv4 and IPv6 comes in the delegation of responsibility to fragment packets appropriately for their route. With IPv4, this was explicitly a concern for the network layer, and one that IPv6 sought to solve. The guidance provided for the fragmentation of a data packet was a major part of the RFC that defined IPv4. Meanwhile, with IPv6, packet fragmentation is considered the joint responsibility of the transport layer and the data link layer.</p>
<p><span>The idea behind this change in responsibilities is the assertion that there should be a step in the end-to-end protocols of the transport layer. That step is nothing but determin</span><span>ing the maximum packet size allowable along a route between two hosts.</span> Meanwhile, the <strong>Maximum Transmission Unit</strong> (<strong>MTU</strong>) of every edge along a route between two hosts should be discoverable from the data link layer when the transmission is initiated. In cases of failure to discover the MTU of the specific route between two hosts, the transport layer should fall back to the default MTU of the internet, which is 1280 bytes of data. Thus, in an ideal case, the data link layer can provide the specific route MTU and the transport layer can fragment its packets accordingly. If the data link layer fails to provide the route's MTU, the transport layer uses a worst-case fragment size of the default MTU, that is, 1,280 bytes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IPv6 to IPv4 interfaces</h1>
                </header>
            
            <article>
                
<p>Because IPv6 so fundamentally alters the structure of the IPv4 packet header, the two versions are entirely incompatible. This obviously poses a problem when network engineers need to support the widely deployed IPv4 over the whole lifetime of the transition to IPv6. To facilitate that transition, a number of intermediary solutions have been devised to allow IPv6 traffic to function over IPv4 networks.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Side-by-side IP deployment</h1>
                </header>
            
            <article>
                
<p>The simplest way to get IPv4 and IPv6 to coexist on a single network is to have each host on that network deploy a full protocol implementation of each version. This is commonly done at the operating system (OS) level and allows traffic travelling to and from a single hardware interface to interact with both IP versions once the physical data transmission is delivered to the OS. Devices that use this side-by-side deployment will acquire an address for IPv4 and IPv6 simultaneously, and if the host has a registered domain name, that domain name will be resolved for both address schemes by a DNS server. Of course, the obvious downside here is that a side-by-side deployment is only as good as the subnet to which it is deployed. If a host supports both protocols, but exists on a network that only supports IPv4, then there's no benefit to be gained. In a strictly controlled sub-network, however, side-by-side deployment is a viable and often simple option.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tunneling interfaces</h1>
                </header>
            
            <article>
                
<p>The other alternative for the cross-version support of IP traffic is known as <strong>tunneling</strong>. This is a mechanism by which IPv6 traffic is tunneled over an IPv4 network by wrapping the IPv6 packet in an IPv4 packet. This process is described in RFC 4213, and is widely used by servers leveraging strictly IPv6 packet schemes.</p>
<p>One of the most popular tunneling schemes, <strong>Teredo</strong>, is consistently used for integrating an IPv6 sub-network onto the wider IPv4 internet. The mechanism by which Teredo accomplishes this is by leveraging our old friend, UDP. The IPv6 packets are wrapped in a UDP packet header, which is itself wrapped in an IPv4 packet. The IPv4 packets are routed normally, until received by a Teredo client or server, which is configured specifically to decompose the IPv4 packets into their original IPv6 structure.</p>
<p>While this is useful information for any network engineer, though, as C# developers, we are lucky enough to not need to concern ourselves with the details of these interfaces. While we have access to the specific IP information from any network traffic in our software, the translation and parsing of IP packets is mostly abstracted away from us. So, let's look now at how we can investigate and understand the nature of IP traffic within our software.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Leveraging IP in C#</h1>
                </header>
            
            <article>
                
<p>Since C# and the .NET Core runtime will abstract away most of the details of IP interactions from our application software, this demonstration will be relatively simple. What we're going to write is a simple web API that simulates a DNS name resolution. We'll use a simple JSON file to store domain names and their associated addresses and provide an instance of the <kbd>IPAddress</kbd> class (or a list of instances of it) as our response. This will demonstrate how the language provides a lot of parsing and negotiation behind the scenes for you, and how that can streamline your development process considerably. And since we've been working with IP addresses and ports throughout this book, much of this should seem familiar to you.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up our server</h1>
                </header>
            
            <article>
                
<p>We'll be using a simple web API project for this, so we'll create it with the <strong>command-line</strong> <span><strong>interface</strong> (</span><strong>CLI</strong>):</p>
<pre><strong>dotnet new webapi -n DNSSimulation</strong></pre>
<p class="mce-root">Once that's up, we'll go ahead and remove all of the scaffolded endpoints in our controller except for our POST endpoint. This will be the route by which users will look up hostnames from our DNS server. We'll also modify our route to more accurately express what our API provides. So, before we start coding, our controller should appear as follows:</p>
<pre>[Route("dns/[controller]")]<br/>[ApiController]<br/>public class HostsController : ControllerBase {<br/>    [HttpPost]<br/>    public IEnumerable&lt;string&gt; Post([FromBody] string domainName) {<br/>    }<br/>}</pre>
<p>Next, we'll need to add a simple host registry for our application to perform lookups on. So, create a JSON file that represents a list of key-value pairs. The keys will be the hostnames we're performing lookups on, and the values will be an array of string representations of arbitrary IP addresses. And for demo purposes, be sure to use both IPv4 and IPv6 addresses in our file. Mine looks like this, but yours can have whatever hostnames and addresses you feel like using:</p>
<pre>{<br/>    "test.com": [ "172.112.98.123" ],<br/>    "fake.net": [<br/>        "133.54.121.89",<br/>        "fe80:0000:0000:0000:5584:7902:d228:6f0e"<br/>    ],<br/>    "not-real.org": [<br/>        "123.12.13.134",<br/>        "dc39::7354:23f3:c34e"<br/>    ]<br/>}</pre>
<p>As a final setup step, we'll just add a simple static class to make our <kbd>hosts.json</kbd> file easier to work with from within our controller. To do that, we'll create a <kbd>Hosts</kbd> static class, give it a single public property called <kbd>Map</kbd>, and then use the static constructor feature of C# to initialize the <kbd>Map</kbd> property with the contents of our JSON file. Then, whenever we need to access our hosts file, we do so with a static reference to our <kbd>Hosts.Map</kbd> method and <kbd>query</kbd> its dictionary accordingly. This pattern is incredibly simple, and incredibly useful for providing straightforward and easily understandable access to static content files in your application code. Our example appears as follows:</p>
<pre>public static class Hosts {<br/>  public static IDictionary&lt;string, IEnumerable&lt;string&gt;&gt; Map;<br/><br/>  static Hosts() {<br/>    try {<br/>      using (var sr = new StreamReader("hosts.json")) {<br/>        var json = sr.ReadToEnd();<br/>        Map = JsonConvert.DeserializeObject&lt;IDictionary&lt;string, IEnumerable&lt;string&gt;&gt;&gt;(json);<br/>      }<br/>    } catch (Exception e) {<br/>      throw e;<br/>    }<br/>  }<br/>}</pre>
<p>And with that, we're ready to implement our IP lookup.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">IP parsing in C#</h1>
                </header>
            
            <article>
                
<p>Now that we're ready to read from our hosts file, we can start parsing incoming requests and returning IP information for our consumers as a JSON string. As with all of our demo code, we'll assume we're getting well-formed inputs and ignore error handling for the time being.</p>
<p>Our inputs will be a fully-qualified URI, and so we'll initialize a temporary URI variable to allow easier domain name acquisition:</p>
<pre>public string Post([FromBody] string domainName) {<br/>  var uri = new UriBuilder(domainName).Uri;</pre>
<p>Next, we'll try to access the IP addresses for the hostname in our <kbd>Hosts.Map</kbd> method. If it fails, we'll defer to the outer DNS server, and return whatever addresses it can provide for our hostname. We'll do this using a utility method written to serialize <kbd>IPAddress</kbd> arrays into a string, called <kbd>GetSerializedIpAddresses()</kbd>, which we'll look at later. For now, though, the important thing to understand is that our fallback when we can't find the hostname in our own server registry is to look to an outer DNS server for our name resolution:</p>
<pre>IEnumerable&lt;string&gt; ipAddressStrings;<br/>if (!Hosts.Map.TryGetValue(uri.Host, out ipAddressStrings)) {<br/>   return GetSerializedIPAddresses(Dns.GetHostAddresses(uri.Host));<br/>}</pre>
<p>Once we've made it past this point, we know that we hold the <kbd>IPAddress</kbd> entries for the requested host, and we can use C#'s <kbd>IPAddress</kbd> class to parse them accordingly. So, first, we'll create a container for our <kbd>IPAddress</kbd> instances. Then, we'll attempt to initialize each instance using the <kbd>IPAddress.TryParse()</kbd> method. Assuming that succeeds (which it does in my example, and provided you have well-formed IP addresses in your own file, it will with yours too), we add the new <kbd>IPAddress</kbd> instances to our list:</p>
<pre>var addresses = new List&lt;IPAddress&gt;();<br/>foreach (var addressString in ipAddressStrings) {<br/>  if (!IPAddress.TryParse(addressString, out var newAddress)) {<br/>    continue;<br/>  }<br/>  addresses.Add(newAddress);<br/>}</pre>
<p>If you've followed my example up to this point, you'll find that the <kbd>TryParse()</kbd> method of the <kbd>IPAddress</kbd> class will automatically detect and account for each of the addressing schemes that I've discussed so far. We could add everything from a human readable dot-decimal-formatted IPv4 address, to an abbreviated IPv6 address, to a raw 32-bit binary string, and the <kbd>TryParse()</kbd> method will build the address accordingly. This kind of utility is why the software demo for this chapter can be so light. Almost all the heavy lifting is done for you by the .NET Core runtime.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using the IPAddress class in C#</h1>
                </header>
            
            <article>
                
<p>Our last task for this service will be converting our list of <kbd>IPAddress</kbd> instances to their corresponding JSON. This is where you will likely hit a pretty substantial snag in your code. Unfortunately, the <kbd>IPAddress</kbd> class doesn't play very well with <kbd>JsonConvert.SerializeObject()</kbd>. In fact, if you tried to execute that method on an instance of <kbd>IPAddress</kbd>, you'll get an exception almost every time. That's because the <kbd>IPAddress.Address</kbd> property is actually deprecated. It's defined as a long type, which, in C#, is a 64-bit integer. However, as you now know, an IPv6 address is a 128-bit value. Unfortunately, though, the <kbd>JsonConverter</kbd> class isn't intelligent enough to determine at runtime which public properties are deprecated. That means it will attempt to access the <kbd>Address</kbd> property of your <kbd>IPAddress</kbd> instance for serialization, and that access will throw an error for any <kbd>IPAddress</kbd> instances containing an IPv6 address.</p>
<p>Now, if you're familiar with writing your own <kbd>JsonConverter</kbd> extension class, you can overwrite the <kbd>JsonConverter</kbd> class for <kbd>IPAddress</kbd> and use that to serialize your return object. However, as that's quite outside the scope of this book, instead, we'll take the less ideal shortcut of writing our own serialization with a <kbd>GetSerializedIPAddresses()</kbd> method. Since we know better than to use the <kbd>IPAddress.Address</kbd> property, we'll just use the <kbd>ToString()</kbd> method to get the value of our <kbd>IPAddress</kbd> instance. That method will simply build out the string representation of each of our <kbd>IPAddress</kbd> instances as JSON, using each public property that we know is not deprecated and safe to access. That method will read as follows:</p>
<pre>private string GetSerializedIPAddresses(IEnumerable&lt;IPAddress&gt; addresses) {<br/>  var str = new StringBuilder("[");<br/>  var firstInstance = true;<br/>  foreach (var address in addresses) {<br/>    if (!firstInstance) {<br/>      str.Append(",");<br/>    } else {<br/>      firstInstance = false;<br/>    }<br/>    str.Append("{");<br/>    str.Append($"\"Address\": {address.ToString()},");<br/>    str.Append($"\"AddressFamily\": {address.AddressFamily},");<br/>    str.Append($"\"IsIPv4MappedToIPv6\": {address.IsIPv4MappedToIPv6}");<br/>    str.Append($"\"IsIPv6LinkLocal\": {address.IsIPv6LinkLocal},");<br/>    str.Append($"\"IsIPv6Multicast\": {address.IsIPv6Multicast},");<br/>    str.Append($"\"IsIPv6SiteLocal\": {address.IsIPv6SiteLocal},");<br/>    str.Append($"\"IsIPv6Teredo\": {address.IsIPv6Teredo}");<br/>    str.Append("}");<br/>  }<br/><br/>  str.Append("]");<br/>  return str.ToString();<br/>}</pre>
<p>And with that method, we see exactly what information the <kbd>IPAddress</kbd> class can provide for us regarding the nature of the IP version and its implementation just through its public properties. We can learn about the mappings or interfaces used to leverage IPv6 over IPv4, or simply learn about the feature support of an IPv6 host.</p>
<p>And with that last piece of the puzzle in place, our final controller method should read as follows:</p>
<pre>[HttpPost]<br/>public string Post([FromBody] string domainName) {<br/>  var uri = new UriBuilder(domainName).Uri;<br/>  IEnumerable&lt;string&gt; ipAddressStrings;<br/>  if (!Hosts.Map.TryGetValue(uri.Host, out ipAddressStrings)) {<br/>    return GetSerializedIPAddresses(Dns.GetHostAddresses(uri.Host));<br/>  }<br/><br/>  var addresses = new List&lt;IPAddress&gt;();<br/>  foreach (var addressString in ipAddressStrings) {<br/>    IPAddress newAddress;<br/>    if (!IPAddress.TryParse(addressString, out newAddress)) {<br/>        continue;<br/>    }<br/>    addresses.Add(newAddress);<br/>  }<br/>  return GetSerializedIPAddresses(addresses);<br/>}</pre>
<p>And if you run the application and <kbd>POST</kbd> hostnames to your endpoint, you'll notice that the IP addresses returned are always well-formed, and even the fully-qualified IPv6 addresses have been abbreviated. With this simple functionality, you can abstract away all of the mess of parsing and manipulating IP addresses within your application code. You can trust that the work is being properly handled for you by a robust implementation of both IPv4 and IPv6 under the hood.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we took an extremely close look at IP, first discerning precisely why IP, as a network layer protocol, was unique from the transport layer protocols that we've examined before it and then learning about the functions and use of IP through its origin. We looked at when the split was made between the transport layer responsibilities of TCP and the network layer responsibilities of what eventually became IP. In doing so, we established clear boundaries on the scope of IP and what functions it is meant to provide, and what functions fall outside its scope.</p>
<p>Once we established the scope and intent of IP, we looked closely at how it has evolved over the years. Starting with IPv4, we learned about the addressing scheme, how it came to be, and how it is used by network software to uniquely identify hosts on a network. We learned about the common mechanisms for distinguishing between a network address and a host address within the IPv4 addressing architecture. We also looked at how subnet masking can help with the distinction between those two fields in a single address. Once we covered the addressing architecture of IPv4, we looked at its limitations with regard to the total number of addressable hosts that IPv4 supports.</p>
<p>After exploring the full scope of IPv4, we looked at its current proposed replacement in IPv6, and saw how the updated addressing structure in the new standard can support an immense number of hosts in a single universal network. Then, briefly, we examined some of the interfaces that allow for IPv4 and IPv6 to coexist. Finally, we looked at the classes that C# provides for parsing and constructing IPv4 and IPv6 addresses in our software for the reliable routing of our network packets.</p>
<p>Now that we've seen how information is routed and delivered at the lowest level, it's time to consider perhaps the most important aspect of network interactions. So, in the next chapter, we'll be looking at how security is provided across networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>What are the two primary functions of IP?</li>
<li>What is classful addressing? What are the classes of IPv4 addresses?</li>
<li>What is variable length subnet masking?</li>
<li>What is address exhaustion?</li>
<li>What is the upper limit of the IPv4 address space?</li>
</ol>
<ol start="6">
<li>What is the structure of an IPv4 address? What about an IPv6 address?</li>
<li>What is Teredo tunneling?</li>
<li>What features does IPv6 enable?</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p><span>For your own reference, I strongly recommend reading the original RFC for IPv4. You'd be surprised how readable it is and how much information you can glean from just the underlying spec. It's also available for free, online, here: </span><a href="https://tools.ietf.org/html/rfc791">https://tools.ietf.org/html/rfc791</a>.</p>
<p>I'd also recommend, simply for its brevity, that you read the original IEN 2 to understand exactly what motivated the development of IP in the first place. It's also free to read online, and surprisingly engaging: <a href="https://www.rfc-editor.org/ien/ien2.txt">https://www.rfc-editor.org/ien/ien2.txt</a>.</p>
<p>Additionally, if you'd like to understand other ways to program for IP, I once again recommend <span><em>Understanding TCP/IP,</em> by <em>Alena Kabelová</em> and <em>Libor Dostálek</em>, available from Packt Publishing here: </span><a href="https://www.packtpub.com/networking-and-servers/understanding-tcpip">https://www.packtpub.com/networking-and-servers/understanding-tcpip</a>.</p>


            </article>

            
        </section>
    </body></html>