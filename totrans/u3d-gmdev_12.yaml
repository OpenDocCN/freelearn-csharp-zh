- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finishing Touches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to the *Finishing Touches* chapter! There is a misconception about how
    long games take to make and the overall difficulty of game development. This chapter
    will act as a toolbox to guide you in finishing your projects. This isn’t a straightforward
    next step, but rather an open box for you to see what we’re using to polish up
    our vertical slice. An interesting feature of the polishing process is that it
    covers a good 80% of game development. This might sound unintuitive; however,
    if you’ve been paying attention to the screenshots during the development, you
    will have noticed that we don’t have a complete game by any stretch of the imagination
    at this point from a consumer’s point of view. The mechanics work and the game
    is an experience by now, just not a complete one.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will go over:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asset finalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lighting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sound polish
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finishing touches are extremely important to a complete experience. We need
    to take what we have and tighten up all the stitches. This is done in several
    ways.
  prefs: []
  type: TYPE_NORMAL
- en: Lighting and sound are very difficult to finalize prior to this point. There
    can be **research and development** (**R&D**), but unless the game’s focus is
    one of those two topics, you won’t be getting finalized lighting or sound until
    there are finalized assets in the game, as seen in the list in the following section.
    You’re correct in wondering why we had a chapter on sound before this. We wanted
    to go over the basics of sound in general and get you familiar with the concept
    of sound design and its implementation within Unity.
  prefs: []
  type: TYPE_NORMAL
- en: Lighting could be worked on early to set a mood but will need to be finalized
    after environments and light pools are well defined and firm in place. Again,
    if lighting and mood are going to be in the experience, then heavy lighting R&D
    will need to take place even in the blocking-in stages of development. All the
    conversations here about lighting will guide you during that stage too if it’s
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: The way this will work is that there will be specific actions that we will cover
    in all three of the major sections in this chapter. These actions are specific
    to our project but could help you with your future projects all the same. Think
    of them as tools instead of a tutorial. Some of them may need programming, and
    some of them may not.
  prefs: []
  type: TYPE_NORMAL
- en: As most of the mechanics have been programmed to a certain degree, we will focus
    first on asset finalization. Remember, as we said, it’s hard to get lighting and
    sound if the assets aren’t done. Let’s start there!
  prefs: []
  type: TYPE_NORMAL
- en: Asset finalization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section will be awesome. There are so many great art assets and finishing
    touches that we can go over. Here is a list of tools we used that may help you
    in your projects in the future:'
  prefs: []
  type: TYPE_NORMAL
- en: Stylized pass on assets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detail normals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture cleanup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Texture blending
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environment clutter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detail meshes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cinematics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondary animation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The way we will go through these sections is that we will have an explanation
    of why we will be doing this for our project, which may help you decide if you
    need to perform these polishing touches on your own projects in the future. After
    that, we will cover the literal steps that we took so that you can see how they
    are done. Interestingly, the actual steps we are taking may not be the only way
    to achieve these finishing touches. The best way to take these actions is as a
    concept or a starting point as the needs will be different for your project. We
    will begin our finishing touches with a stylized pass on our assets.
  prefs: []
  type: TYPE_NORMAL
- en: Stylized pass on assets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When defining an art style, we begin with broad strokes. Even if you take the
    time to outline the art direction, once you get to the polishing phase, you will
    need to make a pass on it to get the finishing touches in place. In our case,
    we found that our assets didn’t have enough of a stylized look to them to fit
    our art direction. The word stylized is used very often and it has the right to
    be used often for games as it means to just not look realistic. In our case, we
    want the stylizing to make everything feel more illustrative in nature. This means
    we need to push all our contrasting silhouettes and colors into the textures.
    We also need broader line weights in our textures.
  prefs: []
  type: TYPE_NORMAL
- en: A good example within our project is Myvari’s necklace. This art piece needs
    to stand out as it is the primary focus of Myvari’s telekinesis. We also know
    that we will be seeing it up close during cinematics, so we need to ensure that
    we put time into designing this piece.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing indoor, chair, desk, blue  Description automatically
    generated](img/B17304_12_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.1: Stylized passes for Myvari’s necklace'
  prefs: []
  type: TYPE_NORMAL
- en: This needs to happen throughout all the art pieces to have as much consistency
    as possible within the character and the world. Once the stylized pass is completed,
    some models may need to have small details added. We call them “detail normals.”
    Let’s go over them now!
  prefs: []
  type: TYPE_NORMAL
- en: Detail normals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A detail normal can sometimes be considered part of the stylized pass. In our
    case, we wanted this to be a standout part of the art direction overall, so we
    pulled it out of the stylized pass. We want to drive home the stylized nature
    of the silhouettes in the models; however, we want to give the materials themselves
    a sense of realism. Leather will need to look like leather, and bark should look
    like bark. Below in *Figure 12.2*, we have a detail normal on the mushroom to
    give a bit of extra nuance to it. The left image has base normals and texture.
    The right image has detail normals layered on top.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing coelenterate, blue, colorful, hydrozoan  Description
    automatically generated](img/B17304_12_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.2: Left, no detail normal; Right, detail normal added'
  prefs: []
  type: TYPE_NORMAL
- en: Detail textures are also interesting as they are generally smaller details from
    a tileable texture that won’t fit nicely on the texture itself due to the sizing
    of the model’s texture. To gain the small details, we layered them in the shader.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.3: Detail normals'
  prefs: []
  type: TYPE_NORMAL
- en: Above is the shader we are using for our detail normal in *Figure 12.3*. The
    way we will break this down is by following the data connection points and explaining
    the reasoning per node. To start off, we begin with a UV node.
  prefs: []
  type: TYPE_NORMAL
- en: '**UV node** – This node sets the UV space you will be manipulating. The dropdown
    allows you to choose which UV map to manipulate. Since we are using the main UV
    channel, we will keep it at `UV0`. We will take the output of the UV node and
    input it into a Swizzle node.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Swizzle node** – The Swizzle node allows users to take an input and mix the
    channels to create an output with the data amount that is needed. You’ll notice
    that we have set `xy` as the output. Our input is a pin line, which refers to
    a `Vector4`, which is shown in the input of the Swizzle as well. We only need
    the red and green channels in this case, so we just request the `xy` or `rg` channel
    and we get a `Vector2` output green line. Unity’s `Shader Graph` already culls
    the rest of the channels, so we do not specifically need this, but it’s a good
    habit to only use the channels that you need to work with. We take this output
    into a Multiply node.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiply node** – We use a float parameter here for the customizability of
    the UVs down the line alongside the Swizzle input. The **Detail Normal Scale**
    parameter is exposed so we can make a change in the inspector later on, tweaking
    it to our needs. The output of this will go into the UV channel of a Sample Texture
    2D node.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sample Texture 2D node** – Another input to this node is our texture 2D parameter
    detail normal. We need to make sure that the **Space** option is set to **Tangent**
    as we will be affecting the tangents to reconstruct the normal later on. We will
    be taking the output and getting to a `Vector2` once again, but with a different
    method than Swizzle. We will be using a Combine node from the individual channels
    on the Sample Texture 2D node.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Combine node** – Taking in the R and G from the Sample Texture 2D node output,
    we combine it to make a `Vector2` that is sampling the texture we want and following
    the UVs we’re setting. Now we need to take this `Vector2` into a scale and bias
    it into a different range.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scale and Bias nodes (using multiply and subtract)** – The next two nodes
    are a basic math function to transform the `(0 to 1)` range to a `(-1 to 1)` range.
    We do this by multiplying by 2 and then subtracting 1 on both the X and Y vectors.
    This is important to us as we may want the normal to appear as concave, or going
    into the model. After we finish this function, we will take the output into a
    Normal Reconstruct Z node.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Normal Reconstruct Z node** – This node’s purpose is to derive the correct
    Z values for the input of R and G from the normal map we chose in the Sample Texture
    2D node.'
  prefs: []
  type: TYPE_NORMAL
- en: After this there are three more steps. We will be following individual figures
    for these next steps. We will take the output of this node and move it into a
    Normal Strength node.
  prefs: []
  type: TYPE_NORMAL
- en: '**Normal Strength node –** Plugging into the Normal Strength node are the normals
    we had as an output from the Normal Reconstruct Z node. There is also a float
    value for which we created a parameter named **Detail Normal Strength**. This
    can be seen below in *Figure 12.4*. We’re using this node so that if the normal
    map seems like it might have too much detail or is not visually appealing, we
    can tone it down a little. The parameter we set in the **Strength** input allows
    us to dynamically set the Detail Normal Strength per material.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B17304_12_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.4: Normal Strength node'
  prefs: []
  type: TYPE_NORMAL
- en: We take the output of this and put it into a Normal Blend node.
  prefs: []
  type: TYPE_NORMAL
- en: '**Normal Blend node –** We ultimately want these detail normals to be layered
    with the normal of the mesh itself. This is the node that we will be doing this
    with.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.5: Normal Blend node'
  prefs: []
  type: TYPE_NORMAL
- en: It will output a normal map with both normals inside the data. We will then
    place the output into a Boolean keyword parameter, which we named `Detail Normal?`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Boolean keyword** – This Boolean keyword is designed in a way to allow us
    to either use a detail normal or not. Since this shader is being used across many
    materials, we need a way to exclude a detail normal from being needed if a mesh
    may not have one. We’ve done this by having the input for `On` be the blended
    normals of the mesh and the detail normal. If it’s set to `Off` then just the
    mesh normal will be accepted.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.6: Detail normal Boolean keyword'
  prefs: []
  type: TYPE_NORMAL
- en: The output of this will then go into the **Master Stack Normal** input. When
    you create a material, if you want to have a detail normal, all you need to do
    is select `On` with the checkbox of the `Detail Normal?` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will work through cleaning up the architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture cleanup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The silhouettes of the current buildings may look good, but does the architecture
    make sense? This is an interesting design issue with building shapes. We need
    to ensure that the architecture looks like something that might be built by a
    living creature. This is a difficult task to get right as the creatures we’re
    looking to emulate don’t exist! They are fictional creatures, which means we need
    to be very clear on the path we take when architecting for them.
  prefs: []
  type: TYPE_NORMAL
- en: We know that they are focused on celestial bodies and time concepts. The shapes
    of space, planets, and the concept of time need to take part in the silhouettes
    of the buildings and materials. This may not mean an entire remodel of the pieces
    but more pushing the shapes so the language stands out enough to fit the culture
    we’re designing for.
  prefs: []
  type: TYPE_NORMAL
- en: We also need to get rid of some geometry that won’t ever be seen. This is in
    order to optimize the game and is important. In games, if you cannot see it, then
    it doesn’t need to render. Therefore, we do something called **backface culling**.
    This means that if you were to look at the back half of a sphere from the inside
    it would be invisible.
  prefs: []
  type: TYPE_NORMAL
- en: The backside of an object isn’t rendered as it’s not seen. If you didn’t do
    that then the sphere would have to render all the inside faces, which would be
    a waste of precious computer time; we need to render everything else.
  prefs: []
  type: TYPE_NORMAL
- en: Texture blending
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When building terrain or larger objects that need to connect, there is always
    a bit of a line that shows that the objects are 3D meshes. This is a common problem,
    and it can hurt immersion or break the experience if not worked with closely.
    There are several ways to make this better. You may add another mesh on top of
    the split. You could also layer or overlap the meshes to make a break in the model
    to let the player think that it was meant to be slightly broken. You could also
    perform something called **texture blending**.
  prefs: []
  type: TYPE_NORMAL
- en: One way that we have done this is through Y-up materials. They may have other
    names as well, but I call them that due to using the Y-up axis to blend in materials.
    What we do is ask the shader to blend in positive Y of the world normal values.
    We use this value at the Lerp value in our shader where the base texture is on
    the A channel and B is the moss or snow texture. Let’s look at *Figures 12.7*
    through *12.9* below for screenshots of the Shadergraph imagery. In *Figure 12.7*,
    we’re showing some rocks that have a single UV set with a rock texture. These
    rocks are exactly the same except we’ve duplicated them and rotated them to show
    the shader that we put together that places the texture on the world normals.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing indoor  Description automatically generated](img/B17304_12_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.7: Rocks with our Y-up shader applied'
  prefs: []
  type: TYPE_NORMAL
- en: The textures applied to this aren’t final moss textures, but they are designed
    to be contrasted to the rock to show the textures separately. This allows us to
    work through the differences easily with visuals. You’ll notice that the rocks
    are the same, but scaled and rotated. This is a strong way to provide reuse within
    your meshes in your scene so you don’t have to model so many rocks! Let’s look
    at the `Shadergraph` on how this works next.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.8: World normal Y-up for T value of Lerp'
  prefs: []
  type: TYPE_NORMAL
- en: We need to plan out how we will split the rendering of the texture on the mesh.
    The interesting thing is that we need to make the texture always appear on the
    top of the mesh regardless of how it’s rotated. We decided to take the normal
    vector of the world space and then multiply it by a `Vector3` that we named `Offset`.
    We want the positive Y, so the default value of our `Offset` parameter will be
    `(0, 1, 0)`. We have two more blending parameters. They are `Blend` and `Level`
    and they are both floats. The **Blend** parameter is a hard value from 0 to 1\.
    With 0 there is no blending and the rock is the only texture, and with 1 there
    is no blending where the other texture has a hard line. This is complemented with
    the `Level` parameter. The `Level` parameter should be set to **Slider** with
    the min value set to 0 and the max to 100, and the **Default** set to 1; these
    can be set in the **Node Settings** in the **Graph Inspector**. We added it in
    this shader to show that you can add more tools for your artists per material.
    At the end of this line of data is a saturate.
  prefs: []
  type: TYPE_NORMAL
- en: This ensures that the data sticks to the 0-1 range, which is what we need to
    be the T value of the Lerp, which we will go over next.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.9: Texture lookups and Lerp'
  prefs: []
  type: TYPE_NORMAL
- en: Above in *Figure 12.9* is our Lerp. Value is the base texture, and B is the
    Y-up texture. T is the output of our saturate in *Figure 12.8*. The output of
    the Lerp is going into our base color. This is only the beginning and you can
    bolster this by using normal maps and height maps to help mix the channels to
    make them even more seamless. We currently aren’t using extra maps in this shader,
    but the concept uses the exact same nodes, just with the additional maps as inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Environment clutter
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a job all on its own. Those who work with environment clutter are known
    in the industry as clutter artists. Their job is to place items to make the environment
    feel lived in. Currently, we have an environment that is mechanically designed.
    We know where Myvari needs to be to trigger cinematics. We know how she will work
    with the physics puzzles. What we don’t know is how the people lived in this space
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: What were these spaces used for before there were puzzles to open the doors?
    Should there be broken things around or did it all break down a long time ago?
    Should there be spiderwebs or plants growing over some pieces?
  prefs: []
  type: TYPE_NORMAL
- en: The clutter artists will have a set of small items to place around to make it
    feel like there was something going on here at one point in time. This is where
    we have an opportunity to tell small stories in every section.
  prefs: []
  type: TYPE_NORMAL
- en: Detail meshes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unity terrain can house detail meshes to place simple meshes, such as grass
    or small rocks. We explained this in *Chapter 5*, *Environment*, in the *Painting
    details* section briefly. The primary reason it’s in this chapter is to explain
    that there is more work to be done with the details. This is very similar to the
    clutter artist’s work; however, this isn’t specific to how the space was lived
    in but to develop the nature. In our case, we are using it for grass and rocks.
    We need to make sure that the grass and rocks are in a spot that makes sense.
  prefs: []
  type: TYPE_NORMAL
- en: This is primarily working through the finer details of cleaning up the scene
    in regard to the detail meshes.
  prefs: []
  type: TYPE_NORMAL
- en: Effects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Polishing effects are similar to polishing animations. They need to be finessed
    to ensure that it is stimulating the correct emotions of the viewer. Most of the
    effects in this vertical slice are meant to be ambient. We will be covering two
    effects. The first one will be the blocker to the stairs in the first portion
    of the cave. The second one will be Myvari’s telekinesis. We chose these two effects
    to cover in the book as they are quite unique from each other.
  prefs: []
  type: TYPE_NORMAL
- en: Stair blocker
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The stair blocker is there to create an obstacle for the player in going up
    the stairs. They need to find a way to disable this so they can progress. We decided
    to go with arcane energy moving upward in front of the stairs. This will be done
    purely through a shader, which means we will cover some simple techniques in the
    Shader Graph.
  prefs: []
  type: TYPE_NORMAL
- en: The image shown here, in *Figure 12.10*, of the effect is static, so jump into
    the project and look at the first puzzle area in front of the stairs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17304_12_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.10: Stair blocking effect'
  prefs: []
  type: TYPE_NORMAL
- en: This effect is made by utilizing a channel-packed texture with three unique
    cloud textures. The cloud textures are a grayscale perlin noise in Adobe Photoshop.
    We took each layer and placed it in the Red, Green, and Blue channels to have
    three textures in one image. This allows us to use multiple different clouds to
    build our own noise pattern when animating its UVs. To make this effect work,
    we needed a way to animate these UVs in multiple ways. We chose an A set and a
    B set, which we created in our parameters. Let’s go through all of our parameters
    to make sure we are on the same page. We will explain why we have each parameter
    as we grow out of this effect as seen in *Figure 12.11* below.
  prefs: []
  type: TYPE_NORMAL
- en: We have **Color**, which will be setting the overall color of the arcane magic.
    **Cloud Tex** will be the texture you can use for this shader. We then have **Offset**
    and **Tiling** with both an A and B version. We will cover the two parameters
    soon. Then we have two edges that are used for a Smoothstep node.
  prefs: []
  type: TYPE_NORMAL
- en: We need to first figure out how to make our texture animate. We will be using
    **Tiling**, **Offset**, and **Cloud Tex** to perform this initial section of the
    shader.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a phone  Description automatically generated with medium
    confidence](img/B17304_12_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.11: StairShield parameters from Blackboard'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at *Figure 12.12* below, we’ve previously seen the Sample Texture 2D
    and **Multiply** nodes. Let’s go over the **Time** node. This node gives you access
    to the game time, the sin and cos of the game time, the delta time, and a smoothed
    delta. We will be using game time and multiplying it by a constant value for our
    speed. The next node that is new is the **Tiling And Offset** node. This node
    is a utility node to help deal with tiling and offsetting the UVs on a mesh that
    the material will be applied to. We assign the offset `Vector2` to the multiplication
    of time. This will provide a moving value for our offset. This will animate the
    UVs in the direction you want them to move.
  prefs: []
  type: TYPE_NORMAL
- en: The last part is to plug the Tiling And Offset node into the UV input of the
    Sample Texture 2D node. You aren’t seeing the Offset and Tiling B set in this
    image as it’s the same nodes with different parameters. The reason we want to
    have multiple sets is that we want to have independent textures with different
    speeds and UV tiling scales. This makes a dynamic texture in the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a video game  Description automatically generated](img/B17304_12_12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.12: Offset and Tiling for our cloud texture'
  prefs: []
  type: TYPE_NORMAL
- en: We need to put together a seemingly never-ending tiling pattern. All of these
    noise patterns are tiling in both horizontal and vertical directions. Sometimes
    this is called a four-way tiling texture. We had planned to move Offset A up in
    the Y axis by a faster amount and then Offset B a bit slower. We would also tile
    the B set somewhere between .5 and .75\. This would give us a totally different
    set of noise to layer on top of the other.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B17304_12_13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.13: Crossing the channels'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 12.13* above we are making three dynamic images to put together.
    Both Sample Texture 2D nodes have different tiling settings and different offsets
    moving in time. Putting them together with a multiply will inevitably create a
    living cloud structure as they cross paths. We’re doing that with all three channels
    `(R, G, B)`. Next, we will multiply each of these by 5 to force the entire image
    channels higher than their original. Then we add together the three channels into
    one output by adding the first two multiplied nodes, then adding the third one
    to that, as seen below in *Figure 12.14*.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a video game  Description automatically generated](img/B17304_12_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.14: Multiply and Add'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a single data stream with movement, we can push values to make
    a more interesting effect. We like to smoothstep data to push anything that is
    close to 0 to 0 and what is close to 1 to 1\. This makes the layered data make
    interesting shapes as seen in *Figure 12.15* below. The problem with this is the
    overall cloudiness is lost in that process, so we want to add in the previous
    **Add** and then saturate it to make sure it’s within the range 0-1 and then multiply
    it by a color parameter so we change the color in the inspector.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a video game  Description automatically generated](img/B17304_12_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.15: Smoothstep and color'
  prefs: []
  type: TYPE_NORMAL
- en: The output of the color node will go into the base color. We then make a material
    that uses the `SH_StairShield` shader, then apply it to a plane in the scene where
    we wanted to show there is something blocking the stairs.
  prefs: []
  type: TYPE_NORMAL
- en: Shuriken system – stair blocker particles layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We like the way the stair block feels, but the effects need layers to feel like
    well-made art. We also needed to spend a bit of time going over Shuriken itself.
    This effect will go over some basic portions of Shuriken for producing simple
    effects to layer into your world. What we will be creating is a stretched sprite
    moving upward to give more energy to the stair blocker.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, we wanted to make something with a default item to show the power
    of particle systems. We are using the `ParticlesUnlit` material, which is a simple
    radial gradient from the center. We sometimes call these “math dots” as they can
    be created without a texture. We want to spawn particles that have a lot of energy
    upward but get slowed down near the end of their life and fade out. We will go
    through the settings below to make this happen; however, we encourage you to look
    in the project at the particle system and play with the settings. Make some changes
    to see if you can make something you feel looks better. Share it on Discord!
  prefs: []
  type: TYPE_NORMAL
- en: The Shuriken system has a large number of parameters inside the modules. We
    will only be going over the ones we modified and needed to enable for this simple
    system. We implore you to look through the Unity documentation for an explanation
    of all the parameters and modules. Let’s look at the main module first, below
    in *Figure 12.16*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated with medium
    confidence](img/B17304_12_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.16: Shuriken main module'
  prefs: []
  type: TYPE_NORMAL
- en: The only parameters we made changes to here were **Start Lifetime**, changing
    it to 1.4, and **Start Speed**, setting it to 0\. We made the lifetime change
    after making all of the other changes as we didn’t know exactly how long we wanted
    this particle system to live. The **Start Speed** we put to 0 because we knew
    we wanted to control the velocity. We also modified the color but we’ll override
    the color in the **Color Over Life** module later on. The next module we will
    go over is **Emission**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17304_12_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.17: Emission module'
  prefs: []
  type: TYPE_NORMAL
- en: As seen above in *Figure 12.17*, this is the **Emission** module. We changed
    **Rate over Time** to 30 to make sure we have plenty of particles spawning. The
    emission of your particles is highly dependent on what you need to convey. For
    us, we wanted to have enough to add to the stair barrier shader, but not too much
    that we overpower it.
  prefs: []
  type: TYPE_NORMAL
- en: We now have a bunch of particles spawning, but we know we want it to be spawning
    near the bottom of the stair blocker. We will use the **Shape** module to restrict
    the spawning to a location that makes sense to the purpose of the effect.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_18.png)![A
    screenshot of a video game  Description automatically generated](img/B17304_12_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.18: Shape module and shape placed in game'
  prefs: []
  type: TYPE_NORMAL
- en: We chose the shape to be a box as we wanted the particles to spawn from the
    bottom of the stair blocker and move up from there to follow the flow of the movement.
    We then needed to get these particles moving. We know we wanted them moving upward
    quickly, thus setting 100 in **Linear Z**, shown in *Figure 12.19* below. This
    blasts them off to space, but we want to add a drag component to our velocity
    to slow them down near the top. This comes from the limit **Velocity over Lifetime**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.19: Velocity over Lifetime module'
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 12.20* below shows where we will add drag to our particles. We’re keeping
    the drag at a constant value and setting it to 5\. This value gave it a nice drag.
    This value wasn’t known beforehand; we just play around with it until it feels
    like what we’re looking for.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, electronics, screenshot  Description automatically
    generated](img/B17304_12_21.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.20: Limit Velocity over Lifetime module'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to colorize these particles as they are just white math dots going
    upward. Enabling the **Color over Lifetime** module, seen below in *Figure 12.21*,
    allows you to define a gradient where the left side is the beginning of the particle’s
    life, and the right side is the end of the particle’s life, including the alpha
    of the particle if your material is set up to accept alpha.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17304_12_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.21: Color over Lifetime'
  prefs: []
  type: TYPE_NORMAL
- en: Clicking on the gradient will pop up a gradient editor, which is seen below
    in *Figure 12.22*. The top of the gradient is the alpha and the bottom is for
    the color. Try to change the color on them to see it change the particles!
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.22: Gradient Editor'
  prefs: []
  type: TYPE_NORMAL
- en: Now we set the render mode from the **Renderer** module. Since we knew that
    we wanted the particles from the beginning to be stretched from the velocity,
    we changed this setting to **Stretched Billboard** very early. If you decided
    to follow along with this particle creation, your particles would look like colored
    dots instead of streaks.
  prefs: []
  type: TYPE_NORMAL
- en: Changing the **Render Mode** to **Stretched Billboard** will fix that, as shown
    below in *Figure 12.23*. We also set **Speed Scale** to 0.1 as they are moving
    very fast, which makes them stretch very far if you go much higher than 0.1\.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17304_12_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.23: Renderer module'
  prefs: []
  type: TYPE_NORMAL
- en: By going through these, we have just shown a simple example of a stretched particle
    to show some of the systems available. The power comes into play when you add
    shaders to the particles. A well-designed visual effect can trigger the emotion
    of an action happening. Though this may seem daunting at first, if you break down
    what you need, it becomes more of a fun time playing with the settings to get
    the right feel for your need. You will see other Shuriken effects around the level
    when you get into the project. Feel free to break them apart and put them back
    together to learn about the differences in the settings and how they play a part
    in the role of the visual effect.
  prefs: []
  type: TYPE_NORMAL
- en: We will be going over VFX Graph in the next section. This is another particle
    system creator that allows us to create GPU particles. This is a different way
    of working as it has its own system design and UI outside of the inspector. Let’s
    get into an example we are using in the project.
  prefs: []
  type: TYPE_NORMAL
- en: VFX Graph – Myvari’s telekinesis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Telekinesis can look like anything. We want it to seem as though Myvari is harnessing
    celestial energy that is flowing from her toward the object she is controlling.
    For this portion, we will cover how we set up the entire VFX Graph, shader, and
    a bit of code for implementation.
  prefs: []
  type: TYPE_NORMAL
- en: We will assume that you have the VFX Graph package installed already and have
    opened up the `FX_BeamSetup` **Visual Effect Asset**.
  prefs: []
  type: TYPE_NORMAL
- en: The **Spawn** context starts out by default with a constant spawn rate block
    in this context. We want to just burst one time with 32 particles that we want
    to manipulate as long as the strip is up. We deleted the constant spawn and put
    in place a **Single Burst** block instead, as seen in *Figure 12.24* below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.24: Spawn context'
  prefs: []
  type: TYPE_NORMAL
- en: The number 32 wasn’t a special number from the beginning. We weren’t sure how
    many we would need, but it’s easy enough to add more during the process of creating
    the strip. Below in *Figure 12.25* is our **Initialize** context. We need to set
    **Particle Per Strip Count** to the same number as the spawn in the burst above.
    We want a **Set Size** block and a **Set Custom Attribute** block. This attribute
    block will be a float data type and we called it `InterpolatedPosition`.
  prefs: []
  type: TYPE_NORMAL
- en: The reason we called it this is that we want to have an index of every particle
    so we can individually place them where we want them.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.25: Initialize context'
  prefs: []
  type: TYPE_NORMAL
- en: We can see in *Figure 12.26* below that we are getting the particle index and
    then dividing it by one less than the total amount. The index starts at 0, so
    we need to start from one below the number we spawned. This gives us a value that
    we can work with and is stored in the float custom attribute we made.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a video game  Description automatically generated](img/B17304_12_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.26: Particle Index nodes'
  prefs: []
  type: TYPE_NORMAL
- en: Now we have a particle strip that needs to have a position to go to. We will
    make two transform parameters in the blackboard just like we do in the Shader
    Graph. We named them `BeamStart` and `BeamEnd`. We will Lerp the particles’ positions
    from the beam start to the beam end according to the interpolated position float
    we initialized with. Looking at *Figure 12.27* below, you can see how we connect
    them together. The output of the Lerp will go to the **Update Context**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_28.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.27: Positioning the beam'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the update context we have two blocks as seen below in *Figure 12.28*: **Set
    Position** and **Add Position**. We will be adding the output of the Lerp for
    their position into this block. There is one trick that will make some strange
    movement happen. On the **Set Position** block there is a small *w* in the middle.
    If it is an *L,* then that means it’s moving the local position. This will cause
    double transforms when moving around the GameObjects. If you click on the *L*
    it will change to *w*, which stands for world space. It is fine to leave **Add
    Position** in local space.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B17304_12_29.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.28: Update context'
  prefs: []
  type: TYPE_NORMAL
- en: Currently we have a straight beam from start to end. This is fine for testing,
    but we need something a bit more fun. Let’s add some turbulence so it isn’t so
    rigid. We will use the Add Position block and the input for that will be some
    manipulations of 3D noise. This has a few more nodes to make the right data for
    nice turbulence, but we will walk through them.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at *Figure 12.29* below, these five nodes are all we need. We want to
    get our current position, then add that to time. We have a **Multiply** node in
    between there so we could speed up or slow down the time value. This could be
    a variable that’s tunable as well. After **Add** is a **Perlin Noise 3D**. The
    values here are purely subjective. Place your coordinates in the **Coordinate**
    slot and then place the output derivates into the **Add Position** block input
    in the **Update** context. From there, play around with the values until it gives
    you the nice turbulence you want. There is a problem with this approach. This
    will update every particle, including the beam start and beam end. This feels
    odd as we wanted it to come from our character’s hand.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_30.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.29: 3D Perlin Noise for turbulence'
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that the beam start and end are independent of this, we went with
    a simple gradient to tell the position whether or not it should be using the turbulence.
    Looking at *Figure 12.30*, we see that we take the interpolated position value
    and sample it across that interpolation with time. The gradient now acts as a
    transfer to which particle will be affected. The 0 value at the beginning and
    end of the strip will make 0 values multiplied with the derivatives from the noise
    generator. Now we plug this into the **Add Position** block.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_31.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.30: Mask for the turbulence'
  prefs: []
  type: TYPE_NORMAL
- en: We’re in the home stretch for setting up the VFX Graph portion. The **Output**
    context is shown in *Figure 12.31*. By default this will be an **Output Particle
    Quad**. This won’t do us any good, so delete it if you have it on your VFX Graph
    and press the spacebar to make a new node. Then type `particlestrip`. You’re looking
    for the **Output ParticleStrip Quad**. The one below has unlit in the name; this
    is due to the material being used.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_32.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.31: Output ParticleStrip Quad context'
  prefs: []
  type: TYPE_NORMAL
- en: The shader is a duplicate of `SH_StairShield` with one change. In the **Graph**
    inspector, the **Support VFX Graph** Boolean is set to true. This shader has enough
    versatility to get the job done for now. We may change the texture before its
    final use, but for now it has what we need to get it going. We then assign it
    to the Shadergraph attribute in the output context. This will expose the parameters
    in the shader.
  prefs: []
  type: TYPE_NORMAL
- en: There are two more steps to finalize this effect. We need to create the GameObject’s
    beam start and beam end, and then implement this effect by placing the locations
    of the GameObjects during gameplay.
  prefs: []
  type: TYPE_NORMAL
- en: To start, let’s make our prefab. Below in *Figure 12.32* we made an empty GameObject
    and named it `Telekinesis`. Then we placed the beam setup object as a child and
    set its position at `0, 0, 0`. Then we created two more empty GameObjects and
    named them `BeamStart` and `BeamEnd`. We also set these positions at `0, 0, 0`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17304_12_33.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.32: Telekinesis prefab'
  prefs: []
  type: TYPE_NORMAL
- en: There is a component you can add to VFX Graph assets called **VFX Property Binder**.
    Add this component to the `FX_BeamSetup` GameObject. We then create two bound
    properties to the transform and name them the same as the properties in the VFX
    Graph (`BeamStart` and `BeamEnd`). Drag the GameObject into the **Target** slot
    to reference the GameObject’s transform. Do the same for `BeamEnd`. This will
    look like *Figure 12.33* below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_34.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.33: VFX Property Binder component'
  prefs: []
  type: TYPE_NORMAL
- en: We now need to go over the implementation. The considerations here are that
    the start of the beam needed to come from our character’s left hand. We also know
    we need the end to be attached to the item we are controlling with physics. We
    also need to turn on and off the visual effect only when the interact button is
    interacting with a physics puzzle item. We will be working with `DragRigidBody.cs`.
  prefs: []
  type: TYPE_NORMAL
- en: This script takes the center of the screen as a point of reference and if you
    are within range of the physics item that you can interact with, it will give
    Myvari control of that Rigidbody from the use of the physics puzzle pieces scripts
    we went over in *Chapter 6*, *Interactions and Mechanics*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fields to add:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: These will be assigned in the editor and should be self-explanatory except possibly
    the `leftWristLoc`. This transform is from Myvari’s joints in her hierarchy. Expand
    her hierarchy and drag the left wrist onto this slot in the inspector.
  prefs: []
  type: TYPE_NORMAL
- en: In the update, we want to turn off the beam if the interact button is released.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: After this we need to work with the `FixedUpdate`. We are working with physics,
    so we need to ask the program to check if we have a Rigidbody, and on the `FixedUpdate`,
    we will turn on the beam if true and set the positions of the `beamStart` and
    `beamEnd` at every `FixedUpdate` loop with the physics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This is it! Save your files, get back in the editor, and assign the transforms
    and visual effects to the script. This script is located in `Main Camera`. *Figure
    12.34* below shows the selected object with the script.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B17304_12_35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.34: Main Camera location for telekinesis scripting'
  prefs: []
  type: TYPE_NORMAL
- en: Particle effects and shader work are always interesting problems to be handled
    with care. Too much of a good thing ends up not feeling good. When working through
    a level, take a moment to think about the tiny details and see if it makes sense
    to add small movements to sell the experience.
  prefs: []
  type: TYPE_NORMAL
- en: From the above two effects, there is quite a bit of thought put into each visual
    effect no matter the size of the effect. Take your time going through each effect
    in the game to break down the parts.
  prefs: []
  type: TYPE_NORMAL
- en: Cinematics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our project, we’re using cinematics for three purposes. The first one is
    to explain that the area has been around a long time, so the areas are fragile.
    The second one is showing the player that Myvari has innate powers by her defending
    herself against a falling boulder. The third cinematic is the ending scene when
    she puts on her tiara and goes through the portal after finishing the final puzzle.
  prefs: []
  type: TYPE_NORMAL
- en: The way that we work through cinematics is we export the models while they are
    in place in the environment. This allows us to make sure that our cinematics match
    with the environment with as much precision as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Secondary animation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes there needs to be additional animation that is easier to simulate
    than it is to rig and hand-key. Hair is a good example of this. The actions that
    hair takes are a secondary animation after momentum is gained. Hand-keying this
    is possible but takes a lot of patience and can be done instead with physics.
    We will be using Unity’s Spring Joint component for this. There are also several
    assets in Unity’s Asset Store that have been made to make this process more robust.
    If you need just simple physics for your secondary animation, it can be done through
    the Unity physics Rigidbody component, the Spring Joint component, and capsule
    colliders.
  prefs: []
  type: TYPE_NORMAL
- en: Lighting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve decided to put lighting in the finishing touches, but this could have
    had its own book. This is one of those topics that are a massive rabbit hole.
    We wanted to go over some basics of lighting here and the reason why it’s important
    to pay attention to lighting, as well as highlighting a few polishing tools and
    how to use lighting in Unity.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to explain that lighting is an art. The purpose of lighting includes
    defining 3D form, providing mood, and designing methods for gameplay. After we
    go through a few design thoughts on lighting, we will take a tour of the Unity
    mixed lighting, lightmaps, reflection, and light probes.
  prefs: []
  type: TYPE_NORMAL
- en: 3D form
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Without lighting, a 3D form is flat. In fact, we use unlit shaders for most
    effects. One reason is that we don’t need to add shadowing and lighting for small
    shiny effects that will only be on screen for a short time. They are flat and
    don’t need lighting to help define them; their texture shape does that work for
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Providing mood
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This goes along with the design of the areas but is focused specifically on
    the lighting. Is the alleyway getting darker as you walk down it? This could push
    a sense of danger or nervousness in your player. Do you want unnatural lighting
    colors around certain areas to give an arcane feeling inside a mage’s house? Completely
    possible! All of these decisions should be thought about when placing lighting.
    In the same vein as mood, we could want our lights to define the gameplay.
  prefs: []
  type: TYPE_NORMAL
- en: Gameplay design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gameplay can be defined through light in many ways. In fact, your entire game
    could be designed around light.
  prefs: []
  type: TYPE_NORMAL
- en: Horror games often use light sources as a way to push away enemies, but it’s
    limited to a small timer as your batteries are inevitably running out! Taking
    a unique route, an older game named Boktai used a light sensor peripheral for
    the Game Boy to charge up your weapons, and if you played it in the dark the game
    was more difficult.
  prefs: []
  type: TYPE_NORMAL
- en: These concepts are a bit on the edge of gameplay elements. We could just use
    light to give the player an idea of where to go, or where to stay away from. We
    probably have a good idea now about general concepts of lighting design and how
    it can influence the player’s experience. Let’s dig into Unity lighting.
  prefs: []
  type: TYPE_NORMAL
- en: Unity lighting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get to a polished state we need to go over the basics first. This will be
    an overview of what you are capable of doing in Unity for lighting, and then we
    will be going over what settings and uses we have for our project. Built-in renderer,
    URP, and HDRP lighting are all different from each other. We will be talking about
    URP lighting specifically. We will also be pushing for a certain feel and explaining
    features that helped us achieve the desired look that we aimed for in our vertical
    slice. Each lighting asset can be configured in different ways, which means that
    these steps will only give as much help as needed to get your feet wet with lighting.
    After you go through this and play around with what we explain, we highly recommend
    reading the documentation for other lighting objects for different rendering pipelines
    depending on the needs of your project. Now that we’ve gone over the construct
    of lighting here, we will begin by talking about mixed lighting.
  prefs: []
  type: TYPE_NORMAL
- en: Mixed lighting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’re taking a slight shortcut here by going into mixed lighting from the start.
    To utilize mixed lighting properly, you need to be using indirect baked lighting
    and dynamic lighting. We will touch on both right now, then get back to mixed
    lighting.
  prefs: []
  type: TYPE_NORMAL
- en: Indirect baked lighting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Real-time lights, that are casting light rays onto static GameObjects bouncing
    off geometry in the world, will be baked onto a lightmap. Those terms are new!
    Static game objects are defined by selecting the **Static** checkbox in the inspector,
    as seen in *Figure 12.35* below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.35: Static checkbox'
  prefs: []
  type: TYPE_NORMAL
- en: hen this is selected, when the game is baking its lightmaps into the Lightmap
    UVs, it will know to add this to the items to bake. You would only choose this
    to be static if you know for certain you will never move the GameObject that you
    would make static. We are fairly certain this concrete fence will remain solid
    the entire game, so we selected it as static. The next term is lightmap. This
    is a secondary set of UVs that are not allowed to overlap with the object that
    you want to bake the lighting onto. When you import a model, you can let Unity
    generate the lightmap UVs for you, and it does a decent job at taking care of
    this. You can do this by selecting the FBX for the 3D model and choosing **Generate
    Lightmap UVs**, as in *Figure 12.36* below.
  prefs: []
  type: TYPE_NORMAL
- en: When you select the checkbox, Lightmap UV settings will show up. These values
    are the average per object you have in your scene. These settings will do a decent
    job of setting up the basics but you may need to look into each attribute to make
    sure each object receives light the way you would expect it to.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B17304_12_37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.36: Generate Lightmap UVs option'
  prefs: []
  type: TYPE_NORMAL
- en: That is for the objects that receive light. As for the lights, you can set any
    available light to be a baked light. Directional, spot, point, and area light
    are all available to be added to lightmaps when generating or baking lighting.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic lighting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This is also referred to as real-time lighting. Real-time lighting has to deal
    with real-time shadows and many settings involved with this. Real-time lighting
    is applied to any item that wasn’t chosen as static. Skeletal meshes are always
    real time as they cannot be static. Their nature is to move!
  prefs: []
  type: TYPE_NORMAL
- en: In our URP asset we can see that in the **Shadows** settings, we can set the
    distance to where the quality of shadows goes down. Below in *Figure 12.37* you
    can see this range in the **Shadows** section.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_38.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.37: URP Shadows settings'
  prefs: []
  type: TYPE_NORMAL
- en: Each real-time light will use these settings for the shadows. **Cascades** are
    how many times the light quality goes down. It’s set in meters by default. This
    can help us design the limits as we know how tall our characters should be in
    general. 1 Unity unit is by default 1 meter. You could set up a test scene to
    see what the shadows would look like for the distance of each cascade to help
    make these decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Something that’s unique to real-time lights is the four lights that are available.
  prefs: []
  type: TYPE_NORMAL
- en: The directional, point, and spot lights are available for real-time lighting
    information. Area lights cannot create real-time shadows.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve gone over the basics of real-time and indirect lighting, we need
    to get back into mixed lighting mode. First, we need to let you know how to put
    lights on the scene. In *Figure 12.38* below you can see the list of lights. You
    can access this menu just as you create any GameObject, by right-clicking in the
    hierarchy or going to the GameObject menu and hovering over the **Light** option
    to get the submenu seen in *Figure 12.38*.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing graphical user interface  Description automatically
    generated](img/B17304_12_39.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.38: Light options'
  prefs: []
  type: TYPE_NORMAL
- en: Now we need to get back to mixed lighting. We’ve talked about both lighting
    modes. Some games may only use baked lighting while some games might only use
    real-time lighting. The majority will use both in URP. When you select any light
    that you make, the inspector has an option to choose real-time, mixed, or baked.
    Remember, baked means baked indirect light. The best part of mixed is that it
    allows the light to be baked where it is, but acts as dynamic when introduced
    to a non-static GameObject. This is useful for the directional light. This light
    acts like the sun, so we want it to bake for the static items, but be dynamic
    for the character or anything non-static. You can see this selected within the
    inspector in *Figure 12.39* below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17304_12_40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.39: Directional light set to mixed'
  prefs: []
  type: TYPE_NORMAL
- en: Even after you’ve set all the meshes to static that you need to, and placed
    lights and set them to either real-time, baked, or mixed, you still need to set
    up your lighting settings within the lighting window. To get there, use the screenshot
    below, in *Figure 12.40*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_41.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.40: Path to the lighting window'
  prefs: []
  type: TYPE_NORMAL
- en: Within the window that pops up, you will have several tunable settings. These
    settings are going to be unique for every project. We know that we want some nice
    shadow fidelity. This means we need more samples and higher resolution for our
    lightmaps. We’re also going to be fairly close to the character in the game and
    during cinematics, which is still real time. These factors need to be considered
    when thinking about your settings. You could potentially crank up the settings
    and have nice shadows with a huge light bake, but then your real-time shadows
    might not be able to handle it and will be blocky, which will cause the game to
    have a strange feel to it. It’s good to consider the system your game will be
    played on and thoroughly test the performance again after adding more lights and
    lightmaps.
  prefs: []
  type: TYPE_NORMAL
- en: There is another tool to use to gain more accurate real-time lighting information
    inside Unity without needing to have a lot of real-time lights. It is called light
    probes. Let’s take a look at that tool.
  prefs: []
  type: TYPE_NORMAL
- en: Light probes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creating light probes is as easy as going to your **Light** GameObject group
    and selecting **Light Probe Group**.
  prefs: []
  type: TYPE_NORMAL
- en: You can see this in the options three figures above in *Figure 12.38*. What
    this tool does is sample the lighting information at points in 3D which are shown
    in *Figure 12.42*. That information is then used in real time even if the lighting
    is baked information only. This is very helpful if you want to use the coloration
    from an area light (which is only baked) and add it to a character. Think about
    a light on a wall where you don’t need to cast a shadow or for it to be real time.
    Instead of being resource-intensive, you can just use light probes around that
    area and it will help pick up on non-static geometry in real time.
  prefs: []
  type: TYPE_NORMAL
- en: To set this up though, you need to place light probes by hand. There are assets
    on the Asset Store to automatically place them but keep in mind that anything
    automated in the entertainment industry needs to have an artist’s input to achieve
    what the experience needs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Light Probe Group** when editing the group looks like *Figure 12.41* below
    in the inspector.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_42.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.41: Light Probe Group component in inspector'
  prefs: []
  type: TYPE_NORMAL
- en: You can add, delete, select all, and duplicate selected. When you’re placing
    Light Probes, just know that they are averages of multiple color locations. These
    aren’t a perfect representation of the light in one area, but more of an approximation
    to give a bit of extra boost to ensure the mood is kept for the real-time actors
    in the game. With that being said, add probes until they form a nice lattice.
    The more you have, the more computational power it will take. For each project,
    as usual, it will depend on the system to know how many light probes will be allowed
    for performance.
  prefs: []
  type: TYPE_NORMAL
- en: After you’ve placed them, you can either press play and walk around, or just
    drag your non-static GameObjects around the scene to see the lighting shift slightly.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example of the initial hallway of our vertical slice’s light probe
    lattice in *Figure 12.42*.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing indoor, athletic game, tennis  Description automatically
    generated](img/B17304_12_43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.42: Light Probe lattice'
  prefs: []
  type: TYPE_NORMAL
- en: This can take some time and will be done after placing your lights. If you change
    up your lighting configuration, make sure to rethink your light probes as well
    afterward. There is just one last thing before we get to polishing sound. We want
    to go over reflections.
  prefs: []
  type: TYPE_NORMAL
- en: Reflection probe
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are materials in the world that reflect the color of the environment.
    These are metallic and/or glossy materials. The problem is, what do they reflect?
    I’m happy you asked that because Unity initially will create a reflection map
    of just the skybox so there is something reflected in those materials. There is
    another tool you can add to your scene, which is a reflection probe that will
    allow you to designate a volume that has the reflection data in that area. You
    can also have overlapping volumes.
  prefs: []
  type: TYPE_NORMAL
- en: This is an interesting issue as it’s not a perfect representation as the probe’s
    reflection position is from the center of the position of that probe. If you have
    a large area, and you need to be very close to the reflections while also needing
    that reflection to be accurate, you will need multiple reflection probes, with
    each probe’s volumes only as large as you need them. The smaller the volume, the
    crisper the reflection image. These types of things won’t be very clear until
    you have run around the world and looked for this or worked through the cinematics
    of your game and seen a strange-looking reflection. There is a small caveat here;
    you can create real-time reflections, but they are very expensive. These should
    be used with caution. That is until we all have quantum computers in our houses.
  prefs: []
  type: TYPE_NORMAL
- en: To create a reflection probe, the option is in the same place as all the rest
    of the lighting, in the GameObject menu under **Lighting**.
  prefs: []
  type: TYPE_NORMAL
- en: When you create the probe and place it in the location you want to reflect around,
    you will have to then use the inspector to edit the volume, which looks like the
    below *Figure 12.43*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.43: Reflection Probe component in the inspector'
  prefs: []
  type: TYPE_NORMAL
- en: The top-center two icons are for editing and moving the volume. Selecting the
    points icon gives you access to the volume’s shape to shrink and grow it to your
    needs. The type can be **Baked**, **Real-time**, or **Custom**. **Baked** will
    only be baked once and cannot change during runtime. **Real-time** changes as
    the game is running every frame. **Custom** allows you to place your own custom
    cubemap instead of sampling the environment. This could be useful if you want
    to distort the environment in the reflections! The cubemap settings are to tweak
    the cubemap’s scale and parameters to increase the needed fidelity at a performance
    cost.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most important settings is the **Importance** setting! This setting
    is an integer that you set to tell the game which reflection probe is being displayed
    when there are overlapping reflection volumes.
  prefs: []
  type: TYPE_NORMAL
- en: The way this works is that the higher the number, the higher the importance.
    If you have two overlapping volumes, such as inside the entrance to a cave versus
    right outside of it, you would then set the hallway to importance level 2\. This
    way when you enter the volume that is of higher importance, the reflection probe
    will switch to it. This can cause some popping on very close reflection surfaces.
    Play through your game and pay attention to reflections when they transition.
  prefs: []
  type: TYPE_NORMAL
- en: Adding lighting overall is a fun task. It can greatly improve the graphical
    quality of your game and there are some great tricks to set that up. Next up is
    sound polish.
  prefs: []
  type: TYPE_NORMAL
- en: Sound polish
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have a few things we can do to make sounds in our game more believable. Sound
    polish comes down to tweaking the volume of sounds, changing the minimum and maximum
    attenuation distances, and even replacing sounds that you feel don’t sound good.
  prefs: []
  type: TYPE_NORMAL
- en: These are all things we’ve adjusted throughout the project already. For example,
    on one of our first ambiences, we can adjust the volume or pitch to see what feels
    right. Or we can change the minimum or maximum distances on the attenuation, add
    sounds that we may have missed, make sure that certain sounds that are more important
    are louder than others, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, mixing and sound polish is a very iterative process of just manipulating
    the values and replacing sounds with other sounds to get a feel for what’s best.
    You never know how a sound will fit with the rest of the sounds until you place
    it in the game.
  prefs: []
  type: TYPE_NORMAL
- en: Triggering sound through animation events
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We wanted to show you how to add sound to an animation event. It’s quite an
    easy process as we already know how to add animation events, and how to trigger
    sounds using `AudioSource` components. We’ll be adding footstep sounds to our
    character walking.
  prefs: []
  type: TYPE_NORMAL
- en: 'First let’s select our character, the `MyvariWithCameraRig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17304_12_45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.44: MyvariWithCameraRig'
  prefs: []
  type: TYPE_NORMAL
- en: Then let’s drop down into its child objects to find the `SM_Myvari` GameObject.
    Here you will see the animator component! We only need a few things here.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s create a new script and call it `AnimationSounds`, then we’ll
    put this right below our **Animator Component**. After this, we’ll add our `AudioSource`
    component. It should all look something like *Figure 12.45* below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_46.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.45: SM_Myvari inspector window'
  prefs: []
  type: TYPE_NORMAL
- en: Before we continue forward, let’s add a function to our `AnimationSounds` script.
    Remove the **Start** and **Update** functions and add a new one called `PlaySound()`.
    Above this new function, declare a new public variable called `public AudioSource`
    `AnimSound`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B17304_12_47.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.46: Our new AnimationSounds.cs'
  prefs: []
  type: TYPE_NORMAL
- en: Now, inside of our `PlaySound()` function, let’s add `AnimSound.Play()`.
  prefs: []
  type: TYPE_NORMAL
- en: Next, in the inspector, we can add the `AudioSource` component to the serialized
    field in the `AnimationSounds.cs` component and add a footstep sound effect!
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_48.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.47: AnimationSounds.cs script in the inspector'
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! Now we can move on to tagging our animation with events.
  prefs: []
  type: TYPE_NORMAL
- en: Tagging animations with events for sound
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One big problem that we have with adding animation events is that we can’t add
    events directly through the animation window, so we’ll have to open up the FBX
    file inside of Unity.
  prefs: []
  type: TYPE_NORMAL
- en: The best way to do this is to go into **Assets** > **Animations** and select
    the `Myvari_Walk_Basic` FBX.
  prefs: []
  type: TYPE_NORMAL
- en: '![Application, icon  Description automatically generated](img/B17304_12_49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.48: The project explorer in Unity in the Assets > Animations folder'
  prefs: []
  type: TYPE_NORMAL
- en: Next we’ll scroll down on the inspector until we reach the **Events** dropdown.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B17304_12_50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.49: Animation clip inspector window'
  prefs: []
  type: TYPE_NORMAL
- en: Open up that **Events** dropdown, and also open up the **Preview** window at
    the bottom of the inspector.
  prefs: []
  type: TYPE_NORMAL
- en: 'It might be hidden at the bottom of the inspector, but you can click and drag
    from the bottom to bring it up! It should look something like *Figure 12.50*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_51.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.50: Animation Clip inspector window preview'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, using the timeline above the preview, we can cycle to different parts
    of the animation. In particular, we are trying to find places for footsteps, so
    we’ll want to find spots like this, where the foot is meeting the ground:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing graphical user interface  Description automatically
    generated](img/B17304_12_52.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.51: Animation Clip inspector window preview'
  prefs: []
  type: TYPE_NORMAL
- en: Once your timeline is lined up, go ahead and add an animation event. And in
    the spot that says **Function**, type in `PlaySound` — *do not* include the parentheses
    you’ve seen previously (in `PlaySound()`)! For some reason, including the parentheses
    won’t trigger our function properly.
  prefs: []
  type: TYPE_NORMAL
- en: Here is where we placed our events.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_53.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.52: Animation Clip inspector window timeline with events'
  prefs: []
  type: TYPE_NORMAL
- en: Now, when you go into the game and walk around, you’ll hear sound! Congrats!
    We now have footstep sounds!
  prefs: []
  type: TYPE_NORMAL
- en: Randomized sounds
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll probably notice that our footstep sound is fairly repetitive. This is
    why we often like to add randomized sounds to a game!
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a process of randomly playing from a pool of sound effects so that
    sounds will be less repetitive! In this instance, we have five different footstep
    sound effects to choose from, which can be found in `/Assets/Sounds`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MainFS_01.wav` – `MainFS_05.wav`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s open up our `AnimationSounds.cs` script and check out how we can
    add randomized sounds. So in this instance, we’re going to use a list of `AudioClips`,
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B17304_12_54.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.53: Animation.cs public list soundPool'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, inside of `PlaySound` we’re going to select a random clip from this,
    and load it into our `AudioSource` component. We’ll use `Random.Range` to accomplish
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text  Description automatically generated](img/B17304_12_55.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.54: Animation.cs PlaySound() function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s open up the inspector where our `AnimationSounds.cs` script lies,
    highlight all of our `MainFS.wav` sounds, and click and drag them directly into
    our sound pool serialized field:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B17304_12_56.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.55: Animation.cs in the inspector'
  prefs: []
  type: TYPE_NORMAL
- en: And that’s all! We now are playing from a pool of random sounds!
  prefs: []
  type: TYPE_NORMAL
- en: Randomized pitch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes adding even more variation can be accomplished through randomizing
    the pitch. This is a very simple process as well. The first thing we have to do
    is define the range of pitch that we will affect.
  prefs: []
  type: TYPE_NORMAL
- en: I like to just play the sound and play around with the pitch to see where it
    sounds good. Open up the `AudioSource` component that holds our footstep sound
    and toggle the **Pitch** slider! This will update in real time.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B17304_12_57.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.56: AudioSource component'
  prefs: []
  type: TYPE_NORMAL
- en: You’ll hear that going too high or too low makes a fairly unrealistic sound.
    So I like to stick to a range of 0.3 and -0.3\. In our code, let’s just add a
    simple `Random.Range()` while targeting the pitch of our `AudioSource` component.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated with medium
    confidence](img/B17304_12_58.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12.57: AudioSource component showing how random pitch is achieved'
  prefs: []
  type: TYPE_NORMAL
- en: This is all we need! One of the most important ways to create depth in the soundscape
    of our game is to add as many sources as possible. And adding things like random
    variation, sound to small details in animations, and dynamic audio can go a long
    way! Go ahead and play the game to hear your changes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter went over many different tools that we have worked through within
    our project. We took some time to go over our process for finalizing the art and
    assets. We focused not only on the models and textures but also on checking in
    on the design to make sure that each asset fits within the world as expected.
    Within this, we also went over adding effects from the Shuriken and VFX Graph
    particle systems. This included the implementation of effects to show telekinesis.
  prefs: []
  type: TYPE_NORMAL
- en: We then went over the lighting design. We broke down Unity lighting with lightmaps,
    reflection, light probes, and baking. Lighting can add so much to a game, so this
    part shouldn’t be taken lightly!
  prefs: []
  type: TYPE_NORMAL
- en: Then to round up our game polish we went through sound polishing to trigger
    sounds through animations and add randomness to the sounds to bring more life
    to the gameplay.
  prefs: []
  type: TYPE_NORMAL
- en: This is it for the book! Thank you so much for reading all the way through and
    we hope it provided you with lots of knowledge. Please consider joining the Discord
    server, where we will be able to answer questions and go over the project in more
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: There is a bonus chapter after this that goes over some more Unity tools that
    can be used for different projects as well as some products that Unity has to
    offer for multiplayer, XR, and visual scripting. Let us know if you would like
    a book on those topics as well!
  prefs: []
  type: TYPE_NORMAL
