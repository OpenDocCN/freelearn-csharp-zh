- en: Packets and Streams
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据包和流
- en: This chapter will build upon the discussion in [Chapter 3](84e54d31-1726-477b-b753-4408a3ee6286.xhtml), *Communication
    Protocols, *of network architecture to trace the flow of data across a network,
    and break down the software you will write in C# to handle the data at each step
    in the process. We will explain the encapsulation of data into minimal packets
    for network transmission, and how that encapsulation helps to ensure that packets
    are delivered to the correct destination and are decoded properly. We will explain
    the concept of a data stream as a serialized sequence of discrete packets, and
    demonstrate the various ways that serialization can be executed in C#. Finally,
    we will demonstrate a variety of abstractions exposed by the `System.IO` namespace
    for handling streams.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将在[第3章](84e54d31-1726-477b-b753-4408a3ee6286.xhtml)，*通信协议*，网络架构讨论的基础上，追踪数据在网络中的流动，并分解您将用C#编写的处理过程中每个步骤的数据的软件。我们将解释将数据封装成最小数据包以进行网络传输，以及这种封装如何有助于确保数据包被正确交付并正确解码。我们将解释数据流作为序列化离散数据包的概念，并演示在C#中执行序列化的各种方式。最后，我们将演示`System.IO`命名空间提供的各种抽象，用于处理流。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding how data moves through a network, and how the various layers of
    network-stack metadata are unwrapped at each step in the transmission process
    to ensure proper delivery
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据在网络中的移动方式，以及网络堆栈的各个层在传输过程中的每一步如何展开元数据，以确保正确交付
- en: A deep dive into the structure of a packet delivered over a network
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入探讨通过网络传输的数据包结构
- en: Understanding the concept of a data stream as a collection of discrete packets,
    and how to leverage it to abstract away the process of receiving and parsing packets
    using C#'s many `Stream` classes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据流作为离散数据包集合的概念，以及如何利用它通过C#的许多`Stream`类来抽象接收和解析数据包的过程
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, we'll be looking closely at network communication. To that
    end, I'll be using the *Wireshark* packet sniffing tool to demonstrate some of
    the concepts we discuss. If you want to follow along and explore the network traffic
    on your own machine, Wireshark is a free download, available at [https://www.wireshark.org/](https://www.wireshark.org/).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我们将密切观察网络通信。为此，我将使用*Wireshark*数据包嗅探工具来演示我们讨论的一些概念。如果您想跟随并探索您自己机器上的网络流量，Wireshark是一个免费下载，可在[https://www.wireshark.org/](https://www.wireshark.org/)获取。
- en: Whether you plan to use it to follow along with this chapter or not, I absolutely
    recommend familiarizing yourself with it as a tool. If you are at all serious
    about doing any meaningful network programming with C#, low-level traffic inspection
    will be a major key to your success and the earlier you learn the tool, the better
    off you'll be.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是否计划使用它来跟随本章，我都绝对建议您熟悉它作为一个工具。如果您对使用C#进行任何有意义的网络编程有认真态度，低级流量检查将是您成功的关键，而且您越早学习这个工具，您就会越受益。
- en: Leveraging networks – transmitting packets for use by remote resources
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用网络 – 为远程资源传输数据包
- en: To understand specifically what a packet is, we should first understand the
    constraints of a network that necessitates packets in the first place. To do that,
    we'll need to understand the limitations of bandwidth, latency, and signal strength.
    Each of these constraints plays a key role in determining the maximum size of
    an atomic unit of data that can be transmitted over a given network. These limitations
    demand that pieces of data transmitted over the network include a number of attributes
    to ensure any measure of reliability. Data packets sent between nodes in a network
    must be small, and contain sufficient context to be properly routed. With that
    in mind, let's look at the ways a network's physical limitations can inform and
    drive the software solutions written for them.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要具体了解数据包是什么，我们首先应该了解网络限制，这些限制是数据包最初产生的必要条件。为了做到这一点，我们需要了解带宽、延迟和信号强度的限制。这些限制在确定可以在给定网络上传输的原子数据单元的最大大小方面起着关键作用。这些限制要求通过网络传输的数据包含一定数量的属性，以确保任何程度的可靠性。网络中节点之间发送的数据包必须小巧，并包含足够的信息以便正确路由。考虑到这一点，让我们看看网络的物理限制如何为针对它们编写的软件解决方案提供信息和驱动。
- en: Bandwidth
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带宽
- en: Anyone with an internet connection is probably fairly familiar with the concept
    of **bandwidth**. The monthly rates for an internet service are typically (at
    least in the US) tiered by the maximum bandwidth provided. In professional programming
    vernacular, the term bandwidth is often used, somewhat loosely, to refer to the
    amount of time or mental capacity a team or team member can dedicate to new tasks.
    Each of us should have a somewhat intuitive understanding of the concept. Put
    simply, it's the maximum rate of data transmission over a given network connection.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 任何拥有互联网连接的人可能都相当熟悉**带宽**这个概念。互联网服务的月费通常（至少在美国）是根据提供的最大带宽进行分级的。在专业的编程术语中，带宽这个术语经常被用来，某种程度上比较宽松地，指代一个团队或团队成员可以投入到新任务中的时间或心理容量。我们每个人都应该对这个概念有一个相当直观的理解。简单来说，它是在给定网络连接上的数据传输的最大速率。
- en: 'While that definition might seem basic, or even trivial, the way that bandwidth
    drives the standards for packet size and structure may be less obvious. So, let''s
    consider more thoroughly what bandwidth describes and how it impacts data transmission.
    There are two things to consider when we''re discussing bandwidth: the speed of
    throughput and the channel''s maximum capacity.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然那个定义可能看起来很基础，甚至微不足道，但带宽如何驱动数据包大小和结构的标准可能不那么明显。因此，让我们更深入地考虑带宽描述了什么以及它如何影响数据传输。当我们讨论带宽时，有两个因素需要考虑：吞吐量的速度和信道的最大容量。
- en: The easiest way to conceptualize these concepts is through the analogy of a
    highway. Imagine that you're the operator of a tollbooth on this hypothetical
    highway. However, for this analogy, let's say that, instead of collecting a toll,
    you're responsible for counting the total number of cars that move past your booth
    over a given period of time. The cars on your highway represent individual bits
    of data. Every time a car crosses your toll booth, you tally it. The total number
    of cars that cross your booth in any given time represents the bandwidth of your
    highway over that time period. With this analogy in place, let's see how the throughput
    and channel capacity can impact that bandwidth.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 通过高速公路的类比来概念化这些概念是最容易的。想象一下，你是这条假设高速公路上的收费站操作员。然而，为了这个类比，让我们说，你不仅负责收取通行费，还负责在给定时间段内统计通过你的收费站的总车辆数。你高速公路上的车辆代表单个数据位。每次一辆车通过你的收费站，你都会计数。在任何给定时间内通过你的收费站的总车辆数代表该时间段内你高速公路的带宽。有了这个类比，让我们看看吞吐量和信道容量如何影响带宽。
- en: In this characterization, the speed of throughput is analogous to the speed
    limit of your highway. It's the physical maximum velocity that a signal can travel
    over a connection. There are a number of factors that can impact or change this
    speed, but in most cases, the physics of electrical or optical signals traveling
    over their respective media render the impact of those changes negligible. Speed
    will ultimately boil down to the physical limits of the transmission medium itself.
    So, for example, fiber-optic cables will have a much higher throughput speed than
    copper wire. Fiber-optic cables transmit data at speeds approaching the speed
    of light, but copper wire introduces resistance to electrical current, slowing
    and weakening any data signal traveling over it. So, in the context of our highway
    analogy, fiber-optic cable networks have a much higher speed limit than copper
    cables. Sitting in your tollbooth over a single shift, more cars will pass by
    on a highway with a higher speed limit. Given this fact, it can be trivially simple
    to increase the bandwidth of a network by taking the basic step to upgrade your
    transmission media.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种描述中，吞吐量的速度类似于你高速公路的速度限制。它是信号可以在连接上传输的物理最大速度。有许多因素可能会影响或改变这个速度，但在大多数情况下，电信号或光信号在其相应媒体中的物理特性使得这些变化的影响微乎其微。速度最终将归结为传输介质的物理极限。因此，例如，光纤电缆将比铜线有更高的吞吐量速度。光纤电缆以接近光速的速度传输数据，但铜线会对电流产生阻力，减缓并削弱通过它的任何数据信号。因此，在我们的高速公路类比中，光纤电缆网络的速度限制比铜线要高得多。在一个班次中坐在你的收费站，高速公路上速度限制更高的地方会有更多的车辆经过。鉴于这个事实，通过基本步骤升级你的传输媒体来增加网络的带宽可以变得非常简单。
- en: While the speed of throughput is a strong determinant of bandwidth, we should
    also take a moment to consider the maximum **capacity** of a given channel. Specifically,
    this refers to how many physical wires can actively carry an individual bit at
    any given moment along a channel. In our highway analogy, the channel capacity
    will describe the number of **lanes** on our highway that a car could travel.
    So, imagine that instead of a single-file line of cars moving down a single lane
    of our highway, it's been expanded to four lanes in one direction. So now, at
    any given moment, we could have four cars, or four bits of data, moving through
    our tollbooth at any given moment.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然吞吐量的速度是带宽的一个强决定因素，但我们也应该花一点时间来考虑给定通道的最大**容量**。具体来说，这指的是在任何给定时刻，有多少物理电线可以沿着通道主动携带一个单独的比特。在我们的高速公路类比中，通道容量将描述高速公路上汽车可以行驶的**车道**数量。所以，想象一下，如果我们不是让一辆车沿着高速公路的单车道行驶，而是将其扩展为单向四车道。因此，现在在任何给定时刻，我们可能有四辆车，或者四比特的数据，通过我们的收费站。 '
- en: Obviously, it's the responsibility of system programmers writing firmware for
    network interface devices to write support for properly handling multiple simultaneous
    channels. However, as I'm sure you can imagine, variable channel capacity can
    demand very specific optimizations for the network entities responsible for breaking
    your data into atomic packets.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，编写网络接口设备固件的系统程序员有责任编写支持正确处理多个同时通道的代码。然而，正如你可以想象的那样，可变的通道容量可能需要针对负责将你的数据分割成原子包的网络实体进行非常具体的优化。
- en: Latency
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 延迟
- en: Bandwidth limitations are only one consideration for the efficiency of a network.
    The next most common limitation for which engineers must design, and that most
    users are at least intuitively familiar, is **latency*.*** Put simply, latency
    is the time between the initial moment a signal is sent, and the first moment
    a response to that signal can be initiated. It's the delay of a network.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 带宽限制只是网络效率的一个考虑因素。工程师必须设计的下一个最常见限制，大多数用户至少是直观熟悉的，是**延迟*****。简单来说，延迟是信号首次发送和响应该信号可以启动之间的时间。它是网络的延迟。
- en: There are two ways to think about latency. Simply put, you can measure it as
    one-way, or round-trip. Obviously, **one-way latency** describes the delay from
    the moment a signal is sent from one device, to the time it is received by the
    target device. Alternately, **round-trip latency** describes the delay between
    the moment a signal is sent from a device, and the moment a response from the
    target is received by that same device.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 关于延迟，有两种思考方式。简单来说，你可以将其测量为单程或往返。显然，**单程延迟**描述了信号从一个设备发送到目标设备接收的延迟。或者，**往返延迟**描述了信号从一个设备发送到目标设备接收响应的延迟。
- en: One thing to note, however, is that round-trip latency actually excludes the
    amount of time the recipient spends processing the initial signal before sending
    a response. For example, if I send a request from my software to an external API
    to provide some calculations on a piece of input data, I should reasonably expect
    that software to take some non-trivial amount of time to process my request. So,
    imagine first that the request spends 0.005 seconds in transit. Then, once received,
    the request is processed by the API in 0.1 seconds. Finally, the response itself
    spends another 0.01 seconds in transit back to my software. The total amount of
    time between my software sending the request and getting a response is *0.005
    + 0.1 + 0.01 = 0.115* seconds. However, since 0.1 seconds was spent processing,
    we will ignore this when measuring round-trip latency, so the round-trip latency
    will be measured as *0.115 - 0.1 = 0.015* seconds total.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，往返延迟实际上排除了接收者在发送响应之前处理初始信号所花费的时间。例如，如果我通过我的软件向外部API发送请求，以对一些输入数据进行计算，我合理地期望该软件需要一些非平凡的时间来处理我的请求。所以，首先想象一下，请求在传输中花费了0.005秒。然后，一旦收到请求，API在0.1秒内处理请求。最后，响应本身在返回我的软件时又花费了0.01秒。从我的软件发送请求到收到响应的总时间是*0.005
    + 0.1 + 0.01 = 0.115*秒。然而，由于花费了0.1秒来处理，我们在测量往返延迟时将忽略这部分时间，因此往返延迟将被测量为*0.115 -
    0.1 = 0.015*秒。
- en: It's not uncommon for a software platform to provide a service that simply **echoes**
    the request it was sent without any processing applied in response. This is typically
    called a **ping** **service**, and is used to provide a useful measurement of
    the current round-trip latency for network requests between two devices. For this
    reason, latency is commonly called **ping**. There are a number of factors that
    confound the reliability of a ping request in any given scenario, so the response
    times for such requests are not generally considered accurate. However, the measurements
    any ping service provides are typically considered to be approximate for a given
    network round-trip, and can be used to help isolate other latency issues with
    a given request pipeline.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 软件平台提供的服务简单地**回声**所接收到的请求，而不对响应应用任何处理，这种情况并不少见。这通常被称为**ping**服务，用于提供两个设备之间网络请求当前往返延迟的有用测量。因此，延迟通常被称为**ping**。在任何特定场景中，影响ping请求可靠性的因素有很多，因此此类请求的响应时间通常不被认为是准确的。然而，任何ping服务提供的测量通常被认为是给定网络往返的近似值，并且可以用来帮助隔离特定请求管道中的其他延迟问题。
- en: As I'm sure you can imagine, a constraint as generically defined as a **network
    delay** can have any number of contributing factors to its impact on network performance.
    This delay could come from just about any point in the network transaction, or
    on any piece of software or hardware in between the originating and target devices.
    On a given packet-switched network, there may be dozens of intermediary routers
    and gateways receiving and forwarding your package for any single request. Each
    of these devices could introduce some delay that will be nearly impossible to
    isolate when performance monitoring or testing. And, if a given gateway is processing
    hundreds of simultaneous requests, you could experience delays just by virtue
    of being queued up behind a number of requests that you had nothing to do with
    and of which you might have no direct knowledge.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所想象的那样，一个如此通用的定义如**网络延迟**可以有许多影响因素，这些因素会影响网络性能。这种延迟可能来自网络事务的任何一点，或者来自原始设备和目标设备之间的任何软件或硬件。在特定的分组交换网络中，可能有数十个中间路由器和网关接收和转发您的数据包以处理任何单个请求。这些设备中的每一个都可能引入一些延迟，当进行性能监控或测试时几乎无法隔离。而且，如果某个网关正在处理数百个并发请求，您可能会因为排在一些与您无关且您可能没有直接了解的请求后面而经历延迟。
- en: Mechanical latency
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机械延迟
- en: The different contributing factors to latency are sometimes categorized slightly
    differently. Mechanical latency, for instance, describes the delay introduced
    into a network by the time it takes for the physical components to actually generate
    or receive a signal. So, for instance, if your 64-bit computer has a clock speed
    of 4.0 GHz, this sets a physical, mechanical limit on the total amount of information
    that can be processed in a given second. Now, to be fair, it would be a lot of
    information to be processed by such a system. Assuming the CPU is processing a
    single byte per clock cycle, it's 4 billion 64-bit instructions per second being
    processed; that's a ton. But that clock speed constitutes a mechanical limit that
    introduces some measurable latency to any transaction. On such a system, a 64-bit
    instruction cannot move onto the network transmission device any faster than at
    least 0.000000128 seconds, assuming a bit is processed and delivered to the transmission
    stream at every interval of the clock cycle.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 导致延迟的不同影响因素有时会被稍微不同地分类。例如，机械延迟描述了物理组件实际生成或接收信号所需时间引入到网络中的延迟。所以，例如，如果你的64位计算机的时钟速度为4.0
    GHz，这为给定秒内可以处理的总信息量设定了一个物理的、机械的限制。现在，公平地说，这样一个系统处理的信息量会非常多。假设CPU每时钟周期处理一个字节，那么每秒处理4亿个64位指令；这是一个巨大的数字。但是，这个时钟速度构成了一个机械限制，为任何交易引入了一些可测量的延迟。在这样的系统中，一个64位指令不能比至少0.000000128秒更快地移动到网络传输设备，假设每个时钟周期间隔处理并交付一个比特到传输流。
- en: Operating system latency
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作系统延迟
- en: The preceding example describes a somewhat unrealistic system, in that 64 bytes
    of data can be sent directly to the transmission media uninterrupted. Realistically,
    an **operating system** (**OS**) will be handling requests from the application
    and system software to send over that hypothetical packet, and it will be doing
    so while simultaneously processing thousands of other requests from hundreds of
    other pieces of software running on the host machine. Almost all modern OSes have
    a system for interlacing operations from multiple requests so that no one process
    is unreasonably delayed by the execution of another. So really, we will never
    expect to achieve latency as low as the minimum mechanical latency defined by
    our clock speed. Instead, what might realistically happen is that the first byte
    of our packet will be queued up for transport, and then the OS will switch to
    servicing another operation on its procedure queue, some time will be spent executing
    that operation, and then it might come back and ready the second byte of our packet
    for transport. So, if your software is trying to send a packet on an OS that is
    trying to execute a piece of long-running or blocking software, you may experience
    substantial latency that is entirely out of your control. The latency introduced
    by how your software's requests are prioritized and processed by the OS is, hopefully
    very obviously, called **OS latency.**
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例描述的是一个有些不切实际的系统，因为在没有中断的情况下，可以直接将64字节的数据发送到传输媒体。现实中，**操作系统**（**OS**）将处理来自应用程序和系统软件的请求，以发送那个假设的数据包，同时它还会处理主机机上运行的数百个其他软件的数千个其他请求。几乎所有现代操作系统都有一个系统，用于交织多个请求的操作，以确保没有进程会因为另一个进程的执行而被不合理地延迟。因此，我们实际上永远不会期望达到由我们的时钟速度定义的最小机械延迟。相反，可能发生的情况是，我们的数据包的第一个字节将被排队等待传输，然后操作系统将切换到处理其程序队列上的另一个操作，执行该操作需要一段时间，然后它可能回来准备我们的数据包的第二字节以进行传输。因此，如果你的软件试图在一个试图执行长时间运行或阻塞软件的操作系统上发送数据包，你可能会遇到完全无法控制的重大延迟。你的软件请求如何被操作系统优先处理和处理的延迟，希望非常明显地被称为**操作系统延迟**。
- en: Operational latency
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作延迟
- en: While I did state earlier that latency typically describes only the time that
    a packet spends in transit, it is often useful for you, as a network engineer,
    to consider the impact of latency on your end user experience. While we would
    all like to, no engineer can get away with ignoring a negative user experience
    by claiming that the causes are out of your control. So even though your software
    may be performing optimally, and deployed to a lightning-fast fiber-optic network,
    if it is dependent on an upstream resource provider that is slow to process requests,
    your end user will ultimately feel that pain, no matter how perfect your own code
    is. For this reason, it's often useful to keep track of the actual, overall window
    of time necessary to process a given network request, including the processing
    time on the remote host. This measurement is the most meaningful when considering
    the impact of network operations on your user's experience, and is what's called
    **operational latency.** So, while most of the contributing factors to the operational
    latency of a task are, typically, out of your control, it is often important to
    be aware of its impact and, wherever possible, try to optimize it down to a minimum.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我之前确实说过，延迟通常只描述数据包在传输过程中花费的时间，但作为网络工程师，考虑延迟对最终用户体验的影响通常是很有用的。虽然我们都希望如此，但没有任何工程师可以通过声称原因超出了自己的控制范围来逃避忽视负面用户体验的责任。因此，即使你的软件可能表现最优，并且部署在超快的光纤网络上，如果它依赖于一个处理请求缓慢的上游资源提供商，你的最终用户最终会感受到这种痛苦，无论你的代码多么完美。因此，跟踪处理特定网络请求所需的总实际时间窗口，包括远程主机上的处理时间，通常是有用的。这种测量在考虑网络操作对用户体验的影响时最有意义，这被称为**操作延迟**。因此，尽管一个任务的操作延迟的许多影响因素通常超出了你的控制范围，但了解其影响并尽可能将其优化到最低限度通常非常重要。
- en: Ultimately, what each of these individual metrics should tell you is that there
    are dozens of points throughout a network request at which latency can be introduced.
    Each of them has varying degrees of impact, and they are often under varying degrees
    of your control, but to the extent that you can, you should always seek to minimize
    the number of points in your application at which external latency can be introduced.
    Designing for optimal network latency is always easier than trying to build it
    in after the fact. Doing so isn't always easy or obvious though, and optimizing
    for minimal latency can look different from either side of a request.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，这些个别指标应该告诉你的是，在整个网络请求过程中，有数十个点可以引入延迟。每个点都有不同程度的影响，并且它们通常受到不同程度的控制，但只要有可能，你应该始终寻求最小化应用程序中引入外部延迟的点数。为最佳网络延迟进行设计总是比事后尝试构建它要容易。然而，这样做并不总是容易或明显的，并且为最小延迟进行优化可能从请求的任何一方看起来都不同。
- en: To illustrate, imagine we are writing an application that is responsible for
    collecting one or more transaction IDs, looking up the monetary value of those
    transactions, and then returning a sum of them. Being a forward-thinking developer,
    you've separated this transaction aggregation service from the database of transactions
    to keep the business logic of your service decoupled from your data-storage implementation.
    To facilitate data access, you've exposed the transaction table through a simple
    REST API that exposes an endpoint for individual transaction lookups by way of
    a single key in the URL, such as `transaction-db/transaction/{id}`. This makes
    the most sense to you since each transaction has a unique key, and allowing individual-transaction
    lookup allows us to minimize the amount of information returned by your database
    service. Less content passed over the network means less latency, and so, from
    the data-producer perspective, we have designed well.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，假设我们正在编写一个应用程序，该应用程序负责收集一个或多个交易ID，查找这些交易的货币价值，然后返回它们的总和。作为一个具有前瞻性的开发者，你已经将这个交易聚合服务从交易数据库中分离出来，以保持你的服务业务逻辑与数据存储实现解耦。为了便于数据访问，你通过一个简单的REST
    API公开了交易表，该API通过URL中的单个键来提供单个交易的查找端点，例如`transaction-db/transaction/{id}`。这对你来说是最有意义的，因为每个交易都有一个唯一的键，允许单个交易查找可以让我们最小化数据库服务返回的信息量。通过网络传输的内容越少，意味着延迟越少，因此，从数据生产者的角度来看，我们已经设计得很好。
- en: Your aggregation service, though, is another story. That service will need multiple
    transaction records to generate a meaningful output. With only a single endpoint
    returning a single record at a time, the aggregation service will send multiple,
    simultaneous requests to the transaction service. Each one of those requests will
    contribute their own mechanical, OS, and operational latencies. While modern OSes
    allow for multithreaded processing of multiple network requests simultaneously,
    there is an upper limit to the number of available threads in a given process.
    As the number of transactions increases, requests will start to become queued,
    preventing simultaneous processing and increasing the operational latency experienced
    by the user.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你的聚合服务却是另一回事。该服务需要多个交易记录来生成有意义的输出。仅通过单个端点一次返回一个记录，聚合服务将向交易服务发送多个同时请求。每个请求都会贡献它们自己的机械、操作系统和操作延迟。虽然现代操作系统允许同时处理多个网络请求的多线程处理，但给定进程中的可用线程数有一个上限。随着交易数量的增加，请求将开始排队，阻止同时处理并增加用户体验到的操作延迟。
- en: In this case, optimizing for both cases is a simple matter of adding an additional
    REST endpoint, and accepting `POST` HTTP requests with multiple transaction IDs
    in the request body. Most of us reading this will have likely already known this,
    but the example is useful as an illustration of how **optimal performance** can
    look very different on either side of the same coin. Often, we won't be responsible
    for both the service application and the database API, and in those cases, we
    will have to do the best we can to improve performance from only one side.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，优化这两种情况只是一个简单的问题，即添加一个额外的REST端点，并接受请求体中包含多个交易ID的`POST` HTTP请求。我们中大多数人阅读这个时可能已经知道了这一点，但这个例子作为一个说明**最佳性能**可以在同一枚硬币的两面看起来非常不同的例子是有用的。通常，我们不会同时负责服务应用程序和数据库API，在这些情况下，我们将尽我们所能从单一方面来提高性能。
- en: No matter what side of a request you're on, though, the impact of network latency
    on application performance demands your consideration for minimizing the size
    of atomic data packets that must be sent over the network. Breaking down large
    requests into smaller, bite-sized pieces provides more opportunities for every
    device in the communication chain to step in, perform other operations, and then
    proceed with processing your packets. If our single-network request will block
    other network operations for the duration of an entire 5 MB file transfer, it
    might be given lower priority in the queue of network transactions that your OS
    is maintaining. However, if our OS only needs to slot in a small, 64-byte packet
    for transmission, it can likely find many more opportunities to send that request
    more frequently, reducing your OS latency overall.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你在请求的哪一方，但网络延迟对应用性能的影响都需要你考虑最小化必须通过网络发送的原子数据包的大小。将大请求分解成更小、更易处理的片段，为通信链中的每个设备提供了更多介入、执行其他操作然后继续处理你的数据包的机会。如果我们的单网络请求在整个5
    MB文件传输期间阻塞其他网络操作，它可能在你的操作系统维护的网络事务队列中拥有较低的优先级。然而，如果我们的操作系统只需要插入一个小的、64字节的传输数据包，它可能找到更多机会更频繁地发送该请求，从而降低你的操作系统延迟。
- en: If our application must send 5 MB of data, then doing so in 64-byte packets
    gives your application's hosting context much more flexibility in determining
    the best way to service that requirement.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的应用程序必须发送5 MB的数据，那么以64字节的数据包发送可以给你的应用程序托管环境提供更多的灵活性，以确定满足该需求的最佳方式。
- en: Signal strength
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信号强度
- en: The last major constraint of network communication that we'll look at is variable
    **signal strength.** Over any non-trivial network, the strength of a given signal
    can be impacted by anything from the distance between wireless transmitters and
    receivers, to just plain distance between two gateways connected by a wire. This
    isn't much of a concern on modern fiber optic networks, since those rely on the
    transmission of visible light through glass or plastic fiber, and are thus not
    subject to many of the confounding factors that interfere with older physical
    network standards. However, reliable signal strength can be a major concern for
    wireless networks, or wired networks that use electric signals over copper wiring.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要考虑的最后一个网络通信的主要限制是可变的**信号强度**。在任何非平凡的网络中，给定信号的强度可能会受到无线发射器和接收器之间距离的影响，以及通过电线连接的两个网关之间的距离。在现代光纤网络中，这并不是一个很大的问题，因为这些网络依赖于通过玻璃或塑料光纤传输可见光，因此不受许多干扰旧物理网络标准的因素的影响。然而，可靠的信号强度对于无线网络或使用铜线传输电信号的有线网络来说可能是一个主要问题。
- en: If you're at all familiar with the impact of resistance on signal strength (for
    those of you who remember your college physics or computer hardware classes),
    you'll know that the longer the wire over which you want to send a signal, the
    weaker the signal will be at the receiving end. If you're defining a bit as being
    a 1 whenever the voltage on a wire is above a given threshold, and the resistance
    of your wire reduces the voltage of a signal over time, there's a non-zero chance
    that some bits of your packet will be rendered indeterminable by your target due
    to the interference of your signal. A weak signal strength means a lower reliability
    of transmission.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉电阻对信号强度的影响（对于那些还记得大学物理或计算机硬件课程的人来说），你会知道，你想要发送信号的电线越长，接收端的信号就越弱。如果你将位定义为当电线上的电压高于给定阈值时为1，并且你的电线电阻随时间降低信号电压，那么你的数据包中的一些位可能会因为信号干扰而被目标设备判定为不可确定。信号强度弱意味着传输可靠性低。
- en: And mere resistance isn't the only thing that can weaken your signal strength.
    Most electrical signals are subject to interference from any other nearby electrical
    signals, or simply the electromagnetic fields that permeate the earth naturally.
    Of course, over time, electrical engineers have devised innumerable ways to mitigate
    those effects; everything from wire insulation to reduce the impact of electromagnetic
    interference, to signal relays to reduce the impact of resistance by amplifying
    a signal along its route. However, as your software is deployed to wider and wider
    networks, the extent to which you can rely on a modern and well-designed network
    infrastructure diminishes significantly. Data loss is inevitable, and that can
    introduce a number of problems for those responsible for ensuring the reliable
    delivery of your requests.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 而仅仅是抵抗并不是唯一可能削弱你的信号强度的事情。大多数电信号都会受到来自任何其他附近电信号的干扰，或者简单地受到自然渗透地球的电磁场。当然，随着时间的推移，电气工程师们已经设计了无数种方法来减轻这些影响；从减少电磁干扰的电线绝缘到信号中继，以放大信号沿其路径的电阻来减少影响。然而，随着你的软件被部署到越来越广泛的网络中，你可以依赖的现代和设计良好的网络基础设施的范围显著减少。数据丢失是不可避免的，这可能会给那些负责确保你的请求可靠传输的人带来一系列问题。
- en: So, how does this intermittent data loss impact the design of network transmission
    formats? It enforces a few necessary attributes of our packets that we'll explore
    in greater depth later, but we'll mention them here quickly. Firstly, it demands
    the transmission of the smallest packets that can reasonably be composed. This
    is for the simple reason that, if there is an issue of data corruption, it invalidates
    the whole payload of a packet. In a sequence of zeroes and ones, uncertainty about
    the value of a single bit can make a world of difference in the actual meaning
    of the payload. Since the payloads are only segments of the overall request or
    response object, we can't rely on having sufficient context within a given packet
    itself to make the correct assertion about the value of an indeterminate bit.
    So, if one bit goes bad and is deemed indeterminable, the entire payload is invalidated,
    and must be thrown out. By reducing the packet size to the smallest reasonable
    size achievable, we minimize the impact of invalid bits on the whole of our request
    payload. It's much more palatable to re-request a single 64-byte packet due to
    an indeterminable bit than it is to restart an entire 5 Mb transmission.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这种间歇性数据丢失如何影响网络传输格式的设计？它强制我们数据包具有一些必要的属性，我们将在稍后更深入地探讨，但在这里我们会简要提及。首先，它要求传输尽可能小的数据包。这仅仅是因为，如果数据损坏的问题存在，它将使整个数据包的有效载荷无效。在一串零和一之间，单个位的值的不确定性可能会在数据包实际意义中产生巨大的差异。由于有效载荷只是整体请求或响应对象的片段，我们无法依赖在给定数据包本身内拥有足够上下文来正确断定一个不确定位的值。因此，如果一个位变坏并且被认为是不可确定的，整个有效载荷就无效了，必须被丢弃。通过将数据包大小减少到可合理达到的最小尺寸，我们最小化了无效位对我们整个请求有效载荷的影响。由于一个位的不确定性而重新请求一个64字节的单一数据包，比重新启动整个5
    Mb的传输要容易接受得多。
- en: Astute readers may have already identified the second attribute of packets that
    are driven by unreliable signal strength. While variable signal strength and external
    interference could simply render a single bit indeterminable, it could also very
    well flip the bit entirely. So, while the recipient might be able to determine
    its received value with certainty, it ultimately determines the **incorrect value**.
    This is a much more subtle problem since, as I mentioned before, packets will
    likely contain insufficient information to determine the appropriate value for
    a specific bit in its payload. This means packets will have to have some mechanism
    for, at the very least, **error detection** baked into the standard headers. So
    long as the consuming device can detect an error, it can know, at the very least,
    to discard the contents of the erroneous packet and request re-transmission.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 聪明的读者可能已经识别出由不可靠的信号强度驱动的数据包的第二种属性。虽然可变的信号强度和外部干扰可能会简单地使单个位不可确定，但它也可能完全翻转位。因此，尽管接收者可能能够确定其接收到的值，但它最终确定的是**错误值**。这是一个更微妙的问题，因为正如我之前提到的，数据包可能包含不足以确定其有效载荷中特定位的适当值的信息。这意味着数据包必须有一些机制，至少是嵌入到标准头部的**错误检测**机制。只要消费设备能够检测到错误，它至少可以知道丢弃错误数据包的内容并请求重新传输。
- en: It's worth noting that the benefits of decomposing a request into smaller and
    smaller packets reach limits beyond which it ceases to be beneficial for network
    performance. Subject this line of thinking to reduction ad absurdum and you'll
    quickly find yourself with a full-fledged packet for every single bit in your
    payload, error-detection and all. With our imagined request payload of 5 Mb, that's
    40,000,000 packets being sent simultaneously. Obviously, this is an absurd number
    of packets for such a small request. Instead, network engineers have found a reliable
    range of sizes for packets being sent according to a given protocol as falling
    somewhere between a few hundred bytes and a few kilobytes.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，将请求分解成越来越小的数据包所带来的好处是有极限的，超过这个极限后，对网络性能的益处就会消失。将这种思维方式推向极端，你会很快发现自己为负载中的每一个比特都分配了一个完整的数据包，包括错误检测等。以我们想象中的5
    Mb请求负载为例，这意味着同时发送了4,000,000个数据包。显然，对于如此小的请求来说，这是一个荒谬的数据包数量。相反，网络工程师已经发现，根据给定的协议，发送的数据包大小有一个可靠的范围，这个范围介于几百字节和几千字节之间。
- en: Now that we know why network communication is done with small, isolated packets,
    we should take a look at what those are.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经知道了为什么网络通信使用小而独立的数据包，那么我们应该看看这些数据包是什么。
- en: The anatomy of a packet
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据包的结构
- en: While I've touched on some features already in this chapter, here we'll take
    a closer look at the attributes that a network packet must exhibit in order to
    actually be useful as a piece of information. We'll look at how the standard for
    network packets is defined and the minimum amount of features that all network
    packets will contain in some form or other. Then we'll take a brief look at how
    different transmission protocols implement their own standards for packets, and
    how some of the required attributes are expanded on to provide more reliable data
    transmission, or higher performance. This will ultimately lay the foundation for
    later in this book where we look at network security, diagnostics, and optimization.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我在本章中已经提到了一些特性，但在这里我们将更仔细地研究网络数据包必须展示的属性，以便真正作为信息的一部分有用。我们将探讨网络数据包标准的定义以及所有网络数据包将以某种形式包含的最小功能。然后我们将简要地看看不同的传输协议如何实现它们自己的数据包标准，以及如何扩展一些必需的属性以提供更可靠的数据传输或更高的性能。这将为本书后面的内容奠定基础，我们将探讨网络安全、诊断和优化。
- en: What is a packet?
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是数据包？
- en: So, to start off with, we should engage in a bit of nit-picking. The term I've
    been using throughout this chapter-packet-is not, strictly speaking, the most
    accurate term for what I've been describing. Until now, I've been using the word
    packet to describe the most atomic unit of data transmission over a network. However,
    for the sake of accuracy, I should note that the term packet refers specifically
    to the most atomic piece of data transmitted by the network layer of the **Open
    Systems Interconnection** (**OSI**) network stack. In the transport layer, where
    we'll be most concerned with it (since that is the lowest layer in the stack we'll
    directly interact with through C#), the atomic unit of data transmission is actually
    called a **datagram. **However, I'll note that it is much more common to refer
    to data units of the transmission layer as packets than datagrams and so will
    continue with this colloquial use of the term throughout the chapter and throughout
    the rest of the book. I did, however, want to take the opportunity to point out
    the distinction between the two terms in case you encountered either being used
    elsewhere in different contexts. With that in mind, what exactly is a datagram,
    or packet?
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，首先，我们应该进行一些细节上的探讨。我在本章中一直使用的术语“数据包”并不是严格意义上描述我所描述内容的最佳术语。到目前为止，我一直使用“数据包”这个词来描述通过网络传输的最基本的数据传输单位。然而，为了准确起见，我应该指出，术语“数据包”特指**开放系统互联**（**OSI**）网络堆栈中网络层传输的最基本的数据单元。在传输层，我们将最关注它（因为那是我们在C#中直接交互的堆栈中的最低层），数据传输的基本单位实际上被称为**数据报**。然而，我要指出的是，通常更常见的是将传输层的数据单元称为数据包而不是数据报，因此我将在本章以及本书的其余部分继续使用这个术语。不过，我确实想利用这个机会指出这两个术语之间的区别，以防你在不同的上下文中遇到了这两个术语中的任何一个。有了这个前提，那么数据报或数据包究竟是什么呢？
- en: We already know quite a bit about what a packet must be in order to be useful,
    so let's formalize it into a definition. A **packet** is an atomic unit of data,
    encapsulated with sufficient context for reliable transmission over an arbitrary
    network implementation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经对包必须具备哪些特性才能变得有用有了相当的了解，所以让我们将其正式化为一个定义。**包**是数据的一个原子单位，它封装了足够的环境信息，以便在任意网络实现中可靠地传输。
- en: So basically, it's a **payload** (unit of data) with a **header** (sufficient
    context). This shouldn't be surprising by this point, but let's look at how this
    translates to an actual array of bytes passed from our transport layer to the
    network layer. To do so, we'll use Wireshark to examine the actual data packets
    being sent to and from my own Ethernet port, and look at how each part of that
    definition translates to actual datagrams.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所以基本上，它是一个**有效载荷**（数据单位）和一个**头部**（足够的环境信息）。这一点到此时应该不会令人惊讶，但让我们看看这个定义是如何转化为从我们的传输层传递到网络层的实际字节数组的。为了做到这一点，我们将使用Wireshark来检查发送到和从我自己的以太网端口的数据包，并查看定义中的每一部分是如何转化为实际的数据报的。
- en: Setting up Wireshark
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Wireshark
- en: 'As a tool for network engineers, Wireshark is immeasurably useful, and I strongly
    encourage you to familiarize yourself with its features and start to think about
    how you could leverage it in your own development tasks. For now, though, we''ll
    be using its most basic packet sniffing functionality to examine every packet
    that comes through our open internet connection. So, once Wireshark is installed,
    simply open it up and select your Ethernet connection as your target for packet
    sniffing, as seen in the following screenshot:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 作为网络工程师的工具，Wireshark极其有用，我强烈建议你熟悉其功能，并开始思考你如何在你的开发任务中利用它。现在，尽管如此，我们将使用其最基本的包嗅探功能来检查通过我们开放的互联网连接的每一个包。因此，一旦安装了Wireshark，只需打开它，并选择你的以太网连接作为包嗅探的目标，如下面的截图所示：
- en: '![](img/4c8c54d3-bcfe-4640-99af-0691cd9fbaee.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/4c8c54d3-bcfe-4640-99af-0691cd9fbaee.png)'
- en: When you open it on your own machine, take a second to watch the graph growing
    out to the right of the traffic source. This actually provides a quick view of
    the relative activity on the given source over time. Once your primary internet
    source is selected, start capturing by clicking the capture button on the top-left
    of the toolbar, or simply double-clicking the desired source. Allow the tool to
    capture traffic for a few minutes just to get a good range of sample data and
    then start exploring on your own. If you've never used a tool such as Wireshark
    or Fiddler before, you'll likely be surprised by how much chatter is actually
    happening, even with no input from you directly.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在自己的机器上打开它时，花点时间观察一下流量源右侧的图表增长。这实际上提供了在给定源随时间变化的相对活动的一个快速视图。一旦你选择了主要的互联网源，就可以通过点击工具栏左上角的捕获按钮或简单地双击所需源来开始捕获。让工具捕获几分钟的流量，以获取良好的样本数据范围，然后开始自己探索。如果你以前从未使用过Wireshark或Fiddler这样的工具，你可能会惊讶于即使没有你的直接输入，实际上也在发生多少对话。
- en: With the tool installed and running, let's take a look at some of the features
    of a packet specified by our definition and see how it translates to real-world
    implementations.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装并运行工具后，让我们看看我们定义的包的一些特性，并看看它是如何转化为实际应用中的。
- en: Atomic data
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原子数据
- en: If you have any experience with database design, you might already have a pretty
    clear idea of what constitutes **atomic data**. Typically, it means the smallest
    components into which a record can be broken down without losing their meaning.
    In the context of network communication, though, we're not really concerned with
    the payload of a packet losing its meaning. It would recompiled into the original
    data structure by the recipient of the payload, and so it's fine if the small
    chunk of data that moves over the network is meaningless on its own. Instead,
    when we talk about atomic data in the context of network transactions, we're really
    talking about the minimum size that we can truncate our data into, beyond which
    we will stop seeing the desired benefits of shrinking our data into smaller and
    smaller chunks. Those chunks may well splice double-precision decimal values in
    two, sending one half over in one packet and the other half in an entirely separate
    packet. So, in that case, neither packet has enough information to make sense
    of the data in its original form. It wouldn't be considered atomic in the same
    way that a `FIRST_NAME` field will be the most atomic way to store the first name
    of a user record in a database. But if that decomposition results in the most
    efficient distribution of packets for transmission over the current network, with
    minimum latency and maximum bandwidth utilization, then it is the most atomic
    way to represent it in a network packet.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何数据库设计的经验，你可能已经对构成**原子数据**的概念有了相当清晰的认识。通常，这意味着记录可以被分解成最小的组成部分，而不会失去其意义。然而，在网络通信的背景下，我们并不真正关心数据包的有效载荷失去意义。它会被接收方重新编译成原始的数据结构，因此，即使通过网络传输的小块数据本身没有意义，这也是可以接受的。相反，当我们谈论网络事务中的原子数据时，我们实际上是在谈论我们可以将数据截断到最小大小的程度，超过这个大小，我们将不再看到将数据缩小成更小块所带来的预期好处。这些块可能会将双精度十进制值分成两部分，一部分在一个数据包中发送，另一部分在完全不同的数据包中发送。因此，在这种情况下，任何一个数据包都没有足够的信息来理解其原始形式的数据。它不会被看作是像数据库中用户记录的`FIRST_NAME`字段那样最原子化的存储方式。但如果这种分解在当前网络中实现了数据包传输的最有效分布，具有最小的延迟和最大的带宽利用率，那么它就是以网络数据包表示的最原子化方式。
- en: 'For an example of this, just look at any arbitrary packet you recorded in your
    Wireshark capture. Looking at a packet in my data stream, we''ve got this arbitrary
    **Transmission Control Protocol** (**TCP**) packet (or datagram), as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，只需查看你在Wireshark捕获中记录的任何任意数据包。查看我的数据流中的一个数据包，我们有一个这样的**传输控制协议**（**TCP**）数据包（或数据报），如下所示：
- en: '![](img/59829791-f402-407e-adb1-76c43942fe39.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/59829791-f402-407e-adb1-76c43942fe39.png)'
- en: As you can see in the selected text of the raw data view on the bottom of my
    Wireshark panel, the payload of that particular packet was 117 bytes of nonsensical
    garbage. That might not seem very useful to you or me, but once that specific
    TCP request is reassembled with the rest of the packets in that request, the resulting
    data should make sense to the consuming software (in this case, the instance of
    Google Chrome running on my computer). So, this is what is meant by an **atomic
    unit of data**. Fortunately, that's not something that we'll have to concern ourselves
    with, since that's handled directly by the hardware implementation of the transport
    layer. So, even though we can implement software that directly leverages a transport
    layer protocol of our choice, the actual act of decomposing and recomposing packets
    or datagrams will always be out of our hands when we're working on the .NET Core
    platform.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在Wireshark面板底部原始数据视图所选文本中看到的那样，该特定数据包的有效载荷是117字节的无意义垃圾。这可能对你或我来说似乎没有太大用处，但一旦将这个特定的TCP请求与该请求中的其他数据包重新组装，最终的数据应该对消费软件（在这种情况下，是我电脑上运行的Google
    Chrome实例）有意义。这就是所谓的**原子数据单元**的含义。幸运的是，这不是我们需要担心的事情，因为这是由传输层的硬件实现直接处理的。因此，尽管我们可以实现直接利用我们选择的传输层协议的软件，但在.NET
    Core平台上工作时，分解和重新组合数据包或数据报的实际行为总是超出我们的控制。
- en: Encapsulated with sufficient context
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 封装了足够多的上下文
- en: This aspect of our definition is actually the real meat of it, and is the real
    reason we're messing about with Wireshark in the first place. What exactly does
    it mean to encapsulate a packet with sufficient context? Let's start with the
    context that a datagram must have. This refers to the information that any device
    in between the source and destination hosts will need to route the packet accordingly,
    as well as any information necessary for the destination host to properly read
    and process the packet once received. For obvious reasons, this information is
    contained at the very front of a packet (which is to say, it composes the first
    bits that will be read by a receiving device), and is what constitutes the header
    of a packet. The **context** is the information necessary to either forward or
    process a packet correctly.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义的这个方面实际上是真正的核心，也是我们最初使用Wireshark的原因。用足够的上下文封装一个数据包究竟意味着什么？让我们从数据报必须具备的上下文开始。这指的是源主机和目的主机之间任何设备都需要的信息，以便相应地路由数据包，以及目的主机在接收到数据包后正确读取和处理所需的信息。出于明显的原因，这些信息包含在数据包的最前面（也就是说，它构成了接收设备将首先读取的位），这就是数据包头部的构成。**上下文**是正确转发或处理数据包所需的信息。
- en: So what, then, constitutes **sufficient context**? Well, that actually depends
    on the specific protocol under which the packet was constructed. Different protocols
    have different requirements and expectations, and thus, different requirements
    to be serviced properly. What constitutes sufficient context for one might be
    grossly insufficient for another.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么构成了**足够的上下文**呢？嗯，这实际上取决于数据包构建的具体协议。不同的协议有不同的要求和期望，因此，对正确服务的要求也不同。对某一方面构成足够上下文的内容，可能对另一方面来说就极其不足。
- en: The two most commonly used transport layer protocols are TCP and **User Datagram
    Protocol** (**UDP**), and each of them have different service contracts for the
    application software that leverages them. This means that both of them have very
    distinct header specifications. TCP seeks to provide sequential, reliable, error-checked
    transmission service for packets traveling between hosts. Meanwhile, UDP, as a
    connection-less protocol (we'll discuss specifically what that means later in
    this book), doesn't explicitly aim to provide the reliability of transmission
    or a guarantee of the ordering of data. Instead, it seeks to provide light weight
    communication with a minimal protocol definition to enforce. As such, the sufficient
    context for UDP is actually substantially less than for that of a TCP packet.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的传输层协议是TCP和**用户数据报协议**（**UDP**），它们各自为利用它们的软件应用提供了不同的服务合同。这意味着它们都有非常不同的头部规范。TCP旨在为在主机之间传输的数据包提供顺序的、可靠的、经过错误检查的传输服务。与此同时，UDP作为一种无连接的协议（我们将在本书的后面具体讨论这意味着什么），并不明确旨在提供传输的可靠性或数据顺序的保证。相反，它寻求提供轻量级通信，并使用最少的协议定义来强制执行。因此，UDP的足够上下文实际上比TCP数据包的上下文要少得多。
- en: 'A UDP packet header consists of a mere 8 bytes of data, broken up into 4 individual
    fields that each are 2 bytes in length; those fields are as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一个UDP数据包头部由8个字节的数据组成，分为4个单独的字段，每个字段长度为2个字节；这些字段如下：
- en: '**Source port:** The specific port of the socket connection on the source machine
    generating the request.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源端口**：生成请求的源机器上套接字连接的特定端口。'
- en: '**Destination port:** The port of the connection on the destination machine.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目的端口**：目的机器上连接的端口。'
- en: '**Length:** The exact length of the packet, including the payload that immediately
    follows the 8-byte header.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长度**：数据包的确切长度，包括紧跟8个字节头部的有效载荷。'
- en: '**Checksum:** A simple value used to verify the data integrity of the payload.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**校验和**：用于验证有效载荷数据完整性的简单值。'
- en: 'Using Wireshark, we can see this in action. With a simple UDP packet, the full
    contents are captured by those few relevant fields, as seen in the Packet Details
    view in the middle of my Wireshark window:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Wireshark，我们可以看到这个动作。在一个简单的UDP数据包中，所有内容都由那些相关字段捕获，正如我在Wireshark窗口中间的“数据包详情”视图中所看到的：
- en: '![](img/d0e6a7b0-dc93-4878-b3c7-a0915489d239.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/d0e6a7b0-dc93-4878-b3c7-a0915489d239.png)'
- en: 'However, since TCP provides reliable delivery, guaranteed ordering, and leverages
    a handshake-protocol that UDP forgoes, the specification of a TCP packet header
    is much longer. Where sufficient context for UDP could be encapsulated in a mere
    8 bytes, sufficient context for TCP demands a header of up to 20 bytes. This is
    including a number of flag-bits indicating the state of the individual packets
    in the context of the larger session, and a sequence number to provide the protocol-specified
    ordering of packets. A brief examination of the Packet Details view of a simple
    TCP packet within Wireshark should illuminate the disparity in the expected context
    provided by a TCP packet header, as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于TCP提供可靠交付、保证顺序，并利用UDP放弃的手 shake-协议，TCP数据包头部的规范要长得多。对于UDP，足够的上下文可以封装在仅仅8个字节中，而对于TCP，足够的上下文需要多达20字节的头部。这包括表示更大会话中单个数据包状态的多个标志位，以及一个序列号，以提供协议指定的数据包顺序。在Wireshark中简单TCP数据包的“数据包详细信息”视图的简要检查应该可以阐明TCP数据包头部提供的预期上下文差异，如下所示：
- en: '![](img/102c266e-88aa-4c56-84c5-c755df460150.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/102c266e-88aa-4c56-84c5-c755df460150.png)'
- en: As you can see here, even though the actual length of the TCP packet in bytes
    is shorter than the UDP packet that we looked at previously, the header provides
    substantially more information than was necessary for a valid UDP connection.
    There was obviously overlap (of the source and destination ports, and a checksum),
    but there was a wider gap between the two headers than there was common ground.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，尽管TCP数据包的实际字节长度比我们之前查看的UDP数据包短，但头部提供了比有效UDP连接所需的信息多得多的信息。显然存在重叠（源端口和目的端口，以及校验和），但两个头部之间的差距比共同点要大。
- en: So, hopefully, it's now clear why what constitutes sufficient context is driven
    by the protocol under which a packet was constructed. The specifics of what is
    sufficient can change, but for every protocol, there will always be a minimum
    amount of context that is sufficient to be forwarded or processed.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，希望现在已经很清楚，构成足够上下文的原因是由构建数据包的协议所驱动的。具体什么是足够的可能会变化，但每个协议都会有足够的最小上下文，足以转发或处理。
- en: Error detection and correction
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 错误检测与纠正
- en: Before we move on, I do want to take a brief moment to talk about the distinction
    between error detection and error correction*.* You might have wondered why I
    left out any stipulation regarding error correction or error detection from my
    definition of a packet. This is because there is no guarantee that, for every
    protocol defined for the transport layer of the OSI stack, packets will always
    contain sufficient information to detect or correct errors incurred in transit.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我确实想花一点时间来谈谈错误检测和错误纠正之间的区别。你可能想知道为什么我在对数据包的定义中省略了有关错误纠正或错误检测的任何规定。这是因为对于OSI堆栈传输层定义的每个协议，并不能保证数据包总是包含足够的信息来检测或纠正传输过程中产生的错误。
- en: 'I will say, however, that it is extremely common to have at least some kind
    of error detection in a given protocol specification. TCP, and even the unreliable
    UDP transport protocol, provide a checksum for simple error detection, as seen
    in the following two packets on Wireshark:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我要说的是，在给定的协议规范中至少有一些形式的错误检测是非常常见的。TCP，甚至是不太可靠的UDP传输协议，都提供了校验和来进行简单的错误检测，如下面在Wireshark中看到的两个数据包所示：
- en: '![](img/8319b2d7-0835-4836-85ed-f878f0aaf4d9.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8319b2d7-0835-4836-85ed-f878f0aaf4d9.png)'
- en: What those protocols don't provide, however, is any mechanism for error correction*,*
    which is actually much more difficult to implement, and for anything other than
    trivial correction capabilities, will require the packet size to balloon upwards.
    For example, while a checksum can tell you whether the payload has altered in
    transit somehow, it cannot tell you specifically where, or to what extent, the
    payload may have been altered. To do so would require enough additional data to
    reconstruct the packet from scratch. Since packet transmission is generally reliable
    over time (which is to say, even if one transmission failed, retrying the transmission
    is likely to succeed), and generally exceptionally fast at the transport layer,
    it's always a much better idea to simply detect an error, discard the erroneous
    packet, and request retransmission.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，那些协议没有提供任何错误纠正机制*，这实际上要困难得多，并且对于任何非简单纠正功能，都需要将数据包大小大幅增加。例如，虽然校验和可以告诉你有效载荷在传输过程中是否发生了改变，但它无法告诉你具体在哪里，或者改变的程度如何。要做到这一点，需要足够多的附加数据来从头开始重建数据包。由于数据包传输在一般情况下是可靠的（也就是说，即使一次传输失败，重试传输很可能会成功），并且在传输层通常非常快，因此简单地检测错误、丢弃错误数据包并请求重传总是更好的选择。
- en: With this in place, we have a solid idea of everything that a packet defined
    under a given protocol must have, and of how we can examine or use individual
    pieces of network data. But our software won't be using tiny little pieces of
    individual data. Our software will be expecting JSON objects, XML payloads, or
    serialized byte-streams of C# objects. So, how does software that consumes network
    traffic make heads or tails of those random flows of bite-sized packets? By using
    them as streams*.*
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们对在给定协议下定义的每个数据包必须具备的一切以及如何检查或使用网络数据的各个部分都有一个稳固的概念。但我们的软件不会使用这些微小的数据片段。我们的软件期望的是JSON对象、XML有效载荷或C#对象的序列化字节流。那么，消费网络流量的软件是如何处理这些随机的小数据包流呢？通过将它们作为流*使用。
- en: Streams and serialization – understanding sequential data transmission
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流和序列化 - 理解顺序数据传输
- en: So with our fat, chunky JSON requests being broken up into tiny, sub-kilobyte
    packets, and sent over as an array of seemingly random, disjointed pieces of data,
    how can we possibly expect our recipients to process this data? Well, in C#, that's
    where the concept of a data stream comes in. Within the context of our application
    code, we can reliably assume that the transport layer will recompose our packets
    into a sequence of bits for us to consume as soon as it becomes available to us.
    So once we get that sequence of bits back, how do we consume it? As an IO stream!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们的庞大、笨重的JSON请求被拆分成微小的、亚千字节的数据包，并以看似随机、不连贯的数据片段数组的形式发送时，我们怎么可能期望我们的接收者处理这些数据呢？好吧，在C#中，这就是数据流概念出现的地方。在我们应用程序代码的上下文中，我们可以可靠地假设传输层会为我们重新组合数据包，以便我们一有机会就可以消费它们。所以，一旦我们得到了这个位序列，我们如何消费它呢？作为一个IO流！
- en: The Stream class
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Stream类
- en: If you've done any reading or writing of files on your local file system in
    C# on older .NET Framework versions, you'll already be familiar with this concept.
    In .NET Core, we can import the `System.IO` namespace to our application to start
    working directly with the data returned by a TCP/IP socket by simply opening up
    a new `StreamReader` object, initialized with a `NetworkStream` instance connected
    to the target socket. So, what is a stream and how should you use it?
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾在旧版.NET Framework版本的C#中读取或写入本地文件系统，你将已经熟悉这个概念。在.NET Core中，我们可以将`System.IO`命名空间导入到我们的应用程序中，通过简单地打开一个新的`StreamReader`对象，并用一个连接到目标套接字的`NetworkStream`实例初始化它，就可以直接开始处理由TCP/IP套接字返回的数据。那么，什么是流？你应该如何使用它？
- en: Streams are a powerful concept in processing serialized data. They provide one-way
    access to a sequential data source and allow you to handle the processing of that
    data explicitly. Executing the `Read()` or `ReadAsAsync()` methods, or other associated
    methods, will trigger this one-way traversal; starting at the beginning and reading,
    on demand, byte by byte through the entire sequence, until a Terminal character
    has been reached. The .NET implementation of this concept is extremely flexible,
    such that, regardless of the specific instance of the `Stream` abstract class
    you're using, the `StreamReader` class will be equipped to accept the data, traverse
    it accordingly, and allow you to build out a non-serialized instance of a C# data
    structure as needed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 流是处理序列化数据的一个强大概念。它们提供对顺序数据源的单一访问，并允许你显式地处理该数据。执行`Read()`或`ReadAsAsync()`方法，或其他相关方法，将触发这种单向遍历；从开始处开始，按需逐字节读取整个序列，直到达到终止字符。.NET对这个概念的实施非常灵活，以至于，无论你使用的是`Stream`抽象类的哪个具体实例，`StreamReader`类都将配备接受数据、相应地遍历它，并允许你根据需要构建非序列化的C#数据结构的功能。
- en: We'll examine streams more thoroughly in later chapters, but for now, I wanted
    to highlight how, in the context of network communication, streams are composed
    of the sequence of packets received by a specific port or socket, and returned
    to your application through a normalized implementation of the `Stream` class.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面的章节中更详细地研究流，但到目前为止，我想强调在网络通信的背景下，流是由特定端口或套接字接收到的数据包序列组成的，并通过`Stream`类的标准化实现返回到您的应用程序。
- en: This is just one example of the power suite of abstractions provided by .NET
    Core. So, even though you now have the understanding necessary to explicitly handle
    individual packets returned from your transport layer to rebuild the response
    of a network request from scratch, you thankfully never have to do that. The Core
    framework handles that headache for you. And with this added perspective of what's
    happening under the hood, I hope you feel better equipped to address potential
    performance issues or subtle network bugs in your network-dependent applications
    going forward.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是.NET Core提供的抽象功能套件的一个例子。因此，尽管你现在已经具备了处理从传输层返回的单独数据包并从头开始重建网络请求响应的必要理解，但你很幸运地不必这样做。Core框架为你处理了这个头疼的问题。并且，有了这个底层的额外视角，我希望你感觉更有能力去解决未来网络依赖型应用程序中可能出现的性能问题或微妙的网络错误。
- en: Summary
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Looking back, this chapter covered the lowest-level details of network communication.
    First, we learned about the three most common constraints of a physical network
    infrastructure that demand the decomposition of a network request into packets.
    We looked at how different aspects of the hosting context of our application can
    contribute some measure of latency to our requests, how bandwidth can change the
    way requests move from one node to another, and how signal strength can compromise
    the integrity of a packet.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾本章，我们涵盖了网络通信的最底层细节。首先，我们学习了物理网络基础设施的三个最常见约束，这些约束要求将网络请求分解成数据包。我们探讨了应用程序托管上下文的各个方面如何对我们的请求贡献一定的延迟，带宽如何改变请求从一个节点移动到另一个节点的方式，以及信号强度如何损害数据包的完整性。
- en: Next, we explored how those factors necessitate small, contextually-complete,
    atomic packets as our transport format for network requests. We unpacked how some
    common protocols provide that complete context with each packet through standardized
    formats. This gave us a clearer idea of how a larger network request is decomposed
    and sent over our network pipes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们探讨了这些因素如何需要小型、上下文完整、原子性的数据包作为我们的网络请求传输格式。我们分析了某些常见协议如何通过标准化格式在每个数据包中提供完整的上下文。这让我们对如何将较大的网络请求分解并发送到我们的网络管道有了更清晰的认识。
- en: Finally, we looked at how a set of packets, delivered at inconsistent intervals,
    can be consumed as a sequential stream. With all of this, the lowest level of
    our foundation is set, and we have the complete context of network infrastructure
    and communication standards necessary to fully explore how C# provides that functionality
    in our .NET Core applications. And that's exactly what we'll be looking at in
    the next chapter, as we finally generate a network request in a user-facing application,
    and fully unpack every step of that process as implemented by the .NET Core hosting
    platform.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们探讨了如何将一组在不一致的时间间隔内交付的数据包作为顺序流进行消费。有了这一切，我们基础的最底层已经建立，我们拥有了探索.NET Core应用程序中C#如何提供该功能的完整网络基础设施和通信标准的背景。这正是我们将在下一章中探讨的内容，我们将最终在面向用户的应用程序中生成一个网络请求，并完全解析由.NET
    Core托管平台实现的该过程的每一步。
- en: Questions
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the three constraints of a network that necessitates the decomposition
    of a network request into packets?
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么网络的三种约束需要将网络请求分解成数据包？
- en: List each of the types of latency discussed in this chapter.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出本章讨论的每种类型的延迟。
- en: Why does unreliable signal strength warrant smaller packet sizes?
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么不可靠的信号强度需要更小的数据包大小？
- en: What is the definition of a datagram?
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据报的定义是什么？
- en: What are the two components of a datagram?
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据报的两个组成部分是什么？
- en: What is sufficient context in terms of a datagram or packet?
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据报或数据包方面，什么算是足够的背景信息？
- en: Which feature of .NET Core facilitates the processing of unreliable data streams?
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: .NET Core的哪个功能促进了不可靠数据流的处理？
- en: Further reading
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For a better understanding of how packets and data streams operate over a distributed
    system, check out *Packet Analysis with Wireshark*, *Anish Nath*, *Packt Publishing*,
    here: [https://www.packtpub.com/networking-and-servers/packet-analysis-wireshark](https://www.packtpub.com/networking-and-servers/packet-analysis-wireshark).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解数据包和数据流如何在分布式系统中操作，请查看以下书籍：*《使用Wireshark进行数据包分析》，作者Anish Nath，Packt Publishing*，详情请见：[https://www.packtpub.com/networking-and-servers/packet-analysis-wireshark](https://www.packtpub.com/networking-and-servers/packet-analysis-wireshark)。
- en: 'For a closer look at data streams in practice, consider *Stream Analytics with
    Microsoft Azure, Anindita Basak*, *Krishna Venkataraman*, *Ryan Murphy*, *and
    Manpreet Singh*, *Packt Publishing*, here: [https://www.packtpub.com/big-data-and-business-intelligence/stream-analytics-microsoft-azure](https://www.packtpub.com/big-data-and-business-intelligence/stream-analytics-microsoft-azure).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地了解实际中的数据流，请考虑以下书籍：*《使用Microsoft Azure进行流分析》，作者Anindita Basak、Krishna Venkataraman、Ryan
    Murphy和Manpreet Singh，Packt Publishing*，详情请见：[https://www.packtpub.com/big-data-and-business-intelligence/stream-analytics-microsoft-azure](https://www.packtpub.com/big-data-and-business-intelligence/stream-analytics-microsoft-azure)。
