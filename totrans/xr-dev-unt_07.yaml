- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Adding Sound and Visual Effects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating immersive XR experiences requires more than just importing 3D assets
    and scripting interactivity. For a truly natural and captivating experience, we
    need to integrate sound and visual effects. Imagine an AR monster hunt game. You’ve
    built the logic, but without sound and visual effects, the blend of real world
    and virtual reality feels off. Adding subtle monster sounds can provide direction
    and distance clues. Integrating a particle effect such as gray fog can enhance
    the spooky, mysterious atmosphere. By stimulating multiple senses and adapting
    these elements to a user’s movements, we can significantly enhance the overall
    immersion and user experience of the AR monster hunt game.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter aims to enhance your XR design skills, targeting more user senses
    for natural, immersive experiences. We’ll delve into sound theory and particle
    behavior basics, making these physics concepts accessible to all. We will delve
    into Unity’s audio and particle systems to understand how they can help us recreate
    real-world phenomena. In line with our hands-on approach, you’ll apply these concepts
    in a practical VR project in Unity, creating your most immersive VR experience
    yet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s dive into this thrilling exploration of creating realistic XR experiences!
    This chapter guides you on your way through these four sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding sound theory and Unity’s audio system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preparing the VR drum scene and adding sound effects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding particle behavior and Unity’s particle system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding particles to VR scenes with varying properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To fully engage with and benefit from the VR application development process
    outlined in this chapter, your hardware must meet certain technical specifications.
    If you followed the tutorial in [*Chapter 3*](B20869_03.xhtml#_idTextAnchor009)
    and your Unity setup remains the same, you can bypass this section.
  prefs: []
  type: TYPE_NORMAL
- en: To follow along with this book’s content and examples, ensure your computer
    system can accommodate *Unity 2021.3 LTS* or a more recent edition, with *Android*
    or *Windows/Mac/Linux Build Support*, depending on the nature of your VR headset
    and PC.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding sound theory and Unity’s audio system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the subsequent sections, we will delve into the fascinating physics of sound
    waves and explore how Unity’s robust audio system allows us to manipulate these
    properties with its diverse range of audio components. Our journey begins with
    an introduction to the fundamentals of sound, the nature of sound itself, and
    its defining features – frequency and amplitude.
  prefs: []
  type: TYPE_NORMAL
- en: What are frequency and amplitude?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sound, in essence, is a form of mechanical energy that propagates as a wave
    through a medium – most commonly, air. Simply put, mechanical energy is energy
    associated with the motion of objects. When an object vibrates, it displaces the
    surrounding air particles, setting off a chain reaction of particle displacement
    that travels outward in the form of a sound wave.
  prefs: []
  type: TYPE_NORMAL
- en: The two main parameters describing a sound wave are frequency and amplitude.
  prefs: []
  type: TYPE_NORMAL
- en: '**Frequency** is the number of complete wave cycles per second, measured in
    **Hertz** (**Hz**). It determines the pitch of the sound – a higher frequency
    corresponds to a higher pitch, and a lower frequency corresponds to a lower pitch.
    In game development, understanding frequency is crucial. For instance, a small,
    light creature such as a bird would have a high-pitched (high-frequency) chirp,
    while a large creature such as an elephant would have a low-pitched (low-frequency)
    roar.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Amplitude** refers to the maximum displacement of particles by the sound
    wave. In simpler terms, it’s how far the particles are pushed when the wave passes
    through. It corresponds to the loudness of the sound – a larger amplitude means
    a louder sound, and a smaller amplitude means a quieter sound. In games and XR
    applications, amplitude can be used to create a sense of distance. A sound source
    far from the player would have a smaller amplitude and thus sound quieter, while
    a source close to the player would sound louder.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding other properties of sound
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While frequency and amplitude are fundamental, several other properties can
    add depth to the sound experience in XR. These include timbre (pronounced *tamber*),
    envelope, spatial audio, reverberation, and echo. Let’s go through them step by
    step:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Timbre**: This describes the color or quality of a sound and allows us to
    distinguish between different sound sources that may have the same pitch and loudness.
    Here, *color* refers to the unique characteristics and tonal nuances of a sound
    that differentiate it from other sounds. It’s what allows us to tell the difference
    between a violin and a flute, even if they’re playing the same note at the same
    volume. In game development, timbre can be used to give different characters or
    environments their unique sound signatures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Envelope**: The envelope of a sound refers to how it evolves over time. It’s
    traditionally broken down into four parts – **Attack, Decay, Sustain, and Release**
    (**ADSR**). ADSR describes the initial spike of a sound (attack), the subsequent
    decrease to a stable level (decay), the maintenance of that level for a duration
    (sustain), and the eventual fading away of the sound (release). In XR, modifying
    the ADSR envelope can make sounds seem more realistic or can be used creatively
    to give sounds a stylized feel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spatial audio**: This refers to the perception of the direction and distance
    of a sound source. Our brains use several cues to pinpoint the location of a sound
    source, such as the time difference between the sound reaching our two ears (binaural
    cues), the change in frequency caused by the shape of our ears (spectral cues),
    and the change in sound as we move our heads (dynamic cues). Game and XR developers
    can simulate these effects to create immersive 3D soundscapes, where players can
    locate a sound source within the game environment. For instance, in a VR horror
    game, you could use spatial audio to make it sound like eerie whispers are coming
    from just over the player’s shoulder, or like the ominous footsteps of a monster
    are getting closer and closer. These techniques can significantly enhance immersion
    and even gameplay, as players could use sound to navigate their environment or
    detect threats.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reverberation** or **reverb**: This is the persistence of sound in a particular
    space after the original sound is removed. It’s caused by sound waves reflecting
    off surfaces in the environment, such as walls and floors, creating a multitude
    of echoes that gradually fade out. This can give players a sense of the size and
    material of the space they’re in – a large, stone-walled cathedral would have
    a long, bright reverb, while a small, carpeted room would have a short, dull reverb.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Echo**: This is the distinct, delayed reflection of sound that can be clearly
    identified as a repetition of the original source. It’s caused when sound waves
    bounce off distant obstacles and return to the listener after a noticeable time
    gap. The time it takes for the reflection to return can give listeners an impression
    of the distance to the reflecting surface – a mountain range would produce a long-delayed
    echo, while a closer building might yield a quicker, more immediate echo. Different
    surfaces can also affect the tonal quality of the echo, with hard surfaces such
    as concrete producing clearer echoes compared to softer surfaces such as dense
    foliage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding and manipulating these aspects of sound can allow you to create
    rich, immersive, and interactive soundscapes in your XR applications. With careful
    design, sound can be not only an accompaniment to the visual experience but also
    a key element of gameplay and immersion. The following section introduces you
    to Unity’s audio system, which we will use throughout this chapter to breathe
    even more life and immersion into our XR experiences.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Unity’s audio system
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sound design is an essential part of creating immersive XR experiences. With
    Unity’s audio system, you can create dynamic, spatialized audio that reacts to
    the player’s actions and movements, enhancing immersion and even guiding gameplay.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in a VR horror game, you could use spatialized sound to create
    an ominous atmosphere and build tension. Distant, eerie noises could hint at unseen
    dangers, while sudden, nearby sounds could provide jump scares. As the player
    navigates the environment, the sounds change based on their position and orientation,
    making the virtual world feel alive and reactive.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and effectively using Unity’s audio system is a crucial skill
    for any XR developer. Sound isn’t just an accessory to the visuals; it’s also
    a powerful tool for storytelling, player guidance, and world-building.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now take a more detailed look at the three core components of Unity’s
    audio system – AudioClips, AudioSources, and AudioListeners.
  prefs: []
  type: TYPE_NORMAL
- en: '`AudioClip` represents a sound file that can be played back in your application.
    It holds the data for the sound, but on its own, it can’t actually produce sound.
    Think of an `AudioClip` file like a CD – it holds music, but you need a CD player
    to actually hear the music. `AudioClip` files are versatile – you can use them
    for short sound effects, such as a character’s footsteps, or for longer pieces
    of audio, such as background music or dialogue. Unity supports a range of audio
    file formats, including `.wav`, `.mp3`, and `.ogg`. When designing sound for XR,
    remember that audio quality is important for immersion. High-quality `AudioClip`
    files can make a virtual environment feel more real.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AudioSource` is like a CD player for your `AudioClip` file. It’s a component
    that can be attached to a GameObject to play sounds. You can think of it as a
    point in your 3D space where sound originates. Every sound you hear in a Unity
    application originates from an `AudioSource` component. An `AudioSource` component
    plays back an `AudioClip` file in the scene and controls how that sound is played.
    The `AudioSource` component offers several properties that you can manipulate:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AudioClip` file that will be played.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AudioSource` component will start playing its `AudioClip` file as soon as
    the scene starts.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AudioSource` component will loop its `AudioClip` file, starting it again as
    soon as it ends.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AudioSource` component, and can be used to fade sounds in or out.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AudioSource`. Higher values result in a higher pitch, and lower values result
    in a lower pitch. This can be used to create a **Doppler effect**, which is a
    change in the frequency or wavelength of a wave for an observer moving relative
    to its source – for instance, the sound of a passing car changing from high to
    low pitch.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3D Sound Settings**: These settings control how the sound is affected by
    distance. You can make the sound get quieter with distance, change the pitch with
    distance, and so on. This is critical for XR applications, as it helps to create
    a sense of space and realism.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`AudioSource` components in the scene and processes them to create the final
    mixed sound that the player will hear. In most games and XR applications, the
    `AudioListener` is attached to the main camera or the player’s avatar. As the
    player moves through the environment, different sounds will get louder or quieter
    based on their distance and direction from the `AudioListener`, creating a dynamic
    soundscape.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that you should generally only have one `AudioListener`
    in your scene. Having more than one can cause sounds to be duplicated, which can
    result in distortion and other audio artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections guide you on how to implement these components into your
    Unity scene through a new, hands-on VR project.
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the VR drum scene and adding sound effects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After exploring the physical properties of sound waves and Unity’s audio system,
    you will finally put this theoretical knowledge into use by building your own
    VR drum scene.
  prefs: []
  type: TYPE_NORMAL
- en: Once you’ve created a VR scene featuring various drums, which can be struck
    by a player equipped with VR drumsticks in each hand, you’ll discover how to augment
    your setup by assigning distinct sound files to each drum that gets hit. Moreover,
    you’ll learn how to adjust the sound volume based on the intensity of the strike
    delivered by the VR drumsticks, adding an extra layer of realism. This refined
    VR drumming environment will plunge users into an impressively accurate and engaging
    drumming experience. Let us now set up and prepare our VR drum scene.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up and preparing your VR drum scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps guide you on how to create your project, set up the needed
    VR settings in the Unity Editor, and add a player with a ground floor:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new project with the URP by selecting `Drum Scene`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the scene has loaded, navigate to **Edit** | **Project Settings** | **XR
    Plugin** **Management** and click the **Install** button. After the installation,
    enable the **OpenXR** checkbox. If you are prompted to restart the Editor, follow
    the instructions to do so.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Edit** | **Project Settings** | **XR Plugin Management**, go to the
    **OpenXR** submenu. Under the **Windows/Linux/Mac** tab, select the interaction
    profile that matches your headset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To add the required prefabs for our VR player to our scene, we need to install
    the XR Interaction Toolkit. To do so, go to `com.unity.xr.interaction.toolkit`
    and `2.5.1`, and then click the **Add** button. This will automatically install
    the XR Interaction Toolkit into your scene. Once the installation process is finished,
    select **XR Interaction Toolkit** in the **Package Manager** window, and click
    the **Import** buttons next to **Starter Assets** and **XR Device Simulator**,
    as shown in *Figure 7**.1*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.1 – The XR Interaction Toolkit successfully installed alongside
    the imported Starter Assets and XR Device Simulator in the Package Manager window](img/B20869_07_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – The XR Interaction Toolkit successfully installed alongside the
    imported Starter Assets and XR Device Simulator in the Package Manager window
  prefs: []
  type: TYPE_NORMAL
- en: Delete the existing main camera in the hierarchy, as the VR player we will add
    comes with a point-of-view camera. Now, navigate to the `Assets` folder in the
    `floor`, and place it at the origin (`0`, `0`, `0`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hurray! You’ve set up the framework for a VR-enabled drum scene in Unity! The
    subsequent section will guide you through the process of adding the drums and
    drumsticks to your scene.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and importing 3D models for your VR drum scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although Unity Asset Store provides an extensive collection of different 3D
    models, it doesn’t offer free drum models that are suitable for our project. Therefore,
    we’ll utilize 3D models available on *Sketchfab*, another rich platform that allows
    you to download free and paid 3D models from a wide range of creators.
  prefs: []
  type: TYPE_NORMAL
- en: The selected drum models for this chapter were found at [https://skfb.ly/o8QvS](https://skfb.ly/o8QvS)
    and were created by Bora Özakaltun. Open the link and download the free models
    in the `.fbx` file format, as shown in *Figure 7**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.2 – \uFEFFThe required mouse clicks (highlighted in yellow) to download\
    \ the drum models as a\uFEFFn .fbx file](img/B20869_07_02.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – The required mouse clicks (highlighted in yellow) to download the
    drum models as an .fbx file
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Should the models be unavailable at your time of reading, you can clone the
    entire project from the GitHub repository for this book and extract the assets
    from there.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the folder is downloaded, unzip all the child folders. Then, drag the
    unzipped drum folder into your **Project** window, completing the model importation.
    Now, it’s time to integrate the drums into your virtual environment. Follow these
    steps to position the drums in your scene:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `Assets` folder, and then to `drum` | `source directory`. Here, you will
    find the drum model that you previously imported.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **drum** file and drag it into your scene. Upon doing so, you might
    observe that the drum appears disproportionately large for the environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To rectify the size issue, select the drum in the hierarchy and scale it down
    to the dimensions (`0.02`, `0.02`, `0.02`). Place the drum at the origin coordinates
    (`0`, `0`, `0`), aligning it perfectly within the virtual space.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once these adjustments are complete, your scene should resemble the depiction
    in *Figure 7**.3*.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.3 – \uFEFFHow your drum scene should currently look in the Game\
    \ \uFEFFview of the Unity Editor](img/B20869_07_03.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – How your drum scene should currently look in the Game view of the
    Unity Editor
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need drumsticks to interact with the drums. By following these steps,
    we will create our own drumsticks within Unity:'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click in the Scene Hierarchy, navigate to `0.01`, `0.2`, `0.01`). Rename
    this GameObject `Drum Stick`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see in the **Inspector** window, the drumstick automatically includes
    a **Capsule Collider** component. A **Capsule Collider** is a 3D shape used in
    Unity that resembles a capsule or pill-like shape, used to detect collisions between
    objects. Additionally, it is essential to add a **Rigidbody** component to the
    drumstick. This allows the object to be affected by forces and physics within
    the Unity environment, enabling dynamic interactions such as the ones needed for
    an immersive drumming experience. With the drumstick selected, head over to its
    **Inspector** window and select the **Add Component** button. Now, add a **Rigidbody**
    component by searching for it and selecting it. This component allows Unity’s
    physics engine to treat the drumstick as a physical object, simulating interactions
    and reactions to forces, which is critical to realistically model the drumstick’s
    behavior when striking a drum.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set **Collision Detection** of the **Rigidbody** component to **Continuous Speculative**.
    This mode enables more accurate and efficient handling of collisions between the
    drumstick and other objects, particularly when dealing with fast motions typical
    of drumming.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new material in the `Assets` folder, and name it `Drum Stick Material`.
    Download `Balsa_Wood_Texture.jpg` from [https://commons.wikimedia.org/wiki/File:Balsa_Wood_Texture.jpg](https://commons.wikimedia.org/wiki/File:Balsa_Wood_Texture.jpg)
    and import it into the project. Select `Drum Stick Material`, go to `Balsa_Wood_Texture.jpg`
    into the **Base Map** field. Apply this material to the drumstick.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select `Drum Stick`, and click on the `Drum`, and save the tag. We will need
    this tag to address the drumsticks in our scene later on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Prefabs`, and drag the drumstick into it. This will create a prefab,
    allowing easy duplication and modification.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, attach the prefab as a child to both the left controller and the right
    controller, as detailed in *Figure 7**.4*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 7.4 – \uFEFFEach drumstick being successfully attached to the respective\
    \ controller of the XR Origin in the Scene Hierarchy window](img/B20869_07_04.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – Each drumstick being successfully attached to the respective controller
    of the XR Origin in the Scene Hierarchy window
  prefs: []
  type: TYPE_NORMAL
- en: You have successfully completed all the steps to set up and prepare your VR
    drum scene. In the following section, you will learn how you can utilize Unity’s
    audio system to add sound effects to your scene.
  prefs: []
  type: TYPE_NORMAL
- en: Adding sound effects to your VR drum scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section guides you through the process of adding sound effects to your
    VR drum scene. The first step involves triggering audio when hitting an instrument,
    adding realism and engagement to the scene.
  prefs: []
  type: TYPE_NORMAL
- en: Scripting sound playback on collision for your VR drum scene
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To trigger a sound playback once our drumsticks collide with the drums, we
    must use C# scripting. Follow these steps to correctly prepare your drums for
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: In the Unity Editor, press *Ctrl* / *Cmd* on your keyboard, and *left-click*
    to select all the drums in your Scene Hierarchy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With the drums selected, add a **Box Collider** component via the **Inspector**
    window by clicking the **Add Component** button and searching for and selecting
    the **Box** **Collider** component.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we must ensure that the collider functions as a trigger, allowing it to
    initiate actions rather than physical interactions. To do this, select the **Is
    Trigger** checkbox in the **Box Collider** component of each drum in the **Inspector**
    window. This option transforms the collider into a non-physical boundary that
    can detect when objects pass through, making it instrumental in triggering sound
    upon collision.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select all the drums in the Scene Hierarchy, and click on the `PlaySoundOnCollision`,
    and click on **New Script**. This action automatically associates the script with
    all selected drums.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Double-click* on the `PlaySoundOnCollision` script in the **Inspector** window
    to open it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the script opens in your preferred IDE, define the following three variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We will use the public `AudioClip` variable to play the audio, the private `AudioSource`
    variable to play the clip, and assign a public `tag` variable to the drumsticks
    so that only these GameObjects trigger the sound.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the `Start()` function of the `PlaySoundOnCollision` script, add the following
    line of code to access `AudioSource` at the beginning of the experience:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Since we are not continuously checking for changes, we don’t need an `Update()`
    function in this script. Instead, we will implement an `OnTriggerEnter()` method,
    which is called when something collides with the trigger collider:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`OnTriggerEnter()` is a special Unity method that is automatically called by
    the Unity engine itself when a collision with a trigger occurs. This is also why
    we don’t need to call this function within our script and why we selected the
    **Is Trigger** checkbox earlier in this setup.'
  prefs: []
  type: TYPE_NORMAL
- en: Within the `OnTriggerEnter()` method, we call `CompareTag()`, a built-in Unity
    function from the `GameObject` class. By calling it inside of an `if` statement,
    we compare the tag of the colliding object to a string. The use of a tag helps
    ensure that the sound is played only when the drumsticks collide with the drum,
    and not when other objects might collide with it. By assigning a unique tag to
    the drumsticks, similar to the `Drum` tag we used, we can easily and efficiently
    identify them within the `OnTriggerEnter()` method and play the sound only in
    response to their collisions with the drum.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you might be wondering why we are using `CompareTag()` instead
    of directly comparing the tags with the equality operator (`==`). The reason for
    this is that using `CompareTag()` is more computationally efficient. Tags in Unity
    are stored in an internal hashed format, and `CompareTag()` compares these hashes,
    while the equality operator would first convert the hash to a string, making the
    comparison slower.
  prefs: []
  type: TYPE_NORMAL
- en: If the tag comparison returns `true`, the next line is executed. The `_soundSource`
    variable refers to the `AudioSource` component that we will attach to the drums
    later on. The `PlayOneShot()` method is another Unity function from the `AudioSource``AudioSource`.
    This functionality is essential for the authenticity of our drum scene. Instead
    of hearing each drum hit in isolation, we seek to create a continuous flow of
    sound. The ability to layer individual hits allows for a more immersive and realistic
    experience, reflecting the natural overlap that occurs when drums are played in
    quick succession. The use of the `PlayOneShot()` method ensures that the sounds
    meld together harmoniously, capturing the essence of a live drumming performance.
  prefs: []
  type: TYPE_NORMAL
- en: By combining these elements, the `OnTriggerEnter()` method ensures that when
    the drumstick comes into contact with the drum, the specified sound is played,
    creating an immediate and realistic response within the virtual environment. It’s
    a powerful way to add immersion and interactivity to your VR experience. After
    finalizing the `PlaySoundOnCollision` script, it is finally time to add sound
    files for each drum to your scene.
  prefs: []
  type: TYPE_NORMAL
- en: Adding sound files to your VR drum scene
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, you will learn how to import sound files and assign `AudioSource`
    components for each drum. Let’s go through this process step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the appropriate sound files for each of the drums in your Unity scene.
    You can find royalty-free `.mp3` sound files on websites such as [https://www.freesoundslibrary.com/](https://www.freesoundslibrary.com/)
    or [https://pixabay.com/sound-effects/](https://pixabay.com/sound-effects/). Alternatively,
    you have the option to utilize the sound files provided within the Unity project
    linked with this chapter. These files are readily available in this book’s GitHub
    repository.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have the necessary sound files on your local system, go to `Assets`
    | `Import New Assets` in the Unity Editor. Navigate to the location of your sound
    files and select the ones you want to import. Click the **Import** button, and
    the sound files will now be available in your Unity project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select all drums in the **Hierarchy** window (*Ctrl* / *Cmd* + *left-click*).
    In the **Inspector** window, click the **Add Component** button, search for the
    **Audio Source** component, and select it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, select each drum individually in the Scene Hierarchy, and navigate to their`PlaySoundOnCollision`
    script in the **Inspector** window. Click on the small circle next to the **Sound
    Clip** field that we defined earlier, and choose an appropriate sound file for
    each drum.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Upon testing, you’ll find that the drum scene is already quite immersive. However,
    a few adjustments can heighten its realism. The following section guides you on
    how to fine-tune your drum scene.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning the VR drum scene to heighten its realism
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The current setup plays the sound at a constant volume, regardless of how hard
    or soft the drum is hit. To enhance realism, we need to adjust the volume in relation
    to the collision velocity. To achieve this, we can utilize an existing script
    from Valve called *VelocityEstimator*. In case you aren’t familiar, Valve is the
    prominent video game developer and distributor behind the Steam gaming platform,
    and they offer a SteamVR plugin for Unity, along with interesting VR scripts available
    on GitHub. The `VelocityEstimator` script is available in the GitHub repository
    of SteamVR’s Unity Plugin at this link: [https://github.com/ValveSoftware/steamvr_unity_plugin/blob/9442d7d7d447e07aa21c64746633dcb5977bdd1e/Assets/SteamVR/InteractionSystem/Core/Scripts/VelocityEstimator.cs#L13](https://github.com/ValveSoftware/steamvr_unity_plugin/blob/9442d7d7d447e07aa21c64746633dcb5977bdd1e/Assets/SteamVR/InteractionSystem/Core/Scripts/VelocityEstimator.cs#L13).'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with complex physical calculations (such as the relationship between
    volume and collision), searching the internet for existing solutions or scripts
    can save time and effort. In XR development, understanding every aspect of physics
    is not always necessary, but knowing how to implement physical calculations accurately
    is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: 'The purpose of Valve’s `VelocityEstimator` script is to calculate and estimate
    the speed and direction of the GameObject we attach it to – in this case, the
    drumsticks. When applied to our VR drum scene, this script will facilitate the
    adjustment of the sound volume based on the drumstick’s striking speed, thereby
    imitating the natural correlation between the force of a drum hit and the resulting
    sound volume. To add the `VelocityEstimator` script to our drumsticks, let’s perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the `VelocityEstimator` script from GitHub (by selecting *Cmd* / *Ctrl*
    + *Shift* + *S*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Scripts` folder, and drag and drop your downloaded file from your local
    file manager into it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, add the `VelocityEstimator` script to both drumsticks as a component by
    clicking the `VelocityEstimator` script component should look in the **Inspector**
    window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 7.5 – \uFEFFHow the drumsticks’ fully configured VelocityEstimator\
    \ script component should look in the Inspector window](img/B20869_07_05.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – How the drumsticks’ fully configured VelocityEstimator script component
    should look in the Inspector window
  prefs: []
  type: TYPE_NORMAL
- en: 'To take advantage of the drumsticks’ speed in our existing `PlaySoundOnCollision`
    script, we must modify it a bit. Open the script again in an IDE, such as Visual
    Studio, and add the following three lines of code to your script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first variable allows us to decide whether we want to take velocity into
    account when playing the sound. By setting this to `true`, we enable the feature.
    The `minimumVelocity` variable defines the lower threshold for velocity, allowing
    us to specify the minimum speed that will impact the volume. Any velocity below
    this value won’t lead to a decrease in volume. Conversely, the `maximumVelocity`
    parameter sets the upper limit of velocity that will influence the volume. Speeds
    above this threshold won’t result in further increases in volume.
  prefs: []
  type: TYPE_NORMAL
- en: These new parameters grant us control over how the velocity of the drumsticks
    influences the volume of the sounds produced. By adjusting the minimum and maximum
    velocity values, we can fine-tune the responsiveness of the drum sounds to create
    a nuanced and realistic drumming simulation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we must modify the `OnTriggerEnter()` method to use the `VelocityEstimator`
    script component if the `enableVelocity` variable is set to `true` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let’s go through the newly added parts of the `OnTriggerEnter()` method. By
    calling `other.GetComponent<VelocityEstimator>()`, we try to get a component of
    the `VelocityEstimator` type from the object with the `Drum` tag. If the `VelocityEstimator`
    component is found and the `enableVelocity` variable is set to `true`, the code
    inside the `if` statement will be executed. In this case, the code first calls
    the `GetVelocityEstimate` method from the `VelocityEstimator` component to get
    the velocity estimate, and then it takes the magnitude of that vector to get the
    speed as a single float value. Then, the volume of the sound based on the speed
    is calculated and stored in the `soundVolume` variable. The `InverseLerp()` method
    returns a value between `0` and `1`, representing where the value of `v` falls
    between `minimumVelocity` and `maximumVelocity`. By calling `_soundSource.PlayOneShot(soundClip,
    soundVolume)` on the next line, a one-time sound is played at the calculated volume.
  prefs: []
  type: TYPE_NORMAL
- en: The `else` statement at the end of `OnTriggerEnter()` is executed if the previous
    `if` statement is not met. The `if` statement is not met if the `VelocityEstimator`
    script component is not found, or if the `enableVelocity` variable is set to `false`.
    The code inside this block will play the sound at its default volume because the
    velocity of the object was not considered.
  prefs: []
  type: TYPE_NORMAL
- en: If we run the scene right now, we will not hear anything at all when we hit
    the drumsticks against the drums. This is because, in the original `VelocityEstimator`
    script from Valve, the velocity estimation routine was meant to start by calling
    `BeginEstimatingVelocity()`. However, in our `PlaySoundOnCollision` script, this
    function wasn’t being called at all; hence, no velocity estimation took place.
    This is why we consistently get a velocity of zero right now when testing out
    the scene and do not hear anything.
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve this problem, we need to ensure that `BeginEstimatingVelocity()` is
    called when the script starts. This can be done by adding the following code lines
    to the `Start()` method of our `VelocityEstimator` script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: By putting the call to `BeginEstimatingVelocity()` inside the `Start()` method,
    we ensure that the velocity estimation begins as soon as the drumstick object
    is ready, which is exactly what we want.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve successfully executed all necessary steps to add a sound to each drum
    that reflects the intensity of each hit. Now, it’s time to put on your VR headset
    and put the final scene to the test. Pay close attention to the variation in volume
    for each drum sound, depending on the collision velocity with the drumstick. Also,
    keenly observe the sound dynamics when you strike two drums simultaneously or
    hit several drums in rapid succession. You’ll be amazed by how incredibly realistic
    our VR drum scene has become.
  prefs: []
  type: TYPE_NORMAL
- en: The next sections will teach you yet another valuable skill to make your scenes
    more natural and immersive – adding particles!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding particle behavior and Unity’s particle system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When designing immersive XR experiences, understanding the physics of particle
    behavior plays an important role. By leveraging Unity’s particle system and the
    fundamentals of particle physics, you can create rich, dynamic, and realistic
    effects that enhance the immersion of your virtual environments. In this section,
    you will learn everything you need to know about real-world particle behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the behavior of particles in the real world
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Particle behavior in the physical world refers to the ways in which small fragments
    or quantities of matter move and interact, based on forces, environmental conditions,
    and intrinsic properties. Particles in the natural environment behave according
    to certain laws and principles. Key factors include gravity, air resistance, life
    span, and collision behavior. Here is an overview of what all these terminologies
    mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Gravitational forces**: Particles are affected by gravitational forces, which
    pull them toward the center of mass. However, it’s important to note that not
    all particles are affected by gravity in the same way. Consider two common particle
    systems – rain falling from the sky, and sparks rising from a fire. In the case
    of rain, gravity pulls the raindrops down toward the ground. Conversely, sparks
    from a fire rise upward because the heat decreases their effective gravitational
    pull (hot air rises).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Air resistance**: Air resistance, also known as **drag**, is the resistance
    a particle experiences when moving through a medium such as air. It affects both
    the speed and the direction of particles, often resulting in less linear, more
    natural-looking motion. Smoke from a fire or a chimney provides a good example.
    While the heat and updraft may initially propel the smoke upward, air resistance
    and wind can cause it to billow, curve, and sway. Similarly, consider a particle
    system representing leaves blowing in the wind. Air resistance causes the leaves
    to flutter and spin, rather than moving directly in the direction of the wind.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Life span**: Every particle has a life span, a duration of existence after
    which it disappears or changes state. This life span, along with changes that
    happen during it, contributes to the believability of a particle effect. Consider
    a firefly effect, where each firefly would be a particle that appears, glows brightly
    for a few seconds (reaching peak brightness midway through its life), and then
    fades away. A snowflake particle system offers another example. As snowflakes,
    which are represented by particles in your Unity scene, fall toward the ground,
    they could fade or shrink to give the illusion of snowflakes melting as they touch
    the warmer ground.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collision behavior**: When particles come into contact with a surface or
    another particle, they react in a manner that depends on their nature and the
    surface they collide with. This is known as collision behavior. Raindrops, for
    example, splash and disappear upon hitting a hard surface, creating smaller droplet
    particles. Conversely, confetti pieces bounce and scatter instead of splashing
    when they hit a surface.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporating these principles of particle physics into your Unity Particle
    System will significantly enhance the realism and immersion of your XR experiences.
    You will learn about Unity’s Particle System in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Unity’s Particle System
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unity’s Particle System is a powerful tool for XR developers that adds another
    level of immersion to the user experience. It is used to create a wide range of
    special effects such as fire, smoke, sparks, and magic spells, as well as more
    abstract visual elements. Understanding and utilizing Unity’s Particle System
    effectively can significantly enhance the visual appeal of your application and
    deepen the sense of presence within the virtual environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a detailed exploration of the core components of Unity’s Particle
    System – specifically, the Particle System component and the Particle System Renderer
    component. Both of these components will be vital later on when we add a particle
    system to our drum scene:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Particle System component** is the main engine of the particle system
    in Unity. The Particle System component itself is attached to a GameObject and
    controls how particles are generated and behave over their lifetime. It offers
    a multitude of modules, each controlling a different aspect of the particle’s
    behavior:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Emission Module**: This controls the rate at which new particles are spawned.
    Whether you need a constant trickle of particles or a sudden burst, this module
    has you covered.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Shape Module**: This defines the region and the form from which particles
    are birthed. This could be a simple point, a complex mesh, or anything in between,
    offering a flexible start to your particles’ life journey.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gravity Modifier**: This is a setting within the Particle System component
    that emulates the influence of gravity on particles. You can adjust this setting
    to make the particles fall faster or slower, allowing you to create effects such
    as floating dust or rapid rainfall.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Velocity over Lifetime Module**: This dictates how a particle’s speed and
    direction change over its lifetime. Coupled with the Gravity Modifier, this can
    create lifelike effects of particles being caught in wind or turbulence.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Drag**: Found under the **Forces over Lifetime** module, which in Unity’s
    Particle System allows users to apply varying forces to particles throughout their
    life span, this property lets you simulate the effect of air or fluid resistance.
    By modifying the Drag property, you can make particles move as if they are in
    a heavier medium, providing a sense of weight and depth to the particles.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Color over Lifetime Module**: This specifies how a particle’s color evolves
    over its life span. This module, in conjunction with the Size over Lifetime module,
    allows you to create a natural fade-in and fade-out effect, enhancing the realism
    of particles.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Size over Lifetime Module**: This determines how a particle’s scale changes
    over its life cycle. By making particles shrink or grow over time, the environment
    seems to evolve and be dynamic to observers.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collision Module**: This module governs how particles interact with other
    GameObjects in the scene upon collision. You can control properties such as bounce
    (restitution), dampen (loss of speed), and lifetime loss on collision. This can
    offer a high degree of realism to how particles respond to their environment,
    such as sparks bouncing off a surface or water droplets splashing.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To illustrate the application of these principles, consider the example of a
    simple campfire. In this case, embers rising from the fire can be created as a
    particle effect where the particles move upward, affected by a slightly randomized
    velocity to simulate the effect of heat and air resistance. Gravity’s influence
    would be negative here (pulling particles upward) due to the heat, and particles
    could have a reddish color at birth, fading to dark as they cool, simulating the
    life cycle of real embers. The smoke, however, can be created with particles moving
    upward with a higher randomized velocity, simulating the churning effect of fire.
    These particles would be less affected by gravity and have a longer life span.
    They could also use a color gradient, changing from dark gray near the fire to
    a lighter color as they rise and cool. Lastly, the fire itself can be simulated
    with a high rate of small, bright particles with short lifetimes and high randomized
    velocity. The effect would be a vibrant, dynamic flickering fire.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The **Particle System Renderer component** is responsible for rendering the
    particles on the screen. This component can be customized to fit the specific
    visual needs of your application. Some of its properties include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Material**: This defines the appearance of the particles and can include
    textures, colors, and shaders'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Render Mode**: This determines how the particles are rendered and can be
    in the form of billboards (always facing the camera), meshes, or other similar
    entities'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sorting Mode**: This determines the order in which particles are rendered
    and is especially important when particles overlap'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember, particles aren’t just visual fluff. They can play a crucial role in
    your storytelling, player guidance, and world-building efforts. For instance,
    a trail of mystical sparkles might guide a player toward a hidden treasure, or
    a plume of smoke could hint at a recently extinguished campfire nearby.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve explored the key components of Unity’s particle system, let’s
    dive into the following section, which explains how to implement a particle system
    into our drum scene. The goal is that every time we hit a drum, fog is released,
    proportionate to how hard we hit it.
  prefs: []
  type: TYPE_NORMAL
- en: Adding particles to VR scenes with varying properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do you recall the last time you attended a live concert when, at the pinnacle
    of a legendary song, the stage was enveloped by a blanket of white fog while you
    were lost in the music with your friends? Taking inspiration from the theatrical
    smoke often utilized in real-world concerts, we’re going to apply our recently
    acquired knowledge about Unity’s Particle System to create a similar effect. Our
    objective is to integrate a particle system into our drum scene to release fog
    every time a drum is hit, with the intensity of the fog corresponding to the velocity
    of the strike. The more frequently the drums are played, the more the fog should
    saturate our scene, and vice versa, thereby fully replicating the euphoric sensation
    of being at a genuine concert.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this objective, we need to first initialize a Particle System in
    our scene.
  prefs: []
  type: TYPE_NORMAL
- en: Initializing a Particle System in your VR drum scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow these steps to establish a Particle System in your VR drum scene:'
  prefs: []
  type: TYPE_NORMAL
- en: In your Unity scene, *right-click* on the **Hierarchy** window, navigate to
    **Effects**, and select **Particle System**. This will instantiate a new Particle
    System within your scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The existing Particle System employs Unity’s standard particle material, which
    isn’t ideal for creating fog. However, we can easily customize our own material
    for the Particle System. Go to the `Fog`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Download a transparent image of a cloud or fog. We will use a cloud image,
    which is available for download at this link: [https://pixlok.com/images/clouds-png-image-free-download/](https://pixlok.com/images/clouds-png-image-free-download/).
    You can also access it through the GitHub folder for this chapter. Drag and drop
    this image into the `Fog` folder you just created.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Within the `Fog` folder, generate a new material by *right-clicking* and then
    selecting `Fog`. Now, drag and drop the previously downloaded image from your
    local filesystem into the base map of the material. Next, modify the **Shader**
    fieldof the material to **Mobile/Particles/Alpha Blended** in the **Inspector**
    window. This setting allows the particles to overlap with each other and blend
    seamlessly, creating a more realistic fog effect.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Particle System, and drag the `Fog` material into its **Inspector**
    window. This will automatically update the material. As a result, your scene should
    now resemble the scene shown in *Figure 7**.6*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 7.6 – \uFEFFHow your current Unity scene and the Inspector window\
    \ of the Particle System should look with the newly added fog](img/B20869_07_06.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – How your current Unity scene and the Inspector window of the Particle
    System should look with the newly added fog
  prefs: []
  type: TYPE_NORMAL
- en: After successfully adding the Particle System to our VR drum scene, let’s modify
    its properties a bit to achieve a more dynamic behavior for the fog, which is
    dependent on the collision velocity of the drums and drumsticks in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying the properties of the Particle System in your VR drum scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s explore the properties of the Particle System in the **Inspector** window
    by expanding it. There are a few critical properties that you need to modify to
    make the fog on your VR drum scene behave naturally. The modified properties can
    be observed in *Figure 7**.7*.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.7 – \uFEFFThe expanded Particle System in its modified form in the\
    \ Inspector window](img/B20869_07_07.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – The expanded Particle System in its modified form in the Inspector
    window
  prefs: []
  type: TYPE_NORMAL
- en: 'These properties are explained in the following list in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`5` seconds to make the scene more dynamic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PlaySoundOnCollision` script.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`5`-second life span should be sufficient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0` and `2`. This randomizes the speed of each particle within these limits,
    creating a more naturalistic fog effect. **Curve** and **Random between Two Curves**
    are two alternative options that you could also choose. They provide even more
    nuanced control over speed variation, allowing you to define how the values change
    over time and within specific ranges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2`,`2`,`2`) to double the size in all dimensions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Start Color**: This determines the initial color of each particle. To enhance
    the visual appeal and make our fog effect more dynamic, we’ll introduce some color
    variations. Click on the arrow symbol next to **Start Color** and select the **Random
    between Two Gradients** option. This option allows us to define two color gradients,
    with the color of each individual particle being randomly assigned a value somewhere
    within these two gradients. After switching the option to **Random between Two
    Gradients**, two color gradient preview fields appear. To customize the color
    gradients, you can click on these fields to open the **Gradient Editor** window.
    In the **Gradient Editor** window, you can add, remove, or rearrange color markers
    to achieve the color gradient you desire. *Figure 7**.8* provides a visual guide
    on how to modify a color gradient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: "![Figure 7.8 – \uFEFFHow to modify the Gradient Editor of the start color](img/B20869_07_08.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – How to modify the Gradient Editor of the start color
  prefs: []
  type: TYPE_NORMAL
- en: Initially, you can set **Mode** to either **Blend** or **Fixed**. The **Fixed**
    mode presents a solid color, whereas the **Blend** mode enables smooth transitions
    between colors. You can then add multiple keyframes by simply *left-clicking*
    either above or below the color space. The upper keyframes establish the alpha
    values, dictating the transparency, while the lower keyframes determine the colors
    themselves.
  prefs: []
  type: TYPE_NORMAL
- en: At the bottom of the window, you’ll see two existing gradient presets, with
    a third, labeled **New**, that corresponds to the gradient we’re currently editing.
    Create two gradient presets as per your preference, and assign them to the start
    color. In our case, we will choose to use the two pre-existing presets that we
    had (the white and rainbow gradients). At runtime, this configuration will yield
    a captivatingly vibrant and dynamic color spectrum in our fog effect, as shown
    in *Figure 7**.9*.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 7.9 – \uFEFFThe visual appearance of the fog when choosing two pre-existing\
    \ presets for the start color](img/B20869_07_09.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – The visual appearance of the fog when choosing two pre-existing
    presets for the start color
  prefs: []
  type: TYPE_NORMAL
- en: '`0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`0.4`. If the simulation speed is adjusted to a value lower than `0.4`, the
    fog’s movement will be even slower, creating a more languid appearance, whereas
    a value higher than `0.4` will make the fog move more rapidly, giving it a brisker
    motion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expand the `13`. `13` is chosen as the ideal rate to achieve the desired particle
    density and appearance for our purpose. By keeping `0`, we ensure that particles
    are emitted based on time alone, not movement, giving us precise control over
    the number of particles being emitted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further down, expand the `3`,`3`,`1`) to create a larger fog effect. Due to
    the Particle System’s -90-degree rotation on the *X* axis, the *Z* axis now points
    in the *Y* direction and doesn’t need to be scaled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable the `30`. This will gradually fade the particles, adding to the realistic
    fog effect. *Figure 7**.10* provides you with a comparison of how the fog looks
    with and without the **Color over Lifetime** module enabled, and with a low **Alpha**
    setting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: "![Figure 7.10 – \uFEFFComparing the visual appearance of the fog with or without\
    \ the Color over Lifetime module enabled](img/B20869_07_10.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – Comparing the visual appearance of the fog with or without the
    Color over Lifetime module enabled
  prefs: []
  type: TYPE_NORMAL
- en: 'While the Particle System provides a plethora of parameters to play around
    with, the ones we’ve discussed are the most crucial to creating a realistic fog
    effect. If you’re interested in diving deeper into Particle Systems, Unity offers
    a short, free course that we highly recommend: [https://learn.unity.com/tutorial/introduction-to-particle-systems#](https://learn.unity.com/tutorial/introduction-to-particle-systems#).'
  prefs: []
  type: TYPE_NORMAL
- en: Scripting fog appearance on collision for your VR drum scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After setting up the particle system, we need to go back to the `PlaySoundOnCollision`
    script and make a few adjustments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Firstly, we need to create a `public` variable that can reference the Particle
    System we want the particles to emit from. The code for this is relatively simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, whenever the drum gets struck, we should call a method that enables the
    emission of particles from the Particle System. We base the number of emitted
    particles on the speed of the drumstick’s impact. Since we already have the `OnTriggerEnter()`
    method that adjusts the sound volume based on the velocity of the drumstick, we
    can simply apply the same logic to the particle system. To do this, we add three
    lines of code to the `if` statement in the `OnTriggerEnter()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`fogParticleSystem` is a reference to the Particle System GameObject we set
    up previously, which will be assigned through the `int numParticles = Mathf.RoundToInt(velocityMagnitude
    * 10f);` line translates the velocity’s magnitude into a corresponding number
    of particles, multiplying it by `10` – an arbitrary factor that can be adjusted
    for your specific needs. The number is rounded to the nearest integer, as the
    particle emission method requires an integer input.'
  prefs: []
  type: TYPE_NORMAL
- en: The `ParticleSystem.EmitParams emitParams = new ParticleSystem.EmitParams();`
    line initializes an instance of `EmitParams`. This struct can be used to change
    specific parameters of the Particle System when particles are emitted via scripting.
    In our case, we will use the default settings of the created Particle System.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `fogParticleSystem.Emit(emitParams, numParticles);` calls the `Emit()`
    method to instantly emit a defined number of particles. It uses the previously
    created `EmitParams` instance and the calculated number of particles derived from
    the object’s velocity.
  prefs: []
  type: TYPE_NORMAL
- en: With these adjustments, the desired functionality is added. Back in the Unity
    Editor, simply drag and drop the Particle System into the `fogParticleSystem`
    field in your `PlaySoundOnCollision` script component of your drums via the **Inspector**
    window. Once done, run your scene, and test the implementation while wearing your
    VR headset. Note how the more frequently the drums are hit, the more the fog saturates
    the scene, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You now know how to fully replicate the euphoric sensation
    of being at a concert featuring a real-life drummer!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we embarked on a fascinating journey through the world of sound
    and particles, understanding their physical properties and delving into the implementation
    of these real-world phenomena in Unity scenes for heightened immersive experiences
    in XR.
  prefs: []
  type: TYPE_NORMAL
- en: Upon reaching the end of this chapter, you should now be capable of not only
    constructing end-to-end XR applications with intricate interactions or animations
    but also feel comfortable enhancing these creations, by effectively using Unity’s
    audio and Particle Systems to introduce an additional layer of realism to your
    XR scenes.
  prefs: []
  type: TYPE_NORMAL
- en: The XR development concepts we’ve covered so far in this book have largely been
    aimed at those at the beginner to intermediate levels. However, as we move forward,
    we have something truly unique and enriching in store for you. The following chapter
    will further elevate your XR development skills by introducing you to some of
    the most significant and advanced techniques in this field, such as hand-tracking,
    eye- and head-tracking, and multiplayer functionalities. This crucial knowledge
    will refine your skillset, transforming you into a more versatile XR developer
    and enabling you to create an even broader array of sophisticated XR applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 3 – Advanced XR Techniques: Hand-Tracking, Gaze-Tracking, and Multiplayer
    Capabilities'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations on completing your journey from being a beginner in XR development
    and Unity to becoming highly proficient in creating various XR technologies with
    sophisticated logic! In this final part of our book, we aim to further enhance
    your skills to become an intermediate-level XR developer. We will introduce you
    to advanced XR techniques that are not only cutting-edge in the XR application
    landscape but will also elevate your XR scenes to a new level of intuitiveness
    and enjoyment.
  prefs: []
  type: TYPE_NORMAL
- en: This section will also introduce you to the different phases and aspects of
    the XR development life cycle. It will provide you with a precise, research-based
    overview of the current state of the art and future trends in XR development.
    By delving into additional XR toolkits and plugins beyond those covered earlier
    in this book, we will prepare you with the knowledge needed to dive deeper into
    your preferred area of XR development once you’ve completed this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part contains the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B20869_08.xhtml#_idTextAnchor026), *Building Advanced XR Techniques*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B20869_09.xhtml#_idTextAnchor028), *Best Practices and Future
    Trends in XR Development*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
