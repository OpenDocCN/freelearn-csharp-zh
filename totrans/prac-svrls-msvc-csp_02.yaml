- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Demystifying Microservices Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Over the last decade, microservices architecture has taken a central role in
    modern software development. In this chapter, we will define what microservices
    architecture is. You will learn the reasons behind the success of microservices,
    their pros and cons, and when it is worth adopting them. Starting with the problems
    that led to their conception, we will discuss typical scenarios of when to use
    them, the impact of their adoption on overall project costs, and the returns you
    might expect.
  prefs: []
  type: TYPE_NORMAL
- en: You will get insights into the organization of microservices, discovering how
    it differs from the usual monolithic application by resembling more of an assembly
    line than user-requests-driven processing. This newly conceived organization brings
    with it new challenges that require ad hoc techniques to enforce coherence, coordination,
    and reliability.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, new patterns and best practices have been created to tackle challenges
    with microservices and optimize their advantages. We will introduce and summarize
    some fundamental patterns here, while their practical implementation, together
    with more specific patterns, will be detailed throughout the remainder of the
    book.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, this chapter covers the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The rise of **Service-Oriented Architectures** (**SOAs**) and microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The definition and organization of microservices architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When is it worth adopting microservices architectures?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices common patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rise of Service-Oriented Architectures (SOAs) and microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Briefly defined, microservices are chunks of software deployed on computer networks
    that communicate through network protocols. However, this is not all; they must
    also obey a set of further constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Before giving a more detailed definition of what a microservices architecture
    is, we must understand how the idea of microservices evolved and what kind of
    problems it was called to solve. We will describe the two main steps of this evolution
    across two separate subsections.
  prefs: []
  type: TYPE_NORMAL
- en: The rise of SOA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step in the direction of microservices was taken by the so-called
    **service-oriented architectures**, or **SOAs**, that is, architectures based
    on networks of communicating processes. Initially, SOAs were implemented as web
    services similar to the ones you might have already experienced in ASP.NET Core.
  prefs: []
  type: TYPE_NORMAL
- en: In an SOA, different macro-modules that implement different features or roles
    in software applications are exposed as separate processes that communicate with
    each other through standard protocols. The first SOA implementation was web services
    communicating through the XML-based SOAP protocol. Then, most web services architectures
    moved toward JSON-based web APIs, which you might already know about since REST
    web services are available as standard ASP.NET project templates. The *Further
    reading* section contains useful links that provide more details on REST web services.
  prefs: []
  type: TYPE_NORMAL
- en: 'SOAs were conceived during the boom in the creation of software for business
    applications as one of the ways to integrate the various preexisting applications
    used by different branches and divisions into a unique company information system.
    Since the preexisting applications were implemented with different technologies,
    and the software expertise available in the various branches and divisions was
    heterogeneous, SOA was the answer to the following compelling needs:'
  prefs: []
  type: TYPE_NORMAL
- en: Enabling software communication between modules implemented with different technologies
    and running on different platforms (Linux + Apache, Linux + NGINX, or Windows
    + IIS). In fact, software based on different technologies is not binary compatible,
    but it can still cooperate with others if each of them is implemented as a web
    service that communicates with the others through a technology-independent standard
    protocol. Among them, it is worth mentioning the text-based HTTP REST protocol
    and the binary gRPC protocol. Worth mentioning also is that the HTTP REST protocol
    is an actual standard while at the moment, gRPC is just a de facto standard proposed
    by Google. The *Further reading* section contains useful links for getting more
    details about these protocols.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enabling the versioning of each macro-module to evolve independently from the
    others. For instance, you might decide to move some web service toward the new
    .NET 9 version to take advantage of new .NET features or new, available libraries,
    while leaving other web services that don’t need modifications with a previous
    version, say, .NET 8.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Promoting public web services that offer services to other applications. As
    an example, think of the various public services offered by Google, such as Google
    Maps, or the artificial intelligence services offered by Microsoft, such as language
    translation services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Below is a diagram that summarizes classical SOA.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B31916_02_1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: SOA'
  prefs: []
  type: TYPE_NORMAL
- en: Over time, the company information system and other complex SOA applications
    conquered more markets and users, so new needs and constraints appeared. We will
    discuss them in the next subsection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Toward microservices architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As application users and traffic increased up to a different order of magnitude,
    the optimization of performance and the optimal balancing of hardware resources
    among the various software modules became a *must*. This led to a new requirement:'
  prefs: []
  type: TYPE_NORMAL
- en: Each software module must be scalable independently from the others so that
    we can allocate to each module the optimal quantity of resources it needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the company information system gained a central role, its continuous operation,
    that is, almost zero downtime, became a *must*, leading to another important constraint:'
  prefs: []
  type: TYPE_NORMAL
- en: Microservices architecture must be redundant. Each software module must have
    several replicas running on different hardware nodes to resist software crashes
    and hardware failures.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, to adapt each application to a rapidly evolving market, the requirements
    on the development times became more compelling. Accordingly, more developers
    were needed to develop and maintain each application with the given strict milestones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, handling software projects involving more than around four people
    to the required quality proved to be substantially impossible. So, a new constraint
    was added to SOAs:'
  prefs: []
  type: TYPE_NORMAL
- en: The services composing an application must be completely independent of each
    other so that they can be implemented by loosely interacting separate teams.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the maintenance effort also needed to be optimized, yielding another
    important constraint:'
  prefs: []
  type: TYPE_NORMAL
- en: Modifications to a service must not propagate to other services. Accordingly,
    each service must have a well-defined interface that doesn’t change with software
    maintenance (or that, at least, rarely changes). For the same reason, design choices
    adopted in the implementation of a service must not constrain any other application
    service.
  prefs: []
  type: TYPE_NORMAL
- en: The first and second requirements can be satisfied by implementing each software
    module as a separate service so that we might allocate more hardware resources
    to it by simply replicating it in N different instances as needed to optimize
    the overall performance and ensure redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: We also need a new actor, something that decides how many copies of each service
    to use and on what hardware to place them. There are similar entities called **orchestrators**.
    It is worth pointing out that we might also have several orchestrators, each taking
    care of a subset of the services, or no orchestrator at all!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summing up, we moved from applications made of coarse-grained coupled web services
    to fine-grained and loosely coupled microservices, each implemented by a different
    developer team, as shown in the following figure.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 2.2: Microservices architecture](img/B31916_02_2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: Microservices architecture'
  prefs: []
  type: TYPE_NORMAL
- en: The diagram shows fine-grained microservices assigned to different loosely coupled
    teams. It is worth pointing out that while loose coupling was also an initial
    target for the primordial web services architectures, it took time to improve
    to a good level, till reaching its peak with the advent of microservices techniques.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The preceding diagram and requirements do not define exactly what microservices
    are; they just explain the start of the microservices era. In the next section,
    we will give a more formal definition of microservices that reflects their current
    stage of evolution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The definition and organization of microservices architectures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will give a definition of microservices and detail their
    immediate consequences on an organization, distinguishing between the *microservices
    definition*, which is expected to change gradually over time, and *microservices
    practical organization*, which might evolve at a faster rate as new technologies
    appear.
  prefs: []
  type: TYPE_NORMAL
- en: In the first subsection, we will focus on the definition and its immediate consequences.
  prefs: []
  type: TYPE_NORMAL
- en: A definition of microservices architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s first list all the microservices requirements. Then, we will discuss each
    of them in a separate subsection.
  prefs: []
  type: TYPE_NORMAL
- en: 'A microservices architecture is an architecture based on SOA that satisfies
    all the constraints below:'
  prefs: []
  type: TYPE_NORMAL
- en: Module boundaries are defined according to the domain of expertise they require.
    As we will discuss in the subsections below, this should ensure they are loosely
    coupled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each module is implemented as a replicable service, called a **microservice**,
    where replicable means one can create several instances of each service to enforce
    scalability and redundancy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each service can be implemented and maintained by a different team, where all
    teams are loosely coupled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each service has a well-defined interface known to all teams involved in the
    development project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Communication protocols are decided at the project start and are known by all
    teams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each service must depend just on the interface exposed by the others and on
    the communication protocols adopted. In particular, no design choice adopted for
    a service can impose constraints on the implementation of the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are encouraged to compare each of the above constraints with the requirements
    that led to the conception of microservices architecture discussed in the previous
    section. In fact, each of these constraints is the immediate result of one or
    more of the previous requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss each constraint in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Domain of expertise and microservices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This constraint has the purpose of providing a practical rule for defining
    the boundary of each microservice so that microservices are kept loosely coupled
    and can be handled by loosely coupled teams. It is based on the theory of **domain-driven
    design** developed by Eric Evans (see *Domain-Driven Design*: [https://www.amazon.com/exec/obidos/ASIN/0321125215/domainlanguag-20](https://www.amazon.com/exec/obidos/ASIN/0321125215/domainlanguag-20)).
    Here, we will go over just a few essential concepts of this theory, but if you’re
    interested in reading more, refer to the *Further reading* section for more details.'
  prefs: []
  type: TYPE_NORMAL
- en: Basically, each domain of expertise uses a typical language. Therefore, during
    the analysis, it is enough to detect changes in the language used by the experts
    you speak with to understand what is included in and excluded from each microservice.
  prefs: []
  type: TYPE_NORMAL
- en: The rationale behind this technique is that toughly interacting people always
    develop a specific language recognized by others who share the same domain of
    expertise, while the absence of such a common language is a signal of loose interaction.
  prefs: []
  type: TYPE_NORMAL
- en: This way, the application **domain** or an application **subdomain** is split
    into so-called **bounded contexts**, each characterized by the usage of a common
    language. It is worth pointing out that **domain**, **subdomain**, and **bounded
    context** are all core concepts of DDD. For more details on them and DDD, you
    may refer to the *Further reading* section, but our simple description should
    suffice for getting started with microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we get the first division of the application into **bounded contexts**.
    Each is assigned to a team and a formal interface for each of them is defined.
    This interface becomes the specification of a microservice, and it is also everything
    the other teams must know about the microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Then, each team that has been assigned a microservice can split it further into
    smaller microservices to scale each of them independently from the others, checking
    that each resulting microservice exchanges an acceptable quantity of messages
    with the others (loose coupling).
  prefs: []
  type: TYPE_NORMAL
- en: The first division is used to split the work among the teams, while the second
    division is designed to optimize performance in various ways, which we will detail
    in the *Microservices organization* subsection.
  prefs: []
  type: TYPE_NORMAL
- en: Replicable microservices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There should be a way to create several instances of the same microservice
    and place them on the available hardware to allocate more hardware resources to
    the most critical microservices. For some applications or single microservices,
    this can be done manually; but, more often, dedicated software tools called **orchestrators**
    are adopted. In this book, we will describe two orchestrators: **Kubernetes**,
    in [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205), *Practical Microservices Organization
    with Kubernetes*, and **Azure Container Apps**, in [*Chapter 9*](Chapter_9.xhtml#_idTextAnchor261),
    *Simplifying Containers and Kubernetes: Azure Container Apps* *and other Tools*.'
  prefs: []
  type: TYPE_NORMAL
- en: Splitting microservices development among different teams
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The way microservices are defined, so that they can be assigned to different
    loosely coupled teams, has already been explained in the *Domain of expertise
    and microservices* subsection. Here, it is worth pointing out that the microservices
    defined at this stage are called **logical microservices**, and then each team
    can decide to split each logical microservice into one or more **physical microservices**
    for various practical reasons.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices, interfaces, and communication protocols
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once microservices are assigned to different teams, it is time to define their
    interfaces and the communication protocol used for each kind of message. This
    information is shared among all teams so that each team knows how to communicate
    with the microservices handled by the other teams.
  prefs: []
  type: TYPE_NORMAL
- en: Only the interfaces of all logical microservices and the associated communication
    protocols must be shared among all teams, while the division of each logical microservice
    into physical microservices is just shared within each team.
  prefs: []
  type: TYPE_NORMAL
- en: 'The coordination of the various teams, and the documentation and monitoring
    of all services, is achieved with various tools. Below are the main tools used:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Context maps** are a graphical representation of the organizational relationships
    among the various teams working on all application-bounded contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service catalogs** collect information about all microservice requirements,
    teams, costs, and other properties. Tools like **Datadog** ([https://docs.datadoghq.com/service_catalog/](https://docs.datadoghq.com/service_catalog/))
    and **Backstage** ([https://backstage.io/docs/features/software-catalog/](https://backstage.io/docs/features/software-catalog/))
    perform various types of monitoring, while tools like **Postman** ([https://www.postman.com/](https://www.postman.com/))
    and **Swagger** ([https://swagger.io/](https://swagger.io/)) are mainly focused
    on formal requirements, such as the testing and automatic generation of clients
    for interacting with the services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just the interfaces of the logical microservices are public
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The code of each microservice can’t make any assumptions about how the public
    interface of all other logical microservices is implemented. Nothing can be assumed
    about the technologies used (.NET, Python, Java, and so on) and their versions,
    and nothing can be assumed about the algorithms and data architectures used by
    other microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Having analyzed the definition of microservices architecture, and its immediate
    consequences, we can move to the current most practical way to organize them.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices organization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first consequence of the independence of microservices design choices is
    that each microservice must have private storage because a shared database would
    cause dependencies among the microservices sharing it. Suppose microservices A
    and B both access the same database table, T. Now, we’re modifying microservice
    A to meet a new user’s requirements. As part of this update, the solution for
    A will require us to replace table T with two new tables, T1 and T2.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a similar situation, we would be forced to also change the code of B to
    adapt it to the replacement of T with T1 and T2\. Clearly, the same limitation
    doesn’t apply to different instances of the same microservice, so they can both
    share the same database. To summarize, we can state the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Instances of different microservices can’t share a common database.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, moving away from a single-application database inevitably leads
    to data duplication and coordination challenges. More specifically, the same chunk
    of data must be duplicated in several microservices, so when it changes, the change
    must be communicated to all microservices that are using a duplicated copy of
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, we may state another organizational constraint:'
  prefs: []
  type: TYPE_NORMAL
- en: Microservices must be designed in a way that minimizes the duplication of data,
    or stated differently, duplications should involve as few microservices as possible.
  prefs: []
  type: TYPE_NORMAL
- en: As has been said in the previous section, if we define microservices according
    to the domain of expertise, the last constraint should be ensured automatically
    because different domains of expertise usually share just a little data.
  prefs: []
  type: TYPE_NORMAL
- en: No other constraints descend immediately from the definition of microservices,
    but it is enough to add a trivial performance constraint on the response time
    to force the organization of microservices in a way that it more closely resembles
    an assembly line than a usual user-request-driven software. Let’s see why.
  prefs: []
  type: TYPE_NORMAL
- en: 'A user request coming to microservice A might cause, in turn, a long chain
    of requests issued to other microservices, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3: Chain of synchronous request-responses](img/B31916_02_3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Chain of synchronous request-responses'
  prefs: []
  type: TYPE_NORMAL
- en: Messages 1-6 are triggered by a request to microservice *A* and are sent in
    sequence, so their processing times sum up to the response time. Moreover, microservice
    *A*, after having sent message *1*, remains blocked, waiting for a response, until
    it receives the last message (*6*); that is, it remains blocked for the whole
    lifetime of the overall chained communication process.
  prefs: []
  type: TYPE_NORMAL
- en: Microservice **B** remains blocked twice, waiting for an answer to a request
    it issued. The first time is during the *2*-*3* communication and then the second
    is during the *4*-*5* communication. To sum up, a naive request-response pattern
    to microservices communication implies high response times and a waste of microservices
    computation time.
  prefs: []
  type: TYPE_NORMAL
- en: The only ways to overcome the above problems are either avoiding complete dependencies
    among microservices or caching all information needed to satisfy any user request
    into the first microservice, *A*. Since reaching total independence is basically
    impossible, the usual solution is caching in *A* whatever data it needs to answer
    requests without asking for further information about other microservices.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this goal, microservices are proactive and adopt the so-called **asynchronous
    data-sharing** approach. Whenever they update data, they send the updated information
    to all other microservices that need it for their responses. Put simply, in the
    example above, tree nodes, instead of waiting for requests from their parent nodes,
    send pre-processed data to all their possible callers each time their private
    data changes, as shown in the figure below.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.4: Data-driven communication](img/B31916_02_4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: Data-driven communication'
  prefs: []
  type: TYPE_NORMAL
- en: Both communications labeled *1* are triggered when the data of the *C*/*D* microservices
    changes, and they may occur in parallel. Moreover, once communication is sent,
    each microservice can return to its job without waiting for a response. Finally,
    when a request arrives at microservice *A*, it already has all the data it needs
    to build the response with no need to interact with other microservices. In general,
    microservices based on **asynchronous data sharing** pre-process data and send
    it to whichever other service might need it as soon as their data changes. This
    way, each microservice already contains precomputed data that it can use to respond
    immediately to user requests with no need for further request-specific communications.
  prefs: []
  type: TYPE_NORMAL
- en: This time, we can’t speak of requests and responses but simply of messages exchanged.
    People working with classical web applications will be accustomed to request/response
    communications where a client issues a request and a server processes that request
    and sends back a response.
  prefs: []
  type: TYPE_NORMAL
- en: In general, in a request/response communication, one of the involved actors,
    say, **A**, sends a message containing a **request** to perform some specific
    processing to another actor, say, **B**, then **B** performs the required processing
    and returns a result (the **response**), which may also be an error notification.
  prefs: []
  type: TYPE_NORMAL
- en: However, we may also have communications that are not request/response-based.
    In this case, we simply speak of messages. In this case, there are not responses
    but just acknowledgments that the messages have been correctly received by either
    the final target or an intermediate actor. Differently from responses, acknowledgments
    are sent before completing the processing of the messages.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to **asynchronous data sharing**, as new data becomes available, each
    microservice does its job and then sends the results to all interested microservices,
    and then it continues performing its job without waiting for a response from its
    recipients.
  prefs: []
  type: TYPE_NORMAL
- en: Each sender just waits for an acknowledgment from its immediate recipient, so
    wait times do not add up like in the initial chained request/response example.
  prefs: []
  type: TYPE_NORMAL
- en: What about message acknowledgments? They also cause small delays. Is it possible
    to also remove this smaller inefficiency? Of course, with the help of asynchronous
    communication!
  prefs: []
  type: TYPE_NORMAL
- en: In synchronous communication, the sender waits for the message acknowledgment
    before continuing its processing. This way, if the acknowledgment times out or
    is replaced by an error notification, the sender can perform corrective actions,
    such as resending the message.
  prefs: []
  type: TYPE_NORMAL
- en: In asynchronous communication, the sender doesn’t wait for either an acknowledgment
    or an error notification but continues its processing, immediately after the message
    is sent, while acknowledgments or error notifications are sent to a callback.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous communication is more effective in microservices because it completely
    avoids wait times. However, the necessity to perform corrective actions in case
    of possible errors complicates the overall message-sending action. More specifically,
    all sent messages must be added to a queue, and each time an acknowledgment arrives,
    the message is marked as correctly sent and removed from this queue. Otherwise,
    if no acknowledgment arrives within a configurable `timeout` time, or if an error
    is raised, the message is marked to be re-sent according to some retry policies.
  prefs: []
  type: TYPE_NORMAL
- en: 'The microservices **asynchronous data-sharing** approach is often accompanied
    by the so-called **Command Query Responsibility Segregation** (**CQRS**) pattern.
    According to CQRS, microservices are split into *updates microservices*, which
    perform the usual CRUD operations, and *query microservices*, which are specialized
    in answering queries that aggregate data from several other microservices, as
    shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.5: Updates and query microservices](img/B31916_02_5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Updates and query microservices'
  prefs: []
  type: TYPE_NORMAL
- en: According to the **asynchronous data-sharing** approach, each update microservice
    sends all its modifications to the query services that need them, while query
    microservices precompute all queries to ensure short response times. It is worth
    pointing out that data-driven updates resemble a factory assembly line that builds
    all possible query results.
  prefs: []
  type: TYPE_NORMAL
- en: Both updates and query microservices are called **frontend** microservices because
    they are involved in the usual request-response pattern with the user. However,
    data updates in their path may also encounter microservices that do not interact
    at all with a user. They are called **worker** microservices. The following figure
    shows the relationship between worker and frontend microservices.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.6: Frontend and worker microservices](img/B31916_02_6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Frontend and worker microservices'
  prefs: []
  type: TYPE_NORMAL
- en: While frontend microservices usually respond to several user requests in parallel
    by creating a thread for each request, worker microservices are involved only
    in data updates, so they don’t need to parallelize requests to ensure low response
    times to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Accordingly, their operation is completely analogous to the one of the stations
    that compose an assembly line. They extract their input messages from an input
    queue and process them one after the other. Output data is sent to all interested
    microservices as soon as they are available. This kind of processing is called
    **data-driven**.
  prefs: []
  type: TYPE_NORMAL
- en: One might object that worker microservices are not necessary since their job
    might be taken care of by the frontend services that consume their outputs. This
    is not the case! For instance, let’s imagine accounting data that needs to be
    consolidated over a period of time before being used as fields of complex queries.
    Of course, each query microservice that needs the consolidated data might take
    care of consolidating it. However, this would result in the duplication of the
    processing effort and the storage needed to hold the partial sums.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, embedding the consolidation processing in other microservices would
    enable its independent scaling, with better optimization of the overall performance.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection shows an example that exemplifies all the concepts learned
    so far.
  prefs: []
  type: TYPE_NORMAL
- en: Car-sharing example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The following figure shows a communication diagram of the routes-handling part
    of a car-sharing application. Dashed lines surround all physical microservices
    belonging to the same logical microservice. Query microservices are at the top
    of the image, updates microservices are at the bottom, and worker microservices
    are in the middle (with gray shading).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7: Route-handling subsystem of a car-sharing application](img/B31916_02_7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.7: Route-handling subsystem of a car-sharing application'
  prefs: []
  type: TYPE_NORMAL
- en: The language analysis detected two logical microservices. The first one speaks
    the language of the car sharer and is made of six physical microservices. The
    second one is focused on topology since it finds the best routes between a source
    and a destination and matches intermediate source-destination pairs with existing
    routes.
  prefs: []
  type: TYPE_NORMAL
- en: Car holders handle their requests with CRUD operations on the `Car-Holding-Requests`
    updates microservice, while users looking for a car interact with the `Car-Seeking-Requests`
    updates microservice in a similar way. The `Routes-Listing` microservice lists
    all available trips with empty slots for new passengers to help car seekers choose
    the date of their trip. Once the date is chosen, the request is submitted through
    the `Car-Seeking-Requests` microservice.
  prefs: []
  type: TYPE_NORMAL
- en: Both car holders and car seekers interact with the `Route-Choosing` updates
    microservice. Car seekers choose one of several available routes for both the
    source and destination, while car holders accept car seekers by selecting the
    routes that fit their sources and destinations. Once a route is selected by a
    car seeker and accepted by the car holder, all other incompatible options are
    deleted from the best matches of both the car holder and the car seeker.
  prefs: []
  type: TYPE_NORMAL
- en: All available routes for both car seekers and car holders are listed by the
    `My-Best-Matches` microservice. The `Routes-Planner` worker microservice computes
    the best routes that fit for the source and destination of a car holder that contains
    also sources and destinations for some car seekers. It stores unmatched car-seeker
    requests until a route passing at an acceptable distance from them is added. When
    this happens, the `Routes-Planner` microservice creates a new alternative route
    for the same trip that contains the new source-destination pair. All routes’ changes
    are sent to both the `My-Best-Matches` and `Route-Choosing` microservices.
  prefs: []
  type: TYPE_NORMAL
- en: The `Locations-Listing` microservice handles a database of known locations,
    and it is used in various kinds of user suggestions, such as autocomplete of user
    sources and destinations and suggestions for interesting trips based on user preferences
    statistics. It takes its input from all car-holder and car-seeker requests.
  prefs: []
  type: TYPE_NORMAL
- en: We have seen what kind of problems microservices were conceived to solve and
    how their adoption adds complexity to the application design. Moreover, it is
    not difficult to imagine that testing and maintaining an application that runs
    on several different machines and relies on complex data-driven communication
    patterns should be a complex and time-consuming task.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is important to assess the impact of using microservices architecture
    in our application to verify that the cost is affordable and that the advantages
    of the adoption outweigh the disadvantages and extra costs. In the next section,
    we will cover some criteria for facing this kind of assessment.
  prefs: []
  type: TYPE_NORMAL
- en: When is it worth adopting microservices architectures?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An application that requires more than five developers is certainly a good target
    for a microservices architecture since logical microservices help split the workforce
    into small, loosely coupled teams.
  prefs: []
  type: TYPE_NORMAL
- en: A high-traffic application with several time-consuming modules is also a good
    target for microservices architecture since it needs module-level performance
    optimizations.
  prefs: []
  type: TYPE_NORMAL
- en: Low-traffic applications that require just a small team of less than five people
    for their implementation are not a good target for a microservices architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Deciding when to adopt microservices in all other situations that fall between
    the above extreme cases is not easy. In general, it requires a detailed analysis
    of costs and returns.
  prefs: []
  type: TYPE_NORMAL
- en: Considering costs, using a microservices architecture requires a development
    effort of about five times that of a usual monolithic application. We got this
    scale as an average on 7 total rewrites of monolithic applications with a Microservices
    architecture.
  prefs: []
  type: TYPE_NORMAL
- en: This is in part due to the extra effort needed to handle reliable communications,
    coordination, and detailed resource management. However, most of the costs come
    from the difficulties of testing, debugging, and monitoring a distributed application.
  prefs: []
  type: TYPE_NORMAL
- en: Later in the book, we will describe tools and methodologies for efficaciously
    handling all of the above problems, but the extra cost brought on by microservices
    remains.
  prefs: []
  type: TYPE_NORMAL
- en: Considering expected returns, the most significant advantage is the capability
    of focusing maintenance on just the critical modules, since if the interface of
    a microservice doesn’t change also the more drastic changes in its implementation,
    such as moving to a different operating system, or to a different development
    stack, or simply to a newer version of the same stack, will not require any change
    to all other Microservices.
  prefs: []
  type: TYPE_NORMAL
- en: We may decide to reduce the maintenance of modules that do not require several
    market-critique changes to a minimum while focusing on just the market-critique
    modules that either increase the perceived value of the application or require
    changes to adapt them to a quickly evolving market. To summarize, we may focus
    on just the important changes required by the users, leaving all modules that
    are not involved in these changes unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on just a few modules ensures a low time to market, so we can satisfy
    market opportunities as soon as they appear without the risk of releasing a new
    version too late.
  prefs: []
  type: TYPE_NORMAL
- en: We are also able to fine-tune performance quickly when the traffic on some specific
    functionalities increases by scaling just the involved microservices. It is worth
    pointing out that the capability of fine-tuning each specific building block of
    our application allows for better usage of the available hardware, thus reducing
    the overall hardware costs. Moreover, the ability to fine-tune and monitor specific
    microservices simplifies achieving better response times and, in general, performance
    goals.
  prefs: []
  type: TYPE_NORMAL
- en: Having analyzed the evolution that led to the microservices architecture, as
    well as its very nature and basic organization, we can move on to patterns that,
    while not specific to microservices, are common in microservices architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices common patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will analyze the fundamental patterns used in all microservices
    architectures whose description is not tied to a specific programming language
    or tool. Most of them concern microservice communication. Let’s start with common
    retry strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Resilient task execution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microservices can be moved from one machine to another to achieve better load
    balancing. They can also be restarted to reset some possible memory leaks or to
    solve other performance issues. During these operations, they may miss some messages
    sent to them, or they may abort some ongoing computation. Moreover, failure due
    to software bugs or hardware faults may occur, too.
  prefs: []
  type: TYPE_NORMAL
- en: Since microservices architectures are required to be reliable (almost zero downtime),
    they are usually redundant, and particular care is needed to detect faults and
    apply corrective actions. Therefore, all microservices architectures must provide
    mechanisms to both detect failures, such as simple timeouts, and correct failed
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: Failures are detected through the detection of either unexpected exceptions
    or timeouts. Since the code can always be arranged in a way to turn timeouts into
    exceptions, failure detection can always be reduced to adequate exception handling.
  prefs: []
  type: TYPE_NORMAL
- en: To resolve this problem, the community of microservices developers defined useful
    **retry policies** one can attach to specific exceptions. They are usually implemented
    through specific libraries together with other reliability patterns, but sometimes
    they are offered out of the box by cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Below are the standard reliability patterns used in microservices architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Exponentials retry**: It has been designed to overcome temporary faults,
    such as a failure due to a microservice instance restart. After each failure,
    the operation is retried with a delay that increases exponentially with the number
    of attempts, until a maximum number of attempts is reached. For instance, first,
    we would retry after 10 milliseconds, and if this retry operation results in a
    new failure, a new attempt is made after 20 milliseconds, then after 40 milliseconds,
    and so on. If the maximum number of attempts is reached, an exception is thrown,
    where it can find another retry policy or some other exception-handling strategy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Circuit break**: It has been designed to handle long-term failures and it
    is usually triggered after an exponential retry reaches its maximum number of
    retries. When a long-term failure is assumed, access to the resource is interdicted
    for a fixed amount of time by returning an immediate exception without attempting
    all the required operations. The interdiction time must be sufficient to allow
    human intervention or any other kind of manual fix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bulkhead isolation**: Bulkhead isolation has been designed to prevent failure
    and congestion propagation. The basic idea is to organize services and/or resources
    into isolated partitions so that failures or congestions originating in a partition
    remain confined to that partition, and the remainder of the system continues working
    properly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppose, for instance, that several microservice replicas use the same database
    (as is common). Due to a failure, a replica might start opening too many database
    connections, thus also congesting all other replicas that need to access the same
    database.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we recognize that database connections are critical resources
    that need bulkhead isolation. Thus, we compute the maximum number of connections
    the database can properly handle and partition them among all replicas, assigning,
    for instance, a maximum of five simultaneous connections to each microservice
    replica.
  prefs: []
  type: TYPE_NORMAL
- en: 'This way, a failure in a replica doesn’t affect the proper access of other
    replicas to the database. Moreover, if the application is properly organized,
    requests that fail to be served because of the failed replica will eventually
    be retried on a properly working replica so that the overall application can continue
    working properly. In general, if we would like to partition all requests to a
    shared resource, we can proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Only a maximum number of similar pending simultaneous outbound requests to the
    shared resource is allowed; let’s say 5, as in the previous database example.
    This is like putting an upper bound on thread creation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Requests exceeding the previous bound are queued.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If a maximum queue length is reached, any further requests result in exceptions
    being thrown to abort them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is worth pointing out that the requests partitioning and throttling pattern
    previously shown is a common way of applying bulkhead isolation, but it is not
    the only way. Any partition plus isolation strategy can be classified as bulkhead
    isolation. For instance, one might split the replicas of two interacting microservices
    into two isolated partitions such that only replicas belonging to the same partition
    might interact. This way, a failure in a partition can’t affect the other partition.
  prefs: []
  type: TYPE_NORMAL
- en: Together with the actions and strategies for handling failures exposed above,
    microservices architectures also offer failure prevention strategies. Failure
    prevention is achieved by monitoring anomalous consumptions of hardware resources
    and performing periodic hardware and software health checks. For this purpose,
    orchestrators monitor the usage of memory and CPU resources and restart a microservice
    instance or add a new instance when they fall out of a developer-defined range.
    Moreover, they offer the possibility of declaring periodic software checks that
    the orchestrator can perform to verify if the microservice is working properly.
    The most common of such health checks is a call to a **health REST endpoint**
    exposed by the microservice. Again, if the microservice fails a health check,
    it is restarted.
  prefs: []
  type: TYPE_NORMAL
- en: When a hardware node fails a health check, all of its microservices are moved
    to a different hardware node.
  prefs: []
  type: TYPE_NORMAL
- en: Efficacious handling of asynchronous communication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Asynchronous communication with associated asynchronous acknowledgment causes
    three important problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Since after the communication the sending microservice moves to serving other
    requests without waiting for the acknowledgment, it must keep a copy of all messages
    it sent until an acknowledgment or a communication failure, such as a timeout,
    is detected, so that it can retry the operation (with an exponential retry, for
    instance), or it can take another kind of corrective action.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since in case of a timeout a message may be re-sent, the intended recipient
    can receive several copies of the same message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Messages can reach a recipient in an order that is different from the one they
    were sent. For instance, if two messages that instruct the recipient to modify
    the name of a product are sent in the order M1, M2, we expect the final name to
    be the one contained in M2\. However, if the recipient receives the two messages
    in the wrong order, M2, M1, the final product name will be the one contained in
    M1, thus causing an error.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The first problem is handled by keeping all messages in a queue, as shown in
    the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.8: Output message queue](img/B31916_02_8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.8: Output message queue'
  prefs: []
  type: TYPE_NORMAL
- en: When an acknowledgment is received, the involved message is removed from the
    queue. If, on the contrary, a failure or timeout is detected, the message is added
    to the end of the queue to be retried. If a retry must be handled with an exponential
    retry, each queue entry must contain both the number of the current attempt and
    the minimum time when the message can be re-sent.
  prefs: []
  type: TYPE_NORMAL
- en: The second and third problems require that each received message has a unique
    identifier and a sequence number. The unique identifier helps recognize and discard
    duplicates, while the sequence number helps the recipient to reconstruct the right
    message order. The following figure shows a possible implementation.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.9: Input message queue](img/B31916_02_9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.9: Input message queue'
  prefs: []
  type: TYPE_NORMAL
- en: Messages can be read from the input queue only after all sequence holes before
    them have been filled and read, while duplicates are easily recognized and discarded.
  prefs: []
  type: TYPE_NORMAL
- en: Event-based communications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose we add a new microservice to the car-sharing application in *Figure
    2.7*, say, a worker microservice that computes statistics about user trips. We
    would be forced to modify all microservices it needs input from, because all these
    microservices must also send some messages to the newly added microservice.
  prefs: []
  type: TYPE_NORMAL
- en: The main constraint of microservices architectures is that modifications to
    a microservice must not propagate to other microservices, but by simply adding
    a new microservice, we have already violated this basic principle.
  prefs: []
  type: TYPE_NORMAL
- en: To overcome this problem, messages that might also interest newly added microservices
    are handled with the **publisher-subscriber** pattern. That is, the sender sends
    the message to a publisher endpoint instead of sending it directly to the final
    recipients. Then, each microservice that is interested in that message simply
    subscribes to this endpoint, so that the subscription endpoint will automatically
    send to it all messages it receives. The following figure shows how the publisher-subscriber
    pattern works.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.10: Publisher-subscriber pattern](img/B31916_02_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10: Publisher-subscriber pattern'
  prefs: []
  type: TYPE_NORMAL
- en: Once a publish endpoint receives a message, it resends it to all subscribers
    that added themselves to its subscriptions queue. This way, if we add a new microservice,
    no modification is required for all message senders since they need just to continue
    sending their messages to the adequate publish endpoints. It is up to the newly
    added microservice to register itself to the proper publish endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: Publish endpoints are handled by applications called message brokers that offer
    this service together with other message-delivering services. Message brokers
    can be deployed themselves as replicable microservices, but they are typically
    offered as standard services by all main cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: Among them, it is worth mentioning **RabbitMQ**, which must be installed as
    a microservice, and **Azure Service Bus**, which is available as a cloud service
    in Azure. We will say more about them throughout the rest of the book, but interested
    readers may find links with more details in the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Interfacing the external world
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microservices applications are usually confined to a private network and expose
    their services through public or private IP addresses by means of gateways, load
    balancers, and web servers. These components may route external addresses to internal
    microservices. However, it is hard to leave to the user client-application the
    choice of the microservice to send each of their requests to.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, input requests are all handled by a unique endpoint called an **API
    gateway** that analyzes them and translates the request to an appropriate request
    for internal microservices. This way, the user client application doesn’t need
    any knowledge of how the microservices application is organized internally. Therefore,
    we are free to change the application organization during its maintenance without
    affecting the clients that use it, since the needed translations are performed
    by the application API gateway. This process is known as **web API interface translation**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure summarizes the API gateway operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.11: API gateway](img/B31916_02_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11: API gateway'
  prefs: []
  type: TYPE_NORMAL
- en: API gateways can also handle application versioning by sending all requests
    to the microservices that belong to the version required by the client application.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, they typically also handle authentication tokens; that is, they have
    the keys to decode them and to verify all user information they contain, such
    as user ID and its access privileges.
  prefs: []
  type: TYPE_NORMAL
- en: Please do not confuse authentication with login. Login is performed once per
    session when the user starts interacting with the application, and it is performed
    by a dedicated microservice. The result of a successful login is an authentication
    token that encodes information about the user and that must be included in all
    subsequent requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Summing up, API gateways offer the following services:'
  prefs: []
  type: TYPE_NORMAL
- en: Web API interface translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Versioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authentication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, they often also offer other services, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: API documentation endpoints, that is, endpoints that offer a formal description
    of the services offered by the application and how to request them. In the case
    of REST communication, API documentation is based on the **OpenAPI** standard
    (see *Further reading*).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caching, that is, adding the right HTTP headers to handle appropriate caching
    of all responses in both the user client and the web intermediate nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is worth pointing out that the above services are just common examples of
    the services available in commercial or open-source API gateways that usually
    offer a wide range of services.
  prefs: []
  type: TYPE_NORMAL
- en: API gateways can be implemented as ad hoc microservices using libraries like
    YARP ([https://microsoft.github.io/reverse-proxy/index.html](https://microsoft.github.io/reverse-proxy/index.html)),
    or they can use preexisting configurable applications, for instance, the open-source
    Ocelot ([https://github.com/ThreeMammals/Ocelot](https://github.com/ThreeMammals/Ocelot)).
    All main providers offer powerful configurable API gateways, called **API management
    systems** (for Azure, see [https://azure.microsoft.com/en-us/products/api-management](https://azure.microsoft.com/en-us/products/api-management)).
    However, there are also independent cloud-native offers, like Kong ([https://docs.konghq.com/gateway/latest/](https://docs.konghq.com/gateway/latest/)).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described the basics of microservices, starting from their
    evolution and continuing on to their definition, organization, and main patterns.
  prefs: []
  type: TYPE_NORMAL
- en: We described the main features and requirements of a microservices-based application,
    how its organization resembles more of an assembly line than a user-requests-driven
    application, how to make microservices reliable, and how to handle efficaciously
    both failures and all problems caused by efficient asynchronous communication.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we described how to make all microservices more independent from each
    other with publisher-subscriber-based communication and how to interface a microservices
    application with the external word.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next chapter describes two important building blocks for building enterprise-level
    microservices: Docker and Onion architectures.'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the main difference between a hold-style SOA and a modern microservices
    architecture?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In Microservices architectures are fine-grained. Moreover, each Microservices
    must not depend on the design choices of other Microservices. Furthermore, microservices
    must be redundant, replicable, and resilient.
  prefs: []
  type: TYPE_NORMAL
- en: Why are loosely coupled teams so important?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Because it is quite easy to coordinate loosely coupled teams.
  prefs: []
  type: TYPE_NORMAL
- en: Why must each logical microservice have dedicated storage?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is an immediate consequence of the independence of the design choices of
    a Microservice from the design choices adopted in all other Microservices. In
    fact, sharing a common database would force common design choices on the database
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: Why is data-driven communication needed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is the only way to avoid long chains of recursive request and answers that
    would cause unacceptable overall response times.
  prefs: []
  type: TYPE_NORMAL
- en: Why is event-driven communication so important?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Because event-driven communication completely decouples Microservices, so that
    developers can add a new Microservice without modifying any of the preexisting
    Microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Do API gateways usually offer login services?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: No login services are offered by specific Microservices called Authentication
    Servers.
  prefs: []
  type: TYPE_NORMAL
- en: What is exponential retry?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A retry policy that exponentially increases the delay between failures and retries
    after each failure.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Eric Evans, Domain-Driven Design: [https://www.amazon.com/exec/obidos/ASIN/0321125215/domainlanguag-20](https://www.amazon.com/exec/obidos/ASIN/0321125215/domainlanguag-20
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More resources on DDD can be found here: [https://www.domainlanguage.com/ddd/](https://www.domainlanguage.com/ddd/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A detailed discussion of CQRS design principles can be found here: [https://udidahan.com/2009/12/09/clarified-cqrs/](https://udidahan.com/2009/12/09/clarified-cqrs/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ASP.NET Core REST API: [https://docs.microsoft.com/en-US/aspnet/core/web-api/](https://docs.microsoft.com/en-US/aspnet/core/web-api/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Datadog: [https://docs.datadoghq.com/service_catalog/](https://docs.datadoghq.com/service_catalog/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Backstage: [https://backstage.io/docs/features/software-catalog/](https://backstage.io/docs/features/software-catalog/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenAPI (REST API specifications): [https://swagger.io/docs/specification/v3_0/about/](https://swagger.io/docs/specification/v3_0/about/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Postman: [https://www.postman.com/](https://www.postman.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'gRPC: [https://grpc.io/](https://grpc.io/ )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RabbitMQ: [https://www.rabbitmq.com/](https://www.rabbitmq.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Azure Service Bus: [https://azure.microsoft.com/en-us/products/service-bus/](https://azure.microsoft.com/en-us/products/service-bus/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ocelot: [https://github.com/ThreeMammals/Ocelot](https://github.com/ThreeMammals/Ocelot)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'YARP: [https://microsoft.github.io/reverse-proxy/index.html](https://microsoft.github.io/reverse-proxy/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kong: [https://docs.konghq.com/gateway/latest/](https://docs.konghq.com/gateway/latest/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Azure API Management: [https://azure.microsoft.com/en-us/products/api-management](https://azure.microsoft.com/en-us/products/api-management)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/PSMCSharp](Chapter_2.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '![A qr code with black squares  AI-generated content may be incorrect.](img/B31916_Discord-QR-Code.png)'
  prefs: []
  type: TYPE_IMG
