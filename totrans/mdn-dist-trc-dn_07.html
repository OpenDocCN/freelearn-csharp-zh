<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-116"><a id="_idTextAnchor115"/>7</h1>
<h1 id="_idParaDest-117"><a id="_idTextAnchor116"/>Adding Custom Metrics</h1>
<p>In the previous chapter, we looked into manual distributed tracing instrumentation, which should help us debug individual operations or analyze service usage with ad hoc queries. Here, we’ll talk about metrics. First, we’ll learn when to use them, understand cardinality requirements, and then see how traces and metrics complement each other. We’ll explore the metrics API’s evolution in .NET and then spend most of this chapter talking about OpenTelemetry metrics. We’ll cover <strong class="bold">instruments</strong> such as counters, gauges, and histograms, and learn about each of them in depth.</p>
<p>We will cover the following topics in the chapter:</p>
<ul>
<li>The benefits, limitations, and evolution of metrics in .NET</li>
<li>How and when to use different counters</li>
<li>How to record and use gauges</li>
<li>How to record value distribution with histograms</li>
</ul>
<p>By the end of this chapter, you should be able to pick the right instrument for each scenario and implement and use it in your applications to analyze performance, health, and usage.</p>
<h1 id="_idParaDest-118"><a id="_idTextAnchor117"/>Technical requirements</h1>
<p>The code for this chapter is available in this book’s repository on GitHub at <a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter7">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter7</a>.</p>
<p>To run the samples and perform analysis, we’ll need the following tools:</p>
<ul>
<li>.NET SDK 7.0 or later</li>
<li>Docker and <code>docker-compose</code></li>
</ul>
<h1 id="_idParaDest-119"><a id="_idTextAnchor118"/>Metrics in .NET – past and present</h1>
<p>Even though we <a id="_idIndexMarker405"/>are focusing on distributed tracing in this book, learning about metrics is important to understand when and how to use them to improve observability.</p>
<p>Metrics allow us to report data that’s been aggregated over a certain period and set of attributes (that is, dimensions or tags). A metric can be represented as a set of time series where each series measures the change of one indicator with a unique combination of attribute values over time. Examples include CPU utilization for a given service instance or HTTP request latency for a given route, HTTP method, response code, and instance.</p>
<p>The key difference between traces and metrics is aggregation – traces capture individual operations with detailed attributes. Traces answer questions such as “<em class="italic">What happened with this specific request?</em>” and “<em class="italic">Why did it happen?</em>” Metrics, on the other hand, tell us what happens in the system or specific parts of it, how common a failure is, how widespread the performance issue is, and so on.</p>
<p>Before diving into the use cases, benefits, and APIs of metrics, we first need to learn about the main limitation of metrics – low <strong class="bold">cardinality</strong>.</p>
<h2 id="_idParaDest-120"><a id="_idTextAnchor119"/>Cardinality</h2>
<p>Cardinality<a id="_idIndexMarker406"/> represents number of combinations of unique attributes <a id="_idIndexMarker407"/>or number of time series. Adding a new attribute causes a combinatorial explosion of a time-series number, which leads to the combinatorial growth of a metric’s volume.</p>
<p class="callout-heading">Note</p>
<p class="callout">Metrics should have low cardinality, but “low” and “high” are relative – their definition depends on the budget, backend limits, and local memory consumption.</p>
<p>For example, a relatively big Prometheus instance can support millions of active time series. If we have 1,000 instances of a service running, and the service exposes four HTTP routes with three methods each and returns five different status codes, we’re going to report 1,000 (instances) * 4 (routes) * 3 (methods) * 5 (status codes) = 60K time series of an HTTP server’s request duration metric (at worst). If we try to include something such as the <code>customer_id</code> attribute and have 1,000 active customers, we’ll start reporting 60M time series for the HTTP server request duration metric only.</p>
<p>We can still do this by scaling Prometheus horizontally, so reporting a few high-cardinality attributes is still feasible when justified.</p>
<p class="callout-heading">Note</p>
<p class="callout">Metrics are aggregated in memory before they are exported, so metrics with high cardinality may affect application performance.</p>
<p>There are no<a id="_idIndexMarker408"/> limits in terms of attribute cardinality in .NET, but the <a id="_idIndexMarker409"/>OpenTelemetry SDK has configurable limits on the maximum number of metrics and the number of attribute combinations per metric.</p>
<h2 id="_idParaDest-121"><a id="_idTextAnchor120"/>When to use metrics</h2>
<p>Resource <a id="_idIndexMarker410"/>consumption, low-level communication details, or the number of open connections are best represented by metrics. In other cases, we have a choice and can report telemetry as metrics, spans, or events. For example, if we want to measure number of incoming HTTP requests by route, we can query spans that are filtered by service, route, and timestamp. Should we also report metrics for it? Let’s see.</p>
<p>Metrics are implemented and optimized under the assumption of low cardinality, which enables several important <a id="_idIndexMarker411"/>benefits:</p>
<ul>
<li><strong class="bold">Predictable costs and limited resource consumption</strong>: The metrics’ volume does not grow much as load increases – we only get a new set of time series when the service scales up adding new instances.</li>
<li><strong class="bold">Low performance impact</strong>: Reporting a single measurement can be done without allocating memory.</li>
<li><strong class="bold">Unbiased usage and performance data</strong>: Metrics are recorded regardless of sampling decisions. Metrics don’t always report exact data, but we can control their precision by configuring collection intervals and histogram boundaries.</li>
<li><strong class="bold">Fast and cheap(er) queries</strong>: While observability backends store metrics in different ways and their pricing options vary, metrics are much more compact, which usually <a id="_idIndexMarker412"/>leads to faster ingestion and cheaper queries.</li>
</ul>
<p>Metrics work best when we use them to monitor service health and usage regularly.</p>
<p>When you want to instrument some operation and are in doubt about which signal to use, the following strategy can help: if you need unbiased data or want to create an alert or a chart on a dashboard, use metrics. Otherwise, start with tracing and ad hoc queries. If you find yourself running a lot of similar queries over traces, then add a metric to optimize such queries.</p>
<p>Assuming your tracing backend does not support rich queries, you probably want to be more proactive <a id="_idIndexMarker413"/>in adding metrics. And if your backend is optimized for high-cardinality data and ad hoc analysis, you might not need metrics much.</p>
<p>Now that we have a rough idea of when we need metrics, let’s dive into instrumentation.</p>
<h2 id="_idParaDest-122"><a id="_idTextAnchor121"/>Reporting metrics</h2>
<p>There are a few<a id="_idIndexMarker414"/> different metrics (and counters) APIs in .NET – let’s take a look at them and learn when to use them.</p>
<h3>Performance counters</h3>
<p>The <code>System.Diagnostics.PerformanceCounter</code> class and its friends implement <a id="_idIndexMarker415"/>Windows performance counters. They don’t support dimensions. These limitations make performance counters an unlikely choice for a modern distributed system monitoring story.</p>
<h3>Event counters</h3>
<p><code>System.Diagnostics.Tracing.EventCounter</code> is a cross-platform implementation <a id="_idIndexMarker416"/>of a counter, which represents a single time series – we saw it in action in <a href="B19423_02.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Native Monitoring in .NET</em>, and <a href="B19423_04.xhtml#_idTextAnchor068"><em class="italic">Chapter 4</em></a>, <em class="italic">Low-Level Performance Analysis with Diagnostic Tools</em>, where we collected counters coming from .NET with <code>dotnet-counters</code> and <code>dotnet-monitor</code>. OpenTelemetry can listen to them too, converting them into OpenTelemetry metrics and enriching them with resource attributes.</p>
<p>If you want to report a metric that does not need any dimensions except static context and want to be able to dynamically turn this metric on and off using diagnostics tools, event counters would be a good choice.</p>
<p>We’re not<a id="_idIndexMarker417"/> going to dive into the <code>EventCounter</code> API, so please refer to the .NET documentation (<a href="https://learn.microsoft.com/dotnet/core/diagnostics/event-counters">https://learn.microsoft.com/dotnet/core/diagnostics/event-counters</a>) to find out more.</p>
<h3>OpenTelemetry metrics</h3>
<p>The APIs we’re <a id="_idIndexMarker418"/>going to focus on are available in the <code>System.Diagnostics.Metrics</code> namespace in the <code>System.Diagnostics.DiagnosticSource</code> NuGet package. These APIs follow OpenTelemetry’s metrics specification and terminology, except the term “tags” is used instead of “attributes.” There is no shim for metrics.</p>
<p>The metrics API supports recording multi-dimensional data using the following instruments:</p>
<ul>
<li><strong class="bold">Counter</strong>: Represents a value that increments over time – for example, the number of open connections</li>
<li><strong class="bold">UpDownCounter</strong>: Represents an additive value that increments or decrements over time – for example, the number of active connections</li>
<li><strong class="bold">Gauge</strong>: Represents a current value – for example, the sequence number of the last message received from the messaging queue</li>
<li><strong class="bold">Histogram</strong>: Represents a distribution of value – for example, HTTP request latency</li>
</ul>
<p>Instruments can be created with the <code>Meter</code> class. So, first, we need an instance of <code>Meter</code>, which we can create using a name and optional instrumentation version: <code>Meter meter = </code><code>new ("sample")</code>.</p>
<p>The name of <code>Meter</code> can match the application name, namespace, class, or anything else that makes sense in your case. It’s used to enable metrics, as shown in the following example:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Program.cs</p>
<pre class="source-code">
using var meterProvider = Sdk.CreateMeterProviderBuilder()
<strong class="bold">  .AddMeter("queue.*")</strong>
  .AddOtlpExporter()
  .Build()!;</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Program.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Program.cs</a></p>
<p>Here, we enabled all metrics coming from any <code>Meter</code> whose name starts with <code>queue.</code> (we can use an exact match or wildcards).</p>
<p><code>Meter</code> is disposable. In some cases, when you use the same <code>Meter</code> instance for the application’s<a id="_idIndexMarker419"/> lifetime, you can make <code>Meter</code> instances static; otherwise, make sure to dispose of them to disable all nested instruments.</p>
<p class="callout-heading">Note</p>
<p class="callout">We can listen to metrics directly, without OpenTelemetry, using the <code>System.Diagnostics.Metrics.MeterListener</code> class. It can subscribe to specific instruments and record their measurements. <code>MeterListener</code> is used by OpenTelemetry, so you might find it useful to debug instrumentation.</p>
<p>Now that we have a <code>Meter</code> instance and configured OpenTelemetry to export metrics, we can create instruments using factory methods on the <code>Meter</code> class; for example, <code>meter.CreateCounter&lt;long&gt;("connections.open")</code>.</p>
<p>We’ll see how to create instruments later in this chapter, but for now, here’s a list of common instrument properties:</p>
<ul>
<li><code>byte</code>, <code>short</code>, <code>int</code>, <code>long</code>, <code>float</code>, <code>double</code>, or <code>decimal</code>).</li>
<li><strong class="bold">The instrument name</strong> represents a unique exported metric name; it’s a required property. OpenTelemetry limits the instrument name to 63 characters and has other limitations. We’ll talk about it more in <a href="B19423_09.xhtml#_idTextAnchor148"><em class="italic">Chapter 9</em></a>, <em class="italic">Best Practices</em>.</li>
<li><strong class="bold">A unit</strong> represents an optional value unit following Unified Code for Units and Measure (<a href="https://unitsofmeasure.org/">https://unitsofmeasure.org/</a>).</li>
<li><strong class="bold">The description</strong> is an optional free-form piece of text that briefly describes the instrument.</li>
</ul>
<p>We can create multiple instances of instruments with the same name in the process – the OpenTelemetry SDK aggregates data coming from them into one value. Instruments are de facto identified by their name, unit, and combination of resource attributes. So, measurements from multiple instrument instances that share the same identity are aggregated together. Let’s <a id="_idIndexMarker421"/>explore instruments one by one and learn how to use them, starting with counters.</p>
<h1 id="_idParaDest-123"><a id="_idTextAnchor122"/>Using counters</h1>
<p><strong class="bold">Counter</strong> and <strong class="bold">UpDownCounter</strong> represent <a id="_idIndexMarker422"/>additive values – values that it <a id="_idIndexMarker423"/>makes sense to sum up. For example, the sum of incoming request counts with different HTTP methods makes sense, but the sum of CPU utilization across different cores does not.</p>
<p>On the instrumentation side, the only difference between <strong class="bold">Counter</strong> and <strong class="bold">UpDownCounter</strong> is that the former increases monotonically (or stays the same), while the latter can decrease. For example, the number of open and closed connections should be represented by <strong class="bold">Counter</strong>, while the number of active connections should be represented by <strong class="bold">UpDownCounter</strong>.</p>
<p>Both kinds of counters can be synchronous and asynchronous:</p>
<ul>
<li><strong class="bold">Synchronous</strong> counters report <a id="_idIndexMarker424"/>a delta of value when<a id="_idIndexMarker425"/> change happens. For example, once we successfully initiate a new connection, we can increment counters for both open and active connections. Once we’ve finished terminating a connection, we decrement the number of active connections only.</li>
<li><code>UpDownCounter</code> instrument and increment it when the item is <a id="_idIndexMarker428"/>enqueued and decrement when dequeued or create <code>ObservableUpDownCounter</code> and return the queue’s length in a callback.</li>
</ul>
<p>Let’s instrument in-memory queue processing and learn about each instrument as we go.</p>
<h2 id="_idParaDest-124"><a id="_idTextAnchor123"/>The Counter class</h2>
<p>A<a id="_idIndexMarker429"/> synchronous <a id="_idIndexMarker430"/>counter is implemented in the <code>System.Diagnostics.Metrics.Counter</code> class. We’ll use it to keep track of the number of enqueued items:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Producer.cs</p>
<pre class="source-code">
private static Meter Meter = new("queue.producer");
private static Counter&lt;long&gt; EnqueuedCounter =
  Meter.CreateCounter&lt;long&gt;("queue.enqueued.count",
    "{count}",
    "Number of enqueued work items");</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Producer.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Producer.cs</a></p>
<p>Here, we created an instance of the <code>Meter</code> class called <code>queue.producer</code>. It’s static here because we never need to disable corresponding instruments. Then, we created a static counter called <code>queue.enqueue.count</code> with a <code>long</code> type parameter, with the unit set to <code>{count}</code>.</p>
<p>We also need to increment it every time an item is enqueued. <code>Counter</code> exposes the <code>Add</code> method to record a positive delta; it has several overloads to pass zero or more attributes. In our sample, we have multiple queues and pass queue names:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Producer.cs</p>
<pre class="source-code">
EnqueuedCounter.Add(1,
  new KeyValuePair&lt;string, object?&gt;("queue", _queueName))</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Producer.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Producer.cs</a></p>
<p>Let’s run the sample application with <code>metrics$ docker-compose up --build</code> and open the metrics endpoint on OpenTelemetry Collector at <code>http://localhost:8889/metrics</code>. We should see <code>queue_enqueued_count_total</code> among other metrics in the Prometheus exposition format:</p>
<pre class="source-code">
# HELP queue_enqueued_count_total Number of enqueued work items
# TYPE queue_enqueued_count_total counter
queue_enqueued_count_total{job="metrics ",queue="add"} 323
queue_enqueued_count_total{job="metrics ",queue="remove"} 323</pre>
<p>Here, we <a id="_idIndexMarker431"/>can see <a id="_idIndexMarker432"/>the description, along with the instrument’s type, followed by a list of all attribute combinations and the latest reported counter values.</p>
<p>We can also visualize this counter in Prometheus (at <code>http://localhost:9090</code>). Usually, we are interested in rates or trends, and not the absolute value of a counter. For example, the rate at which items are enqueued would be a good indication of producer load and performance.</p>
<p>We can get this by using the <code>sum by (queue) (rate(queue_enqueued_count_total[1m]))</code> query – Prometheus calculates the rate per second (and averages it over 1 minute), then sums up values by grouping them by queue name across application instances. The corresponding chart is shown in <em class="italic">Figure 7</em><em class="italic">.1</em>:</p>
<div><div><img alt="Figure 7.1 – Enqueue rate per second grouped by queue name" src="img/Figure_7.01_B19423.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Enqueue rate per second grouped by queue name</p>
<p>Here, we can see that we enqueue items at around 16 items per second to each queue. Instead of <code>sum</code>, we could use the <code>min</code> or <code>max</code> operators to see whether there are application instances that stand out.</p>
<p>Counters, along with other instruments, expose an <code>Enabled</code> flag, which indicates whether there are any listeners for this instrument. Meters are not enabled by default and the specific instrument could be disabled, so the <code>Enabled</code> flag should be used to guard any additional work necessary for metric reporting. It’s really important for native instrumentations, where end users of such libraries may or may not have metrics enabled and the <a id="_idIndexMarker433"/>goal is <a id="_idIndexMarker434"/>to have zero performance impact when metrics are disabled.</p>
<p>Other properties that are exposed on the instruments include <code>Name</code>, <code>Unit</code>, <code>Description</code>, and <code>Meter</code>, which we used to create this instrument.</p>
<h2 id="_idParaDest-125"><a id="_idTextAnchor124"/>The UpDownCounter class</h2>
<p>The <code>System.Diagnostics.Metrics.UpDownCounter</code> class is very similar to <code>Counter</code> in<a id="_idIndexMarker435"/> terms <a id="_idIndexMarker436"/>of the API. You can create one with the <code>CreateUpDownCounter</code> method on the <code>Meter</code> instance by providing an instrument name, along with an optional unit and description. The <code>UpDownCounter</code> class exposes an <code>Add</code> method, which takes a delta of the measured value and zero or more tags. It also exposes the <code>Enabled</code> flag and the properties the instrument was created with, such as its name, unit, and description.</p>
<p>On the consumption side, however, <code>UpDownCounter</code> is different. It’s not monotonic and maps<a id="_idIndexMarker437"/> to<a id="_idIndexMarker438"/> the <code>gauge</code> type in Prometheus. We’ll learn more about it in <em class="italic">The ObservableUpDownCounter </em><em class="italic">class</em> section.</p>
<h2 id="_idParaDest-126"><a id="_idTextAnchor125"/>The ObservableCounter class</h2>
<p><code>System.Diagnostics.Metrics.ObservableCounter</code> implements an asynchronous<a id="_idIndexMarker439"/> version of <code>Counter</code>. There is no difference <a id="_idIndexMarker440"/>between synchronous and asynchronous counters on the consumption side. <code>ObservableCounter</code> just provides a more convenient way to record counters in a callback executed periodically.</p>
<p>For example, the number of completed (by the thread pool) tasks (<code>process.runtime.dotnet.thread_pool.completed_items.count</code>) available in the <code>OpenTelemetryInstrumentation.Runtime</code> NuGet package is implemented as <code>ObservableCounter</code>. On every call, it returns the <code>ThreadPool.CompletedWorkItems</code> property.</p>
<p>We can create an observable counter with the <code>CreateObservableCounter</code> method: <code>Meter.CreateObservableCounter&lt;long&gt;("my.counter", GetValue)</code>. Here, in addition to the name, we pass a lambda function – <code>GetValue</code> – which returns the current value of the counter.</p>
<p>It’s executed when metrics are about to be exported. In our application, this happens every 5 seconds, while the default period for the OTLP exporter is 60 seconds. We configured it with the <code>OTEL_METRIC_EXPORT_INTERVAL</code> environment variable, but it’s also possible to set it explicitly with the <code>PeriodicExportingMetricReaderOptions.ExportIntervalMilliseconds</code> property:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">ExplicitConfiguration.cs</p>
<pre class="source-code">
<strong class="bold">AddOtlpExporter((exporterOptions, readerOptions) =&gt;</strong>
<strong class="bold">  readerOptions.PeriodicExportingMetricReaderOptions</strong>
<strong class="bold">    .ExportIntervalMilliseconds = 5000)</strong></pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/ExplicitConfiguration.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/ExplicitConfiguration.cs</a></p>
<p>The <code>ExportIntervalMilliseconds</code> property controls how frequently counter values are collected, so it controls the precision and volume of individual time series.</p>
<p>This configuration does not affect pull-based exporters such as Prometheus, where it’s controlled externally (for example, with the <code>scrape_interval</code> parameter on the Prometheus instance). In our sample application, we have the OTLP exporter, which is push-based and sends metrics to OpenTelemetry Collector. Collector then exposes metrics on the <code>http://localhost:8889/metrics</code> endpoint, where Prometheus scrapes them from.</p>
<p>With <code>ObservableCounter</code>, we can only record data using the callback provided at start time, and there are several overloads of the <code>CreateObservableCounter</code> method that allow us to report the metric’s value, along with its attributes (via the <code>Measurement</code> struct) or <a id="_idIndexMarker441"/>as a <a id="_idIndexMarker442"/>list of <code>Measurement</code> instances.</p>
<p>There are several important things to know about the callback:</p>
<ul>
<li>Unlike the <code>Counter.Add</code> method, it reports an absolute value of the counter.</li>
<li>It should finish in a reasonable amount of time. We can configure the timeout similarly to the export interval with the <code>OTEL_METRIC_EXPORT_TIMEOUT</code> environment variable or the <code>PeriodicExportingMetricReaderOptions.ExportTimeoutMilliseconds</code> property.</li>
<li>The callback should not return multiple measurements for the same set of attributes. The OpenTelemetry SDK’s behavior is not defined for this case.</li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">These requirements are from the OpenTelemetry specification. <code>MeterListener</code> does not enforce any of them.</p>
<p>To unsubscribe from observable counters, we must dispose of the corresponding <code>Meter</code> instance. So, if the counter relies on any instance data and belongs to an object with a limited lifetime, we must create <code>Meter</code> as an instance variable and dispose of it, along with the object it <a id="_idIndexMarker443"/>belongs to. Let’s see an example of <a id="_idIndexMarker444"/>this with <code>ObservableUpDownCounter</code>.</p>
<h2 id="_idParaDest-127"><a id="_idTextAnchor126"/>The ObservableUpDownCounter class</h2>
<p><code>System.Diagnostics.Metrics.ObservableUpDownCounter</code> represents an asynchronous<a id="_idIndexMarker445"/> version of <code>UpDownCounter</code>. Its <a id="_idIndexMarker446"/>creation is similar to <code>ObservableCounter</code>, but its consumption side matches <code>UpDownCounter</code>.</p>
<p>We’ll use it to report queue length – it should give us a good indication of processor throughput and whether it processes items fast enough.</p>
<p>The queue length is not monotonic – it can go up and down, so a regular counter would not work. We could track it as <code>UpDownCounter</code>: we could increment it when enqueueing an item and decrement when dequeuing. But if we use <code>ObservableUpDownCounter</code>, we’ll achieve the same more frugally by only returning the queue length every few seconds.</p>
<p>In a more complicated case of a distributed queue, we might not be able to instrument both the producer and consumer and would need to periodically get the current distributed queue length with a network call to the broker (be careful if you decide to do this in the counter callback).</p>
<p>Let’s implement the queue length counter. First, the <code>Processor</code> class is disposable, so we should assume it can die before the application ends. It’s important to disable all the instruments when this happens – we need to create a <code>Meter</code> as an instance variable and create the counter:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Processor.cs</p>
<pre class="source-code">
_queueNameTag = new KeyValuePair&lt;string, object?&gt;("queue",
   queueName);
_meter = new Meter("queue.processor");
_queueLengthCounter = _meter
  <strong class="bold">.CreateObservableUpDownCounter(</strong>
<strong class="bold">    "queue.length",</strong>
<strong class="bold">    () =&gt; new Measurement&lt;int&gt;(queue.Count, _queueNameTag),</strong>
<strong class="bold">    "{items}",</strong>
<strong class="bold">    "Queue length");</strong></pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs</a></p>
<p>Here, we created an <code>ObservableUpDownCounter</code> instance with a <code>queue.length</code> name and configured it to report the length in a callback, along with the queue name attribute. The last thing we need to do is to dispose of the <code>Meter</code> instance, along with the processor, using the <code>_meter.Dispose()</code> method. That’s it!</p>
<p>Start the sample application (unless it’s still running) with <code>metrics$ docker-compose up --build</code> and <a id="_idIndexMarker447"/>check <a id="_idIndexMarker448"/>out the <code>queue_length</code> metric (at <code>http://localhost:8889/metrics</code>). You should see it, among other metrics:</p>
<pre class="source-code">
# HELP queue_length Queue length
# TYPE queue_length gauge
queue_length{job="metrics",queue="add"} 2
queue_length{job="metrics",queue="remove"} 0
queue_length{job="metrics",queue="update"} 157</pre>
<p>As you can see, <code>UpDownCounter</code> and <code>ObservableUpDownCounter</code> are both mapped to gauge Prometheus – we’ll learn more about gauges in the next section.</p>
<p>We can visualize this metric in the Prometheus UI (at <code>http://localhost:9090</code>) with the <code>avg by (queue) (queue_length)</code> query, as shown in <em class="italic">Figure 7</em><em class="italic">.2</em>:</p>
<div><div><img alt="Figure 7.2 – Average queue length per queue" src="img/Figure_7.02_B19423.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Average queue length per queue</p>
<p>By looking at this chart, we can say that <a id="_idIndexMarker449"/>the <strong class="bold">update</strong> queue grows linearly while the other queues remain almost empty. We don’t need any complicated queries here because we’re <a id="_idIndexMarker450"/>interested in absolute values as we expect<a id="_idIndexMarker451"/> the queue length to always be small.</p>
<p>Let’s learn about other instruments – gauges and histograms – and investigate what happens with the <strong class="bold">update</strong> queue.</p>
<h1 id="_idParaDest-128"><a id="_idTextAnchor127"/>Using an asynchronous gauge</h1>
<p><code>System.Diagnostics.Metrics.ObservableGauge</code> represents the current value of a <a id="_idIndexMarker452"/>non-additive metric. There is only an asynchronous version of it.</p>
<p>The key difference with <code>ObservableUpdownCounter</code> is that the counter is additive. For example, with counters, if we have multiple metric points for the same counter name, at the same timestamp, and with the same attributes, we can just add them up. For gauge, aggregation makes no sense and OpenTelemetry uses the last reported value.</p>
<p>When exported to Prometheus, <code>ObservableGauge</code> and <code>ObservableUpdownCounter</code> are the same, but their OTLP definitions (over-the-wire formats) are different.</p>
<p class="callout-heading">Tip</p>
<p class="callout">You can get an idea of the internal representation of metric points on the OpenTelemetry side by enabling the <code>ConsoleExporter</code> output or looking into the OpenTelemetry documentation at <a href="https://opentelemetry.io/docs/reference/specification/overview/#metrics-data-model-and-sdk">https://opentelemetry.io/docs/reference/specification/overview/#metrics-data-model-and-sdk</a>.</p>
<p>We use <code>ObservableGauge</code> to report a sequence number for the last processed item. It’s useful with distributed queues, where the sequence number (or offset) represents the unique and ordered position of the item in the queue.</p>
<p>By looking at sequence number trends, we can estimate how many items are processed and how fast they are processed. For example, if the processor is stuck trying to process an invalid work <a id="_idIndexMarker453"/>item, we’d see that the sequence number is not increasing.</p>
<p>Adding up sequence numbers from different queues make no sense, so it should be an <code>ObservableGauge</code>, which we can create using a familiar API:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Processor.cs</p>
<pre class="source-code">
_sequenceNumberGauge = _meter
  .CreateObservableGauge(
    "processor.last_sequence_number",
    () =&gt; new Measurement&lt;long&gt;(_seqNo, _queueNameTag),
    null,
    "Sequence number of the last dequeued item");</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs</a></p>
<p>In the callback, we return the <code>_seqNo</code> instance variable, which we update after dequeuing the work item. The only thing we need here is thread safety; we don’t need precision since data is collected periodically.</p>
<p>We can report values with zero or more attributes or multiple measurements at once, so long as they have different attributes.</p>
<p>If we run the sample application with <code>metrics$ docker-compose up --build</code>, we can check the sequence number in Prometheus with a query such as <code>delta(processor_last_sequence_number[1m])</code>. It returns the delta per minute and is <a id="_idIndexMarker454"/>shown in <em class="italic">Figure 7</em><em class="italic">.3</em>:</p>
<div><div><img alt="Figure 7.3 – Sequence number delta per minute" src="img/Figure_7.03_B19423.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Sequence number delta per minute</p>
<p>As we can see, after the application starts, the delta stabilizes around 3,000 items per minute <a id="_idIndexMarker455"/>in the <code>queue_length</code> counter – the <strong class="bold">update</strong> queue is not processed fast enough. By looking at metrics, we can’t say why, but there is one that can cast some light on it – the processing duration. Let’s take a look at it.</p>
<h1 id="_idParaDest-129"><a id="_idTextAnchor128"/>Using histograms</h1>
<p><code>System.Diagnostics.Metrics.Histogram</code> represents a distribution of values – for example, the operation <a id="_idIndexMarker457"/>duration or payload size. Histograms can only be reported synchronously as each measurement is important. As we saw in <a href="B19423_02.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Native Monitoring in .NET</em>, they allow us to calculate percentiles at query time.</p>
<p>We’ll use a histogram to record the processing duration in our example:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Processor.cs</p>
<pre class="source-code">
_processingDurationHistogram = _meter
  .CreateHistogram&lt;double&gt;(
    "processor.processing.duration",
    "ms",
    "Item processing duration");</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs</a></p>
<p>Every time we process an item from the queue, we should measure and record the time it took:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Processor.cs</p>
<pre class="source-code">
Stopwatch? duration = _processingDurationHistogram
  .Enabled ? Stopwatch.StartNew() : null;
var status = await Process(item);
if (duration != null)
  _processingDurationHistogram.Record(
    duration.Elapsed.TotalMilliseconds,
    _queueNameTag,
    new KeyValuePair&lt;string, object?&gt;("status",
      StatusToString(status)));</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter7/metrics/Processor.cs</a></p>
<p>Here, we are using the <code>Enabled</code> flag – when metrics are not enabled, it prevents us from allocating a <code>Stopwatch</code> object on the heap.</p>
<p>The recording method has multiple overloads to report zero or more attributes associated with this value. Here, we report the queue name and the processing status. The status has low cardinality – it’s an <code>enum</code> with a few values.</p>
<p>We also want to stay as efficient as possible, so we implemented the optimal and non-allocating <code>StatusToString</code> method.</p>
<p>Let’s run the application with <code>metrics$ docker-compose up --build</code> and check out how the histogram looks in Prometheus exposition format (at <code>http://localhost:8889/metrics</code>). You should see a set of <code>processor_processing_duration_milliseconds_bucket</code> points for each queue, status, and bucket.</p>
<p>For example, this is <a id="_idIndexMarker458"/>what I see for the <code>Ok</code> (attributes and some buckets have been omitted for brevity):</p>
<pre class="source-code">
processor_processing_duration_milliseconds_bucket{le="0"} 0
...
processor_processing_duration_milliseconds_bucket{le="50"} 27
processor_processing_duration_milliseconds_bucket{le="75"} 52
processor_processing_duration_milliseconds_bucket{le="100"} 67
processor_processing_duration_milliseconds_bucket{le="250"} 72
...
processor_processing_duration_milliseconds_bucket{le="+Inf"} 72
processor_processing_duration_milliseconds_sum
  4145.833300000001
processor_processing_duration_milliseconds_count 72</pre>
<p>Each bucket is identified by a <code>le</code> attribute – the inclusive upper boundary. There were 27 measurements smaller than or equal to 50 milliseconds, 52 measurements that were smaller than 75 milliseconds, and so on. Overall, there were 72 measurements, and the sum of all durations was around 4,146 milliseconds.</p>
<p>OTLP format defines a few more interesting properties that we can’t see here:</p>
<ul>
<li>The <code>min</code> and <code>max</code> values for each bucket – they are not supported by Prometheus but show<a id="_idIndexMarker459"/> up in OTLP data.</li>
<li><strong class="bold">Exemplars</strong>, which represent examples of traces in a bucket. We could use them to easily navigate from metrics to traces and investigate long processing operations in higher histogram buckets. They are not implemented in OpenTelemetry for .NET yet.</li>
</ul>
<p>The bucket boundaries we can see here are the default ones. They are static and work best if the measured value is well within the [0, 10000] range. If we start to measure values in the [10,000, 20,000] range, every measurement would be in the last two buckets, making the percentile calculation invalid. In this case, we should set explicit boundaries for<a id="_idIndexMarker460"/> corresponding histograms with the <code>MeterProviderBuilder.AddView</code> method.</p>
<p>In the future, OpenTelemetry will allow us to use exponential histograms with dynamic boundaries adjusted to data.</p>
<p>Note that we also have the <code>processor_processing_duration_milliseconds_sum</code> and <code>processor_processing_duration_milliseconds_count</code> metrics, so by reporting only the histogram, we get percentiles, averages, and measurement counters.</p>
<p>We can get the median processing time with the following query:</p>
<pre class="source-code">
histogram_quantile(0.5, sum(rate(processor_processing_duration_milliseconds_bucket{status="Ok"}[1m])) by (le, queue))</pre>
<p>This should produce the chart shown in <em class="italic">Figure 7</em><em class="italic">.4</em>:</p>
<div><div><img alt="Figure 7.4 – Median processing time per queue" src="img/Figure_7.04_B19423.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – Median processing time per queue</p>
<p>Here, we can see <a id="_idIndexMarker461"/>that the median processing time for the <strong class="bold">add</strong> queue is around 61 milliseconds, 48 milliseconds for the <strong class="bold">remove</strong> queue, and 75 milliseconds for the <strong class="bold">update</strong> queue.</p>
<p>Let’s also check the processing rate using the <code>sum by (queue) (rate(processor_processing_duration_milliseconds_count[1m]))</code> query, as shown in <em class="italic">Figure 7</em><em class="italic">.5</em>:</p>
<div><div><img alt="Figure 7.5 – Processing rate per queue" src="img/Figure_7.05_B19423.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.5 – Processing rate per queue</p>
<p>Items from the <strong class="bold">update</strong> queue are processed at a rate of about 14 items per second; the enqueue rate is ~16 items per second, as we saw in <em class="italic">Figure 7</em><em class="italic">.1</em>. This should explain why the <strong class="bold">update</strong> queue <a id="_idIndexMarker462"/>is growing:</p>
<ul>
<li>Processing takes too much time – we should try to optimize it so that it targets at least 60 milliseconds to be able to process 16 items per second.</li>
<li>If optimization is not possible (or is not enough), we know that we need to process an extra 2-3 items per second, so we need ~20% more processor instances.</li>
<li>We could also implement backpressure on the producer side and throttle <strong class="bold">update</strong> requests to decrease the enqueue rate on the processor.</li>
</ul>
<p>With just a small set of metrics, we were able to narrow down the problem to a specific area. If it was a<a id="_idIndexMarker463"/> production incident, we’d be able to quickly mitigate it by scaling the number of processors up and then investigating other options.</p>
<h1 id="_idParaDest-130"><a id="_idTextAnchor129"/>Summary</h1>
<p>In this chapter, we explored metrics in .NET and OpenTelemetry.</p>
<p>Metrics allow us to collect aggregated multi-dimensional data. They produce unbiased telemetry with a predictable volume at any scale and allow us to monitor system health, performance, and usage.</p>
<p>Metrics can’t have high-cardinality attributes, so we can’t use them to detect problems that happen in specific and narrow cases – for this, we need distributed tracing or events. .NET provides an OpenTelemetry metrics implementation that consists of the <code>Meter</code> class, which can create specific instruments: counters, gauges, and histograms.</p>
<p>Counters are used to report additive values and can be synchronous or asynchronous. Gauges report current, non-additive values asynchronously, while histograms report value distribution.</p>
<p>With this, you should be able to identify scenarios where metrics are beneficial, choose appropriate instruments, and efficiently report metrics in your application. You should also be able to configure OpenTelemetry, and, most importantly, start detecting and monitoring performance issues.</p>
<p>In the next chapter, we’re going to look at structured logs and events and learn how to write and consume them efficiently using .NET and OpenTelemetry.</p>
<h1 id="_idParaDest-131"><a id="_idTextAnchor130"/>Questions</h1>
<ol>
<li>Let’s say you want to track the number of meme downloads (from our meme sample applications). Which telemetry signals would you choose? Why?</li>
<li>When reporting HTTP request duration, would you report it as a span, metric, or both?</li>
<li>How would you monitor the number of active application instances and the uptime?</li>
</ol>
</div>
</body></html>