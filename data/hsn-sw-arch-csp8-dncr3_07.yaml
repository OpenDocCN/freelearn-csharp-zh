- en: Applying a Microservice Architecture to Your Enterprise Application
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将微服务架构应用于您的企业应用程序
- en: This chapter is dedicated to describing highly scalable architectures based
    on small modules called microservices. The microservices architecture allows for
    fine-grained scaling operations where every single module can be scaled as required
    without it affecting the remainder of the system. Moreover, they allow for better
    **Continuous Integration/Continuous Deployment** (**CI/CD**) by permitting every
    system subpart to evolve and be deployed independently of the others.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章致力于描述基于称为微服务的小模块的高度可扩展架构。微服务架构允许进行细粒度的扩展操作，其中每个单独的模块都可以按需扩展，而不会影响系统的其余部分。此外，它们通过允许每个系统子部分独立于其他部分进行演变和部署，从而允许更好的**持续集成/持续部署**（**CI/CD**）。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: What are microservices?
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是微服务？
- en: When do microservices help?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务何时有帮助？
- en: How does .NET Core deal with microservices?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: .NET Core 如何处理微服务？
- en: Which tools are needed to manage microservices?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理微服务需要哪些工具？
- en: Use case – logging a microservice
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用例 - 记录微服务
- en: By the end of this chapter, you will have learned how to implement a microservice
    in .NET Core based on this chapter's use case.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将学会如何根据本章的使用案例在 .NET Core 中实现一个微服务。
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will require the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你需要以下内容：
- en: Visual Studio 2017 or 2019 free Community Edition or better with all the database
    tools installed.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Visual Studio 2017 或 2019 的免费社区版或更高版本，并安装了所有数据库工具。
- en: A free Azure account. The *Creating an Azure account* section in [Chapter 1](14b5c5da-4042-439e-9e5a-2e19ba4c4930.xhtml),
    *Understanding the Importance of Software Architecture*, explains how to create
    one.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个免费的 Azure 账户。在[第 1 章](14b5c5da-4042-439e-9e5a-2e19ba4c4930.xhtml)的“*创建 Azure
    账户*”部分，*理解软件架构的重要性*，解释了如何创建一个账户。
- en: 'A local emulator for Azure Service Fabric to debug your microservices in Visual
    Studio. It is free and can be downloaded from [https://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&appid=MicrosoftAzure-ServiceFabric-CoreSDK](https://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&appid=MicrosoftAzure-ServiceFabric-CoreSDK).
    To avoid installation issues, ensure your version of Windows is up to date. Moreover,
    the emulator uses PowerShell high-privilege-level commands that, by default, are
    blocked by PowerShell. To enable them, you need to execute the following command
    in the Visual Studio Package Manager Console or in any PowerShell console. Visual
    Studio or an external PowerShell console must be started as an *administrator*
    for the following command to be successful:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于在 Visual Studio 中调试微服务的 Azure Service Fabric 本地模拟器。它是免费的，可以从[https://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&appid=MicrosoftAzure-ServiceFabric-CoreSDK](https://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&appid=MicrosoftAzure-ServiceFabric-CoreSDK)下载。为了避免安装问题，请确保您的
    Windows 版本是最新的。此外，模拟器使用 PowerShell 高权限级别命令，默认情况下，这些命令被 PowerShell 块。要启用它们，您需要在
    Visual Studio 包管理器控制台或任何 PowerShell 控制台中执行以下命令。Visual Studio 或外部 PowerShell 控制台必须以
    *管理员* 身份启动，以下命令才能成功：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Docker CE for Windows if you want to debug Docker containerized microservices
    in Visual Studio ([https://store.docker.com/editions/community/docker-ce-desktop-windows?tab=description](https://store.docker.com/editions/community/docker-ce-desktop-windows?tab=description)).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想在 Visual Studio 中调试 Docker 容器化的微服务，请使用 Docker CE for Windows ([https://store.docker.com/editions/community/docker-ce-desktop-windows?tab=description](https://store.docker.com/editions/community/docker-ce-desktop-windows?tab=description))。
- en: What are microservices?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是微服务？
- en: Microservice architectures allow each module that makes up a solution to be
    scaled independently from the others to achieve the maximum throughput with minimal
    cost. In fact, scaling whole systems instead of their current bottlenecks inevitably
    results in a remarkable waste of resources, so a fine-grained control of subsystem
    scaling has a considerable impact on the system's overall cost.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构允许每个构成解决方案的模块独立于其他模块进行扩展，以实现最大吞吐量并最小化成本。实际上，扩展整个系统而不是其当前的瓶颈不可避免地会导致资源的巨大浪费，因此对子系统扩展的精细控制对系统的整体成本有重大影响。
- en: However, microservices are more than scalable components – they are software
    building blocks that can be developed, maintained, and deployed independently
    of each other. Splitting development and maintenance among modules that can be
    independently developed, maintained, and deployed improves the overall system's
    CI/CD cycle (the *CI/CD* concept was explained in more detail in the *Organizing
    your work using Azure DevOps* section in [Chapter 3](bc26065f-b001-4123-9524-3bbfa87bfadd.xhtml),
    *Documenting Requirements with Azure DevOps*).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，微服务不仅仅是可扩展的组件——它们是可以在彼此独立开发、维护和部署的软件构建块。将开发和维护分散到可以独立开发、维护和部署的模块中，可以改善整个系统的
    CI/CD 循环（*CI/CD* 概念在[第 3 章](bc26065f-b001-4123-9524-3bbfa87bfadd.xhtml)的*使用 Azure
    DevOps 组织工作*部分中进行了更详细的解释，*使用 Azure DevOps 记录需求*）。
- en: 'The CI/CD improvement is due to microservice *independence* because it enables
    the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD 的改进归功于微服务的**独立性**，因为它使得以下成为可能：
- en: Scaling and distributing microservices on different types of hardware.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同类型的硬件上扩展和分发微服务。
- en: Since each microservice is deployed independently from the others, there can't
    be binary compatibility or database structure compatibility constraints. Therefore,
    there is no need to align the versions of the different microservices that compose
    the system. This means that each of them can evolve, as needed, without being
    constrained by the others.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于每个微服务都是独立于其他微服务部署的，因此不存在二进制兼容性或数据库结构兼容性约束。因此，没有必要对组成系统的不同微服务的版本进行对齐。这意味着它们中的每一个都可以根据需要独立演进，而不会受到其他微服务的限制。
- en: Assigning their development to completely separate smaller teams, thus simplifying
    job organization and reducing all the inevitable coordination inefficiencies that
    arise when handling large teams.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其开发分配给完全独立的较小团队，从而简化工作组织并减少处理大型团队时产生的所有不可避免的协调低效率。
- en: Implementing each microservice with more adequate technologies and in a more
    adequate environment, since each microservice is an independent deployment unit.
    This means choosing tools that best fit your requirements and an environment that
    minimizes development efforts and/or maximizes performance.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用更合适的技术和更合适的环境来实现每个微服务，因为每个微服务都是一个独立的部署单元。这意味着选择最适合您需求的工具和最小化开发努力/最大化性能的环境。
- en: Since each microservice can be implemented with different technologies, programming
    languages, tools, and operating systems, enterprises can use all available human
    resources by matching environments with developers' competences. For instance,
    underused Java developers can also be involved in .NET projects if they implement
    microservices in Java with the same required behavior.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于每个微服务可以使用不同的技术、编程语言、工具和操作系统来实现，企业可以通过将环境与开发者的技能相匹配来利用所有可用的人力资源。例如，未充分利用的 Java
    开发者也可以参与 .NET 项目，如果他们使用 Java 实现具有相同所需行为的微服务。
- en: Legacy subsystems can be embedded in independent microservices, thus enabling
    them to cooperate with newer subsystems. This way, companies may reduce the time
    to market of new system versions. Moreover, this way, legacy systems can evolve
    slowly toward more modern systems with an acceptable impact on costs and the organization.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 历史子系统可以被嵌入到独立的微服务中，从而使得它们能够与较新的子系统进行协作。这样，公司可以缩短新系统版本的上市时间。此外，通过这种方式，历史系统可以缓慢地向更现代的系统演进，同时对成本和组织的影响是可接受的。
- en: The next subsection explains how the concept of microservices was conceived.
    Then, we will continue this introductory section by exploring basic microservice
    design principles and analyzing why microservices are often designed as Docker
    containers.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个子节将解释微服务概念是如何产生的。然后，我们将继续本介绍性章节，探讨基本微服务设计原则，并分析为什么微服务通常被设计为 Docker 容器。
- en: Microservices and the evolution of the concept of modules
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务与模块概念的演进
- en: 'For a better understanding of the advantages of microservices, as well as their
    design techniques, we must keep the two-folded nature of software modularity,
    and of software modules, in mind:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解微服务的优势以及它们的设计技术，我们必须牢记软件模块化和软件模块的双重特性：
- en: Code modularity refers to a code organization that makes it easy for us to modify
    a chunk of code without it affecting the remainder of the application. It is usually
    enforced with object-oriented design, where *modules* can be identified with classes.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码模块化指的是一种代码组织方式，它使得我们能够轻松地修改代码块，而不会影响到应用程序的其他部分。这通常通过面向对象设计来实现，其中*模块*可以通过类来识别。
- en: Deployment modularity depends on what your deployment units are and which properties
    they have. The simplest deployment units are executable files and libraries. Thus,
    for instance, **dynamic link libraries** (**DLL**) are, for sure, more modular
    than static libraries since they must not be linked with the main executable before
    being deployed.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署模块化取决于你的部署单元及其属性。最简单的部署单元是可执行文件和库。因此，例如，**动态链接库**（**DLL**）肯定比静态库更模块化，因为它们在部署之前不需要与主可执行文件链接。
- en: While the fundamental concepts of code modularity have reached stasis, the concept
    of deployment modularity is still evolving and microservices are currently state
    of the art along this evolution path.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然代码模块化的基本概念已经达到稳定状态，但部署模块化的概念仍在不断发展，微服务目前是这一发展路径上的尖端技术。
- en: As a short review of the main milestones on the path that led to microservices,
    we can say that, first, monolithic executables were broken into static libraries.
    Later on, dynamic link libraries replaced static libraries.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对导致微服务的主要里程碑的简要回顾，我们可以这样说，首先，单体可执行文件被分解为静态库。后来，动态链接库取代了静态库。
- en: A great change took place when .NET (and other analogous frameworks, such as
    Java) improved the modularity of executables and libraries. In fact, with .NET,
    they can be deployed on different hardware and on different operating systems
    since they are deployed in an intermediary language that's compiled when the library
    is executed for the first time. Moreover, they overcome some versioning issues
    of previous DLLs since any executable brings with it a DLL with a version that
    differs from the version of the same DLL that is installed in the operating system.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当.NET（以及其他类似框架，如Java）改进了可执行文件和库的模块化时，发生了巨大的变化。实际上，由于.NET在库首次执行时编译为中间语言，因此它们可以在不同的硬件和不同的操作系统上部署。此外，它们克服了先前DLL的一些版本问题，因为任何可执行文件都附带一个与操作系统中安装的相同DLL版本不同的DLL。
- en: 'However, .NET can''t accept two referenced DLLs – let''s say, A and B – using
    two different versions of a common dependency – let''s say, C. For instance, suppose
    there is a newer version of A with a lot of new features we would like to use
    that, in turn, rely on a newer version of C that''s not supported by B. In a similar
    situation, we should renounce the newer version of A because of the incompatibility
    of C with B. This difficulty has led to two important changes:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，.NET无法接受使用不同版本的共同依赖项的两个引用DLL——比如说，A和B。例如，假设有一个A的新版本，它包含许多我们希望使用的新功能，而这些功能反过来又依赖于B不支持的新版本的C。在类似的情况下，我们应该放弃A的新版本，因为C与B的不兼容性。这种困难导致了两个重要的变化：
- en: The development world moved from DLLs and/or single files to package management
    systems such as NuGet and npm, which automatically check version compatibility
    with the help of *semantic versioning*.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发世界从DLL和/或单个文件转向了包管理系统，如NuGet和npm，这些系统通过*语义版本化*自动检查版本兼容性。
- en: '**Service-Oriented Architecture** (**SOA**). Deployment units started being
    implemented as XML and then as REST web services. This solves the version compatibility
    problem since each web service runs in a different process and can use the most
    adequate version of each library with no risk of causing incompatibilities with
    other web services. Moreover, the interface that''s exposed by each web service
    is platform-agnostic, that is, web services can connect with applications using
    any framework and run on any operating system since web service protocols are
    based on universally accepted standards. SOAs and protocols will be discussed
    in more detail in [Chapter 12](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml), *Applying
    Service-Oriented Architectures with .NET Core*.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**面向服务的架构**（**SOA**）。部署单元开始以XML的形式实现，然后是RESTful Web服务。这解决了版本兼容性问题，因为每个Web服务都在不同的进程中运行，并且可以使用每个库的最合适版本，而不会与其他Web服务造成不兼容的风险。此外，每个Web服务暴露的接口是平台无关的，也就是说，Web服务可以使用任何框架与应用程序连接，并在任何操作系统上运行，因为Web服务协议基于普遍接受的标准。SOA和协议将在第12章中更详细地讨论，*使用.NET
    Core应用面向服务的架构*。'
- en: Microservices are an evolution of SOA and add more features and more constraints
    that improve scalability and the modularity of services to improve the overall
    CI/CD cycle. It's sometimes said that *microservices are SOA done well*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务是SOA的演进，增加了更多特性和约束，这些特性和约束提高了服务的可扩展性和模块化，从而改善了整体的CI/CD周期。有时人们会说，*微服务是做得好的SOA*。
- en: Microservice design principles
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务设计原则
- en: To sums things up, the microservice architecture is an SOA that maximizes independence
    and fine-grained scaling. Now that we've clarified all the advantages of microservice
    independence and fine-grained scaling, as well as the very nature of independence,
    we are in a position to look at microservice design principles.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，微服务架构是一种SOA，它最大化了独立性和细粒度扩展。既然我们已经阐明了微服务独立性和细粒度扩展的所有优势，以及独立的本质，我们现在可以看看微服务设计原则。
- en: 'Let start with principles that arise from the independence constraint:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从独立约束产生的原则开始：
- en: '**Independence of design choices**: The design of each microservice must not
    depend on the design choices that were made in the implementation of other microservices.
    This principle enables the full independence of each microservice CI/CD cycle
    and leaves us with more technological choices on how to implement each microservice.
    This way, we can choose the best available technology to implement each microservice.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设计选择的独立性**：每个微服务的架构设计不能依赖于其他微服务实现中做出的设计选择。这个原则使得每个微服务的CI/CD周期完全独立，并给我们提供了更多关于如何实现每个微服务的科技选择。这样，我们可以选择最佳的技术来实现每个微服务。'
- en: Another consequence of this principle is that different microservices can't
    connect to the same shared storage (database or filesystem) since sharing the
    same storage also means sharing all the design choices that determined the structure
    of the storage subsystem (database table design, database engine, and so on).
    Thus, either a microservice has its own data storage or it has no storage at all
    and communicates with other microservices that take care of handling storage.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个原则的另一个后果是，不同的微服务不能连接到同一个共享存储（数据库或文件系统），因为共享相同的存储也意味着共享所有决定了存储子系统结构（数据库表设计、数据库引擎等）的设计选择。因此，要么微服务有自己的数据存储，要么它根本不存储任何数据，并与负责处理存储的其他微服务进行通信。
- en: Here, having dedicated data storage doesn't mean that the physical database
    is distributed within the process boundary of the microservice itself, but that
    the microservice has exclusive access to a database or set of database tables
    that are handled by an external database engine. In fact, for performance reasons,
    database engines must run on dedicated hardware and with OS and hardware features
    that are optimized for their storage functionalities. Usually, *independence of
    design choices* is interpreted in a lighter form by distinguishing between logical
    and physical microservices. More specifically, a logical microservice is implemented
    with several physical microservices that use the same data storage but that are
    load-balanced independently. That is, the logical microservice is designed as
    a logical unity and then split into more physical microservices to achieve better
    load balance.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，拥有专用数据存储并不意味着物理数据库分布在微服务自身的进程边界内，而是微服务可以独占访问由外部数据库引擎处理的数据库或数据库表集。实际上，出于性能原因，数据库引擎必须在专用硬件上运行，并使用针对其存储功能进行优化的操作系统和硬件功能。通常，*设计选择的独立性*通过区分逻辑微服务和物理微服务来以更轻的形式解释。更具体地说，逻辑微服务通过使用相同数据存储但独立负载均衡的多个物理微服务来实现。也就是说，逻辑微服务被设计为一个逻辑统一体，然后拆分为更多的物理微服务以实现更好的负载均衡。
- en: '**Independence from the deployment environment**: Microservices are scaled
    out on different hardware nodes and different microservices can be hosted on the
    same node. Therefore, the less a microservice relies on the services offered by
    the operating system and on other installed software, the more available hardware
    nodes it can be deployed on. More node optimization can also be performed.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**独立于部署环境**：微服务可以在不同的硬件节点上扩展，并且不同的微服务可以托管在同一节点上。因此，微服务对操作系统提供的服务的依赖性越小，对其他已安装软件的依赖性越小，它可以在更多的硬件节点上部署。还可以进行更多的节点优化。'
- en: This is the reason why microservices are usually containerized and use Docker.
    Containers will be discussed in more detail in the *Containers and Docker* subsection
    of this chapter, but basically, containerization is a technique that allows each
    microservice to bring its dependencies with it so that it can run anywhere.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是微服务通常被容器化并使用Docker的原因。容器将在本章的“容器和Docker”小节中更详细地讨论，但基本上，容器化是一种技术，它允许每个微服务携带其依赖项，以便它可以在任何地方运行。
- en: '**Loose coupling**: Each microservice must be loosely coupled with all the
    other microservices. This principle has a two-folded nature. On the one hand,
    this means that, according to object-oriented programming principles, the interface
    that''s exposed by each microservice must not be too specific, but as general
    as possible. However, it also means that communications among microservices must
    be minimized in order to reduce communication costs since microservices don''t
    share the same address space and run on different hardware nodes.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**松散耦合**：每个微服务必须与其他所有微服务松散耦合。这个原则有两个方面。一方面，这意味着根据面向对象编程原则，每个微服务暴露的接口不应过于具体，而应尽可能通用。然而，这也意味着微服务之间的通信必须最小化，以减少通信成本，因为微服务不共享相同的地址空间，并且在不同的硬件节点上运行。'
- en: '**No chained requests/responses**: When a request reaches a microservice, it
    must not cause a recursive chain of nested requests/responses to other microservices
    since a similar chain would result in an unacceptable response time. Chained requests/responses
    can be avoided if the private data models of all the microservices synchronize
    with push notifications each time they change. In other words, as soon as the
    data that''s handled by a microservice changes, those changes are sent to all
    the microservices that may need them to serve their requests. This way, each microservice
    has all the data it needs to serve all its incoming requests in its private data
    storage, with no need to ask other microservices for the data that it lacks.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无链式请求/响应**：当一个请求到达微服务时，它必须不会导致对其他微服务的嵌套请求/响应的递归链，因为类似的链会导致不可接受的响应时间。如果所有微服务的私有数据模型在每次更改时都通过推送通知同步，则可以避免链式请求/响应。换句话说，一旦微服务处理的数据发生变化，这些更改就会发送到所有可能需要它们的微服务，以便它们可以处理请求。这样，每个微服务都可以在其私有数据存储中拥有所有它需要的数据，以处理所有传入的请求，无需请求其他微服务提供它所缺少的数据。'
- en: In conclusion, every microservice must contain all the data it needs to serve
    incoming requests and ensure fast responses. To keep their data models up to date
    and ready for incoming requests, microservices must communicate their data changes
    as soon as they take place. These data changes should be communicated through
    asynchronous messages since synchronous nested messages cause unacceptable performance
    because they block all the threads involved in the call tree until a result is
    returned.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总之，每个微服务都必须包含它为服务传入请求和确保快速响应所需的所有数据。为了保持其数据模型最新并准备好接收传入请求，微服务必须在数据变化发生时立即通知其数据变化。这些数据变化应通过异步消息进行通信，因为同步嵌套消息会导致不可接受的性能，因为它们会阻塞调用树中所有涉及的线程，直到返回结果。
- en: It is worth pointing out that the first constraint we mentioned is substantially
    the Bounded Context principle of domain-driven design, which we will talk about
    in detail in [Chapter 10](2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml), *Understanding
    the Different Domains in Software Solutions*. In this chapter, we will see that,
    often, a full domain-driven design approach is useful for the *update* subsystem
    of each microservice.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，我们提到的第一个约束实质上是领域驱动设计的边界上下文原则，我们将在第10章“理解软件解决方案中的不同领域”中详细讨论。在本章中，我们将看到，通常，完整的领域驱动设计方法对每个微服务的*更新*子系统是有用的。
- en: It's not trivial that the opposite is also true, that is, that systems that
    have been developed according to the Bounded Context principle are better implemented
    with a microservice architecture. In fact, once a system has been decomposed into
    several completely independent and loosely coupled parts, it is very likely that
    these different parts need to be scaled independently because of different traffic
    and different resources requirements.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 反过来也成立，即根据边界上下文原则开发出的系统，用微服务架构实现会更好。事实上，一旦一个系统被分解为几个完全独立且松散耦合的部分，由于不同的流量和不同的资源需求，这些不同的部分很可能需要独立扩展。
- en: The preceding constraints are some best practices for building a reusable SOA.
    More details on these best practices will be given in [Chapter 12](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml),
    *Applying Service-Oriented Architectures with .NET Core*, but nowadays, most SOA
    best practices are automatically enforced by tools and frameworks that are used
    to implement web services.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 前述约束是构建可重用SOA的一些最佳实践。关于这些最佳实践的更多细节将在第12章“使用.NET Core应用服务架构”中给出，但如今，大多数SOA最佳实践都由用于实现Web服务的工具和框架自动执行。
- en: Fine-grained scaling requires that microservices are small enough to isolate
    well-defined functionalities, but this also requires a complex infrastructure
    that takes care of automatically instantiating microservices, allocating instances
    on nodes, and scaling them as needed. These kinds of structure will be discussed
    in the *Which tools are needed to manage Microservices?* section of this chapter.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 精细粒度扩展要求微服务足够小，以便隔离定义良好的功能，但这同时也需要一个复杂的基础设施，该基础设施负责自动实例化微服务、在节点上分配实例以及按需扩展它们。这类结构将在本章的“需要哪些工具来管理微服务？”部分进行讨论。
- en: Moreover, fine-grained scaling of distributed microservices that communicate
    through asynchronous communication requires each microservice to be resilient.
    In fact, communication that's directed to a specific microservice instance may
    fail due to a hardware fault or for the simple reason that the target instance
    was killed or moved to another node during a load balancing operation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过异步通信进行通信的分布式微服务的精细粒度扩展需要每个微服务都具有弹性。实际上，指向特定微服务实例的通信可能会因为硬件故障或简单的理由（例如，在负载均衡操作期间目标实例被杀死或移动到另一个节点）而失败。
- en: Temporary failures can be overcome with exponential retries. This is where we
    retry the same operation after each failure with a delay that increases exponentially
    until a maximum number of attempts is reached. For instance, first, we would retry
    after 10 milliseconds, and if this retried operation results in a failure, a new
    attempt is done after 20 milliseconds, then after 40 milliseconds, and so on.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过指数重试来克服暂时性故障。这就是在每个故障后，我们都会以指数级增加的延迟重试相同的操作，直到达到最大尝试次数。例如，首先，我们会在10毫秒后重试，如果这次重试操作导致失败，则会在20毫秒后进行新的尝试，然后是40毫秒，以此类推。
- en: 'On the other hand, long-term failures often cause an explosion of retry operations
    that may saturate all system resources in a way that is similar to a Denial Of
    Service Attack. Therefore, usually, exponential retries are used together with
    a *circuit break strategy*: after a given number of failures, a long-term failure
    is assumed and access to the resource is prevented for a given time by returning
    an immediate failure without attempting the communication operation.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，长期故障通常会导致重试操作的爆炸性增长，这可能会以类似于拒绝服务攻击的方式耗尽所有系统资源。因此，通常，指数退避与**断路器策略**一起使用：在给定数量的失败之后，假设发生长期故障，并通过返回一个立即失败而不尝试通信操作来防止在给定时间内访问资源。
- en: 'It is also fundamental that the congestion of some subsystems, due to either
    failure or to a requests peak, does not propagate to other system parts, in order
    to prevent overall system congestion. **Bulkhead isolation** avoids congestion
    propagation in the following ways:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，某些子系统由于故障或请求峰值而导致的拥塞不应传播到其他系统部分，以防止整体系统拥塞。**隔离舱隔离**通过以下方式避免拥塞传播：
- en: Only a maximum number of similar simultaneous outbound requests are allowed,
    let's say, 10\. This is similar to putting an upper bound on thread creation.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只允许最大数量的类似同时出站请求，比如说，10个。这类似于对线程创建设置上限。
- en: Requests exceeding the previous bound are queued.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超过之前限制的请求将被排队。
- en: If the maximum queue length is reached, any further requests result in exceptions
    being thrown to abort them.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果达到最大队列长度，任何进一步的请求将导致抛出异常以终止它们。
- en: Retry policies may make it so that the same message is received and processed
    several times because the sender has received no confirmation that the message
    has been received or simply because it has timed-out the operation, while the
    receiver actually received the message. The only possible solution to this problem
    is designing all messages so that they're idempotent, that is, designing messages
    in such a way that processing the same message several times has the same effect
    as processing it once.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 重试策略可能会使得相同的消息被接收和处理多次，因为发送者没有收到消息已被接收的确认，或者简单地因为超时了操作，而接收者实际上已经接收了消息。解决这个问题的唯一可能方法是设计所有消息，使它们是幂等的，也就是说，以这种方式设计消息，即多次处理相同的消息具有与处理一次相同的效果。
- en: 'Updating a database table field to a value, for instance, is an idempotent
    operation since repeating it once or twice has exactly the same effect. However,
    incrementing a decimal field is not an idempotent operation. Microservice designers
    should make an effort to design the overall application with as many idempotent
    messages as possible. The remaining non-idempotent messages must be transformed
    into idempotent ones in the following ways, or with some other similar technique:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，将数据库表字段更新为某个值是一个幂等操作，因为重复一次或两次具有完全相同的效果。然而，增加一个十进制字段不是幂等操作。微服务设计者应努力设计尽可能多的幂等消息的整体应用程序。剩余的非幂等消息必须以下列方式或使用其他类似技术转换为幂等消息：
- en: Attach both a time and some identifier that uniquely identify each message.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 附加一个时间和一些唯一标识符，以唯一标识每条消息。
- en: Store all the messages that have been received in a dictionary that's been indexed
    by the unique identifier attached to the message mentioned in the previous point.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有已接收的消息存储在一个字典中，该字典按前一点提到的消息附加的唯一标识符进行索引。
- en: Reject old messages.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拒绝旧消息。
- en: When a message that may be a duplicate is received, verify whether it's contained
    in the dictionary. If it is, then it has already been processed, so reject it.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当接收到可能重复的消息时，验证它是否包含在字典中。如果是，那么它已经被处理，因此拒绝它。
- en: Since old messages are rejected, they can be periodically removed from the dictionary
    to avoid it growing exponentially.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于拒绝旧消息，它们可以定期从字典中删除，以避免其指数增长。
- en: We will use this technique in the example at the end of this chapter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章末尾的示例中使用这项技术。
- en: In the next subsection, we will talk about microservice containerization based
    on Docker.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将讨论基于Docker的微服务容器化。
- en: Containers and Docker
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器和Docker
- en: 'We''ve already discussed the advantages of having microservices that don''t
    depend on the environment where they run: better hardware usage, the ability to
    mix legacy software with newer modules, the ability to mix several development
    stacks in order to use the best stack for each module implementation, and so on.
    Independence on the hosting environment can be easily achieved by deploying each
    microservice with all its dependencies on a private virtual machine.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了拥有不依赖于运行环境的微服务的优势：更好的硬件使用率，能够混合旧软件与较新的模块，能够混合多个开发堆栈以使用每个模块实现的最佳堆栈，等等。通过在每个微服务上部署所有依赖项到私有虚拟机，可以轻松实现对托管环境的独立性。
- en: However, starting a virtual machine with its private copy of the operating system
    takes a lot of time, and microservices must be started and stopped quickly to
    reduce load balancing and fault recovery costs. In fact, new microservices may
    be started either to replace faulty ones or because they were moved from one hardware
    node to another to perform load balancing. Moreover, adding a whole copy of the
    operating system to each microservice instance would be an excessive overhead.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，启动带有其私有操作系统副本的虚拟机需要很长时间，而微服务必须快速启动和停止以减少负载均衡和故障恢复成本。实际上，新的微服务可能被启动是为了替换有故障的微服务，或者是因为它们从一个硬件节点移动到另一个节点以执行负载均衡。此外，将整个操作系统的副本添加到每个微服务实例中将会造成过度的开销。
- en: 'Luckily, microservices can rely on a lighter form of technology: containers.
    Containers are a kind of light virtual machine. They do not virtualize a full
    machine – they just virtualize the **operating system** (**OS**) filesystem level
    that sits on top of the OS kernel. They use the OS of the hosting machine (kernel,
    DLLs, and drivers) and rely on the OS''s native features to isolate processes
    and resources to ensure an isolated environment for the images they run.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，微服务可以依赖一种更轻量级的技术：容器。容器是一种轻量级的虚拟机。它们不虚拟化整个机器——它们只是虚拟化了位于操作系统内核之上的操作系统（**OS**）文件系统级别。它们使用宿主机的操作系统（内核、DLL
    和驱动程序）并依赖于操作系统的原生功能来隔离进程和资源，以确保为运行的镜像提供一个隔离的环境。
- en: As a consequence, containers are tied to a specific operating system but they
    don't suffer the overhead of copying and starting a whole OS in each container
    instance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，容器与特定的操作系统相关联，但它们不会遭受在每个容器实例中复制和启动整个操作系统的开销。
- en: On each host machine, containers are handled by a runtime that takes care of
    creating them from *images* and creating an isolated environment for each of them.
    The most famous container runtime is Docker, which is a *de facto* standard for
    containerization.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在每台主机机器上，容器由一个运行时处理，该运行时负责从 *镜像* 中创建它们并为每个容器创建一个隔离的环境。最著名的容器运行时是 Docker，它是容器化的**事实标准**。
- en: Images are files that specify what is put in each container and which container
    resources, such as communication ports, to expose outside the container. None
    of the images need to explicitly specify their full content, but they can reference
    other images. This way, images are built by adding new software and configuration
    information on top of existing images.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像是文件，指定了每个容器中包含的内容以及哪些容器资源，例如通信端口，要暴露在容器外部。没有任何镜像需要明确指定其全部内容，但它们可以引用其他镜像。这样，通过在现有镜像之上添加新的软件和配置信息来构建镜像。
- en: For instance, if you want to deploy a .NET Core application as a Docker image,
    it is enough to just add your software and files to your Docker image and then
    reference an already existing .NET Core Docker image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您想将 .NET Core 应用程序作为 Docker 镜像部署，只需将您的软件和文件添加到您的 Docker 镜像中，然后引用一个已经存在的
    .NET Core Docker 镜像即可。
- en: 'To allow for easy image referencing, images are grouped into registries that
    may be either public or private. They are similar to NuGet or npm registries.
    Docker offers a public registry ([https://hub.docker.com/_/registry](https://github.com/Particular/Workshop/tree/master/demos/asp-net-core))
    where you can find most of the public images you may need to reference in your
    own images. However, each company can define private registries. For instance,
    Azure offers a private container registry service: `https://azure.microsoft.com/en-us/services/container-registry/`.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于图像引用，图像被分组到注册表中，这些注册表可以是公共的或私有的。它们类似于 NuGet 或 npm 注册表。Docker 提供了一个公共注册表（[https://hub.docker.com/_/registry](https://github.com/Particular/Workshop/tree/master/demos/asp-net-core)），在那里您可以找到您可能需要在自己的图像中引用的大多数公共图像。然而，每个公司都可以定义私有注册表。例如，Azure
    提供了一个私有容器注册表服务：`https://azure.microsoft.com/en-us/services/container-registry/`。
- en: Before instantiating each container, the Docker runtime must solve all the recursive
    references. This cumbersome job is not performed each time a new container is
    created since the Docker runtime has a cache where it stores the fully assembled
    images that correspond to each input image and that it's already processed.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在实例化每个容器之前，Docker运行时必须解决所有递归引用。这个繁琐的工作不是每次创建新容器时都执行，因为Docker运行时有一个缓存，其中存储了与每个输入镜像相对应的完全组装的镜像，并且这些镜像已经被处理。
- en: 'Since each application is usually composed of several modules to be run in
    different containers, Docker also allows `.yml` files, also known as composition
    files, that specify the following information:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个应用程序通常由多个模块组成，这些模块需要在不同的容器中运行，因此Docker还允许`.yml`文件，也称为组合文件，这些文件指定以下信息：
- en: Which images to deploy.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署哪些镜像。
- en: How the internal resources that are exposed by each image must be mapped to
    the physical resources of the host machine. For instance, how communication ports
    that are exposed by Docker images must be mapped to the ports of the physical
    machine.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个镜像暴露的内部资源必须映射到宿主机的物理资源。例如，Docker镜像暴露的通信端口必须映射到物理机的端口。
- en: We will analyze Docker images and `.yml` files in the *How does .NET Core deal
    with Microservices?* section of this chapter.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的*.NET Core如何处理微服务？*部分分析Docker镜像和`.yml`文件。
- en: The Docker runtime handles images and containers on a single machine but, usually,
    containerized microservices are deployed and load-balanced on clusters that are
    composed of several machines. Clusters are handled by pieces of software called
    **Orchestrators**. Orchestrators will be discussed in the *Which tools are needed
    to manage microservices?* section of this chapter.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Docker运行时在单台机器上处理镜像和容器，但通常，容器化的微服务是在由多台机器组成的集群上部署和负载均衡的。集群由称为**编排器**的软件组件处理。编排器将在本章的*需要哪些工具来管理微服务？*部分进行讨论。
- en: Now that we have understood what microservices are, what problems they can solve,
    and their basic design principles, we are ready to analyze when and how to use
    them in our system architecture. The next section analyzes when we should use
    them.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了微服务是什么，它们可以解决哪些问题，以及它们的基本设计原则，我们准备分析在系统架构中何时以及如何使用它们。下一节将分析何时应该使用它们。
- en: When do microservices help?
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务何时有帮助？
- en: The answer to this question requires us to understand the roles microservices
    play in modern software architectures. We will look at this in the following subsections.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的答案需要我们理解微服务在现代软件架构中扮演的角色。我们将在接下来的小节中探讨这一点。
- en: Layered architectures and microservices
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分层架构和微服务
- en: Enterprise systems are usually organized in logical independent layers. The
    first layer is the one that interacts with the user and is called the presentation
    layer, while the last layer takes care of storing/retrieving data and is called
    the data layer. Requests originate in the presentation layer and pass through
    all the layers until they reach the data layer, and then come back, traversing
    all the layers in reverse until they reach the presentation layer, which takes
    care of presenting the results to the user/client. Layers can't be *jumped*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 企业系统通常以逻辑独立的层组织。第一层是与用户交互的层，称为表示层，而最后一层负责存储/检索数据，称为数据层。请求从表示层发起，穿过所有层直到达到数据层，然后返回，反向穿越所有层直到达到表示层，该层负责将结果展示给用户/客户端。层之间不能*跳过*。
- en: Each layer takes data from the previous layer, processes it, and passes it to
    the next layer. Then, it receives the results from its next layer and sends them
    back to its previous layer. Also, thrown exceptions can't jump layers – each layer
    must take care of intercepting all the exceptions and either *solving them* somehow
    or transforming them into other exceptions that are expressed in the language
    of its previous layer. The layer architecture ensures the complete independence
    of the functionalities of each layer from all the other layers of their functionalities.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层从前一层数据，处理它，并将其传递到下一层。然后，它从下一层接收结果，并将其发送回前一层。此外，抛出的异常不能跨越层——每一层都必须负责拦截所有异常，或者以某种方式*解决*它们，或者将它们转换为其前一层的语言表达的其他异常。层架构确保了每一层的功能完全独立于其他层的功能。
- en: For instance, we can change the database engine without affecting all the layers
    that are above the data layer. In the same way, we can completely change the user
    interface, that is, the presentation layer, without affecting the remainder of
    the system.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以更改数据库引擎，而不会影响数据层之上的所有层。同样，我们可以完全更改用户界面，即表示层，而不会影响系统的其余部分。
- en: Moreover, each layer implements a different kind of system specification. The
    data layer takes care of what the system *must remember*, the presentation layer
    takes care of the system-user interaction protocol, and all the layers that are
    in the middle implement the domain rules, which specify how data must be processed
    (for instance, how an employed paycheck must be computed). Typically, the data
    and presentation layers are separated by just one domain rule layer, called the
    business or application layer.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每一层实现不同类型的系统规范。数据层负责系统*必须记住*的内容，表示层负责系统-用户交互协议，而中间的所有层实现领域规则，这些规则指定数据必须如何处理（例如，如何计算雇员的工资单）。通常，数据和表示层之间仅由一个领域规则层隔开，称为业务层或应用层。
- en: 'Each layer *speaks* a different language: the data layer *speaks* the language
    of the chosen storage engine, the business layer speaks the language of domain
    experts, and the presentation layer speaks the language of users. So, when data
    and exceptions pass from one layer to another, they must be translated into the
    language of the destination layer.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层都*说*着不同的语言：数据层*说*着所选存储引擎的语言，业务层*说*着领域专家的语言，而表示层*说*着用户的语言。因此，当数据和异常从一个层传递到另一个层时，它们必须被翻译成目标层的语言。
- en: A detailed example of how to build a layered architecture will be given in the
    *Use case - Logging Microservices* section in [Chapter 10](2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml),
    *Understanding the Different Domains in Software Solutions*, which is dedicated
    to domain-driven design.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如何构建分层架构的详细示例将在第10章的*用例 - 日志微服务*部分给出，该部分专门介绍软件解决方案中的不同领域，其链接为[Chapter 10](2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml)。
- en: That being said, how do microservices fit into a layered architecture? Are they
    adequate for the functionalities of all the layers or of just some layers? Can
    a single microservice span several layers?
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，微服务如何适应分层架构？它们是否足够满足所有层的功能，或者只是某些层的功能？单个微服务能否跨越几个层？
- en: 'The last question is the easiest to answer: yes! In fact, we''ve already stated
    that microservices should store the data they need within their logical boundaries.
    Therefore, there are microservices that span the business and data layers. Some
    others take care of encapsulating shared data and remain confined in the data
    layer. Thus, we may have business layer microservices, data layer microservices,
    and microservices that span both layers. So, what about the presentation layer?'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个问题最容易回答：是的！实际上，我们早已指出，微服务应该在其逻辑边界内存储它们所需的数据。因此，存在跨越业务和数据层的微服务。还有一些其他微服务负责封装共享数据，并保持在数据层内。因此，我们可能有业务层微服务、数据层微服务和跨越两个层的微服务。那么，表示层呢？
- en: The presentation layer can also fit into a microservice architecture if it is
    implemented on the server-side. Single-page applications and mobile applications
    run the presentation layer on the client machine, so they either connect directly
    to the business microservices layer or, more often, to an *API Gateway* that exposes
    the public interface and takes care of routing requests to the right microservices.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果表示层在服务器端实现，它也可以适应微服务架构。单页应用和移动应用在客户端机器上运行表示层，因此它们要么直接连接到业务微服务层，要么更常见的是连接到一个*API网关*，该网关公开接口并负责将请求路由到正确的微服务。
- en: In a microservices architecture, when the presentation layer is a website, it
    can be implemented with a set of microservices. However, if it requires heavy
    web servers and/or heavy frameworks, containerizing them may not be convenient.
    This decision must also consider the loss of performance that happens when containerizing
    the web server and the possible need for hardware firewalls between the web server
    and the remainder of the system.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在微服务架构中，当表示层是一个网站时，它可以由一组微服务实现。然而，如果它需要重型Web服务器和/或重型框架，容器化它们可能不方便。这个决定还必须考虑容器化Web服务器时可能发生的性能损失，以及可能需要在Web服务器和系统其余部分之间设置硬件防火墙的需求。
- en: ASP.NET Core is a lightweight framework that runs on the light Kestrel web server,
    so it can be containerized efficiently and used in a microservice for intranet
    applications. However, public high-traffic websites require dedicated hardware/software
    components that prevent them from being deployed together with other microservices.
    In fact, while Kestrel is an acceptable solution for an intranet website, public
    websites need a more complete web server such as IIS. In this case, security requirements
    are more compelling and require specialized hardware/software components.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ASP.NET Core是一个轻量级框架，它在轻量级的Kestrel网络服务器上运行，因此它可以有效地容器化并用于内部应用程序的微服务。然而，公共高流量网站需要专门的硬件/软件组件，这阻止了它们与其他微服务一起部署。实际上，虽然Kestrel对于内部网站是一个可接受的解决方案，但公共网站需要一个更完整的网络服务器，如IIS。在这种情况下，安全要求更加紧迫，需要专门的硬件/软件组件。
- en: Monolithic websites can be easily broken into load-balanced smaller subsites
    without microservice-specific technologies, but a microservice architecture can
    bring all the advantages of microservices into the construction of a single HTML
    page. More specifically, different microservices may take care of different areas
    of each HTML page. Unfortunately, at the time of writing, such a similar scenario
    is not easy to implement with the available .NET and .NET Core technology.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 单体网站可以很容易地被拆分成负载均衡的较小子站，而不需要特定的微服务技术，但微服务架构可以将微服务的所有优势带入单个HTML页面的构建中。更具体地说，不同的微服务可能负责每个HTML页面的不同区域。不幸的是，在撰写本文时，使用现有的.NET和.NET
    Core技术实现这样的类似场景并不容易。
- en: 'A proof of concept that implements a website with ASP.NET Core-based microservices
    that cooperate in the construction of each HTML page can be found here: [https://github.com/Particular/Workshop/tree/master/demos/asp-net-core](https://github.com/Particular/Workshop/tree/master/demos/asp-net-core).
    The main limit of this approach is that microservices cooperate just to generate
    the data that''s needed to generate the HTML page and not to generate the actual
    HTML page. Instead, this is handled by a monolithic gateway. In fact, at the time
    of writing, frameworks such as ASP.NET Core MVC don''t provide any facilities
    for the distribution of HTML generation. We will return to this example in [Chapter
    13](003ee8cb-5995-4364-8772-73d73df29cf8.xhtml), *Presenting ASP.NET Core MVC*.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实现基于ASP.NET Core的微服务的概念证明，这些微服务协同构建每个HTML页面，可以在以下位置找到：[https://github.com/Particular/Workshop/tree/master/demos/asp-net-core](https://github.com/Particular/Workshop/tree/master/demos/asp-net-core)。这种方法的主要限制是微服务仅合作生成生成HTML页面所需的数据，而不是生成实际的HTML页面。相反，这由单体网关处理。实际上，在撰写本文时，如ASP.NET
    Core MVC之类的框架不提供任何用于HTML生成的分发功能。我们将在[第13章](003ee8cb-5995-4364-8772-73d73df29cf8.xhtml)，*展示ASP.NET
    Core MVC*中回到这个例子。
- en: Now that we've clarified which parts of a system can benefit from the adoption
    of microservices, we are ready to state the rules when it comes to deciding how
    they're adopted.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经明确了系统哪些部分可以从采用微服务中受益，我们准备好陈述在决定如何采用它们时的规则。
- en: When is it worth considering microservice architectures?
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在什么情况下值得考虑微服务架构？
- en: 'Microservices can improve the implementation of both the business and data
    layer, but their adoption has some costs:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务可以提高业务和数据层的实现，但它们的采用有一些成本：
- en: Allocating instances to nodes and scaling them has a cost in terms of cloud
    fees or internal infrastructures and licenses.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将实例分配到节点并对其进行扩展在云费用或内部基础设施和许可证方面都有成本。
- en: Splitting a unique process into smaller communicating processes increases communication
    costs and hardware needs, especially if the microservices are containerized.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一个独特的过程拆分成更小的通信过程会增加通信成本和硬件需求，尤其是在微服务被容器化的情况下。
- en: Designing and testing software for a microservice requires more time and increases
    human resources costs. In particular, making microservices resilient and ensuring
    that they adequately handle all possible failures, as well as verify these features
    with integration tests, can increase the development time by more than one order
    of magnitude.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为微服务设计和测试软件需要更多时间，并增加了人力资源成本。特别是，使微服务具有弹性并确保它们能够充分处理所有可能的故障，以及通过集成测试验证这些功能，可能会将开发时间增加一个数量级以上。
- en: So, when are microservices worth the cost of using them? Are there functionalities
    that must be implemented as microservices?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，微服务何时值得使用它们的成本？是否有必须作为微服务实现的函数？
- en: 'A rough answer to the first question is: yes, when the application is big enough
    in terms of traffic and/or software complexity. In fact, as an application grows
    in complexity and its traffic increases, it''s recommended that we pay the costs
    connected to scaling it since this allows for more scaling optimization and better
    handling when it comes to the development team. The costs we pay for these would
    soon exceed the cost of microservice adoption.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个问题的粗略答案是：是的，当应用在流量和/或软件复杂度方面足够大时。实际上，随着应用在复杂性和流量方面的增长，我们建议我们承担与扩展相关的成本，因为这允许进行更多的扩展优化，并且在开发团队方面有更好的处理能力。我们为此付出的成本很快就会超过采用微服务的成本。
- en: Thus, if fine-grained scaling makes sense for our application, and if we are
    able to estimate the savings that fine-grained scaling and development give us,
    we can easily compute an overall application throughput limit that makes the adoption
    of microservices convenient.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果细粒度扩展对我们应用有意义，并且我们能够估计细粒度扩展和开发带来的节省，我们就可以轻松计算出整体应用吞吐量限制，这使得采用微服务变得方便。
- en: Microservice costs can also be justified by the market value of our products/services
    increasing. Since the microservice architecture allows us to implement each microservice
    with a technology that has been optimized for its use, the quality that's added
    to our software may justify all or part of the microservice costs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务成本也可以通过我们产品/服务的市场价值增加来证明。由于微服务架构允许我们使用针对其使用进行优化的技术来实现每个微服务，因此我们软件中增加的质量可能证明所有或部分微服务成本是合理的。
- en: However, scaling and technology optimizations are not the only parameters to
    consider. Sometimes, we are forced to adopt a microservice architecture without
    being able to perform a detailed cost analysis.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，扩展和技术优化并不是唯一需要考虑的参数。有时，我们被迫采用微服务架构，而无法进行详细的成本分析。
- en: If the size of the team that takes care of the CI/CD of the overall system grows
    too much, the organization and coordination of this big team cause difficulties
    and inefficiencies. In this type of situation, it is desirable to move to an architecture
    that breaks the whole CI/CD cycle into independent parts that can be taken care
    of by smaller teams.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果负责整个系统CI/CD的团队规模过大，这个大团队的组织和协调会带来困难和低效。在这种情况下，转向一个将整个CI/CD周期分解为独立部分，这些部分可以由较小的团队负责的架构是可取的。
- en: Moreover, since these development costs are only justified by a high volume
    of requests, we probably have high traffic being processed by independent modules
    that have been developed by different teams. Therefore, scaling optimizations
    and the need to reduce interaction between development teams makes the adoption
    of a microservice architecture very convenient.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于这些开发成本只有通过高请求量才能证明是合理的，我们可能处理着由不同团队开发的独立模块的高流量。因此，扩展优化和减少开发团队之间交互的需要使得采用微服务架构非常方便。
- en: From this, we may conclude that, if the system and the development team grows
    too much, it is necessary to split the development team into smaller teams, each
    working on an efficient Bounded Context subsystem. It is very likely that, in
    a similar situation, a microservices architecture is the only possible option.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个结论中，我们可能得出，如果系统和开发团队增长得太大，有必要将开发团队分成更小的团队，每个团队负责一个高效的边界上下文子系统。在类似的情况下，微服务架构可能是唯一可行的选择。
- en: Another situation that forces the adoption of a microservice architecture is
    the integration of newer subparts with legacy subsystems based on different technologies
    since containerized microservices are the only way to implement an efficient interaction
    between the legacy system and the new subparts in order to gradually replace the
    legacy subparts with newer ones. Similarly, if our team is composed of developers
    with experience in different development stacks, an architecture based on containerized
    microservices may become a *must*.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种迫使采用微服务架构的情况是将基于不同技术的较新子部分与旧子系统集成，因为容器化微服务是唯一能够实现旧系统与新子部分之间有效交互以逐步用较新的子部分替换旧子部分的方式。同样，如果我们的团队由具有不同开发栈经验的开发者组成，基于容器化微服务的架构可能成为*必需的*。
- en: In the next section, we will analyze building blocks and tools that are available
    so that we can implement .NET Core-based microservices.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将分析可用的构建块和工具，以便我们可以实现基于.NET Core的微服务。
- en: How does .NET Core deal with microservices?
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: .NET Core如何处理微服务？
- en: .NET Core was conceived as a multi-platform framework that was light and fast
    enough to implement efficient microservices. In particular, ASP.NET Core is the
    ideal tool for implementing REST APIs to communicate with a microservice, since
    it can run efficiently with light web servers such as Kestrel and is itself light
    and modular.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: .NET Core被构想为一个轻量级且快速的跨平台框架，足以实现高效的微服务。特别是，ASP.NET Core是实现REST API的理想工具，用于与微服务通信，因为它可以与轻量级网络服务器如Kestrel高效运行，并且自身也是轻量级和模块化的。
- en: The whole .NET Core framework evolved with microservices as a strategic deployment
    platform in mind and has facilities and packages for building efficient and light
    HTTP communication to ensure service resiliency and to handle long-running tasks.
    The following subsections describe some of the different tools or solutions that
    we can use to implement a .NET Core-based microservice architecture.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 整个.NET Core框架都是基于微服务作为战略部署平台而演化的，它提供了构建高效且轻量级HTTP通信的设施和包，以确保服务弹性并处理长时间运行的任务。以下小节将描述我们可以使用的一些不同工具或解决方案来实现基于.NET
    Core的微服务架构。
- en: .NET Core communication facilities
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: .NET Core通信设施
- en: 'Microservices need two kinds of communication channel:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务需要两种类型的通信渠道：
- en: A communication channel to receive external requests, either directly or through
    an API Gateway. HTTP is the usual protocol for external communication due to available
    web services standards and tools. .NET Core's main HTTP communication facility
    is ASP.NET Core since it's a lightweight HTTP framework, which makes it ideal
    for implementing Web APIs in small microservices. We will describe ASP.NET Core
    App in detail in [Chapter 12](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml), *Applying
    Service-Oriented Architectures with .NET Core*, which is dedicated to HTTP services.
    .NET Core also offers an efficient and modular HTTP client solution that is able
    to pool and reuse heavy connection objects. Also, the `HttpClient` class will
    be described in more detail in [Chapter 12](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml),
    *Applying Service-Oriented Architectures with .NET Core*.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接收外部请求的通信渠道，可以是直接或通过API网关。由于可用的网络服务标准和工具，HTTP是外部通信的常用协议。.NET Core的主要HTTP通信设施是ASP.NET
    Core，因为它是一个轻量级的HTTP框架，这使得它非常适合在小型微服务中实现Web API。我们将在[第12章](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml)中详细描述ASP.NET
    Core应用程序，*使用.NET Core应用服务导向架构*，该章节专门介绍HTTP服务。.NET Core还提供了一个高效且模块化的HTTP客户端解决方案，能够池化和重用重量级的连接对象。此外，`HttpClient`类将在[第12章](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml)中更详细地描述，*使用.NET
    Core应用服务导向架构*。
- en: A different type of communication channel to push updates to other microservices.
    In fact, we have already mentioned that intra-microservice communication cannot
    be triggered by an on-going request since a complex tree of blocking calls to
    other microservices would increase request latency to an unacceptable level. As
    a consequence, updates must not be requested immediately before they're used and
    should be pushed whenever state changes take place. Ideally, this kind of communication
    should be asynchronous to achieve acceptable performance. In fact, synchronous
    calls would block the sender while they are waiting for the result, thus increasing
    the idle time of each microservice. However, synchronous communication that just
    puts the request in a processing queue and then returns confirmation of the successful
    communication instead of the final result is acceptable if communication is fast
    enough (low communication latency and high bandwidth). A publisher/subscriber
    communication would be preferable since, in this case, the sender and receiver
    don't need to know each other, thus increasing the microservices' independence.
    In fact, all the receivers that are interested in a certain type of communication merely need
    to register to receive a specific *event*, while senders just need to publish
    those events. All the wiring is performed by a service that takes care of queuing
    events and dispatching them to all the subscribers. The publisher/subscriber pattern
    will be described in more detail in [Chapter 9](a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml),
    *Design Patterns and .NET Core Implementation*, along with other useful patterns.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种不同的通信通道类型，用于向其他微服务推送更新。实际上，我们已提到，由于复杂的阻塞调用树会提高请求延迟到不可接受的水平，因此微服务之间的内部通信不能由一个正在进行的请求触发。因此，在它们被使用之前不应立即请求更新，并且应在状态发生变化时推送。理想情况下，这种通信应该是异步的，以实现可接受的性能。实际上，同步调用会在等待结果时阻塞发送者，从而增加每个微服务的空闲时间。然而，如果通信足够快（低通信延迟和高带宽），仅将请求放入处理队列并返回成功通信确认而不是最终结果的同步通信是可以接受的。发布/订阅通信会更可取，因为在这种情况下，发送者和接收者不需要相互了解，从而增加了微服务的独立性。实际上，所有对某种类型的通信感兴趣的接收者只需注册以接收特定的
    *事件*，而发送者只需发布这些事件。所有连接都是由一个负责排队事件并将它们分发给所有订阅者的服务来完成的。发布/订阅模式将在第 9 章[设计模式和 .NET
    Core 实现](a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml)中更详细地描述，以及其他有用的模式。
- en: While .NET Core doesn't directly offer tools that may help in asynchronous communication
    or client/server tools that implement a publisher/subscriber communication, Azure
    offers a similar service with *Azure Service Bus*. Azure Service Bus handles both
    queued asynchronous communication through Azure Service Bus *queues* and publisher/subscriber
    communication through Azure Service Bus *topics*.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 .NET Core 没有直接提供帮助异步通信的工具，也没有实现发布/订阅通信的客户端/服务器工具，但 Azure 提供了类似的服务，即 *Azure
    Service Bus*。Azure Service Bus 通过 Azure Service Bus *队列*处理排队异步通信，并通过 Azure Service
    Bus *主题*处理发布/订阅通信。
- en: Once you've configured an Azure Service Bus on the Azure portal, you can connect
    to it in order to send messages/events and to receive messages/events through
    a client contained in the `Microsoft.Azure.ServiceBus` NuGet package.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在 Azure 门户上配置了 Azure Service Bus，你就可以通过包含在 `Microsoft.Azure.ServiceBus` NuGet
    包中的客户端连接到它，以发送消息/事件并通过接收消息/事件。
- en: 'Azure Service Bus has two types of communication: queue-based and topic-based.
    In queue-based communication, each message that''s placed in the queue by a sender
    is removed from the queue by the first receiver that pulls it from the queue.
    Topic-based communication, on the other hand, is an implementation of the publisher/subscriber
    pattern. Each topic has several subscriptions and a different copy of each message
    sent to a topic can be pulled from each topic subscription.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Service Bus 有两种通信类型：基于队列和基于主题。在基于队列的通信中，每个发送者放入队列的消息将由第一个从队列中拉取它的接收者移除。另一方面，基于主题的通信是发布/订阅模式的实现。每个主题都有多个订阅，并且每个发送到主题的消息的不同副本都可以从每个主题订阅中拉取。
- en: 'The design flow is as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 设计流程如下：
- en: Define an Azure Service Bus private namespace.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个 Azure Service Bus 私有命名空间。
- en: Get the root connection strings that were created by the Azure portal and/or
    define new connection strings with fewer privileges.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取由 Azure 门户创建的根连接字符串，或定义具有较少权限的新连接字符串。
- en: Define queues and/or topics where the sender will send their messages in binary
    format.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义发送者将发送其消息的二进制格式的队列和/或主题。
- en: For each topic, define names for all the required subscriptions.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个主题，为所有必需的订阅定义名称。
- en: In the case of queue-based communication, the sender sends messages to a queue
    and the receivers pull messages from the same queue. Each message is delivered
    to one receiver. That is, once a receiver gains access to the queue, it reads
    and removes one or more messages.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在基于队列的通信情况下，发送者向队列发送消息，接收者从同一个队列中拉取消息。每条消息只被发送给一个接收者。也就是说，一旦接收者获得对队列的访问权限，它就会读取并移除一条或多条消息。
- en: In the case of topic-based communication, each sender sends messages to a topic,
    while each receiver pulls messages from the private subscription associated with
    that topic.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在基于主题的通信情况下，每个发送者向一个主题发送消息，而每个接收者从与该主题关联的私有订阅中拉取消息。
- en: 'There are also other commercial alternatives to Azure Service Bus, such as
    NServiceBus, MassTransit, Brighter, and ActiveMQ. There is also a free open source
    option: RabbitMQ . RabbitMQ can be installed locally, on a virtual machine, or
    in a Docker container. Then, you can connect with it through the client contained
    in the `RabbitMQ.Client` NuGet package.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他商业替代方案，如NServiceBus、MassTransit、Brighter和ActiveMQ。还有一个免费的开源选项：RabbitMQ。RabbitMQ可以安装在本地、虚拟机或Docker容器中。然后，你可以通过包含在`RabbitMQ.Client`
    NuGet包中的客户端与之连接。
- en: The functionalities of RabbitMQ are similar to the ones offered by Azure Service
    Bus but you have to take care of all the implementation details, confirmations
    of performed operations, and so on, while Azure Service Bus takes care of all
    the low-level tasks and offers you a simpler interface. Azure Service Bus and
    RabbitMQ will be described alongside Publisher/Subscriber-based communication
    in [Chapter 9](a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml), *Design Patterns and
    .NET Core Implementation*.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ的功能与Azure Service Bus提供的功能类似，但你必须注意所有实现细节、执行操作的确认等，而Azure Service Bus则负责所有底层任务并提供一个更简单的接口。Azure
    Service Bus和RabbitMQ将与基于发布/订阅的通信一起在[第9章](a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml)，“设计模式和.NET
    Core实现”中描述。
- en: If microservices are published to Azure Service Fabric, which will be described
    in the next section, we can use a built-in reliable binary communication. Communication
    is resilient since communication primitives automatically use a retry policy.
    This communication is synchronous, but this is not a big limitation since microservices
    in Azure Service Fabric have built-in queues; thus, once the receiver has received
    a message, they can just put it in a queue and return it immediately, without
    blocking the sender.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果微服务发布到将在下一节中描述的Azure Service Fabric，我们可以使用内置的可靠二进制通信。由于通信原语自动使用重试策略，因此通信是弹性的。这种通信是同步的，但这不是一个大限制，因为Azure
    Service Fabric中的微服务具有内置队列；因此，一旦接收者收到消息，它们只需将其放入队列并立即返回，而不会阻塞发送者。
- en: The messages in the queue are then processed by a separate thread. The main
    limitation of this built-in communication is that it is not based on the publisher/subscriber
    pattern; the senders and receivers must know each other. When this is not acceptable,
    you should use Azure Service Bus. We will learn how to use Service Fabric's built-in
    communication in the *Use case - logging microservices* section of this chapter.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 队列中的消息随后由一个单独的线程进行处理。这种内置通信的主要局限性在于它不是基于发布/订阅模式；发送者和接收者必须相互了解。当这不可接受时，你应该使用Azure
    Service Bus。我们将在本章的“用例 - 日志微服务”部分学习如何使用Service Fabric的内置通信。
- en: Resilient task execution
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弹性任务执行
- en: Resilient communication and, in general, resilient task execution can be implemented
    easily with the help of a .NET Core library called Polly, which is maintained
    by the .NET Foundation. Polly is available through the Polly NuGet package.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用由.NET Foundation维护的名为Polly的.NET Core库，可以轻松实现弹性通信和一般性的弹性任务执行。Polly可以通过Polly
    NuGet包获取。
- en: 'In Polly, you define policies, and then execute tasks in the context of that
    policy, as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在Polly中，你定义策略，然后在该策略的上下文中执行任务，如下所示：
- en: '[PRE1]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The first part of each policy specifies the exceptions that must be handled.
    Then, you specify what to do when one of those exceptions is captured. In the
    preceding code, the `Execute` method is retried up to three times if a failure
    is reported either by an `HttpRequestException` exception or by an `OperationCanceledException`
    exception.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 每个策略的第一部分指定必须处理的异常。然后，您指定在捕获到这些异常之一时执行的操作。在前面的代码中，如果报告失败是由 `HttpRequestException`
    异常或 `OperationCanceledException` 异常引起的，则 `Execute` 方法将重试最多三次。
- en: 'The following is the implementation of an exponential retry policy:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个指数重试策略的实现：
- en: '[PRE2]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first argument of `WaitAndRetry` specifies that a maximum of six retries
    is performed in case of failure. The lambda function passed as second argument
    specifies how much time to wait before the next attempt. In the specific example,
    this time grows exponentially with the number of the attempt with a power of 2
    (2 seconds for the first retry, 4 seconds for the second retry, and so on).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`WaitAndRetry` 的第一个参数指定在失败的情况下最多执行六次重试。作为第二个参数传递的 lambda 函数指定在下次尝试之前等待的时间。在具体示例中，这个时间随着尝试次数的指数增长，以
    2 的幂次（第一次重试为 2 秒，第二次重试为 4 秒，依此类推）。'
- en: 'The following is a simple Circuit Breaker policy:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个简单的断路器策略：
- en: '[PRE3]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After six failures, the task can't be executed for 1 minute since an exception
    is returned.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在连续失败六次后，由于返回异常，任务将无法执行 1 分钟。
- en: 'The following is the implementation of the Bulkhead Isolation policy (see the
    *Microservices design principles* section for more information):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Bulkhead 隔离策略的实现（有关更多信息，请参阅 *微服务设计原则* 部分）：
- en: '[PRE4]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: A maximum of 10 parallel executions is allowed in the `Execute` method. Further
    tasks are inserted in an execution queue. This has a limit of 15 tasks. If the
    queue limit is exceeded, an exception is thrown.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `Execute` 方法中允许最多 10 个并行执行。进一步的任务将被插入到执行队列中。这个队列的容量限制为 15 个任务。如果队列限制被超过，将抛出异常。
- en: For the Bulkhead policy to work properly and, in general, for every strategy
    to work properly, task executions must be triggered through the same policy instance;
    otherwise, Polly is unable to count how many executions of a specific task are
    active.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 Bulkhead 策略正常工作，以及通常为了使每个策略正常工作，任务执行必须通过相同的策略实例触发；否则，Polly 无法计算特定任务的活跃执行次数。
- en: 'Policies can be combined with the `Wrap` method:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将策略与 `Wrap` 方法结合使用：
- en: '[PRE5]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Polly offers several more options, such as generic methods for tasks that return
    a specific type, timeout policies, task result caching, the ability to define
    custom policies, and so on. The link to the official Polly documentation is in
    the *Further reading* section.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Polly 提供了更多选项，例如针对返回特定类型的任务的泛型方法、超时策略、任务结果缓存、定义自定义策略的能力等。官方 Polly 文档的链接在 *进一步阅读*
    部分中。
- en: Using generic hosts
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用泛型托管器
- en: Each microservice may need to run several independent threads, each performing
    a different operation on requests received. Such threads need several resources,
    such as database connections, communication channels, specialized modules that
    perform complex operations, and so on. Moreover, all processing threads must be
    adequately initialized when the microservice is started and gracefully stopped
    when the microservice is stopped as a consequence of either load balancing or
    errors.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 每个微服务可能需要运行几个独立的线程，每个线程对收到的请求执行不同的操作。这些线程需要几个资源，例如数据库连接、通信通道、执行复杂操作的专业模块等。此外，所有处理线程必须在微服务启动时得到适当的初始化，并在微服务由于负载均衡或错误而停止时优雅地停止。
- en: All of these needs led the .NET Core team to conceive and implement *hosted
    services* and *hosts*. A host creates an adequate environment for running several
    tasks, known as **hosted services**, and provides them with resources, common
    settings, and graceful start/stop.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些需求促使 .NET Core 团队构思并实现了 *托管服务* 和 *托管器*。托管器为运行多个任务（称为 **托管服务**）提供了一个适当的环境，并为它们提供资源、通用设置和优雅的启动/停止。
- en: The concept of a web host was mainly conceived to implement the ASP.NET Core
    web framework, but, with effect from .NET Core 2.1, the host concept was extended
    to all .NET applications. All features related to the concept of "host" are contained
    in the `Microsoft.Extensions.Hosting` NuGet package.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 网站托管的概念最初主要是为了实现 ASP.NET Core 网络框架，但从 .NET Core 2.1 开始，托管概念被扩展到所有 .NET 应用程序。与“托管”概念相关的所有功能都包含在
    `Microsoft.Extensions.Hosting` NuGet 包中。
- en: 'First, you need to configure the host with a fluent interface, starting with
    a `HostBuilder` instance. The final step of this configuration is calling the
    `Build` method, which assembles the actual host with all the configuration information
    we provided:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要使用流畅接口配置主机，从 `HostBuilder` 实例开始。此配置的最终步骤是调用 `Build` 方法，该方法将所有提供的配置信息组装成实际的主机：
- en: '[PRE6]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Host configuration includes defining the common resources, defining the default
    folder for files, loading the configuration parameters from several sources (JSON
    files, environment variables, and any arguments that are passed to the application),
    and declaring all the hosted services.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 主机配置包括定义常用资源，定义文件默认文件夹，从多个来源（JSON 文件、环境变量以及传递给应用程序的任何参数）加载配置参数，并声明所有托管服务。
- en: 'Then, the host can be started, which causes all the hosted services to be started:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以启动主机，这将导致所有托管服务启动：
- en: '[PRE7]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The program remains blocked on the preceding instruction until the host is shutdown.
    The host can be shutdown either by one of the hosted services or externally by
    calling `await host.StopAsync(timeout)`. Here, `timeout` is a time span defining
    the maximum time to wait for the hosted services to stop gracefully. After this
    time, all the hosted services are aborted if they haven't been terminated.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 程序在上一条指令上保持阻塞，直到主机关闭。主机可以通过托管服务之一或通过调用 `await host.StopAsync(timeout)` 外部关闭。在这里，`timeout`
    是一个时间跨度，定义了等待托管服务优雅停止的最大时间。在此时间之后，如果托管服务尚未终止，则所有托管服务都将被终止。
- en: Often, the fact that a microservice is being shutdown is signaled by a `CancelationToken`
    being passed when the microservice is started by the orchestrator. This happens
    when microservices are hosted in Azure Service Fabric.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，微服务正在关闭的事实是通过在协调器启动微服务时传递 `CancelationToken` 来表示的。这发生在微服务托管在 Azure Service
    Fabric 中时。
- en: 'In this case, instead of using `host.Start()`, we can use the `RunAsync` method
    and pass it the `CancelationToken` that we received from the orchestrator:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们不必使用 `host.Start()`，而是可以使用 `RunAsync` 方法，并传递我们从协调器那里接收到的 `CancelationToken`：
- en: '[PRE8]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This way of shutting down is triggered as soon as the `cancelationToken` enters
    a canceled state. By default, the host has a 5-second timeout for shutting down;
    that is, it waits 5 seconds before exiting once a shutdown has been requested.
    This time can be changed within the `ConfigureServices` method, which is used
    to declare *hosted services* and other resources:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关闭方式在 `cancelationToken` 进入已取消状态时立即触发。默认情况下，主机关闭超时为 5 秒；也就是说，一旦请求关闭，它将等待 5
    秒后才退出。这个时间可以在 `ConfigureServices` 方法中更改，该方法用于声明 *托管服务* 和其他资源：
- en: '[PRE9]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: However, increasing the host timeout doesn't increase the orchestrator timeout,
    so if the host waits too long, the whole microservice is killed by the orchestrator.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，增加主机超时并不会增加协调器超时，所以如果主机等待时间过长，整个微服务将被协调器杀死。
- en: Hosted services are implementations of the `IHostedService` interface, whose
    only methods are `StartAsync(CancellationToken)` and `StopAsync(CancellationToken`).
    Both methods are passed a `CancelationToken`. The `CancelationToken` in the `StartAsync`
    method signals that a shutdown was requested. The `StartAsync` method periodically
    checks this `CancelationToken` while performing all operations needed to start
    the host, and if it is signaled the host start process is aborted. On the other
    hand, the `CancelationToken` in the `StopAsync` method signals that the shutdown
    timeout expired.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 托管服务是实现 `IHostedService` 接口的实现，其唯一的方法是 `StartAsync(CancellationToken)` 和 `StopAsync(CancellationToken)`。这两个方法都传递了一个
    `CancelationToken`。在 `StartAsync` 方法中，`CancelationToken` 表示请求关闭。`StartAsync` 方法在执行启动主机所需的所有操作时，会定期检查这个
    `CancelationToken`，如果它被触发，则主机启动过程将被终止。另一方面，在 `StopAsync` 方法中，`CancelationToken`
    表示关闭超时已过期。
- en: 'Hosted services must be declared in the same `ConfigureServices` method that''s
    used to define host options, as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 托管服务必须在用于定义主机选项的相同 `ConfigureServices` 方法中声明，如下所示：
- en: '[PRE10]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Most declarations inside `ConfigureServices` require the addition of the following
    namespace:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConfigureServices` 中的大多数声明都需要添加以下命名空间：'
- en: '[PRE11]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Usually, the `IHostedService` interface isn't implemented directly but can be
    inherited from the `BackgroundService` abstract class, which exposes the easier-to-implement
    `ExecuteAsync(CancellationToken)` method, which is where we can place the whole
    logic of the service. A shutdown is signaled by passing `CancellationToken` as
    an argument, which is easier to handle. We will look at an implementation of `IHostedService`
    in the example at the end of this chapter.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，`IHostedService` 接口不是直接实现的，而是可以继承自 `BackgroundService` 抽象类，该类公开了更容易实现的 `ExecuteAsync(CancellationToken)`
    方法，我们可以在其中放置整个服务的逻辑。通过传递 `CancellationToken` 作为参数来表示关闭信号，这更容易处理。我们将在本章末尾的示例中查看
    `IHostedService` 的实现。
- en: 'To allow a hosted service to shutdown the host, we need to declare an `IApplicationLifetime`
    interface as its constructor parameter:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许托管服务关闭宿主，我们需要将其构造函数参数声明为 `IApplicationLifetime` 接口：
- en: '[PRE12]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'When the hosted service is created, it will be automatically passed an implementation
    of `IApplicationLifetime`, whose `StopApplication` method will trigger the host
    shutdown. This implementation is handled automatically, but we can declare custom
    resources whose instances will be automatically passed to all the host service
    constructors that declare them as parameters. There are several ways to define
    these resources:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当托管服务被创建时，它将自动传递一个 `IApplicationLifetime` 的实现，其 `StopApplication` 方法将触发宿主关闭。这种实现是自动处理的，但我们可以声明自定义资源，其实例将被自动传递到所有声明它们为参数的宿主服务构造函数。定义这些资源有几种方式：
- en: '[PRE13]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: When we use `AddTransient`, a different instance is created and passed to all
    the constructors that require an instance of that type. On the other hand, with
    `AddSingleton`, a unique instance is created and passed to all the constructors
    that require the declared type. The overload with two generic types allows you
    to pass an interface and a type that implements that interface. This way, a constructor
    requires the interface and is decoupled from the specific implementation of that
    interface.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 `AddTransient` 时，将创建一个不同的实例并将其传递给所有需要该类型实例的构造函数。另一方面，使用 `AddSingleton`
    时，将创建一个唯一的实例并将其传递给所有需要声明类型的构造函数。具有两个泛型类型的重载允许你传递一个接口及其实现该接口的类型。这样，构造函数需要接口，并且与该接口的具体实现解耦。
- en: If resource constructors contain parameters, they will be automatically instantiated
    with the types declared in `ConfigureServices` in a recursive fashion. This pattern
    of interaction with resources is called **dependency injection** (**DI**) and
    will be discussed in detail in [Chapter 9](a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml),
    *Design Patterns and .NET Core Implementation*.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果资源构造函数包含参数，它们将以递归方式自动使用在 `ConfigureServices` 中声明的类型进行实例化。这种与资源交互的模式称为 **依赖注入**（**DI**），将在第
    9 章 *设计模式和 .NET Core 实现* 中详细讨论。
- en: '`HostBuilder` also has a method we can use to define the default folder:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`HostBuilder` 还有一个我们可以用来定义默认文件夹的方法：'
- en: '[PRE14]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It also has methods that we can use to add logging targets:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 它还提供了我们可以用来添加日志目标的方法：
- en: '[PRE15]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The preceding example shows a console-based logging source, but we can also
    log into Azure targets with adequate providers. The *Further reading* section
    contains links to some Azure logging providers that can work with microservices
    that have been deployed in Azure Service Fabric. Once you've configured logging,
    you can enable your hosted services and log custom messages by adding an `ILoggerFactory`
    parameter in their constructors.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例展示了基于控制台的日志源，但我们可以使用适当的提供程序将日志记录到 Azure 目标。*进一步阅读* 部分包含了一些可以与在 Azure Service
    Fabric 中部署的微服务一起工作的 Azure 日志提供程序的链接。一旦配置了日志，你就可以通过在它们的构造函数中添加 `ILoggerFactory`
    参数来启用你的托管服务并记录自定义消息。
- en: 'Finally, `HostBuilder` has methods we can use to read configuration parameters
    from various sources:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`HostBuilder` 有我们可以用来从各种来源读取配置参数的方法：
- en: '[PRE16]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The way parameters can be used from inside the application will be explained
    in more detail in [Chapter 13](003ee8cb-5995-4364-8772-73d73df29cf8.xhtml), *Presenting
    ASP.NET Core MVC*, which is dedicated to ASP.NET Core.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 13 章 *展示 ASP.NET Core MVC* 中，我们将更详细地解释如何在应用程序内部使用参数，该章节专门介绍 ASP.NET Core。
- en: Visual Studio support for Docker
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Visual Studio 对 Docker 的支持
- en: Visual Studio offers support for creating, debugging, and deploying Docker images.
    Docker deployment requires us to install *Docker CE for Windows* on our development
    machine so that we can run Docker images. The download link can be found in the
    *Technical requirements* section at the beginning of this chapter. Before we start
    any development activity, we must ensure it is installed and running (you should
    see a Docker icon in the window notification bar when the Docker runtime is running).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Studio提供了创建、调试和部署Docker镜像的支持。Docker部署需要我们在开发机器上安装*Windows Docker CE*，这样我们才能运行Docker镜像。下载链接可以在本章开头的*技术要求*部分找到。在我们开始任何开发活动之前，我们必须确保它已安装并正在运行（当Docker运行时，你应该在窗口通知栏中看到Docker图标）。
- en: 'Docker support will be described with a simple ASP.NET Core MVC project. Let''s
    create one. To do so, follow these steps:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Docker支持将通过一个简单的ASP.NET Core MVC项目进行描述。让我们创建一个。为此，请按照以下步骤操作：
- en: Name the project `MvcDockerTest`.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将项目命名为`MvcDockerTest`。
- en: For simplicity, disable authentication.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了简单起见，禁用身份验证。
- en: You are given the option to add Docker support when you create the project,
    but please don't check the Docker support checkbox. You can test how Docker support
    can be added to any project after it has been created.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你创建项目时，你可以选择添加Docker支持，但请不要勾选Docker支持复选框。你可以在项目创建后测试如何将Docker支持添加到任何项目中。
- en: Once you have your ASP.NET Core MVC application scaffolded and running, right-click
    on its project icon in the Solution Explorer and select Container Orchestrator
    Support | Docker Compose. This will enable not only the creation of a Docker image
    but also the creation of a Docker Compose project, which helps you configure Docker
    Compose files so that they run and deploy several Docker images simultaneously.
    In fact, if you add another MVC project to the solution and enable container orchestrator
    support for it, the new Docker image will be added to the same Docker Compose
    file.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的ASP.NET Core MVC应用程序已经搭建并运行，在解决方案资源管理器中右键单击其项目图标，选择容器编排器支持 | Docker Compose。这将不仅启用Docker镜像的创建，还会创建一个Docker
    Compose项目，这有助于你配置Docker Compose文件，以便它们可以同时运行和部署多个Docker镜像。实际上，如果你将另一个MVC项目添加到解决方案中并为它启用容器编排器支持，新的Docker镜像将被添加到同一个Docker
    Compose文件中。
- en: The advantage of enabling Docker Compose instead of just `docker` is that you
    can manually configure how the image is run on the development machine, as well
    as how Docker image ports are mapped to external ports by editing the Docker Compose
    files that are added to the solution.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 启用Docker Compose而不是仅仅`docker`的优势在于，你可以通过编辑添加到解决方案中的Docker Compose文件来手动配置镜像在开发机器上的运行方式，以及Docker镜像端口如何映射到外部端口。
- en: If your Docker runtime has been installed properly and is running, you should
    be able to run the Docker image from Visual Studio.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的Docker运行时已正确安装并正在运行，你应该能够从Visual Studio运行Docker镜像。
- en: 'Let''s analyze the Docker file that was created by Visual Studio. It is a sequence
    of image creation steps. Each step enriches an existing image with something else
    with the help of the `From` instruction, which is a reference to an already existing
    image. The following is the first step:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析由Visual Studio创建的Docker文件。它是一系列创建镜像的步骤。每个步骤都通过`From`指令（它是对已存在镜像的引用）帮助丰富现有的镜像。以下是最初的步骤：
- en: '[PRE17]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The first step uses the `microsoft/dotnet:x.x-aspnetcore-runtime` ASP.NET Core
    runtime that was published by Microsoft in the Docker public repository (where
    `x.x` is the ASP.NET Core version that was selected in your project).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步使用了由Microsoft在Docker公共仓库中发布的`microsoft/dotnet:x.x-aspnetcore-runtime` ASP.NET
    Core运行时（其中`x.x`是你在项目中选择的ASP.NET Core版本）。
- en: 'The `WORKDIR` command creates the directory that follows the current directory
    within the image that is going to be created. If the directory doesn''t exist
    yet, it is created in the image. The two `EXPOSE` commands declare which ports
    of the image ports will be exposed outside the image and mapped to the actual
    hosting machine. Mapped ports are decided in the deployment stage either as command-line
    arguments of a Docker command or within a Docker Compose file. In our case, there
    are two ports: one for HTTP (80) and another for HTTPS (443).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`WORKDIR`命令在将要创建的镜像中创建当前目录下的目录。如果目录尚不存在，它将在镜像中创建。两个`EXPOSE`命令声明了哪些镜像端口将暴露在镜像外部并映射到实际托管机器。映射的端口在部署阶段决定，可以是Docker命令的命令行参数，也可以是在Docker
    Compose文件中。在我们的例子中，有两个端口：一个用于HTTP（80），另一个用于HTTPS（443）。'
- en: This intermediate image is cached by Docker, which doesn't need to recompute
    it since it doesn't depend on the code we write on the selected version of the
    ASP.NET Core runtime.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这个中间图像被Docker缓存，因为它不依赖于我们在选定的ASP.NET Core运行时版本上编写的代码，所以不需要重新计算它。
- en: 'The second step produces a different image that will not be used to deploy.
    Instead, it will be used to create application-specific files that will be deployed:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步生成一个不同的镜像，它将不会用于部署。相反，它将用于创建特定于应用程序的文件，这些文件将被部署：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This step starts from the ASP.NET SDK image, which contains parts we don't need
    to add for deployment; these are needed to process the project code. The new `src`
    directory is created in the `build` image and made the current image directory.
    Then, the project file is copied into `/src/MvcDockerTest`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤从ASP.NET SDK镜像开始，该镜像包含我们不需添加到部署中的部分；这些部分是处理项目代码所需的。在`build`镜像中创建新的`src`目录，并将其设置为当前镜像目录。然后，项目文件被复制到`/src/MvcDockerTest`。
- en: The `RUN` command executes an operating system command on the image. In this
    case, it calls the `dotnet` runtime, asking it to restore the NuGet packages that
    were referenced by the previously copied project file.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`RUN`命令在镜像上执行操作系统命令。在这种情况下，它调用`dotnet`运行时，请求它恢复之前复制的项目文件中引用的NuGet包。'
- en: Then, the `COPY..` command copies the whole project file tree into the `src`
    image directory. Finally, the project directory is made the current directory
    and the `dotnet` runtime is asked to build the project in release mode and copy
    all the output files into the new `/app` directory. Finally, a new image called
    **publish** executes the `publish` command on the output files.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`COPY..`命令将整个项目文件树复制到`src`镜像目录。最后，将项目目录设置为当前目录，并请求`dotnet`运行时以发布模式构建项目，并将所有输出文件复制到新的`/app`目录。最后，一个新的名为**publish**的镜像在输出文件上执行`publish`命令。
- en: 'The final step starts from the image that we created in the first step, which
    contains the ASP.NET Core runtime, and adds all the files that were published
    in the previous step:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步从我们在第一步中创建的镜像开始，该镜像包含ASP.NET Core运行时，并添加了之前步骤中发布的所有文件：
- en: '[PRE19]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `ENTRYPOINT` command specifies the operating system command that's needed
    to execute the image. It accepts an array of strings. In our case, it accepts
    the `dotnet` command and its first command-line argument, that is, the DLL we
    need to execute.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`ENTRYPOINT`命令指定执行镜像所需的操作系统命令。它接受一个字符串数组。在我们的情况下，它接受`dotnet`命令及其第一个命令行参数，即我们需要执行的DLL。'
- en: 'If we right-click on our project and click Publish, we are presented with several
    options:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们右键单击我们的项目并单击发布，我们会看到几个选项：
- en: Publish the image to an existing or new web app (automatically created by Visual
    Studio)
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将镜像发布到现有的或新的Web应用（由Visual Studio自动创建）
- en: Publish to one of several Docker registries, including a private Azure Container
    Registry that, if it doesn't already exist, can be created from within Visual
    Studio
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布到多个Docker注册表中，包括一个私有的Azure容器注册表，如果它还不存在，可以从Visual Studio内部创建。
- en: Publish to an Azure Virtual machine
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布到Azure虚拟机
- en: Docker Compose support allows you to run and publish a multi-container application
    and add further images, such as a containerized database that is available everywhere.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose支持允许您运行和发布多容器应用程序，并添加更多镜像，例如可在任何地方使用的容器化数据库。
- en: 'The following Docker Compose file adds two ASP.NET Core applications to the
    same Docker image:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Docker Compose文件将两个ASP.NET Core应用程序添加到同一个Docker镜像中：
- en: '[PRE20]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code references existing Docker files. Any environment-dependent
    information is placed in the `docker-compose.override.yml` file, which is merged
    with the `docker-compose.yml` file when the application is launched from Visual
    Studio:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码引用现有的Docker文件。任何依赖于环境的信息都放置在`docker-compose.override.yml`文件中，当应用程序从Visual
    Studio启动时，该文件与`docker-compose.yml`文件合并：
- en: '[PRE21]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: For each image, the file defines some environment variables, which will be defined
    in the image when the application is launched, the port mappings, and some host
    files.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个镜像，文件定义了一些环境变量，这些变量将在应用程序启动时在镜像中定义，端口映射和一些主机文件。
- en: The files in the host are directly mapped into the images, so if the image isn't
    projected to a host containing those files, the image won't run properly. Each
    declaration contains the path in the host, how the path is mapped in the image,
    and the desired access rights. In our case, `volumes` are used to map the self-signed
    https certificate that's used by Visual Studio and the user secrets (encrypted
    settings) that are used by ASP.NET Core.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 主机上的文件直接映射到镜像中，所以如果镜像没有映射到包含这些文件的宿主机，镜像将无法正常运行。每个声明包含宿主机中的路径，路径在镜像中的映射方式，以及期望的访问权限。在我们的例子中，使用
    `volumes` 映射了 Visual Studio 和 ASP.NET Core 所使用的自签名 https 证书以及用户密钥（加密设置）。
- en: 'Now, suppose we want to add a containerized SQL Server instance. We would need
    something like the following instructions split between `docker-compose.yml` and
    `docker-compose.override.yml`:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们想要添加一个容器化的 SQL Server 实例。我们需要像以下指令一样在 `docker-compose.yml` 和 `docker-compose.override.yml`
    之间分割：
- en: '[PRE22]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, the preceding code specifies the properties of the SQL Server container,
    as well as the SQL server''s configuration and installation parameters. More specifically,
    the preceding code contains the following information:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，前面的代码指定了 SQL Server 容器的属性，以及 SQL 服务器配置和安装参数。更具体地说，前面的代码包含以下信息：
- en: '`sql.data` is the name that''s given to the container.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sql.data` 是分配给容器的名称。'
- en: '`image` specifies where to take the image from. In our case, the image is contained
    in a public Docker registry.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image` 指定了从哪里获取镜像。在我们的例子中，镜像包含在公共 Docker 仓库中。'
- en: '`environment` specifies the environment variables that are needed by SQL Server,
    that is, the administrator password and the acceptance of a SQL Server license.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`environment` 指定了 SQL Server 需要的环境变量，即管理员密码和接受 SQL Server 许可证的协议。'
- en: As usual, `ports` specifies the port mappings.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如同往常，`ports` 指定了端口映射。
- en: '`docker-compose.override.yml` is used to run the images from within Visual
    Studio. If you need to specify parameters for either the production environment
    or the testing environment, you can add further `docker-compose-xxx.override.yml`
    files, such as `docker-compose-staging.override.yml` and `docker-compose-production.override.yml`,
    and then launch them manually in the target environment with something like the
    following code:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-compose.override.yml` 用于在 Visual Studio 内运行镜像。如果你需要为生产环境或测试环境指定参数，可以添加额外的
    `docker-compose-xxx.override.yml` 文件，例如 `docker-compose-staging.override.yml`
    和 `docker-compose-production.override.yml`，然后在目标环境中手动启动它们，如下面的代码所示：'
- en: '[PRE23]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, you can destroy all the containers with the following code:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用以下代码销毁所有容器：
- en: '[PRE24]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: While `docker-compose` has a limited capability when it comes to handling node
    clusters, it is mainly used in testing and development environments. For production
    environments, more sophisticated tools are needed, as we will see in the *Which
    tools are needed to manage microservices?* section.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `docker-compose` 在处理节点集群方面能力有限，但它主要用于测试和开发环境。对于生产环境，需要更复杂的工具，我们将在 *需要哪些工具来管理微服务？*
    这一部分中看到。
- en: Azure and Visual Studio support for microservice orchestration
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure 和 Visual Studio 对微服务编排的支持
- en: Visual Studio has a specific project template for microservice applications,
    based on the Service Fabric platform, where you can define various microservices,
    configure them, and deploy them to Azure Service Fabric, which is a microservice
    orchestrator. Azure Service Fabric will be described in more detail in the next
    section.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Visual Studio 为基于 Service Fabric 平台的微服务应用程序提供了一个特定的项目模板，你可以定义各种微服务，配置它们，并将它们部署到
    Azure Service Fabric，这是一个微服务编排器。Azure Service Fabric 将在下一节中更详细地描述。
- en: In this section, we will describe the various types of microservice you can
    define within a Service Fabric Application. A complete code example will be provided
    in the last section of this chapter. If you want to debug microservices on your
    development machine, you need to install the Service Fabric emulator listed in
    this chapter's technical requirements.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将描述你可以在 Service Fabric 应用程序中定义的微服务类型。最后一节将提供一个完整的代码示例。如果你想在开发机器上调试微服务，需要安装本章技术要求中列出的
    Service Fabric 模拟器。
- en: 'Service Fabric Applications can be found by selecting *cloud in Visual Studio
    project type drop-down filter* . Once you''ve selected the project, you can choose
    from a variety of services:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 Visual Studio 项目类型下拉筛选器中选择 *云* 可以找到 Service Fabric 应用程序。一旦选择了项目，你可以从各种服务中进行选择：
- en: '![](img/daf2b3ce-48b4-4c21-9e48-d2a24156449d.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/daf2b3ce-48b4-4c21-9e48-d2a24156449d.png)'
- en: All projects under .NET Core use a microservice model that is specific to Azure
    Service Fabric. The Guest executable adds a wrapper around an existing Windows
    application to turn it into a microservice that can run in Azure Service Fabric.
    The Container application enables the addition of any Docker image in the Service
    Fabric Application. All the other choices scaffold a template that allows you
    to code a microservice with a Service Fabric-specific pattern.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 所有.NET Core项目都使用特定于Azure Service Fabric的微服务模型。访客可执行文件在现有Windows应用程序周围添加一个包装器，将其转换为可以在Azure
    Service Fabric中运行的微服务。容器应用程序允许在Service Fabric应用程序中添加任何Docker镜像。所有其他选项都构建了一个模板，允许您使用Service
    Fabric特定的模式编写微服务。
- en: 'Once you select any of the choices in the preceding screenshot and you fill
    in all the request information, Visual Studio creates two projects: an application
    project that contains configuration information for the overall application and
    a project for the specific service you have chosen that contains both the service
    code and service-specific configuration. If you want to add more microservices
    to your application, right-click on the application project and select Add | New
    Service Fabric Service.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在先前的屏幕截图中选择任何选项并填写所有请求信息，Visual Studio将创建两个项目：一个包含整体应用程序配置信息的应用程序项目，以及一个包含所选特定服务代码和服务特定配置的项目。如果您想向应用程序添加更多微服务，请右键单击应用程序项目并选择“添加”|“新Service
    Fabric服务”。
- en: If you right-click on the solution and select Add | New project, a new Service
    Fabric application will be created instead of a new service being added to the
    already existing application.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在解决方案上右键单击并选择“添加”|“新项目”，将创建一个新的Service Fabric应用程序，而不是将新服务添加到已存在的应用程序中。
- en: 'If you select Guest Executable, you need to provide the following:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择访客可执行文件，您需要提供以下信息：
- en: A folder containing the main executable file, along with all the files it needs
    to work properly. You need this if you want to create a copy of this folder in
    your project or simply to link to the existing folder.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含主要可执行文件及其所有必要文件的文件夹。如果您想在项目中创建此文件夹的副本或简单地链接到现有文件夹，则需要此文件夹。
- en: The main executable file.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要可执行文件。
- en: Arguments to pass on the command line to that executable.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要传递给该可执行文件的命令行参数。
- en: Which folder to use as a working folder on Azure. You want to use the folder
    containing the main executable (`CodeBase`), the folder where Azure Service Fabric
    will package the whole microservice (`CodePackage`), or a new subfolder named
    `Work`.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Azure上使用哪个文件夹作为工作文件夹。您希望使用包含主要可执行文件（`CodeBase`）的文件夹，Azure Service Fabric将整个微服务打包到的文件夹（`CodePackage`），或者一个名为`Work`的新子文件夹。
- en: 'If you select Container, you need to provide the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您选择容器，您需要提供以下信息：
- en: The complete name of a Docker image in your private Azure Container Registry.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您私有Azure容器注册表中Docker镜像的完整名称。
- en: The username that will be used to connect to Azure Container Registry. The password
    will be specified manually in the same `RepositoryCredentials` XML element of
    the application configuration file that was automatically created for the username.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将用于连接到Azure容器注册表的用户名。密码将在为该用户名自动创建的应用程序配置文件中的相同`RepositoryCredentials` XML元素中手动指定。
- en: The port where you can access your service (Host Port) and the port inside the
    container the Host Port must be mapped to (Container Port). The Container Port must
    be the same port that was exposed in the Docker file and used to define the Docker
    image.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以访问服务（主机端口）的端口以及主机端口必须映射到的容器内部端口（容器端口）。容器端口必须是Docker文件中公开的相同端口，并用于定义Docker镜像。
- en: Afterward, you may need to add further manual configuration to ensure that your
    Docker application works properly. The *Further reading* section contains links
    to the official documentation where you can find more details.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，您可能需要添加进一步的手动配置以确保您的Docker应用程序能够正常工作。*进一步阅读*部分包含指向官方文档的链接，您可以在那里找到更多详细信息。
- en: There are five types of .NET Core native Service Fabric services. The Actor
    service pattern is an opinionated pattern that was conceived several years ago
    by Carl Hewitt. We will not discuss it here, but the *Further reading* section
    contains some links that provide more information on this.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 有五种类型的.NET Core原生Service Fabric服务。Actor服务模式是一种由Carl Hewitt几年前构思的具有偏见的模式。我们在此不讨论它，但*进一步阅读*部分包含一些链接，提供了更多关于此模式的信息。
- en: The remaining four patterns refer to the usage (or not) of ASP.NET Core as the
    main interaction protocol and to the fact that the service has or hasn't got an
    internal state. In fact, Service Fabric allows microservices to use distributed
    queues and dictionaries that are globally accessible to all instances of the microservice
    that declares them, independent of the hardware node where they are running (they
    are serialized and distributed to all available instances when they're needed).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的四种模式涉及ASP.NET Core作为主要交互协议的使用（或未使用），以及服务是否有内部状态。实际上，Service Fabric允许微服务使用分布式队列和字典，这些队列和字典对所有声明它们的微服务的实例都是全局可访问的，无论它们运行在哪个硬件节点上（当需要时，它们会被序列化和分布到所有可用的实例中）。
- en: 'Stateful and stateless templates differ mainly in terms of their configuration.
    All native services are classes that specify just two methods:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 有状态和无状态模板主要在配置方面有所不同。所有原生服务都是指定仅两个方法的类：
- en: '[PRE25]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `CreateServiceReplicaListeners` method specifies a list of listeners that
    are used by the microservice to receive messages and the code that handles those
    messages. Listeners may use any protocol, but they are required to specify an
    implementation of the relative socket.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '`CreateServiceReplicaListeners`方法指定了一个由微服务用来接收消息及其处理这些消息的代码的监听器列表。监听器可以使用任何协议，但它们必须指定相对套接字的实现。'
- en: '`RunAsync` contains the code for background threads that asynchronously run
    tasks that are triggered by received messages. Here, you can build a host that
    runs several hosted services.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '`RunAsync`包含后台线程的代码，这些线程异步运行由接收到的消息触发的任务。在这里，你可以构建运行多个托管服务的宿主。'
- en: ASP.NET Core templates follow the same pattern; however, they use a unique ASP.NET
    Core-based listener and no `RunAsync` implementation since background tasks can
    be launched from inside ASP.NET Core. However, you may add further listeners to
    the array of listeners returned by the `CreateServiceReplicaListeners` implementation
    created by Visual Studio, and also a custom `RunAsync` override.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ASP.NET Core模板遵循相同的模式；然而，它们使用基于ASP.NET Core的独特监听器和没有`RunAsync`实现，因为后台任务可以从ASP.NET
    Core内部启动。但是，你可以向由Visual Studio创建的`CreateServiceReplicaListeners`实现返回的监听器数组中添加更多的监听器，还可以添加自定义的`RunAsync`重写。
- en: More details on Service Fabric's native services pattern will be provided in
    the *Which tools are needed to manage microservices?* section, while a complete
    code example will be provided in the *Testing the application* section of this
    chapter, which is dedicated to this book's use case.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在“哪些工具需要用来管理微服务？”这一节中，将提供有关Service Fabric原生服务模式的更多详细信息，而在本章的“测试应用程序”部分将提供一个完整的代码示例，该部分专门用于本书的使用案例。
- en: While this section presented the tools we can use to build the code for our
    microservices, the next section describes the tools we can use to define and manage
    the clusters where our microservices will be deployed.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本节介绍了我们可以用来为我们的微服务构建代码的工具，但下一节将描述我们可以用来定义和管理微服务部署的集群的工具。
- en: Which tools are needed to manage microservices?
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哪些工具需要用来管理微服务？
- en: 'Effectively handling microservices in your CI/CD cycles requires both a private
    Docker image registry and a state of-the-art microservice orchestrator that''s
    capable of doing the following:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在CI/CD周期中有效地处理微服务需要私有Docker镜像注册库和最先进的微服务编排器，该编排器能够执行以下操作：
- en: Allocating and load-balancing microservices on available hardware nodes
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可用的硬件节点上分配和负载均衡微服务
- en: Monitoring the health state of services and replacing faulty services if hardware/software
    failures occur
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控服务的健康状态，并在硬件/软件故障发生时替换故障服务
- en: Logging and presenting analytics
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录和展示分析
- en: Allowing the designer to dynamically change requirements such as hardware nodes
    allocated to a cluster, the number of service instances, and so on
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许设计者动态更改需求，例如分配给集群的硬件节点、服务实例数量等
- en: The following subsection describes the Azure facilities we can use to store
    Docker images and to orchestrate microservices.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 以下小节描述了我们可以用来存储Docker镜像和编排微服务的Azure设施。
- en: Defining your private Docker registry in Azure
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Azure中定义你的私有Docker注册库
- en: Defining your private Docker registry in Azure is easy. Just type `Container
    registries` into the Azure search bar and select Container registries. On the
    page that appears, click on the Add button.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure中定义你的私有Docker注册库很容易。只需在Azure搜索栏中输入“容器注册库”并选择容器注册库。在出现的页面上，点击添加按钮。
- en: 'The following form will appear:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 将出现以下形式：
- en: '![](img/ebb61911-66fb-490c-ab9b-760c77695884.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebb61911-66fb-490c-ab9b-760c77695884.png)'
- en: The name you select is used to compose the overall registry URI: `<name>.azurecr.io`.
    As usual, you can specify the subscription, resource group, and location. The
    SKU dropdown lets you choose from various levels of offerings that differ in terms
    of performance, available memory, and a few other auxiliary features.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 您选择的名称用于组成整体注册表 URI：`<name>.azurecr.io`。像往常一样，您可以指定订阅、资源组和位置。SKU 下拉菜单允许您从具有不同性能、可用内存和其他一些辅助功能的各个级别中选择。
- en: If you enable Admin user, an admin user will be created whose username is `<name>`
    and whose password is created automatically by the portal; otherwise, the user
    will log in with your Azure portal credentials. Once Admin user has been selected,
    their login information will be available under the resource *Access key* menu
    item.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您启用管理员用户，将创建一个管理员用户，其用户名为 `<name>`，密码由门户自动创建；否则，用户将使用您的 Azure 门户凭据登录。一旦选择了管理员用户，其登录信息将在资源
    *访问密钥* 菜单项下可用。
- en: 'Whenever you mention image names in Docker commands or in a Visual Studio publish
    form, you must prefix its name with the registry URI: `<name>.azurecr.io/<my imagename>`.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Docker 命令或 Visual Studio 发布表单中提及镜像名称时，必须在名称前加上注册表 URI：`<name>.azurecr.io/<my
    imagename>`。
- en: If images are created with Visual Studio, then they can be published by following
    the instructions that appear once you've published the project. Otherwise, you
    must use `docker` commands to push them into your registry.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用 Visual Studio 创建镜像，则可以按照发布项目后出现的说明进行发布。否则，您必须使用 `docker` 命令将它们推送到您的注册表。
- en: 'Let''s say you have the image in another registry. The first step pulls the
    image onto your local machine:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您在其他注册表中拥有该镜像。第一步是将镜像拉到您的本地计算机上：
- en: '[PRE26]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'If there are several versions of the preceding image, the latest will be pulled
    since no version was specified. The version of the image can be specified as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前一个镜像有多个版本，由于没有指定版本，将拉取最新版本。可以按照以下方式指定镜像版本：
- en: '[PRE27]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Using the following command, you should see `myimage` within the list of local
    images:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令，您应该在本地镜像列表中看到 `myimage`：
- en: '[PRE28]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, log in to Azure by typing in the following command and providing your
    credentials:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过输入以下命令并输入您的凭据来登录 Azure：
- en: '[PRE29]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, tag the image with the path you want to assign in the Azure registry:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用您想要分配的路径在 Azure 注册表中标记镜像：
- en: '[PRE30]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Both the name and destination tag may have versions (`:<version name>`).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 名称和目标标签都可以有版本 (`:<版本名称>`）。
- en: 'Finally, push it:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，推送它：
- en: '[PRE31]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: In this case, you can specify a version; otherwise, the latest version is pushed.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您可以指定版本；否则，将推送最新版本。
- en: 'By doing this, you can remove the image from your local computer using the
    following command:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行以下命令，您应该可以在本地镜像列表中看到 `myimage`：
- en: '[PRE32]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Azure Service Fabric
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure 服务 Fabric
- en: Azure Service Fabric is the main Microsoft orchestrator that can host Docker
    containers, native .NET applications, and a distributed computing model called
    **reliable services**. We've already explained how we can create and publish applications
    that contain these three types of service in the *Azure and Visual Studio support
    for microservice orchestration* subsection. In this section, we will explain how
    to create an Azure Service Fabric cluster in the Azure portal and provide some
    more details on **reliable services**. More practical details regarding *reliable
    services* will be provided in the example described in the *Use case - logging
    microservices* section.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 服务 Fabric 是主要的 Microsoft 调度器，可以托管 Docker 容器、原生 .NET 应用程序以及称为 **可靠服务**
    的分布式计算模型。我们已经在 *Azure 和 Visual Studio 对微服务调度的支持* 子部分中解释了如何创建和发布包含这三种类型服务的应用程序。在本节中，我们将解释如何在
    Azure 门户中创建 Azure 服务 Fabric 集群，并提供有关 **可靠服务** 的更多详细信息。有关 *可靠服务* 的更多实际细节将在 *用例
    - 记录微服务* 部分的示例中提供。
- en: You can enter the Service Fabric section of Azure by typing `Service Fabric`
    into the Azure search bar and selecting Service Fabric Cluster. A multi-step wizard
    will appear. The following subsections describe the available steps.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在 Azure 搜索栏中输入 `Service Fabric` 并选择 Service Fabric Cluster 来进入 Azure 的
    Service Fabric 部分。将出现一个多步骤向导。以下子部分描述了可用的步骤。
- en: 'Step 1: Basic information'
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 1 步：基本信息
- en: 'The following screenshot shows the creation of Azure Service Fabric:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了 Azure 服务 Fabric 的创建：
- en: '![](img/f3a6d357-a608-41a5-8a8d-64a8106434a6.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3a6d357-a608-41a5-8a8d-64a8106434a6.png)'
- en: Here, you can choose the operating system, resource group, subscription, location,
    and username and password you want to use to connect the remote desktop to all
    the cluster nodes. You are required to choose a cluster name, which will be used
    to compose the cluster URI as `<cluster name>.<location>.cloudapp.azure.com`,
    where `location` is a name associated with the datacenter location you have chosen.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以选择要用于连接远程桌面到所有集群节点的操作系统、资源组、订阅、位置、用户名和密码。您必须选择一个集群名称，该名称将用于组成集群 URI，即
    `<cluster name>.<location>.cloudapp.azure.com`，其中 `location` 是与您选择的数据中心位置相关联的名称。
- en: 'Step 2: Cluster configuration'
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 2 步：集群配置
- en: 'In the second step, you can configure the number of nodes and their features:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，您可以配置节点数量及其功能：
- en: '![](img/06c97604-b097-4c3f-92eb-942c3e65149e.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/06c97604-b097-4c3f-92eb-942c3e65149e.png)'
- en: You can specify up to three node types. Nodes of a different node type can be
    scaled independently, and node type 1, called the **primary node** type, is where
    Azure Service Fabric runtime services will be hosted. For each node type, you
    can specify the type of machine (durability tier), machine dimensions (CPU and
    RAM), and the initial number of nodes.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以指定最多三种节点类型。不同节点类型的节点可以独立扩展，节点类型 1，称为**主节点**类型，是 Azure Service Fabric 运行时服务托管的地方。对于每种节点类型，您可以指定机器类型（耐久性层）、机器尺寸（CPU
    和 RAM）以及初始节点数量。
- en: You can also specify all the ports that will be visible from outside the cluster
    (Custom endpoints).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以指定所有将从集群外部可见的端口（自定义端点）。
- en: The services that are hosted on the different nodes of a cluster can communicate
    through any port since they are part of the same local network. Therefore, *Custom
    endpoints* must declare the ports that need to accept traffic from outside the
    cluster. The port that's exposed in *Custom endpoints* is the cluster's public
    interface, which can be reached through the cluster URI, that is, `<cluster name>.<location>.cloudapp.azure.com`.
    Their traffic is automatically redirected to all the microservices that have had
    the same ports opened by the cluster load balancer.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 集群不同节点上托管的服务可以通过任何端口进行通信，因为它们是同一本地网络的一部分。因此，*自定义端点*必须声明需要接受来自集群外部的流量的端口。在*自定义端点*中公开的端口是集群的公共接口，可以通过集群
    URI 访问，即 `<cluster name>.<location>.cloudapp.azure.com`。它们的流量会自动重定向到所有由集群负载均衡器打开相同端口的微服务。
- en: To understand the *enable reverse proxy* option, we must explain how communications
    are sent to several instances of services whose physical addresses change during
    their lifetimes. From within the cluster, services are identified with a URI such
    as `fabric://<application name>/<service name>`. That is, this name allows us
    to access one of the several load-balanced instances of `<service name>`. However,
    these URIs can't be used directly by communication protocols. Instead, they are
    used to get the physical URI of the required resource, along with all its available
    ports and protocols from the Service Fabric naming service.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解*启用反向代理*选项，我们必须解释如何将通信发送到在它们的生命周期中物理地址发生变化的服务的多个实例。在集群内部，服务通过 URI（如 `fabric://<application
    name>/<service name>`）进行标识。也就是说，此名称允许我们访问 `<service name>` 的几个负载均衡实例之一。然而，这些 URI
    不能直接由通信协议使用。相反，它们用于从 Service Fabric 命名服务获取所需资源的物理 URI，以及所有可用的端口和协议。
- en: Later, we will learn how to perform this operation with *reliable services*.
    However, this model is not adequate for Dockerized services that weren't conceived
    to run specifically on Azure Service Fabric since they are not aware of Service
    Fabric-specific naming services and APIs.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将学习如何使用*可靠服务*执行此操作。然而，此模型不适用于未设计在 Azure Service Fabric 上运行的 Docker 化服务，因为它们不了解
    Service Fabric 特定的命名服务和 API。
- en: 'Therefore, Service Fabric provides two more options that we can use to standardize
    URLs instead of interacting directly with its naming service:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Service Fabric 提供了两个额外的选项，我们可以使用它们来标准化 URL，而不是直接与其命名服务交互：
- en: '**DNS**: Each service can specify its `hostname` (also known as its **DNS name**).
    The DNS service takes care of translating it into the actual service URL. For
    example, if a service specifies an `order.processing` DNS name and it has an HTTP
    endpoint on port `80` and a `/purchase` path, we can reach this endpoint with
    `http://order.processing:80/purchase`.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DNS**：每个服务都可以指定其`hostname`（也称为其**DNS名称**）。DNS服务负责将其转换为实际的服务URL。例如，如果一个服务指定了`order.processing`
    DNS名称，并且它在端口`80`上有一个HTTP端点以及`/purchase`路径，我们可以通过`http://order.processing:80/purchase`访问此端点。'
- en: '**Reverse proxy:** Service Fabric''s Reverse Proxy intercepts all the calls
    that have been directed to the cluster address and uses the name service to send
    them to the right application and service within that application. Addresses that
    are resolved by the reverse proxy service have the following structure: `<cluster
    name>.<location>.cloudapp.azure.com: <port>//<app name>/<service name>/<endpoint
    path>?PartitionKey=<value> & PartitionKind=value`. Here, partition keys are used
    to optimize state, fully reliable services and will be explained at the end of
    this subsection. This means that stateless services lack the query string part
    of the previous address. Thus, a typical address that''s solved by reverse proxy
    may be something similar to `myCluster.eastus.cloudapp.azure.com: 80//myapp/myservice/<endpoint
    path>?PartitionKey=A & PartitionKind=Named`. If the preceding endpoint is called
    from a service hosted on the same cluster, we can specify `localhost` instead
    of the complete cluster name (that is, from the same cluster, not from the same
    node): `localhost: 80//myapp/myservice/<endpoint path>?PartitionKey=A & PartitionKind=Named`.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向代理**：Service Fabric的反向代理拦截所有被定向到集群地址的调用，并使用命名服务将它们发送到该应用程序内的正确应用程序和服务。由反向代理服务解析的地址具有以下结构：`<cluster
    name>.<location>.cloudapp.azure.com: <port>//<app name>/<service name>/<endpoint
    path>?PartitionKey=<value> & PartitionKind=value`。在这里，分区键用于优化状态、完全可靠的服务，将在本小节的末尾进行解释。这意味着无状态服务缺少先前地址的查询字符串部分。因此，由反向代理解决的典型地址可能类似于`myCluster.eastus.cloudapp.azure.com:
    80//myapp/myservice/<endpoint path>?PartitionKey=A & PartitionKind=Named`。如果从同一集群托管的服务调用前面的端点，我们可以指定`localhost`而不是完整的集群名称（即，来自同一集群，而不是来自同一节点）：`localhost:
    80//myapp/myservice/<endpoint path>?PartitionKey=A & PartitionKind=Named`。'
- en: By default, the DNS service is activated but the reverse proxy isn't. Therefore,
    we must enable it by checking the *Enable reverse proxy* checkbox in the second
    step of Service Fabric's configuration.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，DNS服务已激活，但反向代理未激活。因此，我们必须通过在Service Fabric配置的第二步中勾选“*启用反向代理*”复选框来启用它。
- en: 'Step 3: Security configuration'
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3步：安全配置
- en: 'Once we''ve submitted the second step, we come to a security page:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 提交第二步后，我们将进入一个安全页面：
- en: '![](img/f0decbde-2744-4755-86b1-dce6c85fa72b.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/f0decbde-2744-4755-86b1-dce6c85fa72b.png)'
- en: If we choose the basic option, the wizard creates an X509 certificate to secure
    our communication with the cluster. Otherwise, we can select an existing one from
    the Azure Key Vault. If you don't have a Key Vault, the wizard will make you create
    one so that you can store the newly created certificate. In the certificate options,
    locate the certificate usage option and select publishing/deploying. If you don't,
    you will receive an error message, along with some instructions telling you what
    to do to fix the issue.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择基本选项，向导将创建一个X509证书来保护我们与集群的通信。否则，我们可以从Azure Key Vault中选择一个现有的证书。如果您没有密钥保管库，向导将要求您创建一个，以便您可以存储新创建的证书。在证书选项中，找到证书用途选项并选择发布/部署。如果不这样做，您将收到一个错误消息，以及一些指示您如何修复问题的说明。
- en: 'Once the certificate is ready, download it onto your machine (by following
    the wizard''s instructions) and double-click on it to install it in your local
    machine. The certificate will be used to deploy applications from your machine.
    Specifically, you are required to insert the following information into the Cloud
    Publish Profile of your Visual Studio Service Fabric applications (see this chapter''s
    *Use case – logging microservices* section for more details):'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦证书准备就绪，请按照向导的说明将其下载到您的计算机上（双击安装），并在本地计算机上安装它。该证书将用于从您的计算机部署应用程序。具体来说，您需要将以下信息插入Visual
    Studio Service Fabric应用程序的云发布配置文件中（有关更多详细信息，请参阅本章的“用例 - 记录微服务”部分）：
- en: '[PRE33]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Since both the client (Visual Studio) and the server use the same certificate
    for authentication, the server and client thumbprint are the same. The certificate
    thumbprint can be copied from your Azure Key Vault. It is worth mentioning that
    you can add also client-specific certificates with the main server certificate
    by selecting the Custom option in *step 3*.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 由于客户端（Visual Studio）和服务器使用相同的证书进行身份验证，因此服务器和客户端的指纹相同。证书指纹可以从您的 Azure Key Vault
    复制。值得一提的是，您还可以通过在**步骤 3**中选择自定义选项，添加与主服务器证书一起使用的客户端特定证书。
- en: 'Once you submit your certificate, you are presented with a summary of your
    configuration. Submitting your approval will create the cluster. Pay attention
    to this: a cluster may spend your Azure free credit in a short time, so just keep
    your cluster on when you''re testing. After, you should delete it.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您提交您的证书，您将看到您的配置摘要。提交您的批准将创建集群。请注意：集群可能在短时间内消耗您的 Azure 免费信用额度，因此当您在测试时，请保持集群开启。之后，您应该将其删除。
- en: 'As we mentioned in the *Azure and Visual Studio support for microservices orchestration*
    subsection, Azure Service Fabric supports two kinds of *reliable service*: stateless
    and stateful. Stateless services either don''t store permanent data or they store
    it in external supports such as the Redis Cache or databases (see [Chapter 7](77cdecb5-cef4-4b02-80a1-052ad366b9f3.xhtml),
    *How to Choose Your Data Storage in the Cloud*, for the main storage options offered
    by Azure).'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在**Azure 和 Visual Studio 对微服务编排的支持**子节中提到的，Azure Service Fabric 支持两种类型的**可靠服务**：无状态和有状态。无状态服务要么不存储永久数据，要么将其存储在外部支持中，例如
    Redis 缓存或数据库（有关 Azure 提供的主要存储选项，请参阅第 7 章，*如何在云中选择您的数据存储*）。
- en: Stateful services, on the other hand, use Service Fabric-specific distributed
    dictionaries and queues. Each distributed data structure is accessible from all
    the *identical* replicas of a service, but only one replica, called the primary
    replica, is allowed to write on them to avoid synchronized access to those distributed
    resources, which may cause bottlenecks. All the other replicas, known as secondary
    replicas, can only be read from these distributed data structures.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 与此相反，有状态服务使用 Service Fabric 特定的分布式字典和队列。每个分布式数据结构都可以从服务的所有**相同**副本中访问，但只有一个副本，称为主副本，被允许在其上写入，以避免对这些分布式资源的同步访问，这可能会导致瓶颈。所有其他副本，称为辅助副本，只能从这些分布式数据结构中读取。
- en: You can check if a replica is primary by looking at the context object your
    code receives from the Azure Service Fabric runtime, but usually, you don't need
    to do this. In fact, when you declare your service endpoints, you are required
    to declare those that are read-only. A read-only endpoint is supposed to receive
    requests so that it can read data from the shared data structures. Therefore,
    since only read-only endpoints are activated for secondary replicas, if you implement
    them correctly, write/update operations should be automatically prevented on stateful
    secondary replicas with no need to perform further checks.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过查看代码从 Azure Service Fabric 运行时接收到的上下文对象来检查副本是否为主副本，但通常您不需要这样做。实际上，当您声明服务端点时，您需要声明那些只读的端点。只读端点应该接收请求，以便它可以从共享数据结构中读取数据。因此，由于只有只读端点被激活在辅助副本上，如果您正确实现它们，则无需进行进一步检查，写入/更新操作应该自动在有状态辅助副本上被阻止。
- en: In stateful services, secondary replicas enable parallelism on read operations,
    so in order to get parallelism on write/update operations, stateful services are
    assigned different data partitions. More specifically, for each stateful service,
    Service Fabric creates a primary instance for each partition. Then, each partition
    may have several secondary replicas.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在有状态服务中，辅助副本在读取操作上启用并行性，因此为了在写入/更新操作上获得并行性，有状态服务被分配不同的数据分区。更具体地说，对于每个有状态服务，Service
    Fabric 为每个分区创建一个主实例。然后，每个分区可能有几个辅助副本。
- en: Distributed data structures are shared between the primary instance of each
    partition and its secondary replicas. The whole extent of data that can be stored
    in a stateful service is split among the chosen number of partitions, according
    to a partition key that is generated by a hashing algorithm on the data to be
    stored.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式数据结构在分区的每个主实例及其辅助副本之间共享。有状态服务可以存储的数据总量根据要存储的数据上生成的分区键的数量来分割。
- en: Typically, partition keys are integers that belong to a given interval that
    is split among all the available partitions. For instance, a partition key can
    be generated by calling the .NET `GetHashCode()` method on one or more string
    fields to get integers that are then processed to get a unique integer (using,
    for instance, an exclusive or operation on the integer bits). Then, this integer
    can be constrained to the integer interval that was chosen for the partition key
    by taking the remainder of an integer division (for instance, the remainder of
    a division for 1,000 will be an integer in the 0-999 interval).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，分区键是整数，属于分配给所有可用分区的给定区间。例如，可以通过在.NET的`GetHashCode()`方法上对一个或多个字符串字段进行调用来生成分区键，从而得到整数，然后对这些整数进行处理以获得一个唯一的整数（例如，通过在整数位上执行异或操作）。然后，可以通过取整数除法的余数（例如，除以1,000的余数将是一个在0-999区间的整数）来将这个整数约束到为分区键选择的整数区间。
- en: 'Let''s say we want four partitions, which will be selected with an integer
    key in the 0-999 interval. Here, Service Fabric will automatically create four
    primary instances of our stateful service and assign them the following four partition
    key subintervals: 0-249, 250-499, 500-749, 750-999.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要四个分区，这些分区将通过0-999区间的整数键进行选择。在这里，Service Fabric将自动创建我们状态化服务的四个主实例，并将以下四个分区键子区间分配给它们：0-249，250-499，500-749，750-999。
- en: From within your code, you are required to compute the partition key of the
    data you send to a stateful service. Then, Service Fabric's runtime will select
    the right primary instance for you. The *Use case – logging microservices* section
    at the end of this chapter provides more practical details on this and how to
    use reliable services in practice.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的代码内部，您需要计算发送到状态化服务的数据的分区键。然后，Service Fabric的运行时将为您选择正确的首选实例。本章末尾的“用例 - 日志微服务”部分提供了更多关于此以及如何在实践中使用可靠服务的实际细节。
- en: Azure Kubernetes Service (AKS)
  id: totrans-330
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure Kubernetes Service (AKS)
- en: Kubernetes is an advanced open source orchestrator that you can install locally
    on your private machine's cluster. At the time of writing, it is the most widespread
    orchestrator, so Microsoft offers it as an alternative to Azure Service Fabric.
    Also, if you prefer Azure Service Fabric, you may be forced to use the **Azure
    Kubernetes Service** (**AKS**) since some advanced solutions (for instance, some
    big data solutions) are built on top of Kubernetes. This subsection provides a
    short introduction to AKS, but more details can by found in the official documentation,
    which is referenced in the *Further reading* section.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个高级开源编排器，您可以在本地安装到您的私有机器集群上。在撰写本文时，它是应用最广泛的编排器，因此Microsoft将其作为Azure
    Service Fabric的替代品提供。此外，如果您更喜欢Azure Service Fabric，您可能被迫使用**Azure Kubernetes Service**（**AKS**），因为一些高级解决方案（例如，一些大数据解决方案）是建立在Kubernetes之上的。本节提供了一个关于AKS的简要介绍，但更多详细信息可以在官方文档中找到，该文档在“进一步阅读”部分有引用。
- en: 'To create an AKS cluster, type `AKS` into Azure search, select Kubernetes services,
    and then click the Add button. The following form will appear:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建AKS集群，请在Azure搜索中输入`AKS`，选择Kubernetes服务，然后点击“添加”按钮。以下表单将出现：
- en: '![](img/230c287a-5924-48e3-842a-167e84e49f0c.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/230c287a-5924-48e3-842a-167e84e49f0c.png)'
- en: As usual, you are required to specify a subscription, resource group, and location.
    Then, you can choose a unique name (Kubernetes cluster name), the prefix of the
    cluster URI (DNS name prefix), and the version of Kubernetes you would like to
    use. For computational power, you are asked to select a machine template for each
    node (Node size) and the number of nodes. If you click Next, you can provide security
    information, namely a *service principal*, and specify whether you wish to enable
    role-based access control. In Azure, service principals are accounts that are
    associated with services you may use to define resource access policies. If you
    have no experience with this concept and/or if you don't have any preexisting
    service principals, you can let the wizard create one for you.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，您需要指定订阅、资源组和位置。然后，您可以选择一个唯一的名称（Kubernetes集群名称）、集群URI的前缀（DNS名称前缀）以及您想要使用的Kubernetes版本。为了计算能力，您需要为每个节点选择一个机器模板（节点大小）和节点数量。如果您点击“下一步”，您可以提供安全信息，即一个*服务主体*，并指定您是否希望启用基于角色的访问控制。在Azure中，服务主体是与您可能使用的服务关联的账户，您可以使用它来定义资源访问策略。如果您没有这方面的经验，或者您没有现有的服务主体，可以让向导为您创建一个。
- en: There are other settings you can change too, but the default values work well.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以更改其他设置，但默认值效果良好。
- en: 'Once you''ve created the Kubernetes cluster, you can interact with it through
    the `kubectl` command-line tool. `kubectl` is integrated into the Azure console,
    so you need just to activate your cluster credentials. Select the Azure console
    at the top of the page portal and then type in the following command:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了 Kubernetes 集群，您就可以通过 `kubectl` 命令行工具与之交互。`kubectl` 集成到 Azure 控制台中，因此您只需激活您的集群凭据。在页面门户的顶部选择
    Azure 控制台，然后输入以下命令：
- en: '[PRE34]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The preceding command downloads the credentials that were automatically created
    to enable your interaction with the cluster and configures the Kubernetes CLI
    so that it can use them.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令下载了自动创建的凭据，以启用您与集群的交互，并配置 Kubernetes CLI 以使用它们。
- en: Then, if you write `kubectl get nodes`, you should get a list of available Kubernetes
    nodes.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果您编写 `kubectl get nodes`，您应该会得到一个可用的 Kubernetes 节点列表。
- en: 'Docker images can be loaded into the cluster and configured by writing a `.yaml`
    configuration file, such as `myClusterConfiguration.yaml`, and typing the following:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过编写一个 `.yaml` 配置文件（例如 `myClusterConfiguration.yaml`）并将以下命令输入到集群中来将 Docker
    镜像加载到集群中并进行配置：
- en: '[PRE35]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: You can create and edit this file by writing `nano` on the Azure console to
    launch the nano editor. Once you're in the editor, you can paste content from
    a local file and then save it.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在 Azure 控制台中输入 `nano` 来创建和编辑此文件，以启动 nano 编辑器。一旦进入编辑器，您可以从本地文件粘贴内容，然后保存它。
- en: 'The preceding command deploys the application and runs it. The deployment state
    can be monitored with the following command:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令部署了应用程序并运行它。可以使用以下命令监控部署状态：
- en: '[PRE36]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Here, `MyDeployment` is the name that's given to deployment in the `.yaml` file.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`MyDeployment` 是在 `.yaml` 文件中分配给部署的名称。
- en: 'When the cluster is no longer needed, you can delete it with the following
    command:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 当集群不再需要时，您可以使用以下命令将其删除：
- en: '[PRE37]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The application state can be monitored by selecting Insights from the resource
    Azure menu. Here, you can apply filters and select the information you need.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过从资源 Azure 菜单中选择洞察来监控应用程序状态。在这里，您可以应用过滤器并选择您所需的信息。
- en: '`.yaml` files have the same structure as JSON files but they have a different
    syntax. You have objects and lists but object properties are not surrounded by
    `{}` and lists are not surrounded by `[]`. Instead, nested objects are declared
    by simply indenting their content with spaces. The number of spaces can be freely
    chosen, but once they''ve been chosen, they must be used coherently.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`.yaml` 文件的结构与 JSON 文件相同，但它们的语法不同。您有对象和列表，但对象的属性不需要用 `{}` 包围，列表也不需要用 `[]` 包围。相反，通过简单地使用空格缩进来声明嵌套对象的内容。空格的数量可以自由选择，但一旦选择，就必须连贯地使用。'
- en: List items can be distinguished from object properties by preceding them with
    a hyphen (`-`). `.yaml` files can contain several sections that are separated
    by a line containing the `---` string. Typically, you define a `Deployment` that
    describes which images to deploy and how many replicas they must have. Each deployment
    groups a set of images to be deployed together on the same node, which means that
    each replica that's deployed in any node must have all those images installed.
    A set of images to be deployed together is called a **pod**.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 列表项可以通过在它们前面加上破折号（`-`）来与对象属性区分开来。`.yaml` 文件可以包含多个由包含 `---` 字符串的行分隔的章节。通常，您定义一个
    `Deployment` 来描述要部署哪些镜像以及它们必须有多少个副本。每个部署将一组要一起部署到同一节点上的镜像分组在一起，这意味着在任意节点上部署的每个副本都必须安装所有这些镜像。要一起部署的镜像集称为
    **pod**。
- en: 'For instance, the following configuration deploys two replicas of a single
    image pod:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下配置部署了一个包含单个镜像的 pod 的两个副本：
- en: '[PRE38]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The initial header declares the Kubernetes API version to use and the kind of
    object we are going to define (a deployment), and assigns a name to the object.
    The deployment name can be used at a later time to modify the cluster with deployment
    edit commands.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 初始头声明了要使用的 Kubernetes API 版本和我们将要定义的对象类型（一个部署），并为对象分配一个名称。部署名称可以在以后使用部署编辑命令来修改集群。
- en: '[PRE39]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: On the other hand, the `spec` attribute under the template lists all the containers
    that will compose each replica of the pod.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，模板下的 `spec` 属性列出了将组成每个 pod 副本的所有容器。
- en: In turn, each container has a name and specifies the Docker image to be used
    to instantiate it. Then, it specifies the average computational resources that
    are needed and their maximum limits. Finally, it specifies the ports that are
    exposed externally. These ports are not forwarded to a different port and are
    exposed as they are. This port setting overrides the EXPOSE Docker file setting.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，每个容器都有一个名称，并指定用于实例化的Docker镜像。接着，它指定所需的平均计算资源及其最大限制。最后，它指定外部暴露的端口。这些端口不会转发到不同的端口，而是直接暴露。此端口设置覆盖了Docker文件中的EXPOSE设置。
- en: Finally, we can specify some environment variables to set inside each container.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以指定一些要在每个容器内部设置的环境变量。
- en: 'Since there are several replicas of the same services located on different
    nodes, and since allocating services to nodes may change dynamically, there is
    a problem when it comes to internal communication among pods and internal-to-external
    communication. This problem is solved by defining services that offer a unique
    entry point for all instances of a pod. A service definition can be added to the
    same `.yaml` file, separated by `---`:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 由于同一服务在不同节点上有多个副本，并且分配服务到节点可能会动态变化，因此在Pod之间的内部通信以及内部到外部的通信中存在一个问题。这个问题通过定义提供所有Pod实例唯一入口点的服务来解决。可以在同一个`.yaml`文件中添加服务定义，并用`---`分隔：
- en: '[PRE40]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The preceding definition creates a service that's exposed on port `8080`, which
    redirects all requests to port `80` of a `MyApplication` replica. The pod that's
    served by the service is selected by the `selector` property. The service IP is
    internally visible, but client pods don't need to know the service IP since the
    services can be reached through their names, just like hosts in a classic network.
    Thus, in this case, `MyApplication-service:8080` does the job.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 上述定义创建了一个在端口`8080`上暴露的服务，该服务将所有请求重定向到`MyApplication`副本的端口`80`。由该服务提供服务的Pod是通过`selector`属性选择的。服务IP在内部可见，但客户端Pod不需要知道服务IP，因为可以通过名称访问服务，就像经典网络中的主机一样。因此，在这种情况下，`MyApplication-service:8080`就完成了这项工作。
- en: 'If we need a publicly accessible IP, we need to add `type: LoadBalancer` under
    `spec` before `ports`. AKS will select a public IP for you. We can get the chosen
    public IP by watching the deployment process with `kubectl get service MyDeployment
    --watch` until the IP is selected. If we bought an IP address in the same resource
    group as AKS, we can specify this IP address by adding `clusterIP: <your IP>`
    under the service `spec`.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '如果我们需要一个公开可访问的IP，我们需要在`spec`下的`ports`之前添加`type: LoadBalancer`。AKS将为您选择一个公共IP。我们可以通过使用`kubectl
    get service MyDeployment --watch`监视部署过程来获取所选的公共IP，直到IP被选中。如果我们已经在与AKS相同的资源组中购买了IP地址，我们可以在服务`spec`下通过添加`clusterIP:
    <your IP>`来指定此IP地址。'
- en: 'Pods can be organized into namespaces if we create namespaces in our `.yaml`
    files:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在`.yaml`文件中创建命名空间，Pod可以被组织到命名空间中：
- en: '[PRE41]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Then, you can target objects (services or deployments) in a namespace by adding
    `namespace: <your namespace>` after its name in its definition metadata. Similarly,
    you can target `kubectl` commands in a specific namespace by adding them with
    the `-- namespace=<your namespace>` option.'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，您可以通过在其定义元数据中的名称后添加`namespace: <your namespace>`来在命名空间中定位对象（服务或部署）。同样，您可以通过添加`--namespace=<your
    namespace>`选项来在特定命名空间中定位`kubectl`命令。'
- en: The use case in the next section will provide more details when it comes to
    defining a Service Fabric application. More details on Kubernetes clusters can
    be found in the references listed in the *Further reading* section.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个用例将提供更多关于定义Service Fabric应用程序的详细信息。有关Kubernetes集群的更多详细信息，可以在*进一步阅读*部分找到的参考资料中找到。
- en: Use case – logging microservices
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例 - 日志微服务
- en: In this section, we will take a look at a microservice-based system that logs
    data about purchases relating to various destinations in our WWTravelClub use
    case. In particular, we will design microservices that takes care of computing
    daily revenues per location. Here, we're assuming that these microservices receive
    data from other subsystems hosted in the same Azure Service Fabric application.
    More specifically, each purchase log message is composed of the location name,
    the overall package cost, and the date and time of the purchase.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一个基于微服务的系统，该系统记录了我们WWTravelClub用例中与各种目的地相关的购买数据。特别是，我们将设计负责计算每个位置每日收入的微服务。在这里，我们假设这些微服务从同一Azure
    Service Fabric应用程序中托管的其他子系统接收数据。更具体地说，每个购买日志消息由位置名称、整体套餐成本以及购买日期和时间组成。
- en: As a first step, let's ensure that the Service Fabric emulator that we mentioned
    in the *Technical requirements* section of this chapter has been installed and
    is running on your development machine. Now, we need so switch it so that it runs
    **5 nodes**.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，让我们确保我们在本章 *技术要求* 部分中提到的 Service Fabric 模拟器已经安装并正在您的开发机器上运行。现在，我们需要将其切换，以便它运行
    **5 个节点**。
- en: Now, we can follow the steps we explained in the *Azure and Visual Studio support
    for microservice orchestration* section to create a Service Fabric project named
    `PurchaseLogging`. Select a .NET Core stateful reliable service and name it `LogStore`.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以按照我们在 *Azure 和 Visual Studio 对微服务编排的支持* 部分中解释的步骤来创建一个名为 `PurchaseLogging`
    的 Service Fabric 项目。选择一个 .NET Core 有状态可靠服务，并将其命名为 `LogStore`。
- en: The solution that's created by Visual Studio is composed of a `PurchaseLogging`
    project, which represents the overall application, and a `LogStore` project, which
    will contain the implementation of the first microservice that's included in the
    `PurchaseLogging` application.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Visual Studio 创建的解决方案由一个 `PurchaseLogging` 项目组成，它代表整个应用程序，以及一个 `LogStore`
    项目，该项目将包含 `PurchaseLogging` 应用程序中包含的第一个微服务的实现。
- en: 'Under the `PackageRoot` folder, the `LogStore` service and each reliable service
    contain the `ServiceManifest.xml` configuration file and a `Settings.xml` folder
    (under the `Config` subfolder). The `Settings.xml` folder contains some settings
    that you can read from the service code. The initial file contains predefined
    settings that are needed by the Service Fabric runtime. Let''s add a new settings
    section, as shown in the following code:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `PackageRoot` 文件夹下，`LogStore` 服务和每个可靠服务都包含一个 `ServiceManifest.xml` 配置文件和一个
    `Settings.xml` 文件夹（位于 `Config` 子文件夹下）。`Settings.xml` 文件夹包含一些可以从服务代码中读取的设置。初始文件包含
    Service Fabric 运行时所需的预定义设置。让我们添加一个新的设置部分，如下面的代码所示：
- en: '[PRE42]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: We will use the value of `MessageMaxDelaySeconds` to configure the system component
    and ensure message idempotency. The setting value is empty, because most of the
    settings are overridden by the overall application settings contained in the `PurchaseLogging`
    project.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `MessageMaxDelaySeconds` 的值来配置系统组件并确保消息幂等性。设置值是空的，因为大多数设置都被包含在 `PurchaseLogging`
    项目中的整体应用程序设置覆盖了。
- en: 'The `ServiceManifest.xml` file contains some configurations tags that are automatically
    handled by Visual Studio, as well as a list of endpoints. Two endpoints are preconfigured
    since they are used by the Service Fabric runtime. Here, we must add the configuration
    details of all the endpoints our microservice will listen to. Each endpoint definition
    has the following format:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '`ServiceManifest.xml` 文件包含一些由 Visual Studio 自动处理的配置标签以及端点列表。由于它们由 Service Fabric
    运行时使用，因此已预配置了两个端点。在这里，我们必须添加我们的微服务将监听的端点的配置细节。每个端点定义具有以下格式：'
- en: '[PRE43]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: If `Type` is `Internal`, the port will be opened just inside the cluster's local
    network; otherwise, the port will be available from outside the cluster as well.
    In the preceding case, we must declare that port in the configuration of the Azure
    Service Fabric cluster as well, otherwise the cluster load balancer/firewall will
    not forward messages to it.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `Type` 是 `Internal`，则端口将在集群的本地网络内部打开；否则，端口也将对外部集群可用。在前一种情况下，我们必须在 Azure Service
    Fabric 集群的配置中声明该端口，否则集群负载均衡器/防火墙不会将消息转发到它。
- en: Public ports can be reached directly from the cluster URI (`<cluster name>.<location
    code>.cloudapp.azure.com`) since the load balancer that interfaces each cluster
    will forward the input traffic it receives to them.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 公共端口可以直接从集群 URI (`<cluster name>.<location code>.cloudapp.azure.com`) 访达，因为接口每个集群的负载均衡器将接收到的输入流量转发到它们。
- en: In this example, we won't define endpoints since we are going to use remoting-based
    communication, which has already been defined, for all internal interactions,
    but we will show you how to use them.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们不会定义端点，因为我们打算使用基于远程通信的通信，这已经定义好了，用于所有内部交互，但我们将向您展示如何使用它们。
- en: 'The `PurchaseLogging` project contains a reference to the `LogStore` project
    under the *services* Solution Explorer node and contains various folders with
    various XML configuration files. More specifically, we have the following folders:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '`PurchaseLogging` 项目在 *services* 解决方案资源管理器节点下包含对 `LogStore` 项目的引用，并包含各种文件夹，其中包含各种
    XML 配置文件。更具体地说，我们有以下文件夹：'
- en: '`ApplicationPackageRoot`, which contains the overall application manifest named
    `ApplicationManifest.xml`. This file contains some initial parameter definitions
    and then further configurations. Parameters have the following format:'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ApplicationPackageRoot`，其中包含名为 `ApplicationManifest.xml` 的整体应用程序清单。此文件包含一些初始参数定义，然后是进一步的配置。参数具有以下格式：'
- en: '[PRE44]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Once defined, parameters can replace any value in the remainder of the file.
    Parameter values are referenced by enclosing the parameter name between square
    brackets, as shown in the following code:'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦定义，参数就可以替换文件其余部分中的任何值。参数值通过在方括号中包围参数名称来引用，如下面的代码所示：
- en: '[PRE45]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Some parameters define the number of replicas and partitions for each service
    and are automatically created by Visual Studio:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 一些参数定义了每个服务的副本和分区数量，并由 Visual Studio 自动创建：
- en: '[PRE46]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Let's replace the initial values suggested by Visual Studio with those in the
    preceding code. We will use just two partitions to show you how partitions work,
    but you can increase this value to improve write/update parallelism. Each partition
    of the `LogStore` service doesn't need several replicas since replicas improve
    performance on read operations and this service is not designed to offer read
    services. Therefore, you may choose just one replica, or at most two, to make
    the system redundant and more robust to failures.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用前面代码中的值替换 Visual Studio 建议的初始值。我们将使用两个分区来向您展示分区是如何工作的，但您可以将此值增加以提高写/更新并行性。`LogStore`
    服务的每个分区不需要多个副本，因为副本可以提高读取操作的性能，而这个服务不是设计来提供读取服务的。因此，您可以选择仅使用一个副本，或者最多两个副本，以使系统冗余并提高对失败的鲁棒性。
- en: 'The preceding parameters are used to define the role of the `LogStore` service
    inside the overall application. This definition is generated automatically by
    Visual Studio in the same file, below the initial definition created by Visual
    studio, with just the partition interval changed to 0-1,000:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 上述参数用于定义 `LogStore` 服务在整体应用程序中的角色。此定义由 Visual Studio 自动生成，在同一文件中，在 Visual Studio
    创建的初始定义下方，只是将分区间隔更改为 0-1,000：
- en: '[PRE47]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`ApplicationParameters` contains possible overrides for parameters defined
    in `ApplicationManifest.xml` for various deployment environments: the cloud (that
    is, the actual Azure Service Fabric cluster) and local emulators with one or five
    nodes.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ApplicationParameters` 包含对 `ApplicationManifest.xml` 中定义的参数的可能的覆盖，适用于各种部署环境：云（即实际的
    Azure Service Fabric 集群）和具有一个或五个节点的本地仿真器。'
- en: '`PublishProfiles` contains the settings that are needed to publish the application
    in the same environments handled by the `ApplicationParameters` folder. You just
    need to customize the cloud publish profile with the actual name of your Azure
    Service Fabric URI and with the authentication certificate you downloaded during
    the Azure cluster configuration process:'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PublishProfiles` 包含发布应用程序所需的设置，这些设置由 `ApplicationParameters` 文件夹处理的环境所处理。您只需自定义云发布配置文件，使用您在
    Azure 集群配置过程中下载的实际 Azure Service Fabric URI 名称，以及您在 Azure 集群配置过程中下载的认证证书：'
- en: '[PRE48]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The remaining steps that need to be followed in order to complete the application
    have been organized into several subsections. Let's start by looking at ensuring
    message idempotency.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成应用程序，需要遵循的剩余步骤已被组织成几个子节。让我们首先看看如何确保消息幂等性。
- en: Ensuring message idempotency
  id: totrans-393
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保消息幂等性
- en: Messages can become lost because of failures or small timeouts caused by load
    balancing. Here, we will use a predefined remoting-based communication that performs
    automatic message retries in the case of failures. However, as we explained in
    the *Microservice design principles* subsection, this may cause the same messages
    to be received twice. Since we are summing up the revenues of purchase orders,
    we must protect ourselves from summing up the same purchase several times.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 消息可能会因为故障或由负载均衡引起的小超时而丢失。在这里，我们将使用基于远程通信的预定义通信，在发生故障的情况下自动重试消息。然而，正如我们在 *微服务设计原则*
    子节中解释的那样，这可能会导致相同的消息被接收两次。由于我们正在汇总采购订单的收入，我们必须防止多次汇总相同的采购订单。
- en: To do this, we will implement a library containing the necessary tools to ensure
    that message replicas are discarded.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将实现一个包含确保消息副本被丢弃所需工具的库。
- en: Let's add a new .NET Standard 2.0 library project called **IdempotencyTools**
    to our solution. Now, we can remove the initial class scaffolded by Visual studio.
    This library needs a reference to the same version of the `Microsoft.ServiceFabric.Services`
    NuGet package referenced by `LogStore`, so let's verify the version number and
    add the same NuGet package reference to the `IdempotencyTools` project.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在解决方案中添加一个新的.NET Standard 2.0库项目，命名为**IdempotencyTools**。现在，我们可以移除Visual
    Studio生成的初始类框架。这个库需要引用与`LogStore`相同的版本的`Microsoft.ServiceFabric.Services` NuGet包，所以让我们验证版本号并将相同的NuGet包引用添加到`IdempotencyTools`项目中。
- en: 'The main tool that ensures message idempotency is the `IdempotentMessage` class:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 确保消息幂等的主体工具是`IdempotentMessage`类：
- en: '[PRE49]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We added the `DataContract` and `DataMember` attributes since they are needed
    by the remoting communication serializer we are going to use for all internal
    messages. Basically, the receding class is a wrapper that adds a `Guid` and a
    time mark to the message class instance that's passed to its constructor.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了`DataContract`和`DataMember`属性，因为它们是我们将要用于所有内部消息的远程通信序列化器所需的。基本上，退行类是一个包装器，它向传递给其构造函数的消息类实例添加一个`Guid`和时间标记。
- en: The `IdempotencyFilter` class uses a distributed dictionary to keep track of
    the messages it's already received. To avoid the indefinite growth of this dictionary,
    older entries are periodically deleted. Messages that are too old to be found
    in the dictionary are automatically discarded.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '`IdempotencyFilter`类使用分布式字典来跟踪它已经接收到的消息。为了避免这个字典无限增长，定期删除较旧的条目。太旧以至于在字典中找不到的消息将自动丢弃。'
- en: 'The time interval entries are kept in the dictionary and are passed in the
    `IdempotencyFilter` static factory method, which creates new filter instances,
    along with the dictionary name and the `IReliableStateManager` instance, which
    are needed to create the distributed dictionary:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 时间间隔条目被保存在字典中，并通过`IdempotencyFilter`静态工厂方法传递，该方法创建新的过滤器实例，以及创建分布式字典所需的字典名称和`IReliableStateManager`实例：
- en: '[PRE50]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The dictionary contains each message time mark indexed by the message `Guid`
    and is created by invoking the `GetOrAddAsync` method of the `IReliableStateManager`
    instance with the dictionary type and name. `lastClear` contains the time of the
    removal of all old messages.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 字典包含每个消息时间标记，按消息`Guid`索引，通过调用`IReliableStateManager`实例的`GetOrAddAsync`方法创建，该方法带有字典类型和名称。`lastClear`包含所有旧消息移除的时间。
- en: 'When a new message arrives, the `NewMessage` method checks whether it must
    be discarded. If the message must be discarded, it returns `null`; otherwise,
    it adds the new message to the dictionary and returns the message without the
    `IdempotentMessage` wrapper:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 当收到新消息时，`NewMessage`方法检查是否必须丢弃该消息。如果必须丢弃该消息，则返回`null`；否则，将新消息添加到字典中，并返回不带`IdempotentMessage`包装器的新消息：
- en: '[PRE51]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'As a first step, the method verifies whether it''s time to clear the dictionary
    and whether the message is too old. Then, it starts a transaction to access the
    dictionary. All distributed dictionary operations must be enclosed in a transaction,
    as shown in the following code:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，该方法验证是否是清除字典的时候，以及消息是否过于陈旧。然后，它开始一个事务来访问字典。所有分布式字典操作都必须在事务中封装，如下面的代码所示：
- en: '[PRE52]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: If the message `Guid` is found in the dictionary, the transaction is aborted
    since the dictionary doesn't need to be updated and the method returns `default(T)`,
    which is actually `null` since the message must not be processed. Otherwise, the
    message entry is added to the dictionary and the unwrapped message is returned.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在字典中找到消息`Guid`，则由于字典不需要更新，方法返回`default(T)`，实际上为`null`，因为消息不得被处理。否则，将消息条目添加到字典中，并返回未包装的消息。
- en: The code of the `Clear` method can be found in the GitHub repository associated
    with this book.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '`Clear`方法的代码可以在与本书相关的GitHub仓库中找到。'
- en: The Interaction library
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交互库
- en: There are some types that must be shared among all microservices. If the internal
    communication is implemented with either remoting or WCF, each microservice must
    expose an interface with all the methods other microservices call. Such interfaces
    must be shared among all microservices. Moreover, with all communication interfaces,
    the classes that implement the messages must also be shared among all microservices
    (or among some subsets of them). Therefore, all of these structures are declared
    in external libraries that are referenced by the microservices.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些类型必须在所有微服务之间共享。如果内部通信是通过远程或WCF实现的，每个微服务都必须公开一个接口，包含其他微服务调用的所有方法。这些接口必须在所有微服务之间共享。此外，对于所有通信接口，实现消息的类也必须在所有微服务（或它们的一些子集）之间共享。因此，所有这些结构都声明在外部库中，这些库被微服务引用。
- en: Now, let's add a new .NET Standard 2.0 library project called `Interactions`
    to our solution. Since this library must use the `IdempotentMessage` generic class,
    we must add it as a reference to the `IdempotencyTools` project. We must also
    add a reference to the remoting communication library contained in the `Microsoft.ServiceFabric.Services.Remoting`
    NuGet package since all interfaces that are used to expose the microservice's
    remote methods must inherit from the `IService` interface defined in this package.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们向我们的解决方案中添加一个新的.NET Standard 2.0库项目，命名为`Interactions`。由于这个库必须使用`IdempotentMessage`泛型类，我们必须将其作为引用添加到`IdempotencyTools`项目中。我们还需要添加对包含在`Microsoft.ServiceFabric.Services.Remoting`
    NuGet包中的远程通信库的引用，因为所有用于公开微服务远程方法的接口都必须继承自该包中定义的`IService`接口。
- en: '`IService` is an empty interface that declares the communication role of the
    inheriting interface. The `Microsoft.ServiceFabric.Services.Remoting` NuGet package
    version must match the version of the `Microsoft.ServiceFabric.Services` package
    declared in the other projects.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '`IService`是一个空接口，它声明了继承接口的通信角色。`Microsoft.ServiceFabric.Services.Remoting`
    NuGet包的版本必须与在其他项目中声明的`Microsoft.ServiceFabric.Services`包的版本相匹配。'
- en: 'The following code shows the declarations of the interface that need to be
    implemented by the `LogStore` class:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了需要由`LogStore`类实现的接口的声明：
- en: '[PRE53]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The following is the code of the `PurchaseInfo` message class, which is referenced
    in the `ILogStore` interface:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 以下为`PurchaseInfo`消息类的代码，该代码在`ILogStore`接口中被引用：
- en: '[PRE54]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Now, we are ready to implement our main `LogStore` microservice.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好实现我们的主要`LogStore`微服务。
- en: Implementing the receiving side of communication
  id: totrans-419
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现通信的接收端
- en: 'To implement the `LogStore` microservice, we must add a reference to the `Interaction`
    library, which will automatically create references to the remoting library and
    to the `IdempotencyTools` project. Then, the `LogStore` class must implement the
    `ILogStore` interface:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现`LogStore`微服务，我们必须添加对`Interaction`库的引用，这将自动创建对远程库和对`IdempotencyTools`项目的引用。然后，`LogStore`类必须实现`ILogStore`接口：
- en: '[PRE55]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Once the service receives a `LogPurchase` call from the remoting runtime, it
    puts the message in the `LogQueue` to avoid the caller remaining blocked, waiting
    for message processing completion. This way, we achieve both the reliability of
    a synchronous message passing protocol (the caller knows that the message has
    been received) and the performance advantages of asynchronous message processing
    that are typical of asynchronous communication.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务从远程运行时接收到`LogPurchase`调用，它将消息放入`LogQueue`以避免调用者保持阻塞，等待消息处理完成。这样，我们既实现了同步消息传递协议的可靠性（调用者知道消息已被接收），又实现了异步通信典型的异步消息处理的性能优势。
- en: '`LoqQueue`, as a best practice for all distributed collections, is created
    in the `RunAsync` method, so `LogQueue` may be null if the first call arrives
    before the Azure Service Fabric runtime has called `RunAsync`. In this case, the
    method returns `false` to signal that the service isn''t ready yet. Otherwise,
    a transaction is created to enqueue the new message.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 根据`LoqQueue`作为所有分布式集合的最佳实践，它在`RunAsync`方法中被创建，因此如果第一个调用在Azure Service Fabric运行时调用`RunAsync`之前到达，`LogQueue`可能为null。在这种情况下，该方法返回`false`以表示服务尚未准备好。否则，将创建一个事务以入队新消息。
- en: 'However, our service will not receive any communication if we don''t furnish
    an implementation of `CreateServiceReplicaListeners()` that returns all the listeners
    that the service would like to activate. In the case of remoting communications,
    there is a predefined method that performs the whole job, so we just need to call
    it:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们不提供一个返回服务希望激活的所有听众的`CreateServiceReplicaListeners()`实现，我们的服务将不会收到任何通信。在远程通信的情况下，有一个预定义的方法执行整个任务，所以我们只需调用它：
- en: '[PRE56]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Here, `CreateServiceRemotingReplicaListeners` is an extension method defined
    in the remoting communication library. It creates listeners for both primary replicas
    and secondary replicas (for read-only operations). When creating the client, we
    can specify whether its communications are addressed just to primary replicas
    or also to secondary replicas.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`CreateServiceRemotingReplicaListeners`是在远程通信库中定义的一个扩展方法。它为主副本和辅助副本（用于只读操作）创建监听器。在创建客户端时，我们可以指定其通信是否仅针对主副本，还是也针对辅助副本。
- en: 'If you would like to use different listeners, you must create an `IEnumerable`
    of `ServiceReplicaListener` instances. For each listener, you must invoke the
    `ServiceReplicaListener` constructor with three arguments:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想使用不同的听众，您必须创建一个`IEnumerable`的`ServiceReplicaListener`实例。对于每个听众，您必须使用三个参数调用`ServiceReplicaListener`构造函数：
- en: A function that receives the reliable service context object as its input and
    returns an implementation of the `ICommunicationListener` interface.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个函数，它接收可靠的服务上下文对象作为输入，并返回`ICommunicationListener`接口的实现。
- en: The name of the listener. This second argument becomes obligatory when the service
    has more than one listener.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 听众的名称。当服务拥有多个听众时，这个第二个参数变为必需。
- en: A Boolean that is true if the listener must be activated on secondary replicas.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个布尔值，如果听众必须在辅助副本上激活则为真。
- en: 'For instance, if we would like to add both custom and HTTP listeners, the code
    becomes something like the following:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想添加自定义和HTTP监听器，代码可能如下所示：
- en: '[PRE57]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '`MyCustomHttpListener` is a custom implementation of `ICommunicationListener`,
    while `KestrelCommunicationListener` is a predefined HTTP listener based on Kestrel
    and ASP.NET Core. The following is the full code that defines the `KestrelCommunicationListener`
    listener:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: '`MyCustomHttpListener`是`ICommunicationListener`的自定义实现，而`KestrelCommunicationListener`是基于Kestrel和ASP.NET
    Core的预定义HTTP监听器。以下是完全定义`KestrelCommunicationListener`监听器的代码：'
- en: '[PRE58]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Usually, `ICommunicationListener` implementations accept the node context and
    an endpoint name in their constructors and are responsible for reading the endpoint
    data defined in the `ServiceManifest.xml` service, as well as creating a listening
    endpoint that satisfies the specification contained there. They do this in their
    `CommunicationListener.OpenAsync` method:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，`ICommunicationListener`实现在其构造函数中接受节点上下文和一个端点名称，并负责读取`ServiceManifest.xml`服务中定义的端点数据，以及创建满足其中包含的规范的监听端点。它们在其`CommunicationListener.OpenAsync`方法中这样做：
- en: '[PRE59]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '`<computedURISchema>` is the URI with the IP address replaced by a "+". Once
    returned by `OpenAsync`, it is published in the Service Fabric naming service
    and used to compute the actual service address from the cluster node IP address
    it''s been deployed in.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '`<computedURISchema>`是将IP地址替换为"+"的URI。一旦通过`OpenAsync`返回，它将在服务 Fabric 命名服务中发布，并用于从已部署在其上的集群节点IP地址计算实际服务地址。'
- en: '`ICommunicationListener` implementations must also have a `Close` method, which
    must close the opened communication channel, and an `Abort` method, which must
    **immediately** close the communication channel (ungracefully, that is, without
    informing connected clients and so on).'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '`ICommunicationListener`实现还必须有一个`Close`方法，它必须关闭打开的通信通道，以及一个`Abort`方法，它必须**立即**关闭通信通道（即不通知连接的客户端等）。'
- en: Now that we have turned communications on, we can implement the service logic.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经开启了通信，我们可以实现服务逻辑。
- en: Implementing service logic
  id: totrans-440
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现服务逻辑
- en: Service logic is executed by the tasks that are launched as independent threads
    when `RunAsync` is invoked by the Service Fabric runtime. It's good practice to
    create an `IHost` and design all the tasks as `IHostedService` implementations
    when you only need to implement one task. In fact, `IHostedService` implementations
    are independent chunks of software that are easier to unit-test. `IHost` and `IHostedService`
    were discussed in detail in the *Using generic hosts* subsection.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 服务逻辑由在Service Fabric运行时调用`RunAsync`时启动的独立线程的任务执行。当只需要实现一个任务时，创建一个`IHost`并将所有任务设计为`IHostedService`实现是良好的实践。实际上，`IHostedService`实现是独立的软件块，更容易进行单元测试。"IHost"和"IHostedService"在*使用通用宿主*小节中进行了详细讨论。
- en: 'In this section, we will implement the logic that computes daily revenues for
    each location into an `IHostedservice` named `ComputeStatistics`, which uses a
    distributed dictionary whose keys are the location names and whose values are
    instances of a class called `RunningTotal`. This class stores the current running
    total and the day that is being computed:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现将每日收入计算逻辑实现为名为`ComputeStatistics`的`IHostedservice`，它使用一个分布式字典，其键是位置名称，值是名为`RunningTotal`的类的实例。这个类存储当前的运行总计数和正在计算的天：
- en: '[PRE60]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'This class has an `Update` method that updates the instance when a new purchase
    message is received. First of all, the incoming message time is normalized to
    universal time. Then, the day part of this time is extracted and compared with
    the current `Day` of the running total, as shown in the following code:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类有一个`Update`方法，当接收到新的购买消息时更新实例。首先，将传入的消息时间标准化为通用时间。然后，从这个时间中提取出天部分，并将其与运行总计的当前`Day`进行比较，如下面的代码所示：
- en: '[PRE61]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'If it''s a new day, we assume that the running total computation of the previous
    day has finished, so the `Update` method returns it in a new `RunningTotal` instance
    and resets `Day` and `Count` so that it can compute the new day running total.
    Otherwise, the new value is added to the running `Count` and the method returns
    `null`, meaning that the day total isn''t ready yet. This implementation can be
    seen in the following code:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是新的日子，我们假设前一天的总计算已经完成，因此`Update`方法返回一个新的`RunningTotal`实例，并重置`Day`和`Count`以便它可以计算新的一天的总计数。否则，新值将添加到当前的`Count`中，并且方法返回`null`，表示这一天的总计数尚未准备好。这种实现可以在以下代码中看到：
- en: '[PRE62]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The `IHostedService` implementation of `ComputeStatistics` needs some parameters
    to work properly, as follows:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: '`IHostedService`的`ComputeStatistics`实现需要一些参数才能正常工作，如下所示：'
- en: The queue containing all the incoming messages
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含所有传入消息的队列
- en: The `IReliableStateManager` service, so that it can create the distributed dictionary
    where it stores data
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IReliableStateManager`服务，以便它可以创建存储数据的分布式字典'
- en: The `ConfigurationPackage` service, so that it can read the settings defined
    in the `Settings.xml` service file and possibly those overridden in the application
    manifest
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ConfigurationPackage`服务，以便它可以读取在`Settings.xml`服务文件中定义的设置，以及可能在应用程序清单中覆盖的设置'
- en: 'The preceding parameters must be passed in the `ComputeStatistics` constructor
    when a `ComputeStatistics` instance is created by `IHost` through dependency injection.
    We will return to the `IHost` definition in the next subsection. For now, let''s
    concentrate on the `ComputeStatistics` constructor and its fields:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建`ComputeStatistics`实例时，必须通过`IHost`通过依赖注入将前面的参数传递给`ComputeStatistics`构造函数。我们将在下一小节回到`IHost`的定义。现在，让我们集中讨论`ComputeStatistics`构造函数及其字段：
- en: '[PRE63]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'All the constructor parameters are stored in private fields so that they can
    be used when `ExecuteAsync` is called:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 所有构造函数参数都存储在私有字段中，以便在调用`ExecuteAsync`时使用：
- en: '[PRE64]'
  id: totrans-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Before entering its loop, the `ComputeStatistics` service prepares some structures
    and parameters. It declares that the queue isn''t empty so that it can start dequeuing
    messages. Then, it extracts `MessageMaxDelaySeconds` from the service settings
    and turns it into an integer. The value of this parameter was left empty in the
    `Settings.xml` file. Now, it''s time to override it and define its actual value
    in `ApplicationManifest.xml`:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入循环之前，`ComputeStatistics`服务准备了一些结构和参数。它声明队列不为空，以便它可以开始出队消息。然后，它从服务设置中提取`MessageMaxDelaySeconds`并将其转换为整数。这个参数在`Settings.xml`文件中留空。现在，是时候在`ApplicationManifest.xml`中覆盖它并定义其实际值了：
- en: '[PRE65]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '`ServiceManifestImport` imports the service manifest in the application and
    overrides some configuration. Its version number must be changed every time its
    content and/or the service definition is changed and the application is redeployed
    in Azure because version number changes tell the Service Fabric runtime what to
    change in the cluster. Version numbers also appear in other configuration settings.
    They must be changed every time the entities they refer to change.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '`ServiceManifestImport`导入服务清单到应用程序中，并覆盖一些配置。每次其内容以及/或服务定义更改，并且应用程序在Azure中重新部署时，其版本号都必须更改，因为版本号的变化告诉服务
    Fabric 运行时在集群中要更改什么。版本号也出现在其他配置设置中。它们必须在它们引用的实体更改时更改。'
- en: '`MessageMaxDelaySeconds` is passed to the instance of the idempotency filter,
    along with a name for the dictionary of the already received messages, and with
    the instance of the `IReliableStateManager` service. Finally, the main distributed
    dictionary that''s used to store running totals is created.'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '`MessageMaxDelaySeconds`被传递给幂等性过滤器实例，以及已接收消息字典的名称，以及`IReliableStateManager`服务实例。最后，用于存储运行总量的主要分布式字典被创建。'
- en: 'After this, the service enters its loop and finishes when `stoppingToken` is
    signaled, that is, when the Service Fabric runtime signals that the service is
    going to be stopped:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，服务进入其循环，并在`stoppingToken`被触发时结束，即当服务 Fabric 运行时指示服务即将停止时：
- en: '[PRE66]'
  id: totrans-461
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The inner loop runs until the queue isn''t empty and then exits and waits 100
    milliseconds before verifying whether new messages have been enqueued:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 内层循环会一直运行，直到队列不为空，然后退出并等待100毫秒，以验证是否有新消息入队：
- en: '[PRE67]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The following is the code for the inner loop, which is enclosed in a transaction:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是为内层循环编写的代码，该循环被包含在一个事务中：
- en: '[PRE68]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Here, the service is trying to dequeue a message. If the queue is empty, it
    sets `queueEmpty` to `true` to exit the loop; otherwise, it passes the message
    through the idempotency filter. If the message survives this step, it uses it
    to update the running total of the location referenced in the message. However,
    correct operation of the distributed dictionary requires that the old counter
    is replaced with a new counter each time an entry is updated. Accordingly, the
    old counter is copied into a new `RunningTotal` object. This new object can be
    updated with the new data if we call the `Update` method:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，服务正在尝试出队一个消息。如果队列为空，它将`queueEmpty`设置为`true`以退出循环；否则，它将消息通过幂等性过滤器。如果消息通过了这一步，它将使用它来更新消息中引用的位置的运行总数。然而，为了正确操作分布式字典，每次更新条目时都必须用新计数器替换旧计数器。因此，旧计数器被复制到一个新的`RunningTotal`对象中。如果我们调用`Update`方法，这个新对象可以更新为新数据：
- en: '[PRE69]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Then, the transaction is committed, as shown in the following code:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，事务被提交，如下面的代码所示：
- en: '[PRE70]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'When the `Update` method returns a complete computation result, that is when
    the `total != null` method is called:'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 当`Update`方法返回完整的计算结果时，即调用`total != null`方法时：
- en: '[PRE71]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: The `SendTotal` method sends the total to a service that publicly exposes all
    the statistics through an HTTP endpoint. After reading [Chapter 12](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml),
    *Applying Service-Oriented Architectures with .NET Core*, which is dedicated to
    the Web API, you may want to implement a similar service with a stateless ASP.NET
    Core microservice connected to a database. The stateless ASP.NET Core service
    template automatically creates an ASP.NET Core-based HTTP endpoint for you.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: '`SendTotal`方法将总数发送到公开通过HTTP端点暴露所有统计信息的服务。在阅读了第12章[Applying Service-Oriented
    Architectures with .NET Core](3ec4db7b-e570-41d0-94fb-2bdbd6dc4a9a.xhtml)之后，该章节专门介绍了Web
    API，你可能希望实现一个类似的服务，该服务是一个无状态的ASP.NET Core微服务，连接到一个数据库。无状态的ASP.NET Core服务模板会自动为你创建一个基于ASP.NET
    Core的HTTP端点。'
- en: However, since this service must receive data from the `SendTotal` method, it
    also needs remote-based endpoints. Therefore, we must create them, just like we
    did for the `LogStore` microservice, and concatenate the remote-based endpoint
    array with the preexisting array containing the HTTP endpoint.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于此服务必须从`SendTotal`方法接收数据，它还需要基于远程的端点。因此，我们必须创建它们，就像我们为`LogStore`微服务所做的那样，并将基于远程的端点数组与包含HTTP端点的现有数组连接起来。
- en: Defining the microservice's host
  id: totrans-474
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义微服务的宿主
- en: 'Now, we have everything in place to define the microservice''s `RunAsync` method:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好定义微服务的`RunAsync`方法：
- en: '[PRE72]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Here, the method verifies whether the cancellation token was signaled, in which
    case we throw an exception to abort the method. Then, the service queue is created,
    and the service settings are saved in `configurationPackage`.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，该方法验证取消令牌是否被信号，如果是，则抛出异常以终止方法。然后，创建服务队列，并将服务设置保存在`configurationPackage`中。
- en: 'After that, we can create the `IHost` service, as we explained in the *Using
    generic hosts* subsection:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们可以创建`IHost`服务，正如我们在*使用通用宿主*子节中解释的那样：
- en: '[PRE73]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '`ConfigureServices` defines all singletons instances that may be needed by
    `IHostedService` implementations, so they are injected into the constructor of
    all the implementations that reference their types. Then, `AddHostedService` declares
    the unique `IHostedService` of the microservice. Once the `IHost` is built, we
    run it until the `RunAsync` cancellation token is signaled. When the cancellation
    token is signaled, the request to shutdown is passed to all `IHostedService` implementations.'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConfigureServices`定义了所有可能由`IHostedService`实现需要的单例实例，因此它们被注入到所有引用其类型的实现构造函数中。然后，`AddHostedService`声明微服务的唯一`IHostedService`。一旦构建了`IHost`，我们就运行它，直到`RunAsync`取消令牌被信号。当取消令牌被信号时，关闭请求传递给所有`IHostedService`实现。'
- en: Communicating with the service
  id: totrans-481
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与服务通信
- en: Since we haven't implemented the whole purchase logic yet, we will implement
    a stateless microservice that sends random data to the `LogStore` service. Right-click
    on the `PurchaseLogging` project in the Solution Explorer and select Add | Service
    Fabric Service. Then, select the .NET Core stateless template and name the new
    microservice project `FakeSource`.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们尚未实现整个购买逻辑，我们将实现一个无状态微服务，该服务向`LogStore`服务发送随机数据。在解决方案资源管理器中右键单击`PurchaseLogging`项目，并选择添加
    | Service Fabric服务。然后，选择.NET Core无状态模板，并将新的微服务项目命名为`FakeSource`。
- en: 'Now, let''s add a reference to the `Interaction` project. Before moving on
    to the service code, we need to update the replica count of the newly created
    service in `ApplicationManifest.xml` and in all the other environment-specific
    parameter overrides (the cloud, one local cluster node, five local cluster nodes):'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加对`Interaction`项目的引用。在继续到服务代码之前，我们需要更新`ApplicationManifest.xml`中以及所有其他环境特定参数覆盖（云、一个本地集群节点、五个本地集群节点）中新建服务的副本计数。
- en: '[PRE74]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This fake service needs no listeners and its `RunAsync` method is straightforward:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模拟服务不需要监听器，其`RunAsync`方法很简单：
- en: '[PRE75]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'In each loop, a random message is created and sent to the counting microservices.
    Then, the thread sleeps for a second and starts a new loop. The code that sends
    the created messages is as follows:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个循环中，创建一个随机消息并发送到计数微服务。然后，线程休眠一秒钟并开始新的循环。发送创建的消息的代码如下：
- en: '[PRE76]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Here, a key in the 0-9,999 interval is computed from the location string. This
    integer is passed to the `ServicePartitionKey` constructor. Then, a service proxy
    is created, and the URI of the service to call and the partition key are passed.
    The proxy uses this data to ask the naming service for a physical URI for a primary
    instance for the given partition value.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，从位置字符串计算出一个0-9,999区间的键。这个整数传递给`ServicePartitionKey`构造函数。然后，创建一个服务代理，并将要调用的服务的URI和分区键传递。代理使用这些数据向命名服务请求给定分区值的物理URI。
- en: '`ServiceProxy.Create` also accepts a third optional argument that specifies
    whether messages that are sent by the proxy can also be routed to secondary replicas.
    The default is that messages are routed just to primary instances. If the message
    target returns `false`, meaning that it''s not ready (remember that `LogPurchase`
    returns `false` when the `LogStore` message queue hasn''t been created yet), the
    same transmission is attempted after 100 milliseconds.'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '`ServiceProxy.Create`还接受一个第三个可选参数，指定代理发送的消息是否也可以路由到二级副本。默认情况下，消息仅路由到主实例。如果消息目标返回`false`，表示它尚未准备好（记住，当`LogStore`消息队列尚未创建时，`LogPurchase`返回`false`），则在100毫秒后尝试相同的传输。'
- en: 'Sending messages to a remoting target is quite easy. However, other communication
    listeners require that the sender interacts manually with the naming service to
    get a physical service URI. This can be done with the following code:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 向远程目标发送消息非常简单。然而，其他通信监听器要求发送者手动与命名服务交互以获取物理服务URI。这可以通过以下代码完成：
- en: '[PRE77]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Moreover, in the case of generic communication protocols, we must manually handle
    failures and retries with a library such as Polly (see the *Resilient task execution*
    subsection for more information).
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在通用通信协议的情况下，我们必须手动使用库（如Polly）处理失败和重试（有关更多信息，请参阅*弹性任务执行*子节）。
- en: Testing the application
  id: totrans-494
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试应用程序
- en: 'To test that the application actually computes running purchase totals, let''s
    place a breakpoint in the `ComputeStatistics.cs` file:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试应用程序实际上是否计算了累计购买总额，让我们在`ComputeStatistics.cs`文件中放置一个断点：
- en: '[PRE78]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Each time the breakpoint is hit, look at the content of `newCounter` to verify
    how the running totals of all the locations change.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 每当断点被触发时，查看`newCounter`的内容以验证所有位置的累计总和是如何变化的。
- en: Summary
  id: totrans-498
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we described what microservices are and how they have evolved
    from the concept of a module. Then, we talked about the advantages of microservices
    and when it's worth using them, as well as general criteria for their design.
    We also explained what Docker containers are and analyzed the strong connection
    between containers and microservice architectures.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们描述了微服务是什么以及它们是如何从模块的概念演变而来的。然后，我们讨论了微服务的优势以及何时值得使用它们，以及它们设计的一般标准。我们还解释了Docker容器是什么，并分析了容器与微服务架构之间的紧密联系。
- en: Then, we took on a more practical implementation by describing all the tools
    that are available in .NET Core so that we can implement microservice-based architectures.
    We also described infrastructures that are needed by microservices and how the
    Azure cluster offers Azure Kubernetes Services and Azure Service Fabric.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过描述.NET Core中所有可用的工具来实施更实际的实现，这样我们就可以实现基于微服务的架构。我们还描述了微服务所需的基础设施以及Azure集群如何提供Azure
    Kubernetes服务和Azure Service Fabric。
- en: Finally, we put these concepts into practice by implementing a Service Fabric
    application. Here, we looked at the various ways in which Service Fabric applications
    can be implemented.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过实现Service Fabric应用程序将这些概念付诸实践。在这里，我们探讨了Service Fabric应用程序可以实现的多种方式。
- en: The next chapter focuses on how to use ORMs and Entity Framework Core to interact
    with various kinds of database while keeping our code independent from the database
    engine we've selected.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将重点介绍如何使用ORM和Entity Framework Core与各种类型的数据库交互，同时保持我们的代码与所选数据库引擎的独立性。
- en: Questions
  id: totrans-503
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the two-folded nature of the module concept?
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模块概念的双重性质是什么？
- en: Is scaling optimization the only advantage of microservices? If not, list some
    further advantages.
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微服务的优势仅仅是扩展优化吗？如果不是，请列出一些其他优势。
- en: What is Polly?
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Polly是什么？
- en: What is `ConfigureServices`?
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ConfigureServices`是什么？'
- en: What Docker support is offered by Visual Studio?
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Visual Studio提供了哪些Docker支持？
- en: 'What Docker application method is more powerful: the one based on `.yml` files
    or the one based on `.yaml` files?'
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那么，哪种Docker应用程序方法更强大：基于`.yml`文件的方法还是基于`.yaml`文件的方法？
- en: What kinds of port must be declared during the definition of an Azure Service
    Fabric cluster?
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定义Azure Service Fabric集群时必须声明哪些类型的端口？
- en: Why are partitions of reliable stateful services needed?
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么需要可靠状态服务的分区？
- en: How can we declare that a remoting communication must be addressed by secondary
    replicas? What about for other types of communication?
  id: totrans-512
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何声明远程通信必须由辅助副本处理？对于其他类型的通信呢？
- en: Further reading
  id: totrans-513
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The following are links to the official documentation for Azure Service Bus
    and RabbitMQ, two event bus technologies:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接是Azure Service Bus和RabbitMQ这两个事件总线技术的官方文档：
- en: '**Azure Service Bus**: [https://docs.microsoft.com/en-us/azure/service-bus-messaging/](https://docs.microsoft.com/en-us/azure/service-bus-messaging/)'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Service Bus**：[https://docs.microsoft.com/en-us/azure/service-bus-messaging/](https://docs.microsoft.com/en-us/azure/service-bus-messaging/)'
- en: '**RabbitMQ**: [https://www.rabbitmq.com/getstarted.html](https://www.rabbitmq.com/getstarted.html)'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RabbitMQ**：[https://www.rabbitmq.com/getstarted.html](https://www.rabbitmq.com/getstarted.html)'
- en: 'The documentation for Polly, a tool for reliable communication/tasks, can be
    found here: [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 可靠通信/任务的工具Polly的文档可以在这里找到：[https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).
- en: 'More information on Docker can be found on Docker''s official website: [https://docs.docker.com/](https://docs.docker.com/).'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于Docker的信息可以在Docker的官方网站上找到：[https://docs.docker.com/](https://docs.docker.com/).
- en: 'The official documentation for Kubernetes and `.yaml` files can be found here:
    [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/).'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes和`.yaml`文件的官方文档可以在这里找到：[https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/).
- en: 'The official documentation for Azure Kubernetes can be found here: [https://docs.microsoft.com/en-US/azure/aks/](https://docs.microsoft.com/en-US/azure/aks/).'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Kubernetes的官方文档可以在这里找到：[https://docs.microsoft.com/en-US/azure/aks/](https://docs.microsoft.com/en-US/azure/aks/).
- en: 'The official documentation for Azure Service Fabric can be found here: [https://docs.microsoft.com/en-US/azure/service-fabric/](https://docs.microsoft.com/en-US/azure/service-fabric/).'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Service Fabric的官方文档可以在这里找到：[https://docs.microsoft.com/en-US/azure/service-fabric/](https://docs.microsoft.com/en-US/azure/service-fabric/).
- en: 'The official documentation for Azure Service Fabric''s reliable services can
    be found here: [https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-introduction](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-introduction).'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Service Fabric的可靠服务的官方文档可以在这里找到：[https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-introduction](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-introduction).
- en: 'More information about the Actor model can be found here: [https://www.researchgate.NET/publication/234816174_Actors_A_conceptual_foundation_for_concurrent_object-oriented_programming](https://www.researchgate.net/publication/234816174_Actors_A_conceptual_foundation_for_concurrent_object-oriented_programming).'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于Actor模型的信息可以在这里找到：[https://www.researchgate.NET/publication/234816174_Actors_A_conceptual_foundation_for_concurrent_object-oriented_programming](https://www.researchgate.net/publication/234816174_Actors_A_conceptual_foundation_for_concurrent_object-oriented_programming).
- en: 'The official documentation for Actor models that can be implemented in Azure
    Service Fabric can be found here: [https://docs.microsoft.com/en-US/azure/service-fabric/service-fabric-reliable-actors-introduction](https://docs.microsoft.com/en-US/azure/service-fabric/service-fabric-reliable-actors-introduction).'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在Azure Service Fabric中实现的Actor模型的官方文档可以在这里找到：[https://docs.microsoft.com/en-US/azure/service-fabric/service-fabric-reliable-actors-introduction](https://docs.microsoft.com/en-US/azure/service-fabric/service-fabric-reliable-actors-introduction).
- en: 'Microsoft has also implemented an advanced actor model that is independent
    of Service Fabric. This is known as the Orleans framework. More information about
    Orleans can be found at the following links:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 微软还实现了一个独立于Service Fabric的高级actor模型，这被称为Orleans框架。更多关于Orleans的信息可以在以下链接中找到：
- en: '**Orleans – Virtual Actors**: [https://www.microsoft.com/en-us/research/project/orleans-virtual-actors/?from=https%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Forleans%2F](https://www.microsoft.com/en-us/research/project/orleans-virtual-actors/?from=https%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Forleans%2F)'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Orleans – 虚拟Actor**：[https://www.microsoft.com/en-us/research/project/orleans-virtual-actors/?from=https%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Forleans%2F](https://www.microsoft.com/en-us/research/project/orleans-virtual-actors/?from=https%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fprojects%2Forleans%2F)'
- en: '**Orleans** **Documentation**: [http://dotnet.github.io/orleans/Documentation/](http://dotnet.github.io/orleans/Documentation/)'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Orleans** **文档**：[http://dotnet.github.io/orleans/Documentation/](http://dotnet.github.io/orleans/Documentation/)'
