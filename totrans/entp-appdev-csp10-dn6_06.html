<html><head></head><body>
		<div id="_idContainer054">
			<h1 id="_idParaDest-69"><em class="italic"><a id="_idTextAnchor205"/>Chapter 4</em>: Threading and Asynchronous Operations</h1>
			<p>So far, we have looked at various design principles, patterns, what is new in .NET 6, and architecture guidelines that we are going to use during this book. In this chapter, we will see how we can take advantage of asynchronous programming while building enterprise applications. </p>
			<p>One of the key measures for any web application is <em class="italic">scalability</em> – that is, scaling to reduce the time taken to serve a request, increase the number of requests that a server can process, and increase the number of users an application can simultaneously serve without increasing the load time. For mobile/desktop apps, scaling can improve the responsiveness of the app, allowing users to perform various actions without freezing the screen. </p>
			<p>The proper use of asynchronous programming techniques and parallel constructs can do wonders in improving these metrics, and the best thing for this in C# is the simplified syntax of the <strong class="bold">Task Parallel Library</strong> (<strong class="bold">TPL</strong>), async-await, with which we can write clean asynchronous code.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Understanding the jargon</li>
				<li>Demystifying threads, lazy initialization, and <strong class="source-inline">ThreadPool</strong></li>
				<li>Understanding locks, semaphores, and <strong class="source-inline">SemaphoreSlim</strong></li>
				<li>Introducing tasks and parallels</li>
				<li>Introducing async-await</li>
				<li>Using concurrent collections for parallelism</li>
			</ul>
			<h1 id="_idParaDest-70"><a id="_idTextAnchor206"/><a id="_idTextAnchor207"/>Technical requirements</h1>
			<p>You will need a basic understanding of .NET Core, C#, and the basics of LINQ. The code examples for this chapter can be found here: <a href="https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Chapter04">https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Chapter04</a>.</p>
			<p>A few instructions for the code can be found here: <a href="https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application">https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application</a>.</p>
			<h1 id="_idParaDest-71"><a id="_idTextAnchor208"/><a id="_idTextAnchor209"/>Understanding the jargon</h1>
			<p>Before we dive<a id="_idIndexMarker191"/> into the technicalities of threading and asynchronous operations, let's take a real-world example and build an analogy between multitasking in real life and parallel programming. Imagine that you are waiting in a queue in a restaurant to order food, and while waiting in the queue, you reply to an email. Then, having ordered the food and while<a id="_idTextAnchor210"/> waiting for it to arrive, you answered a phone call. In the restaurant, there are multiple counters where orders are being taken, and food is prepared by the chef while orders are being placed.</p>
			<p>While you were waiting in line, you concurrently replied to an email. Similarly, while you were ordering, the restaurant was parallelly taking orders at many other counters. The chef is cooking parallelly while orders are being placed. Also, you were given a token to pick up your food from the pickup counter; however, depending upon the preparation time of your food, an order placed after yours may arrive at the pickup counter before yours.</p>
			<p>When talking about parallel programming, some key terms will appear multiple times. This jargon is represented in the following figure:</p>
			<p class="figure-caption"><a id="_idTextAnchor211"/></p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/Figure_4.1_B18507.jpg" alt="Figure 4.1 – Concurrency versus parallelism versus asynchronous&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – Concurrency versus parallelism versus asynchronous</p>
			<p>Let's <a id="_idIndexMarker192"/>cover each term:</p>
			<ul>
				<li><strong class="bold">Parallelism</strong>: This entails<a id="_idTextAnchor212"/><a id="_idIndexMarker193"/> multiple tasks being performed independently at the  same time, as in the example of multiple restaurant orders being placed from different counters. In terms of enterprise applications, parallelism would be multiple threads/tasks being executed at the same time in a multicore CPU. However, a single-core CPU also supports parallelism through hyper-threading, which usually involves the logical division of a single core into more than one core, such as a hyper-threading-enabled dual-core CPU, which acts like a quad-core – that is, four cores.</li>
				<li><strong class="bold">Concurrency</strong>: This <a id="_idIndexMarker194"/>entails doing many tasks at the same time, such as in our previous examp<a id="_idTextAnchor213"/>le of replying to an email while queuing for a restaurant counter, or the chef seasoning one dish and heating the pan for a second dish. In terms of enterprise applications, concurrency involves multiple threads sharing a core and, based on their time slicing, executing tasks and performing <a id="_idIndexMarker195"/>context switching.</li>
				<li><strong class="bold">Asynchronous</strong>: Asynchronous<a id="_idIndexMarker196"/> programming is a technique that relies on executing t<a id="_idTextAnchor214"/>asks asynchronously instead of blocking the current thread while it is waiting. In our example, asynchronicity is waiting for your token to be called for you to go to the pickup counter while the chef is working on preparing your food. But while you're waiting, you have moved away from the ordering counter, thereby allowing other orders to be placed. This is like a task that executes asynchronously and frees up resources while waiting on an I/O task (for instance, while waiting on data from a database call). The beauty of asynchronicity is that tasks are executed either parallelly or concurrently, which is completely abstracted from developers by the framework. This lets the developer focus their development efforts on the business logic of the application rather than on managing tasks. We will see this in the <em class="italic">Tasks and parallels</em> section.</li>
				<li><strong class="bold">Multithreading</strong>: Multithreading is <a id="_idIndexMarker197"/>a way to achieve concurrency where new thread<a id="_idTextAnchor215"/>s are created manually and executed concurrently, as with <strong class="source-inline">CLR ThreadPool</strong>. In a multicore/multiprocessor system, multithreading helps to achieve parallelism by executing newly created threads in different cores.</li>
			</ul>
			<p>Now that we<a id="_idIndexMarker198"/> understand the key terms in parallel programming, let's move on to look at how to create threads and the role of <strong class="source-inline">ThreadPool</strong> in .NET<a id="_idTextAnchor216"/><a id="_idTextAnchor217"/> Core.</p>
			<h1 id="_idParaDest-72"><a id="_idTextAnchor218"/>Demystifying threads, lazy initialization, and ThreadPool</h1>
			<p>A thread <a id="_idTextAnchor219"/>is <a id="_idIndexMarker199"/>the<a id="_idIndexMarker200"/> smallest unit in <a id="_idIndexMarker201"/>an operating system, and it executes instructions in the processor. A process is a bigger executing container, and the thread inside th<a id="_idTextAnchor220"/>e process is the smallest unit to use processor time and execute instructions. The key thing to remember is that whenever your code needs to be<a id="_idTextAnchor221"/> executed in a process, it should be assigned to a thread. Each processor can only execute one instruction at a time; that's why, in a single-core syste<a id="_idTextAnchor222"/>m, at any point time, only one thread is being executed. There are scheduling algorithms that are used to allocate processor time to a thread. A thread typically has a stack (which keeps track of execution history), registers in which to store various variables, and counters to hold instructions that need to be executed.</p>
			<p>A quick look at <strong class="bold">Task Manager</strong> will give us details regarding the number of physical and logical cores, and navigating to <strong class="bold">Resource Monitor</strong> will tell us about the CPU usage in each core. The<a id="_idIndexMarker202"/> following figure shows the details of a hyper-threading-enabled <a id="_idIndexMarker203"/>quad-core CPU that can execute eight<a id="_idIndexMarker204"/> threads in parallel at any<a id="_idTextAnchor223"/> poi<a id="_idTextAnchor224"/>nt in time:</p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/Figure_4.2_B18507.jpg" alt="Figure 4.2 – Task Manager and Resource Monitor&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – Task Manager and Resource Monitor</p>
			<p>A <a id="_idIndexMarker205"/>typical <a id="_idIndexMarker206"/>application in .NET Core has one single<a id="_idIndexMarker207"/> thread when it is started and can ad<a id="_idTextAnchor225"/>d more threads by manually creating them. A quick re<a id="_idTextAnchor226"/>fresher on ho<a id="_idTextAnchor227"/>w this is done will be covered in the follo<a id="_idTextAnchor228"/><a id="_idTextAnchor229"/>wing sections.</p>
			<h2 id="_idParaDest-73"><a id="_idTextAnchor230"/>Working with System.Threading.Thread</h2>
			<p>We can create<a id="_idIndexMarker208"/> new threads by creating an instance of <strong class="source-inline">System.Threading.Threa<a id="_idTextAnchor231"/>d</strong> and passing a method delegate. Here is a simple example that simulates retrieving data from an API and loading a file from a disk:</p>
			<pre class="source-code">Thread loadFileFromDisk = new Thread(LoadFileFromDisk);</pre>
			<pre class="source-code">void LoadFileFromDisk(object? obj)</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">    Thread.Sleep(2000);</pre>
			<pre class="source-code">    Console.WriteLine("data returned from API");</pre>
			<pre class="source-code">}</pre>
			<pre class="source-code">loadFileFromDisk.Start();</pre>
			<pre class="source-code">Thread fetchDataFromAPI = new Thread(FetchDataFromAPI);</pre>
			<pre class="source-code">void FetchDataFromAPI(object? obj)</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">    Thread.Sleep(2000);</pre>
			<pre class="source-code">    Console.WriteLine("File loaded from disk");</pre>
			<pre class="source-code">}</pre>
			<pre class="source-code">fetchDataFromAPI.Start("https://dummy/v1/api"); //Parameterized method</pre>
			<pre class="source-code">Console.Rea<a id="_idTextAnchor232"/>dLine();</pre>
			<p>In the previous code, <strong class="source-inline">FetchDataFromAPI</strong> and <strong class="source-inline">LoadFileFromDisk</strong> are the methods that would run on the new thread.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">At any point in time, only one thread will be executing on each core – that is, only one thread is allotted CPU time. So, to achieve<a id="_idIndexMarker209"/> concurrency, the <strong class="bold">Operating Sy<a id="_idTextAnchor233"/>stem</strong> (<strong class="bold">OS</strong>) does a context switch when a thread that's been allocated CPU time is idle or if a high-priority thread arrives in the queue (there may be other reasons too, such as if a thread is waiting on a synchronization object or the allotted CPU time is reached).</p>
			<p class="callout">Since a thread that is switched out won't have completed its work, at some point, it will be assigned CPU time again. As such, the OS needs to save the state of the thread (its stack, its registers, and so on) and retrieve it again when the thread is allotted CPU time. Context switching is usually very expensive and one of the key areas of performance impr<a id="_idTextAnchor234"/>ovement.</p>
			<p>All the properties and methods of the <strong class="source-inline">Thread</strong> class can be further reviewed at <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.thread?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.threading.thread?view=net-6.0</a>.</p>
			<p>Although managing threads come with the advantage of having more control over how they are executed, it also comes with overheads in the form of the following:</p>
			<ul>
				<li>Managing the life cycle of threads, such as creating threads, recycling them, and context switching.</li>
				<li>Implementing concepts such as progress tracking/reporting for thread execution. Also, cancellation is quite complex and has limited support.</li>
				<li>Exceptions on threads need to be handled appropriately; otherwise, they may lead to the application crashing.</li>
				<li>Debugging, testing, and code maintenance can become a bit complex an<a id="_idTextAnchor235"/>d, at times, can lead to performance issues if not handled correctly.</li>
			</ul>
			<p>This is where <a id="_idIndexMarker210"/>the <strong class="bold">Common Language Runtime</strong> (<strong class="bold">CLR</strong>) <strong class="source-inline">ThreadPool</strong> comes into<a id="_idIndexMarker211"/> play, which is discussed in<a id="_idTextAnchor236"/><a id="_idTextAnchor237"/> the next section.</p>
			<h2 id="_idParaDest-74"><a id="_idTextAnchor238"/>ThreadPool</h2>
			<p>Threads can be <a id="_idIndexMarker212"/>created by making use of pools of threads managed by .NET Core, more commonly known as the CLR <strong class="source-inline">ThreadPool</strong>. The CLR <strong class="source-inline">ThreadPool</strong> is a set of worker threads t<a id="_idTextAnchor239"/>hat are loaded into your application along with the CLR and take care of the thread life cycle, including recycling threads, creating threads, and supporting better context switching. The CLR <strong class="source-inline">ThreadPool</strong> can be consumed by various APIs available in the <strong class="source-inline">System.Threading.ThreadPool</strong> class. Specifically, for scheduling an operation on a thread, there is the <strong class="source-inline">QueueUserWorkItem</strong> method, which takes a delegate of the method that needs to be scheduled. In the previous code, let's replace the code for creating a new thread with the following code, meaning the application will use <strong class="source-inline">ThreadPool</strong>:</p>
			<pre class="source-code">ThreadPool.QueueUserWorkItem(FetchDataFromAPI);</pre>
			<p>As the name suggests, <strong class="source-inline">QueueUserWorkItem</strong> of the <strong class="source-inline">ThreadPool</strong> class does make use of queues, whereby any code that is supposed to be executed on th<a id="_idTextAnchor240"/>e <strong class="source-inline">ThreadPool</strong> thread would be <a id="_idIndexMarker213"/>queued and then dequeued – that is, assigned to a worker thread in a <strong class="bold">First-In, First-Out</strong> (<strong class="bold">FIFO</strong>) manner.</p>
			<p>The way <strong class="source-inline">ThreadPool</strong> is designed is that it has a global queue, and items are queued in it when we do the following:</p>
			<ul>
				<li>Call <strong class="source-inline">QueueUserWorkItem</strong> or a similar method of the <strong class="source-inline">ThreadPool</strong> class using a thread that is not part of the <strong class="source-inline">ThreadPool</strong> threads</li>
				<li>Call through the TPL</li>
			</ul>
			<p>When a new thread is created in <strong class="source-inline">ThreadPool</strong>, it maintains its own local queue that checks the global queue and dequeues the work item in a FIFO manner; however, if the code executing on this thread creates another thread, such as a child thread, then that gets queued in the local queue as opposed to the global queue. </p>
			<p>The order of<a id="_idIndexMarker214"/> execution for operations in the local queue of the worker thread is always <strong class="bold">Last-In, First-Out </strong>(<strong class="bold">LIFO</strong>), and the reason for this is that the most recently created work item may still be hot in the cache and hence can be executed quickly. Also, we can say that at any point in time, there would be <em class="italic">n+1</em> queues in <strong class="source-inline">ThreadPool</strong>, where <em class="italic">n</em> is the number of threads in <strong class="source-inline">ThreadPool</strong> – that is, <em class="italic">n</em> local queues – and <em class="italic">1</em> refers to the global queue.</p>
			<p>A high-level representation of <strong class="source-inline">ThreadPool</strong> is shown in t<a id="_idTextAnchor241"/>he following figure:</p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/Figure_4.3_B18507.jpg" alt="Figure 4.3 – ThreadPool high-level representation&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.3 – ThreadPool high-level representation</p>
			<p>Apart from <strong class="source-inline">QueueUserWorkItem</strong>, there are a lot of other properti<a id="_idTextAnchor242"/>es/methods available for the <strong class="source-inline">ThreadPool</strong> class, such as these:</p>
			<ul>
				<li><strong class="source-inline">SetMinThreads</strong>: Used to set the minimum worker and asynchronous I/O threads that <strong class="source-inline">ThreadPool</strong> will have when the program is started</li>
				<li><strong class="source-inline">SetMaxThreads</strong>: Used to set the maximum worker and asynchronous I/O threads that <strong class="source-inline">ThreadPool</strong> will have, after which, new request<a id="_idTextAnchor243"/>s are queued</li>
			</ul>
			<p>All the properties<a id="_idIndexMarker215"/> and methods of the <strong class="source-inline">ThreadPool</strong> class can be further reviewed at <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.threadpool?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.threading.threadpool?view=net-6.0</a>.</p>
			<p>Although writing multithreaded code via <strong class="source-inline">QueueUserWorkItem</strong> of the <strong class="source-inline">ThreadPool</strong> thread simplifies life cycle management for threads, it has its own limitations:</p>
			<ul>
				<li>We cannot get a response from the work that is scheduled on the <strong class="source-inline">ThreadPool</strong> thread, hence the return type of the delegate is void.</li>
				<li>It is not easy to track the progress of the work that is scheduled on the <strong class="source-inline">ThreadPool</strong> thread, so something such as progress reporting isn't easy to achieve.</li>
				<li>It's not meant for long-running requests.</li>
				<li><strong class="source-inline">ThreadPool</strong> threads are always background threads; so, unlike foreground threads, if a process is shut down, it will not wait for the <strong class="source-inline">ThreadPool</strong> threads to complete their work.</li>
			</ul>
			<p>As there are limitations with <strong class="source-inline">QueueUserWorkItem</strong>, the <strong class="source-inline">ThreadPool</strong> threads<a id="_idTextAnchor244"/> can also be consumed through the TPL, which we will use in our enterprise application and is covered later in this chapter. In .NET Core, the TPL is the preferred approach to achieve concurrency/parallelism, as it overcomes all the limitations we have seen so far and eventually <a id="_idIndexMarker216"/>helps to achieve the goal of allowing your application to sc<a id="_idTextAnchor245"/><a id="_idTextAnchor246"/>ale and be responsive.</p>
			<h2 id="_idParaDest-75"><a id="_idTextAnchor247"/>Lazy initialization</h2>
			<p>The lazy initialization <a id="_idIndexMarker217"/>of a class is a pattern where the creation of an object is deferred until it is used for the first time. This pattern is based on the premise that as long as a class's properties are not being used, there is no advantage to initializing an obj<a id="_idTextAnchor248"/>ect. Hence, this delays object creation and ultimately reduces the memory footprint of the application, improving performance. An example of this would be creating a database connection object only when you are about to retrieve data from a database. Lazy initialization is a good fit for classes that hold a lot of data and are potentially expensive to create. For instance, a class for loading all the products in an e-commerce application can be lazily initialized only when there is a need to list the products.</p>
			<p>A typical implementation of such a class, as presented next, restricts the initialization of properties in constructors and has one or more methods that populate the properties of the class:</p>
			<pre class="source-code">        public class ImageFile</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            string fileName;</pre>
			<pre class="source-code">            object loadImage;</pre>
			<pre class="source-code">            public ImageFile(string fileName)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                this.fileName = fileName;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            public object GetImage()</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                if (loadImage == null)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    loadImage = File.ReadAllText(fileName);</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">                return loadImage;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<p>Assuming this is a class used to load an image from a disk, there is no use in l<a id="_idTextAnchor249"/>oading the image in the constructor <a id="_idIndexMarker218"/>because it cannot be consumed until the <strong class="source-inline">GetImage</strong> method is called. So, the lazy initialization pattern suggests that instead of initializing the <strong class="source-inline">loadImage</strong> object in the constructor, it should be initialized in <strong class="source-inline">GetImage</strong>, which means that the image is loaded into memory only when it is needed. This can also be achieved through properties, as shown here:</p>
			<pre class="source-code">        object loadImage;</pre>
			<pre class="source-code">        public object LoadImage</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            get</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                if (loadImage == null)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    loadImage = File.ReadAllText(fileName);</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">                return loadImage;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<p>As you can see, this is something that's typically done with cache objects and is also known as <a id="_idIndexMarker219"/>the <strong class="bold">cache-aside pattern</strong>, where we load an object in the cache when a specific object is being accessed for the first time. However, this implementation has a challenge in multithreaded code, where a call to disk can happen multiple times for the same file – that is, if two threads call the <strong class="source-inline">LoadImage</strong> method or property, it will lead to making a call to disk multiple times. So, there is a need for synchronizat<a id="_idTextAnchor250"/>ion here through locks or some other mechanism, which obviously will add to the maintenance overhead, and the class implementation might become even more complex.</p>
			<p>So, even though we can implement our own lazy load pattern, in C#, we have the <strong class="source-inline">System.Lazy</strong> class to handle such an implementation. One of the key advantages of using the <strong class="source-inline">System.Lazy</strong> class is that it is thread-safe.</p>
			<p>The <strong class="source-inline">S<a id="_idTextAnchor251"/>ystem.Lazy</strong> class provides multiple constructors to implement lazy initialization. Here<a id="_idIndexMarker220"/> are the two most common ways that we can make use of:</p>
			<ul>
				<li>Wrapping the class around <strong class="source-inline">Lazy</strong> and using the <strong class="source-inline">Value</strong> method of that object to retrieve data. This is typically used for classes that have initialization logic in constructors. Some sample code follows:<p class="source-code">        public class ImageFile</p><p class="source-code">        {</p><p class="source-code">            string fileName;</p><p class="source-code">            public object LoadImage { get; set; }</p><p class="source-code">            public ImageFile(string fileName)</p><p class="source-code">            {</p><p class="source-code">                this.fileName = fileName;</p><p class="source-code">                this.LoadImage = $"File {fileName}</p><p class="source-code">                 loaded from disk";</p><p class="source-code">            }</p><p class="source-code">        }</p></li>
			</ul>
			<p>While initializing this class, we will use the generic type of the <strong class="source-inline">System.Lazy</strong> class and pass the <strong class="source-inline">ImageFile</strong> class as its type and the object of <strong class="source-inline">ImageFile</strong> as a delegate:</p>
			<p class="source-code">        Lazy&lt;ImageFile&gt; imageFile = new</p>
			<p class="source-code">         Lazy&lt;ImageFile&gt;(() =&gt; new ImageFile("test"));</p>
			<p class="source-code">        var image = imageFile.Value.LoadImage;</p>
			<p>Here, if you put a breakpoint in the <strong class="source-inline">ImageFile</strong> class's constructor, it would be hit only when the <strong class="source-inline">Value</strong> method of the <strong class="source-inline">System.Lazy</strong> cl<a id="_idTextAnchor252"/>ass is called.</p>
			<ul>
				<li>For classes that have a method to load various parameters, we can pass the method to <a id="_idIndexMarker221"/>the <strong class="source-inline">Lazy</strong> class as a delegate. Taking the previous sample code and moving the file-retrieving logic to a separate method is shown here:<p class="source-code">        public class ImageFile</p><p class="source-code">        {</p><p class="source-code">            string fileName;</p><p class="source-code">            public object LoadImage { get; set; }</p><p class="source-code">            public ImageFile(string fileName)</p><p class="source-code">            {</p><p class="source-code">                this.fileName = fileName;</p><p class="source-code">            }</p><p class="source-code">            public object LoadImageFromDisk()</p><p class="source-code">            {</p><p class="source-code">                this.LoadImage = $"File</p><p class="source-code">                 {this.fileName} loaded from disk";</p><p class="source-code">                return LoadImage;</p><p class="source-code">            }</p><p class="source-code">        }</p></li>
			</ul>
			<p>And while initializing this class, we pass a Lambda to the generic<a id="_idTextAnchor253"/> delegate, and that generic delegate is passed to initialize an object of the <strong class="source-inline">System.Lazy</strong> class, as shown in the following code:</p>
			<p class="source-code">        Func&lt;object&gt; imageFile = new Func&lt;object&gt;(()</p>
			<p class="source-code">         =&gt; { var obj = new ImageFile("test");</p>
			<p class="source-code">        return obj.LoadImageFromDisk(); });</p>
			<p class="source-code">        Lazy&lt;object&gt; lazyImage = new</p>
			<p class="source-code">         Lazy&lt;object&gt;(imageFile);</p>
			<p class="source-code">        var image = lazyImage.Value;</p>
			<p class="callout-heading">Note</p>
			<p class="callout">A func in C# is a type of delegate that takes zero or more parameters and returns a value. More details can be found here: <a href="https://docs.microsoft.com/en-us/dotnet/api/system.func-1?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.func-1?view=net-6.0</a>.</p>
			<p>Both ways will <a id="_idIndexMarker222"/>delay the initializing of the object until the call to the <strong class="source-inline">Value</strong> method is made. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">One important thing that we need to note is that although <strong class="source-inline">Lazy</strong> objects are thread-safe, objects created through values aren't thread-safe. So, in this case, <strong class="source-inline">lazyImage</strong> is thread-safe, but <strong class="source-inline">image</strong> isn't. Hence, it needs to be synchronized in a multithreaded environment.</p>
			<p>In general, lazy initialization is a good fit for caching classes and singleton classes and can be further extended for objects that are expensive to in<a id="_idTextAnchor254"/>itialize.</p>
			<p>All the properties of the <strong class="source-inline">Lazy</strong> class can be further reviewed at <a href="https://docs.microsoft.com/en-us/dotnet/api/system.lazy-1?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.lazy-1?view=net-6.0</a>.</p>
			<p>Although lazy initialization can be achieved by wrapping the underlying object with the <strong class="source-inline">System.Lazy</strong> class, there is also the <strong class="source-inline">LazyInitializer</strong> static class available in .NET that can be used for lazy initialization through its <strong class="source-inline">EnsureInitial<a id="_idTextAnchor255"/>ized</strong> method.</p>
			<p>It has a couple of constructors as mentioned in the MSDN documentation at <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.lazyinitializer.ensureinitialized?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.threading.lazyinitializer.ensureinitialized?view=net-6.0</a>.</p>
			<p>However, the idea is the same, in that it expects an object and a function to populate the object. Taking the previous example, if we had to use <strong class="source-inline">LazyInitializer.EnsureInitialized</strong> for lazy initialization, we would need to pass the instance of the object and the Lambda that creates the actual object to <strong class="source-inline">LazyInitializer.EnsureInitialized</strong>, as shown in the following code:</p>
			<pre class="source-code">        object image = null;</pre>
			<pre class="source-code">        LazyInitializer.EnsureInitialized(ref image, () =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                var obj = new ImageFile("test");</pre>
			<pre class="source-code">                return obj.LoadImageFromDisk();</pre>
			<pre class="source-code"><a id="_idTextAnchor256"/>            });</pre>
			<p>Here, we are <a id="_idIndexMarker223"/>passing two parameters – one is the object that holds the value of the property of the <strong class="source-inline">image</strong> class, and the other is the function that creates an object of the <strong class="source-inline">image</strong> class and returns the image. So, this is as simple as calling the <strong class="source-inline">Value</strong> property of the <strong class="source-inline">System.Lazy</strong> property without having the overhead of initializing the object.</p>
			<p>Clearly, a small added advantage of lazy initializing using <strong class="source-inline">LazyInitializer</strong> is that there aren't additional objects that aren't created, meaning a smaller memory footprint. On the other hand, <strong class="source-inline">System.Lazy</strong> provides much more readable code. So, if there are clear <em class="italic">space optimizations</em>, go with <strong class="source-inline">LazyInitializer</strong>; otherwise, use <strong class="source-inline">System.Lazy</strong> for much cl<a id="_idTextAnchor257"/><a id="_idTextAnchor258"/>eaner and more readable code.</p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor259"/>Understanding locks, semaphores, and SemaphoreSlim</h1>
			<p>In the previous <a id="_idIndexMarker224"/>sections, we <a id="_idIndexMarker225"/>saw<a id="_idIndexMarker226"/> how we can use various APIs in .NET to achieve parallelism. However, when we are doing that, we need to take additional care with shared variables. Let's take the enterprise e-commerce application that we are building in this book. Think about the workflow of purchasing an item. Say th<a id="_idTextAnchor260"/>at two users are planning to buy a product and only one item i<a id="_idTextAnchor261"/>s available. Let's say that both users add the item to the cart and the first user p<a id="_idTextAnchor262"/>laces their order, and while the order is being processed through the payment gateway, the second user also tries to place their order.</p>
			<p>In such cases, the second order should fail (assuming that the first order succeeded) because the quantity for the book is now zero; that would happen only if there was proper synchronization being applied to the quantity across threads. Also, if the first order fails in the payment gateway or the first user cancels their transaction, the second order should go through. So, what we are saying here is that the quantity should be locked while the first order is being processed and should be released only when the order is completed (ending in success or failure). Before we get into the handling mechanism, let's quickly rec<a id="_idTextAnchor263"/><a id="_idTextAnchor264"/>ap what the critical section is.</p>
			<h2 id="_idParaDest-77"><a id="_idTextAnchor265"/>The critical section and thread safety</h2>
			<p>The critical <a id="_idIndexMarker227"/>section is the part of<a id="_idIndexMarker228"/> an application that reads/writes variables that are used by multiple threads. We can think of these as the global variables th<a id="_idTextAnchor266"/>at are used across the application and are modified in different places at different times or at the same time. In a multithreaded scenario, at any poi<a id="_idTextAnchor267"/>nt in time, only one thread should be allowed to modify such variables, and only one thread should be allowed to enter the critical section. </p>
			<p>If there are no such variables/sections in your application, it can be considered thread-safe. So, it's always advisable to identify variables in the application that are not thread-safe and handle them accordingly. To protect access to the critical section fro<a id="_idTextAnchor268"/>m non-thread-safe variables, there<a id="_idIndexMarker229"/> are <a id="_idIndexMarker230"/>va<a id="_idTextAnchor269"/>rious constructs available, known as <strong class="bold">synchronization primitives</strong> or <strong class="bold">synchronization constructs</strong>, which primarily fall into two categories:</p>
			<ul>
				<li><strong class="bold">Locking constructs</strong>: These allow a thread to e<a id="_idTextAnchor270"/>nter the critical section to protect access to the shared resources, and all other threads wait until the lock is freed by the acquired thread.</li>
				<li><strong class="bold">Signaling constructs</strong>: These allow a thread to enter t<a id="_idTextAnchor271"/>he critical section by signaling the availability of resources, as in a producer-consumer model, where a producer<a id="_idIndexMarker231"/> locks a resource and the consumer waits for a signal rather <a id="_idIndexMarker232"/>than polling.</li>
			</ul>
			<p>Let's discuss a few synchroni<a id="_idTextAnchor272"/><a id="_idTextAnchor273"/>zation primitives in the next section.</p>
			<h2 id="_idParaDest-78"><a id="_idTextAnchor274"/>Introducing locks</h2>
			<p>A <strong class="bold">lock</strong> is a basic<a id="_idIndexMarker233"/> class that allows you to achieve synchron<a id="_idTextAnchor275"/>ization in multithreaded code where any variable inside the lock block can be accessed by only one thread. In locks, the thread acquiring the lock needs to release the lock, and until then, any other thread trying to enter the lock goes into a wait state. A simple lock can be created, as shown in the following code:</p>
			<pre class="source-code">            object locker = new object();</pre>
			<pre class="source-code">            lock (locker)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                quantity--;</pre>
			<pre class="source-code">            }</pre>
			<p>The thread that is the first to execute this code will acquire the lock and release it after the completion of the code block. Locks can also be acquired using <strong class="source-inline">Monitor.Enter</strong> and <strong class="source-inline">Monitor.Exit</strong>, and in fact, using a lock compiler internally converts the thread t<a id="_idTextAnchor276"/>o <strong class="source-inline">Monitor.Enter</strong> and <strong class="source-inline">Monitor.Exit</strong>. A few important points about locks follow:</p>
			<ul>
				<li>They should always be used on the reference type due to their thread affinity.</li>
				<li>They are very expensive in terms of performance, as they pause the threads that want to enter the critical section before allowing them to resume, which adds some lag.</li>
				<li>Double-checking the acquiring lock is also a good practice, similar to how it is done in<a id="_idTextAnchor277"/> the singleton implementation.</li>
			</ul>
			<p>Locks do have some problems:</p>
			<ul>
				<li>You need to lock the shared data/object wherever it's being modified or enumerated. It's easy to miss critical sections in the application as <em class="italic">critical section</em> is more of a logical term. Compilers will not flag it if there aren't any locks around a critical section.</li>
				<li>If not handled correctly, you mig<a id="_idTextAnchor278"/>ht end up in a deadlock.</li>
				<li>Scalability is a problem, as only one thread can access a lock at a time, while all other threads must wait.<p class="callout-heading">Note</p><p class="callout">There is another important<a id="_idIndexMarker234"/> concept known as <strong class="bold">atomicity</strong>. An operation is atomic only if there isn't any way to read the intermediate state of a variable or to write the intermediate state to a variable. For example, if an integer's value is being modified from two to six, any thread reading this integer value will only see two or six; none of the threads will see the thread's intermediate state where the integer was only partially updated. Any code that is thread-safe automatically guarantees atomicity.</p><p class="callout">Use concurrent <a id="_idIndexMarker235"/>collections, described in a later section, instead of locks, as concurrent collections int<a id="_idTextAnchor279"/><a id="_idTextAnchor280"/>ernally handle locking critical secti<a id="_idTextAnchor281"/>ons.</p></li>
			</ul>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor282"/>Mutex (Windows only)</h2>
			<p>A <strong class="bold">mutex</strong> is also a type of<a id="_idIndexMarker236"/> lock, one that not only supports locking a resource within a process but also locking a resource across multiple processes. A mutex can be created using the <strong class="source-inline">System.Threading.Mutex</strong> class, and any thread that wants to enter the critical section needs to call the <strong class="source-inline">WaitOne</strong> method. Releasing a mutex happens through the <strong class="source-inline">ReleaseMutex</strong> method; so, we basically create an instance of the <strong class="source-inline">System.Threading.Mutex</strong> class and call <strong class="source-inline">WaitOne</strong>/<strong class="source-inline">ReleaseMutex</strong> to enter/exit the critical section, respectively. A couple of important<a id="_idTextAnchor283"/> points about mutexes follow:</p>
			<ul>
				<li>Mutexes have thread affinity, so a thread that calls <strong class="source-inline">WaitOne</strong> needs to call <strong class="source-inline">ReleaseMutex</strong>.</li>
				<li>A constructor of the <strong class="source-inline">System.Threading.Mutex</strong> class is available that accepts the name of a mutex, which allows sharing across processes<a id="_idTextAnchor284"/><a id="_idTextAnchor285"/> using the name<a id="_idIndexMarker237"/> passed to the constructor.</li>
			</ul>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor286"/>Introducing semaphores and SemaphoreSlim</h2>
			<p>A <strong class="bold">semaphore</strong> is a<a id="_idIndexMarker238"/> non-exclusive<a id="_idIndexMarker239"/> lock that supports synchronization by allowing multiple threads to enter a critical section. However, unlike exclusive <a id="_idTextAnchor287"/>locks, a semaphore is used in scenarios where there is a need to restrict access to a pool of resources – for example, a database <a id="_idTextAnchor288"/>connection pool that allows a fixed number of connections between an application and a database. </p>
			<p>Going back to our example of shopping for a product in an e-commerce application, if  the available quantity of a product is 10, that means that 10 people can add this item to their shopping carts and place orders. If 11 orders are placed concurrently, 10 users should be allowed to place orders, and the 11th should be put on hold until the first 10 orders are completed.</p>
			<p>In .NET, a semaphore can be created by creating an instance of the <strong class="source-inline">System.Threading.Semaphore</strong> class and passing two parameters:</p>
			<ul>
				<li>The initial number of active requests</li>
				<li>The total number of concurrently allowed requests</li>
			</ul>
			<p>Here is a simple code snippet that creates a semaphore:</p>
			<pre class="source-code">Semaphore quantity = new Semaphore(0, 10);</pre>
			<p>In this case, <strong class="source-inline">0</strong> means none of the requests has acquired the shared resource and a maximum of 10 concurrent requests are allowed. To acquire a shared resource, we need to call <strong class="source-inline">WaitOne()</strong>, and to release a resource, we need to call the <strong class="source-inline">Release()</strong> method.</p>
			<p>To create semaphores, there is another lightweight class available in .NET, and that is <strong class="source-inline">SemaphoreSlim</strong>, the slim version, which usually relies on a<a id="_idIndexMarker240"/> concept called <strong class="bold">spinning</strong>. In this, whenever a shared resource needs to be locked, instead of locking the resource immediately, <strong class="source-inline">SemaphoreSlim</strong> uses a small loop that runs for a few microseconds so that it doesn't have to go through the costly process of blocking, context switching, and internal kernel transition (semaphores use Windows kernel semaphores to lock a resource). Eventually, <strong class="source-inline">SemaphoreSlim</strong> falls back to locking if the shared resource still needs to be locked.</p>
			<p>Creating a <strong class="source-inline">SemaphoreSlim</strong> instance is almost the same as for semaphores; the only difference is that for locking, it has <strong class="source-inline">WaitAsync</strong> instead of <strong class="source-inline">WaitOne</strong>. There is also <strong class="source-inline">CurrentCount</strong> available, which tells u<a id="_idTextAnchor289"/>s the number of locks acquired.</p>
			<p>Some key facts about semap<a id="_idTextAnchor290"/>hores and <strong class="source-inline">SemaphoreSlim</strong> follow:</p>
			<ul>
				<li>As a semaphore is used to access a pool of resources, semaphores and <strong class="source-inline">SemaphoreSlim</strong> don't have thread affinity, and any thread can release a resource.</li>
				<li>The <strong class="source-inline">Semaphore</strong> class in .NET Core supports named semaphores. Named semaphores can be used to lock resources across processes; however, the <strong class="source-inline">SemaphoreSlim</strong> class does not support named semaphores.</li>
				<li>The <strong class="source-inline">SemaphoreSlim</strong> class, unlike <strong class="source-inline">Semaphore</strong>, supports asynchronous methods and cancellation, which means it can be used well with async-await methods. The <a id="_idIndexMarker241"/>async-await keyword helps in writing non-blocking <a id="_idIndexMarker242"/>asynchronous methods and is covered in the <a id="_idTextAnchor291"/><a id="_idTextAnchor292"/><em class="italic">Introducing async-await</em> section in this chapter.</li>
			</ul>
			<h2 id="_idParaDest-81">Choosing the <a id="_idTextAnchor293"/>right synchronization constructs</h2>
			<p>There are <a id="_idIndexMarker243"/>other signaling constructs to cover; the following table gives you a high-level view of their usage and real-life examples of them:</p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/Table_4.1_a.jpg" alt="Table 4.1 – A synchronization constructs comparison&#13;&#10;"/>
				</div>
			</div>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/Table_4.1_b.jpg" alt="Table 4.1 – A synchronization constructs comparison&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Table 4.1 – A sy<a id="_idTextAnchor294"/>nchronization constructs comparison</p>
			<p>So far, we <a id="_idIndexMarker244"/>have covered the following:</p>
			<ul>
				<li>Various ways of multithreading using the <strong class="source-inline">Thread</strong> and <strong class="source-inline">ThreadPool</strong> classes and their limitations</li>
				<li>The importance of lazy initialization and how it helps in multithreaded environments</li>
				<li>The various synchronization co<a id="_idTextAnchor295"/>nstructs that are available in .NET</li>
			</ul>
			<p>We will use these concepts in later chapters when we create some cross-cutting components.</p>
			<p>In the next section, we will see how to overcome the limitations of <strong class="source-inline">Thread</strong> and <strong class="source-inline">T<a id="_idTextAnchor296"/><a id="_idTextAnchor297"/>hreadPool</strong> through<a id="_idIndexMarker245"/> tasks and the use of the TPL.</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor298"/>Introducing tasks and parallels</h1>
			<p>We know <a id="_idIndexMarker246"/>that<a id="_idIndexMarker247"/> asynchronous programming<a id="_idIndexMarker248"/> helps our applic<a id="_idTextAnchor299"/>ations to scale and respond better, so implementing asynchronous applications should not be overhead for developers. <strong class="source-inline">Thread</strong> and <strong class="source-inline">ThreadPool</strong>, while helping to achieve asynchronicity, add a lot of overhead and come with limitations. </p>
			<p>Hence, Microsoft came up with tasks that make it easier to deve<a id="_idTextAnchor300"/>lop asynchronous applications. In fact, most of the newer APIs in .NET 6 only support the asynchronous way of programming – for<a id="_idIndexMarker249"/> example, the <strong class="bold">Universal Windows Platform</strong> (<strong class="bold">UWP</strong>) doesn't even expose APIs to create threads without tasks. As such, understanding tasks and the TPL is fundamental to being able to write asynchronous programs using C#. </p>
			<p>We will dive deep into these topics in this section, and later, we will see how the C# async-await keywords comb<a id="_idTextAnchor301"/><a id="_idTextAnchor302"/>ined with the TPL simplify asynchronous programming.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor303"/>Introduction to Task and the TPL</h2>
			<p>The idea behind <a id="_idIndexMarker250"/>asynchronous<a id="_idIndexMarker251"/> progra<a id="_idTextAnchor304"/>mming is that none of the threads should be waiting on an operation <a id="_idTextAnchor305"/>– that is, the framework should have the capability to wrap an operation into some abstraction and then resume once the operation is completed without blocking any threads. This abstraction is nothing but the <strong class="source-inline">Task</strong> class, which is exposed through <strong class="source-inline">System.Threading.Tasks</strong> and helps in writing asynchronous code in .NET.</p>
			<p>The <strong class="source-inline">Task</strong> class simplifies wrapping any wait operation, whether it is data retrieved from a database, a file being loaded into memory<a id="_idTextAnchor306"/> from disk, or any highly CPU-intensive operat<a id="_idTextAnchor307"/>ion, and simplifies running it on a separate thread if needs be. It has the following important features:</p>
			<ul>
				<li><strong class="source-inline">Task</strong> supports returning values from an operation once it is completed through its generic type, <strong class="source-inline">Task&lt;T&gt;</strong>.</li>
				<li><strong class="source-inline">Task</strong> takes care of scheduling threads on <strong class="source-inline">ThreadPool</strong>, partitioning operations, and scheduling more than one thread from <strong class="source-inline">ThreadPool</strong> accordingly, all while abstracting the complexity of doing it.</li>
				<li>Reports completion supports cancellation through <strong class="source-inline">CancellationToken</strong> and progress reporting through <strong class="source-inline">IProgress</strong>.</li>
				<li><strong class="source-inline">Task</strong> supports creating child tasks and manages relationships between child and parent tasks.</li>
				<li>Exceptions are propagated to the calling application, even for multi-hierarchical parent/child tasks.</li>
				<li>Most importantly, <strong class="source-inline">Task</strong> supports async-await, which helps in resuming the processing in a calling application/method once the operation in the task is completed.</li>
			</ul>
			<p>The TPL is a group of APIs provided by .NET in <strong class="source-inline">System.Threading.Tasks</strong> and <strong class="source-inline">System.Threading</strong>, and it provides wa<a id="_idTextAnchor308"/>ys to create and manage tasks. Tasks can be created by creating an object of the <strong class="source-inline">System.Threading.Tasks.Task</strong> class and passing a<a id="_idIndexMarker252"/> block <a id="_idIndexMarker253"/>of code that needs to be executed on the task. We can create a task in multiple ways:</p>
			<ul>
				<li>You can create an object of the <strong class="source-inline">Task</strong> class and pass a Lambda expression. In this method, it needs to be started explicitly, as shown in the following code:<p class="source-code">            Task dataTask = new Task(() =&gt;</p><p class="source-code">             FetchDataFromAPI("https://foo.com/api"));</p><p class="source-code">            dataTask.Start();</p></li>
				<li>A task can also be created using <strong class="source-inline">Task.Run</strong>, as shown in the following code, which supports creating and starting the task without explicitly calling <strong class="source-inline">Start()</strong>:<p class="source-code">Task dataTask = Task.Run(() =&gt; FetchDataFromAPI ("https://foo.com/api"));</p></li>
				<li>Another way to create a task is by using <strong class="source-inline">Task.Factory.StartNew</strong>:<p class="source-code">Task dataTask = Task.Factory.StartNew(() =&gt; FetchDataFromAPI("https://foo.com/api"));</p></li>
			</ul>
			<p>In all these methods, a <strong class="source-inline">ThreadPo<a id="_idTextAnchor309"/>ol</strong> thread is used to run the <strong class="source-inline">FetchDataFromAPI</strong> method and is refe<a id="_idTextAnchor310"/>renced via the <strong class="source-inline">dataTask</strong> object, which is returned to the caller to track the completion of the operation/exception. </p>
			<p>As this task would asynchronously execute on a <strong class="source-inline">ThreadPool</strong> thread, and as all <strong class="source-inline">ThreadPool</strong> threads are background threads, the application wouldn't wait for the <strong class="source-inline">FetchDataFromAPI</strong> method to complete. The TPL exposes a <strong class="source-inline">Wait</strong> method to wait on the completion of the task, such as <strong class="source-inline">dataTask.Wait()</strong>. Here is a code snippet from a <a id="_idIndexMarker254"/>small <a id="_idIndexMarker255"/>console application that uses a task:</p>
			<pre class="source-code">Task t = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">             FetchDataFromAPI("https://foo.com"));</pre>
			<pre class="source-code">t.Wait();</pre>
			<pre class="source-code">void FetchDataFromAPI(string apiURL)</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">     Thread.Sleep(2000);</pre>
			<pre class="source-code">     Console.WriteLine("data returned from API");</pre>
			<pre class="source-code">}</pre>
			<p>In this snippet, we used a Lambda expression. However, it could be a delegate or action delegate (in the case of a parameter-less method), so something such as the following can also be used to create a task:</p>
			<pre class="source-code">Task t = Task.Factory.StartNew(delegate { FetchDataFromAPI("https://foo.com");});</pre>
			<p>Either way, you receive a reference to<a id="_idTextAnchor311"/> the <strong class="source-inline">Task</strong> object and handle it accordingly. If a meth<a id="_idTextAnchor312"/>od is returning a value, then we can use a generic version of the <strong class="source-inline">Task</strong> class and use the <strong class="source-inline">Result</strong> method to retrieve data from <strong class="source-inline">Task</strong>. For example, if <strong class="source-inline">FetchDataFromAPI</strong> returns a string, we can use <strong class="source-inline">Task&lt;String&gt;</strong>, as shown in the following snippet:</p>
			<pre class="source-code">            Task&lt;string&gt; t =</pre>
			<pre class="source-code">             Task.Factory.StartNew&lt;string&gt;(()</pre>
			<pre class="source-code">             =&gt; FetchDataFromAPI(""));</pre>
			<pre class="source-code">            t.Wait();</pre>
			<pre class="source-code">            Console.WriteLine(t.Result);</pre>
			<p>There are various additional parameters that each of these methods accepts, and a few important ones are as follows:</p>
			<ul>
				<li>Cancellation using an object of the <strong class="source-inline">CancellationToken</strong> class, generated using the <strong class="source-inline">CancellationTokenSource</strong> class.</li>
				<li>Control the behavior of task creation and execution through the <strong class="source-inline">TaskCreationOptions</strong> enum.</li>
				<li>Custom implementation of <strong class="source-inline">TaskScheduler</strong> to control how tasks are queued.</li>
			</ul>
			<p><strong class="source-inline">TaskCreationOptions</strong> is an enum in the TPL that tells <strong class="source-inline">TaskScheduler</strong> what kind of task we are creating. For example, we can create a long-running task, as follows:</p>
			<pre class="source-code">Task&lt;string&gt; t = Task.Factory.StartNew&lt;string&gt;(() =&gt; FetchDataFromAPI(""), TaskCreationOptions.LongRunning);</pre>
			<p>Although this<a id="_idIndexMarker256"/> doesn't<a id="_idIndexMarker257"/> guarantee any faster output, it acts more like a hint to the scheduler to optimize itself. For example, the scheduler can spin up more threads if it sees a long-running task being scheduled. All the options for this enum can be found at <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskcreationoptions?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.threadin<span id="_idTextAnchor313"/>g.tasks.taskcreationoptions?view=net-6.0</a>.</p>
			<p><strong class="source-inline">Task</strong> also supports waiting on multiple tasks at the same time by creating and passing all the tasks as parameters to the following methods:</p>
			<ul>
				<li><strong class="source-inline">WaitAll</strong>: Wait for the completion of all tasks and block the current thread. Not recommended for application development.</li>
				<li><strong class="source-inline">WhenAll</strong>: Wait for the completion of all tasks without blocking the current thread. Usually used with async-await. Recommended for application development.</li>
				<li><strong class="source-inline">WaitAny</strong>: Wait for the completion of one of the tasks and block the current thread until then. Not recommended for application development.</li>
				<li><strong class="source-inline">WhenAny</strong>: Wait for the completion of one of the tasks without blocking the current thread. Usually<a id="_idIndexMarker258"/> used with async-awai<a id="_idTextAnchor314"/>t. Not recommended for application <a id="_idIndexMarker259"/>development<a id="_idTextAnchor315"/>.</li>
			</ul>
			<p>Tasks, unlike threads, have comprehensive e<a id="_idTextAnchor316"/><a id="_idTextAnchor317"/>xception handling support. Let's see that in the next section.</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor318"/>Handling task exceptions</h2>
			<p>Exception <a id="_idIndexMarker260"/>handling in tasks is as simp<a id="_idTextAnchor319"/>le as writing a <strong class="source-inline">try</strong> block around the task and then catching the exceptions, which are usually wrapped in <strong class="source-inline">AggregateException</strong>, as shown in the following code snippet:</p>
			<pre class="source-code">            try</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                Task&lt;string&gt; t =</pre>
			<pre class="source-code">                 Task.Factory.StartNew&lt;string&gt;(()</pre>
			<pre class="source-code">                 =&gt; FetchDataFromAPI(""));</pre>
			<pre class="source-code">                t.Wait();</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            catch (AggregateException agex)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                //Handle exception</pre>
			<pre class="source-code">                Console.WriteLine(</pre>
			<pre class="source-code">                  agex.InnerException.Message);</pre>
			<pre class="source-code">            }</pre>
			<p>In the preceding code, <strong class="source-inline">agex.InnerException</strong> will give you the actual exception, as we are waiting on a single task. However, if we are waiting on multiple tasks, it would be the <strong class="source-inline">InnerExceptions</strong> collection that we could loop through. Also, it comes with a <strong class="source-inline">Handle</strong> callback method, which can be subscribed in a <strong class="source-inline">catch</strong> block, and the callback once triggered will have information about the exception.</p>
			<p>As shown in the preceding code, for a tas<a id="_idTextAnchor320"/>k to propagate an exception, we need to call the <strong class="source-inline">Wait</strong> method or some other blocking construct such as <strong class="source-inline">WhenAll</strong> to trigger the <strong class="source-inline">catch</strong> block. However, under the hood, any exception to <strong class="source-inline">Task</strong> is actually held in the <strong class="source-inline">Exception</strong> property of the <strong class="source-inline">Task</strong> class, which is of the <strong class="source-inline">AggregateException</strong> type and can be observed for any underlying exceptions in the task.</p>
			<p>Also, if a task is the parent of attached child tasks or nested tasks, or if you are waiting on multiple tasks, multiple exceptions can be thrown. To propagate all the exceptions back to the calling<a id="_idIndexMarker261"/> thread, the <strong class="source-inline">Task</strong> infrastru<a id="_idTextAnchor321"/>cture wraps them in an <strong class="source-inline">AggregateException</strong> instance.</p>
			<p>More details about handling exceptions can be found at <a href="https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/exception-handling-task-parallel-library">https://docs.microsoft.com/en-us/dotnet/standar<span id="_idTextAnchor322"/><span id="_idTextAnchor323"/>d/parallel-programming/exception-handling-tas<span id="_idTextAnchor324"/>k-parallel-library</a>.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor325"/>Implementing task cancellation</h2>
			<p>.NET provides <a id="_idIndexMarker262"/>two primary classes to support the cancellation of a task:</p>
			<ul>
				<li><strong class="source-inline">CancellationTokenSource</strong>: A class that creates a cancellation token and supports the cancellation of a token through the <strong class="source-inline">Cancel</strong> method</li>
				<li><strong class="source-inline">CancellationToken</strong>: A structure that listens to cancellation and triggers a notification if a task is canceled</li>
			</ul>
			<p>For canceling a task, there are two types of cancellation: </p>
			<ul>
				<li>One where a task is executed by mistake and needs to be canceled immediately </li>
				<li>Another where a task has started and needs to be stopped (aborted) midway </li>
			</ul>
			<p>For the former, we can create a task that supports cancellation. We use the TPL APIs and pass the cancellation token to the constructor and call the <strong class="source-inline">Cancel</strong> method of the <strong class="source-inline">CancellationTokenSource</strong> class if the task needs to be canceled, as shown in the following code snippet:</p>
			<pre class="source-code">            cts = new CancellationTokenSource();</pre>
			<pre class="source-code">            CancellationToken token = cts.Token;</pre>
			<pre class="source-code">            Task dataFromAPI = Task.Factory.StartNew(()</pre>
			<pre class="source-code">             =&gt; FetchDataFromAPI(new List&lt;string&gt; {</pre>
			<pre class="source-code">                "https://foo.com",</pre>
			<pre class="source-code">                "https://foo1.com",}), token);</pre>
			<pre class="source-code">            cts.Cancel();</pre>
			<p>All the .NET Core APIs that support asynchronous calling, such as <strong class="source-inline">GetAsync</strong> and <strong class="source-inline">PostAsync</strong> of the <strong class="source-inline">HttpClient</strong> class, have overloads to accept cancellation tokens. For the latter case (aborting a task), the decision<a id="_idTextAnchor326"/> is based on whether the operation that would be running supports cancellation or not. Assuming it supports cancellation, we can pass the cancellation token to the method and, inside the method call, check the <strong class="source-inline">IsCancellationRequested</strong> property of the cancellation token and handle it accordingly.</p>
			<p>Let's create a simple console application that creates a task that does support cancellation. Here, we are creating a <strong class="source-inline">FetchDataFromAPI</strong> method that accepts a list of URLs and retrieves data from those URLs. This method also supports cancellation using <strong class="source-inline">CancellationToken</strong>. In the implementation, we loop through the list of URLs and continue until <a id="_idIndexMarker263"/>cancellation is requested or the loop completes all iterations:</p>
			<pre class="source-code">        static string FetchDataFromAPI(List&lt;string&gt;</pre>
			<pre class="source-code">         apiURL, CancellationToken token)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            Console.WriteLine("Task started");</pre>
			<pre class="source-code">            int counter = 0;</pre>
			<pre class="source-code">            foreach (string url in apiURL)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                if (token.IsCancellationRequested)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    throw new TaskCanceledException($"data</pre>
			<pre class="source-code">                     from API returned up to iteration</pre>
			<pre class="source-code">                       {counter}");</pre>
			<pre class="source-code">                    //throw new </pre>
			<pre class="source-code">                    //OperationCanceledException($"data </pre>
			<pre class="source-code">                    //from API returned up to iteration </pre>
			<pre class="source-code">                    //{counter}"); </pre>
			<pre class="source-code">                    // Alternate exception with same result</pre>
			<pre class="source-code">                    //break; // To handle manually</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">                Thread.Sleep(1000);</pre>
			<pre class="source-code">                Console.WriteLine($"data retrieved from</pre>
			<pre class="source-code">                 {url} for iteration {counter}");</pre>
			<pre class="source-code">                counter++;</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            return $"data from API returned up to iteration</pre>
			<pre class="source-code">             {counter}";</pre>
			<pre class="source-code">        }</pre>
			<p>Now, call <strong class="source-inline">FetchDataFrom<a id="_idTextAnchor327"/>API</strong> with<a id="_idIndexMarker264"/> a list of four URLs from the main method, as shown in the following code. Here, we are creating <strong class="source-inline">CancellationToken</strong> using the <strong class="source-inline">Token</strong> property of the <strong class="source-inline">CancellationTokenSource</strong> class and passing it to the <strong class="source-inline">FetchDataFromAPI</strong> method. We are simulating a cancellation after 3 seconds so that <strong class="source-inline">FetchDataFromAPI</strong> will be canceled before the fourth URL is retrieved:</p>
			<pre class="source-code">CancellationTokenSource cts = new CancellationTokenSource();</pre>
			<pre class="source-code">CancellationToken token = cts.Token;</pre>
			<pre class="source-code">Task&lt;string&gt; dataFromAPI;</pre>
			<pre class="source-code">try</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">    dataFromAPI = Task.Factory.StartNew&lt;string&gt;(() =&gt;</pre>
			<pre class="source-code">     FetchDataFromAPI(new List&lt;string&gt; {</pre>
			<pre class="source-code">    "https://foo.com","https://foo1.com","https://foo2.com"</pre>
			<pre class="source-code">      ,"https://foo3.com", "https://foo4.com", }, token));</pre>
			<pre class="source-code">    Thread.Sleep(3000);</pre>
			<pre class="source-code">    cts.Cancel(); //Trigger cancel notification to </pre>
			<pre class="source-code">                  //cancellation token</pre>
			<pre class="source-code">    dataFromAPI.Wait(); // Wait for task completion</pre>
			<pre class="source-code">    Console.WriteLine(dataFromAPI.Result); // If task is </pre>
			<pre class="source-code">      //completed display message accordingly</pre>
			<pre class="source-code">}</pre>
			<pre class="source-code">catch (AggregateException agex)</pre>
			<pre class="source-code">{// Handle exception}</pre>
			<p>Once we run this <a id="_idIndexMarker265"/>code, we can see output for three URLs and then an exception/break (based on whichever line is commented out in the <strong class="source-inline">FetchDataFromAPI</strong> method).</p>
			<p>In the preceding sample, we have simulated a long-running code block using a <strong class="source-inline">for</strong> loop and <strong class="source-inline">Thread.Sleep</strong>, canceled the task, and handled the code accordingly. However, there could be a scenario where the long-running code block may not support cancellation. </p>
			<p>In those cases, we must write a wrapper method that accepts a cancellation token and have the wrapper internally call the long-running operation; then, in the main method, we call the wrapper code. The following snippet shows a wrapper method that makes u<a id="_idTextAnchor328"/>se of <strong class="source-inline">TaskCompletionSource</strong>, which is another class in the TPL. It is used to convert non-task-based asynchronous methods (including even the ones based on asynchronous methods) to tasks through the <strong class="source-inline">Task</strong> property available in the class. In this case, we will pass the cancellation token to <strong class="source-inline">TaskCompletionSource</strong> so that its <strong class="source-inline">Task</strong> is updated accordingly:</p>
			<pre class="source-code">        static Task&lt;string&gt;</pre>
			<pre class="source-code">         FetchDataFromAPIWithCancellation(List&lt;string&gt;</pre>
			<pre class="source-code">         apiURL, CancellationToken cancellationToken)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            var tcs = new TaskCompletionSource&lt;string&gt;();</pre>
			<pre class="source-code">            tcs.TrySetCanceled(cancellationToken);</pre>
			<pre class="source-code">            // calling overload of long running operation </pre>
			<pre class="source-code">            // that doesn't support cancellation token</pre>
			<pre class="source-code">            var dataFromAPI = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">             FetchDataFromAPI(apiURL));</pre>
			<pre class="source-code">            // Wait for the first task to complete</pre>
			<pre class="source-code">            var outputTask = Task.WhenAny(dataFromAPI,</pre>
			<pre class="source-code">             tcs.Task);</pre>
			<pre class="source-code">            return outputTask.Result;</pre>
			<pre class="source-code">        }</pre>
			<p>In this<a id="_idIndexMarker266"/> case, <strong class="source-inline">CancellationToken</strong> is tracked through the <strong class="source-inline">Task</strong> property of <strong class="source-inline">TaskCompletionSource</strong>, and we created another task to call our long-running operation (the one without cancellation token support), and whichever<a id="_idTextAnchor329"/> task finishes first is the one we return.</p>
			<p>Of course, the <strong class="source-inline">Main</strong> method needs to be updated to call the wrapper, as shown here (the rest of the code remains the same):</p>
			<pre class="source-code">            dataFromAPI = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">             FetchDataFromAPIWithCancellation(new</pre>
			<pre class="source-code">             List&lt;string&gt;</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                        "https://foo.com",</pre>
			<pre class="source-code">                        "https://foo1.com",</pre>
			<pre class="source-code">                        "https://foo2.com",</pre>
			<pre class="source-code">                        "https://foo3.com",</pre>
			<pre class="source-code">                        "https://foo4.com",</pre>
			<pre class="source-code">                    }, token)).Result;</pre>
			<p>This doesn't cancel the underlying method but still allows the application to exit before the underlying operation is completed.</p>
			<p>Task cancellation is a very useful mechanism that helps in reducing unwanted processing, either<a id="_idIndexMarker267"/> in tasks that haven't started yet or ones that have started but need to be stopped/abor<a id="_idTextAnchor330"/><a id="_idTextAnchor331"/>ted. Hence, all the asynchronous APIs in .NET do support cancellation.</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor332"/>Implementing continuations</h2>
			<p>In enterprise <a id="_idIndexMarker268"/>applications, m<a id="_idTextAnchor333"/>ost of the time, there will be a need to create multiple tasks, build a hierarchy of tasks, create dependent tasks, or create child/parent relationships between tasks. Task continuation can be used to define such child tasks/sub-tasks. It works like JavaScript promises and supports chaining tasks up to multiple levels. Just like promises, the subsequent task in a hierarchy executes after the first task, and this can be further chained to multiple levels.</p>
			<p>There are various ways to achieve task continuation, but the most common way is to use the <strong class="source-inline">ContinueWith</strong> method of the <strong class="source-inline">Task</strong> class, as shown in the following example:</p>
			<pre class="source-code">Task.Factory.StartNew(() =&gt; Task1(1)) // 1+2 = 3</pre>
			<pre class="source-code">                .ContinueWith(a =&gt; Task2(a.Result)) // 3*2 = 6</pre>
			<pre class="source-code">                    .ContinueWith(b =&gt; Task3(b.Result))// 6-2=4</pre>
			<pre class="source-code">                        .ContinueWith(c =&gt; Console.WriteLine(c.Result));</pre>
			<pre class="source-code">Console.ReadLine();</pre>
			<pre class="source-code">static int Task1(int a) =&gt; a + 2;</pre>
			<pre class="source-code">static in<a id="_idTextAnchor334"/>t Task2(int a) =&gt; a * 2;</pre>
			<pre class="source-code">static int Task3(int a) =&gt; a - 2;</pre>
			<p>As you might have guessed, here the output would be <strong class="source-inline">4</strong>, and each task executes once the preceding task's execution is completed.</p>
			<p><strong class="source-inline">ContinueWith</strong> accepts one important enum called <strong class="source-inline">TaskContinuationOptions</strong>, which supports continuation for different conditions. For example, we can pass <strong class="source-inline">TaskContinuationOptions.OnlyOnFaulted</strong> as a parameter to create a continuation task that executes when there is an exception in the preceding task or pass <strong class="source-inline">TaskContinuationOptions.AttachedToParent</strong> to create a continuation task that enforces a parent-child relationship and forces a parent task to complete execution only after the child task.</p>
			<p>As with <strong class="source-inline">WhenAll</strong> and <strong class="source-inline">WhenAny</strong>, <strong class="source-inline">ContinueWith</strong> also comes with similar siblings, as follows:</p>
			<ul>
				<li><strong class="source-inline">Task.Factory.ContinueWhenAll</strong>: This accepts multiple task references as parameters and creates a continuation when all the tasks are completed.</li>
				<li><strong class="source-inline">Task.Factory.ContinueWhenAny</strong>: This accepts multiple task references as parameters and creates a co<a id="_idTextAnchor335"/>ntinuation when one of the referenced tasks is completed.</li>
			</ul>
			<p>Grasping task <a id="_idIndexMarker269"/>continuation is critical to understanding the under-the-ho<a id="_idTextAnchor336"/><a id="_idTextAnchor337"/>od workings of async-await, which we will discuss later in this chapter.</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor338"/>SynchronizationContext</h2>
			<p><strong class="source-inline">SynchronizationContext</strong> is an <a id="_idIndexMarker270"/>abstract class available in <strong class="source-inline">System.Threading</strong> that helps in communication between <a id="_idTextAnchor339"/>threads. For example, updating a UI element from a parallel task requires the thread to rejoin the UI thread and resume execution. <strong class="source-inline">SynchronizationContext</strong> provides this abstraction primarily through the <strong class="source-inline">Post</strong> method of this class, which accepts a delegate to execute at a later stage. So, in the preceding example, if I need to update a UI element, I need to take <strong class="source-inline">SynchronizationContext</strong> of the UI thread, call its <strong class="source-inline">Post</strong> method, and pass the necessary data to update the UI element.</p>
			<p>As <strong class="source-inline">SynchronizationContext</strong> is an abstract class, there are various derived types of it – for instance, Windows Forms has <strong class="source-inline">WindowsFormsSynchronizationContext</strong> and WPF has <strong class="source-inline">DispatcherSynchronizationContext</strong>.</p>
			<p>The primary advantage of <strong class="source-inline">SynchronizationContext</strong> being an abstraction is that it can be helpful to <a id="_idIndexMarker271"/>queue a d<a id="_idTextAnchor340"/><a id="_idTextAnchor341"/>elegate, irrespective <a id="_idTextAnchor342"/>of the overridden implementation of the <strong class="source-inline">Post</strong> method.</p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor343"/>TaskScheduler</h2>
			<p>When we created tasks using<a id="_idIndexMarker272"/> the various methods described earlier, we saw that a task gets <em class="italic">scheduled</em> on a <strong class="source-inline">ThreadPool</strong> thread, but the question arises of who or what does that. <strong class="source-inline">System.Threading.Tasks.TaskScheduler</strong> is the class available in the TPL that takes care of queueing and executing task delegates on a <strong class="source-inline">ThreadPool</strong> thread.</p>
			<p>Of course, this is an abstract class, and the framework comes with two derived classes:</p>
			<ul>
				<li><strong class="source-inline">ThreadPoolTaskScheduler</strong></li>
				<li><strong class="source-inline">SynchronizationContextScheduler</strong></li>
			</ul>
			<p><strong class="source-inline">TaskScheduler</strong> exposes a <strong class="source-inline">Default</strong> property, which is by default set to <strong class="source-inline">ThreadPoolTaskScheduler</strong>. Hence, by default, all tasks are scheduled to <strong class="source-inline">ThreadPool</strong> threads; however, a GUI application typically uses <strong class="source-inline">SynchronizationContextScheduler</strong> so <a id="_idTextAnchor344"/>that tasks can successfully go back and update UI elements.</p>
			<p>.NET Core comes with sophisticated derived types of the <strong class="source-inline">TaskScheduler</strong> and <strong class="source-inline">SynchronizationContext</strong> classes. However, they play a major role in async-await, and they help in debugging any deadlock-related issues quickly.</p>
			<p>Note that looking at the internal workings of <strong class="source-inline">TaskScheduler</strong> and <strong class="source-inline">SynchronizationContext</strong> is <a id="_idTextAnchor345"/><a id="_idTextAnchor346"/>beyond the scope of this book and is left to you to explore as an exercise.</p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor347"/>Implementing data parallelism</h2>
			<p>Data parallelism <a id="_idIndexMarker273"/>is <a id="_idTextAnchor348"/>all about partitioning a source collection into multiple parallel executable tasks that perform the same operation parallelly. With the TPL, this is available in the <strong class="source-inline">Parallel</strong> static class, which exposes methods such as <strong class="source-inline">For</strong> and <strong class="source-inline">ForEach</strong> with multiple overloads to handle such execution.</p>
			<p>Say you have a collection of a million numbers and you need to find the prime numbers. Data parallelism can come in handy here, as the collection can be split into ranges and evaluated for prime numbers. A typically parallel <strong class="source-inline">for</strong> loop is written, as shown in the following snippet:</p>
			<pre class="source-code">            List&lt;int&gt; numbers = Enumerable.Range(1,</pre>
			<pre class="source-code">             100000).ToList();</pre>
			<pre class="source-code">            Parallel.For(numbers.First(), numbers.Last(), x</pre>
			<pre class="source-code">             =&gt; CalculatePrime(x));</pre>
			<p>However, a more realistic example would be something like an image processing application that needs to process each pixel in an image and reduce the brightness of each pixel by five points. Such operations can be hugely benefited by data parallelism, as each pixel is <a id="_idIndexMarker274"/>inde<a id="_idTextAnchor349"/>pendent of the others and hence can be processed parallelly.</p>
			<p>Similarly, there is a <strong class="source-inline">ForEach</strong> method in the <strong class="source-inline">Parallel</strong> static class, which can be us<a id="_idTextAnchor350"/>ed as follows:</p>
			<pre class="source-code">Parallel.ForEach(numbers, x =&gt; CalculatePrime(x));</pre>
			<p>Some of the key advantages of data parallelism using <strong class="source-inline">Parallel.For</strong> and <strong class="source-inline">Parallel.ForEach</strong> are listed here:</p>
			<ul>
				<li>Good for canceling loops; they work similarly to <strong class="source-inline">break</strong> in a regular <strong class="source-inline">for</strong> loop. In <strong class="source-inline">Parallel.For</strong>, this is supported by passing <strong class="source-inline">ParallelStateOptions</strong> to the delegate and then calling <strong class="source-inline">ParallelStateOptions.Break</strong>. When <strong class="source-inline">Break</strong> is encountered by one of the tasks, the <strong class="source-inline">LowestBreakIteration</strong> property of the <strong class="source-inline">ParallelStateOptions</strong> class is set, and all the parallel tasks will iterate until this number is reached. <strong class="source-inline">ParallelLoopResult</strong>, which is the return type of <strong class="source-inline">Parallel.For</strong> and <strong class="source-inline">Parallel.ForEach</strong>, has the <strong class="source-inline">IsCompleted</strong> property, which states whether the loop executed prematurely.</li>
				<li>They also support stopping the loop immediately through <strong class="source-inline">ParallelStateOptions.Stop</strong>. Also, some of the constructors of <strong class="source-inline">Parallel.For</strong> and <strong class="source-inline">Parallel.ForEach</strong> accept cancellation tokens, which can also be used to simulate <strong class="source-inline">ParallelStateOptions.Stop</strong>; however, a loop should be wrapped within a <strong class="source-inline">try…catch</strong> block, as <strong class="source-inline">OperationCanceledException</strong> would be thrown.</li>
				<li>If one of the tasks throws an exception, all the tasks will complete their current iteration and then stop processing. As with tasks, <strong class="source-inline">AggregateException</strong> is thrown back.</li>
				<li>Degrees of parallelism are supported by passing <strong class="source-inline">ParallelOptions</strong> and setting <strong class="source-inline">MaxDegreeOfParallelism</strong>, which will control the number of cores that tasks can parallelly execute on.</li>
				<li>The custom partitioning of a source collection is supported through range partitioning or chunk partitioning.</li>
				<li>Supports thread-safe local variables that are scoped to a thread or partition.</li>
				<li>Nested <strong class="source-inline">Parallel.For</strong> loops are supported, and their synchronization is automatically <a id="_idIndexMarker275"/>handled without introducing any manual synchronization.</li>
				<li>If <a id="_idTextAnchor351"/>each iteration uses a shared variable, synchronization needs to be implemented explicitly. So, to get the most out of data parallelism, use it for operations that can execute independently for each iteration without depending on shared resources.<p class="callout-heading">Tip</p><p class="callout">Data parallelism should be used carefully, as at times it is misused. It's like splitting 40 tasks among 4 people. If organizing this work (splitting and consolidating it) among 4 people represe<a id="_idTextAnchor352"/>nts much more work than just performing the overall work of the 40 tasks, then data parallelism isn't the right choice. For further reading, refer to <a href="https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/data-parallelism-task-parallel-library">https://docs.microsoft.com/en-u<span id="_idTextAnchor353"/><span id="_idTextAnchor354"/>s/dotnet/standard/parallel-programming/data-parallelism-task-parallel-library</a>.</p></li>
			</ul>
			<h2 id="_idParaDest-90"><a id="_idTextAnchor355"/>Using Parallel LINQ (PLINQ)</h2>
			<p>PLINQ is a <a id="_idIndexMarker276"/>parallel implementation of LINQ; this is a set of APIs available in the <strong class="source-inline">ParallelEnumera<a id="_idTextAnchor356"/>ble</strong> class that enables the parallel execution of LINQ queries. The simplest way of making a LINQ query run parallelly is to embed the <strong class="source-inline">AsParallel</strong> method in the LINQ query. See the following code snippet, which calls a method that calculates the prime numbers between 1 and 1,000:</p>
			<pre class="source-code">List&lt;int&gt; numbers = Enumerable.Range(1, 1000).ToList();</pre>
			<pre class="source-code">var resultList = numbers.AsParallel().Where(I =&gt; CalculatePrime</pre>
			<pre class="source-code">(i)).ToList();</pre>
			<p>Using LINQ query syntax, this would be as follows:</p>
			<pre class="source-code">var primeNumbers = (from i in numbers.AsParallel()where CalculatePrime(i) select i).ToList();</pre>
			<p>Internally, this query is split into multiple smaller queries that are parallelly executed on each processor, hence speeding up the query. The partitioned source needs to be merged back on the main thread so that the result (output c<a id="_idTextAnchor357"/>ollection) can be looped through for further processing/display.</p>
			<p>Let's create a console application that prints all prime numbers between a given range, using PLINQ combined with <strong class="source-inline">Parallel.For</strong>. Add the following method, which takes a number and returns <strong class="source-inline">true</strong> if it's a prime number and <strong class="source-inline">false</strong> otherwise:</p>
			<pre class="source-code">bool CalculatePrime(int num)</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">    bool isDivisible = false;</pre>
			<pre class="source-code">    for (int i = 2; i &lt;= num / 2; i++)</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        if (num % i == 0)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            isDivisible = true;</pre>
			<pre class="source-code">            break;</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">    if (!isDivisible &amp;&amp; num != 1)</pre>
			<pre class="source-code">        return true;</pre>
			<pre class="source-code">    else</pre>
			<pre class="source-code">        return false;</pre>
			<pre class="source-code">}</pre>
			<p>Now, in the main met<a id="_idTextAnchor358"/>hod, add the following code, which creates a list of the first 100 numbers that we will loop through using PLINQ before passing it to the <strong class="source-inline">CalculatePrime</strong> method; then, we'll <a id="_idIndexMarker277"/>finally display the list of prime numbers using <strong class="source-inline">Parallel.ForEach</strong>:</p>
			<pre class="source-code">List&lt;int&gt; numbers = Enumerable.Range(1, 100).ToList();</pre>
			<pre class="source-code">try</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">       var primeNumbers = (from number in </pre>
			<pre class="source-code">       numbers.AsParallel() where CalculatePrime(number) == </pre>
			<pre class="source-code">       true select number).ToList();</pre>
			<pre class="source-code">  Parallel.ForEach(primeNumbers, (primeNumber) =&gt;</pre>
			<pre class="source-code">  {</pre>
			<pre class="source-code">    Console.WriteLine(primeNumber);</pre>
			<pre class="source-code">  });</pre>
			<pre class="source-code">}</pre>
			<pre class="source-code">catch (AggregateException ex)</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">  Console.WriteLine(ex.InnerException.Message);</pre>
			<pre class="source-code">}</pre>
			<p>The output for this sample would be a list of prime numbers; however, you can see that the output will not be prime numbers in ascending order but in a random order, as the <strong class="source-inline">CalculatePrime</strong> method is called with multiple numbe<a id="_idTextAnchor359"/>rs parallelly.</p>
			<p>A diagram of the internal working of the preceding code follows:</p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/Figure_4.4_B18507.jpg" alt="Figure 4.4 – PLINQ and Parallel.ForEach&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – PLINQ and Parallel.ForEach</p>
			<p>PLINQ further <a id="_idIndexMarker278"/>provi<a id="_idTextAnchor360"/>des a method to process the result of each partition/thread without the overhead of merging the result into a calling thread using <strong class="source-inline">ForAll</strong>, and the preceding code can be further optimized as follows:</p>
			<pre class="source-code">            (from i in numbers.AsParallel()</pre>
			<pre class="source-code">             where CalculatePrime(i) == true</pre>
			<pre class="source-code">             select i).ForAll((primeNumber) =&gt;</pre>
			<pre class="source-code">               Console.WriteLine(primeNumber));</pre>
			<p class="callout-heading">Tip</p>
			<p class="callout">One of the best tools for playing around with LINQ/PLINQ is LINQPad; I recommend that y<a id="_idTextAnchor361"/>ou download it from <a href="https://www.linqpad.net/Download.aspx">https://www.linqpad.net/Download.aspx</a>.</p>
			<p>Some of the important things to remember for PLINQ are as follows:</p>
			<ul>
				<li>Merging results to the main thread can be configured by using the <strong class="source-inline">WithMergeOption</strong> method and passing the appropriate value through the <strong class="source-inline">ParallelMergeOperation</strong> enum.</li>
				<li>As with other parallel extensions, any exception is returned as <strong class="source-inline">AggregateException</strong>, and the execution of all the iterations stops immediately. Of course, if exceptions are swallowed within the delegate instead of them being thrown back, the execution can continue.</li>
				<li>There are various other extension methods, such as <strong class="source-inline">AsSequential</strong> and <strong class="source-inline">AsOrdered</strong>, and these can be combined in one single LINQ query. For example, based on that, <strong class="source-inline">AsSequential</strong> can be combined with <strong class="source-inline">AsParallel</strong> so that some partitions can be run sequentially and other partitions can be executed <a id="_idIndexMarker279"/>parallelly.</li>
				<li>Supports cancellation using the <strong class="source-inline">WithCancellation</strong> method.</li>
				<li>Degre<a id="_idTextAnchor362"/>es of parallelism are supported through <strong class="source-inline">WithDegreeOfParallelism</strong>.</li>
			</ul>
			<p>Data parallelism and PLINQ provide a lot of APIs that can be used to quickly enable the parallel execution of code without adding any additional overhead to the application logic. However, there is a subtle difference between them, as explained in the preceding section, and they should be used differently accordingly.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">PLINQ and the TPL together comprise parallel extensions.</p>
			<p>In this section, we have used <strong class="source-inline">Thread.Sleep</strong> in many places, but that has primarily been to simulate long-running operations; however, it is never recommended that you use this in <a id="_idIndexMarker280"/>production.</p>
			<p>In the next section, we will see how <a id="_idTextAnchor363"/><a id="_idTextAnchor364"/>we can club tasks with async-await and use async-await in enterprise applications.</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor365"/>Introducing async-await</h1>
			<p>So far, we have<a id="_idIndexMarker281"/> discussed writing asynchronous code using tasks and how the TPL simplifies creating and managing tas<a id="_idTextAnchor366"/>ks. However, tasks primarily rely on continuation, callbacks, or events to continue execution after the completion of a task. </p>
			<p>In enterprise applications, managing such code would be difficult; any runtime exceptions would be difficult to debug if too many tasks were chained. That's where C# comes in with async-await, a language feature introduced in C# 5.0 that simplifies the writing of asynchronous code, makes it more readable and maintainable, improves exception handling, and makes things easy to debug. So, let's dive into async-await.</p>
			<p><strong class="source-inline">async</strong> is a keyword in C# that is used as a modifier and, when prefixed to any method (or Lambda), converts a method into a state machine, enabling the method to use the <strong class="source-inline">await</strong> keyword in its body.</p>
			<p><strong class="source-inline">await</strong> is a keyword in C# that is used as an operator and is followed by an expression that returns an awaitable object (usually a task). <strong class="source-inline">await</strong> can be used only inside a method that has an <strong class="source-inline">async</strong> modifier, and as soon as a caller encounters an <strong class="source-inline">await</strong> statement, control is retur<a id="_idTextAnchor367"/><a id="_idTextAnchor368"/>ned and things are resumed; after <strong class="source-inline">await</strong>, the task is completed using continuations.</p>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor369"/>The task-based asynchronous pattern</h2>
			<p>Th<a id="_idTextAnchor370"/>e <strong class="bold">Task-Based Asynchronous Pattern</strong> (<strong class="bold">TAP</strong>) is a pattern <a id="_idIndexMarker282"/>used<a id="_idIndexMarker283"/> to implement asynchronous methods in which we make use of the <strong class="source-inline">async</strong> modifier and then use <strong class="source-inline">await</strong> on an asynchronous operation that is wrapped in a task (or any custom awaitable type that exposes <strong class="source-inline">GetAwaiter()</strong>). To put it simply, this pattern involves representing an asynchronous operation using a single method that has an <strong class="source-inline">async</strong> modifier and returns a task; any asynchronous operation is further awaited using <strong class="source-inline">await</strong>. The following is a sample co<a id="_idTextAnchor371"/>de snippet that downloads a file asynchronously, which is implemented<a id="_idTextAnchor372"/> using the TAP:</p>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/Figure_4.5_B18507.jpg" alt="Figure 4.5 – A sample asynchronous method using async-await&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.5 – A sample asynchronous method using async-await</p>
			<p>In the<a id="_idIndexMarker284"/> preceding<a id="_idIndexMarker285"/> figure, control flows as follows (using the number labels in the figure):</p>
			<ol>
				<li>The application starts execution with the <strong class="source-inline">Main</strong> method. Since <strong class="source-inline">Main</strong> is prefixed with the <strong class="source-inline">async</strong> method, it gets transformed into a type that implements a state machine. Execution continues until <strong class="source-inline">await</strong> is encountered at <strong class="source-inline">await</strong> <strong class="source-inline">DownloadFileAsync</strong>, and the thread is returned to the caller.</li>
				<li>Before returning to the caller, a call to the <strong class="source-inline">DownloadFileAsync</strong> method is stored in a <strong class="source-inline">Task</strong> object, and a reference to the <strong class="source-inline">Task</strong> object is also preserved. The remaining code of the <strong class="source-inline">Main</strong> method is wrapped inside the continuation of this task.</li>
				<li>A <strong class="source-inline">ThreadPool</strong> thread will start executing a <strong class="source-inline">DownloadFileAsync</strong> method, and it repeats the same steps – that is, it converts a method into a type that implements a state machine, continues execution until <strong class="source-inline">await</strong> is encountered, and then the task that is referenced is passed back; the remaining code is moved to the continuation of this task.</li>
				<li>At some point, when the <strong class="source-inline">DownloadDataTaskAsync</strong> method is completed, the task continuation gets triggered and will execute the remaining code.</li>
				<li>The process repeats until the task that has the reference of <strong class="source-inline">DownloadFileAsync</strong> completes and its continuation is executed, which is <strong class="source-inline">Console.WriteLine("Fi<a id="_idTextAnchor373"/>le downloaded!!")</strong> in this case, and then the applicat<a id="_idTextAnchor374"/>ion exits.</li>
			</ol>
			<p>At an approximate<a id="_idIndexMarker286"/> high <a id="_idIndexMarker287"/>level, the code would be transformed as shown here:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/Figure_4.6_B18507.jpg" alt="Figure 4.6 – A transformed sample asynchronous method&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.6 – A transformed sample asynchronous method</p>
			<p>Although this is an oversimplification of the under-the-hood workings of async-await, we can see the compiler doing a lot of heavy lifting, including generating a type that implements a state machine and continuing the execution using the state of the callback.</p>
			<p>We have seen how simple it is to write async methods, and we will be writing many such methods in our enterprise application throughout the course of the book. However, async-await is<a id="_idTextAnchor375"/> not a silver bullet; it is not an answer to every application issue. We need to verify certain factors to make use of async-await. Let's see what the principles are for using async-await.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The preceding code would change slightly if there was <strong class="source-inline">SynchronizationContext</strong>. For instance, in Windows Forms or WPF apps, continuation is posted on the current <strong class="source-inline">SynchronizationContext</strong> using the <strong class="source-inline">Post</strong> method of <strong class="source-inline">SynchronizationContext</strong> or <strong class="source-inline">TaskScheduler.FromCurrentSynchronizationContext</strong>. As per the standard naming convention, asynchronous methods are suff<a id="_idTextAnchor376"/><a id="_idTextAnchor377"/>ixed with the word <strong class="source-inline">async</strong> for <a id="_idIndexMarker288"/>readability<a id="_idIndexMarker289"/> purposes, but syntactically, it is not needed.</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor378"/>Principles of using async-await</h2>
			<p>As we s<a id="_idTextAnchor379"/>tart using <a id="_idIndexMarker290"/>async-await, there are certain practices that are recommended that will enable an application to take advantage of asynchronous principles. For example, for nested calls, we should use async-await all the way; do not use <strong class="source-inline">.Result</strong> and so on. Here are a few guidelines to help you use async-await effectively.</p>
			<h3>Chain async-await all the way</h3>
			<p>An asynchronous<a id="_idIndexMarker291"/> method implemented using async-await should be triggered from an <a id="_idTextAnchor380"/>async-await method so that it is properly awaited. If we try to call an asynchronous method from a synchronous method using the <strong class="source-inline">Result</strong> method or the <strong class="source-inline">Wait</strong> method of a task, it could lead to a deadlock. </p>
			<p>Let's look at the following code snippet from a WPF application that downloads files from the network upon a button click. However, instead of awaiting a call to the asynchronous method, we are using the <strong class="source-inline">Result</strong> method of <strong class="source-inline">Task</strong>:</p>
			<pre class="source-code">        private void Button_Click(object sender,</pre>
			<pre class="source-code">         RoutedEventArgs e)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            var task = </pre>
			<pre class="source-code">            DownloadFileAsync("https://github.com/Ravindra-</pre>
			<pre class="source-code">            a/largefile/blob/master/README.md", @$"{System.IO.Directory.GetCurrentDirectory()}\download.txt");</pre>
			<pre class="source-code">            bool fileDownload = task.Result; // Or </pre>
			<pre class="source-code">                            //task.GetAwaiter().GetResult()</pre>
			<pre class="source-code">            if (fileDownload)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                MessageBox.Show("file downloaded");</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">        private async Task&lt;bool&gt; DownloadFileAsync(string</pre>
			<pre class="source-code">         url, string path)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            // Create a new web client object</pre>
			<pre class="source-code">            using WebClient webClient = new WebClient();</pre>
			<pre class="source-code">            // Add user-agent header to avoid forbidden </pre>
			<pre class="source-code">            // errors.</pre>
			<pre class="source-code">            webClient.Headers.Add("user-agent",</pre>
			<pre class="source-code">              "Mozilla/5.0 (Windows NT 10.0; WOW64)");</pre>
			<pre class="source-code">            byte[] data = await</pre>
			<pre class="source-code">              webClient.DownloadDataTaskAsync(url);</pre>
			<pre class="source-code">            // Write data in file.</pre>
			<pre class="source-code">            Using var fileStream = File.OpenWrite(path);</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                await fileStream.WriteAsync(data, 0,</pre>
			<pre class="source-code">                 data.Length);</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            return true;</pre>
			<pre class="source-code">        }</pre>
			<p>In this method, the code after <strong class="source-inline">await</strong> <strong class="source-inline">webClient.DownloadDataTaskAsync(url);</strong> will never execute, for the following reasons:</p>
			<ul>
				<li>As soon as await is encountered, the <strong class="source-inline">Task</strong> reference object captures <strong class="source-inline">SynchronizationContext</strong> in <strong class="source-inline">TaskAwaitable</strong> through the <strong class="source-inline">GetAwaiter</strong> method.</li>
				<li>Once the <strong class="source-inline">async</strong> operation is completed, the continuation of that <strong class="source-inline">await</strong> needs to execute on <strong class="source-inline">SynchronizationContext</strong> (through <strong class="source-inline">SynchronizationContext.Post</strong>).</li>
				<li>However, <strong class="source-inline">SynchronizationContext</strong> is already blocked because the call to <strong class="source-inline">task.Result</strong> on the click of a button is on the same <strong class="source-inline">SynchronizationContext</strong> and <a id="_idTextAnchor381"/>is waiting for <strong class="source-inline">DownloadDataTaskAsync</strong> to complete, hence it is causing a deadlock.</li>
			</ul>
			<p>So, never <a id="_idIndexMarker292"/>block <strong class="source-inline">async</strong> methods; the best way to do <strong class="source-inline">async</strong> is all the way. So, in the preceding code, you would change the call to <strong class="source-inline">await</strong> <strong class="source-inline">DownloadFileAsync</strong> (and <strong class="source-inline">async void</strong> for button click – <strong class="source-inline">await</strong> needs a method to have an <strong class="source-inline">async</strong> modifier).</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The same code works fine in ASP.NET Core 6 applications without causing a deadlock because ASP.NET Core 6 doesn't have <strong class="source-inline">SynchronizationContext</strong>, and continuation executes on a <strong class="source-inline">ThreadPool</strong> thread without any involvement of a request context; however, blocking asynchronous calls is still not recommended, even in ASP.NET Core 6.</p>
			<h3>ConfigureAwait</h3>
			<p>In the p<a id="_idTextAnchor382"/>receding <a id="_idIndexMarker293"/>discussion, since we had the end-to-end<a id="_idIndexMarker294"/> application code, it was easier to find the cause of the deadlock. However, if we are developing a library with asynchronous methods that can be used in WPF, ASP.NET Core 6, or .NET Framework applications, we need to ensure that the asynchronous code within the library does not cause a deadlock, even though the caller may be consuming library methods through synchronous methods (<strong class="source-inline">GetAwaiter().GetResult()</strong>).</p>
			<p>In such cases, <strong class="source-inline">Task</strong> provides a method called <strong class="source-inline">ConfigureAwait</strong> that accepts a Boolean value, which, when <strong class="source-inline">true</strong>, will use the original context of the caller and, when <strong class="source-inline">false</strong>, will resume operation after <strong class="source-inline">await</strong> without depending on the original context. In layman's terms, any code after <strong class="source-inline">await</strong> will execute independently, irrespective of the state of the context that initiated the request.</p>
			<p>Us<a id="_idTextAnchor383"/>e <strong class="source-inline">ConfigureAwait(false)</strong>, especially if you are implementing a library method, as it will avoid running a continuation on the original context. For library methods, it is a must to use <strong class="source-inline">ConfigureAwait(false)</strong>, as they should never depend on the calling/original context for the continuation. For example, the following code won't cause a deadlock:</p>
			<pre class="source-code">        private void Button_Click(object sender, RoutedEventArgs e)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            string output = GetAsync().Result; //Blocking </pre>
			<pre class="source-code">              //code, ideally should cause deadlock.</pre>
			<pre class="source-code">            MessageBox.Show(output);</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">        //  Library code        </pre>
			<pre class="source-code">        public async Task&lt;string&gt; GetAsync()</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            var uri = new Uri("http://www.google.com");</pre>
			<pre class="source-code">            return await new HttpClient().</pre>
			<pre class="source-code">             GetStringAsync(uri).ConfigureAwait(false);</pre>
			<pre class="source-code">        }</pre>
			<p>By default, every <strong class="source-inline">await</strong> expression has <strong class="source-inline">ConfigureAwait(true)</strong>, so it's recommended to call <strong class="source-inline">ConfigureAwait(false)</strong> explicitly as much as possible. Apart from avoiding deadlocks, <strong class="source-inline">ConfigureAwait(false)</strong> also improves performance, as there is no marshaling of the original context.</p>
			<p>This brings us to the question of whether there is a scenario that needs to use <strong class="source-inline">ConfigureAwait(true)</strong>. The answer is that there are scenarios where a cu<a id="_idTextAnchor384"/>stom <strong class="source-inline">SynchronizationContext</strong> is being<a id="_idIndexMarker295"/> built that needs to be used by a <a id="_idIndexMarker296"/>callback, and it is then recommended to use <strong class="source-inline">ConfigureAwait(true)</strong>, or at least not use <strong class="source-inline">ConfigureAwait(false)</strong>, as the default behavior of any task is the same as <strong class="source-inline">ConfigureAwait(true)</strong>.</p>
			<h3>CPU-bound versus I/O-bound</h3>
			<p>Always use <a id="_idIndexMarker297"/>async-await for I/O-bound<a id="_idIndexMarker298"/> work <a id="_idIndexMarker299"/>and the TPL for CPU-bound work to achieve as<a id="_idTextAnchor385"/>ynchrony. I/O operations such as database calls, network calls, and filesystem calls can be wrapped in async-await asynchronous methods. However, a CPU-intensive operation such as calculating pi is better handled using the TPL.</p>
			<p>Going back to our earlier discussion, the idea of asynchronous programming is to release <strong class="source-inline">ThreadPool</strong> threads instead of waiting on the completion of an operation. This can very easily be achieved when we represent outbound calls as tasks and use async-await.</p>
			<p>However, for a CPU-intensive operation, a <strong class="source-inline">ThreadPool</strong> thread will continue to execute instructions on the worker thread (as it is a CPU-intensive operation and needs CPU time) and obviously cannot release that thread. This means that wrapping a CPU-intensive operation in async-await is not going to yield any benefit and is the same as running it synchronously. So, a better way to handle CPU-intensive operations is by using the TPL.</p>
			<p>This does not mean we will stop using async-await the moment we encounter a CPU-intensive method. The recommended way is to still use async-await to manage CPU-bound operations along with the TPL and not break our first principle of using async-await all the way.</p>
			<p>Here is a simple<a id="_idIndexMarker300"/> code snippet<a id="_idIndexMarker301"/> using <a id="_idIndexMarker302"/>async-await to manage CPU-bound work:</p>
			<pre class="source-code">        private async Task CPUIOResult()</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            var doExpensiveCalculationTask = Task.Run(() =&gt; </pre>
			<pre class="source-code">              DoExpensiveCalculation()); //Call a method </pre>
			<pre class="source-code">              //that does CPU intense operation        </pre>
			<pre class="source-code">           var downloadFileAsyncTask = DownloadFileAsync();</pre>
			<pre class="source-code">            await Task.WhenAll(doExpensiveCalculationTask,</pre>
			<pre class="source-code">             downloadFileAsyncTask);</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">private async Task DownloadFileAsync(string url, string path)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            // Implementation</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">        private float DoExpensiveCalculation()</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            //Implementation</pre>
			<pre class="source-code">        }</pre>
			<p>As seen in the preceding code, it's still possible to manage CPU-bound work with a mix of async-await and the TPL; it's up to the developer to assess all the possible options and write their code accordingly.</p>
			<h3>A<a id="_idTextAnchor386"/>void async void</h3>
			<p>Always make <a id="_idIndexMarker303"/>sure to have <strong class="source-inline">Task</strong> or <strong class="source-inline">Task&lt;T&gt;</strong> as the return<a id="_idIndexMarker304"/> type for an asynchronous method implemented using async-await instead of <strong class="source-inline">void</strong> if a method is not expected to return anything. The reason for this is that <strong class="source-inline">Task</strong> is a complex abstraction that handles many things for us, such as exception handling and task completion status. However, if an asynchronous method has an <strong class="source-inline">async</strong> <strong class="source-inline">void</strong> return type, it is like a fire-and-forget method, and any caller to this method won't be able to know the status of the operation, even if there is an exception. </p>
			<p>That is because inside an <strong class="source-inline">async</strong> <strong class="source-inline">void</strong> method, as soon as an <strong class="source-inline">await</strong> expression is encountered, the call is returned to the caller without any reference to <strong class="source-inline">Task</strong>, so there is no reference to raise an exception for. For a UI application such as WPF, any exceptions on the <strong class="source-inline">async</strong> <strong class="source-inline">void</strong> method will crash the application; however, an exception for this is <strong class="source-inline">async</strong> <strong class="source-inline">void</strong> event handlers.</p>
			<p>Another disadvantage with <strong class="source-inline">async</strong> <strong class="source-inline">void</strong> methods is the inability to write unit tests and assert them correctly. So, it's always recommended to use async <strong class="source-inline">Task</strong> exceptions as top-level event handlers (top-level is key here) because top-level events such as a button click or a mouse click are more of a one-way signal an<a id="_idTextAnchor387"/>d are not used any differently in asynchronous code compared to their synchronous counterparts.</p>
			<p>The same consideration needs to be taken in the case of <strong class="source-inline">async</strong> Lambdas, where we need to avoid passing them as an argument to a method that takes the <strong class="source-inline">Action</strong> type as its parameters. See the following example:</p>
			<pre class="source-code">long elapsedTime = AsyncLambda(async() =&gt;</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">    await Task.Delay(1000);</pre>
			<pre class="source-code">});</pre>
			<pre class="source-code">Console.WriteLine(elapsedTime);</pre>
			<pre class="source-code">Console.ReadLine();</pre>
			<pre class="source-code">static long AsyncLambda(Action a)</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">    Stopwatch sw = new Stopwatch();</pre>
			<pre class="source-code">    sw.Start();</pre>
			<pre class="source-code">    for (int i = 0; i &lt; 10; i++)</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        a();</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">    return sw.ElapsedMilliseconds;</pre>
			<pre class="source-code">}</pre>
			<p>Here, it's expected that the value of <strong class="source-inline">elapsedTime</strong> will be somewhe<a id="_idTextAnchor388"/>re around 10,000. However, it's close to 100 for the same reason – that is, with <strong class="source-inline">Action</strong> being a delegate of the <strong class="source-inline">void</strong> return type, the call to <strong class="source-inline">AsyncLambda</strong> is returned immediately to the <strong class="source-inline">Main</strong> method (as with any <strong class="source-inline">async</strong> <strong class="source-inline">void</strong> method). This can be fixed by changing <strong class="source-inline">AsyncLambda</strong> as follows (or just by changing the parameter to <strong class="source-inline">Func&lt;Task&gt;</strong> and handling the <a id="_idIndexMarker305"/>wait on <strong class="source-inline">a()</strong> accordingly) and then forcing the<a id="_idIndexMarker306"/> caller to use <strong class="source-inline">async</strong> all the way:</p>
			<pre class="source-code">        async static Task&lt;long&gt; AsyncLambda(Func&lt;Task&gt; a)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            Stopwatch sw = new Stopwatch();</pre>
			<pre class="source-code">            sw.Start();</pre>
			<pre class="source-code">            for (int i = 0; i &lt; 10; i++)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                await a();</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            return sw.ElapsedMilliseconds;</pre>
			<pre class="source-code">        }</pre>
			<p>A word of caution – if there are methods in your application that accept the <strong class="source-inline">Action</strong> type parameters, it's recommended that you have an overload that accepts <strong class="source-inline">Func&lt;Task&gt;</strong> or <strong class="source-inline">Func&lt;Task&lt;T&gt;&gt;</strong>. Fortunately, the C# compiler automatically handles this and always calls the overload with <strong class="source-inline">Func&lt;Task&gt;</strong> as a parameter.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">Use the <a id="_idTextAnchor389"/><a id="_idTextAnchor390"/>Visual <a id="_idIndexMarker307"/>Studio 2022 Exception Helper feature to <a id="_idIndexMarker308"/>debug <strong class="source-inline">async</strong> exceptions that are rethrown by framework code.</p>
			<h2 id="_idParaDest-94">Async streams with<a id="_idTextAnchor391"/> IAsyncEnumerable</h2>
			<p>We all<a id="_idIndexMarker309"/> know that <strong class="source-inline">foreach</strong> <a id="_idTextAnchor392"/>is used to loop<a id="_idIndexMarker310"/> over <strong class="source-inline">IEnumerable&lt;T&gt;</strong> or <strong class="source-inline">IEnumerator&lt;T&gt;</strong>. Let's look at the following code, in which we retrieve all employee IDs from a database and loop through each employee to print their ID:</p>
			<pre class="source-code">        static async Task Main(string[] args)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            var employeeTotal = await</pre>
			<pre class="source-code">             GetEmployeeIDAsync(5);</pre>
			<pre class="source-code">            foreach (int i in employeeTotal)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                Console.WriteLine(i);</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">        }</pre>
			<p>The <strong class="source-inline">GetEmployeeIDAsync</strong> implementation is as follows:</p>
			<pre class="source-code">        static async Task&lt;IEnumerable&lt;int&gt;&gt;</pre>
			<pre class="source-code">         GetEmployeeIDAsync(int input)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            int id = 0;</pre>
			<pre class="source-code">            List&lt;int&gt; tempID = new List&lt;int&gt;();</pre>
			<pre class="source-code">            for (int i = 0; i &lt; input; i++) //Some async DB </pre>
			<pre class="source-code">              //iterator method like ReadNextAsync</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                await Task.Delay(1000); // simulate async</pre>
			<pre class="source-code">                id += i; // Hypothetically calculation</pre>
			<pre class="source-code">                tempID.Add(id);</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            return tempID;</pre>
			<pre class="source-code">        }</pre>
			<p>Here, you can see that we must use a temporary list until we have receiv<a id="_idTextAnchor393"/>ed all the records from the database, and finally, we return the list. However, if there is an iterator in our method, <strong class="source-inline">yield</strong> in C# is an obvious choice, as that helps in returning the results immediately<a id="_idIndexMarker311"/> and avoiding temporary<a id="_idIndexMarker312"/> variables. Now, say you used <strong class="source-inline">yield</strong>, as shown in the following code:</p>
			<pre class="source-code">yield return id;</pre>
			<p>You would receive the following error upon compilation:</p>
			<pre class="source-code">The body of 'Program.GetEmployeeIDAsync(int)' cannot be an iterator block because 'Task&lt;IEnumerable&lt;int&gt;&gt;' is <a id="_idTextAnchor394"/>not an iterator interface type</pre>
			<p>Hence, there is a need to be able to use <strong class="source-inline">yield</strong> with an <strong class="source-inline">async</strong> method and also loop through a collection to call an application asynchronously. That's where C# 8.0 came up with asynchronous streams through <strong class="source-inline">IAsyncEnumerable</strong>, which primarily enables you to return data immediately and asynchronously consume a collection. So, the preceding code can be changed as follows:</p>
			<pre class="source-code">await foreach (int i in GetEmployeeIDAsync(5))</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        Console.WriteLine(i);</pre>
			<pre class="source-code">    }       </pre>
			<pre class="source-code">static async IAsyncEnumerable&lt;int&gt;</pre>
			<pre class="source-code"> GetEmployeeIDAsync(int input)</pre>
			<pre class="source-code">{</pre>
			<pre class="source-code">    int id = 0;</pre>
			<pre class="source-code">    List&lt;int&gt; tempID = new List&lt;int&gt;();</pre>
			<pre class="source-code">    for (int i = 0; i &lt; input; i++)</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        <a id="_idTextAnchor395"/>await Task.Delay(1000);</pre>
			<pre class="source-code">        id += <a id="_idTextAnchor396"/>i; // Hypothetically calculation</pre>
			<pre class="source-code">        yield return id;</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">}</pre>
			<p>So, here you can see that once a method starts returning, <strong class="source-inline">IAsy<a id="_idTextAnchor397"/><a id="_idTextAnchor398"/><a id="_idTextAnchor399"/>ncEnumerable</strong> loops can be iterated <a id="_idTextAnchor400"/><a id="_idIndexMarker313"/>asynchronously, and this is helpful <a id="_idIndexMarker314"/>in many situations to write cleaner code.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor401"/>ThreadPool starvation</h2>
			<p>Say you have <a id="_idIndexMarker315"/>an application with asynchronous <a id="_idIndexMarker316"/>code. However, you have noticed that periodically, during high loads, the response time for requests drastically increases. You research it further, but neither is the CPU of your server fully utilized nor is the memory of your process high, and it isn't a case of your database becoming a bottleneck either. In this case, your application is possibly causing what is known as <strong class="source-inline">ThreadPool</strong> starvation.</p>
			<p><strong class="source-inline">ThreadPool</strong> starvation is a state in which new threads keep being added to serve concurrent requests, and eventually, a point is reached where <strong class="source-inline">ThreadPool</strong> is unable to add more threads, and requests start seeing delayed response times or even start failing in the worst-case scenario. Even if <strong class="source-inline">ThreadPool</strong> can add threads at a rate of one or two per second, new requests may be coming at a higher rate (as in a burst load on a web application during the holiday season). Hence, there is a significant increase in the response time. There are multiple reasons why this can happen; a few of them are listed here:</p>
			<ul>
				<li>The consumption of more threads to speed up long-running CPU-bound work</li>
				<li>The calling of an <strong class="source-inline">async</strong> method in a <strong class="source-inline">sync</strong> method using <strong class="source-inline">GetAwaiter().GetResult()</strong></li>
				<li>The incorrect use of synchronization primitives, such as a thread holding a lock for a long time and other threads waiting to acquire it</li>
			</ul>
			<p>In all the preceding points, the common thing is blocking code; so, the use of blocking code such as <strong class="source-inline">Thread.Sleep</strong> even for a short duration, something such as <strong class="source-inline">GetAwaiter().GetResult()</strong>, or trying to allocate more threads for a CPU-bo<a id="_idTextAnchor402"/>und item increases the number of threads in <strong class="source-inline">ThreadPool</strong> and eventually leads to starvation.</p>
			<p><strong class="source-inline">ThreadPool</strong> starvation can be furth<a id="_idTextAnchor403"/>er diagnosed <a id="_idIndexMarker317"/>using tools such as <strong class="bold">PerfView</strong>, where you capture a trace for, say, 200 seconds, and verify the growth of threads in your process. If you see that your threads are growing at a rapid pace during peak load, then there is a possibility of starvation.</p>
			<p>The best way to prevent <strong class="source-inline">ThreadPool</strong> starvation is to use async-await throughout the application and never block any <strong class="source-inline">async</strong> calls. Also, the throttling of newly created operations can help, as it restricts the number of items that can be queued at a time.</p>
			<p>In this section, we discussed two important constructs, async-await and the TPL, which when<a id="_idIndexMarker318"/> combined <a id="_idIndexMarker319"/>make writing asynchronous code simpler. In the next section, we will learn about various dat<a id="_idTextAnchor404"/><a id="_idTextAnchor405"/>a structures that are available in .NET 6 to support synchronization/thread safety without writing any additional code.</p>
			<h1 id="_idParaDest-96">Using concurr<a id="_idTextAnchor406"/>ent collections for parallelism</h1>
			<p>Collections <a id="_idIndexMarker320"/>classes are one of the most used types to encapsulate, retrieve, a<a id="_idTextAnchor407"/>nd modify enumerated sets of related data. <strong class="source-inline">Dictionary</strong>, <strong class="source-inline">list</strong>, <strong class="source-inline">queue</strong>, and <strong class="source-inline">array</strong> are some of the frequently used collection types, but they are not thread-safe. These collections are good if you access them from just one thread at a time. </p>
			<p>A real-world environment would be multithreaded, and to make it thread-safe, you will have to implement various synchronization constructs, as described in an earlier section. To solve this problem, Microsoft came up with concurrent collection classes, such as <strong class="source-inline">ConcurrentQueue</strong>, <strong class="source-inline">ConcurrentBag</strong>, <strong class="source-inline">ConcurrentDictionary</strong>, and <strong class="source-inline">ConcurrentStack</strong>, whic<a id="_idTextAnchor408"/><a id="_idTextAnchor409"/>h are thread-safe, as they internally implement synchronization. Let's <a id="_idIndexMarker321"/>look at them in detail in the following sections.</p>
			<h2 id="_idParaDest-97">C<a id="_idTextAnchor410"/>oncurrentDictionary</h2>
			<p>Let's stimulate a <a id="_idIndexMarker322"/>multithreaded <a id="_idIndexMarker323"/>environment using a dictionary. Consider the <strong class="source-inline">t1</strong> task as one operation from a client who is adding to the dictionary and the <strong class="source-inline">t2</strong> task as a second operation from another client who is reading from the dictionary.</p>
			<p>We add <strong class="source-inline">Thread.Sleep</strong> in each task to mimic a real-world scenario to ensure that one task doesn't complete before the other in this example. Let's consider an example console application with the following code snippet:</p>
			<pre class="source-code">// Task t1 as one operation from a client who is adding to the dictionary.</pre>
			<pre class="source-code">Dictionary&lt;int, string&gt; employeeDictionary = new Dictionary&lt;int, string&gt;();            </pre>
			<pre class="source-code">            Task t1 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                for (int i = 0; i &lt; 100; ++i)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    employeeDictionary.TryAdd(i, "Employee"</pre>
			<pre class="source-code">                     + i.ToString());</pre>
			<pre class="source-code">                    Thread.Sleep(100);</pre>
			<pre class="source-code">                    </pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">            });</pre>
			<p>This is <strong class="source-inline">Task</strong> <strong class="source-inline">t2</strong> as a second operation from another client who is reading from the dictionary:</p>
			<pre class="source-code">            Task t2 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                Thread.Sleep(500);</pre>
			<pre class="source-code">                foreach (var item in employeeDictionary)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    Console.WriteLine(item.Key + <a id="_idTextAnchor411"/>"-" +</pre>
			<pre class="source-code">                      item.Value);</pre>
			<pre class="source-code">                    Thread.Sleep(100);</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">            });</pre>
			<p>Now, both <a id="_idIndexMarker324"/>tasks are executed at the <a id="_idIndexMarker325"/>same time, as shown in the following:</p>
			<pre class="source-code">try</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                Task.WaitAll(t1, t2); // Not recommended to </pre>
			<pre class="source-code">                  //use in production application.</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            catch (AggregateException ex)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                Console.WriteLine(ex.Flatten().Message);</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            Console.ReadLine();</pre>
			<p>When you run this progr<a id="_idTextAnchor412"/>am, you will get the following exception, which states that you cannot modify and enumerate the collection at the same time:</p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/Table_4.2.jpg" alt="Table 4.2 – The ConcurrentDictionary sample output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Table 4.2 – The ConcurrentDictionary sample output</p>
			<p>You may think now that we can add a lock to manage thread sy<a id="_idTextAnchor413"/>nchronization and avoid this exception in multithreaded scenarios for thread safety. I added a lock to the code wherever the <a id="_idIndexMarker326"/>dictionary is modified<a id="_idIndexMarker327"/> and enumerated to synchronize the threads. Here are the updated code snippets:</p>
			<ol>
				<li value="1">First, we have <strong class="source-inline">Task</strong> <strong class="source-inline">t1</strong> as one operation from a client who is adding to the dictionary:<p class="source-code">Dictionary&lt;int, string&gt; employeeDictionary = new Dictionary&lt;int, string&gt;();            </p><p class="source-code">            Task t1 = Task.Factory.StartNew(() =&gt;</p><p class="source-code">            {</p><p class="source-code">                for (int i = 0; i &lt; 100; ++i)</p><p class="source-code">                {</p><p class="source-code">                    //Lock the shared data</p><p class="source-code">                    lock (syncObject)</p><p class="source-code">                    {</p><p class="source-code">                        employeeDictionary.TryAdd(i,</p><p class="source-code">                          "Employee" + i.ToString())<a id="_idTextAnchor414"/>;</p><p class="source-code">                    }</p><p class="source-code">                    Thread.Sleep(100);</p><p class="source-code">                    </p><p class="source-code">                }</p><p class="source-code">            });</p></li>
				<li>Then, we have <strong class="source-inline">Task</strong> <strong class="source-inline">t2</strong> as a second operation from another client who is reading<a id="_idIndexMarker328"/> from the<a id="_idIndexMarker329"/> dictionary:<p class="source-code">            Task t2 = Task.Factory.StartNew(() =&gt;</p><p class="source-code">            {</p><p class="source-code">                Thread.Sleep(500);</p><p class="source-code">                //Lock the shared data</p><p class="source-code">                lock (syncObject)</p><p class="source-code">                {</p><p class="source-code">                    foreach (var item in</p><p class="source-code">                     employeeDictionary)</p><p class="source-code">                    {</p><p class="source-code">                        Console.WriteLine(item.Key + </p><p class="source-code">                          "-" + item.Value);</p><p class="source-code">                        Thread.Sleep(100);</p><p class="source-code">                    }</p><p class="source-code">                }</p><p class="source-code">            });</p></li>
				<li>Now, we have both tasks executed at the same time:<p class="source-code">try</p><p class="source-code">            {</p><p class="source-code">                Task.WaitAll(t1, t2); // Not </p><p class="source-code">                  //recommended to use in production </p><p class="source-code">                  //application.</p><p class="source-code">            }</p><p class="source-code">            catch (AggregateException ex)</p><p class="source-code">            {</p><p class="source-code">                Console.WriteLine(ex.Flatten()</p><p class="source-code">                  .Message);</p><p class="source-code">            }</p><p class="source-code">            Console.ReadLine();</p></li>
			</ol>
			<p>When you run this code, you will not see any exceptions. Ho<a id="_idTextAnchor415"/>wever, locks have some issues, as mentioned earlier, so this code can be rewritten using concurrent<a id="_idIndexMarker330"/> collections. They <a id="_idIndexMarker331"/>internally use a multiple-thread synchronization technique that helps to scale well, prevent data corruption, and avoid all the problems with locks.</p>
			<p>We can rewrite our code using <strong class="source-inline">ConcurrentDictionary</strong>, which is available in the <strong class="source-inline">System.Collections.Concurrent</strong> namespace. Replace <strong class="source-inline">Dictionary</strong> with <strong class="source-inline">ConcurrentDictionary</strong> in the sample code. You can also remove the reference to the <strong class="source-inline">System.Collections.Generic</strong> namespace, as <strong class="source-inline">Dictionary</strong> is not used now. Also, remove all the locks. The updated code is as follows, where we replace <strong class="source-inline">Dictionary</strong> with <strong class="source-inline">ConcurrentDictionary</strong> and remove the lock:</p>
			<p>We have <strong class="source-inline">Task t1</strong> as one operation from a client who is adding to the dictionary, and an explicit lock is not needed with concurrent collections:</p>
			<p class="source-code">ConcurrentDictionary&lt;int, string&gt; employeeDictionary = new ConcurrentDictionary&lt;int, string&gt;();</p>
			<p class="source-code">            Task t1 = Task.Factory.StartNew(() =&gt;</p>
			<p class="source-code">            {</p>
			<p class="source-code">                for (int i = 0; i &lt; 100; ++i)</p>
			<p class="source-code">                {</p>
			<p class="source-code">                    employeeDictionary.TryAdd(i, </p>
			<p class="source-code">                      "Employee"</p>
			<p class="source-code">                      + i.ToString());</p>
			<p class="source-code">                    Thread.Sleep(100);</p>
			<p class="source-code">                    </p>
			<p class="source-code">                }</p>
			<p class="source-code">            });</p>
			<ol>
				<li value="4">Then, we have <strong class="source-inline">Task t2</strong> as a second operation from another client who is reading from<a id="_idIndexMarker332"/> the dictionary, and<a id="_idIndexMarker333"/> an explicit lock is not needed with concurrent collections:<p class="source-code">            Task t2 = Task.Factory.StartNew(() =&gt;</p><p class="source-code">            {</p><p class="source-code">                Thread.Sleep(500);</p><p class="source-code">                foreach (var item in </p><p class="source-code">                  employeeDictionary)</p><p class="source-code">                {</p><p class="source-code">                    Console.WriteLine(item.Key + "-" +</p><p class="source-code">                       item.Value);</p><p class="source-code">                    Thread.Sleep(100);</p><p class="source-code">                }</p><p class="source-code">            });</p></li>
				<li>Now, both tasks are executed at the same time:<p class="source-code">try</p><p class="source-code">            {</p><p class="source-code">                Task.WaitAll(t1, t2);</p><p class="source-code">            }</p><p class="source-code">            catch (AggregateException ex) // You will </p><p class="source-code">              //not get Exception</p><p class="source-code">            {</p><p class="source-code">                Console.WriteLine(ex.Flatten()</p><p class="source-code">                  .Message);</p><p class="source-code">            }</p><p class="source-code">            Console.ReadLine();</p></li>
			</ol>
			<p>When you run the program now, you will not<a id="_idTextAnchor416"/> get any exceptions, as all operations are thread-safe and atomic in <strong class="source-inline">ConcurrentDictionary</strong>. There is no overhead for the developer in implementing the locks and maintaining them as the project grows bigger. Here are<a id="_idIndexMarker334"/> some caveats with<a id="_idIndexMarker335"/> concurrent collections such as <strong class="source-inline">ConcurrentDictionary</strong> that you need to bear in mind:</p>
			<ul>
				<li>If two threads call <strong class="source-inline">AddOrUpdate</strong>, there's no guarantee which of the factory delegates will be called and even no guarantee that if a factory delegate produces an item, the item will be stored in the dictionary.</li>
				<li>The enumerator obtained by the <strong class="source-inline">GetEnumerator</strong> call is not a snapshot and may be modified during enumeration (which doesn't cause any exceptions).</li>
				<li>Key and value properties are snapshots of corresponding collections and may not correspond to the ac<a id="_idTextAnchor417"/><a id="_idTextAnchor418"/>tual dictionary state.</li>
			</ul>
			<p>We've looked at <strong class="source-inline">ConcurrentDictionary</strong> in detail; let's look at other concurrent collections in the next section.</p>
			<h2 id="_idParaDest-98"><a id="_idTextAnchor419"/>Producer-consumer concurrent collections</h2>
			<p>In producer<a id="_idIndexMarker336"/>-consumer<a id="_idIndexMarker337"/> concurrent collections, one <a id="_idTextAnchor420"/>or more threads can produce tasks (adding to a queue, stack, or bag, for instance), and one or more other threads can consume tasks from the same collection (the queue, stack, or bag).</p>
			<p><strong class="source-inline">ConcurrentDictionary</strong>, which we saw in the previous section, is a general-purpose collection class where you add an item that you want and specify which item you want to read. Other concurrent collections are designed for specific pr<a id="_idTextAnchor421"/>oblems:</p>
			<ul>
				<li><strong class="source-inline">ConcurrentQueue</strong> is for scenarios where you want FIFO.</li>
				<li><strong class="source-inline">ConcurrentStack</strong> is for scenarios where you want LIFO.</li>
				<li><strong class="source-inline">ConcurrentBag</strong> is for scenarios where you want the same thread producing and consuming data stored in the bag and the order doesn't matter.</li>
			</ul>
			<p>These three collections are also known as <strong class="bold">producer-consumer<a id="_idTextAnchor422"/> collections</strong>, where one or more threads can produce tasks and consu<a id="_idTextAnchor423"/>me tasks from the same collection, as shown in the following figure:</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/Figure_4.7_B18507.jpg" alt="Figure 4.7 – A producer-consumer concurrent collection&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.7 – A producer-consumer concurrent collection</p>
			<p>All these three collections implement the <strong class="source-inline">IProducerConsumerCollection&lt;T&gt;</strong> interface, and the most important methods are <strong class="source-inline">TryAdd</strong> and <strong class="source-inline">TryTake</strong>, as shown here:</p>
			<pre class="source-code">// Returns: true if the object was added successfully; otherwise, false.        </pre>
			<pre class="source-code">bool TryAdd(T item);</pre>
			<pre class="source-code">// Returns true if an object was removed an<a id="_idTextAnchor424"/>d returned successfully; otherwise, false.</pre>
			<pre class="source-code">bool TryTake([MaybeNullWhen(false)] out T item);</pre>
			<p>Let's take an <a id="_idIndexMarker338"/>example <a id="_idIndexMarker339"/>of a producer-consumer and simulate it using <strong class="source-inline">ConcurrentQueue</strong>:</p>
			<ul>
				<li><strong class="bold">Producer</strong>: A client <a id="_idIndexMarker340"/>sending a request to a <a id="_idTextAnchor425"/>web service and the server storing a request in a queue</li>
				<li><strong class="bold">Consumer</strong>: A worker<a id="_idIndexMarker341"/> thread pulling the request from the queue and processing it</li>
			</ul>
			<p>The implementation is shown in the following code:</p>
			<pre class="source-code">//Producer: Client sending request to web service and server storing the request in queue.</pre>
			<pre class="source-code">ConcurrentQueue&lt;string&gt; concurrentQueue = new ConcurrentQueue&lt;string&gt;();            </pre>
			<pre class="source-code">            Task t1 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                for (int i = 0; i &lt; 10; ++i)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    concurrentQueue.Enqueue("Web request " </pre>
			<pre class="source-code">                      + i);</pre>
			<pre class="source-code">                    Console.WriteLine("Sending "+ "Web </pre>
			<pre class="source-code">                      request " + i);</pre>
			<pre class="source-code">                    Thread.Sleep(100);</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">            });</pre>
			<p>Now, we <a id="_idIndexMarker342"/>have <strong class="source-inline">Consumer</strong>, where <a id="_idIndexMarker343"/>a <strong class="source-inline">Worker</strong> thread pulls the request from the queue and processes it:</p>
			<pre class="source-code">            Task t2 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                while (true)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    if (concurrentQueue.TryDequeue(out</pre>
			<pre class="source-code">                     string request))</pre>
			<pre class="source-code">                    {</pre>
			<pre class="source-code">                        Console.WriteLine("Processing "+</pre>
			<pre class="source-code">                         request);</pre>
			<pre class="source-code">                    }</pre>
			<pre class="source-code">                    else</pre>
			<pre class="source-code">                    {</pre>
			<pre class="source-code">                        Console.WriteLine("No request");</pre>
			<pre class="source-code">                    }</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">            });</pre>
			<p>Both producer and consumer tasks are executed at the same time successfully. Wait for all provided tasks to complete execution within the specified number of milliseconds. Refer to the following code snippet:</p>
			<pre class="source-code">try</pre>
			<pre class="source-code">            {                </pre>
			<pre class="source-code">                Task.WaitAll(new Task[] { t1, t2 }, 1000);</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            catch (AggregateException ex) // No exception</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                Console.WriteLine(ex.Flatten().Message);</pre>
			<pre class="source-code">            }</pre>
			<p>This is according to the method definition from Microsoft:</p>
			<ul>
				<li><strong class="source-inline">concurrentQueue.Enqueue</strong>: This adds an object to the end of <strong class="source-inline">ConcurrentQueue&lt;T&gt;</strong>.</li>
				<li><strong class="source-inline">concurrentQueue.TryDequeue</strong>: This tries to remove and return <a id="_idTextAnchor426"/>the object at the beginning of <strong class="source-inline">ConcurrentQueue</strong>.</li>
			</ul>
			<p>When you run the program, you can see <strong class="source-inline">task</strong> <strong class="source-inline">t1</strong> producing requests and <strong class="source-inline">task</strong> <strong class="source-inline">t2</strong> polling and <a id="_idIndexMarker344"/>then consuming<a id="_idIndexMarker345"/> requests. We'll get into the details in a short while. We also said that these classes implement <strong class="source-inline">IProducerConsumerCollection&lt;T&gt;</strong>, so we are going to make three changes to the previous code:</p>
			<ul>
				<li>Replace <strong class="source-inline">ConcurrentQueue&lt;string&gt;</strong> with <strong class="source-inline">IProducerConsumerCollection&lt;string&gt;</strong>.</li>
				<li>Replace <strong class="source-inline">concurrentQueue.Enqueue</strong> with <strong class="source-inline">concurrentQueue.TryAdd</strong>.</li>
				<li>Replace <strong class="source-inline">concurrentQueue.TryDequeue</strong> with <strong class="source-inline">concurrentQueue.TryTake</strong>.</li>
			</ul>
			<p>This is how the code looks now:</p>
			<pre class="source-code">IProducerConsumerCollection&lt;string&gt; concurrentQueue = new ConcurrentQueue&lt;string&gt;();</pre>
			<pre class="source-code">//Removed code for brevity.</pre>
			<pre class="source-code">Task t1 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                for (int i = 0; i &lt; 10; ++i)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    <strong class="source-inline">concurrentQueue.TryAdd</strong>("Web request " + </pre>
			<pre class="source-code">                      i);</pre>
			<pre class="source-code">//Removed code for brevity.</pre>
			<pre class="source-code">Task t2 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                while (true)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    if (<strong class="source-inline">concurrentQueue.TryTake</strong>(out string</pre>
			<pre class="source-code">                     request))</pre>
			<pre class="source-code">//Removed code for brevity.</pre>
			<p>Now, go ahead <a id="_idIndexMarker346"/>and run <a id="_idIndexMarker347"/>the program. You can see <strong class="source-inline">task</strong> <strong class="source-inline">t1</strong> producing requests and <strong class="source-inline">task</strong> <strong class="source-inline">t2</strong> polling and then consuming requests. You can see all 10 requests produced by <strong class="source-inline">task</strong> <strong class="source-inline">t1</strong> and consumed by <strong class="source-inline">task</strong> <strong class="source-inline">t2</strong>. But there are two problems:</p>
			<ul>
				<li>The producer is producing at its own rate, the consumer is consuming at its own rate, and there is no synchronization.</li>
				<li>There is continuous indefinite polling from the consumer in <strong class="source-inline">task</strong> <strong class="source-inline">t2</strong>, which is not good for performance and CPU usage, as we can see by <strong class="bold">No<a id="_idTextAnchor427"/><a id="_idTextAnchor428"/> request</strong> being printed when we don't get any request to process from <strong class="source-inline">concurrentQueue.TryTake</strong>.</li>
			</ul>
			<p>This is where <strong class="source-inline">BlockingCol<a id="_idTextAnchor429"/>lection&lt;T&gt;</strong> comes in handy.</p>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor430"/>The BlockingCollection&lt;T&gt; class</h2>
			<p><strong class="source-inline">BlockingCollection&lt;T&gt;</strong> supports<a id="_idIndexMarker348"/> bounding<a id="_idIndexMarker349"/> and blocking. Bounding allows you to specify a maximum capacity for a collection. Controlling the maximum size of a collection helps to prevent producing threads from moving too far ahead of consuming threads. Multiple producing threads can add items to <strong class="source-inline">BlockingCollection&lt;T&gt;</strong> concurrently until the collection reaches its maximum size, after which they will be blocked until an item is removed by consumers.</p>
			<p>Similarly, multiple consuming threads can remove items from a blocking collection concurrently till the collection becomes empty, after which they will be blocked until an item is added by producers.<a id="_idTextAnchor431"/> A producing thread can invoke the <strong class="source-inline">CompleteAdding</strong> method when no more items will be added and indicate that it has completed adding. This will help consumers to monitor the <strong class="source-inline">IsCompleted</strong> property to know that no more items will be added when the collection is empty. </p>
			<p>When you create a <strong class="source-inline">BlockingCollection&lt;T&gt;</strong> class, along with the bounding capacity, you can also specify the type of concurrent collection to use depending upon the scenario. By default, the collection type is <strong class="source-inline">ConcurrentQueue&lt;T&gt;</strong> for <strong class="source-inline">BlockingCollection&lt;T&gt;</strong> when you don't specify the type.</p>
			<p>Here is a sample code snippet:</p>
			<pre class="source-code">BlockingCollection&lt;string&gt; blockingCollection = new BlockingCollection&lt;string&gt;(new ConcurrentQueue&lt;string&gt;(),5);    </pre>
			<pre class="source-code">            Task t1 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                for (int i = 0; i &lt; 10; ++i)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    blockingCollection.TryAdd("Web request</pre>
			<pre class="source-code">                     " + i);</pre>
			<pre class="source-code">                    Console.WriteLine("Sending " + "Web</pre>
			<pre class="source-code">                      request " + i);</pre>
			<pre class="source-code">                    Thread.Sleep(100);</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">                blockingCollection.CompleteAdding();</pre>
			<pre class="source-code">            });</pre>
			<p>Then, the consumer <a id="_idIndexMarker350"/>with<a id="_idIndexMarker351"/> the <strong class="source-inline">Worker</strong> thread pulls the item from the queue and processes it:</p>
			<pre class="source-code">            Task t2 = Task.Factory.StartNew(() =&gt;</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                while (!blockingCollection.IsCompleted)</pre>
			<pre class="source-code">                {</pre>
			<pre class="source-code">                    if (blockingCollection.TryTake(out</pre>
			<pre class="source-code">                     string request,100))</pre>
			<pre class="source-code">                    {</pre>
			<pre class="source-code">                        Console.WriteLine("Processing " +</pre>
			<pre class="source-code">                         request);</pre>
			<pre class="source-code">                    }</pre>
			<pre class="source-code">                    else</pre>
			<pre class="source-code">                    {</pre>
			<pre class="source-code">                        Console.WriteLine("No request");</pre>
			<pre class="source-code">                    }</pre>
			<pre class="source-code">                }</pre>
			<pre class="source-code">            });</pre>
			<p>Now, the producer and consumer thread are accessed concurrently.</p>
			<p>There are a few points to consider in the code:</p>
			<ul>
				<li>The specified bounding of <strong class="source-inline">5</strong>: <strong class="source-inline">BlockingCollection&lt;string&gt; blockingCollection = new BlockingCollection&lt;string&gt;(new ConcurrentQueue&lt;string&gt;(),5);</strong>.</li>
				<li>The producing thread invokes the <strong class="source-inline">CompleteAdding</strong> method when no more items will be added to indicate that it has completed adding: <strong class="source-inline">blockingCollection.CompleteAdding();</strong>.</li>
				<li>Consumers monitor the <strong class="source-inline">IsCompleted</strong> property to find out that no more items will be added when the collection is empty: <strong class="source-inline">while (!blockingCollection.IsCompleted)</strong>.</li>
				<li>Try to remove an item from <strong class="source-inline">BlockingCollection&lt;T&gt;</strong> in the specified time – for example, I have gone with 100 milliseconds: <strong class="source-inline">if (blockingCollection.TryTake(out string request, 100))</strong>.</li>
			</ul>
			<p>This is the power of a block<a id="_idTextAnchor432"/>ing collection. Both the producer and consumer are decoupled, they <a id="_idIndexMarker352"/>can be <a id="_idIndexMarker353"/>coded independently by different teams, and at runtime, they use a blocking concurrent collection to share data with each other. Plus, at the same time, flow is controlled with the bounding capacity so that <a id="_idTextAnchor433"/>the producer doesn't move too far ahead of consumers.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">In addition to the <strong class="source-inline">TryTake</strong> method that we've seen, you can also use a <strong class="source-inline">foreach</strong> loop to remove items from a blocking collection. You can read about it here: </p>
			<p class="callout"><a href="https://docs.microsoft.com/en-us/dotnet/standard/collections/thread-safe/how-to-use-foreach-to-remove">https://docs.microsoft.com/en-us/dotnet/standard/col<span id="_idTextAnchor434"/>lections/thread-safe/how-to-use-foreach-to-remove</a></p>
			<p class="callout">With blocking collections, there will be scenarios where the consum<a id="_idTextAnchor435"/>er will have to work with multiple collections and take or add items. The <strong class="source-inline">TakeFromAny</strong> and <strong class="source-inline">AddToAny</strong> methods will help you in this scenario. You can read further about these two methods here:</p>
			<p class="callout"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.blockingcollection-1.takefromany?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.blockingcol<span id="_idTextAnchor436"/><span id="_idTextAnchor437"/>lection-1.takefromany?view=net-6.0</a></p>
			<p class="callout"><a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.blockingcollection-1.addtoany?view=net-6.0">https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.blockingcollection-1.addtoany?view=net-6.0</a></p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor438"/>Summary</h1>
			<p>Wrapping up, writing, and maintaining clean asynchronous code is difficult. However, with the various constructs available in .NET and C#, developers can now write asynchronous code with less framework overhead and focus more on the business requirements. </p>
			<p>In this chapter, we covered various ways to write scalable asynchronous code using the TPL, async-await, and concurrent collections, and we also covered the fundamentals of threads and <strong class="source-inline">ThreadPool</strong> in .NET to understand the framework internals and write cleaner code for enterprise applications. Now, we have a deeper understanding of multithreading and how to protect shared data in a multithreaded environment. We learned about creating tasks and implementing asynchronous functions using async-await, and finally, we learned about the concurrent collections available in .NET Core and their implementation in various concurrent scenarios.</p>
			<p>In the next chapter, we will<a id="_idTextAnchor439"/><a id="_idTextAnchor440"/> look into dependency injection in .NET 6 and how it plays a significant role in loosely coupling various low-level classes in enterprise applications.</p>
			<h1 id="_idParaDest-101"><a id="_idTextAnchor441"/>Questions</h1>
			<ol>
				<li value="1">In a multithreaded environment, which of the following data structures should you use to protect data from getting overwritten/corrupted?</li>
			</ol>
			<p>a. <strong class="source-inline">async</strong>-<strong class="source-inline">await</strong>.</p>
			<p>b. Tasks.</p>
			<p>c. Synchronization constructs such as locks.</p>
			<p>d. Data never gets corrupted.</p>
			<p><strong class="bold">Answer : a</strong></p>
			<ol>
				<li value="2">If you have a WPF application that retrieves data from a REST API, which of the following should you implement for better responsiveness?</li>
			</ol>
			<p>a. A concurrent collection</p>
			<p>b. <strong class="source-inline">Parallel.For</strong></p>
			<p>c. <strong class="source-inline">async</strong>-<strong class="source-inline">await</strong> for the REST API calls</p>
			<p><strong class="bold">Answer: c</strong></p>
			<ol>
				<li value="3">Which of the following should be passed to cancel a task?</li>
			</ol>
			<p>a. <strong class="source-inline">CancellationToken</strong></p>
			<p>b. <strong class="source-inline">ConcurrentDictionary</strong></p>
			<p>c. <strong class="source-inline">SemaphoreSlim</strong></p>
			<p><strong class="bold">Answer: a</strong></p>
			<ol>
				<li value="4">Which of the following is the recommended return type <a id="_idTextAnchor442"/><a id="_idTextAnchor443"/>for an asynchronous method that uses async-await and does not return anything?</li>
			</ol>
			<p>a. <strong class="source-inline">async void</strong></p>
			<p>b. <strong class="source-inline">async Task</strong></p>
			<p>c. <strong class="source-inline">async book</strong></p>
			<p>d. <strong class="source-inline">async Task&lt;bool&gt;</strong></p>
			<p><strong class="bold">Answer: b</strong></p>
			<h1 id="_idParaDest-102"><a id="_idTextAnchor444"/>Further reading</h1>
			<ul>
				<li><a href="https://www.packtpub.com/product/hands-on-parallel-programming-with-c-8-and-net-core-3/9781789132410">https://www.packtpub.com/product/hands-on-parallel-programming-with-c-8-and-net-core-3/9781789132410</a></li>
				<li><a href="https://devblogs.microsoft.com/dotnet/configureawait-faq/">https://devblogs.microsoft.com/dotnet/configureawait-faq/</a></li>
				<li><a href="http://www.albahari.com/threading/">http://www.albahari.com/threading/</a></li>
				<li><em class="italic">Dataflow (Task Parallel Library) | Microsoft Docs</em>: <a href="https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/dataflow-task-parallel-library">https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/dataflow-task-parallel-library</a></li>
			</ul>
		</div>
	</body></html>