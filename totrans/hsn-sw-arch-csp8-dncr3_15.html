<html><head></head><body>
        

                            
                    <h1 class="header-title">Applying Service-Oriented Architectures with .NET Core</h1>
                
            
            
                
<p>The term <strong>Service-Oriented Architecture</strong> (<strong>SOA</strong>) refers to a modular architecture where interaction between system components is achieved through communication. SOA allows applications from different organizations to exchange data and transactions automatically and allows organizations to offer services on the internet.</p>
<p>Moreover, as we discussed in the <em>Microservices as the evolution of the concept of modules</em> section of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>, communication-based interaction solves binary compatibility and version mismatch problems that inevitably appear in complex systems made up of modules that share the same address space. Moreover, with SOA, you don't need to deploy different copies of the same component in the various systems/subsystem that use it – each component only needs to be deployed in just one place. This can be a single server, a cluster located in a single data center, or a geographically distributed cluster. Here, each version of your component is deployed just once, and the server/cluster logic automatically creates all the necessary replicas, thus simplifying the overall <strong>Continuous Integration / Continuous Delivery</strong> (<strong>CI/CD</strong>) cycle.</p>
<p>As long as a newer version conforms to the communication interface that's declared to the clients, no incompatibilities can occur. On the other hand, with DLLs/packages, when the same interface is maintained, incompatibilities may arise because of possible version mismatches in terms of the dependencies of other DLLs/packages that the library module might have in common with its clients.</p>
<p class="mce-root"/>
<p>Organizing clusters/networks of cooperating services was discussed in <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>. In this chapter, we will mainly focus on the communication interface offered by each service. More specifically, we will discuss the following topics:</p>
<ul>
<li>Understanding the principles of the SOA approach</li>
<li>How does .NET Core deal with SOA?</li>
<li>Use case – exposing WWTravelClub packages</li>
</ul>
<p>By the end of this chapter, you will know how to publicly expose data from the WWTravelClub book use case through an ASP.NET Core service.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter requires Visual Studio 2017 or 2019 free Community Edition or better with all the database tools installed.</p>
<p>All the concepts in this chapter will be clarified with practical examples based on this book's WWTravelClub book use case. You will find the code for this chapter at <a href="https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8">https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding the principles of the SOA approach</h1>
                
            
            
                
<p>Like classes in an object-oriented architecture, services are implementations of interfaces that, in turn, come from system functional specifications. Therefore, the first step in a <em>service</em> design is the definition of its abstract interface. During this stage, you define all the service operations as interface methods that operate on the types of your favorite language (C#, Java, C++, JavaScript, and so on) and decide which operations to implement with synchronous communication and which ones to implement with asynchronous communication.</p>
<p>The interfaces that are defined in this initial stage won't necessarily be used in the actual service implementation, and are just useful design tools. Once we've decided on the architecture of the services, these interfaces are usually redefined so that we can adapt them to the peculiarity of the architecture.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>It is worth pointing out that SOA messages must keep the same kind of semantics as method calls/answers; that is, the reaction to a message must not depend on any previously received messages. Here, the messages must be independent of each other, and the service <em>must not remember</em> any previously received messages.</p>
<p>For instance, if the purpose of messages is to create a new database entry, this semantic must not change with the context of other messages, and the way the database entry is created must depend on the content of the current message and not on other previously received messages. As a consequence, a client can't create sessions and can't log in to a service, perform some operations, and then log out. An authentication token must be repeated in each message.</p>
<p>The reasons for this constraint are modularity, testability, and maintainability. In fact, a session-based service would be very hard to test and modify due to the interactions that are <em>hidden</em> in the session data.</p>
<p>Once you've decided on the interface that's going to be implemented by a service, you must decide which communication stack/ SOA architecture to adopt. The communication stack must be part of some official or de facto standard to ensure your service's interoperability. Interoperability is the main constraint prescribed by SOA: services must offer a communication interface that does not depend on the specific communication library used, on the implementation language, or on the deployment platform.</p>
<p>Once you've decided on the communication stack/architecture, you need to adapt your previous interfaces to the architecture's peculiarities (see the <em>REST web services</em> subsection of this chapter for more details). Then, you must translate these interfaces into the chosen communication language. This means that you have to map all the programming language types into types that are available in the chosen communication language.</p>
<p>The actual translation of data is usually performed automatically by the SOA libraries that are used by your development environment. However, some configuration might be needed and, in any case, we must be aware of how our programming language types are transformed before each communication. For instance, some numeric types might be transformed into types with less precision or with different ranges of values. </p>
<p>The interoperability constraint can be interpreted in a lighter form in the case of microservices that aren't accessible outside of their clusters, since they need to communicate with other microservices that belong to the same cluster. In this case, this means that the communication stack might be platform-specific so that it can increase performance, but it must be a de facto standard to avoid compatibility problems with other microservices that might be added to the cluster as the application evolves.</p>
<p>We've spoken of the <em>communication stack</em> and not of the <em>communication protocol</em> because SOA communication standards usually define the format of the message's content and provide different possibilities for the specific protocol that's used to embed those messages. For instance, the SOAP protocol just defines an XML-based format for the various kind of messages, but SOAP messages can be conveyed by various protocols. Usually, the most common protocol that's used for SOAP is HTTP, but you may decide to jump to the HTTP level and send SOAP messages directly over TCP/IP for better performance. </p>
<p>The choice of communication stack you should adopt depends on several factors:</p>
<ul>
<li><strong>Compatibility constraints</strong>: If your service must be publicly available on the internet to business clients, then you must conform to the most common choices, which means using either SOAP over HTTP or JSON REST services. The most common choices are different if your clients aren't business clients but <strong>Internet of Things</strong> (<strong>IoT</strong>) clients. Also, within IoT, the protocols that are used in different application areas can be different. For instance, marine vehicle status data isn't typically exchanged with <em>Signal K</em>.</li>
<li><strong>Development/deployment platform</strong>: Not all communication stacks are available on all development frameworks and on all deployment platforms. For instance, .NET remoting, which we used in the code example at the end of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>, is specific to .NET and Azure Service Fabric. Luckily, all the most common communication stacks that are used in public business services, such as SOAP and JSON-based REST communication, are available in all the main development/deployment platforms.</li>
<li><strong>Performance</strong>: If your system is not exposed to the outside world and is a private part of your microservice cluster, performance considerations have a higher priority. That's why, in the Service Fabric example at the end of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>, we used .NET remoting as an internal communication stack. It is worth pointing out that, with <em>private</em> services, you need to be concerned about interoperability and refrain from using custom communication stacks. .NET remoting is not an official standard, but it is acceptable because it is a kind of de facto standard for internal communication within Azure Service Fabric.</li>
<li><strong>Availability of tools and knowledge in your team</strong>: Having knowledge and knowing about the availability of tools in your team/organization has an important weight when it comes to choosing between acceptable communication stacks. However, this kind of constraint always has less priority than compatibility constraints since it makes no sense to conceive a system that is easy to implement for your team but that almost nobody can use.</li>
<li><strong>Flexibility versus available features</strong>: Some communication solutions, while less complete, offer a higher degree of flexibility, while other solutions, while being more complete, offer less flexibility. The need for flexibility started a movement from SOAP-based services to the more flexible REST services in the last few years. This point will be discussed in more detail when we describe SOAP and REST services in the remainder of this section. </li>
<li><strong>Service description</strong>: When services must be exposed on the internet, client applications need a publicly available description of the service specifications in order to design their communication clients. Some communication stacks include languages and conventions to describe service specifications. Formal service specifications that are exposed this way can be processed so that they automatically create communication clients. SOAP goes further and allows service discoverability by means of a public XML-based directory containing information about the tasks each web service can carry out.</li>
</ul>
<p>Once you've chosen the communication stack you wish to use, you must use the tools that are available in your development environment to implement the service in a way that conforms to the chosen communication stack. Sometimes, communication stack compliance is automatically ensured by the development tools, but sometimes, it may require some development effort. For instance, in the .NET world, the compliance of SOAP services is automatically ensured by development tools if you use WCF, while the compliance of REST services falls under the developer's responsibility.</p>
<p>Some of the fundamental features of SOA solutions are as follows:</p>
<ul>
<li><strong>Authentication</strong>: Allows the client to authenticate to access service operations.</li>
<li><strong>Authorization</strong>: Handles the client's permissions.</li>
<li><strong>Security</strong>: This is how communication is kept safe, that is, how to prevent unauthorized systems from reading and/or modifying the content of the communication. Typically, encryption prevents both unauthorized modifications and reading, while electronic signature algorithms prevent just modifications.</li>
<li><strong>Exceptions</strong>: Returns exceptions to the client.</li>
<li><strong>Message reliability</strong>: Ensures that messages reliably reach their destination in case of possible infrastructure faults.</li>
</ul>
<p>Though sometimes desirable, the following features aren't always necessary:</p>
<ul>
<li><strong>Distributed transactions</strong>: The capability to handle distributed transactions, thus undoing all the changes you've made whenever the distributed transactions fail or are aborted</li>
<li><strong>Support for the Publisher/Subscriber pattern</strong>: If and how events and notifications are supported</li>
<li><strong>Addressing</strong>: If and how references to other services and or service/methods are supported</li>
<li><strong>Routing</strong>: If and how messages can be routed through a network of services</li>
</ul>
<p>The remainder of this section is dedicated to describing SOAP and REST services since they are the de facto standard for business services that are exposed outside of their clusters/servers. For performance reasons, microservices use other protocols such as .NET Remoting and AMQP for inter-cluster communication. The usage of .NET Remoting was discussed in <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>, while links on AMQP are given in the <em>Further reading</em> section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">SOAP web services</h1>
                
            
            
                
<p>The <strong>Simple Object Access Protocol</strong> (<strong>SOAP</strong>) allows both one-way messages and answer/response messages. Communication can be both synchronous and asynchronous, but, if the underlying protocol is synchronous, such as in the case of HTTP, the sender receives an acknowledgment saying that the message was received (but not necessarily processed). When asynchronous communication is used, the sender must listen for incoming communications. Often, asynchronous communication is implemented with the subscriber/publisher pattern that we described in <a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml"/><a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml">Chapter 9</a>, <em>Design Patterns and .NET Core Implementation</em>.</p>
<p>Messages are represented as XML documents called <strong>envelopes</strong>. Each envelope contains a <kbd>header</kbd>, a <kbd>body</kbd>, and a <kbd>fault</kbd> element. The <kbd>body</kbd> is where the actual content of the message is placed. The <kbd>fault</kbd> element contains possible errors, so it's the way exceptions are exchanged when communication occurs. Finally, the <kbd>header</kbd> contains any auxiliary information that enriches the protocol but does not contain domain data. For example, the <kbd>header</kbd> may contain an authentication token, and/or a signature if the message is signed. </p>
<p>The underlying protocol that's used to send the XML envelopes is usually HTTP, but the SOAP specification allows any protocol, so we can use TCP/IP or SMTP directly. As a matter of fact, the more diffused underlying protocol is HTTP, so, if you don't have a good reason to choose another protocol, you should use HTTP in order to maximize the service's interoperability.</p>
<p>SOAP specifications contain the basics of message exchange, while other auxiliary features are described in separate specification documents called <kbd>WS- *</kbd> and are usually handled by adding extra information in the SOAP <kbd>header</kbd>. <kbd>WS-*</kbd> specifications handle all the fundamental and desirable features of SOA we listed previously. For instance, <kbd>WS-Security</kbd> takes care of security, including authentication, authorization, and encryption/signatures; <kbd>WS-Eventing</kbd> and <kbd>WS-Notification</kbd> are two alternative ways of implementing the publisher/subscriber pattern; <kbd>WS-ReliableMessaging</kbd> is concerned with the reliable delivery of messages in case of possible faults, and <kbd>WS-Transaction</kbd> is concerned with distributed transactions. </p>
<p>The preceding <kbd>WS-*</kbd> specifications are in no way exhaustive but are the more relevant and supported features. In fact, actual implementations in various environments (such as Java and .NET) furnish the more relevant <kbd>WS-*</kbd> services, but no implementation supports all the <kbd>WS-*</kbd> specifications.</p>
<p>All the XML documents/document parts involved in the SOAP protocol are formally defined in XSD documents, which are special XML documents whose content provides a description of XML structures. Also, all your custom data structures (classes and interfaces in an object-oriented language) must be translated into XSD if they are going to be part of a SOAP envelope.</p>
<p>Each XSD specification has an associated <kbd>namespace</kbd> that identifies the specification and a physical location where it can be found. Both the namespace and the physical location are URIs. The location URI doesn't need to be publicly accessible if the web service is accessible just from within an intranet. </p>
<p>The whole definition of a service is an XSD specification that may contain references to other namespaces, that is, to other XSD documents. In a few words, all the messages of a SOAP communication must be defined in an XSD specification. Then, a server and a client can communicate if they refer to the same XSD specifications. This means, for instance, that you need to create a new XSD specification each time you add another field to a message. After that, you need to update all the XSD files that reference the old message definition to the new message definition by creating a new version of them. In turn, these modifications require the creation of other versions for other XSD files, and so on. Therefore, simple modifications that maintain compatibility with the previous behavior (clients could simply ignore the field that was added) may cause an exponential chain of version changes.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In the last few years, the difficulty in handling modifications, along with the complexity of handling the configuration of all the <kbd>WS-*</kbd> specifications and performance problems, caused a gradual move toward the simpler REST services that we will describe in the upcoming sections. This move started with services that were called from JavaScript due to the difficulty of implementing complete SOAP clients that were able to run efficiently in a web browser. Moreover, the complex SOAP machinery was oversized for the simple needs of the typical clients running in a browser and may have caused a complete waste of development time.</p>
<p>Around 2018, services aimed at non-JavaScript clients started a massive move toward REST services, and nowadays the preferred choice is REST services, with SOAP being used either for compatibility with legacy systems or when features that aren't supported by REST services are needed. A typical application area that continues to prefer to SOAP system is that of payment/banking systems because these systems need transactional support that is offered by the <kbd>WS-Transaction</kbd> SOAP specification. There is no equivalent in the REST services world.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">REST web services</h1>
                
            
            
                
<p>REST services were initially conceived to avoid the complex machinery of SOAP in simple cases such as calls to a service from the JavaScript code of a web page. Then, they gradually became the preferred choice for complex systems. REST services use HTTP to exchange data in JSON or, less commonly, in XML format. In a few words, they replace the SOAP body with the HTTP body, the SOAP header with the HTTP header, and the HTTP response code replaces the fault element and furnishes further auxiliary information on the operation that was performed.</p>
<p>The main reason for the success of REST services is that HTTP already offers most of SOAP's features natively, which means we can avoid building a SOAP level on top of HTTP. Moreover, the whole HTTP machinery is simpler than SOAP: simpler to program, simpler to configure, and simpler to implement efficiently.</p>
<p>Moreover, REST services impose fewer constraints on the clients. In particular, type compatibility between servers and clients conforms to the more flexible JavaScript type compatibility model because JSON is a subset of JavaScript. Moreover, when XML is used in place of JSON, it maintains the same JavaScript type compatibility rules. No XML namespaces need to be specified. </p>
<p>When using JSON and XML, if the server adds some more fields to the response while keeping the same semantic of all the other fields compatible with the previous client, they can simply ignore the new fields. Accordingly, changes that are made to a REST service definition only need to be propagated to previous clients in case of breaking changes that cause an actual incompatible behavior in the server.</p>
<p>Moreover, it is likely that changes are self-limited and do not result in an exponential chain of changes because type compatibility does not require the reference to a specific type to be defined in a unique shared place and simply requires that the shape of types is compatible. </p>
<p>Let's clarify the REST service's type compatibility rules with an example. Let's imagine that several services use a <kbd>Person</kbd> object that contains <kbd>Name</kbd>, <kbd>Surname</kbd>, and <kbd>Address</kbd> string fields:</p>
<pre>{<br/>    Name: string,<br/>    Surname: string,<br/>    Address: string<br/>}</pre>
<p>Type compatibility is ensured if the service and client refer to different copies of the preceding definition. It is also acceptable for the client to use a definition with fewer fields, since it can simply ignore all the other fields:</p>
<pre>{<br/>    Name: string,<br/>    Surname: string,<br/>}</pre>
<p>Now, let's say that a service, S1, that handles a <kbd>Persons</kbd> database, replaces the <kbd>Address</kbd> string with a complex object:</p>
<pre>{<br/>    Name: string,<br/>    Surname: string,<br/>    Address: <br/>        {<br/>            Country: string,<br/>            Town: string<br/>            Location: string<br/>        }<br/>}</pre>
<p>Now, let's say that a service, S2, takes <kbd>Persons</kbd> from S1 and adds it to the responses it returns on some of its methods. After the breaking change of S1, it can adapt its communication client that calls S1 to the new format. Then, it can convert the new <kbd>Person</kbd> format into the older one before using <kbd>Persons</kbd> in its responses. This way. S2 avoids propagating the breaking change of S1.</p>
<p class="mce-root">In general, basing type compatibility on the object shape (tree of nested properties), instead of a reference to the same formal type definition, increases flexibility and modifiability. The price we pay for this increased flexibility is that type compatibility can't be computed automatically by comparing the formal definition of server and client interfaces. In fact, in absence of a univocal specification, each time a new version of the service is released, the developer must verify that the semantics of all the fields that the client and server have in common remain unchanged from the previous version. The basic idea behind REST services is to give up the severity checks and complex protocols for greater flexibility and simplicity, while SOAP does exactly the opposite.</p>
<p>The REST services manifesto states that REST uses native HTTP features to implement all the required service features. So, for instance, authentication will be performed directly with the HTTP <kbd>Authorization</kbd> field, encryption will be achieved with HTTPS, exceptions will be handled with an HTTP error status code, and routing and reliable messaging will be handled by the machinery the HTTP protocol relies on. Addressing is achieved by using URLs to refer to services, their methods, and other resources.</p>
<p>There is no native support for asynchronous communication since HTTP is a synchronous protocol. There's also no native support for the Publisher/Subscriber pattern, but two services can interact with the Publisher/Subscriber pattern by each exposing an endpoint to the other. More specifically, the first service exposes a subscription endpoint, while the second one exposes an endpoint where it receives its notifications, which are authorized through a common secret that's exchanged during the subscription. This pattern is quite common. GitHub also allows us to send our REST services to repository events.</p>
<p>REST services offer no easy options when it comes to implementing distributed transactions, which is why payment/banking systems still prefer SOAP. Luckily, most application areas don't need the strong form of consistency that's ensured by distributed transactions. For them, lighter forms of consistency, such as <em>eventual consistency</em>, are enough and are preferred for performance reasons. Please refer to <a href="77cdecb5-cef4-4b02-80a1-052ad366b9f3.xhtml">Chapter 7</a>, <em>How to Choose Your Data Storage in the Cloud</em>, for a discussion on the various types of consistencies.</p>
<p>The REST manifesto not only prescribes the usage of the predefined solutions that are already available in HTTP but also the usage of a WEB-like semantic. More specifically, all the service operations must be conceived as CRUD operations on resources that are identified by URLs (the same resource may be identified by several URLs). In fact, REST is an acronym for <strong>Representational State Transfer</strong>, meaning that each URL is the representation of some sort of object. Each kind of service request needs to adopt the appropriate HTTP verb, as follows:</p>
<ul>
<li><kbd>GET</kbd> (Read operation): The URL represents the resource that is returned by the read operation. Thus, <kbd>GET</kbd> operations mimic pointer dereferencing. In the case of a successful operation, a 200 (ok) status code is returned.</li>
<li><kbd>POST</kbd> (Creation operation): The JSON/XML object that's contained in the request body is added as a new resource to the object represented by the operation URL. If the new resource is successfully created immediately, a 201 (created) status code is returned, along with a response object that depends on the operation. The response object should contain the most specific URL that identifies the created resource. If creation is deferred to a later time, a 202 (accepted) status code is returned. </li>
<li><kbd>PUT</kbd>: The JSON/XML object contained in the request body replaces the object referenced by the request URL. In the case of successful operation, a 200 (ok) status code is returned. This operation is idempotent, meaning that repeating the same request twice causes the same modification.</li>
<li><kbd>PATCH</kbd>: The JSON/XML object contained in the request body contains instructions on how to modify the object referenced by the request URL. This operation is not idempotent since the modification may be an increment of a numeric field. In the case of successful operation, a 200 (ok) status code is returned.</li>
<li><kbd>DELETE</kbd>: The resource referenced by the request URL is removed. In the case of successful operation, a 200 (ok) status code is returned.</li>
</ul>
<p>If the resource has been moved from the request URL to another URL, a redirect code is returned:</p>
<ul>
<li>301 (moved permanently), plus the new URL where we can find the resource</li>
<li>307 (moved temporarily), plus the new URL where we can find the resource</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>If the operation fails, a status code that depends on the kind of failure is returned. Some examples of failures codes are as follows:</p>
<ul>
<li>400 (bad request): The request that was sent to the server is ill-formed.</li>
<li>404 (not found): When the request URL doesn't refer to any known object.</li>
<li>405 (method not allowed): When the request verb is not supported by the resource referenced by the URL.</li>
<li>401 (unauthorized): The operation requires authentication, but the client has not furnished any valid authorization header.</li>
<li>403 (forbidden): The client is correctly authenticated but has no right to perform the operation. </li>
</ul>
<p>The preceding list of status codes is not exhaustive. References to an exhaustive list will be provided in the <em>Further reading</em> section.</p>
<p>It is fundamental to point out that <kbd>POST</kbd>/<kbd>PUT</kbd>/<kbd>PATCH</kbd>/<kbd>DELETE</kbd> operations may have – and usually have – side effects on other resources. Otherwise, it would be impossible to code operations that act simultaneously on several resources.</p>
<p>In other words, the HTTP verb must conform with the operation that's performed on the resource and referenced by the request URL, but the operation might affect other resources. The same operation might be performed with a different HTTP verb on one of the other involved resources. It is the developer's responsibility to choose which way to perform the same operation in order to implement it in the service interface.</p>
<p>Thanks to the side effects of HTTP verbs, REST services are able to encode all of these operations as CRUD operations on resources represented by URLs.</p>
<p>Often, moving an existing service to REST requires us to split the various inputs between the request URL and the request body. More specifically, we extract the input fields that univocally define one of the objects involved in the method's execution and use them to create a URL that univocally identifies that object. Then, we decide on which HTTP verb to use based on the operation that's performed on the selected object. Finally, we place the remainder of the input in the request body.</p>
<p>If our services were designed with an object-oriented architecture focused on the business domain objects (such as DDD, as described in <a href="2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml">Chapter 10</a>, <em>Understanding the Different Domains in Software Solutions</em>), the REST translation of all the service methods should be quite immediate, since services should already be organized around domain resources. Otherwise, moving to REST might require some service interface redefinitions. </p>
<p>The adoption of full REST semantics has the advantage that services can be extended with or without small modifications being made to the preexisting operation definitions. In fact, extensions should mainly manifest as additional properties of some objects and as additional resources URLs with some associated operations. Therefore, preexisting clients can simply ignore them.</p>
<p>Now, let's learn how methods can be expressed in the REST language with a simple example of an intra-bank money transfer. A bank account can be represented by an URL, as follows:</p>
<pre>https://mybank.com/bankaccounts/{bank account number}</pre>
<p>A transfer might be represented as a PATCH request whose body contains an object with properties representing the amount of money, time of transfer, description, and the account receiving the money. The operation modifies the account mentioned in the URL, but also the receiving account as a <em>side effect</em>. If the account has not enough money, a 403 (Forbidden) status code is returned, along with an object with all the error details (an error description, the available funds, and so on).</p>
<p>However, since all the bank operations are recorded in the account statement, the creation and addition of a new transfer object for a <em>bank account operations</em> collection associated with the bank account is a better way to represent the transfer. In this case, the URL might be something like the following:</p>
<pre>https://mybank.com/bankaccounts/{bank account number}/operations</pre>
<p>Here, the HTTP verb is <kbd>POST</kbd> since we are creating a new object. The body content is exactly the same and a 403 status code is returned in case there's a lack of funds. </p>
<p>Both representations of the transfer cause exactly the same changes in the database. Moreover, once the inputs are extracted from the different URLs and from the possibly different request bodies, the subsequent processing is exactly the same. In both cases, we have exactly the same inputs and the same processing – it's just the exterior appearance of the two requests that's different.</p>
<p>However, the introduction of the virtual <em>operations</em> collection allows us to extend the service with several more operations collection-specific methods. It is worth pointing out that the operations collection doesn't need to be connected with a database table or with any physical object: it lives in the world of URLs and creates a convenient way for us to model the transfer.</p>
<p>The increased usage of REST services leads to a description of REST service interfaces to be created, similar to the ones developed for SOAP. This standard is called <strong>OpenAPI</strong>. We will talk about this in the following subsection.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The OpenAPI standard</h1>
                
            
            
                
<p>OpenAPI is a standard that's used for describing the REST API. It is currently version 3. The whole service is described by a JSON endpoint, that is, an endpoint that describes the service with a JSON object. This JSON object has a general section that applies to the whole service and contains the general features of the services, such as its version and description, as well as shared definitions.</p>
<p>Then, each service endpoint has a specific section that describes the endpoint URL or URL format (in case some inputs are included in the URL), all its inputs, all the possible output types and status codes, and all the authorization protocols. Each endpoint-specific section can reference the definitions contained in the general section.</p>
<p>A description of the OpenAPI syntax is out of the scope of this book, but references are provided in the <em>Further reading</em> section. Various development frameworks automatically generate OpenAPI documentation by processing the REST API code and further information is provided by the developer, so your team doesn't need to have in-depth knowledge of OpenAPI syntax.</p>
<p>The <em>How does .NET Core deal with SOA?</em> section explains how we can generate automatically OpenAPI documentation in ASP.NET Core REST API projects, while the use case at the end of this chapter provides a practical example of its usage.</p>
<p>We will end this subsection by talking about how to handle authentication and authorization in REST services.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">REST services authorization and authentication</h1>
                
            
            
                
<p>Since REST services are sessionless, when authentication is required, the client must send an authentication token in every single request. That token is usually placed in the HTTP authorization header, but this depends on the type of authentication protocol you're using. The simplest way to authenticate is through the explicit transmission of a shared secret. This can be done with the following code:</p>
<pre>Authorization: Api-Key &lt;string known by both server and client&gt;</pre>
<p>The shared secret is called an API key. Since, at the time of writing, there is no standard on how to send it, API keys can also be sent in other headers, as shown in the following code:</p>
<pre>X-API-Key: &lt;string known by both server and client&gt;</pre>
<p>Needless to say, API key-based authentication needs HTTPS to stop shared secrets from being stolen. API keys are very simple to use, but they do not convey information about user authorizations, so they can be adopted when the operations allowed by the client are quite standard and there are no complex authorization patterns. Moreover, when exchanged in requests, API keys are susceptible to being attacked on the server or client side.</p>
<p>Safer techniques use shared secrets that are valid for a long period of time, just by the user logging in. Then, the login returns a short-life token that is used as a shared secret in all the subsequent requests. When the short-life secret is going to expire, it can be renewed with a call to a renew endpoint.</p>
<p>The whole login logic is completely decoupled from the short-life token-based authorization logic. The login is usually based on login endpoints that receive long-term credentials and returns short-life tokens. Login credentials are either usual username-password pairs that are passed as input to the login method or other kinds of authorization tokens that are converted into short-life tokens that are served by the login endpoint. Login can also be achieved with various authentication protocols based on X.509 certificates.</p>
<p>The most widespread short-life token type is the so-called bearer token. Each bearer token encodes information about how long it lasts and a list of assertions, called claims, that can be used for authorization purposes. Bearer tokens are returned by either login operations or renewal operations. Their characteristic feature is that they are not tied to the client that receives them or to any other specific client.</p>
<p>No matter how a client gets a bearer token, this is all a client needs to be granted all the rights implied by its claims. It is enough to transfer a bearer token to another client to empower that client with all rights implied by all the bearer token claims, since no proof of identity is required by bearer token-based authorization. </p>
<p>Therefore, once a client gets a bearer token, it can delegate some operations to third parties by transferring its bearer token to them. Typically, when a bearer token must be used for delegation, during the login phase, the client specifies the claims to include in order to restrict what operations can be authorized by the token.</p>
<p> Compared to API key authentication, bearer token-based authentication is disciplined by standards. In particular, they must use the following <kbd>Authorization</kbd> header:</p>
<pre>Authorization: Bearer &lt;bearer token string&gt;</pre>
<p>Bearer tokens can be implemented in several ways. REST services typically use JWT tokens that are strung with a Base64URL encoding of JSON objects. More specifically, JWT creation starts with a JSON header, as well as a JSON payload. The JSON header specifies the kind of token and how it is signed, while the payload consists of a JSON object that contains all the claims as property/value pairs. The following is an example header:</p>
<pre>{<br/>  "alg": "RS256",<br/>  "typ": "JWT"<br/>}</pre>
<p>The following is an example payload:</p>
<pre>{<br/>  "iss": "issuerbomain.com"<br/>  "sub": "example",<br/>  "aud": ["S1", "S2"],<br/>  "roles": [<br/>    "ADMIN",<br/>    "USER"<br/>  ],<br/>  "exp": 1512975450,<br/>  "iat": 1512968250230<br/>}</pre>
<p>Then, the header and payload are BASE64URL-encoded and the corresponding string is concatenated, as follows:</p>
<pre>&lt;header BASE64 string&gt;.&lt;payload base64 string&gt;</pre>
<p>The preceding string is then signed with the algorithm specified in the header, which, in our example, is RSA +SHA256, and the signature string is concatenated with the original string as follows:</p>
<pre>&lt;header BASE64 string&gt;.&lt;payload base64 string&gt;.&lt;signature string&gt;</pre>
<p>The preceding code is the final bearer token string. A symmetric signature can be used instead of RSA, but, in this case, both the JWT issuer and all the services using it for authorization must share a common secret, while, with RSA, the private key of the JWT issuer doesn't need to be shared with anyone, since the signature can be verified with just the issuer public key.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Some payload properties are standard, such as the following:</p>
<ul>
<li><kbd>iss</kbd>: Issuer of the JWT.</li>
<li><kbd>aud</kbd>: The audience, that is, the services and/or operations that can use the token for authorization. If a service doesn't see its identifier within this list, it should reject the token.</li>
<li><kbd>sub</kbd>: A string that identifies the <em>principal</em> (that is, the user) to which the JWT was issued.</li>
<li><kbd>iat</kbd>, <kbd>exp</kbd>, and <kbd>nbf</kbd>: These are for the time the JWT was issued, its expiration time, and, if set, the time after which the token is valid, respectively. All the times are expressed as a number of seconds from the 1st of January 1970 midnight UTC. Here, all the days are considered as having exactly 86,400 seconds in them.</li>
</ul>
<p>Other claims may be defined as public if we represent them with a unique URI; otherwise, they are considered private to the issuer and to the services known to the issuer.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">How does .NET Core deal with SOA?</h1>
                
            
            
                
<p>.Net Core has excellent support for REST services through ASP.NET Core. In terms of SOAP services, classic .NET handles them with WCF technology. In WCF, service specifications are defined through .NET interfaces and the actual service code is supplied in classes that implement those interfaces.</p>
<p>Endpoints, underlying protocols (HTTP and TCP/IP), and any other features are defined in a configuration file. In turn, the configuration file can be edited with an easy to use configuration tool. Therefore, the developer is responsible for providing just the service behavior as a standard .NET class and for configuring all the service features in a declarative way. This way, the service configuration is completely decoupled from the actual service behavior and each service can be reconfigured so that it can be adapted to a different environment without the need to modify its code.</p>
<p>WCF technology has not been ported to .NET Core and there are no plans to perform a complete port of it. Instead, Microsoft is investing in gRPC, Google's open source technology. </p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The main reasons behind the decision to abandon WCF in .NET core are as follows:</p>
<ul>
<li>As we've already discussed, SOAP technology has been overtaken by REST technology in most application areas.</li>
<li>WCF technology is strictly tied to Windows, so it would be very expensive to reimplement all its features from scratch in .NET Core. Since support for classic .NET will continue, users that need WCF can still rely on classic .NET.</li>
<li>As a general strategy, with .NET Core, Microsoft prefers investing in open source technologies that can be shared with other competitors. That's why, instead of investing in WCF, Microsoft provided a gRPC implementation starting from .NET Core 3.0.</li>
</ul>
<p>While .NET Core doesn't support SOAP technology, it does support SOAP clients. More specifically, it is quite easy to create a SOAP service proxy for an existing SOAP service in Visual Studio, starting from the 2017 version (please refer to <a href="a2d50e08-6698-47f6-a9b5-188de08134c0.xhtml">Chapter 9</a>, <em>Design Patterns and .NET Core Implementation</em>, for a discussion of what a proxy is and of the proxy pattern). In the case of services, a proxy is a class that implements the service interface and whose methods perform their job by calling the analogous methods of the remote service.</p>
<p>To create a service proxy, right-click on the <em>connected services</em> node in Visual Studio, go to Solution Explores, and then select Add connected service. Then, in the form that appears, select Microsoft WCF Service Reference Provider. Here, you can specify the URL of the service (where the WSDL service description is contained), the namespace where you wish to add the proxy class, and much more. At the end of the wizard, Visual Studio automatically adds all the necessary NuGet packages and scaffolds the proxy class. This is enough to create an instance of this class and to call its methods so that we can interact with the remote SOAP service.</p>
<p>There are also third parties, such as NuGet packages that provide limited support for SOAP services, but at the moment, they aren't very useful, since such limited support does not include features that aren't available in REST services.</p>
<p>Starting from .NET Core SDK, Visual Studio 2019 supports the gRPC project template, which scaffolds both a gRPC server and a gRPC client. At the time of writing, gRPC is not a standard and just a Google open source project. However, if both Microsoft and Google continue investing in it, it might become a de facto standard. gRPC implements a remote procedure call pattern that offers both synchronous and asynchronous calls.</p>
<p>It is configured in a way that is similar to WCF and to .NET remoting, as we described at the end of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>. That is, services are defined through interfaces and their code is provided in classes that implement those interfaces, while clients interact with those services through proxies that implement the same service interfaces.</p>
<p>gRPC is a good option for internal communications within a microservices cluster, especially if the cluster is not fully based on Service Fabric technology and can't rely on .NET remoting. Since there are gRPC libraries for all the main languages and development frameworks, it can be used in Kubernetes-based clusters, as well as in Service Fabric clusters that host Docker images that have been implemented in other frameworks. </p>
<p>gRPC is more efficient than the REST services protocol due to its more compact representation of data and it being easier to use, since everything to do with the protocol is taken care of by the development framework. However, at the time of writing, none of its features rely on well-established standards, so it can't be used for publicly exposed endpoints – it can only be used for intra-cluster communication. For this reason, we will not describe gRPC in detail, but the <em>Further reading</em> section of this chapter contains references to both gRPC in general and to its .NET Core implementation. </p>
<p>Using gRPC is super easy since Visual Studio's gRPC project template scaffolds everything so that the gRPC service and its clients are working. The developer just needs to define the application-specific C# service interface and a class that implements it.</p>
<p>The remainder of the section is dedicated to .NET Core support for REST services from both the server and client-side. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">A short introduction to ASP.NET Core</h1>
                
            
            
                
<p>ASP.NET Core applications are .NET Core applications based on the <em>Host</em> concept we described in the <em>Using generic hosts</em> subsection of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>. The <kbd>program.cs</kbd> file of each ASP.NET application creates a Host, builds it, and runs it with the following code:</p>
<pre>public class Program<br/>{<br/>    public static void Main(string[] args)<br/>    {<br/>        CreateHostBuilder(args).Build().Run();<br/>    }<br/><br/>    public static IHostBuilder CreateHostBuilder(string[] args) =&gt;<br/>        Host.CreateDefaultBuilder(args)<br/>            .ConfigureWebHostDefaults(webBuilder =&gt;<br/>            {<br/>                webBuilder.UseStartup&lt;Startup&gt;();<br/>            });<br/>}</pre>
<p><kbd>CreatesDefaultBuilder</kbd> sets up a standard Host, while <kbd>ConfigureWebHostDefaults</kbd> configures it so that it can handle an HTTP pipeline. More specifically, it does the following:</p>
<ul>
<li>It sets the <kbd>ContentRootPath</kbd> property of the <kbd>IHostingEnvironment</kbd> interface for the current directory.</li>
<li>It loads the configuration information from <kbd>appsettings.json</kbd> and <kbd>appsettings.[EnvironmentName].json</kbd>. Once loaded, the configuration information contained in the JSON object properties can be mapped to .NET Object properties with the ASP.NET Core options framework. More specifically, <kbd>appsettings.json</kbd> and <kbd>appsettings.[EnvironmentName].json</kbd> are merged and the <kbd>appsettings.[EnvironmentName]</kbd> file's environment-specific information overrides the corresponding <kbd>appsettings.json</kbd> settings. <kbd>EnvironmentName</kbd> is taken from the <kbd>ASPNETCORE_ENVIRONMENT</kbd> environment variable. In turn, <kbd>ASPNETCORE_ENVIRONMENT</kbd> is defined in the <kbd>Properties\launchSettings.json</kbd> file when the application is run in Visual Studio. The following screenshot shows where you can find <kbd>launchSettings.json</kbd> in Visual Studio Solution Explorer: </li>
</ul>
<div><img src="img/e1030042-bb95-469a-9421-648443cea65e.png"/></div>
<p style="padding-left: 60px">In <kbd>launchSettings.json</kbd>, you can define several environments that can be selected with the dropdown next to Visual Studio's run button <img src="img/27ad6b8b-7341-4dcd-a1bb-20ce544816c4.png" style="width:5.42em;height:1.67em;"/>. By default, the IIS Express setting sets <kbd>ASPNETCORE_ENVIRONMENT</kbd> to <kbd>Development</kbd>. The following is a typical <kbd>launchSettings.json</kbd> file:<br/></p>
<pre style="padding-left: 60px">{<br/>  "iisSettings": {<br/>    "windowsAuthentication": false, <br/>    "anonymousAuthentication": true, <br/>    "iisExpress": {<br/>      "applicationUrl": "http://localhost:2575",<br/>      "sslPort": 44393<br/>    }<br/>  },<br/>  "profiles": {<br/>    "IIS Express": {<br/>      "commandName": "IISExpress",<br/>      "launchBrowser": true,<br/>      "environmentVariables": {<br/>        "ASPNETCORE_ENVIRONMENT": "Development"<br/>      }<br/>    },<br/>    ...<br/>    ...<br/>    }<br/>  }<br/>}</pre>
<p style="padding-left: 60px"><br/>
The value to use for <kbd>ASPNETCORE_ENVIRONMENT</kbd> when the application is published can be added to the published XML file after it has been created by Visual Studio. This value is <kbd>&lt;EnvironmentName&gt;Staging&lt;/EnvironmentName&gt;</kbd>. It can be also specified in your Visual Studio ASP.NET Core project file (<kbd>.csproj</kbd>):<br/>
<kbd>&lt;PropertyGroup&gt; &lt;EnvironmentName&gt;Staging&lt;/EnvironmentName&gt;&lt;/PropertyGroup&gt;</kbd>.</p>
<ul>
<li>It configures Host logging so that it can write to the console and debug output. This setting can be changed with further configuration.</li>
<li>It sets up/connects a web server to the ASP.NET Core pipeline.</li>
</ul>
<p>When the application runs in Linux, the ASP.NET Core pipeline connects to the .NET Core Kestrel web server. Since Kestrel is a minimal web server, you are responsible for reverse proxying requests to it from a complete web server, such as Apache or Nginx, that adds features that Kestrel doesn't have. When the application runs in Windows, by default, <kbd>ConfigureWebHostDefaults</kbd> connects the ASP.NET Core pipeline directly to <strong>Internet Information Services</strong> (<strong>IIS</strong>). However, you can also use Kestrel in Windows and you can reverse proxy IIS requests to Kestrel by changing the <kbd>AspNetCoreHostingModel</kbd> setting of your Visual Studio project file like so:</p>
<pre>&lt;PropertyGroup&gt;<br/>    ...<br/>    &lt;AspNetCoreHostingModel&gt;OutOfProcess&lt;/AspNetCoreHostingModel&gt;<br/>&lt;/PropertyGroup&gt;</pre>
<p><kbd>UseStartup&lt;Startup&gt;()</kbd> lets Host services (see the <em>Using generic hosts</em> subsection in <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>) and the definition of the ASP.NET Core pipeline be taken from the methods of the project's <kbd>Startup.cs</kbd> class. More specifically, services are defined in its <kbd>ConfigureServices(IServiceCollection services)</kbd> method, while the ASP.NET Core pipeline is defined in the <kbd>Configure</kbd> method. The following code shows the standard <kbd>Configure</kbd> method scaffolded with an API REST project:</p>
<pre>public void Configure(IApplicationBuilder app, <br/>    IWebHostEnvironment env)<br/>{<br/>    if (env.IsDevelopment())<br/>    {<br/>        app.UseDeveloperExceptionPage();<br/>    }<br/><br/>    app.UseHttpsRedirection();<br/><br/>    app.UseRouting();<br/><br/>    app.UseAuthorization();<br/><br/>    app.UseEndpoints(endpoints =&gt;<br/>    {<br/>        endpoints.MapControllers();<br/>    });<br/>}</pre>
<p>Each module in the pipeline is defined by an <kbd>app.Use&lt;something&gt;</kbd> method, which often accepts some options. Each module processes the requests and then either forwards the modified request to the next module in the pipeline or returns an HTTP response. When an HTTP response is returned, it is processed by all the previous modules in reverse order.</p>
<p>Modules are inserted in the pipeline in the order they are defined by the <kbd>app.Use&lt;something&gt;</kbd> method calls. The preceding code adds an error page if <kbd>ASPNETCORE_ENVIRONMENT</kbd> is <kbd>Development</kbd>; otherwise, <kbd>UseHsts</kbd> negotiates a security protocol with the client. Finally, <kbd>UseEndpoints</kbd> adds the MVC controllers that create the actual HTTP response. A complete description of the ASP.NET Core pipeline will be given in the <em>Understanding the presentation layers of web applications</em> section of <a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml">Chapter 13</a>, <em>Presenting ASP.NET Core MVC</em>.</p>
<p>In the next subsection, we will explain how the MVC framework lets you implement REST services.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Implementing REST services with ASP.NET Core</h1>
                
            
            
                
<p>In the MVC framework, HTTP requests are processed by classes called Controllers. Each request is mapped to the call of a Controller public method. The selected controller and controller methods depend on the shape of the request path, and they are defined by routing rules, that, for the REST API, are usually provided through attributes associated with both the Controller class and its methods.</p>
<p>Controller methods that process HTTP requests are called action methods. When the controller and action methods are selected, the MVC framework creates a controller instance to serve the request. All the parameters of the controller constructors are resolved with dependency injection with types defined in the <kbd>ConfigureServices</kbd> method of the <kbd>Startup.cs</kbd> class.</p>
<p>Please refer to the <em>Using generic hosts</em> subsection of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>, for a description of how to use dependency injection with .NET Core Hosts, and to the <em>Dependency injection pattern</em> subsection of <a href="2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml">Chapter 10</a>, <em>Understanding the Different Domains in Software Solutions</em>, for a general discussion of dependency injection.</p>
<p>The following is a typical REST API controller and its controller method definitions:</p>
<pre>    [Route("api/[controller]")]<br/>    [ApiController]<br/>    public class ValuesController : ControllerBase<br/>    {<br/>        // GET api/values/5<br/>        [HttpGet("{id}")]<br/>        public ActionResult&lt;string&gt; Get(int id)<br/>        {<br/>            ...</pre>
<p>The <kbd>[ApiController]</kbd> attribute declares that the controller is a REST API controller. <kbd>[Route("api/[controller]")]</kbd> declares that the controller must be selected on paths that start with <kbd>api/&lt;controller name&gt;</kbd>. The controller name is the name of the controller class without the <kbd>Controller</kbd> postfix. Thus, in this case, we have <kbd>api/values</kbd>.</p>
<p><kbd>[HttpGet("{id}")]</kbd> declares that the method must be invoked on GET requests of the <kbd>api/values/&lt;id&gt;</kbd> type, where <kbd>id</kbd> must be a number that's passed as an argument to the method invocation. This can be done with <kbd>Get(int id)</kbd>. There's also an <kbd>Http&lt;verb&gt;</kbd> attribute for each HTTP verb: <kbd>HttpPost</kbd> and <kbd>HttpPatch</kbd>.</p>
<p>We may also have another method defined like so:</p>
<pre>[HttpGet]<br/>public ... Get()</pre>
<p>This method is invoked on <kbd>GET</kbd> requests of the <kbd>api/values</kbd> type, that is, on <kbd>GET</kbd> requests without <kbd>id</kbd> after the controller name.</p>
<p>Several action methods can have the same name, but only one should be compatible with each request path; otherwise, an exception is thrown. In other words, routing rules and <kbd>Http&lt;verb&gt;</kbd> attributes must univocally define which controller and which of its action methods to select for each request. </p>
<p>By default, parameters are passed to the action methods of API controllers according to the following rules:</p>
<ul>
<li>Simple types (<kbd>integers</kbd>, <kbd>floats</kbd>, and <kbd>DateTimes</kbd>) are taken from the request path if routing rules specify them as parameters, as in the case of the previous example's <kbd>[HttpGet("{id}")]</kbd> attribute. If they are not found in the routing rules, the MVC framework looks for query string parameters with the same name. Thus, for instance, if we replace <kbd>[HttpGet("{id}")]</kbd> with <kbd>[HttpGet]</kbd>, the MVC framework will look for something like <kbd>api/values?id=&lt;an integer&gt;</kbd>.</li>
<li>Complex types are extracted from the request body by formatters. The right formatter is chosen according to the value of the request's <kbd>Content-Type</kbd> header. If no <kbd>Content-Type</kbd> header is specified, the JSON formatter is taken. The JSON formatter tries to parse the request body as a JSON object and then tries to transform this JSON object into an instance of the .NET Core complex type. If either the JSON extraction or the subsequent conversion fails, an exception is thrown. By default, just the JSON input formatter is supported, but you can also add an XML formatter that can be used when <kbd>Content-Type</kbd> specifies XML content. It is enough to add the <kbd>Microsoft.AspNetCore.Mvc.Formatters.Xml</kbd> NuGet package and replace <kbd>services.AddMvc()</kbd> with <kbd>services.AddMvc().AddXmlSerializerFormatters()</kbd> in the <kbd>ConfigureServices</kbd> method of <kbd>Startup.cs</kbd>.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p>You can customize the source that's used to fill an action method parameter by prefixing the parameter with an adequate attribute. The following code shows some examples of this:</p>
<pre>...MyAcrionMethod(....[FromHeader] string myHeader....) <br/>// x is taken from a request header named myHeader<br/><br/>...MyAcrionMethod(....[FromServices] MyType x....) <br/>// x is filled with an istance of MyType through dependency injection</pre>
<p>The return type of an <kbd>Action</kbd> method must be an <kbd>IAsyncResult</kbd> interface or a type that implements that interface. In turn, <kbd>IAsyncResult</kbd> has just the following method:</p>
<pre>public Task ExecuteResultAsync (ActionContext context)</pre>
<p>This method is called by the MVC framework at the right time to create the actual response and response headers. The <kbd>ActionContext</kbd> object, when passed to the method, contains the whole context of the HTTP request, which includes a request object with all the necessary information about the original HTTP requests (headers, body, and cookies), as well as a response object that collects all the pieces of the response that is being built.</p>
<p>You don't have to create an implementation of <kbd>IAsyncResult</kbd> manually, since <kbd>ControllerBase</kbd> already has methods to create <kbd>IAsyncResult</kbd> implementations so that all the necessary HTTP responses are generated. Some of these methods are as follows:</p>
<ul>
<li><kbd>OK</kbd>: This returns a 200 status code, as well as an optional result object. It is used either as <kbd>return OK()</kbd> or as <kbd>return OK(myResult)</kbd>.</li>
<li><kbd>BadRequest</kbd>: This returns a 400 status code, as well as an optional request object.</li>
<li><kbd>Created(string uri, object o)</kbd>: This returns a 201 status code, as well as a result object and the URI of the created resource.</li>
<li><kbd>Accepted</kbd>: This returns a 202 status result, as well as an optional result object and resource URI.</li>
<li><kbd>Unauthorized</kbd>: This returns a 401 status result, as well as an optional result object.</li>
<li><kbd>Forbid</kbd>: This returns a 403 status result, as well as an optional list of failed permissions.</li>
<li><kbd>StatusCode(int statusCode, object o = null)</kbd>: This returns a custom status code, as well as an optional result object.</li>
</ul>
<p>An action method can return a result object directly with <kbd>return myObject</kbd>. This is equivalent to returning <kbd>OK(myObject)</kbd>. </p>
<p>When all the result paths return a result object of the same type, say, <kbd>MyType</kbd>, the action method can be declared as returning <kbd>ActionResult&lt;MyType&gt;</kbd> to get a better type check. </p>
<p>By default, result objects are serialized in JSON in the response body. However, if an XML formatter has been added to the MVC framework processing pipeline, as shown previously, the way the result is serialized depends on the <kbd>Accept</kbd> header of the HTTP request. More specifically, if the client explicitly requires an XML format with the <kbd>Accept</kbd> header, the object will be serialized in XML; otherwise, it will be serialized in JSON.</p>
<p>Complex objects that are passed as input to action methods can be validated with validation attributes, as follows:</p>
<pre>public class MyType<br/>{<br/>    [Required]<br/>    public string Name{get; set;}<br/>    ...<br/>    [MaxLength(64)]<br/>    public string Description{get; set;}<br/>}</pre>
<p>If the controller has been decorated with the <kbd>[ApiController]</kbd> attribute and if validation fails, the MVC framework automatically creates a BadRequest response containing a dictionary with all the validation errors detected, without executing the action method. Therefore, you don't need to add further code to handle validation errors.</p>
<p>Action methods can also be declared as async methods, as follows:</p>
<pre>public async Task&lt;IActionResult&gt; MyMethod(......)<br/>{<br/>    await MyBusinessObject.MyBusinessMethod();<br/>    ...<br/>}<br/><br/>public async Task&lt;ActionResult&lt;MyType&gt;&gt; MyMethod(......)<br/>{<br/>    ...</pre>
<p>Practical examples of controllers/action methods will be shown in the use case section of this chapter. In the next subsection, we will explain how to handle authorization and authentication with JWT tokens. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">ASP.NET Core service authorization</h1>
                
            
            
                
<p>When using a JWT token, authorizations are based on the claims contained in the JWT token. All the token claims in any action method can be accessed through the <kbd>User.Claims</kbd> controller property. Since <kbd>User.Claims</kbd> is an <kbd>IEnumerable&lt;Claim&gt;</kbd>, it can be processed with <kbd>LinQ</kbd> to verify complex conditions on claims. If authorization is based on <em>role</em> claims, you can simply use the <kbd>User.IsInRole</kbd> function, as shown in the following code:</p>
<pre>If(User.IsInRole("Administrators") || User.IsInRole("SuperUsers"))<br/>{<br/>    ...<br/>}<br/>else return Forbid();</pre>
<p>However, permissions are not usually checked from within action methods and are automatically checked by the MVC framework, according to authorization attributes that decorate either the whole controller or a single action method. If an action method or the whole controller is decorated with <kbd>[Authorize]</kbd>, then access to the action method is possible only if the request has a valid authentication token, which means we don't have to perform a check on the token claims. It is also possible to check whether the token contains a set of roles using the following code:</p>
<pre>[Authorize(Roles = "Administrators,SuperUsers")]</pre>
<p>More complex conditions on claims require that authorization policies are defined in the <kbd>ConfigureServices</kbd> method of <kbd>Startup.cs</kbd>, as shown in the following code:</p>
<pre>public void ConfigureServices(IServiceCollection services)<br/>{<br/>    services.AddMvc();<br/>    ...<br/>    services.AddAuthorization(options =&gt;<br/>    {<br/>        options.AddPolicy("Father", policy =&gt; <br/>            policy.RequireAssertion(context =&gt;<br/>                context.User<br/>                    .HasClaim(c =&gt;c.Type == "Married") &amp;&amp;<br/>                context.User<br/>                    .HasClaim(c =&gt; c.Type == "HasSon")));<br/>                    <br/>    });<br/>}</pre>
<p>After that, you can decorate the action methods or controllers with <kbd>[Authorize(Policy = "Father")]</kbd>.</p>
<p>Before using JWT-based authorization, you must configure it in <kbd>Startup.cs</kbd>. First of all, you must add the middleware that processes authentication tokens in the ASP.NET Core processing pipeline defined in the <kbd>Configure</kbd> method, as shown here:</p>
<pre>public void Configure(IApplicationBuilder app, IHostingEnvironment env)<br/>{<br/>    ...<br/>    app.UseAuthentication();//authentication middleware<br/>    app.UseMvc();<br/>            <br/>}</pre>
<p>Then, you must configure the authentication services in the <kbd>ConfigureServices</kbd> section. Here, you define the authentication options that will be injected through dependency injection into the authentication middleware:</p>
<pre>services.AddAuthentication(JwtBearerDefaults.AuthenticationScheme)<br/>    .AddJwtBearer(options =&gt; {<br/>        options.TokenValidationParameters =<br/>            new TokenValidationParameters<br/>            {<br/>                ValidateIssuer = true,<br/>                ValidateAudience = true,<br/>                ValidateLifetime = true,<br/>                ValidateIssuerSigningKey = true,<br/><br/>                ValidIssuer = "My.Issuer",<br/>                ValidAudience = "This.Website.Audience",<br/>                IssuerSigningKey = <br/>                new SymmetricSecurityKey(Encoding.ASCII.GetBytes("MySecret"))<br/>    };<br/>});</pre>
<p>The preceding code provides a name to the authentication scheme, that is, a default name. Then, it specifies JWT authentication options. Usually, we require that the authentication middleware verifies that the JWT token is not expired (<kbd>ValidateLifetime = true</kbd>), that it has the right issuer and audience (see the <em>REST services authorization and authentication</em> section of this chapter), and that its signature is valid.</p>
<p>The preceding example uses a symmetric signing key generated from a string. This means that the same key is used to sign and to verify the signature. This is an acceptable choice if JWT tokens are created by the same website that uses them, but it is not an acceptable choice if there is a unique JWT issuer that controls access to several Web API sites.</p>
<p>Here, we should use an asymmetric key (typically, a RsaSecurityKey), so JWT verification requires just the knowledge of the public key associated with the actual private signing key. Identity Server 4 can be used to quickly create a website that works as an authentication server. It emits a JWT token with the usual username/password credentials or converts other authentication tokens. If you use an authentication server such as Identity Server 4, you don't need to specify the <kbd>IssuerSigningKey</kbd> option, since the authorization middleware is able to retrieve the required public key from the authorization server automatically. It is enough to provide the authentication server URL, as shown here:</p>
<pre>.AddJwtBearer(options =&gt; {<br/>        options.Authority = "https://www.MyAuthorizationserver.com";<br/>        options.TokenValidationParameters =...<br/>        ...</pre>
<p>On the other hand, if you decide to emit JWT in your Web API's site, you can define a <kbd>Login</kbd> action method that accepts an object with a username and password, and that, while relying on database information, builds the JWT token with code similar to the following:</p>
<pre>var claims = new List&lt;Claim&gt; <br/>{ <br/>   new Claim(...), <br/>   new Claim(...) ,<br/>   ...<br/>};<br/>       <br/>var token = new JwtSecurityToken( <br/>          issuer: "MyIssuer", <br/>          audience: ..., <br/>          claims: claims, <br/>          expires: DateTime.UtcNow.AddMinutes(expiryInMinutes), <br/>          signingCredentials: <br/>                new SymmetricSecurityKey(Encoding.ASCII.GetBytes("MySecret")); <br/>  <br/>       return OK(new JwtSecurityTokenHandler().WriteToken(token)); </pre>
<p>Here, <kbd>JwtSecurityTokenHandler().WriteToken(token)</kbd> generates the actual token string from the token properties contained in the <kbd>JwtSecurityToken</kbd> instance.</p>
<p>In the next subsection, we will learn how to empower our Web API with an OpenAPI documentation point so that proxy classes for communicating with our services can be generated automatically.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">ASP.NET Core support for OpenAPI</h1>
                
            
            
                
<p>Most of the information that's needed to fill in an OpenAPI JSON document can be extracted from Web API controllers through reflection, that is, input types and sources (path, request body, and header) and endpoint paths (these can be extracted from routing rules). Returned output types and status codes, in general, can't be easily computed since they can be generated dynamically. Therefore, the MVC framework provides the <kbd>ProducesResponseType</kbd> attribute so that we can declare a possible return type – a status code pair. It is enough to decorate each action method with as many <kbd>ProducesResponseType</kbd> attributes as there are possible types, that is, possible status code pairs, as shown in the following code:</p>
<pre>[HttpGet("{id}")] <br/>[ProducesResponseType(typeof(MyReturnType), StatusCodes.Status200OK)] <br/>[ProducesResponseType(typeof(MyErrorReturnType), StatusCodes.Status404NotFound)]<br/>public IActionResult GetById(int id)...<br/></pre>
<p>If no object is returned along a path, we can just declare the status code, as follows:</p>
<pre> [ProducesResponseType(StatusCodes.Status403Forbidden)]</pre>
<p>We can also specify just the status code when all the paths return the same type and when that type is specified in the action method return type as <kbd>ActionResult&lt;CommonReturnType&gt;]</kbd>.</p>
<p>Once all the action methods have been documented, in order to generate any actual documentation for the JSON endpoints, we must install the <kbd>Swashbuckle.AspNetCore</kbd> NuGet package and place some code in the <kbd>Startup.cs</kbd> file. More specifically, we must add some middleware in the <kbd>Configure</kbd> method, as shown here:</p>
<pre>app.UseSwagger(); //open api middleware<br/>app.UseAuthentication();<br/>app.UseMvc();</pre>
<p>Then, we must add some configuration options in the <kbd>ConfigureServices</kbd> method, as follows:</p>
<pre>services.AddSwaggerGen(c =&gt;<br/>{        <br/>    c.SwaggerDoc("MyServiceName", new Info<br/>    {<br/>        Version = "v1",<br/>        Title = "ToDo API",<br/>        Description = "My service description",<br/>        TermsOfService = "My terms of service",<br/>        Contact = new Contact<br/>        {<br/>            Name = "My Contact Name",<br/>            Email = string.Empty,<br/>            Url = "https://MyContatcUrl.com"<br/>        },<br/>        License = new License<br/>        {<br/>            Name = "My License name",<br/>            Url = "https://MyLicensecUrl.com"<br/>        }<br/>    });<br/>});</pre>
<p class="mce-root">The first argument of the <kbd>SwaggerDoc</kbd> method is the documentation endpoint name. By default, the documentation endpoint is accessible through the <kbd>&lt;webroot&gt;//swagger/&lt;endpoint name&gt;/swagger.json</kbd> path, but this can be changed in several ways. The rest of the information contained in the <kbd>Info</kbd> class is self-explanatory.</p>
<p>We can add several <kbd>SwaggerDoc</kbd> calls to define several documentation endpoints. However, by default, all the documentation endpoints will contain the same documentation, which includes a description of all the REST services included in the project. This default can be changed by calling the <kbd>c.DocInclusionPredicate(Func&lt;string, ApiDescription&gt; predicate)</kbd> method from within <kbd>services.AddSwaggerGen(c =&gt; {...})</kbd>. </p>
<p><kbd>DocInclusionPredicate</kbd> must be passed a function that receives a JSON document name and an action method description and must return <kbd>true</kbd> if the documentation of the action must be included in that JSON document. </p>
<p>To declare that your REST APIs need a JWT token, you must add the following code within <kbd>services.AddSwaggerGen(c =&gt; {...})</kbd>: </p>
<pre>var security = new Dictionary&lt;string, IEnumerable&lt;string&gt;&gt;<br/>{<br/>    {"Bearer", new string[] { }},<br/>};<br/><br/>c.AddSecurityDefinition("Bearer", new ApiKeyScheme<br/>{<br/>    Description = "JWT Authorization header using the Bearer scheme. <br/>    Example: \"Authorization: Bearer {token}\"",<br/>    Name = "Authorization",<br/>    In = "header",<br/>    Type = "apiKey"<br/>});<br/>c.AddSecurityRequirement(security);</pre>
<p>You can enrich the JSON documentation endpoint with information that's been extracted from triple-slash comments, which are usually added to generate automatic code documentation. The following code shows some examples of this. The following snippet shows how we can add a method description and parameter information:</p>
<pre>//adds a description to the REST method<br/><br/>/// &lt;summary&gt;<br/>/// Deletes a specific TodoItem.<br/>/// &lt;/summary&gt;<br/>/// &lt;param name="id"&gt;&lt;/param&gt; <br/>[HttpDelete("{id}")]<br/>public IActionResult Delete(long id)</pre>
<p>The following snippet shows how we can add an example of usage:</p>
<pre>//adds an example of usage<br/><br/>/// &lt;summary&gt;<br/>/// Creates an item.<br/>/// &lt;/summary&gt;<br/>/// &lt;remarks&gt;<br/>/// Sample request:<br/>///<br/>/// POST /MyItem<br/>/// {<br/>/// "id": 1,<br/>/// "name": "Item1"<br/>/// }<br/>///<br/>/// &lt;/remarks&gt;</pre>
<p>The following snippet shows how we can add parameter descriptions and return type descriptions for each HTTP status code:</p>
<pre>//Add input parameters and return object descriptions<br/><br/>/// &lt;param name="item"&gt;item to be created&lt;/param&gt;<br/>/// &lt;returns&gt;A newly created TodoItem&lt;/returns&gt;<br/>/// &lt;response code="201"&gt;Returns the newly created item&lt;/response&gt;<br/>/// &lt;response code="400"&gt;If the item is null&lt;/response&gt; </pre>
<p>To enable extraction from triple-slash comments, we must enable code documentation creation by adding the following code in our project file (<kbd>.csproj</kbd>):</p>
<pre>&lt;PropertyGroup&gt;<br/>  &lt;GenerateDocumentationFile&gt;true&lt;/GenerateDocumentationFile&gt;<br/>  &lt;NoWarn&gt;$(NoWarn);1591&lt;/NoWarn&gt;<br/>&lt;/PropertyGroup&gt;</pre>
<p>Then, we must enable code documentation processing from within <kbd>services.AddSwaggerGen(c =&gt; {...})</kbd> by adding the following code:</p>
<pre>var xmlFile = $"{Assembly.GetExecutingAssembly().GetName().Name}.xml";<br/>var xmlPath = Path.Combine(AppContext.BaseDirectory, xmlFile);<br/>c.IncludeXmlComments(xmlPath);</pre>
<p>Once our documentation endpoints are ready, we can add some more middleware that's contained in the same <kbd>Swashbuckle.AspNetCore</kbd> NuGet package to generate a friendly user interface that we can test our REST API on:</p>
<pre>app.UseSwaggerUI(c =&gt;<br/>{<br/>    c.SwaggerEndpoint("/swagger/&lt;documentation name&gt;/swagger.json", "<br/>    &lt;api name that appears in dropdown&gt;");<br/>});</pre>
<p>If you have several documentation endpoints, you need to add a <kbd>SwaggerEndpoint</kbd> call for each of them. We will use this interface to test the REST API defined in this chapter's use case. </p>
<p>Once you have a working JSON documentation endpoint, you can automatically generate the C# or TypeScript code of a proxy class with one of the following methods:</p>
<ul>
<li>The NSwagStudio Windows program, which is available at <a href="https://github.com/RicoSuter/NSwag/wiki/NSwagStudio">https://github.com/RicoSuter/NSwag/wiki/NSwagStudio</a>.</li>
<li>The <kbd>NSwag.CodeGeneration.CSharp</kbd> or <kbd>NSwag.CodeGeneration.TypeScript</kbd> NuGet packages if you want to customize code generation.</li>
<li>The <kbd>NSwag.MSBuild</kbd> NuGet package if you want to tie code generation to Visual Studio build operations. The documentation for this can be found at <a href="https://github.com/RicoSuter/NSwag/wiki/MSBuild">https://github.com/RicoSuter/NSwag/wiki/MSBuild</a>.</li>
</ul>
<p>In the next subsection, you will learn how to invoke a REST API from another REST API or from a .NET Core client.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">.Net Core HTTP clients</h1>
                
            
            
                
<p>The <kbd>HttpClient</kbd> class in the <kbd>System.Net.Http</kbd> namespace is a .NET standard 2.0 built-in HTTP client class. While it could be used directly whenever we need to interact with a REST service, there are some problems in creating and releasing <kbd>HttpClient</kbd> instances repeatedly, as follows:</p>
<ul>
<li>Their creation is expensive.</li>
<li>When an <kbd>HttpClient</kbd> is released, for instance, in a <kbd>using</kbd> statement, the underlying connection isn't closed immediately but at the first garbage collection session, which is a repeated creation. Release operations quickly exhaust the maximum number of connections the operating system can handle.</li>
</ul>
<p>Therefore, either a single <kbd>HttpClient</kbd> instance is reused, such as a singleton, or <kbd>HttpClient</kbd> instances are somehow pooled. Starting from the 2.1 version of .NET Core, an <kbd>HttpClientFactory</kbd> class was introduced to pool HTTP clients. More specifically, whenever a new <kbd>HttpClient</kbd> instance is required for an <kbd>HttpClientFactory</kbd> object, a new <kbd>HttpClient</kbd> is created. However, the underlying <kbd>HttpClientMessageHandler</kbd> instances, which are expansive to create, are pooled until their maximum lifetime expires. </p>
<p><kbd>HttpClientMessageHandler</kbd> instances must have a finite duration since they cache DNS resolution information that may change over time. The default lifetime of <kbd>HttpClientMessageHandler</kbd> is 2 minutes, but it can be redefined by the developer.</p>
<p>Using <kbd>HttpClientFactory</kbd> allows us to automatically pipeline all the HTTP operations with other operations. For instance, we can add a Polly retry strategy to handle all the failures of all our HTTP operations automatically. For an introduction to Polly, please refer to the <em>Resilient task execution</em> subsection of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>.</p>
<p>The simplest way to exploit the advantages offered by the <kbd>HttpClientFactory</kbd> class is to add the <kbd>Microsoft.Extensions.Http</kbd> NuGet package and then to follow these steps:</p>
<ol>
<li>Define a proxy class, say, <kbd>MyProxy</kbd>, to interact with the desired REST service.</li>
<li>Let <kbd>MyProxy</kbd> accept an <kbd>HttpClient</kbd> instance in its constructor.</li>
<li>Use the <kbd>HttpClient</kbd> that was injected into the constructor to implement all the necessary operations.</li>
</ol>
<ol start="4">
<li>Declare your proxy in the services configuration method of your Host which, in the case of an ASP.NET Core application, is the <kbd>ConfigureServices</kbd> method of the <kbd>Startup.cs</kbd> class, while, in the case of a client application, this is the <kbd>ConfigureServices</kbd> method of the <kbd>HostBuilder</kbd> instance. In the simplest case, the declaration is something similar to <kbd>services.AddHttpClient&lt;MyProxy&gt;()</kbd>. This will automatically add <kbd>MyProxy</kbd> to the services that are available for dependency injection, so you can easily inject it, for instance, in your controller's constructors. Moreover, each time an instance of <kbd>MyProxy</kbd> is created, an <kbd>HttpClient</kbd> is returned by an <kbd>HttpClientFactory</kbd> and is automatically injected into its constructor.</li>
</ol>
<p>In the constructors of the classes that need to interact with a REST service, we may also need an interface instead of a specific proxy implementation with a declaration of the type:</p>
<pre>services.AddHttpClient&lt;IMyProxy, MyProxy&gt;()</pre>
<p>A Polly resilient strategy (see the <em>Resilient task execution</em> subsection of <a href="49aed8bb-9a4a-4241-9efc-f53c3f53dd5a.xhtml">Chapter 5</a>, <em>Applying a Microservice Architecture to Your Enterprise Application</em>) can be applied to all the HTTP calls issued by our proxy class, as shown here:</p>
<pre>var myRetryPolicy = Policy.Handle&lt;HttpRequestException&gt;()<br/>    ...//policy definition<br/>    ...;<br/>services.AddHttpClient&lt;IMyProxy, MyProxy&gt;()<br/>    .AddPolicyHandler(myRetryPolicy );</pre>
<p>Finally, we can preconfigure some of the properties of all the <kbd>HttpClient</kbd> instances that are passed to our proxy, as shown here:</p>
<pre>services.AddHttpClient&lt;IMyProxy, MyProxy&gt;(clientFactory =&gt;<br/>{<br/>  clientFactory.DefaultRequestHeaders.Add("Accept", "application/json");<br/>  clientFactory.BaseAddress = new Uri("https://www.myService.com/");<br/>})<br/> .AddPolicyHandler(myRetryPolicy );</pre>
<p>This way, each client that's passed to the proxy is preconfigured so that they require a JSON response and have to work with a specific service. Once the base address has been defined, each HTTP request needs to specify the relative path of the service method to call.</p>
<p class="mce-root"/>
<p>The following code shows how to perform a <kbd>POST</kbd> to a service. Here, we're stating that the <kbd>HttpClient</kbd> that was injected into the proxy constructor has been stored in the <kbd>webClient</kbd> private field:</p>
<pre>//Add a bearer token to authenticate the call<br/>webClient.DefaultRequestHeaders.Add("Authorization", "Bearer " + token);<br/>...<br/>//Call service method with a POST verb and get response<br/>var response = await webClient.PostAsJsonAsync&lt;MyPostModel&gt;("my/method/relative/path",<br/>    new MyPostModel<br/>    {<br/>        //fill model here<br/>        ...<br/>    });<br/>//extract response status code<br/>var status = response.StatusCode;<br/>...<br/>//extract body content from response<br/>string stringResult = await response.Content.ReadAsStringAsync();</pre>
<p>If you use Polly, you don't need to intercept and handle communication errors since this job is performed by Polly. First, you need to verify the status code to decide what to do next. Then, you can parse the JSON string contained in the response body to get a .NET instance of a type, that, in general, depends on the status code. The code to perform the parsing is based on the <kbd>Newtonsoft.Json</kbd> NuGet package's <kbd>JsonConvert</kbd> class and is as follows:</p>
<pre>var result=JsonConvert.DeserializeObject&lt;MyResultClass&gt;(stringResult);</pre>
<p>Performing a GET request is similar but, instead of calling <kbd>PostAsJsonAsync</kbd>, you need to call <kbd>GetAsync</kbd>, as shown here:</p>
<pre>var response = await webClient.GetAsync("my/getmethod/relative/path");</pre>
<p>The use of other HTTP verbs is completely analogous.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Use case – exposing WWTravelClub packages</h1>
                
            
            
                
<p>In this section, we will implement an ASP.NET REST service that lists all the packages that are available for a given vacation's start and end dates. For didactic purposes, we won't structure the application according to the best practices described in <a href="2a42483c-2193-4bd4-91b4-0fdce94f6ed1.xhtml">Chapter 10</a>, <em>Understanding the Different Domains in Software Solutions</em>; instead, we will simply generate the results with a LINQ query that will be directly placed in the controller action method. A well-structured ASP.NET Core application will be presented in <a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml">Chapter 13</a>, <em>Presenting ASP.NET Core MVC</em>, which is dedicated to the MVC framework.</p>
<p>Let's make a copy of the <kbd>WWTravelClubDB</kbd> solution folder and rename the new folder <kbd>WWTravelClubREST</kbd>. The WWTravelClubDB project was built step by step in the various sections of <a href="8c8a9dbc-3bfc-4291-866f-fdd1a62c16ef.xhtml">Chapter 6</a>, <em>Interacting with Data in C# - Entity Framework Core</em>. Let's open the new solution and add a new ASP.NET Core API project to it named WWTravelClubREST (the same name as the new solution folder). For simplicity, select no authentication. Right-click on the newly created project and select Set as StartUp project to make it the default project that's launched when the solution is run.</p>
<p>Finally, we need to add a reference to the WWTravelClubDB project.</p>
<p>ASP.NET Core projects store configuration constants in the <kbd>appsettings.json</kbd> file. Let's open this file and add the database connection string for the database we created in the WWTravelClubDB project to it, as shown here:</p>
<pre>{<br/>    "ConnectionStrings": {<br/>        "DefaultConnection": "Server=<br/>        (localdb)\\mssqllocaldb;Database=wwtravelclub;<br/>        Trusted_Connection=True;MultipleActiveResultSets=true"<br/>    },<br/>    ...<br/>    ...<br/>}</pre>
<p>Now, we must add the WWTravelClubDB entity framework database context to the <kbd>ConfigureServices</kbd> method in <kbd>Startup.cs</kbd>, as shown here:</p>
<pre>services.AddDbContext&lt;WWTravelClubDB.MainDBContext&gt;(options =&gt;<br/>     options.UseSqlServer(<br/>            Configuration.GetConnectionString("DefaultConnection"),<br/>            b =&gt; b.MigrationsAssembly("WWTravelClubDB")));</pre>
<p>The option object settings that are passed to <kbd>AddDbContext</kbd> specify the usage of SQL server with a connection string that is extracted from the <kbd>ConnectionStrings</kbd> section of the <kbd>appsettings.json</kbd> configuration file with the <kbd>Configuration.GetConnectionString("DefaultConnection")</kbd> method. The <kbd>b =&gt; b.MigrationsAssembly("WWTravelClubDB")</kbd> lambda function declares the name of the assembly that contains the database migrations (see <a href="8c8a9dbc-3bfc-4291-866f-fdd1a62c16ef.xhtml">Chapter 6</a>, <em>Interacting with Data in C# - Entity Framework Core</em>) which, in our case, is the DLL that was generated by the WWTravelClubDB project. For the preceding code to compile, you should add <kbd>using Microsoft.EntityFrameworkCore;</kbd>.</p>
<p>Since we want to enrich our REST service with OpenAPI documentation, let's add a reference to the <kbd>Swashbuckle.AspNetCore</kbd> NuGet package. For .NET 3.0, you must select at least version 5.0 RC-4, so, if you don't see the 5.0 version among the search results, please enable the Include prerelease checkbox. Now, we can add the following very basic configuration to the <kbd>ConfigureServices</kbd> method:</p>
<pre>services.AddSwaggerGen(c =&gt;<br/>{<br/>    c.SwaggerDoc("WWWTravelClub", new OpenAPIInfo<br/>    {<br/>        Version = "WWWTravelClub 1.0.0",<br/>        Title = "WWWTravelClub",<br/>        Description = "WWWTravelClub Api",<br/>        TermsOfService = null<br/>    });<br/>});</pre>
<p>Then, we can add the middleware for the OpenAPI endpoint and for adding a user interface for our API documentation, as shown here:</p>
<pre><strong>app.UseSwagger();</strong><br/><strong>app.UseSwaggerUI(c =&gt;</strong><br/><strong>{</strong><br/><strong>    c.SwaggerEndpoint(</strong><br/><strong>        "/swagger/WWWTravelClub/swagger.json", </strong><br/><strong>        "WWWTravelClub Api");</strong><br/><strong>});</strong><br/><br/>app.UseEndpoints(endpoints =&gt; //preexisting code//<br/>{<br/>     endpoints.MapControllers();<br/>});</pre>
<p>Now, we are ready to encode our service. Let's delete <kbd>ValueController</kbd>, which is automatically scaffolded by Visual Studio. Then, right-click on the <kbd>Controller</kbd> folder and select Add | Controller. Now, choose an empty API controller called <kbd>PackagesController</kbd>. First, let's modify the code, as follows:</p>
<pre>[Route("api/packages")]<br/>[ApiController]<br/>public class PackagesController : ControllerBase<br/>{<br/>    [HttpGet("bydate/{start}/{stop}")]<br/>    [ProducesResponseType(typeof(IEnumerable&lt;PackagesListDTO&gt;), 200)]<br/>    [ProducesResponseType(400)]<br/>    [ProducesResponseType(500)]<br/>    public async Task&lt;IActionResult&gt; GetPackagesByDate(<br/>        [FromServices] WWTravelClubDB.MainDBContext ctx, <br/>        DateTime start, DateTime stop)<br/>    {<br/>        <br/>    }<br/>}</pre>
<p>The <kbd>Route</kbd> attribute declares that the basic path for our service will be <kbd>api/packages</kbd>. The unique action method that we implement is <kbd>GetPackagesByDate</kbd>, which is invoked on <kbd>HttpGet</kbd> requests on paths of the <kbd>bydate/{start}/{stop}</kbd> type, where <kbd>start</kbd> and <kbd>stop</kbd> are the <kbd>DateTime</kbd> parameters that are passed as input to <kbd>GetPackagesByDate</kbd>. The <kbd>ProduceResponseType</kbd> attributes declare the following:</p>
<ul>
<li>When a request is successful, a 200 code is returned, and the body contains an IEnumerable of the <kbd>PackagesListDTO</kbd> (which we will soon define) type containing the required package information.</li>
<li>When the request is ill-formed, a 400 code is returned. We don't specify the type returned since Bad Requests are automatically handled by the MVC framework through the <kbd>ApiController</kbd> attribute.</li>
<li>In the case of unexpected errors, a 500 code is returned with an empty body.</li>
</ul>
<p>Now, let's define the <kbd>PackagesListDTO</kbd> class in a new DTOs folder:</p>
<pre>namespace WWTravelClubREST.DTOs<br/>{<br/>    public class PackagesListDTO<br/>    {<br/>        public int Id { get; set; }<br/>        public string Name { get; set; }<br/>        public decimal Price { get; set; }<br/>        public int DuratioInDays { get; set; }<br/>        public DateTime? StartValidityDate { get; set; }<br/>        public DateTime? EndValidityDate { get; set; }<br/>        public string DestinationName { get; set; }<br/>        public int DestinationId { get; set; }<br/>    }<br/>}</pre>
<p>Finally, let's add the following <kbd>using</kbd> clauses to our controller code so that we can easily refer to our DTO and to Entity Framework LINQ methods:</p>
<pre>using Microsoft.EntityFrameworkCore;<br/>using WWTravelClubREST.DTOs;</pre>
<p>Now, we are ready to fill the body of the <kbd>GetPackagesByDate</kbd> method with the following code:</p>
<pre>try<br/>{<br/>    var res = await ctx.Packages<br/>        .Where(m =&gt; start &gt;= m.StartValidityDate<br/>        &amp;&amp; stop &lt;= m.EndValidityDate)<br/>        .Select(m =&gt; new PackagesListDTO<br/>        {<br/>            StartValidityDate = m.StartValidityDate,<br/>            EndValidityDate = m.EndValidityDate,<br/>            Name = m.Name,<br/>            DuratioInDays = m.DuratioInDays,<br/>            Id = m.Id,<br/>            Price = m.Price,<br/>            DestinationName = m.MyDestination.Name,<br/>            DestinationId = m.DestinationId<br/>        })<br/>        .ToListAsync();<br/>    return Ok(res);<br/>}<br/>catch<br/>{<br/>    return StatusCode(500);<br/>}</pre>
<p>The LINQ query is similar to the one contained in the WWTravelClubDBTest project we tested in <a href="8c8a9dbc-3bfc-4291-866f-fdd1a62c16ef.xhtml">Chapter 6</a>, <em>Interacting with Data in C# - Entity Framework Core</em>. Once the result has been computed, it is returned with an <kbd>OK</kbd> call. The method's code handles internal server errors by catching exceptions and returning a 500 status code, since Bad Requests are automatically handled before the controller method is called by the <kbd>ApiController</kbd> attribute.</p>
<p>Let's run the solution. When the browser opens, it's unable to receive any result from our ASP.NET Core website. Let's modify the browser URL so that it's <kbd>https://localhost:&lt;previous port&gt;/swagger</kbd>. The user interface of the OpenAPI documentation will look as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7a2703ef-d1ab-4eb3-8002-3c042dc7336b.png"/></p>
<p><kbd>PackagesListDTO</kbd> is the model we defined to list the packages, while <kbd>ProblemDetails</kbd> is the model that's used to report errors in the case of Bad Requests. By clicking the GET button, we can get more details about our <kbd>GET</kbd> method and we can also test it, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a817823c-098a-4363-aeb0-4f37553a3e6d.png" style="width:44.42em;height:26.75em;"/></p>
<p>Pay attention when it comes to inserting dates that are covered by packages in the database; otherwise, an empty list will be returned. The ones shown in the preceding screenshot should work.</p>
<p>Dates must be entered in a correct JSON format; otherwise, a 400 Bad Request error is returned, like the one shown in the following code:</p>
<pre class=" microlight">{
  "errors": {
    "start": [
      "The value '2019' is not valid."
    ]
  },
  "title": "One or more validation errors occurred.",
  "status": 400,
  "traceId": "80000008-0000-f900-b63f-84710c7967bb"
}</pre>
<p>If you insert the correct input parameters, the Swagger UI returns the packages that satisfy the query in JSON format.</p>
<p>That's all! You have implemented your first API with OpenAPI documentation!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we introduced SOA, its design principles, and its constraints. Among them, it is worth remembering interoperability.</p>
<p>Then, we focused on well-established standards for business applications that achieve the interoperability that's needed for publicly exposed services. Therefore, SOAP and REST services were discussed in detail, along with the transition from SOAP services to REST services, which has taken place in most application areas in the last few years. Then, REST services principles, authentication/authorization, and its documentation were described in greater detail.</p>
<p>Finally, we looked at the tools that are available in .NET Core that we can use to implement and interact with services. We looked at a variety of frameworks for intra-cluster communication, such as .NET remoting and gRPC, and tools for SOAP and REST-based public services.</p>
<p>Here, we mainly focused on REST services. Their ASP.NET Core implementations were described in detail, along with the techniques we can use in order to authenticate/authorize them and their documentation. We also focused on how to implement efficient .NET Core proxies so that we can interact with REST services.</p>
<p>In the next chapter, we will learn how to use .NET Core 3.0 while building an application on ASP .NET Core MVC.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>Can services use cookie-based sessions?</li>
<li>Is it good practice to implement a service with a custom communication protocol? Why or why not?</li>
<li>Can a <kbd>POST</kbd> request to a REST service cause a delete?</li>
<li>How many dot-separated parts are contained in a JWT bearer token?</li>
<li>By default, where are the complex type parameters of a REST service's action methods taken from?</li>
</ol>
<ol start="6">
<li>How is a controller declared as a REST service? </li>
<li>What are the main documentation attributes of ASP.NET Core services?</li>
<li>How are ASP.NET Core REST service routing rules declared?</li>
<li>How should a proxy be declared so that we can take advantage of .NET Core's <kbd>HttpClientFactory</kbd> class features?</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>This chapter mainly focused on the more commonly used REST service. If you are interested in SOAP services, a good place to start is the Wikipedia page regarding SOAP specifications: <a href="https://en.wikipedia.org/wiki/List_of_web_service_specifications">https://en.wikipedia.org/wiki/List_of_web_service_specifications</a>. On the other hand, if you are interested in the Microsoft .NET WCF technology for implementing SOAP services, you can refer to WCF's official documentation here: <a href="https://docs.microsoft.com/en-us/dotnet/framework/wcf/">https://docs.microsoft.com/en-us/dotnet/framework/wcf/</a>.</p>
<p>This chapter mentioned the AMQP protocol as an option for intra-cluster communication without describing it. Detailed information on this protocol is available on AMQP's official site: <a href="https://www.amqp.org/">https://www.amqp.org/</a>.</p>
<p>More information on gRPC is available on Google gRPC's official site: <a href="https://grpc.io/">https://grpc.io/</a>. More information on the Visual Studio gRPC project template can be found here: <a href="https://docs.microsoft.com/en-US/aspnet/core/grpc/?view=aspnetcore-3.0.">https://docs.microsoft.com/en-US/aspnet/core/grpc/?view=aspnetcore-3.0</a>.</p>
<p>More details on ASP.NET Core services are available in the official documentation: <a href="https://docs.microsoft.com/en-US/aspnet/core/web-api/?view=aspnetcore-3.0">https://docs.microsoft.com/en-US/aspnet/core/web-api/?view=aspnetcore-3.0</a>. More information on .NET Core's HTTP client is available here: <a href="https://docs.microsoft.com/en-US/aspnet/core/fundamentals/http-requests?view=aspnetcore-3.0">https://docs.microsoft.com/en-US/aspnet/core/fundamentals/http-requests?view=aspnetcore-3.0</a>.</p>
<p>More information on JWT token authentication is available here: <a href="https://jwt.io/">https://jwt.io/</a>. If you would like to generate JWT tokens with Identity Serve 4, you may refer to its official documentation page: <a href="http://docs.identityserver.io/en/latest/">http://docs.identityserver.io/en/latest/</a>.</p>
<p>More information on OpenAPI is available at <a href="https://swagger.io/docs/specification/about/">https://swagger.io/docs/specification/about/</a>, while more information on Swashbuckle can be found on its GitHub repository page: <a href="https://github.com/domaindrivendev/Swashbuckle">https://github.com/domaindrivendev/Swashbuckle</a>.</p>


            

            
        
    </body></html>