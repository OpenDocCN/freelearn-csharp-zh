<html><head></head><body>
<div id="_idContainer040">
<h1 class="chapter-number" id="_idParaDest-39"><a id="_idTextAnchor038"/><span class="koboSpan" id="kobo.1.1">2</span></h1>
<h1 id="_idParaDest-40"><a id="_idTextAnchor039"/><span class="koboSpan" id="kobo.2.1">Native Monitoring in .NET</span></h1>
<p><span class="koboSpan" id="kobo.3.1">In this chapter, we’ll explore the out-of-the-box diagnostic capabilities of modern .NET applications, starting with logs and ad hoc diagnostics, and then move on to examine what OpenTelemetry provides on top of that. </span><span class="koboSpan" id="kobo.3.2">We’ll create a sample application and instrument it, showcasing cross-process log correlation, and learn how we can capture verbose logs with </span><strong class="source-inline"><span class="koboSpan" id="kobo.4.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.5.1">. </span><span class="koboSpan" id="kobo.5.2">Then, we’ll investigate .NET runtime counters and export them to Prometheus. </span><span class="koboSpan" id="kobo.5.3">Finally, we’ll configure OpenTelemetry to collect traces and metrics from .NET, ASP.NET Core, and Entity Framework, and check out how basic auto-instrumentations address </span><span class="No-Break"><span class="koboSpan" id="kobo.6.1">observability needs.</span></span></p>
<p><span class="koboSpan" id="kobo.7.1">The following topics are what </span><span class="No-Break"><span class="koboSpan" id="kobo.8.1">we’ll cover:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.9.1">Native log correlation in ASP.NET </span><span class="No-Break"><span class="koboSpan" id="kobo.10.1">Core applications</span></span></li>
<li><span class="koboSpan" id="kobo.11.1">Minimalistic monitoring with .NET </span><span class="No-Break"><span class="koboSpan" id="kobo.12.1">runtime counters</span></span></li>
<li><span class="koboSpan" id="kobo.13.1">Install OpenTelemetry and enable </span><span class="No-Break"><span class="koboSpan" id="kobo.14.1">common instrumentations</span></span></li>
<li><span class="koboSpan" id="kobo.15.1">Tracing and performance analysis with HTTP and </span><span class="No-Break"><span class="koboSpan" id="kobo.16.1">database instrumentations</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.17.1">By the end of this chapter, you’ll be ready to use distributed tracing instrumentation in .NET libraries and frameworks, enable log correlation and metrics, and leverage multiple signals together to debug and monitor </span><span class="No-Break"><span class="koboSpan" id="kobo.18.1">your applications.</span></span></p>
<h1 id="_idParaDest-41"><a id="_idTextAnchor040"/><span class="koboSpan" id="kobo.19.1">Technical requirements</span></h1>
<p><span class="koboSpan" id="kobo.20.1">We’re going to start building a sample application and will use the following tools </span><span class="No-Break"><span class="koboSpan" id="kobo.21.1">for it:</span></span></p>
<ul>
<li><span class="koboSpan" id="kobo.22.1">.NET SDK 7.0 </span><span class="No-Break"><span class="koboSpan" id="kobo.23.1">or newer</span></span></li>
<li><span class="koboSpan" id="kobo.24.1">Visual Studio or Visual Studio Code with the C# development setup are recommended, but any text editor </span><span class="No-Break"><span class="koboSpan" id="kobo.25.1">would work</span></span></li>
<li><span class="koboSpan" id="kobo.26.1">Docker </span><span class="No-Break"><span class="koboSpan" id="kobo.27.1">and </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.28.1">docker-compose</span></strong></span></li>
</ul>
<p><span class="koboSpan" id="kobo.29.1">The application code can be found in the book’s repository on GitHub </span><span class="No-Break"><span class="koboSpan" id="kobo.30.1">at </span></span><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter2"><span class="No-Break"><span class="koboSpan" id="kobo.31.1">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter2</span></span></a><span class="No-Break"><span class="koboSpan" id="kobo.32.1">.</span></span></p>
<h1 id="_idParaDest-42"><a id="_idTextAnchor041"/><span class="koboSpan" id="kobo.33.1">Building a sample application</span></h1>
<p><span class="koboSpan" id="kobo.34.1">As shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.35.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.36.1">.1</span></em><span class="koboSpan" id="kobo.37.1">, our application </span><a id="_idIndexMarker095"/><span class="koboSpan" id="kobo.38.1">consists of two REST services and a </span><span class="No-Break"><span class="koboSpan" id="kobo.39.1">MySQL database:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer026">
<span class="koboSpan" id="kobo.40.1"><img alt="Figure 2.1 – Meme service diagram" src="image/B19423_02_01.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.41.1">Figure 2.1 – Meme service diagram</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.42.1">Frontend</span></strong><span class="koboSpan" id="kobo.43.1">: ASP.NET Core Razor Pages</span><a id="_idIndexMarker096"/><span class="koboSpan" id="kobo.44.1"> application that serves user requests to upload and </span><span class="No-Break"><span class="koboSpan" id="kobo.45.1">download images</span></span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.46.1">Storage</span></strong><span class="koboSpan" id="kobo.47.1">: ASP.NET Core </span><a id="_idIndexMarker097"/><span class="koboSpan" id="kobo.48.1">WebAPI application that uses Entity Framework Core to store images in a MySQL database or in memory for </span><span class="No-Break"><span class="koboSpan" id="kobo.49.1">local development</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.50.1">We’ll see how to run the full application using Docker later in this chapter. </span><span class="koboSpan" id="kobo.50.2">For now, run it locally and explore the basic logging and monitoring features that come with </span><span class="No-Break"><span class="koboSpan" id="kobo.51.1">modern .NET.</span></span></p>
<p><span class="koboSpan" id="kobo.52.1">We’re going to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.53.1">Microsoft.Extensions.Logging.ILogger</span></strong><span class="koboSpan" id="kobo.54.1"> API throughout this book. </span><strong class="source-inline"><span class="koboSpan" id="kobo.55.1">ILogger</span></strong><span class="koboSpan" id="kobo.56.1"> provides convenient APIs to write structured logs, along with verbosity control and the ability to send </span><span class="No-Break"><span class="koboSpan" id="kobo.57.1">logs anywhere.</span></span></p>
<p><span class="koboSpan" id="kobo.58.1">ASP.NET Core and Entity Framework use </span><strong class="source-inline"><span class="koboSpan" id="kobo.59.1">ILogger</span></strong><span class="koboSpan" id="kobo.60.1">; all we need to do is configure the logging level for specific categories or events to log incoming requests or database calls, and supply additional context with logging scopes. </span><span class="koboSpan" id="kobo.60.2">We’re going to cover this in detail in </span><a href="B19423_08.xhtml#_idTextAnchor131"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.61.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.62.1">, </span><em class="italic"><span class="koboSpan" id="kobo.63.1">Writing Structured and Correlated Logs</span></em><span class="koboSpan" id="kobo.64.1">. </span><span class="koboSpan" id="kobo.64.2">For now, let’s see log correlation </span><span class="No-Break"><span class="koboSpan" id="kobo.65.1">in action.</span></span></p>
<h2 id="_idParaDest-43"><a id="_idTextAnchor042"/><span class="koboSpan" id="kobo.66.1">Log correlation</span></h2>
<p><span class="koboSpan" id="kobo.67.1">ASP.NET Core enables</span><a id="_idIndexMarker098"/><span class="koboSpan" id="kobo.68.1"> log correlation across multiple services by default. </span><span class="koboSpan" id="kobo.68.2">It creates an activity that loggers can access using </span><strong class="source-inline"><span class="koboSpan" id="kobo.69.1">Activity.Current</span></strong><span class="koboSpan" id="kobo.70.1"> and configures </span><strong class="source-inline"><span class="koboSpan" id="kobo.71.1">Microsoft.Extensions.Logging</span></strong><span class="koboSpan" id="kobo.72.1"> to populate the trace context on </span><a id="_idIndexMarker099"/><span class="koboSpan" id="kobo.73.1">logging scopes. </span><span class="koboSpan" id="kobo.73.2">ASP.NET Core and </span><strong class="source-inline"><span class="koboSpan" id="kobo.74.1">HttpClient</span></strong><span class="koboSpan" id="kobo.75.1"> also support W3C Trace Context by default, so the context is automatically propagated </span><span class="No-Break"><span class="koboSpan" id="kobo.76.1">over HTTP.</span></span></p>
<p><span class="koboSpan" id="kobo.77.1">Some logging providers, for example, OpenTelemetry, don’t need any configuration to correlate logs, but our meme application uses a console provider, which does not print any logging scopes </span><span class="No-Break"><span class="koboSpan" id="kobo.78.1">by default.</span></span></p>
<p><span class="koboSpan" id="kobo.79.1">So let’s configure our console provider to print scopes and we’ll see the trace context on every log record. </span><span class="koboSpan" id="kobo.79.2">Let’s also set the default level to </span><strong class="source-inline"><span class="koboSpan" id="kobo.80.1">Information</span></strong><span class="koboSpan" id="kobo.81.1"> for all categories just so we can see </span><span class="No-Break"><span class="koboSpan" id="kobo.82.1">the output:</span></span></p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.83.1">appsettings.json</span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.84.1">
"Logging": {
  "LogLevel" : {"Default": "Information"},
  "Console" : {</span><strong class="bold"><span class="koboSpan" id="kobo.85.1">"IncludeScopes" : true</span></strong><span class="koboSpan" id="kobo.86.1">}
}</span></pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/appsettings.json"><span class="koboSpan" id="kobo.87.1">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/appsettings.json</span></a></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.88.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.89.1">Usually, you would use </span><strong class="source-inline"><span class="koboSpan" id="kobo.90.1">Information</span></strong><span class="koboSpan" id="kobo.91.1"> for application code only and set </span><strong class="source-inline"><span class="koboSpan" id="kobo.92.1">Warning</span></strong><span class="koboSpan" id="kobo.93.1"> or </span><strong class="source-inline"><span class="koboSpan" id="kobo.94.1">Error</span></strong><span class="koboSpan" id="kobo.95.1"> for frameworks and </span><span class="No-Break"><span class="koboSpan" id="kobo.96.1">third-party libraries.</span></span></p>
<p><span class="koboSpan" id="kobo.97.1">Let’s check it out – start the storage first, then, in a different terminal, start </span><span class="No-Break"><span class="koboSpan" id="kobo.98.1">the frontend:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.99.1">
storage$ dotnet run
frontend$ dotnet run</span></pre>
<p><span class="koboSpan" id="kobo.100.1">Make sure to keep both terminals open so we can check logs later. </span><span class="koboSpan" id="kobo.100.2">Now, let’s get the preloaded meme from the frontend in your browser – hit http://localhost:5051/Meme?name=dotnet and then check </span><span class="No-Break"><span class="koboSpan" id="kobo.101.1">the logs.</span></span></p>
<p><span class="koboSpan" id="kobo.102.1">On the frontend, you </span><a id="_idIndexMarker100"/><span class="koboSpan" id="kobo.103.1">may see something like this (other logs and scopes are omitted </span><a id="_idIndexMarker101"/><span class="No-Break"><span class="koboSpan" id="kobo.104.1">for brevity):</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.105.1">
info: System.Net.Http.HttpClient.storage.LogicalHandler[101]
      =&gt; </span><strong class="bold"><span class="koboSpan" id="kobo.106.1">SpanId:4a8f253515db7fec, TraceId:e61779</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.107.1">      </span></strong><strong class="bold"><span class="koboSpan" id="kobo.108.1">516785b4549905032283d93e09, ParentId:00000000000000</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.109.1">      00</span></strong><span class="koboSpan" id="kobo.110.1"> =&gt; HTTP GET http://localhost:5050/memes/dotnet
      End processing HTTP request after 182.2564ms - 200
info: Microsoft.AspNetCore.Hosting.Diagnostics[2]
      =&gt; </span><strong class="bold"><span class="koboSpan" id="kobo.111.1">SpanId:4a8f253515db7fec, TraceId:e6177951678</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.112.1">      5b4549905032283d93e09, ParentId:0000000000000000</span></strong><span class="koboSpan" id="kobo.113.1"> =&gt;
      Request finished HTTP/1.1 GET http://localhost:
        5051/Meme?name=dotnet - 200 256.6804ms</span></pre>
<p><span class="koboSpan" id="kobo.114.1">The first record describes the outgoing call to the storage service. </span><span class="koboSpan" id="kobo.114.2">You can see the status, duration, HTTP method, and URL, as well as the trace context. </span><span class="koboSpan" id="kobo.114.3">The second record describes an incoming HTTP call and has </span><span class="No-Break"><span class="koboSpan" id="kobo.115.1">similar information.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.116.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.117.1">This trace context is the same on both log records and belongs to the incoming </span><span class="No-Break"><span class="koboSpan" id="kobo.118.1">HTTP request.</span></span></p>
<p><span class="koboSpan" id="kobo.119.1">Let’s see what happened on </span><span class="No-Break"><span class="koboSpan" id="kobo.120.1">the storage:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.121.1">
info: Microsoft.AspNetCore.Hosting.Diagnostics[2]
      =&gt; </span><strong class="bold"><span class="koboSpan" id="kobo.122.1">SpanId:5a496fb9adf85727, TraceId:e61779516785b</span></strong>
<strong class="bold"><span class="koboSpan" id="kobo.123.1">      4549905032283d93e09, ParentId:67b3966e163641c4</span></strong><span class="koboSpan" id="kobo.124.1">
      Request finished HTTP/1.1 GET http://localhost:
        5050/memes/dotnet - 200 1516 102.8234ms</span></pre>
<p class="callout-heading"><span class="koboSpan" id="kobo.125.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.126.1">The </span><strong class="source-inline"><span class="koboSpan" id="kobo.127.1">TraceId</span></strong><span class="koboSpan" id="kobo.128.1"> value is the same on the frontend and storage, so we have cross-process log correlation out of </span><span class="No-Break"><span class="koboSpan" id="kobo.129.1">the box.</span></span></p>
<p><span class="koboSpan" id="kobo.130.1">If we had OpenTelemetry </span><a id="_idIndexMarker102"/><span class="koboSpan" id="kobo.131.1">configured, we’d see a trace similar to that shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.132.1">Figure 2</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.133.1">.2</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.134.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer027">
<span class="koboSpan" id="kobo.135.1"><img alt="Figure 2.2 – Communication between the frontend and storage" src="image/B19423_02_02.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.136.1">Figure 2.2 – Communication between the frontend and storage</span></p>
<p><span class="koboSpan" id="kobo.137.1">We already know that ASP.NET Core creates an activity for each request – it reads trace context headers by default, but we can configure a different propagator. </span><span class="koboSpan" id="kobo.137.2">So, when we make an outgoing request from the frontend to storage, </span><strong class="source-inline"><span class="koboSpan" id="kobo.138.1">HttpClient</span></strong><span class="koboSpan" id="kobo.139.1"> creates another activity – a child of the ASP.NET Core one. </span><strong class="source-inline"><span class="koboSpan" id="kobo.140.1">HttpClient</span></strong><span class="koboSpan" id="kobo.141.1"> injects the trace context from its activity to the outgoing request headers so that they flow to the storage service, where ASP.NET Core parses them and creates a new activity, which becomes a child of the </span><span class="No-Break"><span class="koboSpan" id="kobo.142.1">outgoing request.</span></span></p>
<p><span class="koboSpan" id="kobo.143.1">Even though we didn’t export activities, they are created and are used to enrich the logs with trace context, enabling correlation across </span><span class="No-Break"><span class="koboSpan" id="kobo.144.1">different services.</span></span></p>
<p><span class="koboSpan" id="kobo.145.1">Without exporting activities, we achieve correlation but not causation. </span><span class="koboSpan" id="kobo.145.2">As you can see in the logs, </span><strong class="source-inline"><span class="koboSpan" id="kobo.146.1">ParentId</span></strong><span class="koboSpan" id="kobo.147.1"> on storage is not the same as </span><strong class="source-inline"><span class="koboSpan" id="kobo.148.1">SpanId</span></strong><span class="koboSpan" id="kobo.149.1"> on the outgoing </span><span class="No-Break"><span class="koboSpan" id="kobo.150.1">HTTP request.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.151.1">Hint on causation</span></p>
<p class="callout"><span class="koboSpan" id="kobo.152.1">What happens here is that the outgoing request activity is created inside </span><strong class="source-inline"><span class="koboSpan" id="kobo.153.1">HttpClient</span></strong><span class="koboSpan" id="kobo.154.1">, which does not write logs with </span><strong class="source-inline"><span class="koboSpan" id="kobo.155.1">ILogger</span></strong><span class="koboSpan" id="kobo.156.1">. </span><span class="koboSpan" id="kobo.156.2">The log record on the outgoing request we just saw is written by the handler in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.157.1">Microsoft.Extensions.Http</span></strong><span class="koboSpan" id="kobo.158.1"> package. </span><span class="koboSpan" id="kobo.158.2">This handler is configured by ASP.NET Core. </span><span class="koboSpan" id="kobo.158.3">When the handler logs that the request is starting, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.159.1">HttpClient</span></strong><span class="koboSpan" id="kobo.160.1"> activity has not yet been created, and when the handler logs that the request is ended, the </span><strong class="source-inline"><span class="koboSpan" id="kobo.161.1">HttpClient</span></strong><span class="koboSpan" id="kobo.162.1"> activity is </span><span class="No-Break"><span class="koboSpan" id="kobo.163.1">already stopped.</span></span></p>
<p><span class="koboSpan" id="kobo.164.1">So, with ASP.NET Core </span><a id="_idIndexMarker103"/><span class="koboSpan" id="kobo.165.1">and ILogger, we can easily enable log correlation. </span><span class="koboSpan" id="kobo.165.2">However, logs don’t </span><a id="_idIndexMarker104"/><span class="koboSpan" id="kobo.166.1">substitute distributed traces – they just provide additional details. </span><span class="koboSpan" id="kobo.166.2">Logs also don’t need to </span><span class="No-Break"><span class="koboSpan" id="kobo.167.1">duplicate traces.</span></span></p>
<p><em class="italic"><span class="koboSpan" id="kobo.168.1">Avoiding duplication is important: once, the author saved a company $80k a month by dropping logs that were duplicated by </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.169.1">rich events.</span></em></span></p>
<p><span class="koboSpan" id="kobo.170.1">Going forward in this book, we’ll use logs for debugging and capturing additional information that covers gaps </span><span class="No-Break"><span class="koboSpan" id="kobo.171.1">in traces.</span></span></p>
<h3><span class="koboSpan" id="kobo.172.1">Using logs in production</span></h3>
<p><span class="koboSpan" id="kobo.173.1">To record logs in production, where </span><a id="_idIndexMarker105"/><span class="koboSpan" id="kobo.174.1">we have multiple instances of services and restricted access to them, we usually need a log management system – a set of tools that collect and send logs to a central location, potentially enriching, filtering, or parsing them along the way. </span><span class="koboSpan" id="kobo.174.2">OpenTelemetry can help us collect logs, but we also need a backend to store, index, and query the logs using any context, including </span><strong class="source-inline"><span class="koboSpan" id="kobo.175.1">TraceId</span></strong><span class="koboSpan" id="kobo.176.1">. </span><span class="koboSpan" id="kobo.176.2">With this, we can easily navigate from traces to logs </span><span class="No-Break"><span class="koboSpan" id="kobo.177.1">when needed.</span></span></p>
<h2 id="_idParaDest-44"><a id="_idTextAnchor043"/><span class="koboSpan" id="kobo.178.1">On-demand logging with dotnet-monitor</span></h2>
<p><span class="koboSpan" id="kobo.179.1">It could be useful to dynamically increase log</span><a id="_idIndexMarker106"/><span class="koboSpan" id="kobo.180.1"> verbosity at runtime to get more detailed information while reproducing the issue or, when the log</span><a id="_idIndexMarker107"/><span class="koboSpan" id="kobo.181.1"> exporting pipeline is broken, get logs from the </span><span class="No-Break"><span class="koboSpan" id="kobo.182.1">service directly.</span></span></p>
<p><span class="koboSpan" id="kobo.183.1">It’s possible with </span><strong class="source-inline"><span class="koboSpan" id="kobo.184.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.185.1"> – a diagnostics tool that’s able to connect to a specific .NET process and capture logs, counters, profiles, and core dumps. </span><span class="koboSpan" id="kobo.185.2">We’ll talk about it in </span><a href="B19423_03.xhtml#_idTextAnchor052"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.186.1">Chapter 3</span></em></span></a><span class="koboSpan" id="kobo.187.1">, The </span><em class="italic"><span class="koboSpan" id="kobo.188.1">.NET </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.189.1">Observability Ecosystem</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.190.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.191.1">Let’s install and start </span><strong class="source-inline"><span class="koboSpan" id="kobo.192.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.193.1"> to see what it </span><span class="No-Break"><span class="koboSpan" id="kobo.194.1">can do:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.195.1">
$ dotnet tool install -g dotnet-monitor
$ dotnet monitor collect</span></pre>
<p class="callout-heading"><span class="koboSpan" id="kobo.196.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.197.1">If you’re on macOS or Linux, you need to authenticate requests to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.198.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.199.1"> REST API. </span><span class="koboSpan" id="kobo.199.2">Please refer to the documentation at </span><strong class="source-inline"><span class="koboSpan" id="kobo.200.1">https://github.com/dotnet/dotnet-monitor/blob/main/documentation/authentication.md</span></strong><span class="koboSpan" id="kobo.201.1"> or, for demo purposes only, disable authentication with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.202.1">dotnet monitor collect –</span></strong><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.203.1">no-auth</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.204.1"> command.</span></span></p>
<p><span class="koboSpan" id="kobo.205.1">If you still have frontend and storage</span><a id="_idIndexMarker108"/><span class="koboSpan" id="kobo.206.1"> services running, you should see them among the other .NET processes on your machine when you open </span><strong class="source-inline"><span class="koboSpan" id="kobo.207.1">https://localhost:52323/processes</span></strong><span class="koboSpan" id="kobo.208.1"> in </span><span class="No-Break"><span class="koboSpan" id="kobo.209.1">your browser:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.210.1">
{"pid": 27020, …, "name": "storage"},
{"pid": 29144, … "name": "frontend"}</span></pre>
<p><span class="koboSpan" id="kobo.211.1">Now let’s capture some </span><a id="_idIndexMarker109"/><span class="koboSpan" id="kobo.212.1">debug logs from storage via </span><strong class="source-inline"><span class="koboSpan" id="kobo.213.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.214.1"> by requesting </span><span class="No-Break"><span class="koboSpan" id="kobo.215.1">the following:</span></span></p>
<p><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.216.1">https://localhost:52323/logs?pid=27020&amp;level=debug&amp;duration=60</span></strong></span></p>
<p><span class="koboSpan" id="kobo.217.1">It connects to the process first, enables the requested log level, and then starts streaming logs to the browser for 60 seconds. </span><span class="koboSpan" id="kobo.217.2">It doesn’t change the logging level in the main logging pipeline, but will return the requested logs directly to you, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.218.1">Figure 2</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.219.1">.3</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.220.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer028">
<span class="koboSpan" id="kobo.221.1"><img alt="Figure 2.3 – A﻿d hoc logging with dynamic level using dotnet-monitor" src="image/B19423_02_03.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.222.1">Figure 2.3 – Ad hoc logging with dynamic level using dotnet-monitor</span></p>
<p><span class="koboSpan" id="kobo.223.1">You can apply a more advanced configuration </span><a id="_idIndexMarker110"/><span class="koboSpan" id="kobo.224.1">using the POST logs API – check out https://github.com/dotnet/dotnet-monitor to learn more about it and other </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.225.1">dotnet-monitor</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.226.1"> features.</span></span></p>
<p><span class="koboSpan" id="kobo.227.1">Using </span><strong class="source-inline"><span class="koboSpan" id="kobo.228.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.229.1"> in production </span><a id="_idIndexMarker111"/><span class="koboSpan" id="kobo.230.1">on a multi-instance service with restricted SSH access can be challenging. </span><span class="koboSpan" id="kobo.230.2">Let’s see how we can do it by running </span><strong class="source-inline"><span class="koboSpan" id="kobo.231.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.232.1"> as a sidecar in Docker. </span><span class="koboSpan" id="kobo.232.2">It’s also possible to run it as a sidecar </span><span class="No-Break"><span class="koboSpan" id="kobo.233.1">in Kubernetes.</span></span></p>
<h1 id="_idParaDest-45"><a id="_idTextAnchor044"/><span class="koboSpan" id="kobo.234.1">Monitoring with runtime counters</span></h1>
<p><span class="koboSpan" id="kobo.235.1">So, we have correlated logs from the</span><a id="_idIndexMarker112"/><span class="koboSpan" id="kobo.236.1"> platform and services with which we can debug issues. </span><span class="koboSpan" id="kobo.236.2">But what about system health and performance? </span><span class="koboSpan" id="kobo.236.3">.NET and ASP.NET Core expose event counters that can give some insights into the overall </span><span class="No-Break"><span class="koboSpan" id="kobo.237.1">system state.</span></span></p>
<p><span class="koboSpan" id="kobo.238.1">We can collect counters with OpenTelemetry without running and managing </span><strong class="source-inline"><span class="koboSpan" id="kobo.239.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.240.1">. </span><span class="koboSpan" id="kobo.240.2">But if your metrics pipeline is broken (or if you don’t have one yet), you can attach </span><strong class="source-inline"><span class="koboSpan" id="kobo.241.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.242.1"> to your process for ad </span><span class="No-Break"><span class="koboSpan" id="kobo.243.1">hoc analysis.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.244.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.245.1"> listens to </span><strong class="source-inline"><span class="koboSpan" id="kobo.246.1">EventCounters</span></strong><span class="koboSpan" id="kobo.247.1"> reported by the .NET runtime and returns them on </span><a id="_idIndexMarker113"/><span class="koboSpan" id="kobo.248.1">an HTTP endpoint in </span><strong class="bold"><span class="koboSpan" id="kobo.249.1">Prometheus </span></strong><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.250.1">exposition format</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.251.1">.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.252.1">Note</span></p>
<p class="callout"><strong class="bold"><span class="koboSpan" id="kobo.253.1">Prometheus</span></strong><span class="koboSpan" id="kobo.254.1"> is a metrics platform that scrapes and </span><a id="_idIndexMarker114"/><span class="koboSpan" id="kobo.255.1">stores metrics. </span><span class="koboSpan" id="kobo.255.2">It supports multidimensional data and allows us to slice, dice, filter, and calculate derived metrics</span><a id="_idIndexMarker115"/> <span class="No-Break"><span class="koboSpan" id="kobo.256.1">using </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.257.1">PromQL</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.258.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.259.1">We’re going to run our service as a set of Docker containers with </span><strong class="source-inline"><span class="koboSpan" id="kobo.260.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.261.1"> running as a sidecar for the frontend and storage, and configure Prometheus to scrape metrics from </span><strong class="source-inline"><span class="koboSpan" id="kobo.262.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.263.1"> sidecars, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.264.1">Figure 2</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.265.1">.4</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.266.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer029">
<span class="koboSpan" id="kobo.267.1"><img alt="Figure 2.4 – Meme services with runtime counters in Prometheus" src="image/B19423_02_04.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.268.1">Figure 2.4 – Meme services with runtime counters in Prometheus</span></p>
<p><span class="koboSpan" id="kobo.269.1">This makes our setup closer to real life, where we don’t have the luxury of running </span><strong class="source-inline"><span class="koboSpan" id="kobo.270.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.271.1"> on the </span><span class="No-Break"><span class="koboSpan" id="kobo.272.1">service instance.</span></span></p>
<p><span class="koboSpan" id="kobo.273.1">So, let’s go ahead and run our </span><a id="_idIndexMarker116"/><span class="koboSpan" id="kobo.274.1">application. </span><span class="koboSpan" id="kobo.274.2">Open the terminal, navigate to the </span><strong class="source-inline"><span class="koboSpan" id="kobo.275.1">chapter2</span></strong><span class="koboSpan" id="kobo.276.1"> folder, and run </span><span class="No-Break"><span class="koboSpan" id="kobo.277.1">the following:</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.278.1">
$ docker-compose -f ./docker-compose-dotnet-monitor.yml
  up --build</span></pre>
<p><span class="koboSpan" id="kobo.279.1">You might see some errors while MySQL is starting up. </span><span class="koboSpan" id="kobo.279.2">Let’s ignore them for now. </span><span class="koboSpan" id="kobo.279.3">After a few seconds, you should be able to reach the frontend via the same URL </span><span class="No-Break"><span class="koboSpan" id="kobo.280.1">as before.</span></span></p>
<p><span class="koboSpan" id="kobo.281.1">Let’s explore the CPU and memory counters published by the .</span><span class="No-Break"><span class="koboSpan" id="kobo.282.1">NET Runtime:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.283.1">cpu-usage</span></strong><span class="koboSpan" id="kobo.284.1"> event counter (reported as </span><strong class="source-inline"><span class="koboSpan" id="kobo.285.1">systemruntime_cpu_usage_ratio</span></strong><span class="koboSpan" id="kobo.286.1"> metric to Prometheus): Represents the CPU usage as </span><span class="No-Break"><span class="koboSpan" id="kobo.287.1">a percentage.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.288.1">gc-heap-size</span></strong><span class="koboSpan" id="kobo.289.1"> (or </span><strong class="source-inline"><span class="koboSpan" id="kobo.290.1">systemruntime_gc_heap_size_bytes</span></strong><span class="koboSpan" id="kobo.291.1">): Represents the approximate allocated managed memory size </span><span class="No-Break"><span class="koboSpan" id="kobo.292.1">in megabytes.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.293.1">time-in-gc</span></strong><span class="koboSpan" id="kobo.294.1"> (or </span><strong class="source-inline"><span class="koboSpan" id="kobo.295.1">systemruntime_time_in_gc_ratio</span></strong><span class="koboSpan" id="kobo.296.1">): Represents time spent on garbage collection since the last </span><span class="No-Break"><span class="koboSpan" id="kobo.297.1">garbage collection.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.298.1">gen-0-gc-count</span></strong><span class="koboSpan" id="kobo.299.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.300.1">gen-1-gc-count</span></strong><span class="koboSpan" id="kobo.301.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.302.1">gen-2-gc-count</span></strong><span class="koboSpan" id="kobo.303.1"> (or </span><strong class="source-inline"><span class="koboSpan" id="kobo.304.1">systemruntime_gen_&lt;gen&gt;_gc_count</span></strong><span class="koboSpan" id="kobo.305.1">): Represents the count of garbage collections in the corresponding generation per interval. </span><span class="koboSpan" id="kobo.305.2">The default update interval is 5 seconds, but you can adjust it. </span><span class="koboSpan" id="kobo.305.3">Generation sizes are also exposed </span><span class="No-Break"><span class="koboSpan" id="kobo.306.1">as counters.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.307.1">alloc-rate</span></strong><span class="koboSpan" id="kobo.308.1"> (or </span><strong class="source-inline"><span class="koboSpan" id="kobo.309.1">systemruntime_alloc_rate_bytes</span></strong><span class="koboSpan" id="kobo.310.1">): Represents the allocation rate in bytes </span><span class="No-Break"><span class="koboSpan" id="kobo.311.1">per interval.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.312.1">You can also find counters</span><a id="_idIndexMarker117"/><span class="koboSpan" id="kobo.313.1"> coming from Kestrel, Sockets, TLS, and DNS that can be useful to investigate specific issues such as DNS outages, long request queues, or socket exhaustion on HTTP servers. </span><span class="koboSpan" id="kobo.313.2">Check out the .NET documentation for the full </span><span class="No-Break"><span class="koboSpan" id="kobo.314.1">list (</span></span><span class="No-Break"><span class="koboSpan" id="kobo.315.1">https://learn.microsoft.com/dotnet/core/diagnostics/available-counters</span></span><span class="No-Break"><span class="koboSpan" id="kobo.316.1">).</span></span></p>
<p><span class="koboSpan" id="kobo.317.1">ASP.NET Core and </span><strong class="source-inline"><span class="koboSpan" id="kobo.318.1">HttpClient</span></strong><span class="koboSpan" id="kobo.319.1"> request counters don’t have dimensions, but would be useful if you didn’t have OpenTelemetry tracing or metrics and wanted to get a very rough idea about throughput and failure rate across </span><span class="No-Break"><span class="koboSpan" id="kobo.320.1">all APIs.</span></span></p>
<p><span class="koboSpan" id="kobo.321.1">Prometheus scrapes metrics from the </span><strong class="source-inline"><span class="koboSpan" id="kobo.322.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.323.1"> metrics endpoint. </span><span class="koboSpan" id="kobo.323.2">We can access it ourselves to see the raw data, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.324.1">Figure 2</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.325.1">.5</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.326.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer030">
<span class="koboSpan" id="kobo.327.1"><img alt="Figure 2.5 – Frontend metrics in Prometheus exposure format" src="image/B19423_02_05.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.328.1">Figure 2.5 – Frontend metrics in Prometheus exposure format</span></p>
<p><span class="koboSpan" id="kobo.329.1">It’s also possible to query and </span><a id="_idIndexMarker118"/><span class="koboSpan" id="kobo.330.1">plot basic visualizations with Prometheus, as you can see in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.331.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.332.1">.6</span></em><span class="koboSpan" id="kobo.333.1">. </span><span class="koboSpan" id="kobo.333.2">Just hit </span><strong class="source-inline"><span class="koboSpan" id="kobo.334.1">http://localhost:9090/graph</span></strong><span class="koboSpan" id="kobo.335.1">. </span><span class="koboSpan" id="kobo.335.2">For any advanced visualizations or dashboards, we would need tooling that integrates with </span><a id="_idIndexMarker119"/><span class="koboSpan" id="kobo.336.1">Prometheus, such </span><span class="No-Break"><span class="koboSpan" id="kobo.337.1">as </span></span><span class="No-Break"><strong class="bold"><span class="koboSpan" id="kobo.338.1">Grafana</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.339.1">.</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer031">
<span class="koboSpan" id="kobo.340.1"><img alt="Figure 2.6 – GC memory heap size for frontend and storage services in Prometheus" src="image/B19423_02_06.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.341.1">Figure 2.6 – GC memory heap size for frontend and storage services in Prometheus</span></p>
<p><span class="koboSpan" id="kobo.342.1">As you can see, even basic ASP.NET Core applications come with minimal monitoring capabilities – counters for overall system health and correlated logs for debugging. </span><span class="koboSpan" id="kobo.342.2">With </span><strong class="source-inline"><span class="koboSpan" id="kobo.343.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.344.1"> we can even retrieve</span><a id="_idIndexMarker120"/><span class="koboSpan" id="kobo.345.1"> telemetry at runtime without changing the code or restarting the application (well, of course, only if we have access to the </span><span class="No-Break"><span class="koboSpan" id="kobo.346.1">application instance).</span></span></p>
<p><span class="koboSpan" id="kobo.347.1">With some additional infrastructure changes to run </span><strong class="source-inline"><span class="koboSpan" id="kobo.348.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.349.1"> as a sidecar and logging management solution, we would be able to build a very basic production </span><span class="No-Break"><span class="koboSpan" id="kobo.350.1">monitoring solution.</span></span></p>
<p><span class="koboSpan" id="kobo.351.1">We still lack distributed tracing and metrics that have rich context. </span><span class="koboSpan" id="kobo.351.2">Let’s now see how to enable them with OpenTelemetry instrumentation and improve this </span><span class="No-Break"><span class="koboSpan" id="kobo.352.1">experience further.</span></span></p>
<h1 id="_idParaDest-46"><a id="_idTextAnchor045"/><span class="koboSpan" id="kobo.353.1">Enabling auto-collection with OpenTelemetry</span></h1>
<p><span class="koboSpan" id="kobo.354.1">In this section, we’re going</span><a id="_idIndexMarker121"/><span class="koboSpan" id="kobo.355.1"> to add OpenTelemetry to our demo application and enable auto-collection for ASP.NET Core, </span><strong class="source-inline"><span class="koboSpan" id="kobo.356.1">HttpClient</span></strong><span class="koboSpan" id="kobo.357.1">, Entity Framework, and runtime metrics. </span><span class="koboSpan" id="kobo.357.2">We’ll see what it adds to the bare-bones </span><span class="No-Break"><span class="koboSpan" id="kobo.358.1">monitoring</span></span><span class="No-Break"><a id="_idIndexMarker122"/></span><span class="No-Break"><span class="koboSpan" id="kobo.359.1"> experience.</span></span></p>
<p><span class="koboSpan" id="kobo.360.1">We’ll export traces to Jaeger and metrics to Prometheus, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.361.1">Figure 2</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.362.1">.7</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.363.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer032">
<span class="koboSpan" id="kobo.364.1"><img alt="Figure 2.7 – Meme services sending telemetry to Jaeger and Prometheus" src="image/B19423_02_07.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.365.1">Figure 2.7 – Meme services sending telemetry to Jaeger and Prometheus</span></p>
<p><span class="koboSpan" id="kobo.366.1">You can also send data directly to your observability backend if it has an OTLP endpoint, or you can configure a backend-specific exporter in the application. </span><span class="koboSpan" id="kobo.366.2">So, let’s get started and instrument our application </span><span class="No-Break"><span class="koboSpan" id="kobo.367.1">with OpenTelemetry.</span></span></p>
<h2 id="_idParaDest-47"><a id="_idTextAnchor046"/><span class="koboSpan" id="kobo.368.1">Installing and configuring OpenTelemetry</span></h2>
<p><span class="koboSpan" id="kobo.369.1">OpenTelemetry comes as a set of </span><a id="_idIndexMarker123"/><span class="koboSpan" id="kobo.370.1">NuGet packages. </span><span class="koboSpan" id="kobo.370.2">Here are a few that we’re using in our </span><span class="No-Break"><span class="koboSpan" id="kobo.371.1">demo app:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.372.1">OpenTelemetry</span></strong><span class="koboSpan" id="kobo.373.1">: The SDK that contains all that we need to produce traces and metrics and configure a </span><a id="_idIndexMarker124"/><span class="koboSpan" id="kobo.374.1">generic processing and export pipeline. </span><span class="koboSpan" id="kobo.374.2">It does not collect any telemetry on </span><span class="No-Break"><span class="koboSpan" id="kobo.375.1">its own.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.376.1">OpenTelemetry.Exporter.Jaeger</span></strong><span class="koboSpan" id="kobo.377.1">: This package contains a trace exporter that publishes spans </span><span class="No-Break"><span class="koboSpan" id="kobo.378.1">to Jaeger.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.379.1">OpenTelemetry.Exporter.Prometheus.AspNetCore</span></strong><span class="koboSpan" id="kobo.380.1">: This package contains the Prometheus exporter. </span><span class="koboSpan" id="kobo.380.2">It creates a new </span><strong class="source-inline"><span class="koboSpan" id="kobo.381.1">/metrics</span></strong><span class="koboSpan" id="kobo.382.1"> endpoint for Prometheus to scrape </span><span class="No-Break"><span class="koboSpan" id="kobo.383.1">metrics from.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.384.1">OpenTelemetry.Extensions.Hosting</span></strong><span class="koboSpan" id="kobo.385.1">: This package simplifies OpenTelemetry configuration in ASP.NET </span><span class="No-Break"><span class="koboSpan" id="kobo.386.1">Core applications.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.387.1">OpenTelemetry.Instrumentation.AspNetCore</span></strong><span class="koboSpan" id="kobo.388.1">: This package enables ASP.NET Core tracing and </span><span class="No-Break"><span class="koboSpan" id="kobo.389.1">metrics auto-instrumentation.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.390.1">OpenTelemetry.Instrumentation.Http</span></strong><span class="koboSpan" id="kobo.391.1">: This package enables tracing and metrics</span><a id="_idIndexMarker125"/><span class="koboSpan" id="kobo.392.1"> auto-instrumentation </span><span class="No-Break"><span class="koboSpan" id="kobo.393.1">for </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.394.1">System.Net.HttpClient</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.395.1">.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.396.1">OpenTelemetry.Instrumentation.EntityFrameworkCore</span></strong><span class="koboSpan" id="kobo.397.1">: Tracing</span><a id="_idIndexMarker126"/><span class="koboSpan" id="kobo.398.1"> instrumentation for Entity Framework Core. </span><span class="koboSpan" id="kobo.398.2">We only need it for the </span><span class="No-Break"><span class="koboSpan" id="kobo.399.1">storage service.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.400.1">OpenTelemetry.Instrumentation.Process</span></strong><span class="koboSpan" id="kobo.401.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.402.1">OpenTelemetry.Instrumentation.Runtime</span></strong><span class="koboSpan" id="kobo.403.1">: These two packages enable process-level metrics for CPU and memory utilization and include the runtime counters we saw previously </span><span class="No-Break"><span class="koboSpan" id="kobo.404.1">with </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.405.1">dotnet-monitor</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.406.1">.</span></span></li>
</ul>
<p><span class="koboSpan" id="kobo.407.1">You can also enable other counter sources one by one with the </span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.408.1">OpenTelemetry.Instrumentation.EventCounters</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.409.1"> package.</span></span></p>
<h3><span class="koboSpan" id="kobo.410.1">Distributed tracing</span></h3>
<p><span class="koboSpan" id="kobo.411.1">To configure tracing, first call </span><strong class="source-inline"><span class="koboSpan" id="kobo.412.1">AddOpenTelemetry</span></strong><span class="koboSpan" id="kobo.413.1"> extension method on </span><strong class="source-inline"><span class="koboSpan" id="kobo.414.1">IServiceCollection </span></strong><span class="koboSpan" id="kobo.415.1">and then call the W</span><strong class="source-inline"><span class="koboSpan" id="kobo.416.1">ithTracing</span></strong><span class="koboSpan" id="kobo.417.1"> method, as shown in the </span><span class="No-Break"><span class="koboSpan" id="kobo.418.1">following </span></span><span class="No-Break"><a id="_idIndexMarker127"/></span><span class="No-Break"><span class="koboSpan" id="kobo.419.1">example:</span></span></p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.420.1">Program.cs</span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.421.1">
builder.Services.AddOpenTelemetry().WithTracing(
  tracerProviderBuilder =&gt; tracerProviderBuilder
    .AddJaegerExporter()
    .AddHttpClientInstrumentation()
    .AddAspNetCoreInstrumentation()
    .AddEntityFrameworkCoreInstrumentation());</span></pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/Program.cs"><span class="koboSpan" id="kobo.422.1">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/Program.cs</span></a></p>
<p><span class="koboSpan" id="kobo.423.1">Here, we’re adding the Jaeger exporter and enabling </span><strong class="source-inline"><span class="koboSpan" id="kobo.424.1">HttpClient</span></strong><span class="koboSpan" id="kobo.425.1">, ASP.NET Core, and Entity Framework instrumentations (</span><span class="No-Break"><span class="koboSpan" id="kobo.426.1">on storage).</span></span></p>
<p><span class="koboSpan" id="kobo.427.1">We’re also configuring the </span><a id="_idIndexMarker128"/><span class="koboSpan" id="kobo.428.1">service name via the </span><strong class="source-inline"><span class="koboSpan" id="kobo.429.1">OTEL_SERVICE_NAME</span></strong><span class="koboSpan" id="kobo.430.1"> environment variable in </span><strong class="source-inline"><span class="koboSpan" id="kobo.431.1">launchSetting.json</span></strong><span class="koboSpan" id="kobo.432.1"> and in </span><strong class="source-inline"><span class="koboSpan" id="kobo.433.1">docker-compose-otel.yml</span></strong><span class="koboSpan" id="kobo.434.1"> for Docker runs. </span><span class="koboSpan" id="kobo.434.2">The OpenTelemetry SDK reads it and sets the </span><strong class="source-inline"><span class="koboSpan" id="kobo.435.1">service.name</span></strong><span class="koboSpan" id="kobo.436.1"> resource </span><span class="No-Break"><span class="koboSpan" id="kobo.437.1">attribute accordingly.</span></span></p>
<p><span class="koboSpan" id="kobo.438.1">The Jaeger host is configured with the </span><strong class="source-inline"><span class="koboSpan" id="kobo.439.1">OTEL_EXPORTER_JAEGER_AGENT_HOST</span></strong><span class="koboSpan" id="kobo.440.1"> environment variable </span><span class="No-Break"><span class="koboSpan" id="kobo.441.1">in </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.442.1">docker-compose-otel.yml</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.443.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.444.1">We’ll talk more about configuration in </span><a href="B19423_05.xhtml#_idTextAnchor083"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.445.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.446.1">, </span><em class="italic"><span class="koboSpan" id="kobo.447.1">Configuration and Control Plane</span></em><span class="koboSpan" id="kobo.448.1">, and learn how to configure sampling, enrich telemetry, and add </span><span class="No-Break"><span class="koboSpan" id="kobo.449.1">custom sources.</span></span></p>
<h3><span class="koboSpan" id="kobo.450.1">Metrics</span></h3>
<p><span class="koboSpan" id="kobo.451.1">Metrics configuration is similar – we first call the </span><strong class="source-inline"><span class="koboSpan" id="kobo.452.1">AddOpenTelemetry</span></strong><span class="koboSpan" id="kobo.453.1"> extension method </span><a id="_idIndexMarker129"/><span class="koboSpan" id="kobo.454.1">on </span><strong class="source-inline"><span class="koboSpan" id="kobo.455.1">IServiceCollection</span></strong><span class="koboSpan" id="kobo.456.1"> and then in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.457.1">WithMetrics</span></strong><span class="koboSpan" id="kobo.458.1"> callback set up the Prometheus exporter and auto-instrumentations for </span><strong class="source-inline"><span class="koboSpan" id="kobo.459.1">HttpClient</span></strong><span class="koboSpan" id="kobo.460.1">, ASP.NET Core, Process, and Runtime. </span><span class="koboSpan" id="kobo.460.2">Entity Framework’s instrumentation does not </span><span class="No-Break"><span class="koboSpan" id="kobo.461.1">report metrics.</span></span></p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.462.1">Program.cs</span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.463.1">
builder.Services.AddOpenTelemetry()
        ...
</span><span class="koboSpan" id="kobo.463.2">        .WithMetrics(meterProviderBuilder =&gt; meterProviderBuilder
            .AddPrometheusExporter()
            .AddHttpClientInstrumentation()
            .AddAspNetCoreInstrumentation()
            .AddProcessInstrumentation()
            .AddRuntimeInstrumentation());</span></pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/Program.cs"><span class="koboSpan" id="kobo.464.1">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/Program.cs</span></a></p>
<p><span class="koboSpan" id="kobo.465.1">We also need to </span><a id="_idIndexMarker130"/><span class="koboSpan" id="kobo.466.1">expose the Prometheus endpoint after building the </span><span class="No-Break"><span class="koboSpan" id="kobo.467.1">application instance:</span></span></p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.468.1">Program.cs</span></p>
<pre class="console"><span class="koboSpan" id="kobo.469.1">
var app = builder.Build();
app.UseOpenTelemetryPrometheusScrapingEndpoint();</span></pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/Program.cs"><span class="koboSpan" id="kobo.470.1">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter2/storage/Program.cs</span></a></p>
<p><span class="koboSpan" id="kobo.471.1">We’re ready to run </span><span class="No-Break"><span class="koboSpan" id="kobo.472.1">the application!</span></span></p>
<pre class="console"><span class="koboSpan" id="kobo.473.1">
$ docker-compose -f docker-compose-otel.yml up –-build</span></pre>
<p><span class="koboSpan" id="kobo.474.1">You should see logs from all services including some errors while MySQL is starting up. </span><span class="koboSpan" id="kobo.474.2">Check the frontend to make sure it </span><span class="No-Break"><span class="koboSpan" id="kobo.475.1">works: </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.476.1">https://localhost:5051/Meme?name=dotnet</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.477.1">.</span></span></p>
<h1 id="_idParaDest-48"><a id="_idTextAnchor047"/><span class="koboSpan" id="kobo.478.1">Exploring auto-generated telemetry</span></h1>
<p><span class="koboSpan" id="kobo.479.1">The meme service is </span><a id="_idIndexMarker131"/><span class="koboSpan" id="kobo.480.1">now up and running. </span><span class="koboSpan" id="kobo.480.2">Feel free to upload your favorite memes and if you see any issues, use telemetry to </span><span class="No-Break"><span class="koboSpan" id="kobo.481.1">debug them!</span></span></p>
<h2 id="_idParaDest-49"><a id="_idTextAnchor048"/><span class="koboSpan" id="kobo.482.1">Debugging</span></h2>
<p><span class="koboSpan" id="kobo.483.1">If you try to upload something right </span><a id="_idIndexMarker132"/><span class="koboSpan" id="kobo.484.1">after the service starts, you might get an error like the one shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.485.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.486.1">.8</span></em><span class="koboSpan" id="kobo.487.1">. </span><span class="koboSpan" id="kobo.487.2">Let’s figure </span><span class="No-Break"><span class="koboSpan" id="kobo.488.1">out why!</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer033">
<span class="koboSpan" id="kobo.489.1"><img alt="Figure 2.8 – Error from application with traceparent" src="image/B19423_02_08.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.490.1">Figure 2.8 – Error from application with traceparent</span></p>
<p><span class="koboSpan" id="kobo.491.1">We can approach this investigation from two angles. </span><span class="koboSpan" id="kobo.491.2">The first is to use the </span><strong class="source-inline"><span class="koboSpan" id="kobo.492.1">traceparent</span></strong><span class="koboSpan" id="kobo.493.1"> shown on the page; the second is to filter the traces from the frontend based on the </span><span class="No-Break"><span class="koboSpan" id="kobo.494.1">error status.</span></span><span class="koboSpan" id="kobo.495.1"> In any case, let’s go to Jaeger – our</span><a id="_idIndexMarker133"/><span class="koboSpan" id="kobo.496.1"> tracing backend running on </span><strong class="source-inline"><span class="koboSpan" id="kobo.497.1">http://localhost:16686/</span></strong><span class="koboSpan" id="kobo.498.1">. </span><span class="koboSpan" id="kobo.498.2">We can search by </span><strong class="source-inline"><span class="koboSpan" id="kobo.499.1">Trace ID</span></strong><span class="koboSpan" id="kobo.500.1"> or filter by service and error, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.501.1">Figure 2</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.502.1">.9</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.503.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer034">
<span class="koboSpan" id="kobo.504.1"><img alt="Figure 2.9 – Find the trace in Jaeger by Trace ID (1) or with a combination of the service (2) and error (3)" src="image/B19423_02_09.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.505.1">Figure 2.9 – Find the trace in Jaeger by Trace ID (1) or with a combination of the service (2) and error (3)</span></p>
<p><span class="koboSpan" id="kobo.506.1">If we open the trace, we’ll see</span><a id="_idIndexMarker134"/><span class="koboSpan" id="kobo.507.1"> that the storage service refused the connection – check out </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.508.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.509.1">.10</span></em><span class="koboSpan" id="kobo.510.1">. </span><span class="koboSpan" id="kobo.510.2">What </span><span class="No-Break"><span class="koboSpan" id="kobo.511.1">happened here?</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer035">
<span class="koboSpan" id="kobo.512.1"><img alt="Figure 2.10 – Drill down into the trace: the frontend service could not reach the storage" src="image/B19423_02_10.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.513.1">Figure 2.10 – Drill down into the trace: the frontend service could not reach the storage</span></p>
<p><span class="koboSpan" id="kobo.514.1">Since there are no traces from the </span><a id="_idIndexMarker135"/><span class="koboSpan" id="kobo.515.1">storage, let’s check the storage logs with </span><strong class="source-inline"><span class="koboSpan" id="kobo.516.1">docker logs chapter2-storage-1</span></strong><span class="koboSpan" id="kobo.517.1">. </span><span class="koboSpan" id="kobo.517.2">We’ll query the logs in a more convenient way in </span><a href="B19423_08.xhtml#_idTextAnchor131"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.518.1">Chapter 8</span></em></span></a><span class="koboSpan" id="kobo.519.1">, </span><em class="italic"><span class="koboSpan" id="kobo.520.1">Writing Structured and Correlated Logs</span></em><span class="koboSpan" id="kobo.521.1">. </span><span class="koboSpan" id="kobo.521.2">For now, let’s just grep storage logs around the time the issue occurred and find the relevant record, as shown in </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.522.1">Figure 2</span></em></span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.523.1">.11</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.524.1">:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer036">
<span class="koboSpan" id="kobo.525.1"><img alt="Figure 2.11 – Connection error in storage stdout" src="image/B19423_02_11.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.526.1">Figure 2.11 – Connection error in storage stdout</span></p>
<p><span class="koboSpan" id="kobo.527.1">Apparently, the storage was not able to connect to the MySQL server and it could not start until the connection was established. </span><span class="koboSpan" id="kobo.527.2">If we dig further into the MySQL logs, we’ll discover that it took a while for it to start, but then everything worked </span><span class="No-Break"><span class="koboSpan" id="kobo.528.1">just fine.</span></span></p>
<p><span class="koboSpan" id="kobo.529.1">Some action items from this investigation are to enable retries on the frontend and investigate the slow start for MySQL. </span><span class="koboSpan" id="kobo.529.2">If it happens in production where there are multiple instances of storage, we should also dig into the load balancer and service </span><span class="No-Break"><span class="koboSpan" id="kobo.530.1">discovery behavior.</span></span></p>
<p><span class="koboSpan" id="kobo.531.1">What tracing brings here is </span><em class="italic"><span class="koboSpan" id="kobo.532.1">convenience</span></em><span class="koboSpan" id="kobo.533.1"> – we could have done the same investigation with logs alone, but it would have taken longer and would be more difficult. </span><span class="koboSpan" id="kobo.533.2">Assuming we dealt with a more complicated case with dozens of requests over multiple services, parsing logs would simply not be a </span><span class="No-Break"><span class="koboSpan" id="kobo.534.1">reasonable option.</span></span></p>
<p><span class="koboSpan" id="kobo.535.1">As we can see in this</span><a id="_idIndexMarker136"/><span class="koboSpan" id="kobo.536.1"> example, tracing can help us narrow the problem down, but sometimes we still need logs to understand what’s going on, especially for issues </span><span class="No-Break"><span class="koboSpan" id="kobo.537.1">during startup.</span></span></p>
<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/><span class="koboSpan" id="kobo.538.1">Performance</span></h2>
<p><span class="koboSpan" id="kobo.539.1">Let’s check out </span><a id="_idIndexMarker137"/><span class="koboSpan" id="kobo.540.1">some metrics collected by the HTTP and </span><span class="No-Break"><span class="koboSpan" id="kobo.541.1">runtime instrumentations.</span></span></p>
<p><span class="koboSpan" id="kobo.542.1">OpenTelemetry defines </span><strong class="source-inline"><span class="koboSpan" id="kobo.543.1">http.server.duration</span></strong><span class="koboSpan" id="kobo.544.1"> and </span><strong class="source-inline"><span class="koboSpan" id="kobo.545.1">http.client.duration</span></strong> <strong class="bold"><span class="koboSpan" id="kobo.546.1">histogram</span></strong><span class="koboSpan" id="kobo.547.1"> metrics with</span><a id="_idIndexMarker138"/><span class="koboSpan" id="kobo.548.1"> low-cardinality attributes for method, API route (server only), and status code. </span><span class="koboSpan" id="kobo.548.2">These metrics allow us to calculate latency percentiles, throughputs, and </span><span class="No-Break"><span class="koboSpan" id="kobo.549.1">error rates.</span></span></p>
<p><span class="koboSpan" id="kobo.550.1">With OpenTelemetry metrics, ASP.NET Core instrumentation can populate API routes so we can finally analyze latency, throughput, and error rate per route. </span><span class="koboSpan" id="kobo.550.2">And histograms give us even more flexibility – we can now check the distribution of latency rather than the median, average, or a predefined set </span><span class="No-Break"><span class="koboSpan" id="kobo.551.1">of percentiles.</span></span></p>
<h3><span class="koboSpan" id="kobo.552.1">Latency</span></h3>
<p><span class="koboSpan" id="kobo.553.1">HTTP client latency can be </span><a id="_idIndexMarker139"/><span class="koboSpan" id="kobo.554.1">defined as the time between initiating a request and the response being received. </span><span class="koboSpan" id="kobo.554.2">For servers, it’s the time between receiving a request and the end of the </span><span class="No-Break"><span class="koboSpan" id="kobo.555.1">server’s response.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.556.1">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.557.1">When analyzing latency, filter out errors and check the distribution of latency rather than just averages or medians. </span><span class="koboSpan" id="kobo.557.2">It’s common to check the 95</span><span class="superscript"><span class="koboSpan" id="kobo.558.1">th</span></span><span class="koboSpan" id="kobo.559.1"> percentile (</span><span class="No-Break"><span class="koboSpan" id="kobo.560.1">aka P95).</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.561.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.562.1">.12</span></em><span class="koboSpan" id="kobo.563.1"> shows P95 latency for the </span><strong class="source-inline"><span class="koboSpan" id="kobo.564.1">PUT /meme</span></strong><span class="koboSpan" id="kobo.565.1"> API on the client and </span><span class="No-Break"><span class="koboSpan" id="kobo.566.1">server side:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer037">
<span class="koboSpan" id="kobo.567.1"><img alt="Figure 2.12 – Server versus client PUT /meme latency P95 in milliseconds" src="image/B19423_02_12.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.568.1">Figure 2.12 – Server versus client PUT /meme latency P95 in milliseconds</span></p>
<h4><span class="koboSpan" id="kobo.569.1">Time to first byte versus time to last byte</span></h4>
<p><span class="koboSpan" id="kobo.570.1">In .NET, </span><strong class="source-inline"><span class="koboSpan" id="kobo.571.1">HttpClient</span></strong><span class="koboSpan" id="kobo.572.1"> buffers a response </span><a id="_idIndexMarker140"/><span class="koboSpan" id="kobo.573.1">before returning it, but it can be configured to return the response right after the headers are received with </span><strong class="source-inline"><span class="koboSpan" id="kobo.574.1">HttpCompletionOptions</span></strong><span class="koboSpan" id="kobo.575.1">. </span><strong class="source-inline"><span class="koboSpan" id="kobo.576.1">HttpClient</span></strong><span class="koboSpan" id="kobo.577.1"> instrumentation can’t measure time-to-last-byte in </span><span class="No-Break"><span class="koboSpan" id="kobo.578.1">this case.</span></span></p>
<p><span class="koboSpan" id="kobo.579.1">The distinction between </span><em class="italic"><span class="koboSpan" id="kobo.580.1">time to first body byte</span></em><span class="koboSpan" id="kobo.581.1"> versus </span><em class="italic"><span class="koboSpan" id="kobo.582.1">time to last byte</span></em><span class="koboSpan" id="kobo.583.1"> can be important on frontends with clients using unreliable connections or when transferring a lot of data. </span><span class="koboSpan" id="kobo.583.2">In such cases, it’s useful to instrument stream operations and then measure the time to first byte</span><em class="italic"><span class="koboSpan" id="kobo.584.1"> and</span></em><span class="koboSpan" id="kobo.585.1"> time to last byte. </span><span class="koboSpan" id="kobo.585.2">You can use the difference between these metrics to get an idea about connection quality and optimize the end </span><span class="No-Break"><span class="koboSpan" id="kobo.586.1">user experience.</span></span></p>
<h3><span class="koboSpan" id="kobo.587.1">Error rate</span></h3>
<p><span class="koboSpan" id="kobo.588.1">Error rate is just a rate of unsuccessful</span><a id="_idIndexMarker141"/><span class="koboSpan" id="kobo.589.1"> requests per a given period of time. </span><span class="koboSpan" id="kobo.589.2">The key </span><a id="_idIndexMarker142"/><span class="koboSpan" id="kobo.590.1">question here is what constitutes </span><span class="No-Break"><span class="koboSpan" id="kobo.591.1">an error:</span></span></p>
<ul>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.592.1">1xx</span></strong><span class="koboSpan" id="kobo.593.1">, </span><strong class="source-inline"><span class="koboSpan" id="kobo.594.1">2xx</span></strong><span class="koboSpan" id="kobo.595.1">, and </span><strong class="source-inline"><span class="koboSpan" id="kobo.596.1">3xx</span></strong><span class="koboSpan" id="kobo.597.1"> status codes </span><span class="No-Break"><span class="koboSpan" id="kobo.598.1">indicate success.</span></span></li>
<li><strong class="source-inline"><span class="koboSpan" id="kobo.599.1">5xx</span></strong><span class="koboSpan" id="kobo.600.1"> codes cover errors such as the lack of a response, a disconnected client, network, or </span><span class="No-Break"><span class="koboSpan" id="kobo.601.1">DNS issues.</span></span></li>
<li><span class="koboSpan" id="kobo.602.1">Status codes in the </span><strong class="source-inline"><span class="koboSpan" id="kobo.603.1">4xx</span></strong><span class="koboSpan" id="kobo.604.1"> range are hard to categorize. </span><span class="koboSpan" id="kobo.604.2">For example, </span><strong class="source-inline"><span class="koboSpan" id="kobo.605.1">404</span></strong><span class="koboSpan" id="kobo.606.1"> could represent an issue – maybe the client expected to retrieve the data but it’s not there – but could also be a positive scenario, where the client is checking whether a resource exists before creating or updating it. </span><span class="koboSpan" id="kobo.606.2">There are similar concerns with </span><span class="No-Break"><span class="koboSpan" id="kobo.607.1">other statuses.</span></span></li>
</ul>
<p class="callout-heading"><span class="koboSpan" id="kobo.608.1">Note</span></p>
<p class="callout"><span class="koboSpan" id="kobo.609.1">OpenTelemetry only marks client spans with </span><strong class="source-inline"><span class="koboSpan" id="kobo.610.1">4xx</span></strong><span class="koboSpan" id="kobo.611.1"> as errors. </span><span class="koboSpan" id="kobo.611.2">We’ll see in </span><a href="B19423_05.xhtml#_idTextAnchor083"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.612.1">Chapter 5</span></em></span></a><span class="koboSpan" id="kobo.613.1">, </span><em class="italic"><span class="koboSpan" id="kobo.614.1">Configuration and Control Plane</span></em><span class="koboSpan" id="kobo.615.1">, how to tailor it to </span><span class="No-Break"><span class="koboSpan" id="kobo.616.1">your needs.</span></span></p>
<p><span class="koboSpan" id="kobo.617.1">It’s also common to treat latency </span><a id="_idIndexMarker143"/><span class="koboSpan" id="kobo.618.1">above a given threshold as an error to measure availability, but we don’t strictly need it for </span><span class="No-Break"><span class="koboSpan" id="kobo.619.1">observability purposes.</span></span></p>
<p><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.620.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.621.1">.13</span></em><span class="koboSpan" id="kobo.622.1"> shows an example </span><a id="_idIndexMarker144"/><span class="koboSpan" id="kobo.623.1">of a server error rate chart for a single API grouped by </span><span class="No-Break"><span class="koboSpan" id="kobo.624.1">error code:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer038">
<span class="koboSpan" id="kobo.625.1"><img alt="Figure 2.13 – Error rate per second for ﻿the GET/meme API grouped by error code" src="image/B19423_02_13.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.626.1">Figure 2.13 – Error rate per second for the GET/meme API grouped by error code</span></p>
<p><span class="koboSpan" id="kobo.627.1">It is also important to calculate the error rate per API route and method on servers. </span><span class="koboSpan" id="kobo.627.2">Because of different request rates, it’s easy to miss spikes or changes in less frequently </span><span class="No-Break"><span class="koboSpan" id="kobo.628.1">called APIs.</span></span></p>
<p class="callout-heading"><span class="koboSpan" id="kobo.629.1">Tip</span></p>
<p class="callout"><span class="koboSpan" id="kobo.630.1">Returning precise status codes for ‘‘known’’ errors and letting the service return </span><strong class="source-inline"><span class="koboSpan" id="kobo.631.1">500</span></strong><span class="koboSpan" id="kobo.632.1"> only for unhandled exceptions makes it easier to use your service, but also simplifies monitoring and alerting. </span><span class="koboSpan" id="kobo.632.2">By looking at the error code, we can discern the possible reasons and not waste time on known cases. </span><span class="koboSpan" id="kobo.632.3">Any </span><strong class="source-inline"><span class="koboSpan" id="kobo.633.1">500</span></strong><span class="koboSpan" id="kobo.634.1"> response becomes important to investigate and fix or </span><span class="No-Break"><span class="koboSpan" id="kobo.635.1">handle properly.</span></span></p>
<p><span class="koboSpan" id="kobo.636.1">To check resource </span><a id="_idIndexMarker145"/><span class="koboSpan" id="kobo.637.1">consumption, we can use runtime and process</span><a id="_idIndexMarker146"/><span class="koboSpan" id="kobo.638.1"> metrics. </span><span class="koboSpan" id="kobo.638.2">For example, </span><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.639.1">Figure 2</span></em></span><em class="italic"><span class="koboSpan" id="kobo.640.1">.14</span></em><span class="koboSpan" id="kobo.641.1"> shows </span><span class="No-Break"><span class="koboSpan" id="kobo.642.1">CPU usage:</span></span></p>
<div>
<div class="IMG---Figure" id="_idContainer039">
<span class="koboSpan" id="kobo.643.1"><img alt="Figure 2.14 – CPU usage query" src="image/B19423_02_14.jpg"/></span>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><span class="koboSpan" id="kobo.644.1">Figure 2.14 – CPU usage query</span></p>
<p><span class="koboSpan" id="kobo.645.1">The query returns the average CPU utilization percentage across all instances for each service represented by job dimension – we configured jobs </span><span class="No-Break"><span class="koboSpan" id="kobo.646.1">in </span></span><span class="No-Break"><strong class="source-inline"><span class="koboSpan" id="kobo.647.1">configs/prometheus-otel.yml</span></strong></span><span class="No-Break"><span class="koboSpan" id="kobo.648.1">.</span></span></p>
<p><span class="koboSpan" id="kobo.649.1">The state dimension divides processor time into user and privileged (system) time. </span><span class="koboSpan" id="kobo.649.2">To calculate the total average CPU usage per instance per service, we could write another </span><span class="No-Break"><span class="koboSpan" id="kobo.650.1">Prometheus query:</span></span></p>
<pre class="source-code"><span class="koboSpan" id="kobo.651.1">
sum by (job, instance) (rate(process_cpu_time_s[1m]) * 100)</span></pre>
<p><span class="koboSpan" id="kobo.652.1">The query calculates the total CPU usage per instance and then calculates the average value </span><span class="No-Break"><span class="koboSpan" id="kobo.653.1">per service.</span></span></p>
<p><span class="koboSpan" id="kobo.654.1">As you can see, the </span><a id="_idIndexMarker147"/><span class="koboSpan" id="kobo.655.1">Prometheus query language is a powerful tool allowing</span><a id="_idIndexMarker148"/><span class="koboSpan" id="kobo.656.1"> us to calculate derived metrics and slice, dice, and </span><span class="No-Break"><span class="koboSpan" id="kobo.657.1">filter them.</span></span></p>
<p><span class="koboSpan" id="kobo.658.1">We’ll see more examples of runtime metrics and performance analysis in </span><a href="B19423_04.xhtml#_idTextAnchor068"><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.659.1">Chapter 4</span></em></span></a><span class="koboSpan" id="kobo.660.1">, </span><em class="italic"><span class="koboSpan" id="kobo.661.1">Low-Level Performance Analysis with </span></em><span class="No-Break"><em class="italic"><span class="koboSpan" id="kobo.662.1">Diagnostic Tools</span></em></span><span class="No-Break"><span class="koboSpan" id="kobo.663.1">.</span></span></p>
<h1 id="_idParaDest-51"><a id="_idTextAnchor050"/><span class="koboSpan" id="kobo.664.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.665.1">In this chapter, we explored .NET diagnostics and monitoring capabilities supported by the platform and frameworks. </span><span class="koboSpan" id="kobo.665.2">ASP.NET Core context propagation is enabled by default and logging providers can use it to correlate logs. </span><span class="koboSpan" id="kobo.665.3">We need a log management system to be able to store logs from multiple instances of a service and efficiently </span><span class="No-Break"><span class="koboSpan" id="kobo.666.1">query them.</span></span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.667.1">dotnet-monitor</span></strong><span class="koboSpan" id="kobo.668.1"> allows the streaming of logs on demand from specific instances of your service, and the scraping of event counters with Prometheus to get a basic idea about service health. </span><span class="koboSpan" id="kobo.668.2">It can also be used for low-level performance analysis and can be run </span><span class="No-Break"><span class="koboSpan" id="kobo.669.1">in production.</span></span></p>
<p><span class="koboSpan" id="kobo.670.1">Then, we enabled OpenTelemetry auto-instrumentation for the HTTP stack and Entity Framework. </span><span class="koboSpan" id="kobo.670.2">HTTP and DB traces enable basic debugging capabilities, providing generic information on what happened for each remote call. </span><span class="koboSpan" id="kobo.670.3">You can search for traces based on attributes and query them using your tracing backend. </span><span class="koboSpan" id="kobo.670.4">With tracing, we can easily find a problematic service or component, and when that’s not enough, we can retrieve logs to get more details about the issue. </span><span class="koboSpan" id="kobo.670.5">With logs correlated to traces, we can easily navigate </span><span class="No-Break"><span class="koboSpan" id="kobo.671.1">between them.</span></span></p>
<p><span class="koboSpan" id="kobo.672.1">HTTP metrics enable common performance analysis. </span><span class="koboSpan" id="kobo.672.2">Depending on your backend, you can query, filter, and derive metrics and build dashboards and alerts based </span><span class="No-Break"><span class="koboSpan" id="kobo.673.1">on them.</span></span></p>
<p><span class="koboSpan" id="kobo.674.1">Now that we’ve got hands-on experience with basic distributed tracing and metrics, let’s explore the .NET ecosystem more and see how you can leverage instrumentation for common libraries </span><span class="No-Break"><span class="koboSpan" id="kobo.675.1">and infrastructure.</span></span></p>
<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/><span class="koboSpan" id="kobo.676.1">Questions</span></h1>
<ol>
<li><span class="koboSpan" id="kobo.677.1">How would you show trace context on a </span><span class="No-Break"><span class="koboSpan" id="kobo.678.1">Razor page?</span></span></li>
<li><span class="koboSpan" id="kobo.679.1">Imagine that the observability backend stopped receiving telemetry from some instances of the service. </span><span class="koboSpan" id="kobo.679.2">What can we do to understand what’s going on with </span><span class="No-Break"><span class="koboSpan" id="kobo.680.1">these instances?</span></span></li>
<li><span class="koboSpan" id="kobo.681.1">With the help of the Prometheus documentation (https://prometheus.io/docs/prometheus/latest/querying/basics/), write a query with PromQL to calculate the throughput (requests per second) per service </span><span class="No-Break"><span class="koboSpan" id="kobo.682.1">and API.</span></span></li>
<li><span class="koboSpan" id="kobo.683.1">With our meme service, how would you find out when a meme was uploaded and how many times it had been downloaded if you know only the </span><span class="No-Break"><span class="koboSpan" id="kobo.684.1">meme’s name?</span></span></li>
</ol>
</div>
</body></html>