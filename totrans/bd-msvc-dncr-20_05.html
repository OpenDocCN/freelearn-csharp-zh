<html><head></head><body>
        

                            
                    <h1 class="header-title">Deploying Microservices</h1>
                
            
            
                
<p>Both monolith and microservice architectural styles come with different deployment challenges. In the case of .NET monolithic applications, more often, deployments are a flavor of Xcopy deployments. Microservice deployments present a different set of challenges. Continuous integration and continuous deployment are the key practices when delivering microservice applications. Also, container technologies and toolchain technology, which promise greater isolation boundaries, are essential for microservice deployment and scaling. </p>
<p>In this chapter, we will discuss the fundamentals of microservice deployment and the influence of emerging practices, such as CI/CD tools and containers, on microservice deployment. We will also walk through the deployment of a simple .NET Core service in a Docker container.</p>
<p>By the end of the chapter, you will have an understanding of the following topics:</p>
<ul>
<li>Deployment terminology</li>
<li>What are the factors for successful microservice deployments?</li>
<li>What is continuous integration and continuous deployment?</li>
<li>Isolation requirements for microservice deployment</li>
<li>Containerization technology and its need for microservice deployment</li>
<li>Quick introduction to Docker</li>
<li>How to package an application as a Docker container using Visual Studio</li>
</ul>
<p>Before proceeding further, we should first learn why we are talking about the deployment of microservices. The deployment cycle is one that has a specific flow.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Monolithic application deployment challenges</h1>
                
            
            
                
<p>Monolithic applications are applications where all of the database and business logic is tied together and packaged as a single system. Since, in general, monolithic applications are deployed as a single package, deployments are somewhat simple but painful due to the following reasons:</p>
<ul>
<li>Deployment and release as a single concept: There is no differentiation between deploying build artifacts and actually making features available to the end user. More often, releases are coupled to their environment. This increases the risk of deploying new features.</li>
<li>All or nothing deployment:<strong> </strong>All or nothing deployment increases the risk of application downtime and failure. In the case of rollbacks, teams fail to deliver expected new features and hotfixes or service packs have to be released to deliver the right kind of functionality.</li>
</ul>
<p>A <strong>Hotfix</strong>, also known as a <strong>Quickfix</strong>, is a single or cumulative package (generally called a <strong>patch</strong>). It contains fixes for issues/bugs found in production that must be fixed before the next major release. </p>
<ul>
<li>Central databases as a single point of failure:<strong> </strong>In monolithic applications, a big, centralized database is a single point of failure. This database is often quite large and difficult to break down. This results in an increase in <strong>mean time to recover</strong> (<strong>MTTR</strong>) and <strong>mean time between failures</strong> (<strong>MTBF</strong>).</li>
<li>Deployment and releases are big events:<strong> </strong>Due to small changes in the application, the entire application could get deployed. This comes with a huge time and energy investment for developers and ops teams. Needless to say, a collaboration between the various teams involved is the key to a successful release. This becomes even harder when many teams spread globally are working on the development and release. These kinds of deployments/releases need a lot of hand-holding and manual steps. This impacts end customers who have to face application downtime. If you are familiar with these kinds of deployments, then you'll also be familiar with marathon sessions in the so-called war rooms and endless sessions of defect triage on conference bridges. </li>
<li>Time to market:<strong> </strong>Carrying out any changes to the system in such cases becomes harder. In such environments, executing any business change takes time. This makes responding to market forces difficult—the business can also lose its market share. With microservice architecture, we are addressing some of these challenges. This architecture provides greater flexibility and isolation for service deployment. It has proven to deliver much faster turnaround time and much-needed business agility.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding the deployment terminology</h1>
                
            
            
                
<p>Microservices deployment terminology simply includes steps that start with code changes till release. In this section, we will discuss all these steps of deployment terminology as follows:</p>
<ul>
<li><strong>Build</strong>: In the build stage, the service source gets compiled without any errors along with the passing of all corresponding unit tests. This stage produces build artifacts.</li>
<li><strong>Continuous Integration</strong> (<strong>CI</strong>): CI forces the entire application to build again every time a developer commits any change—the application code gets compiled and a comprehensive set of automated tests are run against it. This practice emerged from the problems of frequent integration of code in large teams. The basic idea is to keep the delta, or change to the software, small. This provides confidence that the software is in a workable state. Even if a check-in made by a developer breaks the system, it is easy to fix it this way.</li>
<li><strong>Deployment</strong>: Hardware provisioning and installing the base OS and correct version of the .NET framework are prerequisites for deployment. The next part of it is to promote these build artifacts in production through various stages. The combination of these two parts is referred to as the deployment stage. There is no distinction between the deployment and release stage in most monolithic applications.</li>
<li><strong>Continuous Deployment</strong> (<strong>CD</strong>): In CD, each successful build gets deployed to production. CD is more important from a technical team's perspective. Under CD, there are several other practices, such as automated unit testing, labeling, versioning of build numbers, and traceability of changes. With continuous delivery, the technical team ensures that the changes pushed to production through various lower environments work as expected in production. Usually, these are small and deployed very quickly.</li>
<li><strong>Continuous delivery:</strong> Continuous<strong> </strong>delivery is different from CD. CD comes from a technical team's perspective, whereas continuous delivery is more focused on providing the deployed code as early as possible to the customer. To make sure that customers get the right defect-free product, in continuous delivery, every build must pass through all the quality assurance checks. Once the product passes the satisfactory quality verification, it is the business stakeholders' decision when to release it.</li>
<li><strong>Build and deployment pipelines</strong>: The build and deployment pipeline is part of implementing continuous delivery through automation. It is a workflow of steps through which the code is committed in the source repository. At the other end of the deployment pipeline, the artifacts for release are produced. Some of the steps that may make up the build and deployment pipeline are as follows:
<ol>
<li>Unit tests</li>
<li>Integration tests</li>
<li>Code coverage and static analysis</li>
<li>Regression tests</li>
<li>Deployments to staging environment</li>
<li>Load/stress tests</li>
<li>Deployment to release repository</li>
</ol>
</li>
</ul>
<ul>
<li><strong>Release</strong>: A business feature made available to the end user is referred to as the release of a feature. To release a feature or service, the relevant build artifacts should be deployed beforehand. Usually, the feature toggle manages the release of a feature. If the feature flag (also called feature toggle) is not switched on in production, it is called a dark release of the specified feature.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Prerequisites for successful microservice deployments</h1>
                
            
            
                
<p>Any architectural style comes with a set of associated patterns and practices to follow. The microservice architectural style is no different. Microservice implementation has more chances of being successful with the adoption of the following practices:</p>
<ul>
<li>Self-sufficient teams: Amazon, who is a pioneer of SOA and microservice architectures, follow the <em>Two Pizza Teams</em> paradigm. This means usually a microservice team will have no more than 7-10 team members. These team members will have all the necessary skills and roles; for example, development, operations, and business analyst. Such a service team handles the development, operations, and management of a microservice. </li>
<li>CI and CD: CI and CD are prerequisites for implementing microservices. Smaller self-sufficient teams, who can integrate their work frequently, are precursors to the success of microservices. This architecture is not as simple as a monolith. However, automation and the ability to push code upgrades regularly enables teams to handle complexity. Tools, such as <strong>Team Foundation Online Services</strong> (<strong>TFS</strong>), TeamCity, and Jenkins, are quite popular toolchains in this space.</li>
<li>Infrastructure as code: The idea of representing hardware and infrastructure components, such as networks with code, is new. It helps you make deployment environments, such as integration, testing, and production, look exactly identical. This means developers and test engineers will be able to easily reproduce production defects in lower environments. With tools such as CFEngine, Chef, Puppet, Ansible, and Powershell DSC, you can write your entire infrastructure as code. With this paradigm shift, you can also put your infrastructure under a version control system and ship it as an artifact in deployment.</li>
<li>Utilization of cloud computing: Cloud computing is a big catalyst for adopting microservices. It is not mandatory as such for microservice deployment though. Cloud computing comes with near infinite scale, elasticity, and rapid provisioning capability. It is a no-brainer that the cloud is a natural ally of microservices. So, knowledge and experience with the Azure cloud will help you adopt microservices.</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Isolation requirements for microservice deployment</h1>
                
            
            
                
<p>In 2012, Adam Wiggins, co-founder of the Heroku platform, presented 12 basic principles. These principles talk about defining new modern web applications from an idea to deployment. This set of principles is now known as the <em>12-factor app</em>. These principles paved the way for new architectural styles, which evolved into microservice architectures. One of the principles of the 12-factor app was as follows:</p>
<p>"Execute the app as one or more stateless processes" </p>
<p>- Adam Wiggins (<a href="https://12factor.net/">https://12factor.net/</a>)</p>
<p>So, services will be essentially stateless (except the database, which acts as the state store). The <em>shared nothing</em> principle is also applied across the entire spectrum of patterns and practices. This is nothing more than the isolation of components in order to achieve scale and agility.</p>
<p>In the microservice world, this principle of isolation is applied in the following ways:</p>
<ul>
<li>Service teams: There will be self-sufficient teams built around services. In effect, the teams will be able to take all the decisions necessary to develop and support the microservices they are responsible for.</li>
<li>Source control isolation: The source repository of every microservice will be separate. It will not share any source code, files, and so on. It is okay to duplicate a few bits of code in the microservice world across services.</li>
<li>Build stage isolation: Build and deploy pipelines for every microservice should be kept isolated. Build and deploy pipelines can even run in parallel, isolated, and deployed services. Due to this, CI-CD tools should be scaled to support different services and pipelines at a much faster speed.</li>
<li>Release stage isolation: Every microservice should be released in isolation with other services. It is also possible that the same service with different versions is in the production environment.</li>
<li>Deploy stage isolation: This is the most important part of isolation. Traditional monolith deployment is done with bare metal servers. With the advancement in virtualization, virtual servers have replaced bare metal servers.</li>
</ul>
<p>In general, a monoliths' standard release process looks like this:</p>
<div><img height="195" src="img/9ce0073e-8ec4-4502-ae59-6e78b1352ddd.png" width="831"/></div>
<p class="CDPAlignLeft CDPAlign">Considering these isolation levels, the microservice build and deployment pipeline may look like this:</p>
<div><img class="image-border" height="556" src="img/a15dd6e7-0dcb-46cf-ab77-ddff584621ef.png" width="781"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Need for a new deployment paradigm</h1>
                
            
            
                
<p>The highest level of isolation for an application can be achieved by adding a new physical machine or bare metal server, so there is a server with its own operating system managing all system resources. This was regular stuff in legacy applications but it is not practical for modern applications. Modern applications are massive systems. Some examples of these systems are Amazon, Netflix, and Nike, or even traditional financial banks, such as ING. These systems are hosted on tens of thousands of servers. These kinds of modern applications demand ultra-scalability to serve their millions of users. For a microservice architecture, it does not make any sense to set up a new server just to run a small service on top of it.</p>
<p>With new CPU architectural breakthroughs, one of the options that emerged was virtual machines. Virtual machines abstract out all the hardware interactions of an operating system through the hypervisor technology. Hypervisors enabled us to run many machines or servers on a single physical machine. One significant point to note is that all the virtual machines get their piece of an isolated system resource from physical host resources.</p>
<p>This is still a good isolated environment to run an application. Virtualization brought the rationale of raising servers for entire applications. While doing so, it kept the components fairly isolated; this helped us utilize spare computer resources in our data centers. It improved the efficiency of our data centers while satisfying applications' fair isolation needs.</p>
<p>However, virtualization on its own is not able to support some of a microservice's needs. Under the 12-factors principles, Adam also talks about this:</p>
<p>"The twelve-factor app’s processes are disposable, meaning they can be started or stopped at a moment’s notice. This facilitates fast elastic scaling, rapid deployment of code or config changes, and robustness of production deploys."</p>
<p>- Adam Wiggins (<a href="https://12factor.net/">https://12factor.net/</a>)</p>
<p>This principle is important for the microservice architectural style. So, with microservices, we must ensure that the services start up faster. In this case, let's assume that there is one service per virtual machine. If we want to spin this service, it first needs to spin the virtual machine; however, the boot time of a virtual machine is long. Another thing is that with such applications, we are talking about a lot of cluster deployments. So services will definitely be distributed in clusters.</p>
<p>This also implies that virtual machines might need to be raised up on one of the nodes in the clusters and booted. This is again a problem with virtual machines' boot-up time. This does not bring the kind of efficiency that we are expecting for microservices.</p>
<p>Now, the only option left is to use the operating system process model, which comes with a quicker boot time. The process programming model has been well-known for ages but even processes come at a cost. They are not well isolated and share system resources as well as the kernel of the operating system.</p>
<p>For microservices, we need a better isolation deployment model and a new paradigm of deployment. The answer is this: innovation of the container technology. A good consideration factor is that the container technology sits well between virtualization and the operating system's process model.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Containers</h1>
                
            
            
                
<p>Container technology is not new to the Linux world. Containers are based on Linux's LXC technology. In this section, let's see how containers are important in the case of microservices.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">What are containers?</h1>
                
            
            
                
<p>A container is a piece of software in a complete filesystem. It contains everything that is needed to run code, runtime, system tools, and system libraries—anything that can be installed on a server. This guarantees that the software will always run in the same way, regardless of its environment. Containers share their host operating system and kernel with other containers on the same host. The technology around containers is not new. It has been a part of the Linux ecosystem for a long time. Due to the recent microservice-based discussions surrounding it, container technology came into the limelight again. Also, it is the technology on which Google, Amazon, and Netflix run.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Suitability of containers over virtual machines</h1>
                
            
            
                
<p>Let's understand the difference between containers and virtual machines—at the surface level, both are tools to achieve isolation and virtualization. </p>
<p>The architectural difference between virtual machines and containers is quite evident from the following diagram:</p>
<div><img height="361" src="img/573dff2c-d1dd-458f-a502-0ca9441871e5.png" width="745"/></div>
<p>By looking at the virtual machine internals, we can see that there is a host operating system along with a kernel, and on top of it, the hypervisor layer. Hosted applications have to bring in their own operating system and environment. In containers though, the containerization technology layer serves as a single layer and is shared across different applications. This removes the need for a guest operating system. Thus, applications in a container come with a smaller footprint and strong isolation levels. Another aspect that will encourage you to use containers for microservice deployment is that we can pack more applications on the same physical machine when compared to the same applications deployed on a virtual machine. This helps us achieve greater economy of scale benefits and provides a comparison of the benefits of virtual machines. </p>
<p>One more thing to note with containers is that they can be run on virtual machines as well. So it is okay to have a physical server with a virtual machine on it. This virtual machine serves as a host to a number of containers.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Transformation of the operation team's mindset </h1>
                
            
            
                
<p>Microsoft's Bill Baker came up with an analogy of pets and cattle and he applied it to servers in a data center. Okay, honestly, we care for our pets. We love them and show affection towards them, we name them as well. We think of their hygiene; if they fall sick, we take them to the vet. Do we take such care of our cattle? Of course, we don't; this is because we do not care that much about cattle. </p>
<p>The same analogy is true with respect to servers and containers. In pre-DevOps days, server admins cared about servers. They used to name those server machines and also have dedicated maintenance downtime and so on. With DevOps practices, such as infrastructure as code and containerization, containers can be treated as cattle. As the operations team, we do not need to care for them since containers are meant for a short lifespan. They can be booted up quickly in clusters and torn down quickly as well. When you are dealing with containers, always keep in mind this analogy. As far as daily operations go, expect the spinning up of and teardown of containers to be normal practice.</p>
<p>This analogy changes the perspective towards microservice deployment and how it supports containerization.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Containers are new binaries</h1>
                
            
            
                
<p>This is a new reality you will face as a .NET developer: working with microservices. Containers are new binaries. With Visual Studio, we compile the .NET program and after compilation, Visual Studio produces .NET assemblies, namely DLLs or EXEs. We take this set of associated DLLs and EXEs emitted by the compiler and deploy them on the servers.</p>
<p>"Containers are new binaries of deployment"</p>
<p>- Steve Lasker, Principal Program Manager at Microsoft</p>
<p>So, in short, our deployment unit was in the form of assemblies. Not anymore! Well, we still have .the NET program generating EXEs and DLLs, but our deployment unit has changed in the microservice world. It is a container now. We will still be compiling programs into assemblies. These assemblies will be pushed to the container and made ready to be shipped.</p>
<p>When we look at the code walkthrough in the following section of this chapter you will understand this point. We, as .NET developers, have the ability (and may I say necessity) to ship the containers. Along with this, another advantage of container deployment is that it removes the barrier between different operating systems and even different languages and runtimes.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Does it work on your machine? Let's ship your machine!</h1>
                
            
            
                
<p>Usually, we hear this a lot from developers: <em>Well, it works on my machine!</em> This usually happens when there is a defect that is not reproducible in production. Since containers are immutable and composable, it is quite possible to eliminate the configuration impedance between the development and production environment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Introducing Docker</h1>
                
            
            
                
<p>Docker (www.docker.com) has been a major force behind popularizing the containerization of applications. Docker is to containers what Google is to search engines. Sometimes, people even use containers and Docker as synonyms. Microsoft has partnered with Docker and is actively contributing to the Docker platform and tools in open source. This makes Docker important for us as .NET developers.</p>
<p>Docker is a very important topic and will be significant enough to learn for any serious .NET developer. However, due to time and scope constraints, we will just scratch the surface of the ecosystem of Docker here. We strongly recommend that you read through the Docker books made available by Packt Publishing.</p>
<p>If you want to safely try and learn Docker without even installing it on your machine, you can do so with <a href="https://www.katacoda.com/" target="_blank">https://KataCoda.com</a>.</p>
<p>Now let's focus on some of the terminologies and tools of the Docker platform. This will be essential for our next section:</p>
<ul>
<li>Docker image: A Docker <em>image</em> is a read-only template with instructions for creating a Docker container. A Docker image consists of a separate filesystem, associated libraries, and so on. Here, an image is always read-only and can run exactly the same abstracting, underlying, host differences. A Docker image can be composed of one layer on top of another. This composability of the Docker image can be compared with the analogy of layered cake. Docker images that are used across different containers can be reused. This also helps reduce the deployment footprint of applications that use the same base images.</li>
<li>Docker registry: A Docker registry is a library of images. A registry can be either public or private. Also, it can be on the same server as the Docker daemon or Docker client or on a totally separate server. </li>
<li>Docker hub: This is a public registry and it stores images. It is located at <a href="http://hub.docker.com/">http://hub.docker.com</a>.</li>
<li>Dockerfile: Dockerfile is a build or scripting file that contains instructions to build a Docker image. There can be multiple steps documented in a Dockerfile, starting with getting the base image.</li>
<li>Docker container: A Docker container is a runnable instance of a Docker image.</li>
<li>Docker compose: Docker compose allows you to define an application’s components—their containers, configuration, links, and volumes—in a single file. Then, a single command will set everything up and start your application. It is an architecture/dependency map for your application.</li>
<li>Docker swarm: Swarm is the Docker service by which container nodes work together. It runs a defined number of instances of a replica task, which is itself a Docker image.</li>
</ul>
<p>Let's look into the individual components of the Docker ecosystem; let's try to understand one of the ways in which the Docker workflow makes sense in the software development life cycle.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Microservice deployment with Docker overview</h1>
                
            
            
                
<p>In order to support this workflow, we need a CI tool and a configuration management tool. For illustration purposes, we have taken the <strong>Visual Studio Team Services</strong> (<strong>VSTS</strong>) build service as CI and VSTS release management for continuous delivery. The workflow would remain the same for any other tools or modes of deployment. The following is one of the flavors of microservice deployment with Docker:</p>
<ol>
<li>The code is checked into the VSTS repository. If this is the project's first check-in, it is done along with Dockerfile for the project.</li>
<li>The preceding check-in triggers VSTS to build the service from the source code and run unit/integration tests.</li>
<li>If tests are successful, VSTS builds a Docker image that is pushed to a <em>Docker registry</em>. VSTS release services deploy the image to the Azure container service.</li>
<li>If QA tests pass as well, VSTS is used to promote the container to deploy and start it in production.</li>
</ol>
<p>The following diagram depicts the steps in detail:</p>
<div><img height="289" src="img/d7114146-d0cb-4056-9907-dc417ff590fe.png" width="636"/></div>
<p>Note that the usual .NET CI-CD tools, such as TeamCity and Octopus Deploy (capabilities are in alpha stage), have features to produce a Docker container as a build artifact and deploy it to production.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Microservice deployment example using Docker</h1>
                
            
            
                
<p>Now we have all the essentials required to move toward coding and see for ourselves how things work. We have taken the product catalog service example here to be deployed as a Docker container. After running the accompanying source code, you should be able to successfully run the product catalog service in the Docker container.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up Docker on your machine</h1>
                
            
            
                
<p>This tutorial doesn't require any existing knowledge of Docker and should take about 20 or 30 minutes to complete. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Prerequisites</h1>
                
            
            
                
<p>You will need to do the following:</p>
<ol>
<li>Install Microsoft Visual Studio 2017 Update 3 (<a href="https://www.visualstudio.com/downloads/download-visual-studio-vs">https://www.visualstudio.com/downloads/download-visual-studio-vs</a>)</li>
<li>Install .NET Core 2.0 (<a href="https://www.microsoft.com/net/download/core">https://www.microsoft.com/net/download/core</a><a href="https://go.microsoft.com/fwlink/?LinkID=827546">)</a></li>
<li>Install Docker For Windows to run your Docker containers locally (<a href="https://www.docker.com/products/docker#/windows">https://www.docker.com/products/docker#/windows</a>)</li>
</ol>
<p>We are using Docker Community Edition for Windows to demonstrate the example.</p>
<ol start="4">
<li>After installation, your system will require restarting to complete the installation.</li>
<li>After restarting, Docker for Windows will prompt you to enable the Hyper-V feature if not enabled on your system. Click OK to enable the Hyper-V feature on your system (a system restart will be required). Refer to the following screenshot:</li>
</ol>
<div><img height="164" src="img/2c544f4d-910c-43c9-8c82-55a51c290387.png" width="450"/></div>
<ol start="6">
<li>Once Docker for Windows is installed, right-click on the Docker icon in the system tray and click on Settings and select Shared Drives:</li>
</ol>
<div><img class="image-border" height="299" src="img/15af9b53-4213-451e-b3ae-e71b91c71d02.png" width="498"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating an ASP.NET Core web application</h1>
                
            
            
                
<p>Following are the simple steps to get started:</p>
<ol>
<li>Create a new project by navigating to File | New Project | .NET Core | select ASP.NET Core Web Application, refer to the following screenshot:</li>
</ol>
<div><img height="448" src="img/27b5d3b3-d1b6-4c2d-a0e1-31752a7c10a4.png" width="734"/></div>
<ol start="2">
<li>From the New ASP.NET Core Web Application window, select .NET Core and ASP.NET Core 2.0.</li>
<li>Select Web Application (Model-View-Controller) from available templates.</li>
<li>Check Enable Docker support.</li>
<li>As we are demonstrating it for Windows select OS as Windows (if you did not install Docker as mentioned in the previous section, here you need to install Docker for Windows).</li>
<li>Click Ok to proceed, refer to the following screenshot:</li>
</ol>
<div><img height="383" src="img/f53a167d-af7a-4ec0-ae9e-cfca32f11edf.png" width="591"/></div>
<p class="mce-root CDPAlignLeft CDPAlign">The preceding steps will create the <kbd>FlixOne.BookStore.ProductService</kbd> project with Docker support. Following is the screenshot showing our project structure:</p>
<div><img height="356" src="img/c34b34a9-ebc3-4241-97c6-21e07ca4d291.png" width="291"/></div>
<p>The following files are added to the project:</p>
<ul>
<li><kbd>Dockerfile</kbd>: The Dockerfile for ASP.NET Core applications is based on the microsoft/aspnetcore image (<a href="https://hub.docker.com/r/microsoft/aspnetcore/">https://hub.docker.com/r/microsoft/aspnetcore/</a>). This image includes the ASP.NET Core NuGet packages, which have been prejitted, improving startup performance. When building ASP.NET Core applications, the Dockerfile FROM instruction (command) points to the most recent microsoft/dotnet image (<a href="https://hub.docker.com/r/microsoft/dotnet/">https://hub.docker.com/r/microsoft/dotnet/</a>) on the Docker hub. Following is the default code-snippet provided by the template:</li>
</ul>
<pre style="padding-left: 60px">FROM microsoft/aspnetcore:2.0<br/>ARG source<br/>WORKDIR /app<br/>EXPOSE 80<br/>COPY ${source:-obj/Docker/publish} .<br/>ENTRYPOINT ["dotnet", "FlixOne.BookStore.ProductService.dll"]</pre>
<div><div><div><p class="CodeMirror-gutter CodeMirror-linenumbers" style="padding-left: 60px">The preceding code is basically a set of instructions and these instructions are as follows:</p>
</div>
</div>
</div>
<p style="padding-left: 60px"><kbd>FROM</kbd> tells Docker that to pull the base image on the existing image, call <kbd>microsoft/aspnetcore:2.0</kbd>. This image already contains all the dependencies for running the ASP.NET Core on Linux, so we don't have to set it.</p>
<p style="padding-left: 60px"><kbd>COPY</kbd> and <kbd>WORKDIR</kbd> copy the current directory's contents to a new directory inside the called/app container and set it to the working directory for subsequent instructions.</p>
<p style="padding-left: 60px"><kbd>EXPOSE</kbd> tells Docker to expose the product catalog service on port 80 of the container.</p>
<p style="padding-left: 60px"><kbd>ENTRYPOINT</kbd> specifies the command to execute when the container starts up. In this case, it's .NET.</p>
<ul>
<li><kbd>Docker-compose.yml</kbd>: This is the base Compose file used to define the collection of images to be built and run with <kbd>Docker-compose</kbd> build/run.</li>
<li><kbd>Docker-compose.dev.debug.yml</kbd>: This is an additional Compose file for iterative changes when your configuration is set to debug. Visual Studio will call <kbd>-f docker-compose.yml</kbd> and <kbd>-f docker-compose.dev.debug.yml</kbd> to merge them. This Compose file is used by Visual Studio development tools.</li>
<li><kbd>Docker-compose.dev.release.yml</kbd>: This is an additional Compose file to debug your release definition. It will load the debugger in isolation so it does not change the content of the production image. </li>
</ul>
<p>The <kbd>docker-compose.yml</kbd> file contains the name of the image that is created when the project is run.</p>
<div><div><p class="CodeMirror-gutters">We now have everything we need to run/launch our service in the Docker container. Before we go further, please refer to <a href="047f5d0b-a008-48e2-9c7f-c57c16e671f9.xhtml">Chapter 2</a>, <em>Implementing Microservices</em>, and add the complete code (that is, controller, repositories, and so on) so the project structure looks like the following screenshot:</p>
</div>
</div>
<div><img height="400" src="img/ade370fb-7585-4a16-936b-d23a1afa3f33.png" width="286"/></div>
<p>Now all you have to do is press <em>F5</em> and launch your service in the container. This is the simplest and easiest way to put your service in the container. Once your microservice is containerized, you can use Visual Studio team services and Azure container services to deploy your container to the Azure cloud (<a href="https://docs.microsoft.com/en-us/azure/container-service/dcos-swarm/container-service-deployment">https://docs.microsoft.com/en-us/azure/container-service/dcos-swarm/container-service-deployment</a>).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>Microservice deployment is an exciting journey for us. For successful microservice delivery, deployment best practices should be followed. We need to focus on implementing isolation requirements for microservices even before we talk about deployment using automated tools. With successful microservice deployment practices, we can deliver business changes rapidly. The different isolation, requirements from self-sufficient teams to continuous delivery, give the scale and agility that are fundamental promises of microservices. Containerization is by far one of the most important innovative technologies we have, and we must take advantage of it for microservice deployment. Combining the Azure cloud with Docker will help us deliver the scale and isolation we are expecting from microservices. With Docker, we can easily achieve greater application density, which means a reduction in our cloud infrastructure cost. We also saw how easy it is to start these deployments with Visual Studio and Docker tools for Windows.</p>
<p>In our next chapter, we will look at microservice security. We will discuss the Azure active directory for authentication, how to leverage OAuth 2.0, and how to secure an API gateway with Azure API Management.</p>
<p> </p>


            

            
        
    </body></html>