<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-34"><a id="_idTextAnchor038"/>2</h1>
<h1 id="_idParaDest-35"><a id="_idTextAnchor039"/>Applying Industrial Principles to Software</h1>
<p>This chapter explains what can be done to make IT a real industry, and this begins with applying the main principles of industrialization, namely cutting complexity into small pieces and then standardizing the modules, and in particular their interfaces. We will make a comparison with the development of cities, where the normalization of water pipes, electricity, and other interfaces has allowed for continuous evolution.</p>
<p>In this chapter, we will explain the very concept of industry, as this is a very often used name, but not necessarily every time with a precise understanding of its meaning. We will also learn about how industrialization works by cutting complex problems into small ones and then making the small ones simple and repeatable, principally by means of standardization. We’ll also understand what benefits can be drawn from such an approach, in particular in information systems.</p>
<p>We’ll cover the following topics in this chapter:</p>
<ul>
<li>What is an industry?</li>
<li>Management of complexity</li>
<li>The benefits of standards and norms</li>
<li>The urbanism metaphor of information systems</li>
</ul>
<h1 id="_idParaDest-36"><a id="_idTextAnchor040"/>What is an industry?</h1>
<p>In the previous <a id="_idIndexMarker046"/>chapter, we compared craftsmanship to industrialization, hopefully showing that, while the former has nothing to be ashamed of, the latter is its natural evolution in time. All industries start with artisans and, with the work becoming more and more controlled and repeatable, potentially end up as real industries where the artisans have gradually converted to engineer competencies and jobs. Most people understand this without any need for explanation because it can be seen in many day-to-day experiences. When one, for example, first attempts at realizing a new task (say, cutting hair), the first trials are not comparable to the ensuing ones. After a period of time, the process starts to become more regular (the hair is cut fine, and the initial customer who accepted to be your <em class="italic">guinea pig</em> does not complain anymore). Given enough training, one gets expertise in the field and develops a routine (the hair is cut at a defined length and with the expected shape, in a way that can be precisely reproduced in a future haircut).</p>
<p>How about <a id="_idIndexMarker047"/>trying to formalize what is behind industrialization, though? In other terms, how do we characterize what constitutes industrialization? As we saw, there is the concept of being reproducible, which means there is a measured norm that should be met. Also, this norm is shared between all knowledgeable people in the field, which means it becomes a standard. In our example with haircuts, there are names for haircuts, and everybody in the field knows what “trimmed” or “shortened” means, which makes it safe for customers not to leave the hairdresser with a hairstyle they did not expect. Also, from one hairdresser to another, one can expect to obtain a globally similar result once stated using the right vocabulary. We obtain a homogeneous quality in this way.</p>
<p>In industrialization, just like in hairdressing, there is also the concept of addressing small parts of the whole. Except if you would like to look like a well-known person, you will not describe your haircut as a whole but describe small parts that form a complete hairstyle. For example (although not a good one, from an aesthetic point of view): long at the back, short on the top, tapered on the side. Addressing the parts instead of the whole and cutting a complex problem into small, simple ones that can be solved simply is the basis for industrialization, engineering, and even problem-solving as a whole.</p>
<p>A good hairdresser may be a fine artisan, but once you can get a similar haircut from many professionals in the field, it has simply become an <strong class="bold">industry</strong>. In the following sections, we will apply this definition to IT and show how industrialization happens there. In order to do so, we will first dive a bit deeper into what really stands behind the concept, in terms of actions to realize<a id="_idTextAnchor041"/>.</p>
<h2 id="_idParaDest-37"><a id="_idTextAnchor042"/>The two roots of industrialization – modularization and standardization</h2>
<p>After a <a id="_idIndexMarker048"/>simple example as an introduction to what we are going to call industrialization when applying it to Information Technology, we are going to dive a bit deeper into two associated movements in the concept, namely cutting big problems into small ones, which can be called <strong class="bold">modularization</strong> (as we expect small <a id="_idIndexMarker049"/>modules of a whole system) and solving these small problems with a normalized approach to reach homogeneous quality, which can be called <strong class="bold">standardizati<a id="_idTextAnchor043"/>on</strong>.</p>
<h2 id="_idParaDest-38"><a id="_idTextAnchor044"/>Modularity to reduce complexity</h2>
<p>Before explaining the concept of complexity, let’s see with another example how it relates to modularity. This time, we will use a mechanical comparison by analyzing the different modules of a car. A modern car is a feat of engineering, gathering so many parts in a sophisticated manner that is it virtually impossible for a person alone to build such a system. When one decomposes a car into modules, there are definitely clear-cut, well-separated modules that each have a purpose:</p>
<ul>
<li>The engine will provide power to displace the car</li>
<li>The body will protect the driver and passengers</li>
<li>The wheels and driving train will transform power into motion</li>
<li>The chassis will hold the other modules together in a rigid way, and so on</li>
</ul>
<p>The engine alone still is quite a beast, but we can decompose it further, into sub-modules:</p>
<ul>
<li>The injection system will bring gas into the chamber</li>
<li>The pistons will transform the explosion into linear motion</li>
<li>The crankshaft will convert linear motion into rotary motion</li>
<li>The lubrication system will ensure the system does not degrade due to wearing, heating, and so on</li>
</ul>
<p>Again, the complexity has lowered, and, if we go one step further into decomposing modules, the lubrication system can be described as the following:</p>
<ul>
<li>A pump ensures oil circulation</li>
<li>The oil performs cooling and allows for frictionless movements</li>
<li>The oil filter removes small debris that could otherwise increase friction and wear, and so on</li>
</ul>
<p>This time, we <a id="_idIndexMarker050"/>have reached such a small level of complexity that almost anyone could act on these modules: adding oil can be done by anyone owning a car, provided they know where to pour it; replacing an oil filter is as simple as unscrewing the old one and screwing a new one into the same place.</p>
<p>Modularity, really, is the art of cutting complex things into small parts that are easier to manage. If modularization is done well, complexity decreases at each step. Imagine we had separated the engine as left and right portions of it: we surely would not have made it easier to observe and maintain. Indeed, modularity is not simply the cutting of the system; it is the art of cutting it in an intelligent way so that complexity decreases. But how can we do that? This is where the experience of artisans and the help of a long history of making comes into place, providing enough expertise to know where the system should be and what will make it simpler. The first engines surely did not have an oil filter, but after some time being obliged to remove all the oil from the engine after a few hundred kilometers, filter it, and pour it back into the engine, it became obvious inserting a filter into the engine oil flow was the clever thing to do. If we try to summarize this in just one sentence, modules should be carved out after functions. The oil filter is there because, in the process of lubrication, there has to be a filtering function. It does make sense to assign this function to one and only one mod<a id="_idTextAnchor045"/>ule.</p>
<h2 id="_idParaDest-39"><a id="_idTextAnchor046"/>Standardization to ensure modularity is helpful</h2>
<p>The <a id="_idIndexMarker051"/>relationship between the different modules, the way they fit together, and how they interact are other criteria that must be taken into account. Cutting down is not enough: if one wants the whole system to function, defining smaller modules is the first step, but once created, they must be put back together to reach the global goal. This is where the way the modules have been cut is important, and we have explained previously that it should follow functions.</p>
<p>But how about putting them back together? If modules are aligned with functions, how can we make sure they fit together well? In fact, the problem is quite simple to explain and sometimes extremely hard to solve, needing large engineering teams to do so: we have to ensure that the common function they share is exactly the same. If two functions have to be reassembled, that means they have a small connecting sub-function in common, which is generally called the interface. This interface has to be defined in a similar pattern on both sides.</p>
<p>Let’s take the<a id="_idIndexMarker052"/> example of our oil filter again: it has been separated from the rest of the lubrication system and engine for its definition, but it also has to be put back in the engine system to operate and participate in the higher level of function, namely providing power to the car. To do so, it has been explained the oil filter has to be screwed back to the position in the engine, and this is where an interface will be needed. This interface is simply a screw thread: the oil filter will present a threaded oil and the engine a threaded growth at the place where the filter has to be placed, with of course a hole in it, allowing oil to flow in and from the filter. The interface itself is defined with functions:</p>
<ul>
<li>It should provide a stable attachment</li>
<li>It should be tight enough to be oil-proof</li>
<li>It should allow enough fluid circulation, and so on</li>
</ul>
<p>We are one step forward, but there remains another step to do in order to reach industrialization: the interface must be standardized, which means all the preceding functions should be specified in such a way that replacement is easy and each provider can participate in the higher-level module simply by knowing the interface. In our example, the oil filter, in order to participate in the engine system, has to adhere to the following:</p>
<ul>
<li>Use the precise thread diameter (for European oil filters, it is a 20-millimeter diameter, with a thread step of 1.5 millimeters)</li>
<li>Oil-proofness is ensured by a circular joint that is 62 millimeters wide in the same standard</li>
<li>The capacity to retain debris based on fluid circulation, and thus the duration of the filter use, is determined by the volume of the filter, which comes in two standard sizes, and so on</li>
</ul>
<p>Here is a very low-grade schema of how an oil filter is attached to a car engine: a threaded hole in the oil filter adapts to a threaded piece of metal with a hole in it that is on the external part of the engine, for easy access:</p>
<div><div><img alt="Figure 2.1 – Schematic positioning of an oil filter on a car engine" src="img/B21293_02_1.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1 – Schematic positioning of an oil filter on a car engine</p>
<p>There we <a id="_idIndexMarker053"/>have it! If we now go back to the explanation, we have modules that are so standardized that one can buy them anywhere and they will have the same interfaces, although their inner functions may be different; modules put together will each have their function but provide a higher-level, more sophisticated function to the global system they form together. A few steps more and the whole system operated by the many modules and submodules will have a complexity that could not have been addressed without this industrial approach.</p>
<p>To take another example that is more associated with our day-to-day experience, small batteries, and chargers are currently the target of a push to standardization by governments. This is particularly visible in the European Community, where USB-C has been pushed down the throat even to massive opponents such as Apple. Large companies have been using many different non-compatible connectors and chargers for decades, leading to a huge waste of electronic systems and complexity in the everyday lives of the users, forcing them to juggle many different pieces of equipment. This law is already having some results in making charging a phone less complex for the public.</p>
<p>Talking about complexity, we will have to define more precisely what is behind this term, and this is what we are going to do in the next se<a id="_idTextAnchor047"/>ction.</p>
<h1 id="_idParaDest-40"><a id="_idTextAnchor048"/>Management of complexity</h1>
<p>The word <em class="italic">complexity</em> refers<a id="_idIndexMarker054"/> to the quality of something that is composed of many different parts. It is often<a id="_idIndexMarker055"/> confused with <em class="italic">complication</em>, which brings the meaning of something hard to understand. Most information systems are complex, and how this complexity is handled can make them comp<a id="_idTextAnchor049"/>licated.</p>
<h2 id="_idParaDest-41"><a id="_idTextAnchor050"/>Different types of complexity</h2>
<p>The concept of <a id="_idIndexMarker056"/>complexity was introduced previously when talking about how to reduce it by cutting large, difficult-to-operate systems into small ones that are easier to deal with. In<a id="_idIndexMarker057"/> this section, we will come back to this concept of complexity and start by stating that there are two kinds of complexity, namely the <strong class="bold">intrinsic</strong>, functional one and the avoidable, <strong class="bold">accidental</strong> one. The first one comes from the function itself, and <a id="_idIndexMarker058"/>if a module is to provide this function, it cannot do less than this. The second one is everything that is added when implementing the function to make it operate, and that cannot be considered as purely necessary for the function itself. Of course, the whole deal will be to reduce as much as possible the second one, since the two add up and the first one cannot be reduced by definition.</p>
<p>In our example of an oil filter for a car engine, the folding of the absorbing paper inside the filter is intrinsic complexity, because the different stacks of paper and how they form a complex path for the oil are the way the filter functions, retaining the heavy metal particles in the foldings of paper, while the oil reaches the output of the filter with cleaner, purer characteristics. The metal casing of the filter, really, cannot be considered as a participant in the filtering operation. Sure – it is helpful to hold the paper sheets together and facilitate manipulation, but it does not participate in filtering: this is accidental complexity in the oil filter.</p>
<p>Information systems are filled with accidental complexity, and considering that the smallest text notes application nowadays uses thousands of lines of code and megabytes of memory, this only starts to show t<a id="_idTextAnchor051"/>he problem.</p>
<h2 id="_idParaDest-42"><a id="_idTextAnchor052"/>Computer science as a way to deal with complexity</h2>
<p>It may<a id="_idIndexMarker059"/> sound weird that complexity has reached such a level considering that computers have been designed with added productivity in mind. After all, early computers were built to strongly accelerate calculations that otherwise would take days, weeks, or even months, and required careful double-checking in order to avoid errors as much as possible. The cost of investment in creating a computer was huge due to increasing complexity at first (designing modern computers and electronic chips is one of the most complex endeavors of our civilization), but the using of the computer to quickly produce accurate results for many problems would largely pay for the investment.</p>
<p>A lot of work currently done by computers today is of a high level of technical complexity: displaying high-resolution real-time pictures from 3D modeling in games, performing long calculations such as discrete Fourier transforms or Monte Carlo simulations, and so on. Lots of these operations could not be realized with the same level of accuracy and low error level by humans or even large groups of them. Thus, we can consider IT has helped reduce<a id="_idTextAnchor053"/> complexity.</p>
<h2 id="_idParaDest-43"><a id="_idTextAnchor054"/>Information systems and complexity</h2>
<p>But at<a id="_idIndexMarker060"/> the same time, and this is particularly true for people like me who have been in the software field for more than 30 years, it just looks like computers actually did not bring the incredible functional advances that the huge increase in computing power would lead us to believe. GPUs are millions of times quicker, but games are only a few times better. Personal computers are hundreds of times more powerful, but vocal typing is still far from perfect, and word processing has basically not changed, with new features being – most of the time – useless at best, and bloatware at worst.</p>
<p>It just happens that, along with the capacity of computers, we have asked them to do more and more. And while some of these additional operations are bringing new value (optimization of mechanical models, capacity to simulate complex physical models, and so on), a lot are non-value-adding features (larger screens, infinity of nuances of colors) that really make for additional<a id="_idIndexMarker061"/> comfort but, in <strong class="bold">line-of-business</strong> (<strong class="bold">LOB</strong>) software applications, do not bring anything to the functional value.</p>
<p>To summarize, it looks very much like accidental complexity has grown almost at the same rhythm as computational power, and thus, the remaining power has brought very little performance in handling intrinsic, business-orient<a id="_idTextAnchor055"/>ed complexity.</p>
<h2 id="_idParaDest-44"><a id="_idTextAnchor056"/>The concept of “as a service”</h2>
<p>Luckily, there <a id="_idIndexMarker062"/>is also good news on the evolution of information systems, and the “as a service” approach is one such example. The “as a service” approach means that something of value is provided to the user without the material part. <strong class="bold">Infrastructure as a service</strong> (<strong class="bold">IaaS</strong>), for example, brings you memory and <a id="_idIndexMarker063"/>CPU without the hardware part of the computer; that is dealt with by someone else, generally the cloud provider. <strong class="bold">Software as a service</strong> (<strong class="bold">SaaS</strong>) provides <a id="_idIndexMarker064"/>you with working software that you can call with a simple web browser without having to worry about prerequisites, installation, purchase of licenses, and so on.</p>
<p>If we consider this approach with respect to the concepts of complexity exposed previously, we can say that the goal is to reduce accidental complexity to almost zero by providing not even the function alone but only the results of the function, which is the service requested. If almost nothing of the surrounding artifacts remains; only the outcome of the software-assisted procedure is obtained. For example, in IaaS, infrastructure as a whole is not what is needed per se by the buyer: one does not crave physical computers consuming space, needing local temperature control, racks, and so on, but has to go through this accidental complexity to obtain CPU power, RAM usage, storage space, or network bandwidth and connectivity.</p>
<p>The “as a service” concept has considerably diminished the perceived complexity of information systems. Of course, there is no free lunch, and the overall complexity is still there (it has even increased). But the separation, not modules by modules this time, but functions by functions, has established a clear cut between the high technical complexity that is handled by the provider of the service and the low complexity that remains for the user. The financial transfer from the latter to the former is explained by the fact that the user gets a great advantage of focusing only on value-adding, business-oriented complexity. How the provider of the service gains a financial interest in handling higher technical complexity (which would be accidental for a mere user, but is standard business complexity for the provider) comes from the fact that they are an expert in it, handle large volumes for many users, and apply scale-related cost savings. In the end, everyone benefits from a clear cut of complexity, which can also be described as a separation of responsibility and task specialization, which is consubstantial with industrialization, as expl<a id="_idTextAnchor057"/>ained previously.</p>
<h2 id="_idParaDest-45"><a id="_idTextAnchor058"/>Link to a minimum viable product</h2>
<p>Lots of <a id="_idIndexMarker065"/>people working with Agile methods know a famous picture illustrating<a id="_idIndexMarker066"/> the concept of a <strong class="bold">minimum viable product</strong> (<strong class="bold">MVP</strong>), from Henrik Kniberg, who created it in the mid-2010s (<a href="https://blog.crisp.se/wp-content/uploads/2016/01/mvp.png">https://blog.crisp.se/wp-content/uploads/2016/01/mvp.png</a>): it shows a first line of product evolution from a wheel to two wheels linked, then to two wheels and a body, and finally a car. During this evolution, a smiley frowns all the time and is only satisfied at the last step. In the second line of the image, the steps are replaced by a skateboard (sad smiley), then a bike (neutral smiley), followed by a motorbike (reasonably happy), and finally a convertible car (extremely happy smiley).</p>
<p>It has been studied a lot and is a great description of the concept of the evolution of a software application from MVP (the skateboard) to a full-fledged project (the car on the right). Lots of imitations do not carry as much meaning because they miss a few details. For example, some of them end up with the same car on the two lines, which is completely wrong as Kniberg purposefully showed different cars at the end of the two processes. The whole story is perfectly explained at <a href="https://blog.crisp.se/2016/01/25/henrikkniberg/making-sense-of-mvp">https://blog.crisp.se/2016/01/25/henrikkniberg/making-sense-of-mvp</a>, and I am certainly not going to paraphrase it, but rather try to make a link with what was written previously about the “as a service” approach.</p>
<p>What is the service that is talked about in that famous picture? Does it have a car? No – owning a car or driving it is merely a side-effect on the service itself, which is “going from one point to another.” Using an MVP will help us collect feedback as quickly as possible on the actual needs of the users. Now, if we go to the extreme of the “as a service” approach and consider displacement of the person (and possible luggage) as the one and only request, science-fiction-like teleportation would be absolutely perfect! And we are a bit more reasonable with possibility and price; as Kniberg says, maybe the most basic approach should be to provide the user with a bus ticket.</p>
<p>This would also be a valuable MVP, but that would be forgetting the fact that an MVP does not mean the designer does not have the final destination in mind: we provide the skateboard to collect feedback (for example, “stability is important”) while still having in mind that we want a car in the end, maybe because the initially expressed need is that of autonomous travel.</p>
<p>What is of uttermost importance – and we will come back to why the cars are not the same in the end – is that, while taking into account feedback, stability was important in this example and the design quickly evolved to a bike, which is more stable and easier to stay on. But <a id="_idIndexMarker067"/>this is not the only feedback that was received. For example, the fact that the vehicle was not covered was not really an issue, and the design evolved into a bike and then a motorbike, which has no wind or rain protection. In the end, the proposed car has no roof: not only because it is simply not requested, but because the interest in driving with hair in the wind may have arisen from the feedback loop. If one had created the car directly, maybe the customer would not have thought of an open roof. But asking for continuous feedback has shown an additional desirable feature (not a need, though, but just a “bonus”) that would have not been detected otherwise.</p>
<p>This is what companies talk about when they express their desire to “delight their customers.” Most of us engineers do not immediately get it because we tend to see problems with one optimized solution that derives from initial specifications, but the best solutions bring value to customers that they would not even have thought about initially. And guess what? Since all companies are generally good at creating the expected features, these unexpected and delightful features will be the ones your customers will use to differentiate your service from your competitors!</p>
<p>Now that the concept of complexity should be clear, we will propose a first approach <a id="_idTextAnchor059"/>to how to reduce it.</p>
<h1 id="_idParaDest-46"><a id="_idTextAnchor060"/>The benefits of standards and norms</h1>
<p>The first section of this chapter, <em class="italic">What is an industry?</em>, started talking about standardization and how it is essential for modularization to make sense. Let’s imagine the contrary and a<a id="_idIndexMarker068"/> system that has been arbitrarily cut into several smaller ones, without reflection on the way to define these parts, how they interact, and how they each can be replaced by improved versions. The result would be that modules could not be designed without knowing the whole and could not be replaced by existing modules since the way they are glued to the rest would not already exist. At best, this would only make the whole problem a bit easier to address; at worst, the added difficulty of putting everything back together would largely overcome the reduction of complexity with respect to addressing the whole system at once.</p>
<p>This is the reason why the cutting interfaces of the modules and their standardization are so important, and why we will dedicate the next section to stressing this with<a id="_idTextAnchor061"/> additional examples.</p>
<h2 id="_idParaDest-47"><a id="_idTextAnchor062"/>Docker, containers, and OCI</h2>
<p>The <strong class="bold">Docker</strong> technology<a id="_idIndexMarker069"/> is a great way to talk about norms and standards because its very name starts with a metaphor for an industrial concept that prospered through standardization, namely freight and shipping containers.</p>
<p>Until the 1950s, freight transportation was not standardized at all, and filling a ship with freight was quite a craftsmanship: packages came in all sizes and weights, some of them being soft, some of them being hard. The way to bind them together so that they did not move during transportation was customized at every different shipping. It was extremely hard to correctly fill a vehicle since there was little chance all packages would fit nicely to occupy all space while keeping fragile and lightweight packages at the top and heavy, solid ones at the bottom. If you then add the problems of load balance, humidity, or temperature effects that could transmit from one package to another, and the occasional last-minute package that was too heavy to put on top of the other ones and forced the dockers to unload part of the shipment and rearrange everything, you start to get an understanding of what a complicated job freight shipping was at that time.</p>
<p>Meet Malcolm McLean, who devised in 1956 a shipping system based on wood boxes that could be easily transferred from trucks to trains and boats. After only 10 years, in 1967, this great idea was used so much that the <strong class="bold">International Organization for Standardization</strong> (<strong class="bold">ISO</strong>) defined <a id="_idIndexMarker070"/>three standard sizes of “containers.” Despite road/train/sea transportation activities being a huge, worldwide business, after only a few decades, virtually every operator on earth uses standard-sized metal containers that allow optimization of the whole logistics chain <a id="_idIndexMarker071"/>and have the following benefits:</p>
<ul>
<li><strong class="bold">Ease of loading</strong>: Any expediter can get their hands on a container and load it at their own rhythm, then contact a transporter and have them carry the container, without any risk of refuse because they cannot take care of a particular shape.</li>
<li><strong class="bold">Improvement in the handling of goods</strong>: Since the metal boxes have standardized sizes and corners with handling holes, there is no use anymore in changing manipulation tools that are needed to press the package (and potentially break its content). Now, the prehensile tools simply lock the four corners<a id="_idIndexMarker072"/> of the container and lift them. The speed of handling is also improved as there is no need to handle different packages one by one: the machines lift a container – that carries many different packages inside – as a single unit.</li>
<li><strong class="bold">Optimized storage</strong>: Industrial containers are plain, parallelepiped-shaped boxes. Their stacking wastes almost no place but the width of the walls. Today, large ships are sized around containers for size optimization.</li>
<li><strong class="bold">Interchangeable material</strong>: Containers have become such commodities that there is almost no question of property. A container can be easily repaired or replaced by another. A container basically never travels empty. Some of them have traveled several times around the world without their initial buyer seeing them again.</li>
</ul>
<p>The Docker name and logo clearly state the philosophy behind the technology: the term <em class="italic">docker</em> refers to the job of loading freight on ships, and Docker’s logo shows a whale carrying containers on its back. The link is quite obvious to the transportation business, and the company wants to become the equivalent of industrial containers for application shipping.</p>
<p>Just as with industrial shipping containers, Docker containers provide standard-based advantages:</p>
<ul>
<li>Whatever is inside the container (Java process, .NET web, Python script, NodeJS API, and so on), the external interface is exactly the same, and one can simply type <code>docker run</code> and have the container up and running.</li>
<li>Once put inside a Docker image, an application can be shipped to any place on the planet through registries and it will be executed in the same manner, whichever country it is used in.</li>
<li><strong class="bold">Independence from the underlying architecture</strong>: Docker containers do not know or care whether they are operated on a Windows machine, a Linux server, or even a Kubernetes cluster. Since they have a standard size, they can fit anywhere.</li>
</ul>
<p>With all these nice features, Docker quickly became the de facto standard for application <a id="_idIndexMarker073"/>deployment. Docker itself could even have become the definitive standard, but there were a few shortcomings, and a higher-level, more widespread standard appeared a few years later: <strong class="bold">Open Container Initiative</strong> (<strong class="bold">OCI</strong>) created a <a id="_idIndexMarker074"/>low-denominator, but undeniable standard that every container technology (Docker, but also other technologies, though less known) adheres to.</p>
<p>Containers have undoubtedly industrialized and strongly improved the way applications are deployed. The rise of microservices is strongly related to container technologies since the deployment of numerous small applications would have been extremely complicated with the old approach of manually setting up dependencies and resources for each application. Some even say microservices architecture appeared only because Docker allowed them to exist.</p>
<p>Docker is an example of how a technology that normalizes a given software-related function (in this case, application deployment) can have a huge impact and replace, through a single standardized approach, loads of proprietary, manual approaches. But this is not the only time this <a id="_idTextAnchor063"/>happened in the industry...</p>
<h2 id="_idParaDest-48"><a id="_idTextAnchor064"/>Another example with IAM</h2>
<p><strong class="bold">Identity and access management</strong> (<strong class="bold">IAM</strong>) is<a id="_idIndexMarker075"/> another field of IT where normalization has brought a great deal of help and positively changed<a id="_idIndexMarker076"/> a difficult situation in the last decades. Remember when each and every software application had its own user management and passwords? Let alone different, not compatible, ways of handling groups and authorization management, and so on. Such a mess... Everyone in the field was glad when the first <a id="_idIndexMarker077"/>approaches of <strong class="bold">single sign-on</strong> (<strong class="bold">SSO</strong>) appeared, and <a id="_idIndexMarker078"/>the <strong class="bold">Central Authentication Service</strong> (<strong class="bold">CAS</strong>) implemented it in readily available software. Identity and authentication providers made the field more complex to grasp for beginners, but avoided hundreds of thousands of badly-designed IAM systems, replacing them with online, always-accessible identities.</p>
<p><strong class="bold">Security Assertion Markup Language</strong> (<strong class="bold">SAML</strong>) quickly <a id="_idIndexMarker079"/>became a standard, and tools such as Shibboleth help diffuse the capacity of handling <a id="_idIndexMarker080"/>in a correct, open source, manner. More recently, <strong class="bold">OpenID Connect</strong> (<strong class="bold">OIDC</strong>), OAuth 2.0, <strong class="bold">JSON Web Token</strong> (<strong class="bold">JWT</strong>), and other standardized <a id="_idIndexMarker081"/>approaches basically killed any discussion on the best way to identify, authenticate, and authorize accounts, accounting for new features that needed to be taken into account and now covering virtually any needs in the field. Keycloak is a<a id="_idIndexMarker082"/> production-ready, standard-based, open source application that can act as the glue between standards, which means we now have all the tools to really deal with IAM in a standard way. The benefits are such that companies not using these approaches yet will be obliged in the next years to take steps to do so, as security issues are going to make it mandatory to stop trying to deal with IAM on proprietary, fragile implementations.</p>
<p>There again, the function of IAM has become a commodity owing to standards and an industrial approach of separating modules, each of them with its own responsibility:</p>
<ul>
<li>Identification deals with who the accounts and individual owners of accounts are, with all associated<a id="_idIndexMarker083"/> metadata. <strong class="bold">Lightweight Directory Access Protocol</strong> (<strong class="bold">LDAP</strong>) and <strong class="bold">LDAP Data Interchange Format</strong> (<strong class="bold">LDIF</strong>) come <a id="_idIndexMarker084"/>to mind as standards for this responsibility, but <strong class="bold">System for Cross-domain Identity Management</strong> (<strong class="bold">SCIM</strong>) also can be used, as well as extensions <a id="_idIndexMarker085"/>such as SCIM Enterprise Profile to incorporate organizational charts, for example. JWTs can be used to carry this data in a normalized way.</li>
<li>Authentication<a id="_idIndexMarker086"/> is about proving the identity of accounts. OIDC, of course, comes to mind, but <strong class="bold">Fast IDentity Online</strong> (<strong class="bold">FIDO</strong>) and <strong class="bold">Universal 2nd Factor</strong> (<strong class="bold">U2F</strong>) are<a id="_idIndexMarker087"/> standards related to authentication as well, introducing physical devices to improve authentication management.</li>
<li>Authorization is – once identity is established with proof of authentication – the way to deal with what the person is allowed to do in the software (or, otherwise, remembering that information systems are mostly, but not only, about software). <strong class="bold">eXtensible Access Control Markup Language</strong> (<strong class="bold">XACML</strong>) is an <a id="_idIndexMarker088"/>XML-based norm for this, but there exist<a id="_idIndexMarker089"/> also more recent approaches such as <strong class="bold">Open Policy </strong><strong class="bold">Agent</strong> (<strong class="bold">OPA</strong>).</li>
</ul>
<p>In conclusion, IAM is another example of how information systems have positively evolved once the <a id="_idIndexMarker090"/>recipe of industrialization has been applied: dividing this complex subject into clear-cut, separate responsibilities, and then applying norms and standards to each of them.</p>
<p>The last part of this chapter will make an analogy with other systems that may be highly complex and use lots of standards, namely the cities in which lots of us live. And I am not talking about smart cities, where software serves urban management, but just citie<a id="_idTextAnchor065"/>s in their organization emerging over time.</p>
<h1 id="_idParaDest-49"><a id="_idTextAnchor066"/>The urbanism metaphor of information systems</h1>
<p>Why did I spend<a id="_idIndexMarker091"/> so much time and use so much text talking about technologies that became standards and had a great impact on the ease of <a id="_idIndexMarker092"/>use and capacity of the evolution of information systems inside of which they are used? Well, because what has been done for application deployment and IAM can be done for any function in a software system. There may not be an undeniable, internationally approved standard behind every functionality you need to operate in your system, but deploying a locally approved standard will provide the exact same benefits inside the perimeter of your own information system.</p>
<p>This approach of industrializing an information system by cutting it into zones and standardizing the interfaces between them is the best approach to keep it in a functional state of health over time. Depending on the context, you may hear about “business/IT alignment,” “enterprise architecture,” or “urbanization of information systems.” The third expression refers to a metaphor where the information system is compared to a modern city:</p>
<ul>
<li><strong class="bold">The organization follows hierarchical zoning</strong>: Large zones are dedicated to housing, commerce, or industry. Inside these zones, one will find neighborhoods that define a smaller portion of the zone. Finally, blocks articulate buildings together inside a neighborhood. One will find the same hierarchy inside a well-groomed information system with large business domain zones (for example, administration), inside of which specialized direction will appear (let’s say human resources), and finally blocks of functions (in our example, hiring management).</li>
<li><strong class="bold">Fluids are standardized for a city to operate correctly</strong>: If firefighters had to adapt<a id="_idIndexMarker093"/> to different pipe diameters in different parts of the city, there would, of course, be a problem. The same goes for electricity, water, waste pipes, and so on. That may sound crazy today since all this has been perfectly normalized for decades, but at the beginning of the 20th century, a city such as Paris had several different electricity companies, some of them<a id="_idIndexMarker094"/> operating 110 volts, some 220 volts, some in <strong class="bold">alternating current</strong> (<strong class="bold">AC</strong>), some in <strong class="bold">constant current</strong> (<strong class="bold">CC</strong>), some<a id="_idIndexMarker095"/> at 50 Hz, some at 60 Hz, and most of them with different plug formats.</li>
<li>A large<a id="_idIndexMarker096"/> city always evolves, and work in progress in the east of the city is meant to have as little impact on the life of inhabitants of the west side. The same goes for information systems where change is the only constant, and the impact on one piece should be as much as possible without impact on other applications. Town architects provide a global vision and direction of evolution but the day-to-day changes of the city are organic and can happen because of normalization. Well-established information systems can do the same.</li>
</ul>
<p>Sadly, it seems that enterprise architecture is not very widespread. This partly comes from the fact that this is a complex activity; but it also comes from a lack of knowledge and information spread, against which this book proposes to humbly provide a remedy. I will try in the next chapters to show that industrial and standardization approaches in information systems can bring a lot of value and radically reduce stiffness and difficulty to evolve for most information systems and that the knowledge and practices to reach this are far from b<a id="_idTextAnchor067"/>eing as complicated, as most IT architects think.</p>
<h1 id="_idParaDest-50"><a id="_idTextAnchor068"/>Summary</h1>
<p>This chapter explained at length the concepts of industrialization and standardization and then explained how they can be applied to the field of software and computer science. Lots of information systems nowadays have difficulty evolving, as stated in the previous chapter, and industrialization, though a recent field in computer science, is a way to strongly improve their efficiency.</p>
<p>In the next chapter, we are going to get a bit more practical, starting from the – admittedly theoretical – material in this chapter, and explain methods to put the industrial approach in place in information systems. The most known approach that will be presented is called “business/IT alignment.” In a few words, it states that the structure of IT must reflect the structure of the business processes the information system is there to help.</p>
</div>
</body></html>