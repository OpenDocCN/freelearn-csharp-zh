<html><head></head><body>
<div><h1 class="chapterNumber">21</h1>
<h1 class="chapterTitle" id="_idParaDest-433">Case Study</h1>
<p class="normal">As mentioned during the previous chapters, for this new edition, we reformulated the way we present the case study of the book – <strong class="keyWord">World Wild Travel Club</strong> (<strong class="keyWord">WWTravelClub</strong>). This case study will take you through the process of creating the software architecture for a travel agency.</p>
<p class="normal">The purpose of this case study is not to furnish a production-ready application, but just to help you understand the theory explained in each chapter and to provide an example of how to develop an enterprise application with Azure, Azure DevOps, C# 12, .NET 8, ASP.NET Core, and all other technologies introduced in this book.</p>
<p class="normal">Let’s start with a description of what our case study application is. Then, we will gradually move to formal specifications.</p>
<h1 class="heading-1" id="_idParaDest-434">Introducing World Wild Travel Club</h1>
<p class="normal">WWTravelClub is a travel agency <a id="_idIndexMarker1547"/>that was created to revolutionize vacation planning and travel experiences globally. To do so, they are developing an online service, where each aspect of a trip is meticulously curated and supported by a dedicated team of destination-specific experts.</p>
<p class="normal">The concept of this platform is that you can be both a visitor and a destination expert at the same time. The more you participate as an expert in a destination, the more points you score. These points can then be redeemed for tickets that people buy online using the platform.</p>
<p class="normal">The responsible for the WWTravelClub project came with the following requirements list for the platform:</p>
<ul>
<li class="bulletList">Common user view:<ul>
<li class="bulletList">Promotional packages on the home page</li>
<li class="bulletList">Get a recommendation</li>
<li class="bulletList">Search for packages</li>
<li class="bulletList">Details for each package:<ul>
<li class="bulletList">Buy a package</li>
<li class="bulletList">Buy a package with a club of experts included</li>
<li class="bulletList">Comment on your experience</li>
<li class="bulletList">Ask an expert</li>
<li class="bulletList">Evaluate an expert</li>
<li class="bulletList">Register as a common user</li>
</ul>
</li>
</ul>
</li>
<li class="bulletList">Destination expert view:<ul>
<li class="bulletList">The same view as the common user view</li>
<li class="bulletList">Answer questions asking for your destination expertise</li>
<li class="bulletList">Manage the points you scored by answering questions</li>
<li class="bulletList">Exchange points for tickets</li>
</ul>
</li>
<li class="bulletList">Administrator view:<ul>
<li class="bulletList">Manage <a id="_idIndexMarker1548"/>packages</li>
<li class="bulletList">Manage common users</li>
<li class="bulletList">Manage destination experts</li>
</ul>
</li>
</ul>
<p class="normal">Besides the functionalities asked for on the platform, it is important to note that WWTravelClub intends to have more than 100 destination experts per package and will offer around 1,000 different packages all over the world.</p>
<p class="normal">It is important to know that, in general, customers do not bring the requirements ready for development. That is why the process of gathering requirements is so important, as described in <em class="italic">Chapter 1, Understanding the Importance of Software Architecture</em>. This process will transform the list presented above into user needs and system requirements. Let’s check how this will work in the next section.</p>
<h1 class="heading-1" id="_idParaDest-435">User needs and system requirements</h1>
<p class="normal">As presented in <em class="italic">Chapter 1, Understanding the Importance of Software Architecture</em>, to summarize the user needs, you may use the User Story pattern. We have used this approach here so that you <a id="_idIndexMarker1549"/>can read the following user stories for WWTravelClub:</p>
<ul>
<li class="bulletList"><code class="inlineCode">US_001</code>: As a common user, I want to view promotional packages on the home page so that I can easily find my next vacation.</li>
<li class="bulletList"><code class="inlineCode">US_002</code>: As a common user, I want to search for packages I cannot find on the home page so that I can explore other trip opportunities.</li>
<li class="bulletList"><code class="inlineCode">US_003</code>: As a common user, I want to see the details of a package so that I can decide which package to buy.</li>
<li class="bulletList"><code class="inlineCode">US_004</code>: As a common user, I want to register myself so that I can start buying the package.</li>
<li class="bulletList"><code class="inlineCode">US_005</code>: As a registered user, I want to process the payment so that I can buy a package.</li>
<li class="bulletList"><code class="inlineCode">US_006</code>: As a registered user, I want to buy a package with an expert recommendation included so that I can have an exclusive trip experience.</li>
<li class="bulletList"><code class="inlineCode">US_007</code>: As a registered user, I want to ask for an expert so that I can find out the best things to do on my trip.</li>
<li class="bulletList"><code class="inlineCode">US_008</code>: As a registered user, I want to comment on my experience so that I can give feedback on my trip.</li>
<li class="bulletList"><code class="inlineCode">US_009</code>: As a registered user, I want to review an expert who has helped me so that I can share with others how fantastic they were.</li>
<li class="bulletList"><code class="inlineCode">US_010</code>: As a registered user, I want to register as a destination expert view so that I can help people who travel to my city.</li>
<li class="bulletList"><code class="inlineCode">US_011</code>: As an expert user, I want to answer questions about my city so that I can score points to be exchanged in the future.</li>
<li class="bulletList"><code class="inlineCode">US_012</code>: As an expert user, I want to exchange points for tickets so that I can travel around the world more.</li>
<li class="bulletList"><code class="inlineCode">US_013</code>: As an administrator user, I want to manage packages so that users can have fantastic opportunities to travel.</li>
<li class="bulletList"><code class="inlineCode">US_014</code>: As an administrator user, I want to manage registered users so that WWTravelClub can guarantee good service quality.</li>
<li class="bulletList"><code class="inlineCode">US_015</code>: As an administrator user, I want to manage expert users so that all the questions regarding our destinations are answered.</li>
<li class="bulletList"><code class="inlineCode">US_016</code>: As an administrator user, I want to offer more than 1,000 packages around the world so that different countries can experience the WWTravelClub service.</li>
<li class="bulletList"><code class="inlineCode">US_017</code>: As the CEO, I want to have more than 1,000 users simultaneously accessing the website so that the business can scale effectively.</li>
<li class="bulletList"><code class="inlineCode">US_018</code>: As a user, I want to access WWTravelClub in my native language so that I can easily understand the package offered.</li>
<li class="bulletList"><code class="inlineCode">US_019</code>: As a user, I want to access WWTravelClub in the Chrome, Firefox, and Edge web browsers so that I can use the web browser of my preference.</li>
<li class="bulletList"><code class="inlineCode">US_020</code>: As a user, I want to know that my credit card information is stored securely, so I can buy packages safely.</li>
<li class="bulletList"><code class="inlineCode">US_021</code>: As a user, I want to get a recommendation of a good place to visit according to other people from my city, so I can find out about new places that fit my style.</li>
</ul>
<p class="normal">Notice that while <a id="_idIndexMarker1550"/>writing the stories, information related to non-functional requirements such as security, environment, performance, and scalability can be included.</p>
<p class="normal">However, some system requirements may be omitted when you write user stories and need to be included in the software specification. These requirements can be related to legal aspects, hardware, and software prerequisites, or even points of attention for the correct system delivery. We discussed them in <em class="italic">Chapter 2, Non-Functional Requirements</em>. So non-functional requirements need to be mapped and listed, as well as the user stories. The WWTravelClub system requirements are presented in the following list. Note that requirements are written in the future tense because the system does not exist yet:</p>
<ul>
<li class="bulletList"><code class="inlineCode">SR_001</code>: The system shall use cloud computing components to deliver the scalability required.</li>
<li class="bulletList"><code class="inlineCode">SR_002</code>: The system shall<a id="_idIndexMarker1551"/> respect <strong class="keyWord">General Data Protection Regulation</strong> (<strong class="keyWord">GDPR</strong>) requirements.</li>
<li class="bulletList"><code class="inlineCode">SR_003</code>: Any web page of this system shall respond within at least 2 seconds of 1,000 users accessing it concurrently.</li>
</ul>
<p class="normal">The idea of having this list of user stories and system requirements is to help you understand how complex the development of a platform might be if you think about it from an architectural perspective.</p>
<p class="normal">Now that we have the list of user stories for the platform, it is time to start selecting the .NET project<a id="_idIndexMarker1552"/> types that will be used at WWTravelClub. Let’s check them in the next topic.</p>
<h1 class="heading-1" id="_idParaDest-436">Main types of .NET projects used at WWTravelClub</h1>
<p class="normal">The development of this book’s use case will be based on various kinds of .NET Core Visual Studio projects. This <a id="_idIndexMarker1553"/>section describes all of them. Let us select <strong class="keyWord">New project</strong> in the Visual Studio <strong class="keyWord">File</strong> menu.</p>
<p class="normal">For instance, you can filter <strong class="keyWord">.NET Core </strong>project types by typing them into the search engine as follows:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_01.png"/></figure>
<p class="packt_figref">Figure 21.1: Searching types of .NET Core projects in Visual Studio</p>
<p class="normal">There, you will find common C# projects (console, a class library, Windows Forms, and WPF), and various types of test projects, each based on a different test framework: xUnit, NUnit, and MSTest. Choosing among the various testing frameworks is just a matter of preference since they all offer comparable features. Adding tests to each piece of software that composes a solution is a common practice and allows the software to be modified frequently without jeopardizing its reliability.</p>
<p class="normal">You may also want to define your class library projects under <strong class="keyWord">.NET Standard</strong>, which was discussed in <em class="italic">Chapter 5</em>,<em class="italic"> Implementing Code Reusability in C# 12</em>. These class libraries are based on standards that make<a id="_idIndexMarker1554"/> them compatible with several .NET versions. For instance, libraries based on 2.0 standards are compatible with all .NET Core versions greater than or equal to 2.0, with all .NET versions greater than 5, and with all .NET Framework versions greater than 4.6. This compatibility advantage comes at the price of having fewer available features.</p>
<p class="normal">Besides filtering <strong class="keyWord">project types</strong> to the <strong class="keyWord">cloud</strong>, we have several more project types. Some of them will enable us to define microservices. Microservice-based architectures allow an application to be split into several independent microservices. Several instances of the same microservice can be created and distributed across several machines to fine-tune the performance of each application part. If you want to learn about microservices, we have talked about them in the following chapters:</p>
<ul>
<li class="bulletList"><em class="italic">Chapter 11</em>,<em class="italic"> Applying a Microservice Architecture to Your Enterprise Application</em></li>
<li class="bulletList"><em class="italic">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET</em></li>
<li class="bulletList"><em class="italic">Chapter 20</em>, <em class="italic">Kubernetes</em></li>
</ul>
<p class="normal">In <em class="italic">Chapter 2</em>, <em class="italic">Non-Functional Requirements</em>, we described an ASP.NET Core application project in the subsection <em class="italic">Creating a scalable web app with .NET 8</em>. There, we defined an ASP.NET Core application, but Visual Studio also contains project templates for projects based on RESTful APIs and the most important single-page application frameworks, such as Angular, React, Vue.js, and the Blazor framework based on WebAssembly, which was discussed in <em class="italic">Chapter 19</em>,<em class="italic"> Client Frameworks: Blazor</em>. Some of them are available with the standard Visual Studio installation, while others require the installation of an SPA package, called <strong class="keyWord">ASP.NET and web development</strong> workload.</p>
<div><p class="normal">To finish, testing projects were discussed in detail in <em class="italic">Chapter 9</em>,<em class="italic"> Testing Your Enterprise Application</em>. We suggest you, as a software architect, try all the templates available at Visual Studio by creating<a id="_idIndexMarker1555"/> proofs of concept that may help you define the best project types for your solution.</p>
</div>
<p class="normal">Now that we have checked these different project types, let’s have a look at Azure DevOps and how it can be helpful in managing WWTravelClub is requirements.</p>
<h1 class="heading-1" id="_idParaDest-437">Managing WWTravelClub’s requirements using Azure DevOps</h1>
<p class="normal">As discussed in <em class="italic">Chapter 3, Managing Requirements</em>, an important step for a software development project is where and <a id="_idIndexMarker1556"/>how the team will organize the user stories mapped<a id="_idIndexMarker1557"/> from the user needs. There, as described in the <em class="italic">Managing system requirements in Azure DevOps</em> section, Azure DevOps enables you to document system requirements using work items, which are mainly tasks or actions that need to be completed to deliver a product or service.</p>
<p class="normal">It is also important to remember that the work items available depend on the <em class="italic">work item process</em> you select while creating the Azure DevOps project.</p>
<p class="normal">Considering the scenario described for WWTravelClub, we decided to use the Agile process and have defined three Epic work items as follows:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_02.png"/></figure>
<p class="packt_figref">Figure 21.2: User case Epics</p>
<p class="normal">The creation of these work items is quite simple:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Inside each work item, we<a id="_idIndexMarker1558"/> link the different types of work items, as you can see in <em class="italic">Figure 21.3</em>.</li>
<li class="numberedList">It is important to <a id="_idIndexMarker1559"/>determine that the connections between work items are useful during software development. Hence, as a software architect, you must provide this knowledge to your team, and, more than that, you must incentivize them to make these connections:</li>
</ol>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_03.png"/></figure>
<p class="packt_figref">Figure 21.3: Defining a Feature link to the Epic selected</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="3">As soon as you <a id="_idIndexMarker1560"/>create a <strong class="screenText">Feature</strong> work item, you will be able to connect it to several<a id="_idIndexMarker1561"/> User Story work items that detail its specifications. The following screenshot shows the details:</li>
</ol>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_04.png"/></figure>
<p class="packt_figref">Figure 21.4: Product Backlog work item</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="4">After that, Task and Test Case work items can be created for each User Story work item. The <a id="_idIndexMarker1562"/>user interface provided by Azure<a id="_idIndexMarker1563"/> DevOps is efficacious because it enables you to track the chain of functionalities and the relationships between them.</li>
</ol>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_05.png"/></figure>
<p class="packt_figref">Figure 21.5: Board view</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="5">Considering we are using Scrum as the basis for the Agile process, as soon as you complete the input for the User Story and Task work items, you will be able to plan the project sprints together with your team. The plan view enables you to drag and drop User Story work items to each planned sprint/iteration:</li>
</ol>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_06.png"/></figure>
<p class="packt_figref">Figure 21.6: Backlogs view</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="6">By clicking on a<a id="_idIndexMarker1564"/> specific sprint on the right, you will see just the work items assigned to that <a id="_idIndexMarker1565"/>sprint. Each sprint page is quite like the backlog page but contains more tabs, where you can define <strong class="screenText">Sprint Period</strong> and <strong class="screenText">Team Capacity</strong>, for instance.</li>
</ol>
<figure class="mediaobject"><img alt="Interface gráfica do usuário, Aplicativo  Descrição gerada automaticamente" src="img/B19820_21_07.png"/></figure>
<p class="packt_figref">Figure 21.7: Planning view</p>
<p class="normal">Also useful is the <strong class="screenText">Sprints</strong> menu on the left, which enables each user to jump immediately to the current sprints of all the projects they are engaged in.</p>
<p class="normal">This is how these work items are created. Once you understand this mechanism, you will be able to create and plan any software project. It is worth mentioning that the tool itself will not solve problems related to team management. However, the tool is a great way to incentivize the team to<a id="_idIndexMarker1566"/> update the project status, so you can maintain a clear perspective of how<a id="_idIndexMarker1567"/> the project is evolving.</p>
<p class="normal">Now that we have defined how we will manage WWTravelClub requirements, it is time to start thinking about the code standard that will be followed by the developers. Let’s check this out in the next section.</p>
<h1 class="heading-1" id="_idParaDest-438">Code standard for WWTravelClub – Dos and don’ts when writing code</h1>
<p class="normal">In <em class="italic">Chapter 4, Best Practices in Coding C# 12</em>, we learned that, as a software architect, you must define a code standard that matches the needs of the company you are working for.</p>
<p class="normal">In the sample project of this<a id="_idIndexMarker1568"/> book, this is no different. The way we decided to present the standard for it is by describing a list of dos and don’ts. We have followed this list while writing the samples we produced. It is worth mentioning that the list is a good way to start your standard and, as a software architect, you should discuss this list with the developers you have in the team so that you can develop it in a practical and good manner.</p>
<p class="normal">It is also important to remember that, in the <em class="italic">Understanding and applying tools that can evaluate C# code</em> section of <em class="italic">Chapter 4, Best Practices in Coding C#12</em>, we have discussed some good tools that can help you define a <em class="italic">coding style </em>for your team<em class="italic">.</em></p>
<p class="normal">In addition, the statements below are designed to clarify the communication between team members and improve the performance and maintenance of the software you are developing.</p>
<p class="normal">You may consider the list below a waste of space in the book since we have great C# community coding standards without the need to enforce a standard. However, how can you guarantee maintainability without it? If defining coding standards was not necessary, we wouldn’t have <a id="_idIndexMarker1569"/>so many projects with maintenance issues. So, let’s check the list of dos and don’ts defined for the WWTravelClub project:</p>
<ul>
<li class="bulletList">DO write your code in English.</li>
<li class="bulletList">DO use PascalCasing for all public member, type, and namespace names consisting of multiple words.</li>
<li class="bulletList">DO use camelCasing for parameter names.</li>
<li class="bulletList">DO write classes, methods, and variables with understandable names.</li>
<li class="bulletList">DO comment public classes, methods, and properties.</li>
<li class="bulletList">DO use the <code class="inlineCode">using</code> statement whenever possible.</li>
<li class="bulletList">DO use <code class="inlineCode">async</code> implementation whenever possible.</li>
<li class="bulletList">DON’T write empty <code class="inlineCode">try-catch</code> statements.</li>
<li class="bulletList">DON’T write methods with a cyclomatic complexity score of more than 10.</li>
<li class="bulletList">DON’T use <code class="inlineCode">break</code> and <code class="inlineCode">continue</code> inside <code class="inlineCode">for/while/do-while/foreach</code> statements.</li>
</ul>
<p class="normal">These dos and don’ts are simple to follow and, better than that, will yield great results for the code your team produces. It is worth mentioning that these DOs and DON’Ts are a guide, not a set of hard-and-fast rules to be followed by every team. They can be adapted as needed for the specific needs of a team before they are sent out to the team members. As a software architect, it is essential that all team members follow the same DOs and DON’Ts.</p>
<p class="normal">Considering we now have a coding standard defined, let’s learn how to apply SonarCloud as a tool for helping us in code analysis.</p>
<h1 class="heading-1" id="_idParaDest-439">Applying SonarCloud to WWTravelClub APIs</h1>
<p class="normal">Now that we have already<a id="_idIndexMarker1570"/> created the WWTravelClub repository, we can Improve the code quality, as discussed in <em class="italic">Chapter 4, Best Practices in Coding C# 12</em>. As we<a id="_idIndexMarker1571"/> saw in that chapter, Azure DevOps enables continuous integration, and this can be useful. In this section, we will discuss more reasons why the DevOps concept and the Azure DevOps platform are so useful.</p>
<p class="normal">For now, the only thing we would like to introduce is the possibility of analyzing code after it is committed by the developers but before it has been published. Nowadays, in a SaaS world for application life cycle tools, this is only possible because of some of the SaaS code analysis platforms that we have. This use case will use SonarCloud.</p>
<p class="normal">SonarCloud is the SaaS version provided by Sonar. Also, it might be worth noting that SonarCloud is exceptionally easy to self-host; this way, sensitive security information may be kept within an enterprise. It is free for open-source code and can analyze code stored in GitHub, Bitbucket, and<a id="_idIndexMarker1572"/> Azure DevOps. The user needs a registration for these platforms. As soon as you log in, assuming your code is stored in <a id="_idIndexMarker1573"/>Azure DevOps, you can follow the steps described in the following article to create a connection between your <a id="_idIndexMarker1574"/>Azure DevOps and SonarCloud: <a href="https://docs.sonarcloud.io/">https://docs.sonarcloud.io/</a>.</p>
<div><p class="normal">Sonar also provides a self-managed edition that can be useful for scenarios where SonarCloud cannot be used. Please check <a href="https://www.sonarsource.com/">https://www.sonarsource.com/</a> for more details.</p>
</div>
<p class="normal">After setting up the connection between your project in Azure DevOps and SonarCloud, you will have a build pipeline like the one that follows:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_08.png"/></figure>
<p class="packt_figref">Figure 21.8: SonarCloud configuration in the Azure build pipeline</p>
<p class="normal">It is worth mentioning that C# projects do not have a GUID number, and this is required by SonarCloud. You can easily <a id="_idIndexMarker1575"/>generate one using this link: <a href="https://www.guidgenerator.com/">https://www.guidgenerator.com/</a>, or using the <strong class="keyWord">Create GUID</strong> tool in Visual <a id="_idIndexMarker1576"/>Studio (<strong class="screenText">Tools</strong> -&gt; <strong class="screenText">Create GUID</strong>). The GUID will need to be placed as in the following screenshot:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_09.png"/></figure>
<p class="packt_figref">Figure 21.9: SonarCloud project GUID</p>
<p class="normal">As soon as you finish the build, the result of the code analysis will be presented in SonarCloud, as can be seen in the following screenshot. If you want to navigate to this project, you can visit <a href="https://sonarcloud.io/summary/overall?id=gabrielbaptista_wwtravelclub-4th">https://sonarcloud.io/summary/overall?id=gabrielbaptista_wwtravelclub-4th</a>:</p>
<figure class="mediaobject"><img alt="Tela de computador com jogo  Descrição gerada automaticamente" src="img/B19820_21_10.png"/></figure>
<p class="packt_figref">Figure 21.10: SonarCloud results</p>
<p class="normal">Also, by this time, the code analyzed is not yet in the release, so this can be useful for getting the next step of<a id="_idIndexMarker1577"/> quality before releasing your system. You can use this approach as a reference for automating code analysis during committal.</p>
<p class="normal">Considering we have<a id="_idIndexMarker1578"/> implemented a way to continuously evaluate code quality, it is time to design reusable software. Let’s look at this in the next section.</p>
<h1 class="heading-1" id="_idParaDest-440">Reusing code as a fast way to deliver good and safe software</h1>
<p class="normal">As we checked in <em class="italic">Chapter 5, Implementing Code Reusability in C# 12</em>, a good approach for accelerating the delivery of good software is creating reusable components. The final design of the solution for <a id="_idIndexMarker1579"/>evaluating content for WWTravelClub can be checked in the diagram below. This approach consists of using many topics that were discussed in that chapter. First, all the code is placed in a .NET 8 class library. This means that you can add this code to different types of solutions, such as ASP.NET Core web apps and Xamarin apps for the Android and iOS platforms:</p>
<figure class="mediaobject"><img alt="Diagrama  Descrição gerada automaticamente" src="img/B19820_21_11.png"/></figure>
<p class="packt_figref">Figure 21.11: WWTravelClub reuse approach</p>
<p class="normal">This design makes use<a id="_idIndexMarker1580"/> of object-oriented principles such as inheritance, so you do not need to write properties and methods more than once that can be used in many classes. The design also makes use of the polymorphism principle so that you can change the behavior of the code without changing the name of the method.</p>
<p class="normal">To finish, the design abstracts the idea of the content by introducing generics as a tool that can facilitate the manipulation of similar classes, such as the ones we have in WWTravelClub, to evaluate content regarding cities, comments, destination experts, and travel packages.</p>
<p class="normal">The big difference between a team that incentivizes code reuse and one that does not is the velocity of delivering good software to end users. Of course, beginning this approach is not easy, but rest assured that you will get good results after some time working with it.</p>
<p class="normal">Since we have covered the<a id="_idIndexMarker1581"/> possibilities of code reuse using object-oriented principles, what about organizing the application using domains created by <strong class="keyWord">domain-driven design</strong> (<strong class="keyWord">DDD</strong>)? We will check it in the next section.</p>
<h1 class="heading-1" id="_idParaDest-441">Understanding the domains of the WWTravelClub application</h1>
<p class="normal">In this section we will perform the<a id="_idIndexMarker1582"/> DDD analysis of the WWTravelClub system, trying to identify all its domains (also called<strong class="keyWord"> bounded contexts</strong>), that is, the subsystems characterized by different languages<a id="_idIndexMarker1583"/> used by the experts. Once identified, each domain might be assigned to a different development team and will give rise to a different microservice.</p>
<p class="normal">From the requirements listed in the <em class="italic">Introducing World Wild Travel Club</em> and <em class="italic">U</em><em class="italic">ser needs and system requirements</em> sections, we know that the WWTravelClub system is composed of the following parts:</p>
<ul>
<li class="bulletList">Information about the available destinations and packages.</li>
<li class="bulletList">Reservation/purchase orders subsystem.</li>
<li class="bulletList">Communication with the experts/review subsystem.</li>
<li class="bulletList">Payment subsystem. We briefly analyzed the features of this subsystem and its relationship with the reservation purchase subsystem at the beginning of <em class="italic">Chapter 7</em>, in the<em class="italic"> Understanding DDD</em> section.</li>
<li class="bulletList">User accounts subsystem.</li>
<li class="bulletList">Statistics reporting subsystem.</li>
</ul>
<p class="normal">Do the preceding subsystems represent different bounded contexts? Can some subsystems be split into different bounded contexts? The answers to these questions are given by the languages that are spoken in each subsystem:</p>
<ul>
<li class="bulletList">The language that’s spoken in subsystem 1 is the language of <strong class="keyWord">travel agencies</strong>. There is no concept of a customer, just of locations, packages, and their features.</li>
<li class="bulletList">The language that’s spoken in subsystem 2 is common to all service purchases, such as the available resources, reservations, and purchase orders. This is a separate bounded context.</li>
<li class="bulletList">The language that’s spoken in subsystem 3 has a lot in common with subsystem 1’s language. However, there are also typical <strong class="keyWord">social media</strong> concepts, such as ratings, chats, post sharing, media sharing, and so on. This subsystem can be split into two parts: a social media subsystem that has a new Bounded Context and an available information subsystem that is part of the Bounded Context of subsystem 1.</li>
<li class="bulletList">As we pointed out in the <em class="italic">Understanding DDD</em> section in <em class="italic">Chapter 7</em>, in subsystem 4, we speak the language of <strong class="keyWord">banking</strong>. This subsystem communicates with the reservation purchase subsystem and executes tasks that are needed to carry out a purchase. From these observations, we<a id="_idIndexMarker1584"/> can see that it is a different Bounded Context and has a customer/supplier relationship with the purchase/reservation system.</li>
<li class="bulletList">Subsystem 5 is a separate Bounded Context (as in almost all web applications). It has a relationship with all the bounded contexts that have either the concept of a user or the concept of a customer because the concept of user accounts always maps to these concepts. You must be wondering how. Well, it’s quite simple—the currently logged-in user is assumed to be the social media user of the social media bounded context, the customer of the reservation/purchase bounded context, and the payer of the payment Bounded Context.</li>
<li class="bulletList">The query-only subsystem (that is, 6) speaks the language of analytics and statistics and differs a lot from the languages that are spoken in the other subsystems. However, it has a connection with almost all the bounded contexts since it takes all its input from them. The preceding constraints force us to adopt CQRS in its strong form, thereby considering it a query-only separated Bounded Context.</li>
</ul>
<p class="normal">In conclusion, each of the listed subsystems defines a different Bounded Context, but part of the communication with the experts/review subsystem must be included in the information about the available destinations, and the package’s Bounded Context.</p>
<p class="normal">As the analysis continues and a prototype is implemented, some bounded contexts may split and some others may be added, but it is fundamental to immediately start modeling the system and to immediately start analyzing the relationships among the bounded contexts with the partial information we have since this will drive further investigations and will help us define the communication protocols and ubiquitous languages that are<a id="_idIndexMarker1585"/> needed so that we can interact with the domain experts.</p>
<p class="normal">The following is a basic first sketch of the domain map:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_12.png"/></figure>
<p class="packt_figref">Figure 21.12: WWTravelClub domain map. Thin black arrows represent data exchanged between bounded contexts, while thick blue arrows represent the relationships between bounded contexts (conformist, customer/supplier, and so on)</p>
<p class="normal">For simplicity, we’ve omitted the <strong class="keyWord">Statistics reporting</strong> bounded context. We say just that it collects statistics on the daily purchases of each package.</p>
<p class="normal">Here, we’re assuming that the <strong class="keyWord">User accounts</strong> and <strong class="keyWord">Social</strong> bounded contexts have a <strong class="keyWord">conformist</strong> relationship with all the other counded contexts that communicate with them because they are implemented with already existing software, so all the other components must adapt to them.</p>
<p class="normal">As we mentioned previously, the relationship between <strong class="keyWord">Reservation</strong> and <strong class="keyWord">Payments</strong> is <strong class="keyWord">customer/supplier</strong> because <strong class="keyWord">Payments</strong> provides services that are used to execute the tasks of <strong class="keyWord">Reservation</strong>. All the other relationships are classified as <strong class="keyWord">partners</strong>. The various concepts of customer/user that most bounded contexts have are coordinated by the <strong class="keyWord">User accounts</strong> <strong class="keyWord">Authorization token</strong> arrow, which indirectly takes care of mapping these concepts between<a id="_idIndexMarker1586"/> all the counded contexts.</p>
<p class="normal">The <strong class="keyWord">Packages/locations</strong> subsystem communicates the following information to <strong class="keyWord">Reservation</strong>:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Chosen package info</strong>, which contains the package information that’s needed to carry out a reservation/purchase</li>
<li class="bulletList"><strong class="keyWord">Price changes</strong>, which takes care of informing pending purchase orders of possible price changes</li>
</ul>
<p class="normal">Social interactions are started from an existing review provided by users (the <strong class="keyWord">Reviews</strong> arrow between <strong class="keyWord">Packages/locations</strong> and <strong class="keyWord">Social</strong>) and are supported by <strong class="keyWord">Location/review info</strong> communications from <strong class="keyWord">Packages/locations</strong> to <strong class="keyWord">Social</strong>.</p>
<p class="normal">Finally, <strong class="keyWord">Reservation</strong> communicates purchase codes, descriptions, and prices to <strong class="keyWord">Payments</strong> through the <strong class="keyWord">Prices/codes/descriptions</strong> arrow.</p>
<p class="normal">Having identified our application’s bounded contexts, we are in a position to organize the application DevOps cycle.</p>
<h1 class="heading-1" id="_idParaDest-442">The WWTravelClub DevOps approach</h1>
<p class="normal">During <em class="italic">Chapter 8, Understanding DevOps Principles and CI/CD</em>, screenshots from the WWTravelClub project <a id="_idIndexMarker1587"/>showed the steps needed to implement a good DevOps cycle. The WWTravelClub team has decided to use Azure DevOps because they understand that the tool is essential for getting the best DevOps experience for the whole cycle. In fact, it appears the most complete of the tools offered by GitHub, since it covers the whole CI/CD cycle from requirements collection to deployment in staging and production. Moreover, all team members already know it very well.</p>
<p class="normal">The requirements were written using user stories, which can be found in the <strong class="keyWord">Work items</strong> section of Azure DevOps. The code is placed in the repository of the Azure DevOps project. Both concepts were explained in <em class="italic">Chapter 3</em>, <em class="italic">Managing Requirements</em>.</p>
<p class="normal">The management life cycle used for getting things done is Scrum, presented in <em class="italic">Chapter 1</em>, <em class="italic">Understanding the Importance of Software Architecture</em>. This approach divides the implementation into sprints, which forces value to be delivered by the end of each cycle. Using the CI facilities we learned in this chapter, code will be compiled each time the team merges new code into the master branch of the repository.</p>
<p class="normal">Once the code is compiled and tested, the first stage of the deployment is done. The first stage is normally named development/test because you enable it for internal tests. Both Application Insights and Test and Feedback can be used to get the first feedback on the new release.</p>
<p class="normal">If the tests and the <a id="_idIndexMarker1588"/>feedback of the new release pass, it is time to go to the second stage, quality assurance. Application Insights and Test and Feedback can be used again, but now in a more stable environment.</p>
<p class="normal">The cycle ends with the authorization to deploy in the production stage. This certainly is a tough decision, but DevOps indicates that you must do it continuously so you can get better feedback from customers. Application Insights keeps being a useful tool since you can monitor the evolution of the new release in production, even comparing it to past releases.</p>
<p class="normal">The WWTravelClub project approach described here can be used in many other modern application development life cycles. As a software architect, you must oversee the process. The tools are ready to go, and it depends on you to make things right!</p>
<p class="normal">For this reason, even considering WWTravelClub as a hypothetical scenario, some concerns were considered while building it:</p>
<ul>
<li class="bulletList">CI is enabled, but a multi-stage scenario is enabled too.</li>
<li class="bulletList">Even with a multi-stage scenario, the <strong class="keyWord">PR</strong> (<strong class="keyWord">Pull Request</strong>) is a way to guarantee that only good-quality code will be presented in the first stage.</li>
<li class="bulletList">To do a good job in the PR, peer reviews are undertaken.</li>
<li class="bulletList">The peer reviews check, for instance, the presence of a feature flag while creating a new feature.</li>
<li class="bulletList">The peer reviews check both unit and functional tests developed during the creation of the new feature.</li>
</ul>
<p class="normal">The preceding steps are not exclusively for WWTravelClub. You, as a software architect, will need to define the approach to guarantee a safe CI/CD scenario. You may use this as a starting point. It is worth pointing out that both in Azure DevOps and GitHub, we can completely disable pushing on the master branch, thus forcing the usage of PR for merging modifications<a id="_idIndexMarker1589"/> on the master branch.</p>
<p class="normal">In the next section, we will start with the actual code, by showing how to choose among various data storage options.</p>
<h1 class="heading-1" id="_idParaDest-443">How to choose your data storage in the cloud</h1>
<p class="normal">In <em class="italic">Chapter 12</em>, <em class="italic">Choosing Your Data Storage in the Cloud,</em> we learned how to use NoSQL. Now we must decide whether NoSQL databases are adequate for our book use case WWTravelClub application. We<a id="_idIndexMarker1590"/> need to store the following families of data:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Information about available destinations and packages</strong>: Relevant operations for these data are reads since packages and destinations do not change very often. However, they must be accessed as fast as possible from all over the world to ensure a pleasant user experience when users browse the available options. Therefore, a distributed relational database with geographically distributed replicas is possible but not necessary since packages can be stored inside their destinations in a cheaper NoSQL database.</li>
<li class="bulletList"><strong class="keyWord">Destination reviews</strong>: In this case, distributed write operations have a non-negligible impact. Moreover, most writes are additions since reviews are not usually updated. Additions benefit a lot from sharding and do not cause consistency issues like updates do. Accordingly, the best option for this data is a NoSQL collection.</li>
<li class="bulletList"><strong class="keyWord">Reservations</strong>: In this case, consistency errors are not acceptable because they may cause overbooking. Reads and writes have a comparable impact, but we need reliable transactions and good consistency checks. Luckily, data can be organized in a multi-tenant database where tenants are destinations since reservation information belonging to different destinations is completely unrelated. Accordingly, we may use sharded Azure SQL Database instances.</li>
</ul>
<p class="normal">In conclusion, the best option for data in the first and second bullet points is Cosmos DB, while the best option for the third point is Azure SQL Server. Actual applications may require a more detailed analysis of all data operations and their frequencies. In some cases, it is worth<a id="_idIndexMarker1591"/> implementing prototypes for various possible options and executing performance tests with typical workloads on all of them.</p>
<p class="normal">In the remainder of this section, we will migrate the destinations/packages data layer we looked at in <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>, to Cosmos DB.</p>
<h2 class="heading-2" id="_idParaDest-444">Implementing the destinations/packages database with Cosmos DB</h2>
<p class="normal">Let’s move on to the database example we built in <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>, and implement<a id="_idIndexMarker1592"/> this database with Cosmos DB by following these steps:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">First, we need to make a copy <a id="_idIndexMarker1593"/>of the WWTravelClubDB project and rename its root folder as <code class="inlineCode">WWTravelClubDBCosmo</code>.</li>
<li class="numberedList">Open the project and delete the <code class="inlineCode">Migrations</code> folder since migrations are not required anymore.</li>
<li class="numberedList">We need to replace the SQL Server Entity Framework provider with the Cosmos DB provider. To do this, go to <strong class="keyWord">Manage NuGet Packages</strong> and uninstall the <code class="inlineCode">Microsoft.EntityFrameworkCore.SqlServer</code> NuGet package. Then, install the <code class="inlineCode">Microsoft.EntityFrameworkCore.Cosmos</code> NuGet package.</li>
<li class="numberedList">Then, do the following on the <code class="inlineCode">Destination</code> and <code class="inlineCode">Package</code> entities:<ul>
<li class="bulletList">Remove all data annotations.</li>
<li class="bulletList">Add the <code class="inlineCode">[Key]</code> attribute to their <code class="inlineCode">Id</code> properties since this is obligatory for Cosmos DB providers.</li>
<li class="bulletList">Transform the type of the <code class="inlineCode">Id</code> properties of both <code class="inlineCode">Package</code> and <code class="inlineCode">Destination</code> and the <code class="inlineCode">PackagesListDTO</code> classes from <code class="inlineCode">int</code> to <code class="inlineCode">string</code>. We also need to turn the <code class="inlineCode">DestinationId</code> external references in <code class="inlineCode">Package</code> and in the <code class="inlineCode">PackagesListDTO</code> classes into <code class="inlineCode">string</code>. In fact, the best option for keys in distributed databases is a string generated from a GUID, because it is hard to maintain an identity counter when table data is distributed among several servers.</li>
</ul>
</li>
<li class="numberedList">In the <code class="inlineCode">MainDBContext</code> file, we need to specify that packages related to a destination must be stored inside the destination document itself. This can be achieved by replacing the <strong class="keyWord">Destination-Package</strong> relation configuration in the <code class="inlineCode">OnModelCreating</code> method with the following code:
        <pre class="programlisting code"><code class="hljs-code">builder.Entity&lt;Destination&gt;()
    .OwnsMany(m =&gt;m.Packages);
</code></pre>
</li>
<li class="numberedList">Here, we must replace <code class="inlineCode">HasMany</code> with <code class="inlineCode">OwnsMany</code>. There is no equivalent to <code class="inlineCode">WithOne</code> since once an entity is owned, it must have just one owner, and the fact that the <code class="inlineCode">MyDestination</code> property contains a pointer to the father entity is evident from its type. Cosmos <a id="_idIndexMarker1594"/>DB also allows the use of <code class="inlineCode">HasMany</code>, but in this case, the two entities <a id="_idIndexMarker1595"/>are not nested one in the other. There is also an <code class="inlineCode">OwnOne</code> configuration method for nesting single entities inside other entities.</li>
<li class="numberedList">Both <code class="inlineCode">OwnsMany</code> and <code class="inlineCode">OwnsOne</code> are available for relational databases, but in this case, the difference between <code class="inlineCode">HasMany</code> and <code class="inlineCode">HasOne</code> is that children entities are automatically included in all queries that return their father entities, with no need to specify an <code class="inlineCode">Include</code> LINQ clause. However, child entities are still stored in separate tables.</li>
<li class="numberedList"><code class="inlineCode">LibraryDesignTimeDbContextFactory</code> must be modified to use Cosmos DB connection data, as shown in the following code:
        <pre class="programlisting code"><code class="hljs-code">using Microsoft.EntityFrameworkCore;
using Microsoft.EntityFrameworkCore.Design;
namespace WWTravelClubDB
{
    public class LibraryDesignTimeDbContextFactory
        : IDesignTimeDbContextFactory&lt;MainDBContext&gt;
    {
        private const string endpoint = "&lt;your account endpoint&gt;";
        private const string key = "&lt;your account key&gt;";
        private const string databaseName = "packagesdb";
        public MainDBContext CreateDbContext(params string[] args)
        {
            var builder = new DbContextOptionsBuilder&lt;MainDBContext&gt;();
            builder.UseCosmos(endpoint, key, databaseName);
            return new MainDBContext(builder.Options);
        }
    }
}
</code></pre>
</li>
<li class="numberedList">Finally, in our test <a id="_idIndexMarker1596"/>console, we must<a id="_idIndexMarker1597"/> explicitly create all entity principal keys using GUIDs:
        <pre class="programlisting code"><code class="hljs-code">var context = new LibraryDesignTimeDbContextFactory()
    .CreateDbContext();
context.Database.EnsureCreated();
var firstDestination = new Destination
{
    Id = Guid.NewGuid().ToString(),
    Name = "Florence",
    Country = "Italy",
    Packages = new List&lt;Package&gt;()
    {
    new Package
    {
        Id=Guid.NewGuid().ToString(),
        Name = "Summer in Florence",
        StartValidityDate = new DateTime(2019, 6, 1),
        EndValidityDate = new DateTime(2019, 10, 1),
        DurationInDays=7,
        Price=1000
    },
    new Package
    {
        Id=Guid.NewGuid().ToString(),
        Name = "Winter in Florence",
        StartValidityDate = new DateTime(2019, 12, 1),
        EndValidityDate = new DateTime(2020, 2, 1),
        DurationInDays=7,
        Price=500
    }
  }
};
</code></pre>
</li>
<li class="numberedList">Here, we call <code class="inlineCode">context.Database.EnsureCreated()</code> instead of applying migrations since we only need to create the database. Once the database and collections have been created, we can fine-tune their settings from the Azure portal. Hopefully, future versions of the Cosmos DB Entity Framework Core provider will allow us to specify all collection options.</li>
<li class="numberedList">Finally, the final query (which starts with <code class="inlineCode">context.Packages.Where...</code>) must be modified since queries can’t start with entities that are nested in other documents (in our case, <code class="inlineCode">Packages</code> entities). Therefore, we must start our query from the unique root <code class="inlineCode">DbSet&lt;T&gt;</code> property we<a id="_idIndexMarker1598"/> have in our <code class="inlineCode">DBContext</code>, that is, <code class="inlineCode">Destinations</code>. We can <a id="_idIndexMarker1599"/>move from listing the external collection to listing all the internal collections with the help of the <code class="inlineCode">SelectMany</code> method, which performs a logical merge of all nested <code class="inlineCode">Packages</code> collections. However, since Cosmos DB SQL doesn’t support <code class="inlineCode">SelectMany</code>, we must force <code class="inlineCode">SelectMany</code> to be simulated on the client with <code class="inlineCode">AsEnumerable()</code>, as shown in the following code:
        <pre class="programlisting code"><code class="hljs-code">var list = context.Destinations
    .AsEnumerable() // move computation on the client side
    .SelectMany(m =&gt;m.Packages)
    .Where(m =&gt; period &gt;= m.StartValidityDate....)
    ...
</code></pre>
</li>
<li class="numberedList">The remainder of the query remains unchanged. If you run the project now, you should see the same outputs that were received in the case of SQL Server (except for the primary key values).</li>
</ol>
<p class="normal">After executing the program, go to your Cosmos DB account. You should see something like the following:</p>
<figure class="mediaobject"><img alt="A picture containing table  Description automatically generated" src="img/B19820_21_13.png"/></figure>
<p class="packt_figref">Figure 21.13: Execution results</p>
<p class="normal">The packages have <a id="_idIndexMarker1600"/>been nested inside their <a id="_idIndexMarker1601"/>destinations as required and Entity Framework Core creates a unique collection that has the same name as the <code class="inlineCode">DBContext</code> class.</p>
<p class="normal">If you would like to continue experimenting with Cosmos DB development without wasting all your free Azure portal credit, you can install the Cosmos DB emulator, available at this link: <a href="https://aka.ms/cosmosdb-emulator">https://aka.ms/cosmosdb-emulator</a>.</p>
<p class="normal">Having learned how to<a id="_idIndexMarker1602"/> choose the best <a id="_idIndexMarker1603"/>options for data storage, we are in a position to start coding our first microservice.</p>
<h1 class="heading-1" id="_idParaDest-445">A worker microservice with ASP.NET Core</h1>
<p class="normal">In this section, we will show you<a id="_idIndexMarker1604"/> how to implement a microservice that receives communications through gRPC and an internal queue based on a database table. The first subsection briefly describes the microservice specifications and the overall architecture. You are encouraged<a id="_idIndexMarker1605"/> to review <em class="italic">Chapter 14</em>, <em class="italic">Implementing Microservices with .NET,</em> which contains all the theory behind this example.</p>
<h2 class="heading-2" id="_idParaDest-446">The specifications and architecture</h2>
<p class="normal">Our example microservice is required to compute the daily sums of all purchases. According to the data-driven approach, we suppose that all daily sums are pre-computed by receiving messages that<a id="_idIndexMarker1606"/> are sent as soon as a new purchase is finalized. The purpose of the microservice is to maintain a database of all purchases and all daily sums that can be queried by an administrative user. We will implement just the functionalities needed to fill the two database tables.</p>
<p class="normal">The implementation described in this section is based on an ASP.NET Core application that hosts a gRPC service. The gRPC service simply fills a messages queue and immediately returns to avoid the sender remaining blocked for the whole time of the computation.</p>
<p class="normal">The actual processing is performed by an ASP.NET Core-hosted service declared in the dependency injection engine associated with the application host. The worker-hosted service executes an endless loop where it extracts <code class="inlineCode">N</code> messages from the queue and passes them to <code class="inlineCode">N</code> parallel threads that process them.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_14.png"/></figure>
<p class="packt_figref">Figure 21.14: gRPC microservice architecture</p>
<p class="normal">When the <code class="inlineCode">N</code> messages are taken<a id="_idIndexMarker1607"/> from the queue, they are not immediately removed but are simply marked with the extraction time. Since messages can only be extracted from the queue if their last extraction time is far enough ahead (say, a time <code class="inlineCode">T</code>), no other worker thread can extract them again while they are being processed. When message processing is successfully completed, the message is removed from the queue. If the processing fails, no action is taken on the message, so the message remains blocked in the queue till the <code class="inlineCode">T</code> interval expires, and then it can be picked up again by the worker thread.</p>
<p class="normal">The microservice can be scaled vertically by increasing the processor cores and the number <code class="inlineCode">N</code> of threads. It can be scaled horizontally, too, by using a load balancer that splits the loads into several identical copies of the ASP.NET Core application. This kind of horizontal scaling increases the number of threads that can receive messages and the number of worker threads, but since all ASP.NET Core applications share the same database, it is limited by database performance.</p>
<p class="normal">The database layer is implemented in a separate <strong class="keyWord">DLL</strong> (<strong class="keyWord">Dynamic Link Library)</strong> and all functionalities are abstracted in two interfaces, one for interacting with the queue and another for adding a new purchase to the database.</p>
<p class="normal">The next subsection briefly describes the database layer. We will not give all the details since the main focus of the example is the microservice architecture and the communication technique. However, the full code is available in the <code class="inlineCode">ch15/GrpcMicroService</code> folder of the GitHub repository associated with the book.</p>
<p class="normal">Having defined the overall architecture, let’s start with the storage layer code.</p>
<h2 class="heading-2" id="_idParaDest-447">The storage layer</h2>
<p class="normal">The storage layer is based on<a id="_idIndexMarker1608"/> a database. It uses Entity Framework Core and is based on three entities with their associated tables:</p>
<ul>
<li class="bulletList">A <code class="inlineCode">QueueItem</code> entity that represents a queue item</li>
<li class="bulletList">A <code class="inlineCode">Purchase</code> entity that represents a single purchase</li>
<li class="bulletList">A <code class="inlineCode">DayTotal</code> entity that represents the total of all purchases performed in a given day</li>
</ul>
<p class="normal">Below is a definition of the interface that manipulates the queue:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IMessageQueue
{
    public Task&lt;IList&lt;QueueItem&gt;&gt; Top(int n);
    public Task Dequeue(IEnumerable&lt;QueueItem&gt; items);
    public Task Enqueue(QueueItem item);
}
</code></pre>
<p class="normal"><code class="inlineCode">Top</code> extracts the <code class="inlineCode">N</code> messages to pass to a maximum of <code class="inlineCode">N</code> different threads. <code class="inlineCode">Enqueue</code> adds a new message to the queue. Finally, <code class="inlineCode">Dequeue</code> removes the items that have been successfully processed from the queue.</p>
<p class="normal">The interface that updates the purchase data is defined as shown below:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IDayStatistics
{
    Task&lt;decimal&gt; DayTotal(DateTimeOffset day);
    Task&lt;QueueItem?&gt; Add(QueueItem model);
}
</code></pre>
<p class="normal"><code class="inlineCode">Add</code> adds a new purchase to the database. It returns the input queue item if the addition is successful, and <code class="inlineCode">null</code> otherwise. <code class="inlineCode">DayTotal</code> is a query method that returns a single day total.</p>
<p class="normal">The application layer communicates with the database layer through these two interfaces, through the three database entities, through the <code class="inlineCode">IUnitOfWork</code> interface (which, as explained in the <em class="italic">How data and domain layers communicate with other layers</em> section of <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em> abstracts the <code class="inlineCode">DbContext</code>), and through a dependency injection extension method like the one below:</p>
<pre class="programlisting code"><code class="hljs-code">public static class StorageExtensions
{
    public static IServiceCollection AddStorage(this IServiceCollection services,
 string connectionString)
    {
        services.AddDbContext&lt;IUnitOfWork,MainDbContext&gt;(options =&gt;
            options.UseSqlServer(connectionString, b =&gt;
b.MigrationsAssembly("GrpcMicroServiceStore")));
        services.AddScoped&lt;IMessageQueue, MessageQueue&gt;();
        services.AddScoped&lt;IDayStatistics, DayStatistics&gt;();
        return services;
    }
}
</code></pre>
<p class="normal">This method, which will be called in the application layer dependency injection definition, receives as<a id="_idIndexMarker1609"/> input the database connection string and adds the <code class="inlineCode">DbContext</code> abstracted with <code class="inlineCode">IUnitOfWork</code>, with the two interfaces we defined before.</p>
<p class="normal">The database project, called <code class="inlineCode">GrpcMicroServiceStore</code>, is contained in the <code class="inlineCode">ch15/GrpcMicroService</code> folder of the GitHub repository associated with the book. It already contains all the necessary database migrations, so you can create the needed database with the steps below:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">In the Visual Studio <strong class="screenText">Package Manager Console</strong>, select the <strong class="screenText">GrpcMicroServiceStore</strong> project.</li>
<li class="numberedList">In Visual Studio <strong class="screenText">Solution Explorer</strong>, right-click on the <strong class="screenText">GrpcMicroServiceStore</strong> project and set it as the startup project.</li>
<li class="numberedList">In the Visual Studio <strong class="screenText">Package Manager Console</strong>, issue the <code class="inlineCode">Update-Database</code> command.</li>
</ol>
<p class="normal">Having a working storage layer, we can proceed with the microservices application layer.</p>
<h2 class="heading-2" id="_idParaDest-448">The application layer</h2>
<p class="normal">The application layer is an <strong class="keyWord">ASP.NET Core gRPC service</strong> project called <code class="inlineCode">GrpcMicroService</code>. When the project is scaffolded by <a id="_idIndexMarker1610"/>Visual Studio, it contains a <code class="inlineCode">.proto</code> file in its <code class="inlineCode">Protos</code> folder. This file needs to be deleted and replaced by a file called <code class="inlineCode">counting.proto</code>, whose content must be as follows:</p>
<pre class="programlisting code"><code class="hljs-code">syntax = "proto3";
option csharp_namespace = "GrpcMicroService";
import "google/protobuf/timestamp.proto";
package counting;
service Counter {
  // Accepts a counting request
rpc Count (CountingRequest) returns (CountingReply);
}
message CountingRequest {
  string id = 1;
  google.protobuf.Timestamp time = 2;
  string location = 3;
  sint32 cost =4;
  google.protobuf.Timestamp purchaseTime = 5;
}.
message CountingReply {}
</code></pre>
<p class="normal">The above code defines the gRPC service with its input and output messages and the .NET namespace where you place them. We import the <code class="inlineCode">google/protobuf/timestamp.proto</code> predefined <code class="inlineCode">.proto</code> file because we need the <code class="inlineCode">TimeStamp</code> type. The<a id="_idIndexMarker1611"/> request contains purchase data, the <code class="inlineCode">time</code> when the request message was created, and a unique message <code class="inlineCode">id</code> that is used to force message idempotency.</p>
<p class="normal">In the database layer, the implementation of the <code class="inlineCode">IDayStatistics.Add</code> method uses this <code class="inlineCode">id</code> to verify if a purchase with the same <code class="inlineCode">id</code> has already been processed, in which case it returns immediately:</p>
<pre class="programlisting code"><code class="hljs-code">bool processed = await ctx.Purchases.AnyAsync(m =&gt; m.Id == model.MessageId);
if (processed) return model;
</code></pre>
<p class="normal">Automatic code generation for this file is enabled by replacing the existing <code class="inlineCode">protobuf</code> XML tag with:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;Protobuf Include="Protos\counting.proto" GrpcServices="Server" /&gt;
</code></pre>
<p class="normal">The <code class="inlineCode">Grpc</code> attribute set to <code class="inlineCode">"Server"</code> enables server-side code generation.</p>
<p class="normal">In the <code class="inlineCode">Services</code> project folder, the predefined gRPC service scaffolded by Visual Studio must be replaced with a file <a id="_idIndexMarker1612"/>named <code class="inlineCode">CounterService.cs</code> with the content below:</p>
<pre class="programlisting code"><code class="hljs-code">using Grpc.Core;
using GrpcMicroServiceStore;
namespace GrpcMicroService.Services;
public class CounterService: Counter.CounterBase
{
    private readonly IMessageQueue queue;
    public CounterService(IMessageQueue queue)
    {
	 If (queue == null) throw new 					ArgumentNullException(nameof(queue));
        this.queue = queue;
    }
    public override async  Task&lt;CountingReply&gt; Count(CountingRequest request,
        ServerCallContext context)
    {
            await queue.Enqueue(new GrpcMicroServiceStore.Models.QueueItem
            {
                Cost = request.Cost,
                MessageId = Guid.Parse(request.Id),
                Location = request.Location,
                PurchaseTime = request.PurchaseTime.ToDateTimeOffset(),
                Time = request.Time.ToDateTimeOffset()
            });
            return new CountingReply {  }; 
    }
}
</code></pre>
<p class="normal">The actual service that receives the purchase messages inherits from the <code class="inlineCode">Counter.CounterBase</code> abstract class created by the code generator from the <code class="inlineCode">counting.proto</code> file. It receives the database layer interface <code class="inlineCode">IMessageQueue</code> using dependency injection and overrides the abstract <code class="inlineCode">Count</code> method inherited from <code class="inlineCode">Counter.CounterBase</code>. Then, <code class="inlineCode">Count</code> uses <code class="inlineCode">IMessageQueue</code> to enqueue each received message.</p>
<p class="normal">Before compiling, a few other steps are necessary:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">We must add a reference to the database-layer <code class="inlineCode">GrpcMicroServiceStore</code> project.</li>
<li class="numberedList">We must add the database connection string to the <code class="inlineCode">appsettings.json</code> setting file:
        <pre class="programlisting code"><code class="hljs-code">"ConnectionStrings": {
"DefaultConnection": "Server=(localdb)\\mssqllocaldb;Database=grpcmicroservice;Trusted_Connection=True;MultipleActiveResultSets=true"
}
</code></pre>
</li>
<li class="numberedList">We must add all the<a id="_idIndexMarker1613"/> necessary database-layer interfaces to the dependency injection by calling the <code class="inlineCode">AddStorage</code> database layer extension method:
        <pre class="programlisting code"><code class="hljs-code">builder.Services.AddStorage(
builder.Configuration.GetConnectionString("DefaultConnection"));
</code></pre>
</li>
<li class="numberedList">In <code class="inlineCode">Program.cs</code>, we must remove the declaration of the gRPC service scaffolded by Visual Studio, and we must replace it with:
        <pre class="programlisting code"><code class="hljs-code">app.MapGrpcService&lt;CounterService&gt;();
</code></pre>
</li>
</ol>
<p class="normal">At this point, compilation should succeed. Having completed the application-layer infrastructure, we can move to the hosted service that performs the actual queue processing.</p>
<h2 class="heading-2" id="_idParaDest-449">Processing the queued requests</h2>
<p class="normal">The actual request processing is <a id="_idIndexMarker1614"/>performed by a worker-hosted service that runs in parallel with the ASP.NET Core pipeline. It is implemented with the hosted services we discussed in the <em class="italic">Using generic hosts</em> section of <em class="italic">Chapter 11</em>, <em class="italic">Applying a Microservice Architecture to Your Enterprise Application</em>. It is worth recalling that hosted services are implementations of the <code class="inlineCode">IHostedService</code> interface defined in the dependency injection engine as follows:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddHostedService&lt;MyHostedService&gt;();
</code></pre>
<p class="normal">We already described how to implement hosted services for the implementation of ASP.NET Core-based worker microservices in the <em class="italic">Implementing worker microservices with ASP.NET Core</em> section of <em class="italic">Chapter 14, Implementing Microservices with .NET</em>.</p>
<p class="normal">Below, we repeat the whole <a id="_idIndexMarker1615"/>code with all details that are specific to our example. The hosted service is defined in the <code class="inlineCode">ProcessPurchases.cs</code> file placed in the <code class="inlineCode">HostedServices</code> folder:</p>
<pre class="programlisting code"><code class="hljs-code">using GrpcMicroServiceStore;
using GrpcMicroServiceStore.Models;
namespace GrpcMicroService.HostedServices;
public class ProcessPurchases : BackgroundService
{
    IServiceProvider services;
    public ProcessPurchases(IServiceProvider services)
    {
        this.services = services;
    }
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        bool queueEmpty = false;
        while (!stoppingToken.IsCancellationRequested)
        {
           while (!queueEmpty &amp;&amp; !stoppingToken.IsCancellationRequested)
           {
             ...
           }
            await Task.Delay(100, stoppingToken);
            queueEmpty = false;
        }
    }
}
</code></pre>
<p class="normal">Below is the content of the inner loop:</p>
<pre class="programlisting code"><code class="hljs-code">using (var scope = services.CreateScope())
{
    IMessageQueue queue = scope.ServiceProvider.GetRequiredService&lt;IMessageQueue&gt;();
                   
    var toProcess = await queue.Top(10);
    if (toProcess.Count &gt; 0)
    {
        Task&lt;QueueItem?&gt;[] tasks = new Task&lt;QueueItem?&gt;[toProcess.Count];
        for (int i = 0; i &lt; tasks.Length; i++)
        {
            var toExecute = ...
            tasks[i] = toExecute();
        }
        await Task.WhenAll(tasks);
        await queue.Dequeue(tasks.Select(m =&gt; m.Result)
           .Where(m =&gt; m != null).OfType&lt;QueueItem&gt;());
    }
    else queueEmpty = true;
}
</code></pre>
<p class="normal">The above code was already <a id="_idIndexMarker1616"/>explained in the <em class="italic">Implementing worker microservices with ASP.NET Core</em> section of <em class="italic">Chapter 14, Implementing Microservices with .NET</em>. Therefore, here, we will analyze just the <code class="inlineCode">toExecute</code> lambda that is specific to our example:</p>
<pre class="programlisting code"><code class="hljs-code">var toExecute = async () =&gt;
{
    using (var sc = services.CreateScope())
    {
        IDayStatistics statistics = sc.ServiceProvider.GetRequiredService&lt;IDayStatistics&gt;();
        return await statistics.Add(toProcess[i]);
    }
};
</code></pre>
<p class="normal">Each task creates a different session scope so it can have a private copy of <code class="inlineCode">IDayStatistics</code>, and then processes its request with <code class="inlineCode">statistics.Add</code>.</p>
<p class="normal">That’s all! Now we need a source of purchase data to test our code. In the next subsection, we will create a fake microservice that randomly creates purchase data and passes it to the <code class="inlineCode">Counter</code> <code class="inlineCode">gRPC</code> service.</p>
<h2 class="heading-2" id="_idParaDest-450">Testing the GrpcMicroservice project with a fake purchase requests generator</h2>
<p class="normal">Let’s implement another <a id="_idIndexMarker1617"/>microservice that feeds the previous microservice with randomly generated requests. The right project for a worker service that is not based on ASP.NET Core is the <strong class="keyWord">Worker Service</strong> project template. This project template automatically scaffolds a host containing a unique hosted service called <code class="inlineCode">Worker</code>. We called this project <code class="inlineCode">FakeSource</code>. In order to enable gRPC client usage, we must add the following NuGet packages: <code class="inlineCode">Google.Protobuf</code>, <code class="inlineCode">Grpc.NET.Client</code>, and <code class="inlineCode">Grpc.Tools</code>.</p>
<p class="normal">Then, we must add the same <code class="inlineCode">counting.proto</code> file as was added to the previous project. However, this time, we must require client code generation by placing the code below in the <code class="inlineCode">FakeSource</code> project file:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;ItemGroup&gt;
&lt;Protobuf Include="..\GrpcMicroService\Protos\counting.proto" GrpcServices="Client"&gt;
&lt;Link&gt;Protos\counting.proto&lt;/Link&gt;
&lt;/Protobuf&gt;
&lt;/ItemGroup&gt;
</code></pre>
<p class="normal">The <code class="inlineCode">GrpcServices</code> attribute <a id="_idIndexMarker1618"/>set to <code class="inlineCode">Client</code> is what enables client code generation instead of server code generation. The <code class="inlineCode">link</code> tag appears since we added the same <code class="inlineCode">counting.proto</code> file of the <code class="inlineCode">GrpcMicroService</code> project as a link instead of copying it into the new project.</p>
<p class="normal">The hosted service is defined with the usual endless loop:</p>
<pre class="programlisting code"><code class="hljs-code">using Grpc.Net.Client;
using GrpcMicroService;
using Google.Protobuf.WellKnownTypes;
namespace FakeSource;
public class Worker : BackgroundService
{
    private readonly string[] locations = new string[]
           { "Florence", "London", "New York", "Paris" };
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        Random random = new Random();
        while (!stoppingToken.IsCancellationRequested)
        {
          try
          {
             ...
             await Task.Delay(2000, stoppingToken);
          }
          catch (OperationCanceledException)
          {
             return;
          }
          catch { }
        }
    }
}
</code></pre>
<p class="normal">The <code class="inlineCode">locations</code> array contains locations that will be randomly selected. As soon as the <code class="inlineCode">ExecuteAsync</code> method <a id="_idIndexMarker1619"/>starts, it creates the <code class="inlineCode">Random</code> instance that will be used in all random generations.</p>
<p class="normal">Each loop is enclosed in a <code class="inlineCode">try</code>/<code class="inlineCode">catch</code>; if an <code class="inlineCode">OperationCanceledException</code> is generated, the method exits, since a similar exception is created when the application is being shut down and the thread is killed. In the case of other exceptions, the code tries to recover by simply moving to the next loop. In an actual production application, the final <code class="inlineCode">catch</code> should contain instructions to log the intercepted exception and/or instructions for a better recovery strategy. In the next example, we will see more sophisticated exception handling that is adequate for actual production applications.</p>
<p class="normal">Inside the <code class="inlineCode">try</code>, the code creates a purchase message, sends it to the <code class="inlineCode">Counter</code> service, and then sleeps for 2 seconds.</p>
<p class="normal">Below is the code that sends the requests:</p>
<pre class="programlisting code"><code class="hljs-code">var purchaseDay = new DateTimeOffset(DateTime.UtcNow.Date, TimeSpan.Zero);
//randomize a little bit purchase day
purchaseDay = purchaseDay.AddDays(random.Next(0, 3) - 1); 
//message time
var now = DateTimeOffset.UtcNow;
//add random location
var location = locations[random.Next(0, locations.Length)];
var messageId = Guid.NewGuid().ToString();
//add random cost
int cost = 200 * random.Next(1, 4);
//send message
using var channel = GrpcChannel.ForAddress("http://localhost:5000");
var client = new Counter.CounterClient(channel);
//since this is a fake random source
//in case of errors we simply do nothing.
//An actual client should use Polly
//to define retry policies
try
{
    await client.CountAsync(new CountingRequest
    {
        Id = messageId,
        Location = location,
        PurchaseTime = Timestamp.FromDateTimeOffset(purchaseDay),
        Time = Timestamp.FromDateTimeOffset(now),
        Cost = cost
    });
                   
}
catch {}
</code></pre>
<p class="normal">The code just prepares the message with random data; then, it creates a communication channel for<a id="_idIndexMarker1620"/> the gRPC server address and passes it to the constructor of the <code class="inlineCode">Counter</code> service proxy. Finally, the <code class="inlineCode">Count</code> method is called on the proxy. The call is enclosed in a <code class="inlineCode">try</code>/<code class="inlineCode">catch</code>, and in the case of an error, the error is simply ignored, since we are just sending random data. Instead, an actual production application should use <strong class="keyWord">Polly</strong> to retry the communication with predefined strategies. <strong class="keyWord">Polly</strong> was described in the <em class="italic">Resilient task execution</em> section of <em class="italic">Chapter 11</em>, <em class="italic">Applying a Microservice Architecture to Your Enterprise Application</em>. We will show you how to use <strong class="keyWord">Polly</strong> in the example in the next section.</p>
<p class="normal">And there you have it! Now it is time to test everything. Right-click on the solution and select <strong class="keyWord">Set Startup Projects</strong>, then set both <code class="inlineCode">FakeSource</code> and <code class="inlineCode">GrpcMicroService</code> to start. This way, both projects will be launched simultaneously when the solution is run.</p>
<p class="normal">Launch Visual Studio and then let both processes run for a couple of minutes, then go to <strong class="keyWord">SQL Server Object Explorer</strong> and look for a database called <code class="inlineCode">grpcmicroservice</code>. If the <strong class="keyWord">SQL Server Object Explorer</strong> window is not available in the left menu of Visual Studio, go to the top <strong class="keyWord">Window</strong> menu and select it.</p>
<p class="normal">Once you have located the database, show the content of the <code class="inlineCode">DayTotals</code> and <code class="inlineCode">Purchases</code> tables. You should see all computed daily sums and all processed purchases.</p>
<p class="normal">You can also inspect what happens in the server project by opening the <code class="inlineCode">HostedServices/ProcessPurchases.cs</code> file and placing breakpoints on the <code class="inlineCode">queue.Top(10)</code> and <code class="inlineCode">await</code> <code class="inlineCode">queue.Dequeue(...)</code> instructions.</p>
<p class="normal">You can also move <code class="inlineCode">FakeSource</code> into a different Visual Studio solution so that you can simultaneously run several copies of <code class="inlineCode">FakeSource</code> each in a different Visual Studio instance. It is also possible to double-click on the <code class="inlineCode">FakeSource</code> project, which gives the option to save a new Visual Studio solution containing just a reference to the <code class="inlineCode">FakeSource</code> project.</p>
<p class="normal">The full code is in the <a id="_idIndexMarker1621"/><code class="inlineCode">GrpcMicroService</code> subfolder of the <code class="inlineCode">ch15</code> folder of the book’s GitHub repository. The next section shows you how to solve the same problem with queued communication using the RabbitMQ message broker.</p>
<h1 class="heading-1" id="_idParaDest-451">A worker microservice based on RabbitMQ</h1>
<p class="normal">This section explains the <a id="_idIndexMarker1622"/>modifications needed to use a message broker instead of gRPC communication with an internal queue. This kind of solution is usually more difficult to test and design but allows for better horizontal scaling, and also enables extra features at almost no cost since they are offered by the message broker itself.</p>
<p class="normal">We assume that RabbitMQ has already been installed and adequately prepared, as explained in the <em class="italic">Installing RabbitMQ core</em> subsection of <em class="italic">Chapter 14, Implementing Microservices with .NET</em>.</p>
<p class="normal">First, the ASP.NET Core project must be replaced by another <strong class="keyWord">Worker Service</strong> project. Also, this project must add the connection string to its configuration file and must call the <code class="inlineCode">AddStorage</code> extension method to add all the database services to the dependency injection engine. Below is the full content of the <code class="inlineCode">Program.cs</code> file:</p>
<pre class="programlisting code"><code class="hljs-code">using GrpcMicroService.HostedServices;
using GrpcMicroServiceStore;
IHost host = Host.CreateDefaultBuilder(args)
    .ConfigureServices((hostContext, services) =&gt;
    {
        services.AddStorage(hostContext.Configuration
            .GetConnectionString("DefaultConnection"));
        services.AddHostedService&lt;ProcessPurchases&gt;();
    })
    .Build();
await host.RunAsync();
</code></pre>
<p class="normal">We don’t need the gRPC services and service proxies anymore, just ProtoBuf for the binary messages, so both<a id="_idIndexMarker1623"/> the <code class="inlineCode">FakeSource</code> process and the <code class="inlineCode">GrpcMicroService</code> projects must add just the <code class="inlineCode">Google.Protobuf</code> and <code class="inlineCode">Grpc.Tools</code> NuGet packages. Both projects need the following <code class="inlineCode">messages.proto</code> file, which defines just the purchase message:</p>
<pre class="programlisting code"><code class="hljs-code">syntax = "proto3";
option csharp_namespace = "GrpcMicroService";
import "google/protobuf/timestamp.proto";
package purchase;
message PurchaseMessage {
  string id = 1;
  google.protobuf.Timestamp time = 2;
  string location = 3;
  int32 cost =4;
  google.protobuf.Timestamp purchaseTime = 5;
}
</code></pre>
<p class="normal">The automatic generation of the message classes is enabled in both projects with the same XML declaration in their project files:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;ItemGroup&gt;
&lt;Protobuf Include="Protos\messages.proto" GrpcServices="Client" /&gt;
&lt;/ItemGroup&gt;
</code></pre>
<p class="normal">Both projects need to specify <code class="inlineCode">Client</code> code generation since no service needs to be created.</p>
<p class="normal">To communicate with the RabbitMQ server, both projects must add the <code class="inlineCode">RabbitMQ.Client</code> NuGet package.</p>
<p class="normal">Finally, <code class="inlineCode">FakeSource</code> also adds the <code class="inlineCode">Polly</code> <code class="inlineCode">NuGet</code> package because we will use Polly to define reliable communication strategies.</p>
<p class="normal">The <code class="inlineCode">ExecuteAsync</code> method of the client project is a little bit different:</p>
<pre class="programlisting code"><code class="hljs-code">protected override async Task ExecuteAsync(CancellationToken stoppingToken)
{
    Random random = new Random();
    var factory = new ConnectionFactory{ HostName = "localhost" };
    IConnection? connection =null;
    IModel? channel = null;
    try
    {
        while (!stoppingToken.IsCancellationRequested)
        {
        ...      
        }
    }
    finally
    {
        if (connection != null)
        {
            channel.Dispose();
            connection.Dispose();
            channel = null;
            connection = null;
        }
    }
}
</code></pre>
<p class="normal">Communication requires the creation of a connection factory, then the creation factory generates a connection, and the connection generates a channel. The connection factory is created outside of the main loop since it can be reused several times, and it is not invalidated by <a id="_idIndexMarker1624"/>communication errors.</p>
<p class="normal">For the connection and channel, outside of the main loop, we just define the variables and where to place them since they are invalidated in the case of communication exceptions, so we must dispose of them and recreate them from scratch after each exception.</p>
<p class="normal">The main loop is enclosed in <code class="inlineCode">try</code>/<code class="inlineCode">finally</code> to ensure that any channel/connection pair is disposed of before leaving the method.</p>
<p class="normal">Inside the main loop, as a first step, we create the purchase message:</p>
<pre class="programlisting code"><code class="hljs-code">var purchaseDay = DateTime.UtcNow.Date;
//randomize a little bit purchase day
purchaseDay = purchaseDay.AddDays(random.Next(0, 3) – 1);
var purchase = new PurchaseMessage
{
    //message time
    PurchaseTime = Timestamp.FromDateTime(purchaseDay),
    Time = Timestamp.FromDateTime(DateTime.UtcNow),
    Id = Guid.NewGuid().ToString(),
    //add random location
    Location = locations[random.Next(0, locations.Length)],
    //add random cost
    Cost = 200 * random.Next(1, 4)
};
</code></pre>
<p class="normal">Then, the message is serialized:</p>
<pre class="programlisting code"><code class="hljs-code">byte[]? body = null;
using (var stream = new MemoryStream())
{
    purchase.WriteTo(stream);
    stream.Flush();
    body = stream.ToArray();
}
</code></pre>
<p class="normal">Before executing the <a id="_idIndexMarker1625"/>communication, we define a Polly policy:</p>
<pre class="programlisting code"><code class="hljs-code">var policy = Policy
    .Handle&lt;Exception&gt;()
    .WaitAndRetry(6,
        retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2,
        retryAttempt)));
</code></pre>
<p class="normal">The above policy is an exponential retry, which, in the case of an exception, waits for an exponentially growing amount of time. So, if six attempts are made, then the second attempt is made after 2 seconds, the third after 4 seconds, the fourth after 8 seconds, and so on. If all attempts fail, the exception is rethrown and causes the message to be lost. If it’s important that messages can’t be lost, we can combine this strategy with a circuit break strategy (see <em class="italic">Resilient task execution</em> in <em class="italic">Chapter 11</em>, <em class="italic">Applying a Microservice Architecture to Your Enterprise Application</em>).</p>
<p class="normal">Once we have defined the retry policy, we can execute all the communication steps in the context of this policy:</p>
<pre class="programlisting code"><code class="hljs-code">policy.Execute(() =&gt;
{
try
{
    if(connection == null || channel == null)
    {
        connection = factory.CreateConnection();
        channel = connection.CreateModel();
        channel.ConfirmSelect();
    }
    //actual communication here
    ...
    ...
}
catch
{
    channel.Dispose();
    connection.Dispose();
    channel = null;
    connection = null;
    throw;
}
</code></pre>
<p class="normal">If there are no valid connections or channels, they are created. <code class="inlineCode">channel.ConfirmSelect()</code> declares that we need confirmation that the message was safely received and stored on <a id="_idIndexMarker1626"/>disk. In the case that an exception is thrown, both the channel and the connection are disposed of, since they might have been corrupted by the exception. This way, the next communication attempt will use fresh communication and a new channel. After the disposal, the exception is rethrown so it can be handled by the Polly policy.</p>
<p class="normal">Finally, here are the actual communication steps:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">First of all, if the queue doesn’t already exist, it is created. The queue is created as <code class="inlineCode">durable</code>; that is, it must be stored on disk and not be <code class="inlineCode">exclusive</code> so that several servers can extract messages from the queue in parallel:
        <pre class="programlisting code"><code class="hljs-code">channel.QueueDeclare(queue: "purchase_queue",
    durable: true,
    exclusive: false,
    autoDelete: false,
   arguments: null);
</code></pre>
</li>
<li class="numberedList">Then, each message is declared as persistent; that is, it must be stored on disk:
        <pre class="programlisting code"><code class="hljs-code">var properties = channel.CreateBasicProperties();
properties.Persistent = true;
</code></pre>
</li>
<li class="numberedList">Finally, the message is sent through the default exchange, which sends it to a specific named queue:
        <pre class="programlisting code"><code class="hljs-code">channel.BasicPublish(exchange: "",
        routingKey: "purchase_queue",
        basicProperties: properties,
        body: body);
</code></pre>
</li>
<li class="numberedList">As a final step, we wait until the message is safely stored on disk:
        <pre class="programlisting code"><code class="hljs-code">channel.WaitForConfirmsOrDie(new TimeSpan(0, 0, 5));
</code></pre>
</li>
</ol>
<p class="normal">If a confirmation doesn’t arrive within the specified timeout, an exception is thrown that triggers the Polly retry policy. When messages are taken from a local database queue, we can also use a non-blocking confirmation that triggers the removal of the message from the local queue.</p>
<p class="normal">The <code class="inlineCode">ExecuteAsync</code> method <a id="_idIndexMarker1627"/>of the server-hosted process is defined in the <code class="inlineCode">HostedServices/ProcessPurchase.cs</code> file:</p>
<pre class="programlisting code"><code class="hljs-code">protected override async Task ExecuteAsync(CancellationToken stoppingToken)
{
    while (!stoppingToken.IsCancellationRequested)
    {
        try
        {
            var factory = new ConnectionFactory() { HostName = "localhost" };
            using (var connection = factory.CreateConnection())
            using (var channel = connection.CreateModel())
            {
                channel.QueueDeclare(queue: "purchase_queue",
                                     durable: true,
                                     exclusive: false,
                                     autoDelete: false,
                                     arguments: null);
                channel.BasicQos(prefetchSize: 0, prefetchCount: 1, global: false);
                var consumer = new EventingBasicConsumer(channel);
                consumer.Received += async (sender, ea) =&gt;
                {
                    // Message received even handler
                    ...
                };
                channel.BasicConsume(queue: "purchase_queue",
                            autoAck: false,
                            consumer: consumer);
                 await Task.Delay(1000, stoppingToken);
            }
         }
        catch { }
    }
}
</code></pre>
<p class="normal">Inside the main loop, if an exception is thrown, it is intercepted by the empty <code class="inlineCode">catch</code>. Since the two <code class="inlineCode">using</code> statements are left, both the connection and channel are disposed of. Therefore, after the exception, a new loop is executed that creates a new fresh connection and a new channel.</p>
<p class="normal">In the <code class="inlineCode">using</code> statement body, we ensure that our queue exists, and then set <code class="inlineCode">prefetch</code> to <code class="inlineCode">1</code>. This means that each server <a id="_idIndexMarker1628"/>must extract just one message at a time, which ensures a fair distribution of the load among all servers. However, setting <code class="inlineCode">prefetch</code> to <code class="inlineCode">1</code> might not be convenient when servers are based on several parallel threads since it sacrifices thread usage optimization in favor of fair distribution among servers. As a consequence, threads that could successfully process further messages (after the first) might remain idle.</p>
<p class="normal">Then, we define a <code class="inlineCode">message received</code> event handler. <code class="inlineCode">BasicConsume</code> starts the actual message reception. With <code class="inlineCode">autoAck</code> set to <code class="inlineCode">false</code>, when a message is read from the queue, it is not removed but just blocked so it is not available to other servers that read from the same queue. The message is actually removed when a confirmation that it has been successfully processed is sent to RabbitMQ. We can also send a failure confirmation, in which case, the message is unblocked and becomes available for processing again.</p>
<p class="normal">If no confirmation is received, the message remains blocked till the connection and channel are disposed of.</p>
<p class="normal"><code class="inlineCode">BasicConsume</code> is non-blocking, so the <code class="inlineCode">Task.Delay</code> after it blocks till the cancelation token is signaled. In any case, after 1 second, <code class="inlineCode">Task.Delay</code> unblocks and both the connection and the channel are replaced with fresh ones. This prevents non-confirmed messages from remaining blocked forever.</p>
<p class="normal">Let’s move on to the code inside the <em class="italic">message received</em> event. This is the place where the actual message processing takes place.</p>
<p class="normal">As a first step, the code verifies if the application is being shut down, in which case it disposes of the channel<a id="_idIndexMarker1629"/> and connection and returns without performing any further operations:</p>
<pre class="programlisting code"><code class="hljs-code">if (stoppingToken.IsCancellationRequested)
{
    channel.Close();
    connection.Close();
    return;
}
</code></pre>
<p class="normal">Then, a session scope is created to access all session-scoped dependency injection services:</p>
<pre class="programlisting code"><code class="hljs-code">using (var scope = services.CreateScope())
{
  try
  {
  // actual message processing
  ...
  }
  catch {
    ((EventingBasicConsumer)sender).Model.BasicNack(ea.DeliveryTag, false, true);
  }
}
</code></pre>
<p class="normal">When an exception is thrown during the message processing, a <code class="inlineCode">Nack</code> message is sent to RabbitMQ to inform it that the message processing failed. <code class="inlineCode">ea.DeliveryTag</code> is a tag that uniquely identifies the message. The second argument set to <code class="inlineCode">false</code> informs RabbitMQ that the <code class="inlineCode">Nack</code> is just for the message identified by <code class="inlineCode">ea.DeliveryTag</code> that doesn’t also involve all other messages waiting for confirmation from this server. Finally, the last argument set to <code class="inlineCode">true</code> asks RabbitMQ to requeue the message whose processing failed.</p>
<p class="normal">Inside the <code class="inlineCode">try</code> block, we get an instance of <code class="inlineCode">IDayStatistics</code>:</p>
<pre class="programlisting code"><code class="hljs-code">IDayStatistics statistics = scope.ServiceProvider
    .GetRequiredService&lt;IDayStatistics&gt;();
</code></pre>
<p class="normal">Then, we deserialize the message body to get a <code class="inlineCode">PurchaseMessage</code> instance and add it to the database:</p>
<pre class="programlisting code"><code class="hljs-code">var body = ea.Body.ToArray();
PurchaseMessage? message = null;
using (var stream = new MemoryStream(body))
{
    message = PurchaseMessage.Parser.ParseFrom(stream);
}
var res = await statistics.Add(new Purchase {
    Cost= message.Cost,
    Id= Guid.Parse(message.Id),
    Location = message.Location,
    Time = new DateTimeOffset(message.Time.ToDateTime(), TimeSpan.Zero),
    PurchaseTime = new DateTimeOffset(message.PurchaseTime.ToDateTime(), TimeSpan.Zero)
});
</code></pre>
<p class="normal">If the operation<a id="_idIndexMarker1630"/> fails, the <code class="inlineCode">Add</code> operation returns <code class="inlineCode">null</code>, so we must send a <code class="inlineCode">Nack</code>; otherwise, we must send an <code class="inlineCode">Ack</code>:</p>
<pre class="programlisting code"><code class="hljs-code">if(res != null)
    ((EventingBasicConsumer)sender).Model
        .BasicAck(ea.DeliveryTag, false);
else
    ((EventingBasicConsumer)sender).Model
        .BasicNack(ea.DeliveryTag, false, true);
</code></pre>
<p class="normal">That’s all! The full code is in the <code class="inlineCode">GrpcMicroServiceRabbitProto</code> subfolder of the <code class="inlineCode">ch15</code> folder in the GitHub repository of this book. You can test the code by setting both the client and server projects as the start project and running the solution. After 1–2 minutes, the database should be populated with new purchases and new daily totals. In a staging/production environment, you can run several copies of both the client and server.</p>
<p class="normal">The <code class="inlineCode">GrpcMicroServiceRabbit</code> subfolder in the <code class="inlineCode">ch15</code> folder of the GitHub repository contains another version of the same application that uses the <em class="italic">Binaron</em> NuGet package for serialization. It is faster than ProtoBuf, but being .NET-specific, it is not interoperable. Moreover, it has no features to facilitate message versioning. It is useful when performance is critical and versioning and interoperability are not a priority.</p>
<p class="normal">The <em class="italic">Binaron</em> version differs in that it has no <code class="inlineCode">.proto</code> files or other ProtoBuf stuff, but it explicitly defines a <code class="inlineCode">PurchaseMessage</code> .NET class. Moreover, ProtoBuf serialization and deserialization instructions are replaced by the following:</p>
<pre class="programlisting code"><code class="hljs-code">byte[]? body = null;
using (var stream = new MemoryStream())
{
    BinaronConvert.Serialize(purchase, stream);
    stream.Flush();
    body = stream.ToArray();
}
</code></pre>
<p class="normal">Together with:</p>
<pre class="programlisting code"><code class="hljs-code">PurchaseMessage? message = null;
using (var stream = new MemoryStream(body))
{
    message = BinaronConvert.Deserialize&lt;PurchaseMessage&gt;(stream);
}.
</code></pre>
<p class="normal">Now that we have<a id="_idIndexMarker1631"/> created a microservice connected to a message broker, it is also important to learn how to expose packages from WWTravelClub using web APIs. Let’s see this in the next section.</p>
<h1 class="heading-1" id="_idParaDest-452">Exposing WWTravelClub packages using Web APIs</h1>
<p class="normal">In this section, we will implement an ASP.NET REST service that lists all the packages that are available for a given<a id="_idIndexMarker1632"/> vacation’s start and end dates. For <a id="_idIndexMarker1633"/>didactic purposes, we will not structure the application according to the best practices we have described previously; instead, we will simply generate the results with a LINQ query that will be directly placed in the controller action method. A well-structured ASP.NET Core application has been presented in <em class="italic">Chapter 18</em>, <em class="italic">Implementing Frontend Microservices with ASP.NET Core</em>.</p>
<p class="normal">Let us make a copy of the <code class="inlineCode">WWTravelClubDB</code> solution folder and rename the new folder <code class="inlineCode">WWTravelClubWebAPI80</code>. The WWTravelClubDB project was built step by step in the various sections of <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>. Let us open the new solution and add a new ASP.NET Core API project to it named <code class="inlineCode">WWTravelClubWebAPI80</code> (the same name as the new solution folder). For simplicity, select <strong class="keyWord">No Authentication</strong>. Right-click on the newly created project and select <strong class="keyWord">Set as StartUp project</strong> to make it the default project that is launched when the solution is run.</p>
<p class="normal">Finally, we need to add a reference to the WWTravelClubDB project.</p>
<p class="normal">ASP.NET Core projects store configuration constants in the <code class="inlineCode">appsettings.json</code> file. Let’s open this file and add the database connection string for the database we created in the WWTravelClubDB<a id="_idIndexMarker1634"/> project to it, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">{
"ConnectionStrings": {
"DefaultConnection": "Server=
   (localdb)\\mssqllocaldb;Database=wwtravelclub;
Trusted_Connection=True;MultipleActiveResultSets=true"
},
    ...
    ...
}
</code></pre>
<p class="normal">Now, we must add the <a id="_idIndexMarker1635"/>WWTravelClubDB entity framework database context to <code class="inlineCode">Program.cs</code>, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddDbContext&lt;WWTravelClubDB.MainDBContext&gt;(options =&gt;
options.UseSqlServer(
builder.Configuration.GetConnectionString("DefaultConnection"),
            b =&gt;b.MigrationsAssembly("WWTravelClubDB")))
</code></pre>
<p class="normal">The option object settings that are passed to <code class="inlineCode">AddDbContext</code> specify the usage of SQL Server with a connection string that is extracted from the <code class="inlineCode">ConnectionStrings</code> section of the <code class="inlineCode">appsettings.json</code> configuration file with the <code class="inlineCode">Configuration.GetConnectionString("DefaultConnection")</code> method. The <code class="inlineCode">b =&gt;b.MigrationsAssembly("WWTravelClubDB")</code> lambda function declares the name of the assembly that contains the database migrations (see <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>), which, in our case, is the DLL that was generated by the WWTravelClubDB project. For the preceding code to compile, you should add the <code class="inlineCode">Microsoft.EntityFrameworkCore</code> namespace.</p>
<p class="normal">Since we want to enrich our REST service with OpenAPI documentation, let’s add a reference to the <code class="inlineCode">Swashbuckle.AspNetCore</code> NuGet package. Now, we can add the following very basic configuration to <code class="inlineCode">Program.cs</code>:</p>
<pre class="programlisting code"><code class="hljs-code">var builder = WebApplication.CreateBuilder(args);
...
builder.Services.AddSwaggerGen(c =&gt;
{
    c.SwaggerDoc("v2", new() { Title = "WWTravelClub REST API - .NET 8", Version = "v2" });
});
var app = builder.Build();
...
app.UseSwagger();
app.UseSwaggerUI(c =&gt; c.SwaggerEndpoint("/swagger/v2/swagger.json", "WWTravelClub REST API - .NET 8"));
...
app.Run();
</code></pre>
<p class="normal">Now, we are ready to encode <a id="_idIndexMarker1636"/>our service. Let’s delete <code class="inlineCode">WeatherForecastController</code>, which is automatically<a id="_idIndexMarker1637"/> scaffolded by Visual Studio. Then, right-click on the <code class="inlineCode">Controllers</code> folder and select <strong class="screenText">Add | Controller</strong>. Now, choose an empty API controller called <code class="inlineCode">PackagesController</code>. First, let’s modify the code as follows:</p>
<pre class="programlisting code"><code class="hljs-code">[Route("api/packages")]
[ApiController]
public class PackagesController : ControllerBase
{
    [HttpGet("bydate/{start}/{stop}")]
    [ProducesResponseType(typeof(IEnumerable&lt;PackagesListDTO&gt;), 200)]
    [ProducesResponseType(400)]
    [ProducesResponseType(500)]
    public async Task&lt;IActionResult&gt; GetPackagesByDate(
        [FromServices] WWTravelClubDB.MainDBContext ctx,
        DateTime start, DateTime stop)
    {
    }
}
</code></pre>
<p class="normal">The <code class="inlineCode">Route</code> attribute declares that the basic path for our service will be <code class="inlineCode">api/packages</code>. The unique action method that we implement is <code class="inlineCode">GetPackagesByDate</code>, which is invoked on <code class="inlineCode">HttpGet</code> requests on paths of the <code class="inlineCode">bydate/{start}/{stop}</code> type, where <code class="inlineCode">start</code> and <code class="inlineCode">stop</code> are the <code class="inlineCode">DateTime</code> parameters that are passed as input to <code class="inlineCode">GetPackagesByDate</code>. The <code class="inlineCode">ProduceResponseType</code> attributes declare the following:</p>
<ul>
<li class="bulletList">When a request is successful, a 200 code is returned, and the body contains an <code class="inlineCode">IEnumerable</code> of the <code class="inlineCode">PackagesListDTO</code> type (which we will soon define) containing the required package information.</li>
<li class="bulletList">When the request is ill formed, a 400 code is returned. We don’t specify the type returned since bad requests are automatically handled by the ASP.NET Core framework <a id="_idIndexMarker1638"/>through the <code class="inlineCode">ApiController</code> attribute.</li>
<li class="bulletList">In the case of <a id="_idIndexMarker1639"/>unexpected errors, a 500 code is returned with the exception error message.</li>
</ul>
<p class="normal">Now, let’s define the <code class="inlineCode">PackagesListDTO</code> class in a new <code class="inlineCode">DTOs</code> folder:</p>
<pre class="programlisting code"><code class="hljs-code">namespace WWTravelClubWebAPI80.DTOs;
public record PackagesListDTO
{
    public int Id { get; set; }
    public string Name { get; set; }
    public decimal Price { get; set; }
    public int DurationInDays { get; set; }
    public DateTime? StartValidityDate { get; set; }
    public DateTime? EndValidityDate { get; set; }
    public string DestinationName { get; set; }
    public int DestinationId { get; set; }
}
</code></pre>
<p class="normal">Finally, let’s add the following <code class="inlineCode">using</code> clauses to our controller code so that we can easily refer to our DTO and Entity Framework LINQ methods:</p>
<pre class="programlisting code"><code class="hljs-code">using Microsoft.EntityFrameworkCore;
using WWTravelClubWebAPI80.DTOs;
</code></pre>
<p class="normal">Now, we are ready to fill the body of the <code class="inlineCode">GetPackagesByDate</code> method with the following code.</p>
<pre class="programlisting code"><code class="hljs-code">try
{
    var res = await ctx.Packages
        .Where(m =&gt; start &gt;= m.StartValidityDate
        &amp;&amp; stop &lt;= m.EndValidityDate)
        .Select(m =&gt; new PackagesListDTO
        {
            StartValidityDate = m.StartValidityDate,
            EndValidityDate = m.EndValidityDate,
            Name = m.Name,
            DurationInDays = m.DurationInDays,
            Id = m.Id,
            Price = m.Price,
            DestinationName = m.MyDestination.Name,
            DestinationId = m.DestinationId
        })
        .ToListAsync();
    return Ok(res);
}
catch (Exception err)
{
    return StatusCode(500, err.ToString());
}
</code></pre>
<p class="normal">It is important to<a id="_idIndexMarker1640"/> remember that we are focusing only on presenting the results of an API exposed using the <code class="inlineCode">Swashbuckle.AspNetCore</code> NuGet package. It is not a good practice to make use of the <code class="inlineCode">DbContext</code> in a <code class="inlineCode">Controller</code> <a id="_idIndexMarker1641"/>class, and as a software architect, you may define the best architectural design for your application (multi-tier, hexagonal, onion, clean, DDD, and so on).</p>
<p class="normal">The LINQ query is like the one contained in the <code class="inlineCode">WWTravelClubDBTest</code> project we tested in <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>. Once the result has been computed, it is returned with an <code class="inlineCode">OK</code> call. The method’s code handles internal server errors by catching exceptions and returning a 500 status code since bad requests are automatically handled before the <code class="inlineCode">Controller</code> method is called by the <code class="inlineCode">ApiController</code> attribute.</p>
<p class="normal">Let’s run the solution. When the browser opens, it is unable to receive any result from our ASP.NET Core website. Let’s modify the browser URL so that it is <code class="inlineCode">https://localhost:&lt;previous port&gt;/swagger</code>. It is worth mentioning that you can also configure your local settings file to either launch and go to the Swagger URL automatically, or have Swagger live under the root.</p>
<p class="normal">The user interface of the OpenAPI documentation will look as follows:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_15.png"/></figure>
<p class="packt_figref">Figure 21.15: Swagger output</p>
<p class="normal"><strong class="screenText">PackagesListDTO</strong> is the model we defined to list the packages, while <strong class="screenText">ProblemDetails</strong> is the model that is used to <a id="_idIndexMarker1642"/>report errors in the event of bad requests. By clicking the <strong class="screenText">GET</strong> button, we can get <a id="_idIndexMarker1643"/>more details about our <code class="inlineCode">GET</code> method and we can also test it, as shown in the following screenshot:</p>
<figure class="mediaobject"><img alt="Interface gráfica do usuário, Aplicativo  Descrição gerada automaticamente" src="img/B19820_21_16.png"/></figure>
<p class="packt_figref">Figure 21.16: GET method details</p>
<p class="normal">Pay attention when it comes to<a id="_idIndexMarker1644"/> inserting dates that are covered by packages in the database; otherwise, an <a id="_idIndexMarker1645"/>empty list will be returned. The ones shown in the preceding screenshot should work.</p>
<p class="normal">Dates must be entered in a correct JSON format; otherwise, a 400 Bad Request error is returned, like the one shown in the following code:</p>
<pre class="programlisting code"><code class="hljs-code">{
"errors": {
"start": [
"The value '2019' is not valid."
]
},
"title": "One or more validation errors occurred.",
"status": 400,
"traceId": "80000008-0000-f900-b63f-84710c7967bb"
}
</code></pre>
<p class="normal">If you insert the correct input parameters, the Swagger UI returns the packages that satisfy the query in JSON format.</p>
<p class="normal">That is all! You have implemented your first API with OpenAPI documentation! Now let’s check how easy it can be to implement a serverless solution using Azure Functions.</p>
<h1 class="heading-1" id="_idParaDest-453">Implementing Azure Functions to send emails</h1>
<p class="normal">Here, we will use a subset of the <a id="_idIndexMarker1646"/>Azure components. The use case from WWTravelClub proposes a worldwide implementation of the service, and there is a chance that this service will need different architecture designs to achieve all the key performance points that we described in <em class="italic">Chapter 1</em>, <em class="italic">Understanding the Importance of Software Architecture</em>.</p>
<p class="normal">If you go back to the user stories that were described in this chapter, you will find that many needs are related to communication. Because of this, it is common to have some alerts provided by emails in the solution. This implementation will focus on how to send emails. The architecture will be totally serverless. The benefits of using an architecture like that are explained below.</p>
<p class="normal">The following diagram shows the basic structure of the architecture. To give users a great experience, all the emails that are sent by the application will be queued asynchronously, thereby<a id="_idIndexMarker1647"/> preventing significant delays in the system’s responses:</p>
<figure class="mediaobject"><img alt="Diagram  Description automatically generated" src="img/B19820_21_17.png"/></figure>
<p class="packt_figref">Figure 21.17: Architectural design for sending emails</p>
<p class="normal">Basically, when a user does any action that requires sending an alert (1), the alert is posted in a <strong class="keyWord">send email request function</strong> (2), which stores the request in Azure Queue Storage (3). So, for the user, the alert is already performed at this moment, and they can keep working. However, since we have a queue, no matter the number of alerts sent, they will be processed by the <strong class="keyWord">send email function </strong>that is triggered (4) as soon as a request is made, respecting the time needed to process the requests, but guaranteeing that the receiver will get the alert (5). Note that there are no dedicated servers that manage Azure Functions for enqueuing or dequeuing messages from Azure Queue Storage. This is exactly what we call serverless, as described in <em class="italic">Chapter 16, Working with Serverless - Azure Functions</em>. It is worth mentioning that this architecture is not restricted to only sending emails – it can also be used to process any HTTP <code class="inlineCode">POST</code> request.</p>
<p class="normal">Now, we will learn, in three steps, how to set up security in the API so that only authorized applications can use the given solution.</p>
<h2 class="heading-2" id="_idParaDest-454">First step — creating an Azure queue storage</h2>
<p class="normal">It is quite simple to create<a id="_idIndexMarker1648"/> storage in the Azure portal. Let us learn how. First, you will need to create a storage account by clicking on <strong class="screenText">Create a resource</strong> on the main page of the Azure portal and searching for <strong class="screenText">Storage account</strong>. Then, you will be able to set up its basic information, such as <strong class="screenText">Storage account name</strong> and <strong class="screenText">Location</strong>. Information about <strong class="screenText">Networking</strong> and <strong class="screenText">Data protection</strong>, as shown in the following screenshot, can be checked in this wizard, too. There are default values for these settings that we will cover the demo:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_18.png"/></figure>
<p class="packt_figref">Figure 21.18: Creating an Azure storage account</p>
<p class="normal">Once you have the storage account in place, you will be able to set up a queue. You will find this option by clicking on the <strong class="screenText">Overview</strong> link in the storage account and selecting the <strong class="screenText">Queue service</strong> option <a id="_idIndexMarker1649"/>or by selecting <strong class="screenText">Queues</strong> via the <strong class="screenText">Storage account</strong> menu. Then, you will find an option to add the queue (<strong class="screenText">+ Queue</strong>), where you just need to provide its name:</p>
<figure class="mediaobject"><img alt="Interface gráfica do usuário, Texto, Aplicativo  Descrição gerada automaticamente" src="img/B19820_21_19.png"/></figure>
<p class="packt_figref">Figure 21.19: Defining a queue to monitor emails</p>
<p class="normal">The created queue will give you an overview of the Azure portal. There, you will find your queue’s URL and be able to use Storage Explorer:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_20.png"/></figure>
<p class="packt_figref">Figure 21.20: Queue created</p>
<p class="normal">Note that you will also be able to connect to this storage using Microsoft Azure Storage Explorer (<a href="https://azure.microsoft.com/en-us/features/storage-explorer/">https://azure.microsoft.com/en-us/features/storage-explorer/</a>):</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_21.png"/></figure>
<p class="packt_figref">Figure 21.21: Monitoring the queue using Microsoft Azure Storage Explorer</p>
<p class="normal">This tool is especially <a id="_idIndexMarker1650"/>useful if you are not connected to the Azure portal. Let’s move to the second step, where we will create the function that receives the requests to send emails.</p>
<h2 class="heading-2" id="_idParaDest-455">Second step — creating the function to send emails</h2>
<p class="normal">Now, you can start programming in earnest, informing the queue that an email is waiting to be sent. Here, we <a id="_idIndexMarker1651"/>need to use an HTTP trigger. Note that the function is a static class that runs asynchronously. The following code, written in Visual Studio, gathers the request data coming from the HTTP trigger and inserts the data into a queue that will be processed later. It is worth mentioning that the environment variable <code class="inlineCode">EmailQueueConnectionString</code> is set in the function app settings, and it contains the information provided by the Azure Queue Storage connection string.</p>
<p class="normal">We have below a code snippet from the function available in the GitHub repository of the book:</p>
<pre class="programlisting code"><code class="hljs-code">public static class SendEmail
{
    [FunctionName(nameof(SendEmail))]
    public static async Task&lt;HttpResponseMessage&gt;RunAsync( [HttpTrigger(AuthorizationLevel.Function, "post")] HttpRequestMessage req, ILogger log)
    {
        var requestData = await req.Content.ReadAsStringAsync();
        var connectionString = Environment.GetEnvironmentVariable("EmailQueueConnectionString");
        var storageAccount = CloudStorageAccount.Parse(connectionString);
        var queueClient = storageAccount.CreateCloudQueueClient();
        var messageQueue = queueClient.GetQueueReference("email");
        var message = new CloudQueueMessage(requestData);
        await messageQueue.AddMessageAsync(message);
        log.LogInformation("HTTP trigger from SendEmail function processed a request.");
        var responseObj = new { success = true };
        return new HttpResponseMessage(HttpStatusCode.OK)
        {
            Content = new StringContent(JsonConvert.SerializeObject(responseObj), Encoding.UTF8, "application/json"),
         };
    }
}
</code></pre>
<div><p class="normal">In some scenarios, you <a id="_idIndexMarker1652"/>may try to avoid the queue setup indicated in the preceding code by using a queue output binding. Check out the details at <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue-output?tabs=csharp">https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-storage-queue-output?tabs=csharp</a>.</p>
</div>
<p class="normal">You can use a tool such as Postman to test your function. Before that, you just need to run the app in Visual Studio, which will launch Azure Functions Core Tools and its emulator:</p>
<figure class="mediaobject"><img alt="Interface gráfica do usuário, Texto, Aplicativo  Descrição gerada automaticamente" src="img/B19820_21_22.png"/></figure>
<p class="packt_figref">Figure 21.22: Postman function test</p>
<p class="normal">The result will appear in<a id="_idIndexMarker1653"/> Microsoft Azure Storage Explorer and the Azure portal. In the Azure portal, you can manage each message and dequeue each of them or even clear the queue storage:</p>
<figure class="mediaobject"><img alt="Interface gráfica do usuário, Texto, Aplicativo, Email  Descrição gerada automaticamente" src="img/B19820_21_23.png"/></figure>
<p class="packt_figref">Figure 21.23: HTTP trigger and queue storage test</p>
<p class="normal">To finish this topic, let’s <a id="_idIndexMarker1654"/>move on to the final third step, where we will create the function that will process the requests for sending emails.</p>
<h2 class="heading-2" id="_idParaDest-456">Third step — creating the queue trigger function</h2>
<p class="normal">After this, you can create a second <a id="_idIndexMarker1655"/>function by right-clicking the project and selecting <strong class="screenText">Add -&gt; New Azure Function</strong>. This one will be triggered by data entering your queue. It is worth mentioning that, for Azure Functions v4, you will have the <code class="inlineCode">Microsoft.Azure.WebJobs.Extensions.Storage</code> library added as a NuGet reference automatically:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" src="img/B19820_21_24.png"/></figure>
<p class="packt_figref">Figure 21.24: Creating a queue trigger</p>
<p class="normal">Once you have set the <a id="_idIndexMarker1656"/>connection string inside <code class="inlineCode">local.settings.json</code>, you will be able to run both functions and test them with Postman. The difference is that, with the second function running, if you set a breakpoint at the start of it, you will be able to check whether the message has been sent:</p>
<figure class="mediaobject"><img alt="Tela de computador com texto preto sobre fundo branco  Descrição gerada automaticamente" src="img/B19820_21_25.png"/></figure>
<p class="packt_figref">Figure 21.25: Queue triggered in Visual Studio 2022</p>
<p class="normal">From this point, the way <a id="_idIndexMarker1657"/>to send emails will depend on the email options you have. You may decide to use a proxy or connect directly to your email server.</p>
<p class="normal">There are several advantages to creating an email service this way:</p>
<ul>
<li class="bulletList">Once your service has been coded and tested, you can use it to send emails from any of your applications. This means that your code can always be reused.</li>
<li class="bulletList">Apps that use this service will not be stopped from sending emails due to the asynchronous advantages of posting in an HTTP service.</li>
<li class="bulletList">You do not need to pool the queue to check whether data is ready for processing.</li>
</ul>
<p class="normal">Finally, the queue process runs concurrently, which delivers a better experience in most cases. It is possible to turn it off by setting some properties in <code class="inlineCode">host.json</code>. All the options for this can be found in the <em class="italic">Further reading</em> section at the end of this chapter.</p>
<p class="normal">In this part of the case study, we checked an example of an architecture where you connect multiple functions to avoid pooling data and enable concurrent processing. We have seen with this demo <a id="_idIndexMarker1658"/>how great the fit between serverless and event-driven architecture is.</p>
<p class="normal">Now, let’s change the subject a bit, and discuss how to implement a frontend microservice.</p>
<h1 class="heading-1" id="_idParaDest-457">A frontend microservice</h1>
<p class="normal">In this section, as an example of an ASP.NET Core MVC frontend microservice described in <em class="italic">Chapter 18, Implementing Frontend Microservices with ASP.NET Core</em>, we will implement the administrative panel for <a id="_idIndexMarker1659"/>managing the destinations and packages of the <code class="inlineCode">WWTravelClub</code> book use case. The application will be implemented with the<strong class="keyWord"> </strong>DDD<strong class="keyWord"> </strong>approach and associated patterns described in <em class="italic">Chapter 7</em>, <em class="italic">Understanding the Different Domains in Software Solutions</em>. So, having a good understanding of that chapter is a fundamental prerequisite to reading this chapter. The subsections that follow describe the overall application specifications and organization. The full code of the example can be found in the <code class="inlineCode">ch19</code> folder of the GitHub repository associated with the book.</p>
<p class="normal">As usual, let’s start by stating clearly our frontend microservice specifications.</p>
<h2 class="heading-2" id="_idParaDest-458">Defining application specifications</h2>
<p class="normal">The destinations and packages were described in <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>. Here, we will use the same data model, with the necessary modifications to adapt it to the DDD<a id="_idIndexMarker1660"/> approach. The administrative panel must allow packages, a destination listing, and CRUD operations on it. To simplify the application, the two listings will be quite simple: the application will show all destinations sorted according to their names, while all packages will be sorted starting from the ones with a later validity date.</p>
<p class="normal">Furthermore, we make the following assumptions:</p>
<ul>
<li class="bulletList">The application that shows destinations and packages to the user shares the same database used by the administrative panel. Since only the administrative panel application needs to modify data, there will be just one write copy of the database with several read-only replicas.</li>
<li class="bulletList">Price modifications and package deletions are immediately used to update the user’s shopping carts. For this reason, the administrative application must send asynchronous<a id="_idIndexMarker1661"/> communications about price changes and package removals. We will not implement all the communication logic here, but we will just add all such events to an event table, which should be used as input to a parallel thread that’s in charge of sending these events to all relevant microservices.</li>
</ul>
<p class="normal">Here, we will give the full code for just package management; most of the code for destination management is designed as an exercise for you. The full code is available in the <code class="inlineCode">ch16</code> folder of the GitHub repository associated with this book. In the remainder of this section, we will describe the application’s overall organization and discuss some relevant samples of code. We start with an overall description of the application architecture.</p>
<h2 class="heading-2" id="_idParaDest-459">Defining the application architecture</h2>
<p class="normal">The application is organized based on the guidelines described in <em class="italic">Chapter 7</em>, <em class="italic">Understanding the Different Domains in Software Solutions</em>, while considering the DDD approach and related patterns. That is, the<a id="_idIndexMarker1662"/> application is organized into three layers, each implemented as a different project:</p>
<ul>
<li class="bulletList">There’s a domain implementation layer, which contains the repository’s implementation and the classes describing database entities. It is a .NET library project. However, since it needs some interfaces, like <code class="inlineCode">IServiceCollection</code>, which are defined in <code class="inlineCode">Microsoft.NET.Sdk.web</code>, and since the layer <code class="inlineCode">DBContext</code> must inherit from the identity framework in order to also handle the application authentication and authorization database tables, we must add a reference not only to the .NET SDK but also to the ASP.NET Core SDK. This can be done as follows:<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Right-click on the project icon in Solution Explorer and select <strong class="screenText">Edit project file</strong>, or just double-click the project name.</li>
<li class="numberedList">In the <strong class="screenText">Edit</strong> window, add:
            <pre class="programlisting code"><code class="hljs-code">&lt;ItemGroup&gt;
&lt;FrameworkReference
 Include="Microsoft.AspNetCore.App" /&gt;
&lt;/ItemGroup&gt;
</code></pre>
</li>
</ol>
</li>
</ul>
<p class="normal">There’s also a domain layer abstraction, which contains repository specifications – that is, interfaces that describe repository implementations and DDD aggregates. In our implementation, we decided to implement aggregates by hiding<a id="_idIndexMarker1663"/> the forbidden operations/properties of root data entities behind interfaces. Hence, for instance, the <code class="inlineCode">Package</code> entity class, which is an aggregate root, has a corresponding <code class="inlineCode">IPackage</code> interface in the domain layer abstraction that hides all the property setters of the <code class="inlineCode">Package</code> entity. The domain layer abstraction also contains the definitions of all the domain events, while the event handlers that will subscribe to these events are defined in the application layer. <code class="inlineCode">IPackage</code> has also the associated <code class="inlineCode">IPackageRepository</code> repository interface.</p>
<p class="normal">All repository interfaces inherit from the empty <code class="inlineCode">IRepository</code> interface.</p>
<div><p class="normal">This way, they declare it as a repository interface, and all repository interfaces can be automatically discovered with reflection and added to the dependency injection engine together with their implementations.</p>
</div>
<p class="normal">Finally, there’s the application layer – that is, the ASP.NET Core MVC application – where we define DDD queries, commands, command handlers, and event handlers. Controllers fill query objects and execute them to get ViewModels they can pass to Views. They update storage by filling command objects and executing their associated command handlers. In turn, command handlers use <code class="inlineCode">IRepository</code> interfaces (that is, interfaces that inherit from the empty <code class="inlineCode">IRepository</code> interface) and <code class="inlineCode">IUnitOfWork</code> instances coming from the domain layer to manage and coordinate transactions.</p>
<p class="normal">It is worth pointing out that, in more complex microservices, the application layer may be implemented as a separate library project and would contain just DDD queries, commands, command handlers, and event handlers. While, the MVC project would contain just controllers, UIs, and dependency injection.</p>
<p class="normal">The application uses the <strong class="keyWord">Command Query Responsibility Segregation</strong> (<strong class="keyWord">CQRS</strong>) pattern; therefore, it uses command objects to modify the <a id="_idIndexMarker1664"/>storage and the query object to query it.</p>
<p class="normal">The query is simple to use and implement: controllers fill their parameters and then call their execution methods. In turn, query objects have direct LINQ implementations that project results directly onto<a id="_idIndexMarker1665"/> the ViewModels used by the controller Views with <code class="inlineCode">Select</code> LINQ methods. You may also decide to hide the LINQ implementation behind the same repository classes used for the storage update operations, but this would turn the definition and modification of simple queries into very time-consuming tasks.</p>
<p class="normal">In any case, it can be beneficial to encapsulate query objects behind interfaces so that their implementations can be replaced by fake implementations when you test controllers.</p>
<p class="normal">However, the chain of objects and calls involved in the execution of commands is more complex. This is because it requires the construction and modification of aggregates (as well as a definition of the interaction between several aggregates and between aggregates and other applications through domain events) to be provided.</p>
<p class="normal">The following diagram is a sketch of how storage update operations are performed. The circles are data being exchanged between the various layers, while rectangles are the procedures that process them. Moreover, dotted arrows connect interfaces with types that implement them:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_26.png"/></figure>
<p class="packt_figref">Figure 21.26: Diagram of command execution</p>
<p class="normal">Here’s the flow of action through <em class="italic">Figure 21.26</em> as a list of steps:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">A controller’s action method receives one or more ViewModels and performs validation.</li>
<li class="numberedList">One or more ViewModels containing changes to apply are hidden behind interfaces (<code class="inlineCode">IMyUpdate</code>) defined in the domain layer. They are used to fill the properties of a command object. These interfaces must be defined in the domain layer since<a id="_idIndexMarker1666"/> they will be used as arguments of the repository aggregate methods defined there.</li>
<li class="numberedList">A command handler matching the previous command is retrieved via <strong class="keyWord">Dependency Injection</strong> (<strong class="keyWord">DI</strong>) in the controller action method (through the <code class="inlineCode">[FromServices]</code> parameter attribute we described in the <em class="italic">Defining controllers and views</em> subsection). Then, the handler is executed. During its execution, the handler interacts with various repository interface methods and with the aggregates they return.</li>
<li class="numberedList">When creating the command handler discussed in <em class="italic">step 3</em>, the ASP.NET Core DI engine automatically injects all parameters declared in its constructor. In particular, it injects all repository implementations needed to perform all command handler transactions. The command handler performs its job by calling the methods of these <code class="inlineCode">IRepository</code> implementations received in its constructor to build aggregates and modify the built aggregates. Aggregates either represent already-existing entities or newly created ones. Handlers use the <code class="inlineCode">IUnitOfWork</code> interface contained in each repository interface, as well as the concurrency exceptions returned by the data layer, to organize their operations as transactions. It is worth pointing out that each aggregate has its own repository implementation, and that the whole logic for updating each aggregate is defined in the aggregate itself, not in its associated repository implementation, to keep the code more modular.</li>
<li class="numberedList">Behind the scenes, in the domain layer implementation, repository implementations use Entity Framework to perform their job. Aggregates are implemented by root data entities hidden behind interfaces defined in the domain layer, while <code class="inlineCode">IUnitOfWork</code> methods, which handle transactions and pass changes to the database, are implemented with <code class="inlineCode">DbContext</code> methods. In other words, <code class="inlineCode">IUnitOfWork</code> is implemented with the application’s <code class="inlineCode">DbContext</code>.</li>
<li class="numberedList">Domain events are generated during each aggregate process and are added to the aggregates themselves by calling their <code class="inlineCode">AddDomainEvent</code> methods. However, they are not triggered immediately. Usually, they are triggered at the end of all the aggregates’ processing and before changes are passed to the database; however, this is not a general rule.</li>
<li class="numberedList">The application handles errors by throwing exceptions.
    <div><p class="normal">A more efficient approach would be to define a request-scoped object in the dependency engine, where each application subpart may add its errors as domain events. However, while this approach is more efficient, it increases the complexity of the code and the application development time.</p>
</div></li>
</ol>
<p class="normal">The Visual Studio solution is<a id="_idIndexMarker1667"/> composed of three projects:</p>
<ul>
<li class="bulletList">There’s a project containing the domain layer abstraction called <code class="inlineCode">PackagesManagementDomain</code>, which is a .NET Standard 2.1 library. When a library doesn’t use features or NuGet packages that are specific to a .NET version, it is a good practice to implement it as a .NET Standard library because, this way, it doesn’t need modifications when the application is moved to a newer .NET version.</li>
<li class="bulletList">There’s a project containing the whole domain layer implementation called <code class="inlineCode">PackagesManagementDB</code>, which is a .NET 8.0 library.</li>
<li class="bulletList">Finally, there’s an ASP.NET Core MVC 8.0 project called <code class="inlineCode">PackagesManagement</code> that contains both the application and presentation layers. When you define this project, select <strong class="screenText">No Authentication</strong>; otherwise, the user database will be added directly to the ASP.NET Core MVC project instead of to the database layer. We will add the user database manually in the data layer.</li>
</ul>
<p class="normal">Let’s start by creating the <code class="inlineCode">PackagesManagement</code> ASP.NET Core MVC project so that the whole solution has the same name as the ASP.NET Core MVC project. Then, we’ll add the other two library projects to the same solution.</p>
<p class="normal">Finally, let the ASP.NET Core MVC project reference both projects, while <code class="inlineCode">PackagesManagementDB</code> references <code class="inlineCode">PackagesManagementDomain</code>. We suggest you define your own projects and then copy the code of this book’s GitHub repository into them as you read this section.</p>
<p class="normal">The next subsection describes the code of the <code class="inlineCode">PackagesManagementDomain</code> domain layer abstraction project.</p>
<h2 class="heading-2" id="_idParaDest-460">Defining the domain layer abstraction</h2>
<p class="normal">Once the <code class="inlineCode">PackagesManagementDomain</code> Standard 2.1 library project has been added to the solution, we’ll add a <code class="inlineCode">Tools</code> folder to the project root. Then, we’ll place all the <code class="inlineCode">DomainLayer</code> tools contained in the code associated with <code class="inlineCode">ch11</code>. Since the code contained in this folder uses data annotations<a id="_idIndexMarker1668"/> and defines DI extension methods, we must also add references to the <code class="inlineCode">System.ComponentModel.Annotations</code> and<code class="inlineCode"> Microsoft.Extensions.DependencyInjection.Abstration</code> NuGet packages.</p>
<p class="normal">Then, we need an <code class="inlineCode">Aggregates</code> folder containing all the aggregate definitions (remember, we implemented aggregates as interfaces) – namely, <code class="inlineCode">IDestination</code>, <code class="inlineCode">IPackage</code>, and <code class="inlineCode">IPackageEvent</code>. Here, <code class="inlineCode">IPackageEvent</code> is the aggregate associated with the table where we will place events to be propagated to other applications.</p>
<p class="normal">As an example, let’s analyze <code class="inlineCode">IPackage</code>:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IPackage : IEntity&lt;int&gt;
{
    void FullUpdate(IPackageFullEditDTO packageDTO);
    string Name { get; set; } = null!;
    string Description { get;} = null!;
    decimal Price { get; set; }
    int DurationInDays { get; }
    DateTime? StartValidityDate { get;}
    DateTime? EndValidityDate { get; }
    int DestinationId { get; }
       
}
</code></pre>
<p class="normal">It contains the same properties as the <code class="inlineCode">Package</code> entity, which we saw in <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>. The only differences are the following:</p>
<ul>
<li class="bulletList">It inherits from <code class="inlineCode">IEntity&lt;int&gt;</code>, which furnishes all basic functionalities of aggregates</li>
<li class="bulletList">It has no <code class="inlineCode">Id</code> property since it is inherited from <code class="inlineCode">IEntity&lt;int&gt;</code></li>
<li class="bulletList">All properties are read-only, and it has a <code class="inlineCode">FullUpdate</code> method since all aggregates can only be modified through update operations defined in the user domain (in our case, the <code class="inlineCode">FullUpdate</code> method)</li>
</ul>
<p class="normal">Now, let’s also add a <code class="inlineCode">DTOs</code> folder. Here, we place all interfaces used to pass updates to the aggregates. Such interfaces are implemented by the application layer ViewModels used to define such updates. In our case, it contains <code class="inlineCode">IPackageFullEditDTO</code>, which we can use to update existing <a id="_idIndexMarker1669"/>packages. If you would like to add the logic to manage destinations, you must define an analogous interface for the <code class="inlineCode">IDestination</code> aggregate.</p>
<p class="normal">An <code class="inlineCode">IRepositories</code> folder contains all repository specifications – namely, <code class="inlineCode">IDestinationRepository</code>, <code class="inlineCode">IPackageRepository</code>, and <code class="inlineCode">IPackageEventRepository</code>. Here, <code class="inlineCode">IPackageEventRepository</code> is the repository associated with the <code class="inlineCode">IPackageEvent</code> aggregate. As an example, let’s have a look at the <code class="inlineCode">IPackageRepository</code> repository:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IPackageRepository:
        IRepository&lt;IPackage&gt;
{
    Task&lt;IPackage?&gt; GetAsync(int id);
    IPackage New();
    Task&lt;IPackage?&gt; Delete(int id);
}
</code></pre>
<p class="normal">Repositories always contain just a few methods since all business logic should be represented as aggregate methods – in our case, just the methods to create a new package, to retrieve an existing package, and to delete an existing package. The logic to modify an existing package is included in the <code class="inlineCode">FullUpdate</code> method of <code class="inlineCode">IPackage</code>.</p>
<p class="normal">Finally, as with all domain layer projects, <code class="inlineCode">PackagesManagementDomain</code> contains an <code class="inlineCode">Events</code> folder containing all domain event definitions. In our case, the folder is named <code class="inlineCode">Events</code> and contains the package-deleted event and the price-changed event:</p>
<pre class="programlisting code"><code class="hljs-code">public class PackageDeleteEvent: IEventNotification
{
    public PackageDeleteEvent(int id, long oldVersion)
    {
        PackageId = id;
        OldVersion = oldVersion;
    }
    public int PackageId { get; }
    public long OldVersion { get; }
       
}
public class PackagePriceChangedEvent: IEventNotification
{
    public PackagePriceChangedEvent(int id, decimal price,
 long oldVersion, long newVersion)
    {
            PackageId = id;
            NewPrice = price;
            OldVersion = oldVersion;
            NewVersion = newVersion;
     }
    public int PackageId { get; }
    public decimal NewPrice { get; }
    public long OldVersion { get; }
    public long NewVersion { get; }
}
</code></pre>
<p class="normal">When an aggregate sends all its <a id="_idIndexMarker1670"/>changes to another application, it should have a version property. The application that receives the changes uses this version property to apply all changes in the right order. An explicit version number is necessary because changes are sent asynchronously, so the order in which they are received may differ from the order in which they were sent. For this purpose, events that are used to publish changes outside of the application have both <code class="inlineCode">OldVersion</code> (the version before the change) and <code class="inlineCode">NewVersion</code> (the version after the change) properties. Events associated with delete events have no <code class="inlineCode">NewVersion</code> since, after being deleted, an entity can’t store any versions.</p>
<p class="normal">For more details on how to use and process version information to restore the right order of incoming messages, please refer to the <em class="italic">A worker microservice with ASP.NET Core</em> section of this chapter.</p>
<p class="normal">The next subsection explains how all interfaces defined in the domain layer abstraction are implemented in the domain layer implementation.</p>
<h2 class="heading-2" id="_idParaDest-461">Defining the domain layer implementation</h2>
<p class="normal">The data layer project contains<a id="_idIndexMarker1671"/> references to the <code class="inlineCode">Microsoft.AspNetCore.Identity.EntityFrameworkCore</code> and <code class="inlineCode">Microsoft.EntityFrameworkCore.SqlServer</code> NuGet packages, since we are using Entity Framework Core with SQL Server. It references <code class="inlineCode">Microsoft.EntityFrameworkCore.Tools</code> and <code class="inlineCode">Microsoft.EntityFrameworkCore.Design</code>, which are needed to generate database migrations, as explained in the <em class="italic">Entity Framework Core migrations</em> section of <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>.</p>
<p class="normal">We have a <code class="inlineCode">Models</code> folder that contains all database entities. They are similar to the ones in <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>. The only differences are as follows:</p>
<ul>
<li class="bulletList">They inherit from <code class="inlineCode">Entity&lt;T&gt;</code>, which contains all the basic features of aggregates. Please note that inheriting from <code class="inlineCode">Entity&lt;T&gt;</code> is only needed for aggregate roots; all other entities must be defined as explained in <em class="italic">Chapter 7</em>, <em class="italic">Understanding the Different Domains in Software Solutions.</em> In our example, all entities are aggregate roots.</li>
<li class="bulletList">They have no <code class="inlineCode">Id</code> since it is inherited from <code class="inlineCode">Entity&lt;T&gt;</code>.</li>
<li class="bulletList">Some of them have <a id="_idIndexMarker1672"/>an <code class="inlineCode">EntityVersion</code> property that is decorated with the <code class="inlineCode">[ConcurrencyCheck]</code> attribute. It contains the entity version, which is essential for propagating all entity changes to other applications. The <code class="inlineCode">ConcurrencyCheck</code> attribute is needed to prevent concurrency errors while updating the entity version. This prevents suffering the performance penalty implied by a transaction.</li>
</ul>
<p class="normal">More specifically, when saving entity changes, if the value of a field marked with the <code class="inlineCode">ConcurrencyCheck</code> attribute is different from the one that was read when the entity was loaded in memory, a concurrency exception is thrown to inform the calling method that someone else modified this value after the entity was read but before we attempted to save its changes. This way, the calling method can repeat the whole operation with the hope that this time, no one will write the same entity in the database during its execution.</p>
<p class="normal">The only alternative to the <code class="inlineCode">ConcurrencyCheck</code> attribute would be:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Start a transaction.</li>
<li class="numberedList">Read the interested aggregate.</li>
<li class="numberedList">Increment its <code class="inlineCode">EntityVersion</code> property.</li>
<li class="numberedList">Update the aggregate.</li>
<li class="numberedList">Save all changes.</li>
<li class="numberedList">Close the transaction.</li>
</ol>
<p class="normal">The transaction duration would be unacceptably long since the transaction should be maintained for the time of various database commands – namely, from the initial read to the final update – thus, preventing other requests from accessing the involved tables/records for too long a time.</p>
<p class="normal">On the contrary, by using the <code class="inlineCode">ConcurrencyCheck</code> attribute, we open just a very short single-command transaction when the aggregate is saved to the database:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">Read the interested aggregate.</li>
<li class="numberedList">Increment the value of the <code class="inlineCode">EntityVersion</code> property.</li>
<li class="numberedList">Update the aggregate.</li>
<li class="numberedList">Save all changes with a<a id="_idIndexMarker1673"/> fast single-command transaction.</li>
</ol>
<p class="normal">It is worth analyzing the code of the <code class="inlineCode">Package</code> entity:</p>
<pre class="programlisting code"><code class="hljs-code">public class Package: Entity&lt;int&gt;, IPackage
{
    public void FullUpdate(IPackageFullEditDTO o)
    {
        if (IsTransient())
        {
            Id = o.Id;
            DestinationId = o.DestinationId;
        }
        else
        {
            if (o.Price != this.Price)
                this.AddDomainEvent(new PackagePriceChangedEvent(
                        Id, o.Price, EntityVersion, EntityVersion+1));
        }
        Name = o.Name;
        Description = o.Description;
        Price = o.Price;
        DurationInDays = o.DurationInDays;
        StartValidityDate = o.StartValidityDate;
        EndValidityDate = o.EndValidityDate;
    }
    [MaxLength(128)]
    public string Name { get; set; }= null!;
    [MaxLength(128)]
    public string? Description { get; set; }
    public decimal Price { get; set; }
    public int DurationInDays { get; set; }
    public DateTime? StartValidityDate { get; set; }
    public DateTime? EndValidityDate { get; set; }
    public Destination MyDestination { get; set; }= null!;
    [ConcurrencyCheck]
    public long EntityVersion{ get; set; }
    public int DestinationId { get; set; }
}
</code></pre>
<p class="normal">The <code class="inlineCode">FullUpdate</code> method is the only way to update the <code class="inlineCode">IPackage</code> aggregate. When the price changes, add <code class="inlineCode">PackagePriceChangedEvent</code> to the entity list of events.</p>
<p class="normal">The <code class="inlineCode">MainDBContext.cs</code> file <a id="_idIndexMarker1674"/>contains the database context definition. It doesn’t inherit from <code class="inlineCode">DbContext</code> but from the following predefined context class:</p>
<pre class="programlisting code"><code class="hljs-code">IdentityDbContext&lt;IdentityUser&lt;int&gt;, IdentityRole&lt;int&gt;, int&gt;
</code></pre>
<p class="normal">This context defines the user’s tables needed for the authentication. In our case, we opted for the <code class="inlineCode">IdentityUser&lt;T&gt;</code> standard and <code class="inlineCode">IdentityRole&lt;S&gt;</code> for users and roles, respectively, and used integers for both the <code class="inlineCode">T</code> and <code class="inlineCode">S</code> entity keys. However, we may also use classes that inherit from <code class="inlineCode">IdentityUser</code> and <code class="inlineCode">IdentityRole</code> and then add further properties.</p>
<p class="normal">In the <code class="inlineCode">OnModelCreating</code> method, we must call <code class="inlineCode">base.OnModelCreating(builder)</code> in order to apply the configuration defined in <code class="inlineCode">IdentityDbContext</code>.</p>
<p class="normal"><code class="inlineCode">MainDBContext</code> implements <code class="inlineCode">IUnitOfWork</code>. The following code shows the implementation of all methods that start, roll back, and commit a transaction:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task StartAsync()
{
    await Database.BeginTransactionAsync();
}
public Task CommitAsync()
{
    Database.CommitTransaction();
    return Task.CompletedTask;
}
public Task RollbackAsync()
{
    Database.RollbackTransaction();
    return Task.CompletedTask;
}
</code></pre>
<p class="normal">However, they are rarely used by command classes in a distributed environment. This is because retrying the same operation until no concurrency exception is returned usually ensures better performance than transactions.</p>
<p class="normal">It is worth analyzing the implementation of the method that passes all changes applied to <code class="inlineCode">DbContext</code> to the database:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task&lt;bool&gt; SaveEntitiesAsync()
{
    try
    {
        return await SaveChangesAsync() &gt; 0;
    }
    catch (DbUpdateConcurrencyException ex)
    {
        foreach (var entry in ex.Entries)
        {
            entry.State = EntityState.Detached;
                        
        }
        throw;
    }
}
</code></pre>
<p class="normal">The preceding<a id="_idIndexMarker1675"/> implementation just calls the <code class="inlineCode">SaveChangesAsync</code> <code class="inlineCode">DbContext</code> context method, which saves all changes to the database, but then it intercepts all concurrency exceptions and detaches all the entities involved in the concurrency error from the context. This way, the next time a command retries the whole failed operation, their updated versions will be reloaded from the database.</p>
<p class="normal">The <code class="inlineCode">Repositories</code> folder contains all repository implementations. It is worth analyzing the implementation of the <code class="inlineCode">IPackageRepository.Delete</code> method:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task&lt;IPackage?&gt; Delete(int id)
{
    var model = await GetAsync(id);
    if (model is not Package package) return null;
    context.Packages.Remove(package);
    model.AddDomainEvent(
        new PackageDeleteEvent(
            model.Id, package.EntityVersion));
    return model;
}
</code></pre>
<p class="normal">It reads the entity from the database and formally removes it from the <code class="inlineCode">Packages</code> dataset. This will force the entity to be deleted from the database when changes are saved to the database. Moreover, it adds <code class="inlineCode">PackageDeleteEvent</code> to the aggregate list of events.</p>
<p class="normal">The <code class="inlineCode">Extensions</code> folder <a id="_idIndexMarker1676"/>contains the <code class="inlineCode">DBExtensions</code> static class, which, in turn, defines two extension methods to be added to the application DI engine and the ASP.NET Core pipeline, respectively. Once added to the pipeline, these two methods will connect the database layer to the application layer.</p>
<p class="normal">The <code class="inlineCode">IServiceCollection</code> extension of <code class="inlineCode">AddDbLayer</code> accepts (as its input parameters) the database connection string and the name of the <code class="inlineCode">.dll</code> file that contains all migrations. Then, it does the following:</p>
<pre class="programlisting code"><code class="hljs-code">services.AddDbContext&lt;MainDbContext&gt;(options =&gt;
                options.UseSqlServer(connectionString,
                b =&gt; b.MigrationsAssembly(migrationAssembly)));
</code></pre>
<p class="normal">That is, it adds the database context to the DI engine and defines its options – namely, that it uses SQL Server, the database connection string, and the name of the <code class="inlineCode">.dll</code> file that contains all migrations.</p>
<p class="normal">Then, it does the following:</p>
<pre class="programlisting code"><code class="hljs-code">services.AddIdentity&lt;IdentityUser&lt;int&gt;, IdentityRole&lt;int&gt;&gt;()
                .AddEntityFrameworkStores&lt;MainDbContext&gt;()
                .AddDefaultTokenProviders();
</code></pre>
<p class="normal">That is, it adds and configures all the types needed to handle database-based authentication and authorization. It adds <code class="inlineCode">UserManager</code>, which the application layer can use to manage users. <code class="inlineCode">AddDefaultTokenProviders</code> adds the provider that creates the authentication tokens using data contained in the database when users log in.</p>
<p class="normal">Finally, it discovers and adds to the DI engine all repository implementations by calling the <code class="inlineCode">AddAllRepositories</code> method, which is defined in the DDD tools we added to the domain layer project.</p>
<p class="normal">The <code class="inlineCode">UseDBLayer</code> extension method ensures migrations are applied to the database by calling <code class="inlineCode">context.Database.Migrate()</code>, and then it populates the database with some initial objects. In our case, it uses <code class="inlineCode">RoleManager</code> and <code class="inlineCode">UserManager</code> to create an administrative role and an initial administrator, respectively. Then, it creates some sample destinations and packages.</p>
<p class="normal"><code class="inlineCode">context.Database.Migrate()</code> is useful to quickly set up and update staging and test environments. When deploying in production, if we don’t have the credentials for creating a new database or for modifying its structure, we can also produce an SQL script from the migrations using the migration tools. Then, this script should be examined before being applied by the person in charge of maintaining the database and, finally, applied with their credentials.</p>
<p class="normal">To create migrations, we <a id="_idIndexMarker1677"/>must add the aforementioned extension methods to the ASP.NET Core MVC <code class="inlineCode">Program.cs</code> file, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">    ...
    builder.Services.AddRazorPages();
    builder.Services.AddDbLayer(
        builder.Configuration.GetConnectionString("DefaultConnection"),
        "PackagesManagementDB");
    ...
    app.UseAuthentication();
    app.UseAuthorization();
    ...
</code></pre>
<p class="normal">Please be sure that both the authorization and authentication middleware have been added to the ASP.NET Core pipeline in the right order; otherwise, the authentication/authorization engine will not work.</p>
<p class="normal">Then, we must add the connection string to the <code class="inlineCode">appsettings.json</code> file, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">{
"ConnectionStrings": {
"DefaultConnection": "Server=(localdb)\\mssqllocaldb;Database=package-management;Trusted_Connection=True;MultipleActiveResultSets=true"
},
    ...
}
</code></pre>
<p class="normal">Finally, let’s add <code class="inlineCode">Microsoft.EntityFrameworkCore.Design</code> to the ASP.NET Core project.</p>
<p class="normal">At this point, let’s open the Visual Studio Package Manager Console, select <code class="inlineCode">PackageManagementDB</code> as the default project, and then launch the following command:</p>
<pre class="programlisting con"><code class="hljs-con">Add-Migration Initial -Project PackageManagementDB
</code></pre>
<p class="normal">The preceding command will scaffold the first migration. We may apply it to the database with the <code class="inlineCode">Update-Database</code> command. Please note that if you copy the project from GitHub, you don’t need to scaffold migrations since they have already been created, but you still <a id="_idIndexMarker1678"/>need to update the database.</p>
<p class="normal">In the next subsection, we will define the application layer that contains the business logic for manipulating the aggregates.</p>
<h2 class="heading-2" id="_idParaDest-462">Defining the application layer</h2>
<p class="normal">As a first step, for simplicity, let’s<a id="_idIndexMarker1679"/> freeze the application culture to <code class="inlineCode">en-US</code> by adding the following code to the ASP.NET Core pipeline:</p>
<pre class="programlisting code"><code class="hljs-code">app.UseAuthorization();
// Code to add: configure the Localization middleware
var ci = new CultureInfo("en-US");
app.UseRequestLocalization(new RequestLocalizationOptions
{
    DefaultRequestCulture = new RequestCulture(ci),
    SupportedCultures = new List&lt;CultureInfo&gt;
    {
        ci,
    },
     SupportedUICultures = new List&lt;CultureInfo&gt;
    {
        ci,
    }
});
</code></pre>
<p class="normal">Then, let’s create a <code class="inlineCode">Tools</code> folder and place the <code class="inlineCode">ApplicationLayer</code> code there, which you can find in the <code class="inlineCode">ch11</code> code of the GitHub repository associated with this book. With these tools in place, we can add the code that automatically discovers and adds all queries, command handlers, and event handlers to the DI engine, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">...
...
builder.Services.AddAllQueries(this.GetType().Assembly);
builder.Services.AddAllCommandHandlers(this.GetType().Assembly);
builder.Services.AddAllEventHandlers(this.GetType().Assembly);
</code></pre>
<p class="normal">Then, we must add a <code class="inlineCode">Queries</code> folder to place all queries and their associated interfaces. As an example, let’s<a id="_idIndexMarker1680"/> have a look at the query that lists all packages:</p>
<pre class="programlisting code"><code class="hljs-code">public class PackagesListQuery(MainDbContext ctx) :IPackagesListQuery
{
    public async Task&lt;IReadOnlyCollection&lt;PackageInfosViewModel&gt;&gt; GetAllPackages()
    {
        return await ctx.Packages.Select(m =&gt; new PackageInfosViewModel
        {
            StartValidityDate = m.StartValidityDate,
            EndValidityDate = m.EndValidityDate,
            Name = m.Name,
            DurationInDays = m.DurationInDays,
            Id = m.Id,
            Price = m.Price,
            DestinationName = m.MyDestination.Name,
            DestinationId = m.DestinationId
        })
            .OrderByDescending(m=&gt; m.EndValidityDate)
            .ToListAsync();
    }
}
</code></pre>
<p class="normal">The query object is automatically injected into the application DB context. The <code class="inlineCode">GetAllPackages</code> method uses LINQ to project all of the required information into <code class="inlineCode">PackageInfosViewModel</code> and sorts all results in descending order on the <code class="inlineCode">EndValidityDate</code> property.</p>
<p class="normal">Projections that involve several properties are time-wasting and error-prone; that’s why there are mapping libraries that automatically generate these projections using naming conventions and configuration settings. Mapping libraries helps also in copying data from one object to another, such as, for example, from a ViewModel to a DTO, and vice versa.</p>
<p class="normal">Among all mapping software, it is worth at <a id="_idIndexMarker1681"/>least mentioning AutoMapper (<a href="https://www.nuget.org/packages/AutoMapper">https://www.nuget.org/packages/AutoMapper</a>).</p>
<p class="normal"><code class="inlineCode">PackageInfosViewModel</code> is placed in the <code class="inlineCode">Models</code> folder together with all other ViewModels. It is common practice to organize ViewModels into folders by defining a different folder for each <a id="_idIndexMarker1682"/>controller. It is worth analyzing the ViewModel used for editing packages:</p>
<pre class="programlisting code"><code class="hljs-code">public class PackageFullEditViewModel: IPackageFullEditDTO
    {
        public PackageFullEditViewModel() { }
        public PackageFullEditViewModel(IPackage o)
        {
            Id = o.Id;
            DestinationId = o.DestinationId;
            Name = o.Name;
            Description = o.Description;
            Price = o.Price;
            DurationInDays = o.DurationInDays;
            StartValidityDate = o.StartValidityDate;
            EndValidityDate = o.EndValidityDate;
        }
        ...
        ...
</code></pre>
<p class="normal">It has a constructor that accepts an <code class="inlineCode">IPackage</code> aggregate. This way, package data is copied into the ViewModel that is used to populate the edit view. It implements the <code class="inlineCode">IPackageFullEditDTO</code> DTO interface defined in the domain layer. This way, it can be directly used to send <code class="inlineCode">IPackage</code> updates to the domain layer.</p>
<p class="normal">All properties contain validation attributes that are automatically used by client-side and server-side validation engines. Each property contains a <code class="inlineCode">Display</code> attribute that defines the label to give to the input field that will be used to edit the property. It is better to place the field labels in the ViewModels than it is to place them directly into the views since, this way, the same names are automatically used in all views that use the same ViewModel. The following code block lists all its properties:</p>
<pre class="programlisting code"><code class="hljs-code">public int Id { get; set; }
[StringLength(128, MinimumLength = 5), Required]
[Display(Name = "name")]
public string Name { get; set; }= null!;
[Display(Name = "package infos")]
[StringLength(128, MinimumLength = 10), Required]
public string Description { get; set; }= null!;
[Display(Name = "price")]
[Range(0, 100000)]
public decimal Price { get; set; }
[Display(Name = "duration in days")]
[Range(1, 90)]
public int DurationInDays { get; set; }
[Display(Name = "available from"), Required]
public DateTime? StartValidityDate { get; set; }
[Display(Name = "available to"), Required]
public DateTime? EndValidityDate { get; set; }
[Display(Name = "destination")]
public int DestinationId { get; set; }
</code></pre>
<p class="normal">The <code class="inlineCode">Commands</code> folder <a id="_idIndexMarker1683"/>contains all commands. As an example, let’s have a look at the command used to modify packages:</p>
<pre class="programlisting code"><code class="hljs-code">public class UpdatePackageCommand: ICommand
{
    public UpdatePackageCommand(IPackageFullEditDTO updates)
    {
        Updates = updates;
    }
    public IPackageFullEditDTO Updates { get; private set; }
}
</code></pre>
<p class="normal">Its constructor must be invoked with an implementation of the <code class="inlineCode">IPackageFullEditDTO</code> DTO interface, which, in our case, is the edit ViewModel we described previously. Command handlers are placed in the <code class="inlineCode">Handlers</code> folder. It is worth analyzing the command that updates packages:</p>
<pre class="programlisting code"><code class="hljs-code">public class UpdatePackageCommandHandler(IPackageRepository repo, IEventMediator mediator)
</code></pre>
<p class="normal">Its principal constructor has automatically injected the <code class="inlineCode">IPackageRepository</code> repository and an <code class="inlineCode">IEventMediator</code> instance needed to trigger event handlers. The following code also shows the implementation of the standard <code class="inlineCode">HandleAsync</code> command handler method:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task HandleAsync(UpdatePackageCommand command)
{
    bool done = false;
    IPackage model;
    while (!done)
    {
        try
        {
            model = await repo.GetAsync(command.Updates.Id);
            if (model == null) return;
            model.FullUpdate(command.Updates);
            await mediator.TriggerEvents(model.DomainEvents);
            await repo.UnitOfWork.SaveEntitiesAsync();
            done = true;
        }
        catch (DbUpdateConcurrencyException)
        {
          // add some logging here
        }
    }
}
</code></pre>
<p class="normal"><code class="inlineCode">HandleAsync</code> uses the<a id="_idIndexMarker1684"/> repository to get an instance of the entity to modify. If the entity is not found (it has been deleted), the commands stop its execution. Otherwise, all changes are passed to the retrieved aggregate. Immediately after the update, all events contained in the aggregate are triggered. In particular, if the price has changed, the event handler associated with the price change is executed. The concurrency check declared with the <code class="inlineCode">[ConcurrencyCheck]</code> attribute on the <code class="inlineCode">EntityVersion</code> property of the <code class="inlineCode">Package</code> entity ensures that the package version is updated properly (by incrementing its previous version number by 1), as well as that the price-changed event is passed the right version numbers.</p>
<p class="normal">Also, event handlers are placed in the <code class="inlineCode">Handlers</code> folder. As an example, let’s have a look at the price-changed event handler:</p>
<pre class="programlisting code"><code class="hljs-code">public class PackagePriceChangedEventHandler( IPackageEventRepository repo) :
	IEventHandler&lt;PackagePriceChangedEvent&gt;
{
    public Task HandleAsync(PackagePriceChangedEvent ev)
    {
        repo.New(PackageEventType.CostChanged, ev.PackageId,
            ev.OldVersion, ev.NewVersion, ev.NewPrice);
      return Task.CompletedTask;
    }
}
</code></pre>
<p class="normal">The principal constructor has automatically injected the <code class="inlineCode">IPackageEventRepository</code> repository, which handles the database table and all the events to send to other applications. The <code class="inlineCode">HandleAsync</code> implementation simply calls the repository method, which adds a new <code class="inlineCode">IPackageEvent</code> to a queue of events to be sent to other microservices.</p>
<p class="normal">The <code class="inlineCode">IPackageEvent</code> records should be extracted by the above queue and sent to all interested microservices by a<a id="_idIndexMarker1685"/> parallel task, which is not implemented in the GitHub code associated with this section. It can be implemented as a hosted service (thus inheriting from the <code class="inlineCode">BackgroundService</code> class) and then added to the DI engine with a call such as <code class="inlineCode">builder.Services.AddHostedService&lt;MyHostedService&gt;()</code>, as detailed in the <em class="italic">Using generic hosts</em> subsection of <em class="italic">Chapter 11</em>, <em class="italic">Applying a Microservice Architecture to Your Enterprise Application</em>.</p>
<p class="normal">We are almost finished! Just the presentation layer is missing, which, in the case of an MVC-based application, consists of controllers and views. The next subsection defines both controllers and views needed by our microservice.</p>
<h2 class="heading-2" id="_idParaDest-463">Defining controllers and views</h2>
<p class="normal">We need to add two more controllers to<a id="_idIndexMarker1686"/> the one automatically scaffolded by Visual Studio – namely, <code class="inlineCode">AccountController</code>, which takes care of user login/logout and registration, and <code class="inlineCode">ManagePackageController</code>, which handles all package-related operations. It is enough to right-click on the <code class="inlineCode">Controllers</code> folder and then select <strong class="screenText">Add | Controller</strong>. Then, choose the controller name and select the empty MVC controller to avoid the possibility of Visual Studio scaffolding code you don’t need.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_27.png"/></figure>
<p class="packt_figref">Figure 21.27: Adding AccountController</p>
<p class="normal">It is worth pointing out that Visual Studio can automatically scaffold all of the UI for managing users if one <a id="_idIndexMarker1687"/>selects to automatically add authentication when the MVC project is created. However, scaffolded code doesn’t respect any layer or onions architecture: it inserts everything in the MVC project. That’s why we decided to proceed manually.</p>
<p class="normal">For simplicity, our implementation of <code class="inlineCode">AccountController</code> just has login and logout methods, so you can log in just with the initial administrator user. However, you can add further action methods that use the <code class="inlineCode">UserManager</code> class to define, update, and delete users.</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_28.png"/></figure>
<p class="packt_figref">Figure 21.28: Login, logout, and authentication</p>
<p class="normal">The <code class="inlineCode">UserManager</code> class can<a id="_idIndexMarker1688"/> be provided through DI, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">public AccountController(
  UserManager&lt;IdentityUser&lt;int&gt;&gt; userManager,
  SignInManager&lt;IdentityUser&lt;int&gt;&gt; signInManager) : Controller
</code></pre>
<p class="normal"><code class="inlineCode">SignInManager</code> takes care of login/logout operations. The <code class="inlineCode">Logout</code> action method is quite simple and is shown here (for more information on authentication in ASP.NET Core, please refer to the <em class="italic">Defining the ASP.NET Core pipeline</em> section of <em class="italic">Chapter 17</em>, <em class="italic">Presenting ASP.NET Core</em>):</p>
<pre class="programlisting code"><code class="hljs-code">[HttpPost]
public async Task&lt;IActionResult&gt; Logout()
{
    await signInManager.SignOutAsync();
    return RedirectToAction(nameof(HomeController.Index), "Home");
}
</code></pre>
<p class="normal">It just calls the <code class="inlineCode">signInManager.SignOutAsync</code> method and then redirects the browser to the home page. To avoid it being called by clicking a link, it is decorated with <code class="inlineCode">HttpPost</code>, so it can only be invoked via a form submit.</p>
<div><p class="normal">All requests that cause modifications must never use a <code class="inlineCode">GET</code> verb; otherwise, someone might erroneously trigger those actions either by clicking a link or by writing the wrong URL in the browser. An action triggered by GET might also be exploited by a phishing website that might adequately “camouflage” a link that triggers a dangerous GET action. The GET verb should be used just for retrieving information.</p>
</div>
<p class="normal">Login, on the other hand, requires<a id="_idIndexMarker1689"/> two action methods. The first one is invoked via <code class="inlineCode">GET</code> and shows the login form, where the user must place their username and password. It is shown here:</p>
<pre class="programlisting code"><code class="hljs-code">[HttpGet]
public async Task&lt;IActionResult&gt; Login(string? returnUrl = null)
{
    // Clear the existing external cookie
//to ensure a clean login process
await HttpContext
         .SignOutAsync(IdentityConstants.ExternalScheme);
    ViewData["ReturnUrl"] = returnUrl;
    return View();
}
</code></pre>
<p class="normal">It receives <code class="inlineCode">returnUrl</code> as its parameter when the browser is automatically redirected to the login page by the authorization module. This happens when an unlogged-in user tries to access a protected page. <code class="inlineCode">returnUrl</code> is stored in the <code class="inlineCode">ViewState</code> dictionary that is passed to the login view. </p>
<p class="normal">The form in the login view passes it back to the controller, together with the username and password when it is submitted, as shown in this code:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;form asp-route-returnurl="@ViewData["ReturnUrl"]" method="post"&gt;
...
&lt;/form&gt;
</code></pre>
<p class="normal">The form post is intercepted by an action method with the same <code class="inlineCode">Login</code> name but decorated with the <code class="inlineCode">[HttpPost]</code> attribute, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">[ValidateAntiForgeryToken]
public async Task&lt;IActionResult&gt; Login(
    LoginViewModel model,
 string? returnUrl = null)
        {
            ...
</code></pre>
<p class="normal">The preceding method receives the <code class="inlineCode">Login</code> model used by the login view, together with the <code class="inlineCode">returnUrl</code> query string parameter. The <code class="inlineCode">ValidateAntiForgeryToken</code> attribute verifies a token (called an anti-forgery token) that MVC forms automatically. This is then added to a hidden field to prevent XSRF/CSRF attacks.</p>
<div><p class="normal">Forgery attacks exploit authentication cookies stored in the victim’s browser to submit a legitimate authenticated request to a web application. They do this by inducing the user to click a button on a phishing website that causes a submit to the target web application. The fraudulent request is accepted since, once a form is submitted, the authentication cookies for the target URL are automatically sent by the browser. There are just two defenses against this kind of attack:</p>
<ul>
<li class="bulletList">Authentication cookies are defined as same-origin – that is, they are sent from other domains just in case of GET requests. Thus, when a form is submitted from a phishing website to the target application, they are not sent.</li>
<li class="bulletList">Anti-forgery tokens added to forms. In this case, if authentication cookies are sent together with the submitted form, the application understands that the request comes from a different website and blocks it since it is missing a valid anti-forgery token.</li>
</ul>
</div>
<p class="normal">As a first step, the action<a id="_idIndexMarker1690"/> method logs the user out if they are already logged in:</p>
<pre class="programlisting code"><code class="hljs-code">if (User.Identity.IsAuthenticated)
{
      await signInManager.SignOutAsync();
     
}
</code></pre>
<p class="normal">Otherwise, it verifies whether there are validation errors, in which case, it shows the same view filled with the data of the ViewModel to let the user correct their errors:</p>
<pre class="programlisting code"><code class="hljs-code">if (ModelState.IsValid)
{
     ...
}
else
// If we got this far, something failed, redisplay form
return View(model);
</code></pre>
<p class="normal">If the model is valid, <code class="inlineCode">signInManager</code> is used to log the user in:</p>
<pre class="programlisting code"><code class="hljs-code">var result = await signInManager.PasswordSignInAsync(
    model.UserName,
    model.Password, model.RememberMe,
    lockoutOnFailure: false);
</code></pre>
<p class="normal">If the result returned by the operation is successful, the action method redirects the browser to <code class="inlineCode">returnUrl</code> if it’s not null; otherwise, it redirects the browser to the home page:</p>
<pre class="programlisting code"><code class="hljs-code">if (result.Succeeded)
{
    if (!string.IsNullOrEmpty(returnUrl))
        return LocalRedirect(returnUrl);
    else
return RedirectToAction(nameof(HomeController.Index), "Home");
}
else
{
    ModelState.AddModelError(string.Empty,
        "wrong username or password");
    return View(model);
}
</code></pre>
<p class="normal">If the login fails, it adds an <a id="_idIndexMarker1691"/>error to <code class="inlineCode">ModelState</code> and shows the same form to let the user try again.</p>
<p class="normal"><code class="inlineCode">ManagePackagesController</code> contains an <code class="inlineCode">Index</code> method that shows all packages in table format (for more details on controllers, views, and the MVC pattern in general, please refer to the <em class="italic">The MVC pattern</em> section of <em class="italic">Chapter 17</em>, <em class="italic">Presenting ASP.NET Core</em>):</p>
<pre class="programlisting code"><code class="hljs-code">[HttpGet]
public async Task&lt;IActionResult&gt; Index(
    [FromServices] IPackagesListQuery query)
{
    var results = await query.GetAllPackages();
    var vm = new PackagesListViewModel { Items = results };
    return View(vm);
}
</code></pre>
<p class="normal">The query object is injected into the action method by DI. Then, the action method invokes it and inserts the resulting <code class="inlineCode">IEnumerable</code> into the <code class="inlineCode">Items</code> property of a <code class="inlineCode">PackagesListViewModel</code> instance. It is a good practice to include <code class="inlineCode">IEnumerables</code> in ViewModels instead of passing them directly to the views so that, if necessary, other properties can be added without the need to modify the existing view code.</p>
<p class="normal">Moreover, it is good practice to define enumerable properties of ViewModels as <code class="inlineCode">IReadOnlyCollection&lt;T&gt;</code> if the enumerables are read-only or as <code class="inlineCode">IList&lt;T&gt;</code> if the enumerables can be modified or if they are involved in model binding. In fact, <code class="inlineCode">ICollection&lt;T&gt;</code> has a <code class="inlineCode">Count</code> property, which may be very useful when rendering ViewModels in views, while <code class="inlineCode">IList&lt;T</code>&gt; also has indexers that are necessary for rendering all items with appropriate names for model binding to succeed (see this Phil Haack post: <a href="http://haacked.com/archive/2008/10/23/model-binding-to-a-list.aspx">http://haacked.com/archive/2008/10/23/model-binding-to-a-list.aspx</a>). <code class="inlineCode">IEnumerable&lt;T&gt;</code> should be preferred only in the case that one needs the typical lazy evaluation of <code class="inlineCode">IEnumerable&lt;T&gt;.</code></p>
<p class="normal">The results are shown in a Bootstrap table since Bootstrap CSS is automatically scaffolded by Visual Studio. Bootstrap<a id="_idIndexMarker1692"/> is a good choice for a CSS framework, since it is quite simple and extensible, and is not connected to any particular company but is handled by an independent team.</p>
<p class="normal">The result is shown here:</p>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" src="img/B19820_21_29.png"/></figure>
<p class="packt_figref">Figure 21.29: Application packages handling page</p>
<p class="normal">The <strong class="screenText">New package</strong> link (it is shaped like a <strong class="screenText">Bootstrap</strong> button, but it is a link) invokes a controller <code class="inlineCode">Create</code> action method, while the <strong class="screenText">delete</strong> and <strong class="screenText">edit</strong> links in each row invoke a <code class="inlineCode">Delete</code> and <code class="inlineCode">Edit</code> action method, respectively, and pass them the ID of the package shown in the row.</p>
<p class="normal">Here is the implementation of the two row links:</p>
<pre class="programlisting code"><code class="hljs-code">@foreach(var package in Model.Items)
{
&lt;tr&gt;
&lt;td&gt;
&lt;a asp-controller="ManagePackages"
 asp-action="@nameof(ManagePackagesController.Delete)"
 asp-route-id="@package.Id"&gt;
            delete
        &lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;a asp-controller="ManagePackages"
 asp-action="@nameof(ManagePackagesController.Edit)"
 asp-route-id="@package.Id"&gt;
            edit
        &lt;/a&gt;
&lt;/td&gt;
    ...
    ...
</code></pre>
<p class="normal">It is worth describing the code of the <code class="inlineCode">HttpGet</code> and <code class="inlineCode">HttpPost</code> <code class="inlineCode">Edit</code> action methods:</p>
<pre class="programlisting code"><code class="hljs-code">[HttpGet]
public async Task&lt;IActionResult&gt; Edit(
 int id,
    [FromServices] IPackageRepository repo)
{
    if (id == 0) return RedirectToAction(
        nameof(ManagePackagesController.Index));
    var aggregate = await repo.Get(id);
    if (aggregate == null) return RedirectToAction(
        nameof(ManagePackagesController.Index));
    var vm = new PackageFullEditViewModel(aggregate);
    return View(vm);
}
</code></pre>
<p class="normal">The <code class="inlineCode">Edit</code> method of <code class="inlineCode">HttpGet</code> uses <code class="inlineCode">IPackageRepository</code> to retrieve the existing package. If the package is not<a id="_idIndexMarker1693"/> found, that means it has been deleted by some other user, and the browser is redirected again to the list page to show the updated list of packages. Otherwise, the aggregate is passed to the <code class="inlineCode">PackageFullEditViewModel</code> ViewModel, which is rendered by the <code class="inlineCode">Edit</code> view.</p>
<p class="normal">The view used to render the package must render an HTML <code class="inlineCode">select</code> with all possible package destinations, so it needs an instance of the <code class="inlineCode">IDestinationListQuery</code> query that was implemented to assist with the destination selection HTML logic. This query is injected directly into the view since it is the view’s responsibility to decide how to enable the user to select a destination. The code that injects the query and uses it is shown here:</p>
<pre class="programlisting code"><code class="hljs-code">@inject PackagesManagement.Queries.IDestinationListQuery destinationsQuery
@{
    ViewData["Title"] = "Edit/Create package";
    var allDestinations =
        await destinationsQuery.AllDestinations();
}
</code></pre>
<p class="normal">The action method that <a id="_idIndexMarker1694"/>processes the post of the view form is given here:</p>
<pre class="programlisting code"><code class="hljs-code">[HttpPost]
public async Task&lt;IActionResult&gt; Edit(
    PackageFullEditViewModel vm,
    [FromServices] ICommandHandler&lt;UpdatePackageCommand&gt; command)
{
    if (ModelState.IsValid)
    {
        await command.HandleAsync(new UpdatePackageCommand(vm));
        return RedirectToAction(
            nameof(ManagePackagesController.Index));
    }
    else
return View(vm);
}
</code></pre>
<p class="normal">If <code class="inlineCode">ModelState</code> is valid, <code class="inlineCode">UpdatePackageCommand</code> is created and its associated handler is invoked; otherwise, the View is displayed again to the user to enable them to correct all the errors.</p>
<p class="normal">The new links to the package list page and login page must be added to the main menu, which is in the <code class="inlineCode">_Layout</code> view, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">@if (User.Identity.IsAuthenticated)
{
	&lt;li class="nav-item"&gt;
&lt;a class="nav-link text-dark"
 asp-controller="ManagePackages"
 asp-action="Index"&gt;Manage packages&lt;/a&gt;
&lt;/li&gt;
&lt;li class="nav-item"&gt;
&lt;a class="nav-link text-dark"
 href="javascript:document.getElementById('logoutForm').submit()"&gt;
            Logout
        &lt;/a&gt;
&lt;/li&gt;
}
else
{
    &lt;li class="nav-item"&gt;
&lt;a class="nav-link text-dark"
 asp-controller="Account" asp-action="Login"&gt;Login&lt;/a&gt;
&lt;/li&gt;
}
</code></pre>
<p class="normal"><code class="inlineCode">logoutForm</code> is an empty form whose only purpose is to send a post to the <code class="inlineCode">Logout</code> action method. It has been added <a id="_idIndexMarker1695"/>to the end of the body, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">@if (User.Identity.IsAuthenticated)
{
    &lt;form asp-area="" asp-controller="Account"
 asp-action="Logout" method="post"
 id="logoutForm" &gt;&lt;/form&gt;
}
</code></pre>
<p class="normal">Now, the application is ready! You can run it, log in, and start to manage packages.</p>
<p class="normal">After having learned how to implement, in practice, a presentation layer with server-side technologies in this section, we now just need to learn how to implement it also with client-side technologies. We will do this in the next section.</p>
<h1 class="heading-1" id="_idParaDest-464">Using client technologies</h1>
<p class="normal">In this section, we will implement <a id="_idIndexMarker1696"/>a package search application for the WWTravelClub book use case. The first subsection explains how to set up the solution exploiting the domain layer and data layer of the MVC application we implemented in the previous<a id="_idIndexMarker1697"/> section of this chapter.</p>
<h2 class="heading-2" id="_idParaDest-465">Preparing the solution</h2>
<p class="normal">We will modify the <code class="inlineCode">PackagesManagement</code> project both to save coding time and to show how to transform a solution based on <a id="_idIndexMarker1698"/>server-side MVC technology into a solution based on the Blazor client-side technology. </p>
<p class="normal">First of all, create a copy of the <code class="inlineCode">PackagesManagement</code> solution folder we created in the previous section and rename it <code class="inlineCode">PackagesManagementBlazor</code>.</p>
<p class="normal">To open the solution, right-click on the web project (the one named <code class="inlineCode">PackagesManagement</code>) and remove it (the <code class="inlineCode">Remove</code> menu item). Then, go to the solution folder and delete the whole web project folder (the one named <code class="inlineCode">PackagesManagement</code>).</p>
<p class="normal">Now, right-click on the solution and select <strong class="screenText">Add New Project</strong>. Add a new <strong class="screenText">Blazor WebAssembly Standalone App</strong> project called <code class="inlineCode">PackagesManagementBlazor.Client</code>. Select <strong class="screenText">None</strong> for the authentication type, <strong class="screenText">Configure for https</strong>, and <strong class="screenText">Include Sample Pages</strong>. We don’t need authentication since the search-by-location feature we are going to implement must also be available to unregistered users.</p>
<p class="normal">Now, add a <code class="inlineCode">PackagesManagementBlazor.Server</code> <strong class="screenText">ASP.NET Core Web API</strong> project. Select <strong class="screenText">None</strong> for the authentication type, <strong class="screenText">Configure for https</strong>, <strong class="screenText">Enable OpenAPI Support</strong>, and <strong class="screenText">Use Controllers</strong>.</p>
<p class="normal">Finally, add a <code class="inlineCode">PackagesManagementBlazor.Shared</code> <strong class="screenText">Class Library</strong> project, delete the default <code class="inlineCode">Class1</code> class created by Visual Studio, and add this project to both <code class="inlineCode">PackagesManagementBlazor.Client</code> and <code class="inlineCode">PackagesManagementBlazor.Server</code> as reference.</p>
<p class="normal">The server project needs to reference both the domain implementation (<code class="inlineCode">PackagesManagementDB</code>) and the domain abstraction (<code class="inlineCode">PackagesManagementDomain</code>) projects, so please add them as references.</p>
<p class="normal">Both <code class="inlineCode">PackagesManagementBlazor.Client</code> and <code class="inlineCode">PackagesManagementBlazor.Server</code> must start simultaneously, so define them as starting projects by right-clicking on the solutions, selecting <strong class="keyWord">Configure Startup Projects</strong>, and choosing them as startup projects.</p>
<p class="normal">Now, launch the solution to verify that everything works properly. Two browser windows should open, one for testing the REST API project and the other containing a Blazor application.</p>
<p class="normal">Take note of the Blazor application URL (<code class="inlineCode">https://localhost:7027/</code> in my case) since we will need it. </p>
<p class="normal">The Blazor website will exchange data with the REST API website, which runs on a different domain (a domain is identified by both hostname and port number). REST API calls coming from browsers running on different domains are clues of potential phishing attacks; therefore, the receiving server only accepts them if they come from well-known domains (this way, they are sure they don’t come from phishing websites).</p>
<p class="normal">On the other hand, when a browser application tries to communicate with a different URL, the browser detects it and issues the call with a different protocol called CORS. Therefore, as soon as it <a id="_idIndexMarker1699"/>detects the CORS protocol, the receiving server understands it is dealing with a request coming from a different website, and serves the request only if the other domain has been registered with a so-called CORS policy.</p>
<p class="normal">In ASP.NET Core, CORS policies are registered with the <code class="inlineCode">builder.Services.AddCors</code> extension method in <code class="inlineCode">Program.cs</code>.</p>
<p class="normal">Therefore, in our case, we need to register a CORS policy for the domain of the <code class="inlineCode">PackagesManagementBlazor.Client</code> web application in the <code class="inlineCode">PackagesManagementBlazor.Server</code> web application, since all REST API calls of <code class="inlineCode">PackagesManagementBlazor.Client</code> will be issued to <code class="inlineCode">PackagesManagementBlazor.Server</code>.</p>
<p class="normal">Accordingly, let’s open <code class="inlineCode">Program.cs</code> of the <code class="inlineCode">PackagesManagementBlazor.Server</code> project and enable it for CORS by adding this:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddCors(o =&gt; {
    o.AddDefaultPolicy(pbuilder =&gt;
    {
        pbuilder.AllowAnyMethod();
        pbuilder.WithHeaders(HeaderNames.ContentType, HeaderNames.Authorization);
        pbuilder.WithOrigins("https://localhost:7027/");
    });
});
</code></pre>
<p class="normal">Also, add <code class="inlineCode">app.UseCors();</code> in the ASP.NET Core pipeline, immediately before <code class="inlineCode">app.UseAuthorization();</code> .</p>
<p class="normal">Now, we must enable the Blazor application to communicate with this server. Launch the solution again and take note of the REST API URL (in my case, <code class="inlineCode">https://localhost:7269/</code>), and then replace the URL in the <code class="inlineCode">HttpClient</code> configuration in the <code class="inlineCode">Program.cs</code> file of the Blazor application with this URL:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddScoped(sp =&gt; new HttpClient {
 BaseAddress = new Uri("https://localhost:7269/")});
</code></pre>
<p class="normal">Let’s also copy the same connection string of the old web project into the <code class="inlineCode">PackagesManagementBlazor.Server</code> <code class="inlineCode">appsettings.json</code> file:</p>
<pre class="programlisting code"><code class="hljs-code">"ConnectionStrings": {
"DefaultConnection": "Server=(localdb)\\mssqllocaldb;Database=package-management;Trusted_Connection=True;MultipleActiveResultSets=true"
},
</code></pre>
<p class="normal">This way, we can<a id="_idIndexMarker1700"/> reuse the database we have created. We also need to add the same DDD tools we added to the old web project. Add a folder named <code class="inlineCode">Tools</code> in the project root and copy the contents of the <code class="inlineCode">ch07</code> -&gt;<code class="inlineCode"> ApplicationLayer</code> folder of the GitHub repository associated with the book there.</p>
<p class="normal">In order to finish the solution setup, we just need to connect <code class="inlineCode">PackagesManagementBlazor.Server</code> with the domain layer by adding the following code at the end of the services configuration code in the <code class="inlineCode">Program.cs</code> file:</p>
<pre class="programlisting code"><code class="hljs-code">builder.services.AddDbLayer(Configuration
                .GetConnectionString("DefaultConnection"),
                "PackagesManagementDB");
</code></pre>
<p class="normal">It is the same method we added to the old web project. Finally, we can also add the <code class="inlineCode">AddAllQueries</code> extension method, which discovers all queries in the web project:</p>
<pre class="programlisting code"><code class="hljs-code">builder.services.AddAllQueries(this.GetType().Assembly);
</code></pre>
<p class="normal">We don’t need other automatic discovery tools since this is a query-only application.</p>
<p class="normal">Due to a bug in Entity Framework Core 8, you also need to change a setting in the server project that prevents the usage of .NET culture. You must change the <code class="inlineCode">InvariantGlobalization</code> project setting to <code class="inlineCode">false</code>:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;InvariantGlobalization&gt;false&lt;/InvariantGlobalization&gt;
</code></pre>
<p class="normal">At this point, we have the project completely configured. We just need to implement server-side code and client-side code that implements our package search.</p>
<p class="normal">The next subsection<a id="_idIndexMarker1701"/> explains how to design the server-side REST API.</p>
<h2 class="heading-2" id="_idParaDest-466">Implementing the required ASP.NET Core REST APIs</h2>
<p class="normal">As the first step, let’s define the <a id="_idIndexMarker1702"/>ViewModels used in the communication between the server and the client applications. They must be defined in the <code class="inlineCode">PackagesManagementBlazor.Shared</code> project that is referenced by both applications.</p>
<p class="normal">Let’s start with the <code class="inlineCode">PackageInfosViewModel</code> ViewModel, which will be the data structure used by the Blazor application to exchange package info with the server-side REST API:</p>
<pre class="programlisting code"><code class="hljs-code">using System;
namespace PackagesManagementBlazor.Shared
{
    public class PackageInfosViewModel
    {
        public int Id { get; set; }
        public required string Name { get; set; }
        public decimal Price { get; set; }
        public int DurationInDays { get; set; }
        public DateTime? StartValidityDate { get; set; }
        public DateTime? EndValidityDate { get; set; }
        public required string DestinationName { get; set; }
        public int DestinationId { get; set; }
        public override string ToString()
        {
            return $"{Name}. {DurationInDays} days in {DestinationName}, price: {Price}";
        }
    }
}
</code></pre>
<p class="normal">Then, add the ViewModel that encloses all packages to return to the Blazor application:</p>
<pre class="programlisting code"><code class="hljs-code">using System.Collections.Generic;
namespace PackagesManagementBlazor.Shared
{
    public class PackagesListViewModel
    {
        Public required ReadOnlyCollection&lt;PackageInfosViewModel&gt;
            Items { get; set; }
    }
}
</code></pre>
<p class="normal">Now, we can also add our query that searches packages by location. Let’s add a <code class="inlineCode">Queries</code> folder in the root of <a id="_idIndexMarker1703"/>the <code class="inlineCode">PackagesManagementBlazor.Server</code> project and then add the interface that defines our query, <code class="inlineCode">IPackagesListByLocationQuery</code>:</p>
<pre class="programlisting code"><code class="hljs-code">using DDD.ApplicationLayer;
using PackagesManagementBlazor.Shared;
using System.Collections.Generic;
using System.Threading.Tasks;
namespace PackagesManagementBlazor.Server.Queries
{
    public interface IPackagesListByLocationQuery: IQuery
    {
        Task&lt;ReadOnlyCollection&lt;PackageInfosViewModel&gt;&gt;
            GetPackagesOf(string location);
    }
}
</code></pre>
<p class="normal">Finally, let’s also add the query implementation:</p>
<pre class="programlisting code"><code class="hljs-code">public class PackagesListByLocationQuery(MainDbContext ctx):IPackagesListByLocationQuery
{
   
    public async Task&lt;ReadOnlyCollection&lt;PackageInfosViewModel&gt;&gt;
 GetPackagesOfAsync(string location)
    {
        Return new ReadOnlyCollection&lt;PackageInfosViewModel&gt;
	(await ctx.Packages
            .Where(m =&gt; m.MyDestination.Name.StartsWith(location))
            .Select(m =&gt; new PackageInfosViewModel
        {
            StartValidityDate = m.StartValidityDate,
            EndValidityDate = m.EndValidityDate,
            Name = m.Name,
            DurationInDays = m.DurationInDays,
            Id = m.Id,
            Price = m.Price,
            DestinationName = m.MyDestination.Name,
            DestinationId = m.DestinationId
        })
            .OrderByDescending(m=&gt; m.EndValidityDate)
            .ToListAsync());
    }
}
</code></pre>
<p class="normal">We are finally ready to<a id="_idIndexMarker1704"/> define our <code class="inlineCode">PackagesController</code>:</p>
<pre class="programlisting code"><code class="hljs-code">using Microsoft.AspNetCore.Mvc;
using PackagesManagementBlazor.Server.Queries;
using PackagesManagementBlazor.Shared;
using System.Threading.Tasks;
namespace PackagesManagementBlazor.Server.Controllers
{
    [Route("[controller]")]
    [ApiController]
    public class PackagesController : ControllerBase
    {
        // GET api/&lt;PackagesController&gt;/Flor
        [HttpGet("{location}")]
        public async Task&lt;PackagesListViewModel&gt;    
 GetAsync(string location,
            [FromServices] IPackagesListByLocationQuery query )
        {
            return new PackagesListViewModel
            {
                Items = await query.GetPackagesOf(location)
            };
        } 
    }
}
</code></pre>
<p class="normal">The server-side code is finished! Let’s move on to the definition of the Blazor service that communicates with the server.</p>
<h2 class="heading-2" id="_idParaDest-467">Implementing the business logic in a service</h2>
<p class="normal">Let’s add a <code class="inlineCode">ViewModels</code> and a <code class="inlineCode">Services</code> folder to the <code class="inlineCode">PackagesManagementBlazor.Client</code> project. Most of the <a id="_idIndexMarker1705"/>ViewModels we need were defined in the <strong class="keyWord">PackagesManagementBlazor.Shared</strong> project. We only need a ViewModel for the search form. Let’s add it to the <code class="inlineCode">ViewModels</code> folder:</p>
<pre class="programlisting code"><code class="hljs-code">using System.ComponentModel.DataAnnotations;
namespace PackagesManagementBlazor.Client.ViewModels
{
    public class SearchViewModel
    {
        [Required]
        public string? Location { get; set; }
    }
}
</code></pre>
<p class="normal">Let’s call our <a id="_idIndexMarker1706"/>service <code class="inlineCode">PackagesClient</code>, and let’s add it to the <code class="inlineCode">Services</code> folder:</p>
<pre class="programlisting code"><code class="hljs-code">namespace PackagesManagementBlazor.Client.Services
{
    public class PackagesClient
    {
        private HttpClient client;
        public PackagesClient(HttpClient client)
        {
            this.client = client;
        }
        public async Task&lt;IEnumerable&lt;PackageInfosViewModel&gt;&gt;
            GetByLocationAsync(string location)
        {
            var result =
                await client.GetFromJsonAsync&lt;PackagesListViewModel&gt;
                    ("Packages/" + Uri.EscapeDataString(location));
            return result.Items;
        }
    }
}
</code></pre>
<p class="normal">The code is straightforward! The <code class="inlineCode">Uri.EscapeDataString</code> method URL-encodes the parameter so it can be safely appended to the URL.</p>
<p class="normal">Finally, let’s register the service in the dependency injection:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddScoped&lt;PackagesClient&gt;();
</code></pre>
<p class="normal">It is worth pointing out that in a commercial application, we should have registered the service through an <code class="inlineCode">IPackagesClient</code> interface in order to be able to mock it in the tests (<code class="inlineCode">.AddScoped&lt;IPackagesClient, PackagesClient&gt;()</code>).</p>
<p class="normal">With everything in <a id="_idIndexMarker1707"/>place, we just need to build the UI.</p>
<h2 class="heading-2" id="_idParaDest-468">Implementing the user interface</h2>
<p class="normal">As the first step, let’s delete the <a id="_idIndexMarker1708"/>application pages we don’t need – namely, <code class="inlineCode">Pages-&gt;Counter.razor</code> and <code class="inlineCode">Pages-&gt;Weather.razor</code>. Let’s also remove their links from the side menu in <code class="inlineCode">Shared</code> -&gt; <code class="inlineCode">NavMenu.razor</code>.</p>
<p class="normal">We will put our code in the <code class="inlineCode">Pages</code> -&gt; <code class="inlineCode">Home.razor</code> page. Let’s replace the code of this page with the following:</p>
<pre class="programlisting code"><code class="hljs-code">@using PackagesManagementBlazor.Client.ViewModels
@using PackagesManagementBlazor.Shared
@using PackagesManagementBlazor.Client.Services
@inject PackagesClient client
@page "/"
&lt;h1&gt;Search packages by location&lt;/h1&gt;
&lt;EditForm Model="search"
 OnValidSubmit="Search"&gt;
&lt;DataAnnotationsValidator /&gt;
&lt;div class="form-group"&gt;
&lt;label for="integerfixed"&gt;Insert location starting chars&lt;/label&gt;
&lt;InputText @bind-Value="search.Location" /&gt;
&lt;ValidationMessage For="@(() =&gt; search.Location)" /&gt;
&lt;/div&gt;
&lt;button type="submit" class="btn btn-primary"&gt;
        Search
  &lt;/button&gt;
&lt;/EditForm&gt;
@code{
    SearchViewModel search { get; set; } = new SearchViewModel();
    async Task Search()
    {
        ...
    }
}
</code></pre>
<p class="normal">The preceding code adds the needed <code class="inlineCode">@using</code> statements, injects our <code class="inlineCode">PackagesClient</code> service into the page, and<a id="_idIndexMarker1709"/> defines the search form. When the form is successfully submitted, it invokes the <code class="inlineCode">Search</code> callback, where we will place the code that retrieves all the results.</p>
<p class="normal">It is time to add the logic to display all the results and to complete the <code class="inlineCode">@code</code> block. The following code must be placed immediately after the search form:</p>
<pre class="programlisting code"><code class="hljs-code">@if (packages != null)
{
...
}
else if (loading)
{
    &lt;p&gt;&lt;em&gt;Loading...&lt;/em&gt;&lt;/p&gt;
}
@code{
    SearchViewModel search { get; set; } = new SearchViewModel();
    private IEnumerable&lt;PackageInfosViewModel&gt; packages;
    bool loading;
    async Task Search()
    {
        packages = null;
        loading = true;
        await InvokeAsync(StateHasChanged);
        packages = await client.GetByLocationAsync(search.Location);
        loading = false;
    }
}
</code></pre>
<p class="normal">The omitted code in the <code class="inlineCode">if</code> block is responsible for rendering a table with all the results. We will show it after having commented on the preceding code.</p>
<p class="normal">Before retrieving the results with the <code class="inlineCode">PackagesClient</code> service, we remove all previous results and set the <code class="inlineCode">loading</code> field so the Razor code selects the <code class="inlineCode">else if</code> path that replaces the previous table with a loading message. Once we’ve set these variables, we are forced to call <code class="inlineCode">StateHasChanged</code> to trigger change detection and refresh the page. After all the results have been retrieved and the callback returns, there is no need to call <code class="inlineCode">StateHasChanged</code> again because the termination of the callback itself triggers change detection and causes the required page refresh.</p>
<p class="normal">Here is the code that renders the table with all the results:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;div class="table-responsive"&gt;
&lt;table class="table"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col"&gt;Destination&lt;/th&gt;
&lt;th scope="col"&gt;Name&lt;/th&gt;
&lt;th scope="col"&gt;Duration/days&lt;/th&gt;
&lt;th scope="col"&gt;Price&lt;/th&gt;
&lt;th scope="col"&gt;Available from&lt;/th&gt;
&lt;th scope="col"&gt;Available to&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
      @foreach (var package in packages)
      {
        &lt;tr&gt;
&lt;td&gt;
            @package.DestinationName
          &lt;/td&gt;
&lt;td&gt;
            @package.Name
          &lt;/td&gt;
&lt;td&gt;
            @package.DurationInDays
          &lt;/td&gt;
&lt;td&gt;
            @package.Price
          &lt;/td&gt;
&lt;td&gt;
            @(package.StartValidityDate.HasValue ?
              package.StartValidityDate.Value.ToString("d")
              :
              String.Empty)
          &lt;/td&gt;
&lt;td&gt;
            @(package.EndValidityDate.HasValue ?
              package.EndValidityDate.Value.ToString("d")
              :
              String.Empty)
          &lt;/td&gt;
&lt;/tr&gt;
      }
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</code></pre>
<p class="normal">Run the project and write the initial characters of Florence. Since we inserted Florence as a location in the same database in previous chapters (see the <em class="italic">Querying and updating data with Entity Framework Core</em> section of <em class="italic">Chapter 13</em>, <em class="italic">Interacting with Data in C# – Entity Framework Core</em>), some results should appear. If you inserted different data, please try with different starting words.</p>
<p class="normal">Usually, together with<a id="_idIndexMarker1710"/> web-based clients, all applications also furnish mobile-native applications to get a better performance with possibly slow mobile devices. So, let’s also design a mobile-native client application!</p>
<h2 class="heading-2" id="_idParaDest-469">Adding a Blazor MAUI version</h2>
<p class="normal">In this section, we explain how to <a id="_idIndexMarker1711"/>add a Blazor MAUI version to the application of the previous solution.</p>
<p class="normal">First of all, right-click on the solution icon in Solution Explorer and add a new project to the solution. Select a MAUI Blazor application and call it <code class="inlineCode">PackagesManagementMAUIBlazor</code>.</p>
<p class="normal">Open the <code class="inlineCode">PackagesManagementMAUIBlazor</code> project file and remove all the platforms you don’t want to support (I removed Android, iOS, and Mac Catalyst, and kept only Windows):</p>
<pre class="programlisting code"><code class="hljs-code">&lt;TargetFrameworks&gt; Condition="$([MSBuild]::IsOSPlatform('windows'))"&gt;$(TargetFrameworks);net8.0-windows10.0.19041.0 &lt;/TargetFrameworks&gt;
</code></pre>
<p class="normal">Then, add a reference to the <code class="inlineCode">PackagesManagementBlazor.Shared</code> project.</p>
<p class="normal">Now, right-click on the client WebAssembly project and select <strong class="screenText">Open Folder in File Explorer</strong>. Then, copy the <code class="inlineCode">ViewModels</code> and <code class="inlineCode">Services</code> folders, and paste them in Visual Studio Solution Explorer under the newly created <code class="inlineCode">PackagesManagementMAUIBlazor</code> node.</p>
<p class="normal">Then, change the namespaces of the files contained in these folders to be, respectively, <code class="inlineCode">PackagesManagementMAUIBlazor.ViewModels</code> and <code class="inlineCode">PackagesManagementMAUIBlazor.Services</code>.</p>
<p class="normal">Now, replace the content of the <code class="inlineCode">Shared</code> and <code class="inlineCode">Pages</code> folders of the newly created project with the content of the <code class="inlineCode">Layout</code> and <code class="inlineCode">Pages</code> folders of the client Blazor WebAssembly project.</p>
<p class="normal">Edit the newly copied <code class="inlineCode">Home.razor</code> file and replace its header with:</p>
<pre class="programlisting code"><code class="hljs-code">@using PackagesManagementMAUIBlazor.Services
@using PackagesManagementBlazor.Shared
@using PackagesManagementMAUIBlazor.ViewModels
@inject PackagesClient client
@page "/"
</code></pre>
<p class="normal">Finally, add the same <code class="inlineCode">HttpClient</code> and <code class="inlineCode">PackagesClient</code> configurations of the WebAssembly<a id="_idIndexMarker1712"/> project to <code class="inlineCode">MAUIProgram.cs</code>:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddScoped(sp =&gt; new HttpClient
    { BaseAddress = new Uri("https://localhost:7269/") });
builder.Services.AddScoped&lt;PackagesClient&gt;();
</code></pre>
<p class="normal">With this, you must add <code class="inlineCode">PackagesManagementMAUIBlazor</code> to the projects to start. Right-click on the solution and select <strong class="screenText">Configure Startup Projects</strong>.</p>
<p class="normal">In the windows that open, select also the newly created MAUI Blazor project.</p>
<p class="normal">Now, you can launch the application. Three windows should open (two browser windows and a Windows window) but both client project windows should show exactly the same application.</p>
<p class="normal">After having discussed all the components of our WWTravelClub application, we need just to describe how to test it.</p>
<h1 class="heading-1" id="_idParaDest-470">Testing the WWTravelClub application</h1>
<p class="normal">In this section, we add some unit<a id="_idIndexMarker1713"/> and functional test projects to the <code class="inlineCode">PackagesManagement</code> frontend microservice we described in the <em class="italic">A frontend microservice</em> section of this chapter. If you don’t have it, you can download it from the section of the GitHub repository associated with the book in the <code class="inlineCode">ch19</code> folder. It is worth pointing out that in real-world projects, unit test batteries are enhanced by integration tests, and acceptance tests would include not only functional tests but also various kinds of performance tests.</p>
<p class="normal">You are encouraged to review <em class="italic">Chapter 9</em>, <em class="italic">Testing Your Enterprise Application</em>, before continuing with this section.</p>
<p class="normal">As a first step, let’s make a new copy of the solution folder and name it <code class="inlineCode">PackagesManagementWithTests</code>. Then, open the solution and add it to an xUnit .NET C# test project named <code class="inlineCode">PackagesManagementTest</code>. Finally, add a reference to the ASP.NET Core project (<code class="inlineCode">PackagesManagement</code>), since we will test it, and a reference to the latest version of the <code class="inlineCode">Moq</code> <code class="inlineCode">NuGet</code> package, since we require mocking capabilities. </p>
<p class="normal">It is worth remembering that <code class="inlineCode">Moq</code> is a mocking library and that the purpose of mocking is to decouple dependencies between classes by replacing actual classes with mocked classes whose behavior is under the complete control of the test code. This way, each class can be unit tested independently <a id="_idIndexMarker1714"/>from the behavior of other classes it references. For more details about <code class="inlineCode">Moq</code>, please refer to <em class="italic">Chapter 9</em>, <em class="italic">Testing Your Enterprise Application</em>.</p>
<p class="normal">At this point, we are ready to write our tests.</p>
<p class="normal">As an example, we will write unit tests for the <code class="inlineCode">Edit</code> method decorated with <code class="inlineCode">[HttpPost]</code> of the <code class="inlineCode">ManagePackagesController</code> controller, which is shown as follows:</p>
<pre class="programlisting code"><code class="hljs-code">[HttpPost]
public async Task&lt;IActionResult&gt; Edit(
    PackageFullEditViewModel vm,
    [FromServices] ICommandHandler&lt;UpdatePackageCommand&gt; command)
{
    if (ModelState.IsValid)
    {
        await command.HandleAsync(
		new  UpdatePackageCommand(vm));
        return RedirectToAction(
            nameof(ManagePackagesController.Index));
    }
    else
return View(vm);
}
</code></pre>
<p class="normal">Before writing our test methods, let’s rename the test class that was automatically included in the test project as <code class="inlineCode">ManagePackagesControllerTests</code>.</p>
<p class="normal">The first test verifies that if there are errors in <code class="inlineCode">ModelState</code>, the action method renders a view with the same model it received as an argument so that the user can correct all errors. We need to test all possibilities. Let’s delete the existing test method and write an empty <code class="inlineCode">DeletePostValidationFailedTest</code> method, as follows:</p>
<pre class="programlisting code"><code class="hljs-code">[Fact]
public async Task DeletePostValidationFailedTest()
{
}
</code></pre>
<p class="normal">The method must be <code class="inlineCode">async</code> and the <a id="_idIndexMarker1715"/>return type must be <code class="inlineCode">Task</code> since the <code class="inlineCode">Edit</code> method that we have to test is <code class="inlineCode">async</code>. In this test, we don’t need mocked objects since no injected object will be used. Thus, as a preparation for the test, we just need to create a controller instance, and we must add an error to <code class="inlineCode">ModelState</code> as follows:</p>
<pre class="programlisting code"><code class="hljs-code">var controller = new ManagePackagesController();
controller.ModelState
    .AddModelError("Name", "fake error");
</code></pre>
<p class="normal">Then, we invoke the method, injecting <code class="inlineCode">ViewModel</code> and a <code class="inlineCode">null</code> command handler as its arguments, since the command handler will not be used:</p>
<pre class="programlisting code"><code class="hljs-code">var vm = new PackageFullEditViewModel();
var commandDependency =
                new Mock&lt;ICommandHandler&lt;UpdatePackageCommand&gt;&gt;();
var result = await controller.Edit(vm, commandDependency.Object);
</code></pre>
<p class="normal">In the verification stage, we verify that the result is <code class="inlineCode">ViewResult</code> and that it contains the same model that was injected into the controller:</p>
<pre class="programlisting code"><code class="hljs-code">var viewResult = Assert.IsType&lt;ViewResult&gt;(result);
Assert.Equal(vm, viewResult.Model);
</code></pre>
<p class="normal">Now, we also need a test to verify that if there are no errors, the command handler is called, and then the browser is redirected to the <code class="inlineCode">Index</code> controller action method. We call the <code class="inlineCode">DeletePostSuccessTest</code> method:</p>
<pre class="programlisting code"><code class="hljs-code">[Fact]
public async Task DeletePostSuccessTest()
{
}
</code></pre>
<p class="normal">This time, the preparation code must include the preparation of a command handler mock, as follows:</p>
<pre class="programlisting code"><code class="hljs-code">var controller = new ManagePackagesController();
var commandDependency =
    new Mock&lt;ICommandHandler&lt;UpdatePackageCommand&gt;&gt;();
commandDependency
    .Setup(m =&gt;
	m.HandleAsync(It.IsAny&lt;UpdatePackageCommand&gt;()))
    .Returns(Task.CompletedTask);
var vm = new PackageFullEditViewModel();
</code></pre>
<p class="normal">Since the handler <code class="inlineCode">HandleAsync</code> method returns no <code class="inlineCode">async</code> value, we can’t use <code class="inlineCode">ReturnsAsync</code>, but we <a id="_idIndexMarker1716"/>have to return just a completed <code class="inlineCode">Task (Task.Complete)</code> with the <code class="inlineCode">Returns</code> method. The method to test is called with both <code class="inlineCode">ViewModel</code> and the mocked handler:</p>
<pre class="programlisting code"><code class="hljs-code">var result = await controller.Edit(vm,
    commandDependency.Object);
</code></pre>
<p class="normal">In this case, the verification code is as follows:</p>
<pre class="programlisting code"><code class="hljs-code">commandDependency.Verify(m =&gt; m.HandleAsync(
    It.IsAny&lt;UpdatePackageCommand&gt;()),
    Times.Once);
var redirectResult = Assert.IsType&lt;RedirectToActionResult&gt;(result);
Assert.Equal(nameof(ManagePackagesController.Index),
    redirectResult.ActionName);
Assert.Null(redirectResult.ControllerName);
</code></pre>
<p class="normal">As the first step, we verify that the command handler has actually been invoked once. A better verification should also include a check that it was invoked with a command that includes <code class="inlineCode">ViewModel</code> passed to the action method. We will take it up as an exercise.</p>
<p class="normal">Then we verify that the action method returns <code class="inlineCode">RedirectToActionResult</code> with the right action method name and with no controller name specified.</p>
<p class="normal">Once all the tests are ready, if the test window does not appear on the left bar of Visual Studio, we may simply select the <strong class="screenText">Run all tests</strong> item from the Visual Studio <strong class="screenText">Test</strong> menu. Once the test window appears, further invocations can be launched from within this window.</p>
<p class="normal">If a test fails, we can add a breakpoint to its code, so we can launch a debug session on it by right-clicking on it in the test window and then selecting <strong class="screenText">Debug selected tests</strong>. It is worth remembering that failures do not depend necessarily on errors in the code under test but might also depend on errors in the testing code itself.</p>
<p class="normal">In the next subsection, we<a id="_idIndexMarker1717"/> will show how to upload our code to a shared Azure DevOps repository and how to automatize our tests with an Azure DevOps pipeline.</p>
<h2 class="heading-2" id="_idParaDest-471">Connecting to an Azure DevOps repository</h2>
<p class="normal">Tests play a fundamental role in the<a id="_idIndexMarker1718"/> application CI/CD cycle, specifically in CI. They must be executed at least each time the master branch of the application repository is modified to verify that changes don’t introduce bugs.</p>
<p class="normal">The following steps show how to connect our solution to an Azure DevOps repository, where we will define an Azure DevOps pipeline that builds the project, and that also launches all the unit tests we defined in the <code class="inlineCode">PackagesManagementTest</code> project at each build.</p>
<p class="normal">However, the functional tests that we defined in the <code class="inlineCode">PackagesManagementFTest</code> project must be executed only before a sprint is released. Therefore, they must be placed in a different pipeline that takes care of delivering the application.</p>
<p class="normal">In this way, every day after all developers have pushed their changes, we can launch the pipeline to verify that the repository code compiles and passes all the unit tests:</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="1">As a first step, we need a free DevOps subscription. If you don’t already have one, please create one by clicking the <strong class="screenText">Start free</strong> button on this page: <a href="https://azure.microsoft.com/en-us/services/devops/">https://azure.microsoft.com/en-us/services/devops/</a>. Here, let’s follow the wizard to define an organization and then a project.</li>
<li class="numberedList">On the project page, select the <strong class="screenText">Files</strong> menu, click on the <strong class="screenText">Repos</strong> menu item, and then copy the repository URL:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface  Description automatically generated with medium confidence" src="img/B19820_21_30.png"/></figure>
<p class="packt_figref">Figure 21.30: Copying the repository URL</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="3">Ensure you are logged in to Visual Studio with your Azure account (the same one used in the creation <a id="_idIndexMarker1719"/>of the DevOps account). In the <strong class="screenText">Git Changes</strong> tab, click the <strong class="screenText">Create Git Repository...</strong> button:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" src="img/B19820_21_31.png"/></figure>
<p class="packt_figref">Figure 21.31: Opening the connection window</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="4">In the window that opens, select <strong class="screenText">Existing remote</strong> from the left menu and copy and paste the remote repository URL:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" src="img/B19820_21_32.png"/></figure>
<p class="packt_figref">Figure 21.32: Connection window</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="5">Then, click the <strong class="screenText">Create and Push</strong> button and wait until the ready icon in the bottom-left corner of<a id="_idIndexMarker1720"/> Visual Studio is checked:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, application, Teams  Description automatically generated" src="img/B19820_21_33.png"/></figure>
<p class="packt_figref">Figure 21.33: Operation completed</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="6">At this point, the repository has been created locally, connected with the selected remote repository, and all changes have been committed and pushed to the remote repository.</li>
<li class="numberedList">Now, click the <strong class="screenText">Pipelines</strong> menu item to create a DevOps pipeline to build and test your project. In the window that appears, click the button to create a new pipeline:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, application  Description automatically generated" src="img/B19820_21_34.png"/></figure>
<p class="packt_figref">Figure 21.34: Pipeline page</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="8">You will be<a id="_idIndexMarker1721"/> prompted to select where your repository is located:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" src="img/B19820_21_35.png"/></figure>
<p class="packt_figref">Figure 21.35: Repository selection</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="9">Select <strong class="screenText">Azure Repos Git</strong> and then<a id="_idIndexMarker1722"/> your repository. Then, you will be prompted about the nature of the project:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, text, application  Description automatically generated" src="img/B19820_21_36.png"/></figure>
<p class="packt_figref">Figure 21.36: Pipeline configuration</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="10">Select <strong class="screenText">ASP.NET Core</strong>. A pipeline<a id="_idIndexMarker1723"/> for building and testing your project will be automatically created for you. Save it by committing the newly created <code class="inlineCode">.yaml</code> file to your repository:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email  Description automatically generated" src="img/B19820_21_37.png"/></figure>
<p class="packt_figref">Figure 21.37: Pipeline properties</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="11">The pipeline can be run by selecting the <strong class="screenText">Queue</strong> button, but since the standard pipeline <a id="_idIndexMarker1724"/>scaffolded by DevOps has a trigger on the master branch of the repository, it is automatically launched each time changes to this branch are committed and each time the pipeline is modified. The pipeline can be modified by clicking the <strong class="screenText">Edit</strong> button:</li>
</ol>
<figure class="mediaobject"><img alt="Graphical user interface, text, application, email, Teams  Description automatically generated" src="img/B19820_21_38.png"/></figure>
<p class="packt_figref">Figure 21.38: Pipeline code</p>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="12">Once in edit<a id="_idIndexMarker1725"/> mode, all pipeline steps can be edited by clicking the <strong class="screenText">Settings</strong> link that appears above each of them. New pipeline steps can be added as follows:<ol class="alphabeticList" style="list-style-type: lower-alpha;">
<li class="alphabeticList" value="1">Write <code class="inlineCode">- task:</code> where the new step must be added and then accept one of the suggestions that appear while you are typing the task name.</li>
<li class="alphabeticList">Once you have written a valid task name, a <strong class="screenText">Settings</strong> link appears above the new step. Click it.</li>
<li class="alphabeticList">Insert the desired task parameters in the window that appears and then save.</li>
</ol>
</li>
<li class="numberedList">To have our test working, we need to specify the criteria to locate all assemblies that contain tests. In our case, since we have to execute just the tests contained in <code class="inlineCode">PackagesManagementTest.dll</code> and not the ones contained in <code class="inlineCode">PackagesManagementFTest.dll</code>, we must specify the exact .<code class="inlineCode">ddl</code> name.
    <p class="normal">Click the <strong class="screenText">Settings</strong> link of the <code class="inlineCode">VSTest@2</code> test task and replace the content that is automatically suggested for the <strong class="screenText">Test files</strong> field with the following:</p>
<pre class="programlisting code"><code class="hljs-code">**\PackagesManagementTest.dll
!**\*TestAdapter.dll
!**\obj\**
</code></pre></li>
</ol>
<ol class="numberedList" style="list-style-type: decimal;">
<li class="numberedList" value="14">Then, click <strong class="screenText">Add</strong> to modify <a id="_idIndexMarker1726"/>the actual pipeline content. As soon as you confirm your changes in the <strong class="screenText">Save and run</strong> dialog, the pipeline is launched and, if there are no errors, test results are computed. The results of tests launched during a specific build can be analyzed by selecting the specific build in the pipeline <strong class="screenText">Runs</strong> tab and by clicking the <strong class="screenText">Tests</strong> tab on the page that appears. In our case, we should see something like the following screenshot:</li>
</ol>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B19820_21_39.png"/></figure>
<p class="packt_figref">Figure 21.39: Test results</p>
<p class="normal">Summing up, we created a new Azure DevOps repository, published the solution to the new repository, and then created a build pipeline that executes our tests after each build. The build pipeline is<a id="_idIndexMarker1727"/> executed as soon as we save it and will be executed each time someone commits to the master branch.</p>
<h1 class="heading-1" id="_idParaDest-472">Summary</h1>
<p class="normal">The main purpose of this chapter was to deliver pieces of implementations that can be useful to begin the challenge of delivering a software solution for an enterprise. Although we have not shown the complete implemention of the WWTravelClub application, we are confident that the microservices and code provided here can help you in your professional projects; this is in line with what we understand to be the main purpose of a software architect―to help the team in developing software that meets the users’ needs exactly as required.</p>
<h1 class="heading-1">Leave a review!</h1>
<p class="normal">Enjoyed this book? Help readers like you by leaving an Amazon review. Scan the QR code below for a 20% discount code.</p>
<p class="normal"><img alt="" role="presentation" src="img/Leave_a_review_QR.png"/></p>
<p class="normal"><em class="italic">*Limited Offer</em></p>
</div>
</body></html>