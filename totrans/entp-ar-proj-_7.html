<html><head></head><body>
        

                            
                    <h1 class="header-title">AR for Automation with Vuforia and AR Glasses</h1>
                
            
            
                
<p>In this chapter, we will go deeper into Vuforia, the SDK we introduced previously in <a href="3ef942da-7d11-444e-b3e9-ddbf24bb2d09.xhtml">Chapter 6</a>, <em>AR for Retail with Vuforia</em>. You will learn how to use the framework along with AR glasses, more specifically, the Epson Moverio BT-350 model, and you will learn how to use the Vuforia image recognition features to create an app to guide operators, step by step, in industrial works, and how to modify a scene so that you can integrate it into your AR glasses.</p>
<p>It's important to note that to complete this chapter, you will need to have the AR glasses to build upon them. Although we have structured the content so that you can follow most of the process using a mobile Android device, you will only be able to see the final result, the differences in the mobile device view, and the possibilities that the AR see-through devices offer if you can launch the project on the real glasses.</p>
<p>This chapter has three main goals: first of all, to acquire a fuller understanding of how Vuforia works so that you can extend and improve the current example beyond the scope of this book. The second goal is to understand the possibilities AR offers in the industrial field and, specifically, in automation. You will see that AR is not only a visually attractive technology but that it can guide operators in their work, reducing training time and possible errors during operations. The idea is to provide you with the necessary skills to reproduce and adapt the current project to your needs. The final goal is to introduce an AR headset, such as the Epson Moverio AR glasses, to explain how they work and to easily integrate Vuforia with them.</p>
<p class="mce-root"/>
<p>Using AR glasses instead of tablets can be a valuable asset in the industrial field as it allows operators to have both hands free while they are working. The following image shows a pair of AR glasses:</p>
<div><img class="aligncenter size-full wp-image-1628 image-border" src="img/16d3c4e6-e5ff-4ffb-9fe7-49d9b0fd310e.jpg" style="width:27.50em;height:19.83em;"/></div>
<p>The Epson Moverio BT-350 AR glasses</p>
<p>In this chapter, we will be covering the following topics:</p>
<ul>
<li>Using AR in automation</li>
<li>Exploring Vuforia</li>
<li>Developing image-based AR in Vuforia</li>
<li>Creating an industrial guide for AR glasses</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>The technical requirements for this chapter are as follows:</p>
<ul>
<li>A Unity 3D supporting computer (see the latest requirements here: <a href="https://unity3d.com/es/unity/system-requirements">https://unity3d.com/es/unity/system-requirements</a>). This chapter's example project has been developed on a Windows 10 x64 computer.</li>
<li>Unity 3D (2019.1.2f1 in this book).</li>
<li>Microsoft Visual Studio Community 2017 (included in the Unity installation).</li>
<li>The latest version of Vuforia included with Unity 3D (8.3.8 in this book).</li>
<li>Epson Moverio BT-350 AR glasses.</li>
</ul>
<p class="mce-root"/>
<p>The resources and code files for this chapter can be found here: <a href="https://github.com/PacktPublishing/Enterprise-Augmented-Reality-Projects/tree/master/Chapter07">https://github.com/PacktPublishing/Enterprise-Augmented-Reality-Projects/tree/master/Chapter07</a>.</p>
<p>Other AR glasses (from Moverio and other companies) might work with this example. However, some points have to be taken into account, for example, their operating system must be Android 4.1 or above (required by Unity 3D v2019).</p>
<p>Let's get started with AR in automation.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using AR in automation</h1>
                
            
            
                
<p>The arrival of the fourth industrial revolution, also called <strong>industry 4.0</strong>, has boosted the use of AR in industrial environments. Industry 4.0 revolves around digitalization and interconnectivity, and technologies such as <strong>Augmented Reality</strong> (<strong>AR</strong>), <strong>Virtual Reality</strong> (<strong>VR</strong>), the <strong>Internet of Things</strong> (<strong>IoT</strong>), <strong>Big Data Analytics</strong> (<strong>BDA</strong>), <strong>Additive Manufacturing</strong> (<strong>AM</strong>), <strong>Cyber-Physical Systems</strong> (<strong>CPS</strong>), and <strong>Artificial Intelligence</strong> (<strong>AI</strong>) have become the base of this industrial revolution.</p>
<p>AR is the natural interface and connection to IoT and big data. It allows workers to visualize and interact with the data coming from the and sensors of a factory in an easy and attractive way, either using mobile devices or AR headsets.</p>
<p>AR use in automation can go from the facial recognition of an employee to getting access to a concrete machine, to real-time on-site surveillance of the production process or remote access to and control of the system through AR glasses.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Introducing the scenario and process</h1>
                
            
            
                
<p>For this project, we will be creating a step-by-step guide that can be used in production, maintenance, and training. Users performing a task will receive guidance on how to do it correctly, as well as have access to useful information such as blueprints drawings, or pdf documents. </p>
<p class="mce-root"/>
<p>For that, we will use a Volkswagen Beetle (car) as an example. We will work with three pictures as targets (side, back view with the trunk closed, and back view with the trunk open) to simulate an operator that starts from the side of the car and then moves to check the state of the car engine, all while receiving information from the AR glasses. In a real environment, these pictures would correspond with the real car (or industrial equipment).</p>
<p> The images we are going to use in this project have been retrieved from the following link:</p>
<ul>
<li>A 3D model of the Beetle car: <a href="https://sketchfab.com/3d-models/beetlefusca-version-2-2f3bea70178345c8b7cc4424886f9386">https://sketchfab.com/3d-models/beetlefusca-version-2-2f3bea70178345c8b7cc4424886f9386</a></li>
<li>A blueprint: <a href="https://getoutlines.com/blueprints/6826/1968-volkswagen-beetle-sedan-blueprints">https://getoutlines.com/blueprints/6826/1968-volkswagen-beetle-sedan-blueprints</a></li>
<li>An image in a PDF file: <a href="https://getoutlines.com/blueprints/6943/1972-volkswagen-beetle-1500-sedan-blueprints">https://getoutlines.com/blueprints/6943/1972-volkswagen-beetle-1500-sedan-blueprints</a></li>
</ul>
<p>In the next section, we will introduce Vuforia briefly before starting to develop the guide project.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Exploring Vuforia</h1>
                
            
            
                
<p>As we discussed in <a href="3ef942da-7d11-444e-b3e9-ddbf24bb2d09.xhtml">Chapter 6</a>, <em>AR for Retail with Vuforia</em>, Vuforia is one of the oldest and most well-known AR SDKs that has been integrated in Unity since its 2017.2 version. It provides multiple AR features such as image recognition, ground plane recognition, model detection, and so on. You can find all the available features at <a href="https://engine.vuforia.com/features.html">https://engine.vuforia.com/features.html</a>. For this project, we will focus on image recognition.</p>
<p>In <a href="3ef942da-7d11-444e-b3e9-ddbf24bb2d09.xhtml">Chapter 6</a>, <em>AR for Retail with Vuforia</em>, in the <em>Exploring Vuforia</em> section,<em> </em>we explained the steps to integrate Vuforia for the first time in a Unity project. Please follow <em>steps 1-7</em> in that section but change the following parameters:</p>
<ul>
<li>Unity project name (<em>step 3</em>): <kbd>AR_Automation</kbd></li>
<li>Scene name (<em>step 4</em>): <kbd>ARGuide</kbd></li>
<li>Product name (<em>step 6</em>, <em>player settings</em>): <kbd>AR Guide</kbd></li>
</ul>
<p class="mce-root"/>
<p>Finally, set the light's Rotation points or axes to X:<kbd>20</kbd>, Y:<kbd>0</kbd>, and Z:<kbd>0</kbd> and place it inside the ARCamera (as a child) to maintain its directionality:</p>
<div><img class="aligncenter size-full wp-image-1649 image-border" src="img/032bc32d-2358-4629-8468-19fa77960aa7.png" style="width:50.25em;height:40.92em;"/></div>
<p>The Directional Light with its new values and child of the ARCamera</p>
<p>Now that we have the Vuforia engine ready in our project, let's start with the AR creation process.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Developing image-based AR in Vuforia</h1>
                
            
            
                
<p>One of the most powerful features of Vuforia is image recognition. The Vuforia engine can process any <kbd>.jpeg</kbd> or <kbd>.png</kbd> image (our AR marker or target) and extract its main features. It will later compare those features to the real-time images coming from the camera of a mobile device or AR glasses to find that marker in the real world and overlap the virtual elements on it to create the AR. In our case, we will be working with three images of a Beetle car that have been extracted from a 3D model. The images, however, can come from any source, such as real-life pictures or computer designed images.</p>
<p>The next section will show us how to create targets in Vuforia.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating the targets</h1>
                
            
            
                
<p>Vuforia offers two different options when working with images:</p>
<ul>
<li><em>Device databases</em> are groups of image targets that are created through the Vuforia Target Manager and then downloaded and included <em>locally</em> in the project.</li>
<li><em>Cloud recognition </em>makes reference to the hosting and managing of the image targets groups directly <em>online</em>.</li>
</ul>
<p>For this project, we will be using the first option. Databases, also known as <strong>datasets</strong> in the SDK, are groups of targets. They help with the classification of large amounts of targets, as well as memory and CPU usage. Databases can be dynamically loaded/unloaded at runtime and all the targets inside a loaded database will be added to the AR search. At the time of writing this book, there is no hard limit to the number of targets inside a database, although Vuforia recommends no more than 1,000 for performance reasons.</p>
<p>To create our own database and targets, we will have to log into the Vuforia development portal and head to the Target Manager, as shown in the following steps:</p>
<ol>
<li>Go to the Target Manager page at <a href="https://developer.vuforia.com/vui/develop/databases">https://developer.vuforia.com/vui/develop/databases</a>.</li>
<li>Log In or Register (if you don't have an account) to enter the page:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1630 image-border" src="img/77b3402a-6465-419a-a9b6-3c4a04675d03.png" style="width:114.17em;height:47.17em;"/></p>
<p>The Target Manager page</p>
<ol start="3">
<li>Click on Add Database at the top right to create a new database. Because we will be using the Beetle images as targets, give the database the name <kbd>Beetle</kbd>: </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1995 image-border" src="img/df940284-d82b-4199-ad08-bb100bcf6545.png" style="width:25.75em;height:17.58em;"/></p>
<p>Creating a new database</p>
<ol start="4">
<li>Now, click on the created database and click on Add Target.</li>
</ol>
<ol start="5">
<li>Click on the Browse button and select the <kbd>Side.jpg</kbd> image from the <kbd>Targets</kbd> folder of the project's resources. Once it's been uploaded, you will see that the Name field at the bottom will automatically be filled. Give it a Width value of <kbd>1</kbd> and click Add:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"> <img class="aligncenter size-full wp-image-1632 image-border" src="img/4863b319-ff50-4dd0-ae80-4b8c1e89d53b.png" style="width:34.67em;height:39.00em;"/></p>
<p>Creating a new target</p>
<ol start="6">
<li>The target will automatically be created, and next to it, you will see a number of stars, as depicted in the following screenshot. These stars indicate how recognizable the image will be by the AR software. Four or five stars are good targets.</li>
</ol>
<p>If you have any doubt or you want to know more about the other options that appear when you create a target, you can take a look at <a href="https://library.vuforia.com/articles/Solution/How-To-Work-with-Device-Databases.html">https://library.vuforia.com/articles/Solution/How-To-Work-with-Device-Databases.html</a>.</p>
<ol start="7">
<li>Repeat <em>steps 4</em> and <em>step</em> <em>5</em> with the <kbd>Back_closed.jpg</kbd> and <kbd>Back_open.jpg</kbd> images and with the same Width of <kbd>1</kbd> so that all of them will have a similar scale in the Unity editor:</li>
</ol>
<div><img class="aligncenter size-full wp-image-2035 image-border" src="img/5918d141-6923-4072-bb92-8755da508942.png" style="width:69.08em;height:43.67em;"/></div>
<p>The Target Manager page with the Beetle database and its targets</p>
<ol start="8">
<li>Once the three targets have been created, click on Download Database (All), select Unity Editor, and click Download. It will download a <kbd>Beetle.unitypackage</kbd> file that we will import into the project.</li>
<li>Double-click on the <kbd>Beetle.unitypackage</kbd> file to import it in Unity. You can also import it from the Unity editor by clicking on Assets|Import Package|Custom Package… and selecting the file:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1183 image-border" src="img/d5b4b0f4-cf56-4938-a6fb-7dee167bd536.png" style="width:33.83em;height:26.92em;"/></div>
<p>The target database files to be imported in Unity</p>
<ol start="10">
<li>This will add the database to a newly created <kbd>StreamingAssets/Vuforia</kbd> folder and the compressed images of the three targets to the <kbd>Editor/Vuforia/ImageTargetTextures/Beetle</kbd> folder.</li>
</ol>
<p>Now that we have the database included in our project, we are going to add the three targets to the scene by following these steps:</p>
<ol>
<li>Right-click on the Hierarchy window and click on Vuforia Engine|Image. This will create an ImageTarget object in our scene:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1184 image-border" src="img/e6086d01-8591-470b-bae8-7b1e68594484.png" style="width:22.17em;height:43.33em;"/></p>
<p>Adding a Vuforia ImageTarget to the scene</p>
<ol start="2">
<li>By default, the ARCamera and ImageTarget will be in the same position and nothing will appear on camera. Using the Rotation tab, rotate the camera by <kbd>90</kbd> in the X axis and move it upwards <kbd>3</kbd> units until the target is in view:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1185 image-border" src="img/0534e307-2fe9-48d1-af6e-2503e69d59fd.png" style="width:31.83em;height:12.00em;"/></p>
<p>ARCamera Transform values</p>
<ol start="3">
<li>Create the other two ImageTargets and move them until the three are in view. Name them <kbd>Target_Side</kbd>, <kbd>Target_Close</kbd>, and <kbd>Target_Open</kbd> so that you can differentiate between them: </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1634 image-border" src="img/4ca32c4c-5b67-4266-8a6f-9bf6ad1d69de.png" style="width:99.92em;height:41.25em;"/></p>
<p>The three targets in the scene</p>
<ol start="4">
<li>By default, the ImageTarget represents the first target found in the first database, sorted alphabetically. To change it, select the Target_Side in the Hierarchy window, and in the Inspector window, under the Image Target Behavior component, select its image. Do the same with Target_Open. If you want, scale the targets up/down using the scale tab and move them until they look similar and take up all the camera width for a better view: </li>
</ol>
<div><img class="aligncenter size-full wp-image-1186 image-border" src="img/5030841a-2d07-4fac-ae79-08451c58524f.png" style="width:31.83em;height:25.00em;"/></div>
<p>Changing the image reference for the targets</p>
<p>We'll learn how to add test cubes in the next section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding some test cubes</h1>
                
            
            
                
<p>To quickly test our scene, let's create three different objects to visualize on top of each target:</p>
<ol>
<li>Right-click on Target_Side and select 3D Object|Cube.</li>
<li>Scale it down so it doesn't hide the target completely.</li>
</ol>
<p> </p>
<ol start="3">
<li>For Target_Close, create a 3D Object|Sphere instead of a cube, and for Target_Open, create a 3D Object|Capsule.</li>
<li>Scale them down as well so that the targets are partially in view. As it's only for testing purposes, we are not going to add any material or texture to these objects:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1635 image-border" src="img/74c31f19-ea11-4f97-ad56-20f101af0f73.png" style="width:93.50em;height:40.92em;"/> </div>
<p>Testing the 3D objects inside each target</p>
<p>Now, let's obtain our Vuforia key so that we can test the app.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Obtaining the key</h1>
                
            
            
                
<p>In order to test the app or run it on a device, we need to provide a license key in the VuforiaConfiguration object. As we already logged into the Vuforia page to create the targets, we are now going to obtain the required key. Let's get started:</p>
<ol start="1">
<li>Go to the license manager page at <a href="https://developer.vuforia.com/vui/develop/licenses">https://developer.vuforia.com/vui/develop/licenses</a>.</li>
<li>On the License Manager tab, select Get Development Key to obtain a free key to use while developing.</li>
<li>Give it the name of your app, <kbd>AR Guide</kbd>, read and accept the terms, and press Confirm.</li>
<li>Select your newly created license and copy the key.</li>
</ol>
<p> </p>
<ol start="5">
<li>Now, go to the Unity editor and select the ARCamera from the scene.</li>
<li>Click on the Open Vuforia Engine configuration button in the Inspector window to open the general Vuforia configuration:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1187 image-border" src="img/e7454376-9010-4c51-b3bc-b402a4907e29.png" style="width:30.67em;height:46.58em;"/></div>
<p>Opening the Vuforia Engine configuration button</p>
<ol start="7">
<li>Paste your key into the App License Key field:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1188 image-border" src="img/12cec8bb-19d7-4155-870f-3ac6cfc22f3a.png" style="width:33.17em;height:30.67em;"/></p>
<p>Vuforia license key field in the Inspector window</p>
<p>Now, let's test the app to check that our AR scene has been set up properly.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Testing the app</h1>
                
            
            
                
<p>Once the scene has been configured and the key has been added, click on the play button in the top Toolbar and point to the three target images with the webcam. You will see the different 3D objects appearing in each target when pointing at them.</p>
<p>You will be able to see the scene better if you select Maximize on Play in the Game view's top-right corner.</p>
<p class="mce-root"/>
<p>The next image shows the cube appearing over the car side when the camera points at it:</p>
<div><img class="aligncenter size-full wp-image-1636 image-border" src="img/8975d5a8-9fa7-4500-8ed6-1630ed83f790.png" style="width:124.33em;height:76.50em;"/> <br/>
In the Game view, the cube object appears over the Target_Side target</div>
<p>You can find the pictures in the Project window inside the <kbd>Assets/ Editor/Vuforia/ImageTargetTextures/Beetle</kbd> folder. Double-click on them to open them in the computer, and either print them or directly point to them using the webcam.</p>
<p>Now that we have the basic functionality set up, let's create the full app.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Creating an industrial guide for AR glasses</h1>
                
            
            
                
<p>Now that we have the basic setup ready, we are going to create a guide that will instruct workers on how to proceed, step by step, with the maintenance process of a car. The app will show them instructions with visual aids such as colored pictures and arrows that mark which part of the car they have to look at. It will also provide a help PDF file that they will be able to open to consult if needed. </p>
<p class="mce-root"/>
<p>The general working of the app will be as follows:</p>
<ol>
<li>When the app starts, it will ask the worker to point at the car's side to start the process:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1637 image-border" src="img/824cbc07-0b03-464d-a8e0-9608725f9ca0.png" style="width:19.75em;height:10.83em;"/></p>
<p>The initial message</p>
<ol start="2">
<li>When pointing with the camera at the side of the car (Target_Side), a blueprint of it will appear over the top of it, indicating a problem in the engine in red:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1638 image-border" src="img/02584604-8c51-41db-9f4c-8d657d24d0e6.png" style="width:20.92em;height:10.50em;"/></p>
<p>The blueprint over the marker with the engine in red</p>
<ol start="3">
<li>When the operator touches the red square, the app will instruct them to go to the back of the car:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1639 image-border" src="img/81a7e52f-0333-4f2a-a226-2c8106de7075.png" style="width:19.08em;height:9.50em;"/></p>
<p>The message when the user touches the engine</p>
<ol start="4">
<li>When pointing with the camera at the back of the car (Target_Close), the app will indicate to open the trunk via a blinking arrow:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1640 image-border" src="img/13eb829e-685a-4a21-9fa4-1370b8eee40c.png" style="width:21.50em;height:12.50em;"/></p>
<p>The message to open the trunk</p>
<ol start="5">
<li>Once the worker has opened the trunk and is pointing at the engine (Target_Open), the app will indicate that the user needs to remove and change the top left spark plug.</li>
<li>On one side of the screen, a help PDF file with the instructions will be available in case the worker needs them.</li>
<li>When the operator has finished replacing the piece, they will press a button to confirm that they've completed the task:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1641 image-border" src="img/2f2a6144-4095-48bb-9842-eda5c1df344f.png" style="width:22.42em;height:12.67em;"/></p>
<p>The arrow pointing at the spark to replace and the UI buttons of this step</p>
<p>Note: The content we are going to use is just for demonstration purposes and doesn't correspond to the real instructions of this procedure.</p>
<p>In the following section, we are going to add the required material to our project.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Preparing the material</h1>
                
            
            
                
<p>For this project, we are going to use some media content that has to be imported into the project and customized. We have to put it inside the project and then use it in our scene. For that, follow these steps:</p>
<ol>
<li>Create your own folder inside the <kbd>Assets</kbd> folder on the Project window and name it <kbd>@MyAssets</kbd>. Then, create two other folders inside it called <kbd>Images</kbd> and <kbd>Scripts</kbd>:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1189 image-border" src="img/9245a600-84c8-4d4f-9bf6-e2c1e1221c66.png" style="width:36.83em;height:40.58em;"/></div>
<p>Creating a new folder in the Project window</p>
<ol start="2">
<li>From the resources of this chapter, drag the <kbd>arrow.png</kbd>, <kbd>blueprint.png</kbd>, <kbd>icon_file.png</kbd>, and <kbd>icon_home.png</kbd> image files into the <kbd>Images</kbd> folder you just created.</li>
<li>Select the images called icons and in the Inspector window, change their Texture Type to Sprite (2D and UI) so that we can use them inside the UI:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1190 image-border" src="img/7a55925b-1421-4ac0-bba4-bb6b9f30d9c7.png" style="width:62.67em;height:51.42em;"/></p>
<p>Changing the icon texture type</p>
<ol start="4">
<li>Create a new folder in the <kbd>Assets/StreamingAssets</kbd> folder of the Project window, call it <kbd>PDF</kbd>, and drag the <kbd>WorkOrder_0021.pdf</kbd> PDF file to it:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1191 image-border" src="img/b9358354-4d5c-437f-a393-a08b39dea584.png" style="width:33.25em;height:26.50em;"/></div>
<p>The PDF file in the StreamingAssets/PDF folder</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding the UI</h1>
                
            
            
                
<p>An important thing to take into account for this project is that the target device is not a phone or tablet, but AR glasses. When working with glasses, the scene view is duplicated (for each eye) and is smaller than that of a tablet or phone. Thus, the UI and the size of its elements have to be adapted accordingly. </p>
<p>As a summary, for this guide, we are going to need the following elements:</p>
<ul>
<li><strong>Main message</strong>: Some text that occupies most of the screen to provide the main instructions (point at the side of the car, go to the back, and so on).</li>
<li><strong>Bottom message</strong>: Some indication text placed at the bottom of the screen to give secondary instructions combined with AR elements (touch the red elements to see instructions, open the trunk, replace a piece, and so on).</li>
<li><strong>PDF button</strong>: A button for the extra information in PDF format.</li>
<li><strong>Home button</strong>: To return to the initial screen.</li>
</ul>
<p>Let's create all of them step by step:</p>
<ol>
<li>Start by creating a Canvas object in the Hierarchy window:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1192 image-border" src="img/a56469f7-5217-4023-b264-63b5475afe5b.png" style="width:23.33em;height:43.92em;"/></p>
<p>Adding a Canvas to the scene</p>
<p>When creating the Canvas object (parent to any other UI element), an Event System object, which is in charge of the user events that connect with the UI, is automatically created. If you try to create any UI component (for example, text, button, and so on) before creating the Canvas, Unity will create a Canvas element (with its EventSystem object) and make the new component a child of it.</p>
<ol start="2">
<li>In the Inspector window, change the Canvas component's Render Mode from Screen Space - Overlay to World Space and select the ARCamera as Event Camera. This way, the Canvas is placed in the 3D world instead of fixed and can be moved/scaled. In the Rect Transform component, enter the values of the image so that the Canvas is in front of the camera:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1193 image-border" src="img/25726091-1150-4e7a-b5c2-d4aa48180366.png" style="width:27.50em;height:36.92em;"/></p>
<p>Values of the Canvas gameobject</p>
<ol start="3">
<li>Let's create the main message. Right-click on the Canvas element in the Hierarchy window and select UI|Text. Name it <kbd>Main_message</kbd>:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1194 image-border" src="img/4dfe761e-cf4a-4342-9c10-36587277316c.png" style="width:40.08em;height:38.00em;"/></div>
<p>Creating new text inside the Canvas element</p>
<ol start="4">
<li>In the Hierarchy window, change the values on the Rect Transform component to match the following screenshot. Remove the default text, change the Alignment so it's centered in the screen, check the Best Fit checkbox so that the text fills the container, set the Max Size to <kbd>80</kbd> to ensure it's big enough, and change the Color to white:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1195 image-border" src="img/7a6e678c-160b-4cd1-8b03-011538ddda85.png" style="width:21.83em;height:43.75em;"/></div>
<p>Values of the Rect Transform and Text components in the Main_message</p>
<ol start="5">
<li>We are now going to create a secondary message panel. As it's going to be very similar to the previous one, we can directly right-click on the previous and select Duplicate: </li>
</ol>
<div><img class="aligncenter size-full wp-image-1196 image-border" src="img/d4209f63-47bd-4f32-9c9b-aa7052873595.png" style="width:14.42em;height:13.42em;"/></div>
<p>Duplicating the message</p>
<ol start="6">
<li>Change its name to <kbd>Bottom_message</kbd> and change its Rect Transform values so its place is at the bottom of the screen:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1197 image-border" src="img/1fa5fbf3-4b73-4f9d-8e78-b99b8a62f641.png" style="width:23.33em;height:27.33em;"/></p>
<p>New message's values</p>
<ol start="7">
<li>To create the buttons, right-click on the Canvas element and select UI|Button:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1198 image-border" src="img/66093bf4-df8a-430e-b8cb-f9768580572d.png" style="width:40.08em;height:47.00em;"/></div>
<p>Creating a button element on the Canvas</p>
<ol start="8">
<li>Remove the text from it and change the button name to <kbd>Home_button</kbd>.</li>
<li>On the Rect Transform, select anchoring it to the bottom left and copy the values from the image to place it at the bottom left of the screen with an appropriate size for the glasses. </li>
<li>On the Image component, select the <kbd>icon_home</kbd> image as the Source Image, and on the Button component, change the Pressed Color. This way, when the button is clicked, it will change from white to blue: </li>
</ol>
<div><img class="aligncenter size-full wp-image-1199 image-border" src="img/2f224bd8-1ce3-4456-8b2a-30d6387bb2fe.png" style="width:35.42em;height:42.83em;"/></div>
<p>Home_button's values on the Inspector</p>
<ol start="11">
<li>Duplicate the button to create a copy of it and call it <kbd>File_button</kbd>. Change its Rect Transform so that you can locate it at the top-right corner of the screen and change its Source Image to icon_file, as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1200 image-border" src="img/4c39a164-6b4c-4373-aca9-fc5a336adff7.png" style="width:22.67em;height:46.67em;"/></p>
<p>The values of the File_button</p>
<ol start="12">
<li>Now, create the last button from scratch, call it <kbd>OK_button</kbd>, and place it at the bottom-right corner of the screen. Change its Normal Color to light green: </li>
</ol>
<div><img class="aligncenter size-full wp-image-1201 image-border" src="img/8e664f7a-b6af-4c83-be17-a5fdfd43d1ad.png" style="width:71.42em;height:74.75em;"/></div>
<p>Values of the Ok_button element</p>
<ol start="13">
<li>Select the Text child on the button and change the Rect Transform and Text component parameters so that they match what's shown in the following screenshot: </li>
</ol>
<div><img class="aligncenter size-full wp-image-1202 image-border" src="img/fcab318e-0d9c-4cc8-a006-f3758fe9d3e0.png" style="width:26.58em;height:46.42em;"/></div>
<p>Values of the Text element inside the Ok_button</p>
<ol start="14">
<li>Your Scene and Game views should now look like this:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1203 image-border" src="img/0139bb46-cee4-4242-af5f-0c740167874b.png" style="width:57.25em;height:50.67em;"/></p>
<p>Scene and Game views with the created UI</p>
<p>Note that if you press the play button in the Toolbar, you will see that when the real camera feed is launched, the UI disappears. Don't worry about it at this point as we will be adjusting it later in this section.</p>
<div><p class="mceNonEditable">Now that the UI elements are ready, we are going to add the virtual elements, which will appear in AR, and the logic attached to them.</p>
</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Mounting the AR scene</h1>
                
            
            
                
<p>The first thing we are going to do is modify the <kbd>DefaultTrackableEventHandler.cs</kbd> script attached to each of the targets in the scene. This script determines the actions to perform whenever a target is found or lost in the real world; by default, it shows and hides the Renderer, Collider, and Canvas elements attached to any child of that target.</p>
<p>For our app, we need to know whenever a target has been found, and for that, we are going to add a variable to the script.</p>
<p>For this project, we only need to make a slight change in the script. However, if you want to add more code to control when targets are found or lost, it's better to create a new class that inherits from <kbd>ITrackableEventHandler</kbd> like <kbd>DefaultTrackableEventHandler</kbd> does so that you always have a reference class to come back to in case anything fails in your code.</p>
<p>In the Project window, double-click on this script, which you can find in Vuforia|Scripts. When the Visual Studio window opens, we need to add the <kbd>public bool found = false;</kbd> variable to the variables:</p>
<p>Then, <em>inside</em> the <kbd>OnTrackingFound()</kbd> method, add <kbd>found = true;</kbd> at the end.</p>
<p>And <em>inside</em> the <kbd>OnTrackingLost()</kbd> method, add <kbd>found = false;</kbd> at the end.</p>
<p>This way, we can use this variable from any other class to know if a target has been found.</p>
<p>Back in Unity, let's start adding the AR elements. For that, first of all, remove the test 3D cube, sphere, and capsule.</p>
<p>Now, we are going to look at the first target:</p>
<ol>
<li>Right-click on the Target_Side and create a 3D Object|Plane: </li>
</ol>
<div><img class="aligncenter size-full wp-image-1204 image-border" src="img/faca1576-afb8-4387-9b2f-eb31dd00f713.png" style="width:28.17em;height:28.58em;"/></div>
<p>Creating a new plane</p>
<ol start="2">
<li>From the Project window, drag the blueprint image over the plane to make it its texture:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1205 image-border" src="img/6cf264ca-dec4-436c-b6db-2ec89cb7f1aa.png" style="width:27.50em;height:39.50em;"/></p>
<p>Assigning the blueprint image as texture of the plane</p>
<ol start="3">
<li>In the Inspector window, change its name to <kbd>Blueprint</kbd>. On the material panel at the bottom, change the Rendering Mode to Fade to make it transparent and smooth. Now rotate, scale, and move the plane until the blueprint matches the car beneath, as shown in the following screenshot: </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1642 image-border" src="img/78c60e66-c0ac-4510-87c1-a7a81ac99a1f.png" style="width:30.08em;height:32.17em;"/></p>
<p>The blueprint over the target and its values in the Inspector window</p>
<p>Important! Keep the Y position value to <kbd>0.01</kbd> so the drawing is placed over the target but not too far away from it. This is to ensure the AR works correctly and the blueprint won't flicker for being too separated from the target.</p>
<ol start="4">
<li>Now, we have to create another plane that covers the engine area so that when the user touches it, it gives them directions. Create another plane child of the Blueprint and call it <kbd>Engine</kbd>. Move and resize it until it fits the engine area (marked in red in the blueprint):</li>
</ol>
<div><strong>Important!</strong> Keep it <em>on top</em> of the blueprint (Y Position <kbd>0.015</kbd> or <kbd>0.02</kbd>).</div>
<p style="padding-left: 60px">The next image shows the new grey plane placed over the engine area:</p>
<div><img class="aligncenter size-full wp-image-1207 image-border" src="img/74e7e747-3bd2-459f-8ad2-9bcc09e85239.png" style="width:58.75em;height:16.33em;"/><br/>
<br/>
The new plane located over the engine area</div>
<p style="padding-left: 60px">Now, we have to make this plane invisible as it's only going to act as an activator. In the Inspector panel, remove its Mesh Renderer component by clicking on the gear at the top right and selecting Remove Component. Now, you will only see the plane if you select it: </p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1209 image-border" src="img/634c0af9-cf1d-4d1d-a74a-a429411c9c00.png" style="width:27.92em;height:38.67em;"/></p>
<p>Removing the Mesh Renderer component from the plane</p>
<p>Let's move to the second target. This target will show an arrow to indicate to the user to open the trunk:</p>
<ol>
<li>Right-click on Target_Close, create a new 3D Object|Plane, and place it in the middle of the trunk.</li>
<li>Drag the arrow image to the plane to make it its texture.</li>
<li>In the Inspector window, call the plane <kbd>Arrow</kbd>. Remember to set the Y Position to <kbd>0.01</kbd>. In the Material field, set Rendering Mode to Fade and change the Albedo color to a light blue: </li>
</ol>
<div><img class="aligncenter size-full wp-image-1210 image-border" src="img/365b6b00-92bd-4871-94da-9947ad160de4.png" style="width:24.92em;height:38.75em;"/></div>
<p>The values of the Arrow plane</p>
<ol start="4">
<li>To add the blinking effect of the arrow, create a new C# script in the <kbd>@MyAssets/Script</kbd> folder and call it <kbd>Blinking.cs</kbd>:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1211 image-border" src="img/6cec223a-bd64-4a7e-82ef-234f8aa4fd08.png" style="width:46.08em;height:38.75em;"/></p>
<p>Adding a new script to the @MyAssets/Scripts folder</p>
<ol start="5">
<li>Double-click on it to open it in Visual Studio:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1643 image-border" src="img/108ead84-ef53-44fe-83ae-44b90eb5aaf4.png" style="width:47.83em;height:28.00em;"/></p>
<p>Blinking script in Visual Studio</p>
<ol start="6">
<li>Now, add the following lines to create the blinking effect. First, declare the following variables:</li>
</ol>
<pre style="padding-left: 60px">private IEnumerator coroutine;<br/>private bool blinking; </pre>
<p style="padding-left: 60px"> <kbd>coroutine</kbd> is a special function in Unity that pauses the execution and gives control back to the calling method until a certain condition is completed, and then resumes the execution where it left off. We will use it to blink every half a second. </p>
<ol start="7">
<li>Now, <em>inside</em> the <kbd>Start()</kbd> method, include the following initialization lines:</li>
</ol>
<pre style="padding-left: 60px">coroutine = BlinkingArrow(); <br/>blinking = false;</pre>
<p class="mce-root"/>
<ol start="8">
<li>Add the <kbd>coroutine</kbd> <em>after</em> the <kbd>Update()</kbd> method:</li>
</ol>
<pre style="padding-left: 60px">private IEnumerator BlinkingArrow()<br/>{<br/>    while (true)<br/>    {<br/>        GetComponent&lt;MeshRenderer&gt;().enabled = false;<br/>        yield return new WaitForSeconds(0.5f);<br/>        GetComponent&lt;MeshRenderer&gt;().enabled = true;<br/>        yield return new WaitForSeconds(0.5f);<br/>    }<br/>} </pre>
<p style="padding-left: 60px">The usual pausing command for a <kbd>coroutine</kbd> is <kbd>yield return null;</kbd>, which pauses the execution for a frame. For this <kbd>coroutine</kbd>, we have used <kbd>yield return new WaitForSeconds(0.5f);</kbd> to tell the <kbd>coroutine</kbd> to wait half a second before executing the following line. With this code, we are making the <kbd>MeshRenderer</kbd> component of the GameObject the script is attached to (the arrow) appear and disappear every half a second.</p>
<ol start="9">
<li><em>Inside</em> the <kbd>Update()</kbd> method, we are going to use the <kbd>coroutine</kbd> so that the arrow blinks only while the target is being detected and is hidden otherwise. With the blinking Boolean, we will verify that the <kbd>coroutine</kbd> is only launched once:</li>
</ol>
<pre style="padding-left: 60px">if (GetComponentInParent&lt;DefaultTrackableEventHandler&gt;().found &amp;&amp; !blinking)<br/>{<br/>    blinking = true;<br/>    StartCoroutine(coroutine);<br/>}<br/>else if (!GetComponentInParent&lt;DefaultTrackableEventHandler&gt;().found &amp;&amp; blinking)<br/>{<br/>    blinking = false;<br/>    StopAllCoroutines();<br/>    GetComponent&lt;MeshRenderer&gt;().enabled = false;<br/>}</pre>
<p class="mce-root"/>
<ol start="10">
<li>Back in the Unity editor, go to the Inspector window, click on Add Component, and add the Blinking script to the Arrow plane:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1213 image-border" src="img/2774b5c1-4a02-49bd-97e1-33981c9ec254.png" style="width:29.00em;height:46.42em;"/></p>
<p>Adding the new script to the plane</p>
<p>To finish, let's go to the third target, which will have another arrow:</p>
<ol>
<li>Right-click on the Arrow game object and press Copy.</li>
<li>Then, right-click on the Target_Open game object and paste it.</li>
<li>Move and rotate it until it's pointing at the top left of the trunk: </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1644 image-border" src="img/0e20e4f3-095f-459b-83e8-e3049c1078a7.png" style="width:128.67em;height:41.25em;"/></p>
<p>The two arrows pointing to different places on the trunk</p>
<p>At the moment, if we press the Play button on the top Toolbar, we will see the blueprint and arrows appearing when we point at each marker. However, we need to convert them into a step-by-step guide that will only show an instruction when the previous one is completed. We are going to add that logic in another script:</p>
<ol>
<li>In the Project window, in the <kbd>@MyAssets/Scripts</kbd> folder, right-click and create another C# script.</li>
</ol>
<p> </p>
<ol start="2">
<li>Call it <kbd>MainHandler.cs</kbd> and double-click on it to open it in Visual Studio:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1645 image-border" src="img/58656cbf-172b-480f-9415-20dd3f6f6434.png" style="width:69.50em;height:42.83em;"/></p>
<p>MainHandler script in VisualStudio</p>
<ol start="3">
<li>Start by adding Vuforia's <kbd>UnityEngine.UI</kbd> to the libraries:</li>
</ol>
<pre style="padding-left: 60px">using Vuforia;<br/>using UnityEngine.UI;</pre>
<ol start="4">
<li>Then, add the following variables:</li>
</ol>
<pre style="padding-left: 60px"> public DefaultTrackableEventHandler targetSide;<br/> public DefaultTrackableEventHandler targetClose;<br/> public DefaultTrackableEventHandler targetOpen;<br/> <br/> public GameObject mainMessage;<br/> public GameObject bottomMessage;<br/> public GameObject fileButton;<br/> public GameObject okButton;</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">They are all <kbd>public</kbd> because we will initialize them from the Unity editor. They make references to the different scene elements we are going to play with, the targets, and the UI elements.</p>
<ol start="5">
<li>Now, add this property <em>after</em> the variables:</li>
</ol>
<pre style="padding-left: 60px">public bool Finished { get; set; }</pre>
<p style="padding-left: 60px">It's also <kbd>public</kbd> because we are going to assign it from the editor as well when the user presses the Done button.</p>
<ol start="6">
<li>Finally, add the following private variable, which is an enumeration to control each of the states of the app:</li>
</ol>
<pre style="padding-left: 60px">private enum State<br/>{<br/>    Init = 0,<br/>    Side = 1,<br/>    Engine = 2,<br/>    Close = 3,<br/>    Open = 4,<br/>    Plug = 5<br/>}<br/>private State state;</pre>
<ol start="7">
<li>Now, let's add some methods <em>after</em> the <kbd>Update()</kbd> method. Create a new method called <kbd>ShowElements()</kbd>:</li>
</ol>
<pre style="padding-left: 60px">private void ShowElements()<br/>{<br/>}</pre>
<p style="padding-left: 60px">It will be used privately inside the class to show or hide the different components, depending on the state the app is in. This method will also control which markers show information in each step.</p>
<ol start="8">
<li>We will create a <kbd>switch</kbd> call <em>inside</em> <kbd>ShowElements()</kbd>:</li>
</ol>
<pre style="padding-left: 60px">switch (state)<br/>{<br/>    case State.Init:<br/>    break;<br/>    case State.Side:<br/>    break;<br/>    case State.Engine:<br/>    break; <br/>    case State.Close:<br/>    break;<br/>    case State.Open:<br/>    break;<br/>    case State.Plug:<br/>    break;<br/>}</pre>
<p style="padding-left: 60px">Here, we will tell the method to perform a different action, depending on which state the app is in at the time. </p>
<ol start="9">
<li>Inside the <kbd>State.Init</kbd> case, add the following:</li>
</ol>
<pre style="padding-left: 60px">targetSide.gameObject.SetActive(true);<br/>targetOpen.gameObject.SetActive(false);<br/>targetClose.gameObject.SetActive(false);<br/><br/>mainMessage.SetActive(true);<br/>bottomMessage.SetActive(false);<br/>fileButton.SetActive(false);<br/>okButton.SetActive(false);<br/><br/>mainMessage.GetComponentInChildren&lt;Text&gt;().text = "Point with the camera at the side of the car to start the maintenance process.";</pre>
<p style="padding-left: 60px">Here, we are only showing the <kbd>targetSide</kbd> target. To ensure the user will not be able to see the instructions for the other two, we activate only the main message and add the text to it.</p>
<ol start="10">
<li>Inside the <kbd>State.Side</kbd> case, add the following:</li>
</ol>
<pre style="padding-left: 60px">mainMessage.SetActive(false);<br/>bottomMessage.SetActive(true);<br/><br/>bottomMessage.GetComponentInChildren&lt;Text&gt;().text = "Touch the red components to see instructions.";</pre>
<p style="padding-left: 60px">When the user has found the <kbd>targetSide</kbd> with the camera, we enter this state, where we deactivate the main message and show the bottom message.</p>
<p class="mce-root"/>
<ol start="11">
<li>Inside the <kbd>State.Engine</kbd> case, add the following:</li>
</ol>
<pre style="padding-left: 60px">targetClose.gameObject.SetActive(true);<br/><br/>mainMessage.SetActive(true);<br/>bottomMessage.SetActive(false);<br/><br/>mainMessage.GetComponentInChildren&lt;Text&gt;().text = "One of the spark plugs is broken. Point at the trunk and follow the steps.";</pre>
<p style="padding-left: 60px">If the user has touched the red component, we activate the next target and show the main message with instructions on how to find it.</p>
<ol start="12">
<li>Inside the <kbd>State.Close</kbd> case, add the following:</li>
</ol>
<pre style="padding-left: 60px">targetSide.gameObject.SetActive(false);<br/>targetOpen.gameObject.SetActive(true);<br/><br/>mainMessage.SetActive(false);<br/>bottomMessage.SetActive(true);<br/><br/>bottomMessage.GetComponentInChildren&lt;Text&gt;().text = "Open the trunk to access the engine.";</pre>
<p style="padding-left: 60px">The user has found <kbd>targetClose</kbd> so we deactivate the previous one and activate the next one. We also add a bottom message to open the trunk.</p>
<ol start="13">
<li>Inside the <kbd>State.Open</kbd> case, add the following:</li>
</ol>
<pre style="padding-left: 60px">targetClose.gameObject.SetActive(false);<br/><br/>fileButton.SetActive(true);<br/>okButton.SetActive(true);<br/><br/>bottomMessage.GetComponentInChildren&lt;Text&gt;().text = "Take the spark plug out and replace it. When you finish press 'Done'";</pre>
<p style="padding-left: 60px">Here, we activate the two buttons: <kbd>fileButton</kbd> to see the PDF, and <kbd>okButton</kbd> to finish the process.</p>
<ol start="14">
<li>Inside the <kbd>State.Plug</kbd> case, add the following:</li>
</ol>
<pre style="padding-left: 60px">targetOpen.gameObject.SetActive(false);<br/><br/>mainMessage.SetActive(true);<br/>bottomMessage.SetActive(false);<br/>fileButton.SetActive(false);<br/>okButton.SetActive(false);<br/><br/>mainMessage.GetComponentInChildren&lt;Text&gt;().text = "Well done, you can take a coffee now :)";</pre>
<p style="padding-left: 60px">This is the final step, so we will hide the buttons and targets and only leave the end message visible.</p>
<ol start="15">
<li>Now, create another method called <kbd>NextStep()</kbd>:</li>
</ol>
<pre style="padding-left: 60px">private void NextStep()<br/>{<br/>    state++;<br/>    ShowElements();<br/>}</pre>
<p style="padding-left: 60px">We will call this method to change from one step to the next one.</p>
<ol start="16">
<li>Add another method called <kbd>ResetInstructions()</kbd>:</li>
</ol>
<pre style="padding-left: 60px">public void ResetInstructions()<br/>{<br/>    state = 0;<br/>    ShowElements();<br/>}</pre>
<p style="padding-left: 60px">This method is <kbd>public</kbd> because it will be called from the editor by the Home button. It will go to the initial state of the app.</p>
<ol start="17">
<li>Now, let's modify the <kbd>Start()</kbd> method to convert it into a <kbd>coroutine</kbd> that waits until Vuforia is initialized before hiding the second and third targets with <kbd>ShowElements()</kbd>. Otherwise, it might not recognize them:</li>
</ol>
<pre style="padding-left: 60px">IEnumerator Start()<br/>{<br/>    while (!VuforiaARController.Instance.HasStarted) //waits until Vuforia has instanciated the three markers<br/>        yield return null;<br/>    state = State.Init;<br/>    ShowElements();<br/> }</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<ol start="18">
<li>Finally, inside the <kbd>Update()</kbd> method, enter the logic to change from one step to the next one. Thus, the app will jump from one step to the next when the following happens:</li>
</ol>
<ul>
<li style="padding-left: 30px">In the <kbd>Init</kbd>, <kbd>Engine</kbd>, and <kbd>Close</kbd> states, the app detects the corresponding target (side, close, open)</li>
<li style="padding-left: 30px">In the <kbd>Side</kbd> state, the user touches the screen over the engine area of the car</li>
<li style="padding-left: 30px">In the <kbd>Open</kbd> state, the user has touched the Done button:</li>
</ul>
<pre style="padding-left: 90px">if ((state == State.Init &amp;&amp; targetSide.found) || (state == State.Engine &amp;&amp; targetClose.found) || (state == State.Close &amp;&amp; targetOpen.found))<br/>{<br/>    NextStep();<br/>}<br/>else if (state == State.Side)<br/>{<br/>    if (Input.GetMouseButtonDown(0))<br/>    {<br/>        RaycastHit hit;<br/>        Ray ray = Camera.main.ScreenPointToRay(Input.mousePosition);<br/>        if (Physics.Raycast(ray, out hit))<br/>            if (hit.transform.name == "Engine")<br/>                NextStep();<br/>    }<br/>}<br/>else if (state == State.Open &amp;&amp; Finished)<br/>{<br/>    Finished = false;<br/>    NextStep();<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p>Once we have finished with the script, go back to Unity:</p>
<ol>
<li>Drag the script from the Project window to the ARCamera game object in the Hierarchy window. Alternatively, click on the ARCamera and in the Inspector window, click Add Component and select the script. Fill in each of the fields in the Main Handler script with the elements from our scene:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"> <img class="aligncenter size-full wp-image-1647 image-border" src="img/3d103765-8f38-47bc-b18b-10ab70a44987.png" style="width:32.25em;height:41.08em;"/></p>
<p>Main Handler with its fields in the ARCamera GameObject</p>
<ol start="2">
<li>Select the Home_button. Then, in the Inspector window, in the On Click () panel, add a new event, select the ARCamera, and then select the ResetInstructions() method:</li>
</ol>
<div><img class="aligncenter size-full wp-image-1214 image-border" src="img/81e91934-449e-4f96-95b2-186a1a58222a.png" style="width:31.33em;height:7.92em;"/></div>
<p>On Click () event in the Home_button</p>
<ol start="3">
<li>Select the OK_button. Then, in the Inspector window, in the On Click () panel, add a new event, select the ARCamera, and then the Finished property. Mark the checkbox so that whenever the button is pressed, the Finished property will be set to true:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1215 image-border" src="img/e5e52a05-c001-4463-a6c3-fb4dbeb6dff8.png" style="width:25.25em;height:7.42em;"/></p>
<p>On Click () event in the OK_button</p>
<p>Now that we have the main functionalities ready, let's configure the scene so that we can build it in the glasses.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Configuring the AR for glasses</h1>
                
            
            
                
<p>This step is an important one so that we understand how the glasses work<em>.</em></p>
<p>If, at this point, we compile the app in the Moverio glasses, we will see the video feed over the glasses screens, as if we were using a phone. This is not the best way of working with AR; what we want is for the background to remain transparent and only the UI elements and AR elements appear over the screens.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>However, to see the effect and some characteristics of the AR in the glasses, we are going to compile the app and then make the relevant modifications.</p>
<p>Turn on the Moverio glasses and connect them to your computer via USB.</p>
<p>As you have already defined the settings, switched the platform to Android, and added the current scene to the building list in the introduction, just click <em>Ctrl</em> + <em>B</em> or click on File|Build And Run (if you skipped any of these steps, or if you are not sure, go to File|Build Settings… and check if everything is correct). Give the <kbd>.apk</kbd> file a name and build it.</p>
<p>As we've discussed, you will see the video feed on your glasses, and the UI will be larger than expected. For now, forget about the UI and take a look at the video feed. If you compare the video feed to the real-world image behind it, you will see that the video feed is smaller and slightly displaced compared to the real world (take into account that the camera is placed on one side of the glasses). The following image shows this displacement (take into account the picture is taken only from the left screen of the glasses, so the displacement is even greater than when the left- and right-hand sides are combined):</p>
<div><img class="aligncenter size-full wp-image-1216 image-border" src="img/e5f9d1b9-1e61-4c2d-a6c5-201fc40f9163.png" style="width:30.92em;height:27.00em;"/></div>
<p>The AR view from the glasses</p>
<p>We have to take this into account because when we take the video feed out, the AR elements will look smaller and displaced on the targets.</p>
<p class="mce-root"/>
<p>So, first of all, let's take the video feedback. This is a very easy step in Vuforia as in the latest versions, they have taken it out from the code and placed it as a checkbox in the Vuforia Engine configuration. Follow these steps to do so:</p>
<ol>
<li>Select the ARCamera and in the Inspector window, click on Open Vuforia Engine configuration.</li>
<li>In the Video Background component, uncheck Enable video background:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1217 image-border" src="img/a7ae644c-1054-4f23-aefa-77642c3c87c2.png" style="width:30.67em;height:15.42em;"/></p>
<p>Disabling the video feed in the Vuforia Engine configuration</p>
<ol start="3">
<li>And that's it! Build the app again by pressing <em>Ctrl</em> + <em>B</em> and you will see how the video doesn't appear this time and that when you point at the side target with the glasses, only the AR element is shown. You will also see how, without the video feed, the UI will be of the correct size.</li>
</ol>
<p>Before the Video Background component, there is also a Digital Eyewear component. In the beginning, when Vuforia first enabled the AR glasses, the configuration of the scene went through this component. However, now, it is only valuable for HoloLens users to select the configuration for those glasses.</p>
<ol start="4">
<li>Finally, let's make the AR elements match the real elements that can be seen through the glasses. Unfortunately, at the moment, there is not an exact method to do this. Therefore, we will take the displacement and size parameters out by trial and error and apply them to the rest of the elements. For this project, those values are as follows:</li>
</ol>
<ul>
<li style="padding-left: 30px">Displacement: <kbd>+0.5f</kbd> in the x axis</li>
<li style="padding-left: 30px">Scale: <kbd>*2.5</kbd> in all axes</li>
</ul>
<p style="padding-left: 60px">Instead of applying them one by one, create a new script called <kbd>GlassesHandler.cs</kbd> in your <kbd>@MyAssets/Scripts</kbd> folder and open it in Visual Studio. Add the following lines <em>inside</em> the <kbd>Start()</kbd> method:</p>
<pre style="padding-left: 60px">foreach (Transform child in transform)<br/>{<br/>   Vector3 scale = child.localScale;<br/>    scale *= 2.5f;<br/>    child.localScale = scale;<br/>    <br/>    Vector3 position = child.position;<br/>    position += new Vector3(0.5f, 0, 0);<br/>    child.position = position;<br/>}</pre>
<p>Position, rotation, and scale parameters can't be added directly; an intermediate variable has to be used instead.</p>
<p style="padding-left: 60px">Your code should look like this:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1648 image-border" src="img/d5c93256-0063-4fd8-9ac0-35d07159fc27.png" style="width:39.08em;height:28.33em;"/></p>
<p>GlassesHandler script in Visual Studio</p>
<ol start="5">
<li>Drag this script to the three targets or add it by selecting each target, pressing Add Component in the Inspector window, and selecting the script.</li>
<li>Press <em>Ctrl</em> + <em>B</em> to build your app and see how the elements now appear over the real elements.</li>
</ol>
<p>To finish our app, we will add the PDF functionality to help the operator with their work.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding the PDF file</h1>
                
            
            
                
<p>PDF files are a slightly difficult task; since Unity doesn't open them internally, an external application must be used. In this section, we are going to learn about a simple call that we can use for opening the PDF files but that can also be used for other types of extensions (such as videos) and opening server files through a URL.</p>
<p>Important! First, you must install an app in the glasses that can open PDF files, such as Adobe Reader. Please head to the Moverio website to learn where to find and how to install these kinds of applications.</p>
<p>As you may remember, we have not placed the video and PDF files inside the <kbd>@MyAssets</kbd> folder but in the <kbd>StreamingAssets/PDF</kbd> folder. This folder is a special folder inside Unity, and all the files in it are copied verbatim to the destination device, meaning they are not processed by Unity at all. We can't load them directly from this path, so we will copy them to an accessible path first.</p>
<p>Go to Visual Studio and in the <kbd>MainHandler.cs</kbd> script, let's add some code to handle these files. Follow these steps to do so:</p>
<ol>
<li>Add the <kbd>System.IO</kbd> library:</li>
</ol>
<pre style="padding-left: 60px">using System.IO;</pre>
<ol start="2">
<li>Add the following variables at the beginning to indicate the paths of the PDF file inside the device:</li>
</ol>
<pre style="padding-left: 60px">private string originalPath;<br/>private string savePath;</pre>
<ol start="3">
<li>Initialize them <em>inside</em> the <kbd>Start()</kbd> method:</li>
</ol>
<pre style="padding-left: 60px">originalPath = Application.streamingAssetsPath + "/PDF/WorkOrder_0021.pdf";<br/>savePath = Application.persistentDataPath + "/WorkOrder_0021.pdf";</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<ol start="4">
<li>Add the following <kbd>coroutine</kbd>, which copies the PDF file from the <kbd>StreamingAssets</kbd> location to an accessible path and opens it:</li>
</ol>
<pre style="padding-left: 60px">private IEnumerator OpenFileCoroutine()<br/>{<br/>    WWW www = new WWW(originalPath);<br/>    yield return www;<br/>    if (www.error != null)<br/>        Debug.Log("Error loading: " + www.error);<br/>    else<br/>    {<br/>        byte[] bytes = www.bytes;<br/>        File.WriteAllBytes(savePath, bytes);<br/>        Application.OpenURL(savePath);<br/>    }<br/>}</pre>
<ol start="5">
<li>Finally, add the following <kbd>public</kbd> method to open the PDF file:</li>
</ol>
<pre style="padding-left: 60px">public void OpenPDFFile()<br/>{<br/>    if (File.Exists(savePath))<br/>        Application.OpenURL(savePath);<br/>    else<br/>        StartCoroutine(OpenFileCoroutine());<br/>}</pre>
<p class="mce-root"/>
<p style="padding-left: 60px">If the file already exists in an accessible location, it opens it. Otherwise, it copies first and opens it from the coroutine.</p>
<div><kbd>Application.OpenURL()</kbd> opens the given path, regardless of whether it's a URL or an internal path. </div>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Back in Unity editor, select the File_button, and in the Inspector window, add the OpenPDFfile() call to its On Click () event:</p>
<div><img class="aligncenter size-full wp-image-1218 image-border" src="img/3455961d-a978-4328-99ea-d6400134df4f.png" style="width:29.58em;height:7.75em;"/></div>
<p>On Click () event in the File_button</p>
<p>Press <em>Ctrl</em> + <em>B</em> one last time to see the full app in the glasses.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, you have learned about another of Vuforia's features, <kbd>ImageTargets</kbd><em>,</em> and how to create your own image target and add virtual content to it. You have also learned about how to work with the Unity interface and scripts in order to create messages and buttons, as well as sequenced instructions.</p>
<p class="mce-root"/>
<p>With all this, you have acquired the skills you need to use Vuforia to create an industrial AR guide that can be implemented in mounting, maintenance, or training processes. You have also learned how to customize a step with extra PDF or even video and data files that have been taken either locally (like in this project) or from a remote server by using the OpenURL method with a URL inside it.</p>
<p>Now, you can use this knowledge to create your own guide for your processes and use the current project as a template for it. You can also improve and extend it by using real-life pictures, linking some of the steps to your instruction PDF files or triggering the change from one step to another using signals or information coming from your servers.</p>
<p>As you have seen, the project is also easily deployed in mobile devices, and from here, you can try to migrate it to other types of glasses and see the results. You have also acquired the skills to try the rest of the Vuforia examples, which can be found in the Unity Asset Store, which has been published by PTC: <a href="https://assetstore.unity.com/publishers/24484">https://assetstore.unity.com/publishers/24484</a>.</p>
<p>In the next chapter, we will completely change the scope and learn how to create an AR portal to transport the user into a virtual 3D world with ARKit for the tourism sector.</p>


            

            
        
    </body></html>