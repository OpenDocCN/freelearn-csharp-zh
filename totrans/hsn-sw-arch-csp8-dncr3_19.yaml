- en: Testing Your Code with Unit Test Cases and TDD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing software, it is essential that you ensure that an application
    is bug-free and that it satisfies all specifications. This can be done by testing
    all the modules while they are being developed or when the overall application
    has been either completely or partially implemented.
  prefs: []
  type: TYPE_NORMAL
- en: Performing all the tests manually is not a feasible option since most of the
    tests must be executed each time the application is modified, and, as explained
    throughout this book, modern software is being continuously modified to adapt
    the applications to the needs of a fast-changing market. This chapter discusses
    all the types of tests needed to deliver reliable software, and how to organize
    and automate them.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, this chapter covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding automated tests and their usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the basics of **test-driven development** (**TDD**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing a software investment using TDD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining C# test projects in Visual Studio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we'll see which types of tests are worth implementing, and
    what unit tests are. We'll see the different types of projects available and how
    to write unit tests in them. By the end of the chapter, the book use case will
    help us to execute our tests in Azure DevOps during the **Continuous Integration/Continuous
    Delivery** (**CI/CD**) cycle of our applications automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires the 2019 free Community Edition with all database tools
    installed. It also requires a free Azure account; if you have not already created
    one, see the *Creating an Azure account* section in [Chapter 1](14b5c5da-4042-439e-9e5a-2e19ba4c4930.xhtml), *Understanding
    the Importance of Software Architecture.*
  prefs: []
  type: TYPE_NORMAL
- en: All concepts in this chapter are clarified with practical examples based on
    the WWTravelClub book use case. The code for this chapter is available at: [https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8](https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding automated tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Delaying the application testing until immediately after most of its functionalities
    have been completely implemented must be avoided for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: If a class or module has been incorrectly designed or implemented, it might
    have already influenced the way other modules were implemented. Therefore, at
    this point, fixing the problem might have a very high cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The possible combination of input that is needed to test all possible paths
    that execution can take grows exponentially with the number of modules or classes
    that are tested together. Thus, for instance, if the execution of a class method
    `A` can take three different paths, while the execution of another method `B`
    can take four paths, then testing `A` and `B` together would require 3 x 4 different
    inputs. In general, if we test several modules together, the total number of paths
    to test is the product of the number of paths to test in each module. If modules
    are tested separately, instead, the number of inputs required is just the sum of
    the paths needed to test each module.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a test of an aggregate made of N modules fails, then locating the origin
    of the bug among the N modules is usually a very time consuming activity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When N modules are tested together, we have to redefine all tests involving
    the N modules, even if just one of the N modules changes during the application's
    CI/CD cycle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding considerations show that it is more convenient to test each module
    method separately. Unluckily, a battery of tests that verifies all methods independently
    from their context is incomplete because some bugs may be caused by incorrect
    interactions between modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, tests are organized into two stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit tests**: These verify that all execution paths of each module behave
    properly. They are quite complete and usually cover all possible paths. This is
    feasible because there are not very many possible execution paths of each method
    or module compared to the possible execution paths of the whole application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration tests**: These are executed once the software passes all its
    unit tests. Integration tests verify all modules interact properly to get the
    expected results. Integration tests do not need to be complete since unit tests
    will have already verified that all execution paths of each module work properly.
    They need to verify all patterns of interaction, that is, all the possible ways
    the various modules may cooperate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Usually, each interaction pattern has more than one test associated with it:
    a typical activation of a pattern, and some extreme cases of activation. For instance,
    if a whole pattern of interaction receives an array as input, we will write a
    test for the typical size of the array, a test with a `null` array, a test for
    an empty array, and a test with a very big array. This way we verify that the
    way the single module was designed is compatible with the needs of the whole interaction
    pattern.'
  prefs: []
  type: TYPE_NORMAL
- en: With the preceding strategy in place, if we modify a single module without changing
    its public interface, we need to change the unit tests for that module.
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, the change involves the way some modules interact, then we also
    have to add new integration tests or to modify existing ones. However, usually,
    this is not a big problem since most of the tests are unit tests, so rewriting
    a large percentage of all integration tests does not require too big an effort.
    Moreover, if the application was designed according to the **Single Responsibility,
    Open/Closed, Liskov Substitution, Interface Segregation, Dependency Inversion** (**SOLID**)
    principles, then the number of integration tests that must be changed after a
    single code modification should be small since the modification should affect
    just a few classes that interact directly with the modified method or class.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, it should be clear that both unit tests and integration tests
    must be reused during the entire lifetime of the software. That is why it is worth
    automating them. Automation of unit and integration tests avoids possible errors
    of manual test execution and saves time. A whole battery of several thousand automated
    tests can verify software integrity after each small modification in a few minutes,
    thus enabling the frequent changes needed in the CI/CD cycles of modern software.
  prefs: []
  type: TYPE_NORMAL
- en: As new bugs are found, new tests are added to discover them so that they cannot
    reappear in future versions of the software. This way automated test always become
    more reliable and protect the software more form bugs added by new changes. Thus,
    the probability of adding new bugs (that are not immediately discovered) is greatly
    reduced.
  prefs: []
  type: TYPE_NORMAL
- en: The next section will give us the basics for organizing and designing automated
    unit and integration tests, as well as practical details on how to write a test
    in C# in the *C# Test Projects* section.
  prefs: []
  type: TYPE_NORMAL
- en: Writing automated (unit and integration) tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tests are not written from scratch; all software development platforms have
    tools that help us to both write tests and launch them (or some of them). Once
    the selected tests have been executed, all tools show a report and give the possibility
    to debug the code of all failed tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, all unit and integration test frameworks are made of three
    important parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Facilities for defining all tests: **They verify if the actual results correspond
    to expected results. Usually, a test is organized into test classes, where each
    test calls tests either a single application class or a single class method. Each
    test is split into three stages:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test preparation**: The general environment needed by the test is prepared.
    This stage doesn''t prepare the single input each method to test must be called
    with, but just the global environment, such as objects to inject in class constructors
    or simulations of database tables. Usually, the same preparation procedure is
    used in several tests, so test preparations are factored out into dedicated modules.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test execution**: The methods to test are invoked with adequate input and
    all results of their executions are compared with expected results with constructs
    such as `Assert.Equal(x, y)`, `Assert.NotNull(x)`, and so on.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tear-down**: The whole environment is cleaned up to avoid the execution of
    a test influencing other tests. This step is the converse of step 1.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mock facilities**: While integration tests use all (or almost all) classes
    involved in a pattern of objects cooperation, in unit tests the use of other application
    classes is forbidden. Thus, if a class under test, say, `A`, uses a method of
    another application class, `B`, that is injected in its constructor in one of
    its methods, `M`, then in order to test `M` we must inject a fake implementation
    of `B`. It is worth pointing out that only classes that do some processing are
    not allowed to use another class during unit tests, while pure data classes can.
    Mock frameworks contain facilities to define fake implementations of interfaces
    and interface methods that return data that can be defined in tests. Typically,
    fake implementations are also able to report information on all fake method calls.
    Such fake implementations do not need the definition of actual class files but
    are done online in the test code by calling methods such as `new Mock<IMyInterface>()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execution and reporting tool**: This is a visual configuration-based tool
    that the developer may use to decide which tests to launch and when to launch
    them. Moreover, it also shows the final outcome of the tests as a report containing
    all successful tests, all failed tests, each test''s execution time, and other
    information that depends on the specific tool and on how it was configured. Usually,
    execution and reporting tools that are executed in development IDEs such as Visual
    Studio also give you the possibility of launching a debug session on each failed
    test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since mock frameworks can only create fake implementations of interfaces but
    not of classes, we should inject interfaces or pure data classes (that don't need
    to be mocked) in class constructors and methods; otherwise, classes cannot be
    unit tested. Therefore, for each cooperating class that we want to inject into
    another class, we must define a corresponding interface.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, classes should use instances that are injected in their constructors
    or methods, and not class instances available in the public static fields of other
    classes; otherwise, the hidden interactions might be forgotten while writing tests,
    and this might complicate the *preparation* step of tests.
  prefs: []
  type: TYPE_NORMAL
- en: The next section describes other types of test used in software development.
  prefs: []
  type: TYPE_NORMAL
- en: Writing acceptance and performance tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Acceptance tests define the contract between the project stakeholders and the
    development team. They are used to verify that the software developed actually
    behaves as agreed with them. Acceptance tests verify not only functional specifications
    but also constraints on the software usability and user interface. Since they also have
    the purpose of showing how the software appears and behaves on actual computer
    monitors and displays, they are never completely automatic but consist mainly
    of lists of recipes and verifications that must be followed by an operator.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, automatic tests are developed to verify just the functional specifications,
    but such tests usually bypass the user interface and inject the test input directly
    in the logic that is immediately behind the user interface. For instance, in the
    case of an ASP.NET Core MVC application, the whole website is run in a complete
    environment that includes all the needed storage filled with test data; input
    is not provided to HTML pages but is injected directly in the ASP.NET Core controllers.
    Tests that bypass the user interface are called subcutaneous tests. ASP.NET Core
    supplies various tools to perform subcutaneous tests and also tools that automate
    the interaction with HTML pages.
  prefs: []
  type: TYPE_NORMAL
- en: 'Subcutaneous tests are usually preferred in the case of automated tests, while
    full tests are executed manually for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: No automatic test can verify how the user interface appears and how usable it
    is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating the actual interaction with the user interface is a very time-consuming
    task.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: User interfaces are changed frequently to improve their usability and to add
    new features, and also small changes in a single application screen, may force
    a complete rewrite of all tests that operate on that screen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a few words, user interface tests are very expansive and have low reusability,
    so it's rarely worth automating them. However, ASP.NET Core supplies the `Microsoft.AspNetCore.Mvc.Testing`
    NuGet package to run the whole website in a testing environment. Using it together
    with the `AngleSharp` NuGet package, which parses HTML pages into DOM trees, you
    can write automated full tests with an acceptable programming effort. The automated
    ASP.NET Core acceptance tests will be described in detail in [Chapter 20](e61b3c5d-3abd-4442-9c9c-e12fd3acedcc.xhtml), *Automation
    for Software Testing*.
  prefs: []
  type: TYPE_NORMAL
- en: Performance tests apply a fake load to an application to see if it is able to
    handle the typical production load, to discover its load limits, and to locate
    bottlenecks. The application is deployed in a staging environment that is a copy
    of the actual production environment in terms of hardware resources. Then, fake
    requests are created and applied to the system, and response times and other metrics
    are collected. Fake request batches should have the same composition as the actual
    production batches. They can be generated from the actual production request logs
    if they are available.
  prefs: []
  type: TYPE_NORMAL
- en: If response times are not satisfactory, other metrics are collected to discover
    possible bottlenecks (low memory, slow storages, or slow software modules). Once
    located, a software component that is responsible for the problem can be analyzed
    in the debugger to measure the execution time of the various method calls involved
    in a typical request.
  prefs: []
  type: TYPE_NORMAL
- en: Failures in the performance tests may lead either to a redefinition of the hardware
    needed by the application or to the optimization of some software modules, classes
    or methods.
  prefs: []
  type: TYPE_NORMAL
- en: Both Azure and Visual Studio offer tools to create fake loads and to report
    execution metrics. However, they have been declared obsolete and will be discontinued
    in quite a short time (about one year from writing this book), and so we will
    not describe them. As an alternative, there are both open source and third-party
    tools that can be used. Some of them are listed in the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: The next section describes a software development methodology that gives a central
    role to tests.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding test-driven development (TDD)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Test-driven development** (**TDD**) is a software development methodology
    that gives a central and central role to unit tests. According to this methodology,
    unit tests are a formalization of the specifications of each class, so they must
    be written before the code of the class. Actually, a full test that covers all
    code paths univocally defines the code behavior, so it can be considered a specification
    for the code. It is not a formal specification that defines the code behavior
    through some formal language, but a specification based on behavior examples.'
  prefs: []
  type: TYPE_NORMAL
- en: The ideal way to test software would be to write formal specifications of the
    whole software behavior and to verify with some completely automatic tools if
    the software that was actually produced conforms with them. In the past, some
    research effort was spent defining formal languages for describing code specifications,
    but expressing the behavior the developer has in mind with similar languages was
    a very difficult and error-prone task. Therefore, these attempts were quickly
    abandoned in favor of approaches based on examples. At that time, the main purpose
    was the automatic generation of code. Nowadays, automatic code generation has
    been substantially abandoned and survives in small application areas, such as
    the creation of device drivers. In these areas, the effort of formalizing the
    behavior in a formal language is worth the time saved in trying to test difficult-to-reproduce
    behaviors of parallel threads.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests were initially conceived as a way to encode example-based specifications
    in a completely independent way, as a part of a specific agile development methodology
    called **Extreme Programming**. However, nowadays, TDD is used independently of
    Extreme Programming and is included as an obligatory prescription in other agile
    methodologies.
  prefs: []
  type: TYPE_NORMAL
- en: While it is undoubtedly true that unit tests refined after finding hundreds
    of bugs act as reliable code specifications, it is not obvious that developers
    can easily design unit tests that can be immediately used as reliable specifications
    for the code to be written. In fact, generally, you need an infinite or at least
    an immense number of examples to univocally define a code's behavior if examples
    are chosen at random.
  prefs: []
  type: TYPE_NORMAL
- en: 'The behavior can be defined with an acceptable number of examples only after
    you have understood all possible execution paths. In fact, at this point, it is
    enough to select a typical example for each execution path. Therefore, writing
    a unit test for a method after that method has been completely coded is easy:
    it simply requires selecting a typical instance for each execution path of the
    already existing code. However, writing unit tests this way does not protect from
    errors in the design of the execution paths themselves. For instance, it doesn''t
    prevent the typical error of forgetting to test a variable for the `null` value
    before invoking a member. That is why TDD suggests writing unit tests before the
    application code.'
  prefs: []
  type: TYPE_NORMAL
- en: We may conclude that, while writing unit tests, the developer must forecast
    somehow all execution paths by looking for extreme cases and by possibly adding
    more examples than strictly needed. However, the developer can make mistakes while
    writing the application code, and he or she can also make mistakes in forecasting
    all possible execution paths while designing the unit tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have found the main drawback of TDD: unit tests themselves may be wrong.
    That is, not only application code, but also its associated TDD unit tests may
    be incoherent with the behavior the developer has in mind. Therefore, in the beginning,
    unit tests can''t be considered software specifications, but rather a possible
    wrong and incomplete description of the software behavior. Therefore, we have
    two descriptions of the behavior we have in mind, the application code itself
    and its TDD unit tests that were written before the application code.'
  prefs: []
  type: TYPE_NORMAL
- en: What makes TDD work is that the probability of making exactly the same error
    while writing the tests and while writing the code is very low. Therefore, whenever
    a test fails there is an error either in the tests or in the application code,
    and, conversely, if there is an error either in the application code or in the
    test, there is a very high probability a test will fail. That is, the usage of
    TDD ensures that most of the bugs are immediately found!
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing a class method or a chunk of code with TDD is a loop composed of three
    stages:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Red stage: In this stage, the developer designs new unit tests that must necessarily
    fail because at this time there is no code that implements the behavior they describe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Green stage: In this stage, the developer writes the minimum code or makes
    the minimum modifications to existing code that are necessary to pass all unit
    tests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refactoring stage: Once the test is passed, code is refactored to ensure good
    code quality and the application of best practices and patterns. In particular,
    in this stage, some code can be factored out in other methods or in other classes.
    During this stage, we may also discover the need for other unit tests, because
    new execution paths or new extreme cases are discovered or created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The loop stops as soon as all tests pass without writing new code or modifying
    the existing code.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it is very difficult to design the initial unit tests because it
    is quite difficult to imagine how the code might work and the execution paths
    it might take. In this case, you can get a better understanding of the specific
    algorithm to use by writing an initial sketch of the application code. In this
    initial stage, we need to focus just on the main execution path, completely ignoring
    extreme cases and input verifications. Once we get a clear picture of the main
    ideas behind an algorithm that should work we can enter the standard three-stage
    TDD loop.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will list all test projects available in Visual Studio
    and describe xUnit in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Defining C# test projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Visual Studio contains project templates for three types of unit testing frameworks,
    namely, MSTest, xUnit, and NUnit. Once you start the new project wizard, in order
    to visualize the version of all of them that is adequate for .NET Core C# applications,
    set Project type as Test, Language as C#, and Platform as Linux, since .NET Core
    projects are the only ones that can be deployed on Linux.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the selection that should appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e137b957-4a21-44f1-8824-b7e36823e952.png)'
  prefs: []
  type: TYPE_IMG
- en: All the preceding projects automatically include the NuGet package for running
    all the tests in the Visual Studio test user interface (Visual Studio test runner).
    However, they do not include any facility for mocking interfaces, so you need
    to add the `Moq` NuGet package that contains a popular mocking framework.
  prefs: []
  type: TYPE_NORMAL
- en: All test projects must contain a reference to the project to be tested.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will describe xUnit, since it is probably the most popular
    of the three frameworks. However, all three frameworks are quite similar and differ
    mainly in the names of the methods and in the names of the attributes used to
    decorate various testing stuff.
  prefs: []
  type: TYPE_NORMAL
- en: Using the xUnit test framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In xUnit, tests are methods decorated with either with the `[Fact]` or with
    the `[Theory]` attributes. Tests are automatically discovered by the test runner
    that lists all of them in the user interface so the user can run either all of
    them or just a selection of them.
  prefs: []
  type: TYPE_NORMAL
- en: A new instance of the test class is created before running each test, so the
    *test preparation* code contained in the class constructor is executed before
    each test of the class. If you also need *tear-down* code, the test class must
    implement the `IDisposable` interface so that the tear-down code can be included
    in the `IDisposable.Dispose` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test code invokes the methods to be tested and then tests the results with
    methods of the `Assert` static class, such as `Assert.NotNull(x)`, `Assert.Equal(x,
    y)`, and `Assert.NotEmpty(IEnumerable x)`. There are also methods that verify
    if a call throws an exception of a specific type, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: When an assertion fails, an exception is thrown. A test fails if a not-intercepted
    exception is thrown either by the test code or by an assertion.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a method that defines a single test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `[Fact]` attribute is used when a method defines just one test, while the `[Theory]` attribute
    is used when the same method defines several tests, each on a different tuple
    of data. Tuples of data can be specified in several ways and are injected in the
    test as method parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous code can be modified to test `MethodToTest` on several input as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Each `InlineData` attribute specifies a tuple to be injected in the method
    parameters. Since just simple constant data can be included as attribute arguments,
    xUnit gives you also the possibility to take all data tuples from a class that
    implements `IEnumerable`, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The type of the class that provides the test data is specified with the `ClassData`
    attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also possible to take data from a static method of a class that returns
    an `IEnumerable` with the `MemberData` attribute, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `MemberData` attribute is passed the method name as the first parameter,
    and the class type in the `MemberType` named parameter. If the static method is
    part of the same test class the `MemberType` parameter can be omitted.
  prefs: []
  type: TYPE_NORMAL
- en: The next section shows how to deal with some advanced preparation and tear-down
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced test preparation and tear-down scenarios
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes the preparation code contains very time-consuming operations, such
    as opening a connection with a database, that don't need to be repeated before
    each test but can be executed once before all the tests contained in the same
    class. In xUnit, this kind of test preparation code can't be included in the test
    class constructor; since a different instance of the test class is created before
    every single test, it must be factored out in a separate class called a fixture
    class.
  prefs: []
  type: TYPE_NORMAL
- en: If we also need a corresponding tear-down code, the fixture class must implement
    `IDisposable`. In other test frameworks, such as NUnit, the test class instances
    are created just once instead, so they don't need the fixture code to be factored
    out in other classes. However, test frameworks that, like NUnit, do not create
    a new instance before each test may suffer from bugs because of unwanted interactions
    between test methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of an xUnit fixture class that opens and closes
    a database connection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Since a fixture class instance is created just once before all tests associated
    with the fixture are executed and the same instance is disposed of immediately
    after the tests, then the database connection is created just once when the fixture
    class is created and is disposed of immediately after the tests when the fixture
    object is disposed of.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fixture class is associated with each test class by letting the test class
    implement the empty `IClassFixture<T>` interface, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A fixture class instance is automatically injected in the test class constructor
    in order to make all data computed in the fixture test preparation available for
    the tests. This way, for instance, in our previous example we can get the database
    connection instance so that all test methods of the class can use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to execute some test preparation code on all tests contained in
    a collection of test classes instead of a single test class, we must associate
    the fixture class to an empty class that represents the collection of test classes,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `CollectionDefinition` attribute declares the name of the collection, and
    the `IClassFixture<T>` interface has been replaced with `ICollectionFixture<T>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we declare that a test class belongs to the previously defined collection
    by applying it to the `Collection` attribute with the name of the collection,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `Collection` attribute declares which collection to use, while the `DataBaseFixture`
    argument in the test class constructor provides an actual fixture class instance,
    so it can be used in all class tests.
  prefs: []
  type: TYPE_NORMAL
- en: The next section shows how to mock interfaces with the Moq framework.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking interfaces with Moq
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mocking capabilities are not included in any of the test frameworks we listed
    in this section as they are not included in xUnit. Therefore, they must be provided
    by installing a specific NuGet package. The Moq framework available in the `Moq`
    NuGet package is the most popular mock framework available for .NET and .NET Core.
    It is quite easy to use and will be briefly described in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we''ve installed the NuGet package, we need to add a `using Moq` statement
    in our test files. A mock implementation is easily defined, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The behavior of the mock dependency on specific input of the specific method
    can be defined with the `Setup/Return` method pair as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: After `Return`, we may place another `Setup/Return` pair that defines either
    the behavior of different input of the same method or the behavior of a different
    method. This way we can specify an indefinite number of input/output behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of specific input values, we may also use wildcards that match a specific
    type as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once configured the mock dependency we may extract the mocked instance from
    its `Object` property and use it as if it were an actual implementation, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: However, mocked methods are usually called by the code under test, so we just
    need to extract the mocked instance and use it as an input in our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We may also mock properties and async methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: With async methods, `Returns` must be replaced by `ReturnsAsync`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each mocked instance records all calls to its methods and properties, so we
    may use this information in our tests. The following code shows an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding statement asserts `MyMethod` that has been invoked with the given
    arguments at least twice. There are also `Times.Never`, a `Times.Once` (that asserts
    the method was called just once), and more.
  prefs: []
  type: TYPE_NORMAL
- en: The Moq documentation summarized up to now should cover 99% of the needs that
    may arise in your tests, but Moq also offers more complex options. The *Further
    reading* section contains the link to the complete documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The next section shows how to define in practice unit tests and how to run them
    both in Visual Studio and in Azure DevOps with the help of the book use case.
  prefs: []
  type: TYPE_NORMAL
- en: Use case – automating unit tests in DevOps Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we add some unit test projects to the example application we
    built in [Chapter 13](003ee8cb-5995-4364-8772-73d73df29cf8.xhtml), *Presenting
    ASP.NET Core MVC*. If you don't have it, you can download it from the [Chapter
    13](003ee8cb-5995-4364-8772-73d73df29cf8.xhtml), *Presenting ASP.NET Core MVC*,
    section of the GitHub repository associated with the book. The [Chapter 4](049a0a4b-74b6-41a1-92db-87a4f8af9fd1.xhtml),
    *Deciding The Best Cloud-Based Solution*, section of the GitHub repository contains
    the code we will add in this section and all the instructions to add it.
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, let's make a new copy of the solution folder and name it `PackagesManagementWithTests`.
    Then open the solution and add it to xUnit .NET Core C# test project named `PackagesManagementTest`.
    Finally, add a reference to the ASP.NET Core project (`PackagesManagement`), since
    we will test it, and a reference to the last version of the `Moq` NuGet package,
    since we need mocking capabilities. At this point, we are ready to write our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, we will write unit tests for the `Edit` method decorated with
    `[HttpPost]` of the `ManagePackagesController` controller, which is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Before writing our test methods, let's rename the test class that was automatically
    included in the test project as `ManagePackagesControllerTests`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first test verifies that in case there are errors in `ModelState` the action
    method renders a view with the same model it received as an argument so that the
    user can correct all errors. Let''s delete the existing test method and write
    an empty `DeletePostValidationFailedTest` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The method must be `async` since the `Edit` method that we have to test is
    `async`. In this test, we don''t need mocked objects since no injected object
    will be used. Thus, as a preparation for the test we just need to create a controller
    instance, and we must add an error to `ModelState` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we invoke the method, injecting `ViewModel` and a `null` command handler
    as its arguments since the command handler will not be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'In the verification stage, we verify that the result is `ViewResult` and that
    it contains the same model that was injected in the controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we also need a test to verify that in case there are no errors the command
    handler is called, and then the browser is redirected to the `Index` controller
    action method. We call the `DeletePostSuccessTest` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This time the preparation code must include the preparation of a command handler
    mock, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Since the handler `HandleAsync` method returns no `async` value, we can''t
    use `ReturnsAsync`, but we have to return just a completed `Task` (`Task.Complete`)
    with the `Returns` method. The method to test is called with both `ViewModel`
    and the mocked handler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, the verification code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As the first step, we verify that the command handler has actually been invoked
    once. A better verification should also include a check that it was invoked with
    a command that includes `ViewModel` passed to the action method. This can be done
    by extracting this information from `commandDependency.Invocations`. We will take
    it up as an exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Then we verify that the action method returns `RedirectToActionResult` with
    the right action method name and with no controller name specified.
  prefs: []
  type: TYPE_NORMAL
- en: Once all tests are ready, if the test windows don't appear on the left bar of
    Visual Studio, we may simply select the Run all tests item from Visual Studio
    Test menu. Once the test window appears, further invocations can be launched from
    within this window.
  prefs: []
  type: TYPE_NORMAL
- en: If a test fails, we can add a breakpoint to its code, so we can launch a debug
    session on it by right-clicking on it in the test window and then by selecting
    Debug selected tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps show how to connect our solution with an Azure DevOps repository,
    and we will define an Azure DevOps pipeline that builds the project and launches
    its tests. In this way, every day after that all developers have pushed their
    changes we can launch the pipeline to verify that the repository code compiles
    and passes all the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, we need a free DevOps subscription. If you don't already have
    one, please create one by clicking the Start Free button on this page: [https://azure.microsoft.com/en-us/services/devops/](https://azure.microsoft.com/en-us/services/devops/).
    Here, let's define an organization but stop before creating a project, since we
    will create the project from within Visual Studio.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ensure you are logged into Visual Studio with your Azure account (the same
    used in the creation of the DevOps account). At this point, you may create a DevOps
    repository for your solution by right-clicking on the solution and by selecting
    Configure continuous delivery to Azure.... In the window that appears, an error
    message will inform you that you have no repository configured for your code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/dbc6d39a-7382-45bc-9bc0-9a16480889fd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Click the Add to source control now link. After that, the DevOps screen will
    appear in the Visual Studio Team Explorer tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ea638c5d-f9df-4efb-9900-55e2d82f91ac.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once you click the Publish Git Repo button, you will be prompted to select
    your DevOps organization and a name for the repository. After you successfully
    publish your code to a DevOps repository, the DevOps screen should change as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fee29f8b-e302-4bba-a4c0-f5e238a8360f.png)'
  prefs: []
  type: TYPE_IMG
- en: The DevOps screen shows a link to your online DevOps project. In future when
    you open your solution, if the link does not appear, please click the DevOps screen
    Connect button or the Manage connections link (whichever appears) to select and
    connect your project.
  prefs: []
  type: TYPE_NORMAL
- en: Click this link to go to the online project. Once there, if you click the Repos item,
    on the left-hand menu, you will see the repository you just published.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, click the Pipelines menu item to create a DevOps pipeline to build and
    test your project. In the window that appears, click the button to create a new
    pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d6b38797-da24-4450-9375-88d70a784da6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You will be prompted to select where your repository is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/312d6a6e-71f3-4f9e-945c-df13b556ad9d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select Azure Repos Git and then your repository. Then you will be prompted
    about the kind of project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/dd35e542-279e-473b-9f8a-a6212f4fa607.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Select ASP.NET Core. A pipeline for building and testing your project will
    be automatically created for you. Save it by committing the newly created `.yaml`
    file to your repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c97e7062-e8f8-4ee0-a7f9-ae78f5c77746.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The pipeline can be run by selecting the Queue button, but since the standard
    pipeline scaffolded by DevOps has a trigger on the master branch of the repository,
    it is automatically launched each time changes to this branch are committed and
    each time the pipeline is modified. The pipeline can be modified by clicking the
    Edit button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/9d650049-a388-41e8-8617-ac1603d5b610.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once in edit mode, all pipeline steps can be edited by clicking the Settings link
    that appears above each of them. New pipeline steps can be added as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write `task:` where the new step must be added and then accept one of the suggestions
    that appear while you are typing the task name.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: After you have written a valid task name a Settings link appears above the new
    step, click it.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the desired task parameters in the window that appears and save.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In order to have our test working, we need to specify the criteria to locate
    all assemblies that contain tests. In our case, since we have a unique `.dll` file
    containing the tests, it is enough to specify its name. Click the Settings link
    of the `VSTest@2` test task, and replace the content that is automatically suggested
    for the Test files field with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Then click Add to modify the actual pipeline content. As soon as you confirm
    your changes in the Save and run dialog, the pipeline is launched, and if there
    are no errors, test results are computed. The results of tests launched during
    a specific build can be analyzed by selecting the specific build in the pipeline
    History tab and by clicking the Tests tab on the page that appears. In our case,
    we should see something like the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2f00596e-c2af-4fa5-94f6-fea25143eb4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If you click the Analytics tab of the pipeline page, you will see analytics
    about all builds, including analytics about the test results:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/3826cfb0-e925-40f6-b796-29ea9865b12a.png)'
  prefs: []
  type: TYPE_IMG
- en: Clicking the test area of the Analytics page gets us a detailed report about
    all pipeline test results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explained why it is worth automating software tests, and
    then we focused on the importance of unit tests. We also listed all types of tests
    and their main features, focusing mainly on unit tests. We analyzed the advantages
    of TDD, and how to use it in practice. With this knowledge, you should be able
    to produce software that is both reliable and easy to modify.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we analyzed all test tools available for .NET Core projects, focusing
    on the description of xUnit and Moq and showed how to use them in practice both
    in Visual Studio and in Azure DevOps with the help of the book use case.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter looks at how to test and measure the quality of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is it worth automating unit tests?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main reason TDD is able immediately to discover most bugs?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the `[Theory]` and `[Fact]` attributes of xUnit?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which xUnit static class is used in test assertions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which methods allow the definition of the Moq mocked dependencies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it possible to mock async methods with Moq? If yes, how?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the documentation on xUnit included in the chapter is quite complete,
    it doesn't include the few configuration options offered by xUnit. The full xUnit
    documentation is available at [https://xunit.net/](https://xunit.net/). Documentation
    for MSTest and NUnit can be found at [https://github.com/microsoft/testfx](https://github.com/microsoft/testfx) and
    at [https://github.com/nunit/docs/wiki/NUnit-Documentation](https://github.com/nunit/docs/wiki/NUnit-Documentation) respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Moq full documentation is at [https://github.com/moq/moq4/wiki/Quickstart](https://github.com/moq/moq4/wiki/Quickstart).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some links to performance test frameworks for web applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://jmeter.apache.org/](https://jmeter.apache.org/) (free and open source)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.neotys.com/neoload/overview](https://www.neotys.com/neoload/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview](https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.microfocus.com/en-us/products/silk-performer/overview](https://www.microfocus.com/en-us/products/silk-performer/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
