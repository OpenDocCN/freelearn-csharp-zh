- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Caching Strategies for Enhanced Performance
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提高性能的缓存策略
- en: It’s been frequently mentioned how minimal APIs should be just that, minimal.
    For the most part, this minimalism has been based on minimizing real estate –
    trying to keep the visible footprint of our code on the page as minimal as possible.
    But minimalism in APIs also extends to the resource footprint, meaning that, where
    possible, we should minimize the strain put on the system by overusing database/network
    connections and CPU.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 经常提到最小API应该是真正的最小化。在很大程度上，这种简约主义是基于最小化空间占用——尽量使我们的代码在页面上的可见足迹尽可能小。但API的简约主义也扩展到了资源占用，这意味着，在可能的情况下，我们应该最小化过度使用数据库/网络连接和CPU对系统造成的压力。
- en: Enhancing the performance of APIs through minimalism is the goal, and this can
    be achieved in part by caching.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简约主义提高API的性能是我们的目标，这可以通过缓存部分实现。
- en: When data is cached, it is stored following its first use for reuse in future
    operations. By doing this, we can reduce the latency or overhead incurred when
    fetching that data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据被缓存时，它将按照首次使用后的顺序存储，以便在未来的操作中重复使用。通过这样做，我们可以减少获取该数据时产生的延迟或开销。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Introduction to caching in minimal APIs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小API中的缓存介绍
- en: In-memory caching techniques
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存缓存技术
- en: Distributed caching strategies
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式缓存策略
- en: Response caching
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应缓存
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Visual Studio 2022 or Visual Studio Code will be required to run the code in
    this chapter. You will also need SQL Server 2022 installed on your system, with
    a working database you can query as an example. It is recommended that you complete
    [*Chapter 9*](B20968_09.xhtml#_idTextAnchor143) before this chapter so that you
    have the example employee database configured for use.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本章中的代码，需要Visual Studio 2022或Visual Studio Code。您还需要在系统上安装SQL Server 2022，并配置一个可以查询的工作数据库作为示例。建议您在阅读本章之前完成[*第9章*](B20968_09.xhtml#_idTextAnchor143)，以便您可以使用配置好的示例员工数据库。
- en: 'The code for this chapter is available in the GitHub repository at: [https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9](https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9)
    .'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可在GitHub仓库中找到：[https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9](https://github.com/PacktPublishing/Minimal-APIs-in-ASP.NET-9)。
- en: This chapter demonstrates distributed caching strategies that require an in-memory
    caching provider – in this example’s case, Redis. Installing Redis is not within
    the scope of this book, but documentation on how to install Redis or host it in
    Azure can be found at [https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/quickstart-create-redis](https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/quickstart-create-redis)
    and [https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/)
    .
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍需要内存缓存提供程序的分布式缓存策略——在本例中，是Redis。安装Redis不在本书的范围内，但有关如何在Azure中安装Redis或托管Redis的文档可以在[https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/quickstart-create-redis](https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/quickstart-create-redis)和[https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/)找到。
- en: 'The way to use Redis on your local Windows machine would be to install it through
    **Windows Subsystem for Linux** ( **WSL** ) and host it on your local WSL instance.
    More information on installing WSL can be found here: [https://learn.microsoft.com/en-us/windows/wsl/install](https://learn.microsoft.com/en-us/windows/wsl/install)
    .'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的本地Windows机器上使用Redis的方法是通过**Windows Subsystem for Linux**（**WSL**）安装它，并在您的本地WSL实例上托管它。有关安装WSL的更多信息，请参阅此处：[https://learn.microsoft.com/en-us/windows/wsl/install](https://learn.microsoft.com/en-us/windows/wsl/install)。
- en: Introduction to caching in minimal APIs
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小API中的缓存介绍
- en: APIs execute operations, and operations (usually) rely on data or state. Data
    needs to be retrieved or calculated as it either exists *at rest* (i.e., in a
    database or in a remote file location) or it exists as *data in use* (i.e., data
    that is yet to be calculated to produce other data).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: API执行操作，而操作（通常）依赖于数据或状态。数据需要被检索或计算，因为它要么存在于*静态*（即，在数据库中或在远程文件位置），要么存在于*使用中*（即，尚未计算以生成其他数据）的数据。
- en: Whichever way we look at it, there is overhead in retrieving data, whether it
    is retrieved as-is or whether it is the result of a computation. Caching aims
    to reduce that overhead by making use of data or state that has already been produced
    from its original source.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们如何看待它，检索数据都会产生开销，无论是直接检索还是作为计算结果检索。缓存旨在通过利用已从原始来源产生的数据或状态来减少这种开销。
- en: It could be argued that computing is so fast now that the overhead should be
    minimal to the point that caching is no longer needed. This would, however, be
    woefully inaccurate. Looking at a single operation in isolation, such as retrieving
    a record from a SQL database, may seem extremely quick, but at scale, the benefits
    of caching become more apparent.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 可以争论说，现在的计算速度如此之快，以至于开销应该微乎其微，以至于不再需要缓存。然而，这将是极其不准确的。单独查看一个操作，例如从SQL数据库中检索记录，可能看起来非常快，但在规模上，缓存的益处变得更加明显。
- en: Let’s take a working example of how caching can be beneficial. A start-up has
    built a system that can be used to send alerts to mobile devices, accessible via
    a minimal API. They must ensure that requests are allowed to be processed by calling
    clients, so they require an API key to be sent in the request headers for validation
    during each request.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个实际例子来看看缓存如何有益。一家初创公司构建了一个系统，可以用来通过最小API向移动设备发送警报。他们必须确保请求可以通过调用客户端处理，因此他们需要在每次请求的请求头中发送一个API密钥以进行验证。
- en: To validate the key, the start-up’s developers decided to outsource the key
    validation to a cloud company that manages the key and the encryption algorithms
    to be used – hosting an API itself for this purpose. The start-up is charged per
    request for validating the key.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证密钥，初创公司的开发者决定将密钥验证外包给一家管理密钥和要使用的加密算法的云公司——为此自己托管一个API。初创公司按请求验证密钥收费。
- en: In the early days, the cost of validating keys went relatively unnoticed because
    they had a low number of sporadic requests. However, as soon as their business
    started to grow, so did the number of requests. Soon, they had a scary invoice
    from their cloud partner for a huge amount of API validations, charged per request.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期，验证密钥的成本相对不明显，因为它们的请求数量很少且分散。然而，随着他们的业务开始增长，请求的数量也随之增加。很快，他们收到了来自云合作伙伴的令人恐惧的账单，账单上显示了大量按请求收费的API验证。
- en: Caching could have been used to mitigate the cost of validating API keys. An
    initial request could be made to validate the key, and then the result could be
    cached. From then on, when requests using that key are received, there would be
    an initial check against the cache first. If there is a record in the cache that
    validates the key, there is no need to call the paid API to validate it. Each
    cached record has an expiration date, meaning that it can be refreshed by calling
    the paid API again. This dramatically reduces the financial effects of validating
    API keys.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存本可以用来减轻验证API密钥的成本。可以首先发起一个请求来验证密钥，然后将其结果缓存起来。从那时起，当收到使用该密钥的请求时，首先会检查缓存。如果缓存中有验证密钥的记录，则无需调用付费API进行验证。每个缓存的记录都有一个过期日期，这意味着可以通过再次调用付费API来刷新它。这大大减少了验证API密钥的财务影响。
- en: 'We’ve established that caching is good for performance, reducing latency, and
    supporting overall application scalability, but what type of caching should we
    use? To answer this, we will explore three key caching methods available in minimal
    API development: in-memory caching, distributed caching, and response caching.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定缓存对性能、减少延迟和整体应用可扩展性有好处，但我们应该使用哪种类型的缓存？为了回答这个问题，我们将探讨在最小API开发中可用的三种关键缓存方法：内存缓存、分布式缓存和响应缓存。
- en: In-memory caching techniques
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存缓存技术
- en: Out of the various caching techniques supported by ASP.NET Core, **in-memory
    caching** is probably the simplest. This type of caching stores its contents in
    the memory of the machine hosting the minimal API.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在ASP.NET Core支持的多种缓存技术中，**内存缓存**可能是最简单的。这种类型的缓存将其内容存储在托管最小API的机器的内存中。
- en: The implementation of the cache is based on **IMemoryCache** , included within
    the **Microsoft.Extensions.Caching.Memory** package, which is usually included
    by default in ASP.NET Core projects.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存的实现基于**IMemoryCache**，它包含在**Microsoft.Extensions.Caching.Memory**包中，该包通常默认包含在ASP.NET
    Core项目中。
- en: Like other core services, **IMemoryCache** is available using dependency injection,
    so we can quite easily inject it as needed within various areas of a minimal API.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 就像其他核心服务一样，**IMemoryCache** 可以通过依赖注入来使用，因此我们可以很容易地在最小 API 的各个区域中按需注入它。
- en: Using this cache type, we can store an object, which is our minimal requirement,
    but we can also very easily specify an expiration time, which is a best practice
    as periodically recycling the cache keeps it running smoothly.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种缓存类型，我们可以存储一个对象，这是我们的最小要求，但我们也可以非常容易地指定一个过期时间，这是一个最佳实践，因为定期回收缓存可以使其运行顺畅。
- en: Let’s explore a simple example within a minimal API. I’m going to use the API
    project from [*Chapter 9*](B20968_09.xhtml#_idTextAnchor143) (which is available
    on GitHub) as a foundation for this example project. Our aim is to mitigate the
    latency and overhead incurred when communicating with a database.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一个最小 API 中的简单示例。我将使用来自 [*第 9 章*](B20968_09.xhtml#_idTextAnchor143)（可在 GitHub
    上找到）的 API 项目作为这个示例项目的基础。我们的目标是减轻与数据库通信时产生的延迟和开销。
- en: In this API, we have an endpoint that allows clients to get an employee with
    a specific ID. The API will use Entity Framework to run a SQL query against the
    database, returning the result in the request response.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个 API 中，我们有一个允许客户端通过特定 ID 获取员工的端点。API 将使用 Entity Framework 对数据库执行 SQL 查询，并将结果返回在请求响应中。
- en: 'Using an in-memory cache, we can add some optimization logic to this operation.
    Here are the steps we are going to work through:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用内存缓存，我们可以为这个操作添加一些优化逻辑。以下是我们要执行的步骤：
- en: Run the operation as requested, fetching the data from the database.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照要求运行操作，从数据库中获取数据。
- en: Check the in-memory cache to see whether the employee with this ID is currently
    cached.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查内存缓存以查看是否已缓存具有此 ID 的员工。
- en: If it isn’t, add the retrieved employee to the cache.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有，将检索到的员工添加到缓存中。
- en: Return the employee in the request response.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在请求响应中返回员工。
- en: Create a request for the same employee ( same ID).
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为同一员工（相同的 ID）创建一个请求。
- en: Get the employee from the cache instead of the database.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从缓存而不是数据库中获取员工。
- en: Return the cached employee to the client.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将缓存的员工返回给客户端。
- en: Before we can achieve this goal, we need to reference **IMemoryCache** in the
    project.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们实现这个目标之前，我们需要在项目中引用 **IMemoryCache**。
- en: 'First, add **IMemoryCache** to the dependency injection container in **Program.cs**
    :'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在 **Program.cs** 中将 **IMemoryCache** 添加到依赖注入容器中：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you can create the **GET** endpoint, injecting this **IMemoryCache**
    object along with **DapperService** :'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以创建 **GET** 端点，注入这个 **IMemoryCache** 对象以及 **DapperService**：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now that you have a cache, you can add code for retrieving values from it:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了缓存，你可以添加从其中检索值的代码：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: By first running a check, we can avoid unnecessary execution of code and get
    the required object to the client much quicker, also avoiding a call into the
    database via Dapper.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过首先进行检查，我们可以避免不必要的代码执行，并更快地将所需对象传递给客户端，同时避免通过 Dapper 调用数据库。
- en: 'Assuming that the item doesn’t exist, we will use our original logic of looking
    up the **Employee** record from the database using **DapperService** . However,
    instead of returning the item straight away, we will first add it to the cache:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 假设该项目不存在，我们将使用我们的原始逻辑，通过 **DapperService** 从数据库中查找 **Employee** 记录。然而，我们不会立即返回项目，而是首先将其添加到缓存中：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This works well but, ideally, we don’t want this to stay in the cache forever.
    It’s a good idea to refresh the cache periodically because data may change, and
    we want to ensure we are getting the most up-to-date data where possible while
    balancing this with reducing latency from database transactions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这效果很好，但理想情况下，我们不想让它永远留在缓存中。定期刷新缓存是个好主意，因为数据可能会变化，我们希望确保尽可能多地获取最新数据，同时平衡减少数据库事务的延迟。
- en: 'We can strike this balance by imposing an expiration on cached objects. This
    needs to be done after the retrieval of the **Employee** object but before it
    is added to the cache. Let’s set an expiry of **30** seconds as an example:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过对缓存的对象设置过期时间来达到这个平衡。这需要在检索 **Employee** 对象之后但在将其添加到缓存之前完成。例如，我们可以将其设置为
    **30** 秒的过期时间：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'By creating an instance of **MemoryCacheEntryOptions** , we have defined some
    cache configuration parameters that can be passed into the cache when we add a
    new object to it. Update the **cache.Set()** method to include this parameter:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建一个 **MemoryCacheEntryOptions** 实例，我们定义了一些缓存配置参数，当我们将新对象添加到缓存中时可以传递给缓存。更新
    **cache.Set()** 方法以包含此参数：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Your endpoint should now look like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你的端点现在应该看起来像这样：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There you go! You’ve successfully introduced caching to your minimal API endpoint
    using **IMemoryCache** .
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！你已经成功地将缓存引入到你的最小 API 端点，使用了 **IMemoryCache**。
- en: In-memory caching is most likely the default caching strategy when starting
    an API project, but if your system has growth in adoption, then scalability and
    high availability will become increasingly important measurements of success.
    When looking to scale, distributed caching strategies can be adopted with the
    use of a reputable caching framework. Let’s look at one of the most famous caching
    technologies, Redis.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动 API 项目时，内存缓存很可能是默认的缓存策略，但如果你的系统采用率有所增长，那么可扩展性和高可用性将变得越来越重要的成功衡量标准。当考虑扩展时，可以使用可靠的缓存框架采用分布式缓存策略。让我们看看最著名的缓存技术之一，Redis。
- en: Distributed caching strategies
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式缓存策略
- en: A **distributed caching strategy** uses methods such as **IMemoryCache** within
    an architecture that supports scalability. In contrast to **IMemoryCache** , distributed
    caching involves a connection between the ASP.NET application hosting your minimal
    API and the caching provider.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**分布式缓存策略**使用诸如 **IMemoryCache** 之类的在支持可扩展性的架构中的方法。与 **IMemoryCache** 相比，分布式缓存涉及
    ASP.NET 应用程序（托管你的最小 API）和缓存提供程序之间的连接。'
- en: In this example, the caching provider I will be using is **Redis** .
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我将使用的缓存提供程序是 **Redis**。
- en: Redis is an in-memory caching provider that can also be used as an in-memory
    database. It is available as an open source product for installation on-premises
    or in the cloud.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 是一个内存缓存提供程序，也可以用作内存数据库。它作为一个开源产品提供，可以安装在本地或云端。
- en: For the purposes of this demonstration, I installed Redis on an Ubuntu machine
    as a basic service. I then updated the Redis configuration so that Redis binds
    to **0.0.0.0** , listening on the default port of **6379** . This should only
    be relevant to you if your Redis service is running on a separate machine like
    mine is.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示目的，我在 Ubuntu 机器上安装了 Redis 作为基本服务。然后我更新了 Redis 配置，使其绑定到 **0.0.0.0**，监听默认端口
    **6379**。这仅在你像我一样，Redis 服务运行在单独的机器上时才相关。
- en: With a Redis instance available, I can add the required NuGet packages to the
    API project for interacting with Redis as a cache.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有 Redis 实例可用，我可以向 API 项目添加所需的 NuGet 包，以便与 Redis 作为缓存进行交互。
- en: 'Add the **NRedisStack** package to the project:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 将 **NRedisStack** 包添加到项目中：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We will still be interacting with the cache in **Program.cs** , so we need
    to reference namespaces from **NRedisStack** here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然会在 **Program.cs** 中与缓存进行交互，因此在这里我们需要从 **NRedisStack** 引用命名空间：
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now, we can update the endpoint for retrieving employees by **Id** with a new
    cache, replacing the **IMemoryCache** implementation with Redis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以更新通过 **Id** 获取员工的端点，使用新的缓存，用 Redis 替换 **IMemoryCache** 实现。
- en: 'We start by creating **ConfigurationOptions** , which can be passed as a parameter
    when connecting to the Redis instance:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建 **ConfigurationOptions**，这可以在连接到 Redis 实例时作为参数传递：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Following this, we should now have a Redis connection that can be referenced
    in the **db** variable. Next, we will add the equivalent logic for caching from
    the **IMemoryCache** example, where we first check for a cache entry with a key
    (the **Employee** ID as a string, in this case) and return that if it exists,
    returning the **Employee** instance from the cache if it does:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们现在应该有一个可以由 **db** 变量引用的 Redis 连接。接下来，我们将添加来自 **IMemoryCache** 示例的等效缓存逻辑，我们首先检查具有键（在这种情况下是
    **Employee** ID 的字符串）的缓存条目，如果存在则返回它，如果不存在，则从缓存返回 **Employee** 实例：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When calling **StringGet()** to retrieve a relevant entry from Redis, if it
    doesn’t exist already, an object will be returned with **HasValues** set to **false**
    . Assuming that the Redis cache doesn’t contain the **Employee** record we’re
    looking for, we fetch it from the database and cache it before returning it to
    the client:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用 **StringGet()** 从 Redis 获取相关条目时，如果它不存在，将返回一个对象，其中 **HasValues** 设置为 **false**。假设
    Redis 缓存不包含我们正在寻找的 **Employee** 记录，我们将从数据库中获取它并在返回给客户端之前将其缓存：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Please note that Redis doesn’t natively support the insertion of strongly typed
    .NET objects, so we need to convert the **Employee** object to a JSON string through
    serialization when saving it and deserialize it from a JSON string to an **Employee**
    object when retrieving it.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Redis 本身不支持直接插入强类型 .NET 对象，因此当保存时，我们需要通过序列化将 **Employee** 对象转换为 JSON 字符串，并在检索时从
    JSON 字符串反序列化回 **Employee** 对象：
- en: 'Your updated Redis-connected endpoint should now look like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你更新的Redis连接端点现在应该看起来像这样：
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Implementing a cache in a separately hosted environment using something such
    as Redis has introduced more flexibility to our minimal API. I encourage you to
    take this simple example further by creating a generic service that can facilitate
    the interactions between ASP.NET and the Redis cache so that you are ultimately
    decoupling the API from its caching system. In the future, should you wish to
    move away from Redis to a different caching technology, you need to be able to
    do this without affecting the original API code.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Redis等工具在独立托管环境中实现缓存，为我们的最小API引入了更多的灵活性。我鼓励你通过创建一个通用的服务来进一步扩展这个简单的示例，该服务可以促进ASP.NET和Redis缓存之间的交互，从而最终将API与其缓存系统解耦。在未来，如果你希望从Redis迁移到不同的缓存技术，你需要能够做到这一点而不影响原始API代码。
- en: We’ve covered two examples of caching strategies so far. Let’s wrap up with
    a third technique, focusing on the caching of request responses.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了两种缓存策略的示例。让我们以第三种技术结束，重点关注请求响应的缓存。
- en: Response caching
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应缓存
- en: '**Response caching** works within the same logical principles as the previous
    two caching strategies, but instead of caching database objects in memory, it
    caches responses at the HTTP level.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**响应缓存**与前面两种缓存策略的逻辑原理相同，但不是在内存中缓存数据库对象，而是在HTTP级别缓存响应。'
- en: 'Like **IMemoryCache** , minimal APIs can leverage ASP.NET’s native middleware
    by enabling response caching as a feature in **Program.cs** :'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 与**IMemoryCache**一样，最小API可以通过在**Program.cs**中启用响应缓存作为功能来利用ASP.NET的本地中间件：
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Once enabled, response caching is very simple to add to a **GET** endpoint.
    We can add **HttpContext** to the parameters, and then, whenever we have the **Employee**
    object and are ready to return it, we can set the response to be cached for a
    certain amount of time, meaning that requesting the same data within that time
    will simply return the cached HTTP response instead of touching the database:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启用，响应缓存添加到**GET**端点非常简单。我们可以将**HttpContext**添加到参数中，然后，每当我们有**Employee**对象并准备返回它时，我们可以设置响应以缓存一定的时间，这意味着在指定时间内请求相同的数据将直接返回缓存的HTTP响应，而不是接触数据库：
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, this is a remarkably straightforward way to cache frequent responses,
    and the expiry time can, of course, be adjusted as needed. You could even combine
    the caching approaches, having an in-memory cache that retrieves the data and
    then caching the response.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这是一种非常直接的方式来缓存频繁的响应，并且过期时间当然可以根据需要进行调整。你甚至可以将缓存方法结合起来，有一个内存缓存来检索数据，然后缓存响应。
- en: With three working examples of caching in a minimal API under our belt, let’s
    review what we’ve learned in this chapter.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在手头有三个最小API中的缓存工作示例后，让我们回顾本章学到的内容。
- en: Summary
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we have explored caching using three different strategies:
    ASP.NET in-memory, distributed, and response caching.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了使用三种不同的策略进行缓存：ASP.NET内存、分布式和响应缓存。
- en: We started by defining caching as a concept, relating it to the context of minimal
    APIs, before exploring a hypothetical scenario of a company looking to save on
    the cost of retrieving data via APIs with a cache.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义了缓存作为一个概念，将其与最小API的上下文相关联，然后探讨了公司希望通过缓存来节省通过API检索数据成本的假设场景。
- en: Following this, we explored the ASP.NET native method of caching in memory,
    learning about **IMemoryCache** and how it can be implemented within an endpoint
    to limit the overhead produced by database transactions. We also learned how to
    make cached data expire.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，我们探讨了ASP.NET原生内存缓存方法，了解了**IMemoryCache**以及如何在端点中实现它以限制数据库事务产生的开销。我们还学习了如何使缓存数据过期。
- en: Then, we took this knowledge and expanded on it, following similar caching principles
    within a distributed cache in the form of Redis.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将这些知识扩展，遵循类似缓存原则，在分布式缓存中以Redis的形式进行。
- en: Finally, we reviewed an example of response caching, allowing us to take frequently
    sent requests and bypass the database by resending a previously sent HTTP request.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们回顾了一个响应缓存的示例，使我们能够通过重新发送之前发送的HTTP请求来绕过数据库，处理频繁发送的请求。
- en: In the next chapter, we will explore the best practices you can observe to increase
    the readibility, scalibility and maintainability of your minimal APIs.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨你可以观察到的最佳实践，以增加你最小API的可读性、可扩展性和可维护性。
- en: Part 4 - Best Practices, Design, and Deployment
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四部分 - 最佳实践、设计和部署
- en: In the final part, we shift our focus to the principles of robust API design
    and deployment. You’ll learn about best practices for shipping production-ready
    minimal APIs, as well as strategies for testing and maintaining compatibility
    across different environments.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一部分，我们将关注点转移到稳健的API设计和部署原则。您将了解如何将生产就绪的最小API投入使用的最佳实践，以及在不同环境中进行测试和维护兼容性的策略。
- en: 'This part has the following chapters:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 13*](B20968_13.xhtml#_idTextAnchor183) , *Best Practices for Minimal
    API Resiliency*'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B20968_13.xhtml#_idTextAnchor183) ，*最小API弹性的最佳实践*'
- en: '[*Chapter 14*](B20968_14.xhtml#_idTextAnchor200) , *Unit Testing* *, Compatibility,
    and Deployment of Minimal APIs*'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第14章*](B20968_14.xhtml#_idTextAnchor200) ，*最小API的单元测试、兼容性和部署*'
