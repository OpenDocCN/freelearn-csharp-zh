- en: Chapter 3. Learning Concurrency with Parallel Loops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a basic parallel for loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a basic parallel foreach loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breaking a parallel loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stopping a parallel loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cancelling a parallel loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling exceptions in a parallel loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling the degree of parallelism in a loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Partitioning data in a parallel loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Thread Local Storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most developers frequently write sequential code in the form of loops where
    they are doing something to each of the items in a collection of data. Loops are
    often an ideal place to introduce parallelism, because most of the time, the items
    in the collections are not related to each other, and we usually want to perform
    the same independent operation on all the items in a collection. However, parallelism
    comes with overhead. The individual loop iterations must perform enough work to
    justify the overhead of parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: The **.NET 4.5 Parallel Extensions** includes methods that simulate both parallel
    `For` and parallel `ForEach` loops, and both look very much like the loop syntax
    you already use for sequential loops. In fact, it is quite easy to change a sequential
    loop into a parallel loop which can complete faster on a computer with multiple
    cores.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will be taking a look at how to use parallel `For` and parallel
    `ForEach` loops in your programs.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a basic parallel for loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we will take a look at the syntax of a basic parallel `for`
    loop and compare its performance against a sequential `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: For our comparison we will create a console application with two methods. Both
    methods will loop over a very large array of numbers and use the `Math.Sqrt()`
    method to calculate the square root of each number in the array. One of our methods
    will use a sequential `for` loop to process the array, the other will use a parallel
    `for` loop.
  prefs: []
  type: TYPE_NORMAL
- en: Our program will time both operations and will display the results to the console
    when both loops finish.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s open up Visual Studio and create some parallel loops. The steps
    for creating the parallel `for` loops are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `ParallelFor` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, let's implement the `Main` method of the program class. We are going
    to create a `StopWatch` object to perform the timing, create a large array of
    random numbers, and then call the methods to run the loops.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next let's create our `SequentialLoop` method which, as you might have guessed,
    executes a sequential `for` loop that calculates the square root of each number
    in the array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now we just need to create our `ParallelLoop` method which uses a parallel `for`
    loop to calculate the square root of each number in the array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you can see from the preceding results, on my quad-core machine there were
    some performance improvements with the parallel loop, but not as much as you might
    have expected. It is possible that on your machine the sequential loop might have
    even outperformed the parallel loop. If this is the case, it probably means that
    the overhead of creating the threads and performing the context switches to execute
    the threads on the CPU outweighed the benefits of parallelizing the loop. As the
    chapter continues, we will look at how we can improve the performance of our loops
    a bit more. For now, we are just focusing on the basics of the parallel for loop
    syntax.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we used the basic overload of the static `For` method of the
    `Parallel` class to create our loop. At this level the syntax looks very much
    like that of a sequential for loop.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The first two parameters forms the range the loop will iterate over. Note that
    `from` is an inclusive parameter and `to` is exclusive. So, if our first parameter
    is 0 and our second parameter is 10, our loop will iterate from 0 to 9.
  prefs: []
  type: TYPE_NORMAL
- en: The third parameter is a delegate of type `Action<int>` which always returns
    `void`. In this recipe, we use a Lambda expression for the delegate.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Creating a basic parallel foreach loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe we will take a look at the syntax of a basic parallel foreach
    loop and compare its performance against that of a sequential foreach loop.
  prefs: []
  type: TYPE_NORMAL
- en: For our comparison, like the previous recipe, we will create a Console Application
    with two methods which both loop over a very large array of numbers and use the
    `Math.Sqrt()` method to calculate the square root of each number in the array.
    One of our methods will use a sequential foreach loop to process the array, the
    other will use a parallel foreach loop.
  prefs: []
  type: TYPE_NORMAL
- en: Our program will time both operations and we will display the results to the
    console when both loops finish.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s go to Visual Studio and see how to create parallel for loops. The
    steps to create parallel ForEach loops are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `ParallelForEach` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let's start off by putting some code in the `Main` method of the program class
    to create a `StopWatch` object to perform the timing, create a large array of
    random numbers, and then call the two methods to run the loops.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next we need to create our `SequentialLoop` method to execute a sequential `foreach`
    loop that calculates the square root of each number in the array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now let's create our `ParallelLoop` method which uses a parallel `ForEach` loop
    to calculate the square root of each number in the array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This time the sequential loop outperformed the parallel loop by a bit, at least
    on my machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this recipe, we used the basic overload of the static `ForEach` method of
    the `Parallel` class to create our loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Basically, this is just a source that implements `IEnumerable<T>` and a delegate.
    In our case we used a Lambda expression for the delegate.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Other than the type of loop we used and the parameter types, the code in this
    project is very much like that of our parallel for loop recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking a parallel loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Occasionally when writing loops, we will want to break out of the loop under
    certain conditions. In a sequential loop we would accomplish this breakout with
    a C# `break` statement. However, a break statement is only valid when enclosed
    within an iteration statement like a foreach loop. When we run a parallel foreach,
    we are not running an iteration statement. It is actually a delegate running in
    a method.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe we will we learn how to use a TPL class called `ParallelLoopState`
    to break out of a parallel ForEach loop. `ParallelLoopState` is a class that allows
    concurrently running loop bodies to interact with each other. It also provides
    us with a way to break out of a loop. When the loop breaks or completes, we will
    check the completion status of our loop using the `ParallelLoopResult` structure.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to create a Console Application to download the contents of a book
    and split the individual words into a list of strings. We will then loop through
    the list of strings looking for a specific word. When we find the word we are
    looking for, we will use `ParallelLoopState` to break out of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let''s take a look at how to cancel a parallel loop. The steps to cancel
    a parallel loop are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `BreakALoop` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, let's add some code to the `Main` method of our program class to use
    a `WebClient` to download the contents of the book and split the words of the
    book into a string array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, let's create our loop. The loop needs to process the list of strings looking
    for the word "immutability". When we find it, use `ParallelLoopState.Break` to
    break out of the loop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will finish adding a couple of lines to display the loop iteration we broke
    on, the completion status of the loop, and wait for the user to exit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, we used a different overload of `Parallel.ForEach`. This overload
    takes an `Action` delegate with the source and a loop state parameter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the body of our loop, we used the loop state parameter to cancel the loop.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that we didn't instantiate the `ParallelLoopState` parameter that we passed
    into the loop. It was created and provided to us by the `Parallel` class. We just
    have to change our Lambda expression to indicate that we want to use the loop
    state parameter.
  prefs: []
  type: TYPE_NORMAL
- en: The `Parallel.ForEach` method returns a `ParallelLoopResult` structure (`var
    loopResult`). This structure has a couple of very useful properties. One of which
    is `IsCompleted` that gets the loop completion status. A value of true indicates
    that all iterations of the loop were executed and the loop didn't receive a request
    to end prematurely. `LowestBreakIteration` gets the index of the lowest iteration
    from which `Break` was called.
  prefs: []
  type: TYPE_NORMAL
- en: There is an important difference between breaking from a parallel loop and a
    sequential loop. When breaking a sequential loop, the break statement will immediately
    terminate the loop. `ParallelLoopState.Break` has a different behavior. What we
    are actually doing is signaling that we would like the loop terminated at the
    system's earliest convenience. The issue is that we are not processing a single
    element at a time. If we call `ParallelLoopState.Break` in one of our threads,
    other threads are likely to still be executing. Some code will continue to run
    for a short time after you request to terminate the loop.
  prefs: []
  type: TYPE_NORMAL
- en: Stopping a parallel loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you break from a parallel loop, the application will actually continue
    to process any elements of the collection that were found prior to the element
    that was being processed when the `ParallelLoopState.Break` method was called.
    Sometimes this behavior is not desirable and we want to end the loop immediately,
    without processing any loop iterations that are currently running.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will look at how to use the `ParallelLoopState.Stop` method
    to request that the processing of elements terminate as soon as possible without
    guaranteeing that any other elements will be processed. We will again be using
    `WebClient` to download the contents of a book, and splitting the words into a
    sorted list of strings. We will loop through the list looking for the word "immutability".
    When we find it, we will stop the loop.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s start Visual Studio and see how to stop a parallel loop. The steps
    to stop a parallel loop are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `StopALoop` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, let's add some code to the `Main` method of our program class to use
    a `WebClient` to download the contents of the book, and split the words of the
    book into a string array.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, let's create our loop. The loop needs to process the list of strings looking
    for the word "immutability". When we find it, use `ParallelLoopState.Stop` to
    stop the loop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We will finish adding a couple of lines to display the loops' completion status
    and wait for user's input to exit.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_04.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As in the previous recipe, we used the overload of `Parallel.ForEach` that takes
    an `Action` delegate with the source and a loop state parameter.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the body of our loop, we used the loop state parameter to stop the loop.
    We also used the `ParallelLoopState.IsStopped` property to display the status
    of our loop.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding results, the elements of the list that were
    currently in process when we stopped the loop, still get written to the console.
    However, `ParallelLoopState.Stop` does stop the loop more quickly than `ParallelLoopState.Break`
    and is better to use in a situation where you are searching for an element of
    a condition in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: Both `ParallelLoopState.Break` and `ParallelLoopState.Stop` behave differently
    from a break statement in a sequential loop. We are asking the application to
    process more than one thing at a time and we can no longer count on the sequence.
    It is easy to parallelize loops with the TPL, but it should be approached with
    caution because we can no longer rely on the order of the results.
  prefs: []
  type: TYPE_NORMAL
- en: Cancelling a parallel loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've seen in previous recipes, to create a task that can be cancelled, you
    pass in a cancellation token from a `CancellationTokenSource` object. If you then
    make a call to the `CancellationTokenSource.Cancel` method, the token signals
    all of the tasks that use it should terminate. The linked tasks detect this signal
    via the token and stop their activity in a safe manner.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel loops support the same cancellation token mechanism as parallel tasks.
    In a parallel loop, you supply the `CancellationToken` to the method in the `ParallelOptions`
    parameter.
  prefs: []
  type: TYPE_NORMAL
- en: This recipe will download the contents of a book and split the words into a
    list of strings. We will then use a parallel loop to iterate through the words
    writing each to the console. However, we will create a separate task that sleeps
    for a few seconds and then calls the `CancellationTokenSource.Cancel` method which
    will cancel the loop.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s create a Console Application in Visual Studio so that we can see how
    to break a loop. The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `BreakALoop` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, in the `Main` method of the program class, let's create a `CancellationTokenSource`
    and then add the `CancellationToken` to a `ParallelOptions` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, just below the previous lines, create a simple task that sleeps for a
    few seconds and then calls the `Cancel` method on the `CancellationTokenSource`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now create a `WebClient` to download the text of a book, and split the words
    from the book into a list of strings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, let's create a simple parallel `foreach` loop that writes the strings
    to the console. The loop should be in a try/catch and we should be catching `OperationCancelledException`
    and `AggregateException`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_05.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe we are using another overload of the `Parallel.ForEach` method
    that accepts an `IEnumerable` source, a `ParallelOptions` object, and an `Action`
    delegate.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The difference between cancelling a task and cancelling a parallel loop is how
    we pass in the `CancellationToken`. With a task, a `CancellationToken` is passed
    directly into the constructor of the task. For a parallel loop, we set the `CancellationToken`
    property of a `ParallelOptions` object with our `CancellationToken`, and then
    pass the `ParallelOptions` object into the parallel loop method.
  prefs: []
  type: TYPE_NORMAL
- en: If the token that signals the cancellation is the same token that is set on
    the `ParallelOptions` instance, then the parallel loop will throw an `OperationCanceledException`
    on cancellation. If a different token causes cancellation, the loop will throw
    an `AggregateException` with an `OperationCanceledException` as an `InnerException`.
    Both should be handled in your `catch` blocks.
  prefs: []
  type: TYPE_NORMAL
- en: Handling exceptions in a parallel loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a sequential loop throws an exception, the normal flow of the loop is interrupted.
    Control will be passed to a `catch` block or, if left unhandled, the exception
    is passed to the .NET runtime, and the process is aborted.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel `For` and `ForEach` loops are similar in that they do not have any
    special mechanism to handle exceptions that might be thrown. It is up to us to
    handle any exceptions which might be thrown on one or multiple threads by wrapping
    all exceptions from the loop in an `AggregateException`.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we will create a simple parallel `For` loop that loops through
    a range of numbers, writing the values to the console. If the number being processed
    is higher than a set number, we will throw a new `ArgumentException` which we
    will then store in a queue and later throw as part of an `AggregateException`.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this recipe we need to turn off the Visual Studio 2012 Exception Assistant.
    The Exception Assistant appears whenever a runtime exception is thrown, and intercepts
    the exception before it gets to our handler.
  prefs: []
  type: TYPE_NORMAL
- en: To turn off the Exception Assistant, go to the **Debug** menu and select **Exceptions**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Uncheck the **User-unhandled** checkbox next to **Common Language Runtime Exceptions**.![Getting
    ready…](img/0225OT_03_10.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s take a look at how to handle exceptions in parallel loops. The steps
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `LoopExceptions` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the `Main` method of the program class, create a try/catch block. The `catch`
    block should have some code for looping through `AggregateException.InnerExceptions`
    and displaying the wrapped exception messages to the console.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Inside the `try` block, define a variable of type `ConcurrentCollection<Exception>`.
    This will be the container to hold our exceptions until we are ready to wrap them
    in an `AggregateException`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, let's create a simple parallel `ForEach` loop that loops from 0 to
    100\. If the loop encounters a number greater than 95, it should throw an `ArgumentException`.
    The body of the loop needs a try/catch block to catch the argument exception to
    enqueue it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_06.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this recipe, the outer `catch` block handles `AggregateException` which can
    wrap many individual exception objects. Any one or all the actual threads created
    by calling `Parallel.For` could throw an `AggregateException`. In our `catch`
    block, we need to loop through `AggregateException.InnerExceptions` to process
    individual exceptions that occurred.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: We have also created a try/catch block in the body of the parallel loop. This
    `catch` block catches any type of exception thrown in the loop and simply enqueues
    it in a `ConcurrentQueue<Exception>`. `ConcurrentQueue<T>` is a thread-safe first-in-first-out
    collection that implements `IEnumerable<T>`. `AggregateException` has a constructor
    overload that accepts `IEnumerable<Exception>`, so we can wrap our exception collection
    in `AggregateException` by passing the `ConcurrentCollection` to the constructor.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Controlling the degree of parallelism in a loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, `Parallel.For` and `Parallel.ForEach` utilize as many threads as
    the underlying thread scheduler will provide. Usually it is good enough to let
    the system manage how iterations of a parallel loop are mapped to your computer's
    cores. Sometimes, however, you might want more control over the maximum number
    of threads that are used. For example, if you know that an algorithm you are using
    won't scale beyond a certain number of cores; you might want to limit the cores
    used in order to avoid wasting cycles.
  prefs: []
  type: TYPE_NORMAL
- en: The number of tasks created by `Parallel.For` and `Parallel.ForEach` is often
    greater than the number of available cores. However, you can limit the maximum
    number of tasks used concurrently by specifying the `MaxDegreeOfParallelism` property
    of a `ParallelOptions` object.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to create a large array of integers. We will then
    pass this array to a couple of parallel `For` loops. One loop will run with the
    default degree of parallelism, and the other will be limited to four threads.
    We will display the time it takes to run each loop to see if there is any performance
    difference between the two.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s take a look at how we can control the degree of parallelism in a parallel
    loop. The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `DegreeOfParallelism` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, in the program class, let's create a method named `DefaultParallelism`
    that takes an array of `Int32` as a parameter. The method calls `Parallel.For`
    and loops through the array calculating the square root of each element.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, let's create another method named `LimitedParallelism` that takes the
    same type of parameter. This method will also call `Parallel.For` and loop through
    the array calculating the square root of each element. The only difference is
    that this method will also create a `ParallelOptions` object with the `MaxDegreeOfParallelism`
    property set to `4`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, in the `Main` method, we need to create a large array of `Int32` and
    initialize the array elements to random numbers. We also need to set up a `StopWatch`
    object so we can capture some time and call the two methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe doesn't have an algorithm that benefits from controlling the degree
    of parallelism, but in certain long running loop bodies, the ThreadPool's heuristics
    will be unable to determine the right number of threads to utilize, and could
    end up injecting many more than is appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: The degree of parallelism is controlled by creating a `ParallelOptions` object
    and setting the `MaxDegreeOfParallelism` property.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Once created, the `ParallelOptions` object can be passed into one of the many
    overloads of `Parallel.For` or `Parallel.ForEach` that accept `ParallelOptions`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Partitioning data in a parallel loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When creating a `Parallel.For` or `Parallel.ForEach` loops, we are effectively
    queuing up a delegate of work that will eventually be run on a ThreadPool worker
    thread. The amount of time taken to create and swap out these delegate payloads
    can have a very adverse effect on performance, especially when we create loops
    with small delegate bodies.
  prefs: []
  type: TYPE_NORMAL
- en: There is a default `Partitioner<T>` class that uses a default partitioning algorithm
    that takes into account the number of cores on your system and other factors,
    but default portioning may or may not yield the best results.
  prefs: []
  type: TYPE_NORMAL
- en: The .NET 4.5 Parallel Extensions also allows us to create our own custom partitioning
    chunks so that the workload of a `Parallel.For` or `Parallel.ForEach` is broken
    up into of a size that we specify in our code. We are effectively creating a custom
    partitioning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe we are going to create three parallel loops that each iterate
    over a large array of integers. One of the loops will use no data partitioning,
    one will use the default partitioner, and one will use a custom partition. We
    will capture the time it takes each loop to iterate over the array and display
    the results.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s see how we can partition data for a parallel loop. The steps are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `PartitionData` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, in the program class, let's create a method called `NoPartitioning` that
    takes an array of integers as a parameter. As the name indicates, this method
    will use no partitioning and will just iterate over the elements in the array
    calculating the square root of each element.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, we need to create a method called `DefaultPartition`. Like the other method,
    this one will take an array of integers as its parameter and will iterate over
    the array calculating the square root of each element in the array. This method
    will use the `Partitioner.Create` method to create a partition for the data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now let's create a method called `CustomPartitioning`. This method will use
    a different overload of `Partitioner.Create` which allows us to specify the range
    size we want to use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Finally, in the `Main` method, we need to create a large array of `Int32` and
    initialize the array elements to random numbers. We also need to set up a `StopWatch`
    object so we can capture some time and call the three methods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_08.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you can see from the preceding screenshot, there was quite a performance
    improvement realized from using custom partitioning.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, the `NoPartitioning` method iterates through the array performing
    the `Math.Sqrt` operation on each element with no partitioning of the array at
    all. The body of the loop is handed to the `Parallel.ForEach` method as a delegate,
    and the body of a parallel loop is so small that the cost of the delegate invocation
    on each loop's iteration is very significant. As a result, the performance is
    not very good.
  prefs: []
  type: TYPE_NORMAL
- en: In the `DefaultPartitioning` method, we used one of the `Create` method overloads
    of the `Partitioner` class to create an `IEnumerable<T>` of range partitions over
    the source array. The benefit of doing this is that the delegate invocation cost
    is incurred only once per range, rather than once per element. As you can see,
    that resulted in a pretty nice performance improvement.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: In the `CustomPartitioning` method, we use a different overload of `Partitioner.Create`
    to create a custom partition that chunks a range that we specified.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Basically we told the partitioner to create a partition from 0 to `numbers.Count()`
    with a chunk size of 1,00,000\. In other words, we partitioned the array into
    ten equal parts. The performance improvement was pretty substantial.
  prefs: []
  type: TYPE_NORMAL
- en: The key lesson here is that the overhead of delegate invocation, particularly
    in loops with small bodies, can be very significant. Consider using either the
    default partitioning scheme, or a custom chunk partitioner to improve the performance
    of your parallel loops.
  prefs: []
  type: TYPE_NORMAL
- en: Using Thread Local Storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Computers are pretty good at counting. Sometimes we need to create loops that
    accumulate a running count of the occurrence of some piece data. How would we
    manage something like that when using `Parallel.For` or `Parallel.Foreach` loops?
    We could have any number of threads counting at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: What we need to accomplish this is **Thread Local Storage**. Thread Local Storage
    gives us the ability to store and retrieve states in each separate task that is
    created by a `Parallel.For` or `Parallel.ForEach` loop, and avoid the overhead
    of synchronizing accesses to a shared state variable.
  prefs: []
  type: TYPE_NORMAL
- en: Thread Local Storage is a programming method that uses static memory local to
    a thread. This is sometimes needed because normally all threads in a process share
    the same address space. In other words, data in a static or global variable is
    normally always located at the same memory location, when referred to from the
    same process. TLS variables are on the call and are local to threads, because
    each thread has its own stack.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we are going to see how we can use the thread-local variables
    to store the value of a word count in each thread created by `Parallel.ForEach`
    loop. After the loops finish, we will then write the final result only once to
    a shared variable.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ok, let''s take a look at how we can use the Thread Local Storage in our parallel
    loops. The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Start a new project using the **C# Console Application** project template and
    assign `ThreadLocalStorage` as the **Solution name**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add the following `using` directives to the top of your program class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, let's add some code to the `Main` method of the program class to use
    `WebClient` to download the text of a book, and split the words of the book into
    an array of strings. Also, we will create an `integer` variable which will hold
    our word count.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Next, let's create a parallel `ForEach` loop that takes an array of `String`,
    has an `Int32` thread-local variable, and passes its `Int32` result to an `Interlocked.Add`
    method.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let's finish up by displaying the result and waiting for user input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In Visual Studio 2012, press *F5* to run the project. You should see output
    similar to the following screenshot:![How to do it…](img/0225OT_03_09.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using a thread-local variable in a parallel `ForEach` loop means that we have
    to use the `Parallel.ForEach` method overload that takes two type parameters and
    two function parameters. Our first parameter is the type of the elements in our
    source (`String`). The second parameter specifies the type of our thread-local
    variable (`Int32`). The third parameter is a `Func<TSource, ParallelLoopState,
    TLocal, TLocal>` delegate that is invoked on each loop iteration. The fourth parameter
    is an `Action<T>` delegate that the method will invoke when all loops are finished.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: In the body of our loop, the loop passes our input parameters to our function
    delegate. The parameters are the current element, a `ParallelLoopState` variable
    and the thread local variable.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'After the loop completes, we return our thread-local variable and it gets passed
    to the `Action<T>` delegate where we add it to our shared state variable using
    `Interlocked.Add()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
