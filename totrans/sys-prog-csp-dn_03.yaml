- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The One with the Memory Games
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Efficient* *Memory Management*'
  prefs: []
  type: TYPE_NORMAL
- en: Performance is critical for system programming. We discussed this in the previous
    chapter and outlined why it is crucial. Memory consumption is just as important,
    however. The trouble is that better performance often leads to worse memory usage.
    And trying to optimize for memory usage often leads to worse performance. As in
    all things in life, it is a matter of compromising.
  prefs: []
  type: TYPE_NORMAL
- en: That being said, you might also encounter situations where you get both simultaneously
    – for instance, using the stack instead of the heap (or value types instead of
    reference types) results in faster code using less memory.
  prefs: []
  type: TYPE_NORMAL
- en: However, you usually don’t get one item for free while pursuing the other. You
    have to make informed decisions and the correct choices. And that is what this
    chapter is all about. I hope you remember most of it once we reach the end of
    this chapter!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of memory management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of the **garbage** **collector** (**GC**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to correctly use `IDisposable`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A long list of tips and tricks on how to save memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsafe code and pointers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Everything in this chapter can be done in a plain installation of C#. The only
    thing you might need extra if you’re following along is the NuGet `MessagePack`
    package. You can install that through Visual Studio Code or using the following
    CLI command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: An overview of the GC
  prefs: []
  type: TYPE_NORMAL
- en: .NET is a managed system. As discussed earlier, many issues developers had to
    deal with are now handled by the **Common Language Runtime** (**CLR**). The CLR
    abstracts away most of the tedious tasks a developer faces so that they can focus
    on functionality instead.
  prefs: []
  type: TYPE_NORMAL
- en: '**Memory management** is a tricky thing to do right, but also very important.
    Doing this wrong usually leads to memory leakage or instability in the software.
    Although no software should have that, system programming needs to avoid this.
    It might lead to unstable systems, making the whole computer unusable. Therefore,
    it is good that .NET developers don’t have to worry about this. The GC manages
    much of the memory and deals with those intricate details.'
  prefs: []
  type: TYPE_NORMAL
- en: Learning how the GC works is worth it so that your code is much more memory
    efficient. That means knowing how memory allocation functions in .NET.
  prefs: []
  type: TYPE_NORMAL
- en: We already discussed the difference between the stack and the heap. But just
    as a reminder, the stack is the short-term, smaller, but faster piece of memory
    that’s used for value types, while the heap is longer-term and much more extensive
    but also slower.
  prefs: []
  type: TYPE_NORMAL
- en: If you declare an integer in a code block, the CLR puts it on the stack. That
    memory is released at the end of that block’s scope. The heap works differently.
    Since items on the heap can live much longer, we need another way of handling
    this memory. That’s where GC comes in.
  prefs: []
  type: TYPE_NORMAL
- en: The GC process can run on a separate thread or in the main or user thread. For
    now, it is easiest to assume that the GC runs on a background thread. We will
    deal with the real-world situation a bit later.
  prefs: []
  type: TYPE_NORMAL
- en: GC and its generations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GC is a generational system. This means it works with generations. Does that
    help? I guess not. Okay, let me elaborate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Look at the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This snippet is not our most exciting piece of code, but we must start somewhere.
    The curly braces are necessary here, though.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding code snippet results in less activity than expected, especially
    if you come from a C or C++ background.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figures will help you make sense of what’s going on when we run
    the preceding code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure \uFEFF3.1: The empty, allocated heap](img/B20924_04_01.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: The empty, allocated heap'
  prefs: []
  type: TYPE_NORMAL
- en: During the program’s startup, the CLR allocates a continuous memory block. This
    block isn’t very big but big enough to house all the startup objects, plus anything
    else it can determine is needed. At that point, a pointer is created that points
    to the first area available for the project to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'On line 1, we begin a code block. Then, on line 2, we create an instance of
    the `Object` type and store that in the `a` variable. The memory of all data that
    belongs to that object lives on the heap. The runtime initializes, calculates
    how big that memory for `a` should be, and moves the allocation pointer up to
    the next available piece of memory in the block. A pointer is created on the stack
    (we call it `a`), and that pointer points to the memory block on the heap where
    its data lives:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure \uFEFF3.2: The heap after creating object a](img/B20924_04_02.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: The heap after creating object a'
  prefs: []
  type: TYPE_NORMAL
- en: 'On line 3, we end the scope of that variable. As we have learned, variables
    on the stack live only as long as the scope they belong to. Thus, `a` pointer
    is cleared, and its occupied memory is released. But on the heap, nothing happens.
    The data for `a` is still there, and the allocation pointer still points to the
    same place:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure \uFEFF3.3: The heap after a goes out of scope](img/B20924_04_03.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3: The heap after a goes out of scope'
  prefs: []
  type: TYPE_NORMAL
- en: Then, on line 4, we create a new scope block; on line 5, we create a new instance
    of `Object` and call it `b`. The whole circus starts all over again, but the data
    for `b` is now stored on top of `a`. Nobody knows about this; the data for `a`
    has become unreachable. But it is still there!
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure \uFEFF3.4: The heap when we allocate object b](img/B20924_04_04.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: The heap when we allocate object b'
  prefs: []
  type: TYPE_NORMAL
- en: 'And, of course, on line 6, the scope ends, so the stack variable, `b`, is removed
    again. Again, nothing happens to the heap:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B20924_04_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure3.5: The heap after b also goes out of scope'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, we don’t allocate or deallocate memory on the heap. Here, a
    pointer moves up whenever we need a new object. Moving a pointer is much faster
    than allocating and freeing memory. Allocating and deallocating, or freeing memory,
    are very expensive performance-wise. Avoiding these operations as much as possible
    is one of the reasons applications in .NET can run so fast.
  prefs: []
  type: TYPE_NORMAL
- en: However, you have probably seen a potential problem. What happens when we run
    out of space on the heap? The allocation pointer cannot move beyond the end of
    that block, so what happens then?
  prefs: []
  type: TYPE_NORMAL
- en: I’m glad you asked. That’s when the GC comes into play. The moment we run out
    of memory in the block we allocated initially, the GC will have a look at all
    the items in that block.
  prefs: []
  type: TYPE_NORMAL
- en: First, it goes through all objects in the heap and sees which still have active
    pointers pointing to them. In our example, we have none, but imagine that we have
    some other objects allocated that are still in scope.
  prefs: []
  type: TYPE_NORMAL
- en: The GC marks all those orphaned memory locations to know it can reclaim that
    memory. But what about the items that the GC cannot remove?
  prefs: []
  type: TYPE_NORMAL
- en: The answer to that question concerns the GC being “generational.” The CLR places
    each object in a particular part of the heap marked with a generation number.
    All new objects are in generation 0.
  prefs: []
  type: TYPE_NORMAL
- en: When the GC does its trick, it moves all objects still alive and in scope to
    the next generation. They are now in the generation 1 heap.
  prefs: []
  type: TYPE_NORMAL
- en: A bit more detail
  prefs: []
  type: TYPE_NORMAL
- en: 'In reality, there are only two heaps: one for all generations and one for the
    **large object heap** (**LOH**) (we’ll cover this in more detail later). The heap
    is divided into sections, one for each generation. However, we can think of each
    generation as having its own heap. Although this isn’t technically correct, thinking
    about the layout like this makes it a bit easier to understand what’s going on.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, all objects that survived the garbage collection process are in the generation
    1 heap; all objects that can no longer be reached are ready to be cleaned up.
    The GC clears out the memory and sets the allocation pointer back to the beginning
    of the heap. Now, the whole thing can start all over again.
  prefs: []
  type: TYPE_NORMAL
- en: That’s pretty neat, isn’t it? But there’s another problem. What happens if our
    generation 1 heap fills up?
  prefs: []
  type: TYPE_NORMAL
- en: In that case, we see a similar behavior. Everything in generation 1 that is
    no longer reachable (and that includes not being reachable from objects that are
    in other generations) is marked for deletion; the GC promotes all others to generation
    2.
  prefs: []
  type: TYPE_NORMAL
- en: Okay; let’s continue. What happens when generation 2 fills up? You would be
    wrong if you guessed that all reachable items move to generation 3\. There’s no
    generation 3\. If we fill up generation 2, the runtime allocates a new block that’s
    big enough to hold the current heap and sufficient to add more objects. Then,
    it moves all objects to the new heap and returns the old heap to the operating
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, the CLR asks for more memory for the heap and gets a slap on the
    wrist from the operating system. There’s no more memory available. In that case,
    we see the dreaded `OutOfMemoryException` error.
  prefs: []
  type: TYPE_NORMAL
- en: Handling OutOfM emoryException errors
  prefs: []
  type: TYPE_NORMAL
- en: The rule with handling exceptions is that you should only catch exceptions you
    know how to handle so that you can bring the system back into a stable state.
    With `OutOfMemory`, you have no way of doing that. The `OutOfMemoryException`
    error is one of the exceptions you’d better just let go. You can’t do much here
    to help.
  prefs: []
  type: TYPE_NORMAL
- en: The LOH
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can probably imagine that moving data in memory takes a lot of time and
    will hinder your performance. And that is correct: performance takes a huge hit
    when the GC runs.'
  prefs: []
  type: TYPE_NORMAL
- en: The GC is optimized to prevent that as much as possible, but memory operations
    are inherently expensive. Reallocating memory and moving the bytes around to all
    the different locations in particular take a lot of time to perform.
  prefs: []
  type: TYPE_NORMAL
- en: One of the things the CLR designers did to alleviate that problem a little bit
    was to declare a special heap called the LOH.
  prefs: []
  type: TYPE_NORMAL
- en: As the name implies, it is a heap for large objects. Currently, it deals with
    large objects – that is, objects bigger than 85,000 bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Objects of that size or bigger do not go to the regular heap. They are not subject
    to the generational behavior of the rest of the system.
  prefs: []
  type: TYPE_NORMAL
- en: The GC does help with keeping the LOH clean, but it runs far less frequently.
    Also, it doesn’t have generations for the LOH.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the GC clears objects from the LOH, the memory gets fragmented. What this
    means is that after a while, our block of memory looks a bit like Swiss cheese:
    there are holes everywhere. Areas of the memory that were once occupied by objects,
    which have been reclaimed, are now empty. After a while, the memory consists of
    valid objects and empty space. That means that although technically there is enough
    memory to allocate new objects, the system cannot find one continuous block of
    memory. If that happens, the GC will compact the LOH to make the memory contiguous
    again. But that only happens on very rare occasions. This way of working means
    the LOH is much slower than the other heaps.'
  prefs: []
  type: TYPE_NORMAL
- en: Also, the LOH doesn’t have a predefined size. It grows if needed. Again, this
    is a costly and slow operation.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that these large objects are out of your way in the usual heaps,
    so they don’t slow down the GC there.
  prefs: []
  type: TYPE_NORMAL
- en: Be mindful when creating large objects. They can bring your application to a
    grinding halt.
  prefs: []
  type: TYPE_NORMAL
- en: Finalizers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You may have been programming in .NET for over a decade and have never seen
    or used a finalizer. If that is the case, good job. We don’t need them. Well,
    we mostly don’t. There are some edge cases when we do; one is when you use the
    `IDisposable` pattern. This pattern has a whole section dedicated to it later
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: I want to show you what happens with the GC if you add a finalizer to your classes.
  prefs: []
  type: TYPE_NORMAL
- en: Fun fact!
  prefs: []
  type: TYPE_NORMAL
- en: 'Finalizers are often mistaken for destructors. That makes sense: if we have
    a constructor at the start of the lifetime of an object, why not have destructors
    at the end of that? C++ has them, after all. But we don’t. So, never call finalizers
    as destructors. They don’t destroy. They are pacifists who just want to clean
    up after them.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me briefly explain what a finalizer is. A **finalizer** is a method in
    a C# class that the runtime calls just before the object is cleaned up and removed.
    Just like a constructor, it has a special name. The following code block provides
    an example of a finalizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This class, `MyClass`, has both a constructor and a finalizer. The constructor
    has the name of the class, an access modifier (`public`, in this case), no return
    type (since it is not a method), and it might have some parameters. I have no
    parameters here, but I could have added them if needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'This constructor is called after the CLR has allocated the memory. You can
    think of it as being called as part of a “new” operation. You know when it is
    called: as soon as you create an instance, the CLR invokes the constructor. Simple
    enough, right?'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, an instance of a class can be created like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The finalizer is a bit different. It has no access modifier, no return type,
    and no parameters. It is the name of the class that is preceded by a tilde (`~`).
    You never call this code. The CLR does. You cannot set any parameters here.
  prefs: []
  type: TYPE_NORMAL
- en: The question is, of course, when is it called? And the answer is that we don’t
    know.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go back to the GC run. Generation 0 is getting full, so the GC must clean
    up. It looks for all objects that are out of scope to remove that memory. Let’s
    assume `myClass` is also out of scope.
  prefs: []
  type: TYPE_NORMAL
- en: I explained how the GC cleans up memory previously but left out two steps the
    GC also takes.
  prefs: []
  type: TYPE_NORMAL
- en: The first extra step is that after it finds all the locations in memory without
    active variables pointing to them, it looks for objects in those areas with a
    finalizer. If it finds one, it will place a pointer to that memory structure in
    a special queue called `FReachableQueue` (the F stands for finalizer). Then, it
    leaves it alone. The memory on the heap for that object is not reclaimed. It is
    also not moved to another generation. It just survives the cleaning up. Now, it
    just sits there once more.
  prefs: []
  type: TYPE_NORMAL
- en: Well, only until the GC runs again. That’s where the second step comes into
    play. Just before it cleans up the generation, it goes through `FReachableQueue`.
    For all objects in that queue, the CG calls the finalizers. Then, it removes the
    pointer from `FReachableQueue`, and the object is now finally ready to be garbage
    collected.
  prefs: []
  type: TYPE_NORMAL
- en: 'This has some profound implications:'
  prefs: []
  type: TYPE_NORMAL
- en: Objects with finalizers survive an extra round of garbage collection. They stick
    around longer, adding to the memory pressure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Objects with finalizers will have their finalizers called, but we have no idea
    when. We don’t know when the GC runs, after all.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving the pointers around is an extra step for the GC, making things even slower.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finalizers are a huge performance drain. They are better not used at all. Unless,
    of course, you use the `IDisposable` pattern to clean up. We’ll discuss this next.
  prefs: []
  type: TYPE_NORMAL
- en: IDisposable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: .NET is a managed environment. I have said that before, and I will mention it
    again. I keep repeating this because many think “managed” means “I don’t have
    to take care of stuff.” And as we have seen, that is simply not true. Yes, the
    CLR takes away a lot of the pain other developers suffer, but still, there’s a
    lot that you have to do yourself – especially if you are, like we are, writing
    system software.
  prefs: []
  type: TYPE_NORMAL
- en: One of the things the CLR does is clean up resources after us. Value types are
    on the stack and don’t need to be cleaned up. Reference types need to be cleaned
    up, but the GC takes care of that. However, as we have seen, cleaning up doesn’t
    always happen when we expect it to happen.
  prefs: []
  type: TYPE_NORMAL
- en: 'And there is another problem: the GC doesn’t clean up all used resources. The
    CLR only cleans up managed objects. Non-managed objects are yours to clean up
    and dispose of. Most examples that explain this behavior mention classes such
    as files and database connections. And to be honest, for most developers, those
    are the only real-life occurrences they will find when dealing with unmanaged
    resources. For us, this is a bit different. When writing system software, we,
    more often than usual, encounter things from low-level APIs, external hardware,
    interfacing with third-party software, attaching our code to external debuggers,
    and so on. We will see examples of these later in this book when we talk about
    the filesystem, networking, and interfacing with other hardware.'
  prefs: []
  type: TYPE_NORMAL
- en: So, you must understand how to clean up if the GC doesn’t do this for you. And
    that is where `IDisposable` comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `IDisposable` interface is very simple. This is what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Classes that implement this interface must ensure they have a `void` method
    without parameters called `Dispose`.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is an interface, so it doesn’t do anything. If you add it to a class, nothing
    happens. The CLR ignores it. This statement is important. I will repeat it: the
    CLR does nothing with classes that implement this interface.'
  prefs: []
  type: TYPE_NORMAL
- en: The `IDisposable` interface is more like a contract. We add it to classes that
    deal with unmanaged resources. Other developers see that interface in the class
    declaration and assume they must handle unmanaged resources.
  prefs: []
  type: TYPE_NORMAL
- en: And that is it.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how do we implement it? Let’s have a look at the following sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the constructor, we allocate a block of memory of `8 KB`. We store the pointer
    to that block in `ptr;`.
  prefs: []
  type: TYPE_NORMAL
- en: This block of memory is unmanaged. So, it is up to us to clean it up as well.
    We decided to do that in the finalizer. After all, it is guaranteed to run, so
    we are good here!
  prefs: []
  type: TYPE_NORMAL
- en: But we have already established that we aren’t sure when this will happen. And
    we don’t want a block of perfectly fine memory just being allocated until the
    GC decides to run (twice, since it is in a finalizer!). That’s just wasting memory
    and a lot of CPU cycles.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need another way to clean up. Let’s rewrite the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This code moves the cleanup code to a new method called `Cleanup`. If we want
    to use this class, we can simply create an instance and then make sure we always
    call `Cleanup()`. We can ensure that by using a `try-finally` block. Let’s do
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This is pretty simple, right? And to be honest, that is all there is to it
    for the `IDispose` interface. The most significant difference is that instead
    of having a method called `Cleanup()`, we have a method called `Dispose()`. And
    we mark our class with the correct interface, just as a courtesy to other developers.
    That way, they know they must clean up after using our class. Let’s do this using
    the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'And that’s all we need to do. In our calling code, we should call `Dispose()`
    instead of `Cleanup()` so that our code compiles. Let’s do that. I won’t show
    you that code here as I’m sure you know how to do that. However, I will show you
    the **Intermediate Language** (**IL**) code. As a reminder, IL is a language that
    is not quite C# but also not machine code. It sits in between. But it does give
    us a nice indication of what the compiler makes of our code before it turns it
    into actual machine code. The IL code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The IL code looks almost identical to our C# code. The critical part for us
    is on lines 15 through 23\. This is the `finally` block, containing the call to
    the `Dispose()` method. We now know that, no matter what, our resources will be
    cleaned up.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is brilliant. It’s so useful (and important) that the people behind the
    C# language gave us a new construct that helps us in doing so: they gave us the
    `using` statement.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using that statement means that `Dispose()` is called when you don’t need the
    resource anymore. That calling can be done in two ways: as a block statement or
    as an inline statement.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The block statement looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, `using` starts a new scoping block. The resource can be deallocated and
    cleaned up at the end of the scope.
  prefs: []
  type: TYPE_NORMAL
- en: 'The inline variant is even easier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The compiler will detect when `myClass` goes out of scope automatically. As
    soon as that happens, the typical workflow of the `using` statement resumes.
  prefs: []
  type: TYPE_NORMAL
- en: “But,” I can almost hear you say, “you just told me that the CLR does nothing
    with that IDisposable interface, yet here it understands what to do with it!”
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s a smart observation, but the knowledge about `IDisposable` is not in
    the CLR here. The compiler is the one who’s that smart. If we take the inline
    version of `using`, build our program, and inspect the IL, we’ll see the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: There are tiny differences between this code and the one where we called `Dispose()`
    ourselves, but these differences are not important. What’s important is that the
    compiler looked at our code and translated that into a `try-finally` block with
    the `Dispose()` method being called in that `finally` part. In other words, it
    does precisely the same thing.
  prefs: []
  type: TYPE_NORMAL
- en: So, `using` is just a convenient shorthand to instruct the compiler. If we had
    used `Cleanup()` instead of `Dispose()`, the compiler would not have understood
    it. But in the end, the code that gets run on the processor is the same. There’s
    no difference. There’s no magic involved in using `IDisposable()`.
  prefs: []
  type: TYPE_NORMAL
- en: The IDisposable pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Unfortunately, we aren’t done yet. The preceding code works. It cleans up and
    does this when we don’t need the resources anymore. But we rely on the user of
    our `ResourceUser` class to do the right thing: they have to use `Dispose()` or
    a `using` statement. If they don’t, we might have a memory leak. And don’t forget
    that the developer who fails to do that is probably you, 6 months after you have
    forgotten what you did.'
  prefs: []
  type: TYPE_NORMAL
- en: We need a better way to do this.
  prefs: []
  type: TYPE_NORMAL
- en: The `IDisposable` pattern is a recipe to make sure the resources get cleaned
    up, no matter what.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, what happens if the user of our class doesn’t call `Dispose()`,
    either directly or through the `using` statement? We need to clean up no matter
    what. Fortunately, we can do that. We have the finalizer. This always runs, although
    it might not run at the best time. But at least we can be sure that our resources
    get cleaned up eventually.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could copy the cleaning-up code to our finalizer. However, we don’t want
    to clean up twice. The preferred way to ensure our resources are disposed of is
    to write an overloaded version of `Dispose`. The whole implementation looks like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let’s see what happens here.
  prefs: []
  type: TYPE_NORMAL
- en: On line 3, we have the pointer to our unmanaged memory block. On line 4, I added
    a new field for another class that implements `IDisposable`. This field could
    be anything, such as a file or a database. What it is isn’t important here. All
    we need to know here is that it is a managed class we must clean up after use.
    On line 5, I added a Boolean that we use to see if the instance of this class
    has already been disposed of.
  prefs: []
  type: TYPE_NORMAL
- en: Lines 6 through 10 comprise the constructor’s body in which we allocate our
    8K memory block.
  prefs: []
  type: TYPE_NORMAL
- en: On line 11, we have our `Dispose` method. In that, I first call an overloaded
    method of `Dispose` and give it a `true` parameter. We use this parameter to keep
    track of who calls the overloaded `Dispose`. What this parameter does is something
    I explain in a couple of lines below, but before I do that, I have to explain
    the `GC.SuppressFinalize(this)` line. This is the magic line. It tells the GC
    not to move this instance to `FReachableQueue` when it’s doing its magic. Effectively,
    this removes the finalizer code from our class so that when the GC runs, it can
    clear away the memory on the stack immediately instead of waiting for another
    run.
  prefs: []
  type: TYPE_NORMAL
- en: After this, we have the finalizer. The finalizer only gets called if the class
    user forgets to call `Dispose` (or `using`) due to the `GC.SuppressFinalize(this)`
    call. This time, we call `Dispose(false)`.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss the parameter I added to the `Dispose()` method and that I promised
    to explain. On line 20, we have the actual code for the cleanup. By now, I hope
    that you understand what the `isDisposing` flag does. If that flag is set to `true`,
    we got here because the user of the class called `Dispose()`. If the flag is `false`,
    the developer didn’t use `Dispose()` and left it to the finalizer.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we first check if we didn’t already clean up by checking the `_isDisposed`
    variable on line 22.
  prefs: []
  type: TYPE_NORMAL
- en: Line 24 is essential. Our class has a managed resource that we need to clean
    up. But if we came from the finalizer, we have no idea when this code will run.
    It might be the case that the GC already cleaned up the memory allocated by `_someOtherDisposableClass`.
    There’s no way of knowing. If it had already been deallocated, calling `Dispose()`
    on it would result in a severe error and potentially crash our system. So, we
    must ensure we only call `Dispose` on that member if we are sure it is still around.
    If we got in this method via the finalizer, we cannot be sure. The order in which
    things are destroyed is non-deterministic. The only time we can be sure is when
    we got here through the call to `Dispose()`.
  prefs: []
  type: TYPE_NORMAL
- en: The memory block, however, is something else. That block is unmanaged, so we
    know that the GC didn’t clean it up already. It can’t. That’s why we call it unmanaged.
    So, we clean it up here on lines 28 through 32, no matter what.
  prefs: []
  type: TYPE_NORMAL
- en: 'And that is it. Things get a little bit more complicated if you have a derived
    class that stems from this class but isn’t so complex that you can’t figure it
    out yourself (hint: make `void Dispose(bool isDisposing)` protected virtual),'
  prefs: []
  type: TYPE_NORMAL
- en: The `IDisposable` interface is very important if you want your code to use memory
    as efficiently as possible. Here, you learned how to implement it properly and
    how to code in such a way as to remove memory leaks. Again, since we as system
    programmers are more likely to have to deal with unmanaged code compared to other
    developers, this is crucial knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: But knowing about `IDisposable` is not enough. There are many more tips and
    tricks I want to share with you about saving memory in your app.
  prefs: []
  type: TYPE_NORMAL
- en: Memory-saving tips and tricks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: System programmers need to be aware of the memory that’s used by the systems
    they write on. So, I want to share tips that will help you reduce **memory pressure**.
    Memory pressure is a fancy word to indicate how much memory is used compared to
    the amount of memory available. Again, some of these tips will make your system
    slower. As a system programmer, you must make informed choices and trade-offs
    between fast and memory-efficient code writing. Sometimes, you get lucky, and
    you get both. Other times, you must look at the options and pick the lesser of
    two evils. The following will cover specific things you can do to reduce memory
    pressure on your system.
  prefs: []
  type: TYPE_NORMAL
- en: '**Use value types over reference types**: Values types on the stack are usually
    smaller than reference types. The overhead of the pointer to the class and the
    pointers in the heap themselves can be a reason to move to value types, such as
    structs, instead of using reference types, such as classes. However, you’ll probably
    notice a performance hit if your structs get too big. Value types are copied by
    value when used as parameters, and copying big structures takes much longer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ObjectPool<T>` class holds a pool of objects you can use and return when you’re
    done with them. Instead of creating an instance of your class and waiting for
    the GC to clean it up, you can make a couple and store them in the pool. Initially,
    this might increase memory pressure, but depending on your scenario, it might
    save you some memory usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`List<T>`. The list does offer a lot of functionality. It can be very flexible
    but comes with a higher memory consumption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`List<T>`, sometimes, it is tempting to use it to store some items. The same
    applies to `Dictionary<TKey, TValue>`. But you don’t always need it. If you know
    what you want to store in your classes, it might be more efficient to declare
    simpler variables for this and use those instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I have seen people using `Dictionary<TKey, TValue>` to store a username and
    an email address. Using two fixed strings for that would have been much easier,
    faster, and memory efficient. Be a smart developer!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Use Span<T> and Memory <T>**: Assume you have an array of integers. Nothing
    special, just something like this:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Arrays are reference types, so this allocates a memory block on the heap. There’s
    nothing wrong with that. You want to split the array into two parts for some reason.
    There are multiple ways of doing that, but the simplest (although not the fastest)
    is using Linq, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have three arrays on the heap. One is the original, and the others are
    the two new ones. That uses a lot of memory. That’s without me even mentioning
    the performance hit we get by copying all that data.
  prefs: []
  type: TYPE_NORMAL
- en: Maybe you need a copy. If so, then this is a good approach. However, you should
    use `Span<T>` if you just need to split. This class is a view on the memory you
    give it. It isn’t copying; it’s just a window on the original data.
  prefs: []
  type: TYPE_NORMAL
- en: 'That code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This code sample doesn’t copy the data or allocate a new array. It just gives
    you a view of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, if the original array is garbage collected, the span points to invalid
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: Here, `Memory<T>` is more or less the same, but it’s better when you’re using
    async operations. Next to that, a span always lives on the stack. So, you cannot
    have a span as a field in a class (remember, classes are reference types, so all
    their data is stored on the heap). In contrast, `Memory<T>` can be used on the
    heap so that you can use them as fields in classes.
  prefs: []
  type: TYPE_NORMAL
- en: '**Avoid boxing**: Value types are fast and memory-efficient, so long as they
    stay value types. As we discussed previously, value types suddenly have the annoying
    habit of turning into reference types. We call this process **boxing**. Boxing
    takes a lot more memory than the simple value type. So, try to be aware of those
    situations and avoid them if possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use lazy initialization**: If you create an instance of a complicated class,
    you might not need to initialize all fields in the constructor. Sometimes, it’s
    better to do that only when needed. This way of working is called **lazy initialization**:
    try to postpone that initialization for as long as possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`System.IO.Compression`. This contains many classes that help you compress
    and deflate your data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unload unnecessary data**: You could choose to remove data you don’t need
    lying around all the time. Then, when you need it, you can reload it on demand.
    The overhead of doing this might be worth it if you have large datasets and don’t
    always need them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WeakReference<T>` reference. This means you tell the GC to remove the object
    if needed. Let me show you what I mean:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: First, we create an instance of an object, called `myObject`. Then, we get a
    weak reference to it. Let’s assume that later in our code, we need `myObject`
    again. First, we ask `WeakReference` if the object is still available or if the
    GC has collected it. If it is available, we can use it. Otherwise, we recreate
    it and store the new pointer in `WeakReference`. Pretty neat.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Compact object representations**: Sometimes, you can save some memory by
    smartly combining data into other data structures. Let me show you. We can express
    three states a customer can have in the following manner:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, `bool` is usually internally represented by a byte. So, this takes 3 bytes.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We could rewrite this as follows. First, we create a new `enum` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The notation I have used to assign the values reminds me where I am in the
    sequence: by doing a left shift, I can easily number the items (`0`, `1`, and
    `2`).'
  prefs: []
  type: TYPE_NORMAL
- en: Shifting bits
  prefs: []
  type: TYPE_NORMAL
- en: In system programming, we work with bits and bytes a lot. So, you should be
    aware of this kind of notation.
  prefs: []
  type: TYPE_NORMAL
- en: The `<<` operator takes all the bits in a byte and moves them one step to the
    left, effectively multiplying the value by 2\. So, `1 << 0` moves nothing, `1
    << 1` moves all bits 1 step and results in the value 2, while `1 << 2` moves the
    bits 2 steps, resulting in 4\. In binary, the results are `00000001`, `00000010`,
    and `00000100`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can set a variable as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We have the same information as we had in the first example, but this time,
    we’re only using one byte. That’s a 66% reduction in memory usage!
  prefs: []
  type: TYPE_NORMAL
- en: '`null` allows them to be cleaned up. Since the CLR stores large objects on
    the much less frequently cleaned-up LOH, setting them to `null` enables the GC
    to clean them up there.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consider using static classes**:Instance classes have many pointers going
    back and forth between the members and their data. These pointers and the member
    data can take up extra memory. Using static classes eliminates this overhead.
    The savings can be pretty significant.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this point, I want to reiterate that for system developers, it is very important
    to be as memory-efficient as we can. The tips and tricks I just shared with you
    should be part of your development style. Saving memory frees up time from the
    GC and it makes your programs faster to load and usually also to execute. It helps
    in getting a better experience for the user. Of course, these tips and tricks
    can be applied to all sorts of C# programming. Every program could use better
    memory management. The same thing, however, cannot be said about unsafe code and
    pointers. Those are topics that most developers will rarely encounter. However,
    we, as system programmers, probably cannot avoid them. So, I think we should spend
    some time looking at them.
  prefs: []
  type: TYPE_NORMAL
- en: Unsafe code and pointers in C#
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you’re concerned about the memory, you could take over from the CLR and the
    GC and do it all yourself. I wouldn’t recommend this, but sometimes, you have
    no choice. Although the compiler, the CLR, and the GC do amazing things, they
    cannot always predict what you are trying to achieve or what your limitations
    are. Especially for system developers, this can sometimes hinder you in achieving
    your goals. In those cases, you might have to resort to managing memory yourself.
    I think an example is in order here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with a simple class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The `MessagePackObject` and `Key` attributes come from the `MessagePack` NuGet
    library.
  prefs: []
  type: TYPE_NORMAL
- en: The `MessagePack` library is a tool that enables you to serialize and deserialize
    instances of classes into a binary representation. Another popular serializer
    format is JSON, which is far less efficient regarding memory. That is why we’re
    using binary formatting here.
  prefs: []
  type: TYPE_NORMAL
- en: 'I have written two methods: one to serialize and one to deserialize. The serializer
    comes first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This is pretty simple. We get an object and give it to the `Serialize` method
    of the `MessagePackSerializer` static class. That will return a `byte[]` value
    that we return to the caller of this method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, this also needs deserialization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This method is slightly more complicated: we get a pointer to a piece of memory
    and the length of our data. We create a `byte[]` value of the correct size. Then,
    we copy the memory from the heap into the byte array so that we can deserialize
    it with the `MessagePackSerializer` class. The object we get is then returned.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use these methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Here, we create an instance of `SimpleClass` and give it some data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we serialize that object using our new `SerializeToByteArray` method
    we discussed. This gives us a `byte[]` value with the raw data. Then, we allocate
    the memory on the heap where we want to store that data. We copy the data. Then,
    we can discard the `simpleClass` instance: it can be garbage collected.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that the GC will never clean up the memory we just allocated. Our data
    is stored in our memory.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to use it, we need to deserialize it again, which is something we
    can do by calling `DeserializeFromByteArray`. We give the pointer to the allocated
    memory and the size we occupy.
  prefs: []
  type: TYPE_NORMAL
- en: And, of course, we need to free the memory when we’re done with it. The GC doesn’t
    do that for us. We are responsible for this.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we only used 29 bytes to store the data, which isn’t a lot.
    We can allocate that memory if needed and deallocate it when we decide. This is
    a very fast and efficient way of handling the memory of our system.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs: []
  type: TYPE_NORMAL
- en: Don’t use `BinaryFormatter` to do this. Although using `BinaryFormatter` is
    much simpler, it is inherently unsafe. You are better off using `MessagePack`,
    as I showed here, or using a JSON-based serializer and deserializer. For more
    information, please read [https://aka.ms/binaryformatter](https://aka.ms/binaryformatter).
  prefs: []
  type: TYPE_NORMAL
- en: We can go a bit further with this. Using pointer arithmetic, we can manually
    copy all the data into our memory block. Since pointer arithmetic is unsafe, we
    need to tell the compiler we want to do this by using the `unsafe` keyword and
    setting the project options to `allow unsafe`, as we discussed at the end of the
    previous chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The serialization remains the same. Deserialization is simpler. The code to
    store the bits in our memory is slightly different. The whole code, however, is
    faster and more memory efficient. Here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: We start similarly by using `MessagePack` to get a binary representation of
    our object. But instead of using `Marshal.Copy()`, we copy the bytes ourselves.
    We have a pointer to the beginning of the data; we take the first byte, copy it
    into the memory block we allocated, increase the pointer, and repeat this until
    we copy the whole thing.
  prefs: []
  type: TYPE_NORMAL
- en: Deserialization works in the same way. We get the pointer to the block of memory
    we allocated, which now contains our data. We read the first byte, copy it into
    the array, and repeat until we finish.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we deserialize it by calling the `MessagePackSerializer.Deserialize()`
    method, which takes a type, and we give it the array with all bytes.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this is a speedy and efficient way to handle memory, but it does come
    with many risks. Remember, making a small mistake will mess up your day.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unsafe code and using pointers in your code can speed things up a lot. But
    I want to make sure you understand the implications: you’re taking over all control
    from the CLR. You’re responsible for making sure your program runs fine and safe.
    Make sure you know what you’re doing when going this route. If you do this, there
    are a lot of benefits when it comes to speed and memory efficiency!'
  prefs: []
  type: TYPE_NORMAL
- en: Next steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I hope you remember most of the things we discussed, but just in case you forgot,
    we will go through the most essential points again.
  prefs: []
  type: TYPE_NORMAL
- en: First, we discussed how the CLR and GC work together to remove the pain of memory
    management. We looked into how the GC works, what the generations mean, and what
    the LOH does.
  prefs: []
  type: TYPE_NORMAL
- en: We also talked about finalizers and why they can kill your performance. We also
    saw that they have a place when you use the `IDisposable` pattern (so long as
    you don’t forget to call `GC.SupressFinalize(this)` to remove the finalizer if
    it is unnecessary).
  prefs: []
  type: TYPE_NORMAL
- en: Then, I shared a couple of techniques you can use to optimize your memory usage
    if you need the least amount of memory usage in your system.
  prefs: []
  type: TYPE_NORMAL
- en: I want to reiterate a crucial point about memory optimization. In 99 of 100
    cases, the CLR and the GC do an outstanding job. Trying to outsmart them doesn’t
    always result in better systems. The team behind these tools is good at what they
    do, and they use all the tricks in the book (and some that are not in that book!)
    to help you reduce memory pressure.
  prefs: []
  type: TYPE_NORMAL
- en: As a system programmer, you will run into situations where the GC and the CLR
    are just not doing a good enough job, and that is when the topics discussed here
    can help. But please be very careful. Managing memory can lead to weird and even
    catastrophic results when done wrong.
  prefs: []
  type: TYPE_NORMAL
- en: You should test and benchmark your code before tweaking memory usage. But if
    you follow my tips and advice, you can get exceptional results! However, things
    get much more complicated once you have multiple threads in your system. We need
    to talk about threads. A lot. And that is precisely what we are going to do in
    the next chapter!
  prefs: []
  type: TYPE_NORMAL
