["```cs\n    namespace HotdogOrNot.ImageClassifier;\n    internal sealed class ClassifierOutput\n    {\n        ClassifierOutput() { }\n    }\n    ```", "```cs\n    namespace HotdogOrNot.ImageClassifier;\n    public interface IClassifier\n    {\n        ClassifierOutput Classify(byte[] bytes);\n    }\n    ```", "```cs\n    namespace HotdogOrNot.ImageClassifier;\n    internal class MLNetClassifier : Iclassifier\n    {\n        public MLNetClassifier(byte[] model)\n        {\n            // Initialize Model here\n        }\n        public ClassifierOutput Classify(byte[] imageBytes)\n        {\n            // Code will be added here\n        }\n    }\n    ```", "```cs\n        readonly InferenceSession session;\n        readonly bool isBgr;\n        readonly bool isRange255;\n        readonly string inputName;\n        readonly int inputSize;\n    ```", "```cs\n            Session = new InferenceSession(model);\n            isBgr = session.ModelMetadata.CustomMetadataMap[\"Image.BitmapPixelFormat\"] == \"Bgr8\";\n            isRange255 = session.ModelMetadata.CustomMetadataMap[\"Image.NominalPixelRange\"] == \"NominalRange_0_255\";\n            inputName = session.InputMetadata.Keys.First();\n            inputSize = session.InputMetadata[inputName].Dimensions[2];\n    ```", "```cs\n    using Microsoft.ML.OnnxRuntime;\n    namespace HotdogOrNot.ImageClassifier;\n    internal class MLNetClassifier : Iclassifier\n    {\n        readonly InferenceSession session;\n        readonly bool isBgr;\n        readonly bool isRange255;\n        readonly string inputName;\n        readonly int inputSize;\n        public MLNetClassifier(byte[] model)\n        {\n            session = new InferenceSession(model);\n            isBgr = session.ModelMetadata.CustomMetadataMap[\"Image.BitmapPixelFormat\"] == \"Bgr8\";\n            isRange255 = session.ModelMetadata.CustomMetadataMap[\"Image.NominalPixelRange\"] == \"NominalRange_0_255\";\n            inputName = session.InputMetadata.Keys.First();\n            inputSize = session.InputMetadata[inputName].Dimensions[2];\n        }\n        public ClassifierOutput Classify(byte[] imageBytes)\n        {\n            // Code will be added here\n        }\n    }\n    ```", "```cs\n    static (Tensor<float>, byte[] resizedImage) LoadInputTensor(byte[] imageBytes, int imageSize, bool isBgr, bool isRange255)\n        {\n        }\n    ```", "```cs\n        {\n            var input = new DenseTensor<float>(new[] { 1, 3, imageSize, imageSize });\n            byte[] pixelBytes;\n            // Add code here\n            return (input, pixelBytes);\n        }\n    ```", "```cs\n    using (var image = Image.Load<Rgb24>(imageBytes))\n        {\n            image.Mutate(x => x.Resize(imageSize, imageSize));\n            pixelBytes = new byte[image.Width * image.Height * Unsafe.SizeOf<Rgba32>()];\n            image.ProcessPixelRows(source =>\n            {\n                // Add Code here\n            });\n        }\n    ```", "```cs\n    using Image = SixLabors.ImageSharp.Image;\n    ```", "```cs\n    using Microsoft.ML.OnnxRuntime;\n    using SixLabors.ImageSharp.Formats.Png\n    using Microsoft.ML.OnnxRuntime.Tensors;\n    using Image = SixLabors.ImageSharp.Image;\n    ```", "```cs\n    image.ProcessPixelRows(source =>\n    {\n        for (int y = 0; y < image.Height; y++)\n        {\n            Span<Rgb24> pixelSpan = source.GetRowSpan(y);\n            for (int x = 0; x < image.Width; x++)\n            {\n                if (isBgr)\n                {\n                    input[0, 0, y, x] = pixelSpan[x].B;\n                    input[0, 1, y, x] = pixelSpan[x].G;\n                    input[0, 2, y, x] = pixelSpan[x].R;\n                }\n                else\n                {\n                    input[0, 0, y, x] = pixelSpan[x].R;\n                    input[0, 1, y, x] = pixelSpan[x].G;\n                    input[0, 2, y, x] = pixelSpan[x].B;\n                }\n                if (!isRange255)\n                {\n                    input[0, 0, y, x] = input[0, 0, y, x] / 255;\n                    input[0, 1, y, x] = input[0, 1, y, x] / 255;\n                    input[0, 2, y, x] = input[0, 2, y, x] / 255;\n                 }\n             }\n         }\n    });\n    ```", "```cs\n                });\n                var outStream = new MemoryStream();\n                image.Save(outStream, new PngEncoder());\n                pixelBytes = outStream.ToArray();\n            }\n            return (input, pixelBytes);\n    ```", "```cs\n        public ClassifierOutput Classify(byte[] imageBytes)\n        {\n            (Tensor<float> tensor, byte[] resizedImage) = LoadInputTensor(imageBytes, inputSize, isBgr, isRange255);\n        }\n    ```", "```cs\n        public ClassifierOutput Classify(byte[] imageBytes)\n        {\n            (Tensor<float> tensor, byte[] resizedImage) = LoadInputTensor(imageBytes, inputSize, isBgr, isRange255);\n            var resultsCollection = session.Run(new List<NamedOnnxValue>\n            {\n                        NamedOnnxValue.CreateFromTensor<float>(inputName, tensor)\n             });\n        }\n    ```", "```cs\n        public ClassifierOutput Classify(byte[] imageBytes)\n        {\n            (Tensor<float> tensor, byte[] resizedImage) = LoadInputTensor(imageBytes, inputSize, isBgr, isRange255);\n            var resultsCollection = session.Run(new List<NamedOnnxValue>\n                    {\n                        NamedOnnxValue.CreateFromTensor<float>(inputName, tensor)\n                    });\n            var topLabel = resultsCollection\n                ?.FirstOrDefault(i => i.Name == \"classLabel\")\n                ?.AsTensor<string>()\n                ?.First();\n        }\n    ```", "```cs\n        public ClassifierOutput Classify(byte[] imageBytes)\n        {\n            (Tensor<float> tensor, byte[] resizedImage) = LoadInputTensor(imageBytes, inputSize, isBgr, isRange255);\n            var resultsCollection = session.Run(new List<NamedOnnxValue>\n                    {\n                        NamedOnnxValue.CreateFromTensor<float>(inputName, tensor)\n                    });\n            var topLabel = resultsCollection\n                ?.FirstOrDefault(i => i.Name == \"classLabel\")\n                ?.AsTensor<string>()\n                ?.First();\n            var labelScores = resultsCollection\n                ?.FirstOrDefault(i => i.Name == \"loss\")\n                ?.AsEnumerable<NamedOnnxValue>()\n                ?.First()\n                ?.AsDictionary<string, float>();\n        }\n    ```", "```cs\n        public ClassifierOutput Classify(byte[] imageBytes)\n        {\n            (Tensor<float> tensor, byte[] resizedImage) = LoadInputTensor(imageBytes, inputSize, isBgr, isRange255);\n            var resultsCollection = session.Run(new List<NamedOnnxValue>\n                    {\n                        NamedOnnxValue.CreateFromTensor<float>(inputName, tensor)\n                    });\n            var topLabel = resultsCollection\n                ?.FirstOrDefault(i => i.Name == \"classLabel\")\n                ?.AsTensor<string>()\n                ?.First();\n            var labelScores = resultsCollection\n                ?.FirstOrDefault(i => i.Name == \"loss\")\n                ?.AsEnumerable<NamedOnnxValue>()\n                ?.First()\n                ?.AsDictionary<string, float>();\n            return ClassifierOutput.Create(topLabel, labelScores, resizedImage);\n        }\n    ```", "```cs\n    internal sealed class ClassifierOutput\n    {\n        public string TopResultLabel { get; private set; }\n        public float TopResultScore { get; private set; }\n        public IDictionary<string, float> LabelScores { get; private set; }\n        public byte[] Image { get; private set; }\n        ClassifierOutput() { }\n        public static ClassifierOutput Create(string topLabel, IDictionary<string, float> labelScores, byte[] image)\n        {\n            var topLabelValue = topLabel ?? throw new ArgumentException(nameof(topLabel));\n            var labelScoresValue = labelScores ?? throw new ArgumentException(nameof(labelScores));\n            return new ClassifierOutput\n            {\n                TopResultLabel = topLabelValue,\n                TopResultScore = labelScoresValue.First(i => i.Key == topLabelValue).Value,\n                LabelScores = labelScoresValue,\n                Image = image,\n            };\n        }\n    }\n    ```", "```cs\n    namespace HotdogOrNot;\n    internal partial class AppPermissions\n    {\n    }\n    ```", "```cs\n        public static async Task<PermissionStatus> CheckRequiredPermission<TPermission>() where TPermission : Permissions.BasePermission, new() => await Permissions.CheckStatusAsync<TPermission>();\n    ```", "```cs\n        public static async Task<PermissionStatus> CheckAndRequestRequiredPermission() <TPermission>() where TPermission : Permissions.BasePermission, new()\n        {\n            PermissionStatus status = await Permissions.CheckStatusAsync< TPermission >();\n            if (status == PermissionStatus.Granted)\n                return status;\n            if (status == PermissionStatus.Denied && DeviceInfo.Platform == DevicePlatform.iOS)\n            {\n                // Prompt the user to turn on in settings\n                // On iOS once a permission has been denied it may not be requested again from the application\n                await App.Current.MainPage.DisplayAlert(\"Required App Permissions\", \"Please enable all permissions in Settings for this App, it is useless without them.\", \"Ok\");\n            }\n            if (Permissions.ShouldShowRationale< TPermission >())\n            {\n                // Prompt the user with additional information as to why the permission is needed\n                await App.Current.MainPage.DisplayAlert(\"Required App Permissions\", \"This app uses photos, without these permissions it is useless.\", \"Ok\");\n            }\n            status = await MainThread.InvokeOnMainThreadAsync(Permissions.RequestAsync<TPermission>);\n            return status;\n        }\n    }\n    ```", "```cs\nusing Android.App;\nusing Android.Runtime;\n// Needed for Picking photo/video\n[assembly: UsesPermission(Android.Manifest.Permission.ReadExternalStorage, MaxSdkVersion = 32)]\n[assembly: UsesPermission(Android.Manifest.Permission.ReadMediaImages)]\n// Needed for Taking photo/video\n[assembly: UsesPermission(Android.Manifest.Permission.Camera)]\nIMAGE_CAPTURE intent as follows in the AndroidManifest.xml file:\n\n```", "```cs\n\n For iOS and Mac Catalyst, the only thing we need to do is add the following four usage descriptions to the `info.plist` file in the `platform/ios` and `platform/maccatalyst` folders:\n\n```", "```cs\n\n For Windows, we need to add the following highlighted code to the `Capabilities` section of the `package.appxmanifest` file in the `platforms/windows` folder:\n\n```", "```cs\n\n Now that we have declared the permissions we need for each platform, we can implement the remaining functionality to take a photo or pick an existing image.\nBuilding the first view\nThe first view in this app will be a simple view with two buttons. One button will be to start the camera so that users can take a photo of something to determine whether it is a hot dog. The other button will be to pick a photo from the photo library of the device. We will continue to use the MVVM pattern in this chapter, so we will split the view into two classes, `MainView` for the UI visible to the user and `MainViewModel` for the actual implementation.\nBuilding the ViewModel class\nWe will start by creating the `MainViewModel` class, which will handle what will happen when a user taps one of the buttons. Let’s set this up by going through the following steps:\n\n1.  Create a new folder called `ViewModels`.\n2.  Add a NuGet reference to `CommunityToolkit.Mvvm`; we use `CommunityToolkit.Mvvm` to implement the `INotifyPropertyChanged` interface and commands, as we did in other chapters.\n3.  Create a new partial class called `MainViewModel` in the `ViewModels` folder, using `ObservableObject` from the `CommunityToolkit.Mvvm.ComponentModel` namespace as a base class.\n4.  Create a private field of the `IClassifier` type and call it `classifier`, as shown in the following code block:\n\n    ```", "```cs\n\nInitializing the ONNX model requires the use of asynchronous methods, so we need to handle them carefully, since we will be calling them from the constructor and the button handlers. The following steps will create the model initializer:\n\n1.  Create an `InitTask` property that is of the `Task` type.\n2.  Use a property initializer to set it to a new `Task`, using `Task.Run`.\n3.  Initialize the model from the raw resources of the .NET MAUI app. The method should look like the following code:\n\n    ```", "```cs\n\n    The `InitTask` property holds a reference to `Task` that does the following:\n\n    *   Loads the `hotdog-or-not.onnx` file into `Stream`\n    *   Copies the bytes from the original stream to an array of bytes so that the original stream can be closed and any native resources, such as file handles, can be released.\n    *   Creates and returns a new instance of the `MLNetClassifier` class using the loaded model. 4.  To ensure that `InitTask` will only run successfully once, add the following highlighted code:\n\n    ```", "```cs\n\n    In `InitAsync`, the initialization task is captured by a field only if the field is `null` or its value has faulted. This ensures that we only run the initialization successfully once. The value of the field is then returned to the caller, which, in this case, is the constructor. Unwinding this, the constructor calls `InitAsync` and throws away the return value. `InitAsync`, meanwhile, captures the value returned by the `InitTask` property, which is `Task` that has already been queued for execution. Since `InitAsync` and `InitTask` and their closure are all asynchronous, they complete sometime after the constructor completes.\n\nNow that we have initialized the `hotdog-or-not` ONNX model, we can now implement the two buttons, one that takes a photo and another that allows the user to pick a photo from their device storage. Let’s start by implementing a couple of helper methods to use in both use cases.\nThe first helper method is used to convert `FileResult` to `byte[]`. To implement `ConvertPhotoToBytes`, follow these steps:\n\n1.  Open the `MainViewModel.cs` file.\n2.  Add a new method named `ConvertPhotoToBytes`, which takes `FileResult` as a parameter and returns `byte []`. Since the method is `async`, you’ll need to return `Task` and use the `async` modifier.\n3.  In the method, check whether `FileResult` is `null` and that it returns an empty array.\n4.  Next, open a stream from `FileResult` using the `OpenStreamAsync` method.\n5.  Create a new variable of the `MemoryStream` type and initialize it using the default constructor.\n6.  Use the `Copy` method to copy `stream` to `MemoryStream`.\n7.  Finally, return `MemoryStream` as `byte[]`; your method should look like the following:\n\n    ```", "```cs\n\nThe other helper method we will need is to use our classification model to get the results of a photo and return the results. We will need a new type to return the results. Follow these steps to implement the new class:\n\n1.  Create a new folder named `Models` in the project.\n2.  In the `Models` folder, create a new class, `Result`, in a file named `Result.cs`.\n3.  Add a public property, `IsHotdog`, as `bool`.\n4.  Add a public property, `Confidence`, as `float`.\n5.  Add a public property, `PhotoBytes`, as `byte[]`; the class should now look like the following:\n\n    ```", "```cs\n\n    The `IsHotdog` property is used to capture whether the label returned from the model is “hotdog.” `Confidence` is a score of how sure the model is that this is a hotdog or not. Finally, since we transform the image prior to processing, we store the transformed image in the `PhotoBytes` property.\n\nNow, we can implement the method that will run and process the classification result, by following these steps:\n\n1.  Open the `MainViewModel.cs` file.\n2.  In the `MainViewModel` class, add a new field, `isClassifying`, with a `bool` type.\n3.  Add the `ObservableAttribute` attribute to the field; it should look like the following:\n\n    ```", "```cs\n\n     4.  Add a new method to the `MainViewModel` class, named `RunClassificationAsync`. The method will accept a `byte[]` parameter and return `Result`, wrapped in `Task`, since it is `async`:\n\n    ```", "```cs\n\n     5.  In the method, the first thing we do is set the `IsClassifying` property to `true`; this will be used to disable the buttons later in the chapter.\n6.  Add a `try..catch..finally` statement.\n7.  Inside the `try` statement, ensure the model is initialized by calling `InitAsync`.\n8.  Then, call `Classify` on the `classifier` field passing `byte[]`, representing the image as a parameter and storing the result.\n9.  The last statement in the `try` statement block is to return a new `Result`, setting `IsHotdog` to `true` only if the classification result’s `TopResultLabel` property is “hotdog,” `Confidence` is set to the classification result’s `TopResultScore` property, and `PhotoBytes` is set to the classification result’s `Image` property. The `try` portion should look like the following:\n\n    ```", "```cs\n\n     10.  Now, in the `catch` statement block, return a new `Result`, setting the `IsHotdog` property to `false`, `Confidence` to `0.0f`, and the `PhotoBytes` property to the bytes passed into the method. The `catch` block should look like the following:\n\n    ```", "```cs\n\n     11.  Lastly, for the `finally` block, we want to set the `IsClassiying` property back to `false`; however, we will need to do this on the main UI thread using the `MainThread.BeginInvokeOnMainThread` method from .NET MAUI, as shown in the following code:\n\n    ```", "```cs\n\nNow that we have written the helper methods, we can create two methods, one to handle capturing an image from the camera and another to pick a photo from user storage. We will start with the camera capture method.\nLet’s set this up by following these steps:\n\n1.  Open the `MainViewModel.cs` file.\n2.  Create a public async void method called `TakePhoto`.\n3.  Add the `RelayCommand` attribute to make the method bindable.\n4.  Add an `if` statement to check whether the `MediaPicker.Default.IsCaptureSupported` parameter is `true`.\n5.  In the `true` statement block of `if`, get the status of the `Camera` permission using the `CheckAndRequestPermission` method.\n6.  If the status is `Granted`, then use `CheckAndRequestMethod` again to check the `WriteExternalStorage` permission.\n7.  If the status is `Granted`, use `MediaPicker` to capture a photo using the `Capture``PhotoAsync` method.\n8.  Call a method named `ConvertPhotoToBytes`, passing in the file returned from `MediaPicker`.\n9.  Pass the photo bytes to the `RunClassificationAsync` method.\n10.  Finally, we will dynamically navigate to the `Result` view, which we will create in the next section, passing the result from `RunClassificationAsync` as a parameter. We do this by using `Shell.Current.GotoAsync` and ensuring that the app uses the main thread to do so, as shown in the following code block:\n\n    ```", "```cs\n\n`Shell.Current.GotoAsync` takes two parameters – the first is the route that `Shell` is to navigate to, and the second is a dictionary of key-value pairs to send to the destination view. Later in this chapter, we will see how to configure a route to a view without using XAML and, when we create the `Result` view, how to access the parameters passed to it.\nWe will now create the `PickPhoto` method to allow a user to use an image from their device. Use the following steps to create the method:\n\n1.  Create a public async void method called `PickPhoto`.\n2.  Add the `RelayCommand` attribute to make the method bindable.\n3.  Grant the status of the `Photos` permission using the `CheckAndRequestPermission` method.\n4.  If the status is `Granted`, use `MediaPicker` to capture a photo using the `Pick``PhotoAsync` method.\n5.  Call a method named `ConvertPhotoToBytes`, passing in the file returned from `MediaPicker`.\n6.  Pass the photo bytes to the `RunClassificationAsync` method.\n7.  Finally, we will dynamically navigate to the `Result` view, which we will create in the next section, passing the result from `RunClassificationAsync` as a parameter. We will do this by using `Shell.Current.GotoAsync` and ensuring that the app uses the main thread to do so, as shown in the following code block:\n\n    ```", "```cs\n\nWhen a user clicks on a button, the classification could take a noticeable amount of time. To prevent the user from clicking the button again because they think it’s not working, we will disable the buttons until the operation completes. The `IsClassifying` property is already set; we just need to use that value to restrict `RelayCommands`, by following these steps:\n\n1.  Add a new method that returns a Boolean named `CanExecuteClassification`, and return the inverse of the `IsClassifying` property, as shown in the following code:\n\n    ```", "```cs\n\n     2.  Update the `RelayCommand` attribute for the `TakePhoto` method, as highlighted here:\n\n    ```", "```cs\n\n     3.  Update the `RelayCommand` attribute for the `PickPhoto` method, as highlighted here:\n\n    ```", "```cs\n\nNow that ViewModel for the main page is complete, we can build View for the main page.\nBuilding the view\nNow, once we have created the `MainViewModel` class, it is time to create the code for the `MainView` view:\n\n1.  Create a new folder called `Views`.\n2.  Add a new `MainView`.\n3.  Set the `Title` property of `ContentPage` as `Hotdog or` `Not hotdog`.\n4.  Add `HorizontalStackLayout` to the page, and set its `VerticalOptions` property to `Center` and its `HorizontalOptions` property to `CenterAndExpand`.\n5.  Add `Button` to the `HorizontalStackLayout`, with the text `Take Photo`. For the `Command` property, add a binding to the `TakePhoto` property in the `MainViewModel` class.\n6.  Add `Button` to `HorizontalStackLayout`, with the text `Pick Photo`. For the `Command` property, add a binding to the `PickPhoto` property in the `MainViewModel` class, as shown in the following code block:\n\n    ```", "```cs\n\nIn the code-behind `MainView.xaml.cs` file, we will set the binding context of the view by following these steps:\n\n1.  Add `MainViewModel` as a parameter of the constructor.\n2.  After the `InitialComponent` method call, set the `BindingContext` property of the view to the `MainViewModel` parameter.\n3.  Use the `SetBackButtonTitle` static method on the `NavigationPage` class so that an arrow to navigate back to this view will be shown in the navigation bar on the result view, as shown in the following code block:\n\n    ```", "```cs\n\nBuilding the result view\nThe last thing we need to do in this project is to create the result view. This view will show the input photo and the classification of a hot dog or not.\nBuilding the ResultViewModel class\nBefore we create the view, we will create a `ResultViewModel` class that will handle all the logic for the view, by following these steps:\n\n1.  Create a `partial` class called `ResultViewModel` in `ViewModels`.\n2.  Add `ObservableObject` as a base class to the `ResultViewModel` class.\n3.  Create a `private` field of the `string` type, called `title`. Add the `ObservableProperty` attribute to the field to make it a bindable property.\n4.  Create a `private` field of the `string` type, called `description`. Add the `ObservableProperty` attribute to the field to make it a bindable property.\n5.  Create a `private` field of the `string` type, called `Title`. Add the `ObservableProperty` attribute to the field to make it a bindable property, as shown in the following code block:\n\n    ```", "```cs\n\nThe next thing we will do in `ResultViewModel` is to create an `Initialize` method that will have the result as a parameter. Let’s set this up by following these steps:\n\n1.  Add a `private` method named `Initialize` to the `ResultViewModel` class that accepts a parameter of the `Result` type, named `result`, and returns `void`.\n2.  In the `Initialize` method, set the `PhotoBytes` property to the value of the `PhotoBytes` property of the `result` parameter.\n3.  Add an `if` statement that checks whether the `IsHotDog` property of the `result` parameter is `true` and whether `Confidence` is higher than `90%`. If this is the case, set `Title` to `\"Hot dog\"` and `Description` to `\"This is for sure` `a hotdog\"`.\n4.  Add an `else if` statement to check whether the `IsHotdog` property of the `result` parameter is `true`. If this is the case, set `Title` to `\"Maybe\"` and `Description` to `\"This is maybe` `a hotdog\"`.\n5.  Add an `else` statement that sets `Title` to `\"Not a hot dog\"` and `Description` to `\"This is not a hot dog\"`, as shown in the following code block:\n\n    ```", "```cs\n\nThe final thing we need to do is call the `Initialize` method with the result. If you recall from the previous section on building the main view, we navigated to the `Result` view and passed the `Result` object as a parameter. To access the parameter and call the `Initialize` method properly, follow these steps:\n\n1.  Add the `IQueryAttributable` interface to the list of inherited interfaces:\n\n    ```", "```cs\n    public void ApplyQueryAttributes(IDictionary<string, object> query)\n    {\n    }\n    ```", "```cs\n\n     2.  Now, in the method, call the `Initialize` method, passing the `“result”` object from the query dictionary and casting it to a `Result` type, as shown in the following code:\n\n    ```", "```cs\n\n`ViewModel` is now complete, and we are ready to create `View`.\nBuilding the view\nBecause we want to show the input photo in the result view, we need to convert it from `byte[]` to `Microsft.Maui.Controls.ImageSource`. We will do this in a value converter that we can use together with the binding in the **XAML**, by following these steps:\n\n1.  Create a new folder called `Converters`.\n2.  Create a new class called `BytesToImageConverter` in the `Converters` folder.\n3.  Add and implement the `IValueConverter` interface, as shown in the following code block:\n\n    ```", "```cs\n\nThe `Convert` method will be used when `ViewModel` updates a view. The `ConvertBack` method will be used in two-way bindings when `View` updates `ViewModel`. In this case, we only need to write code for the `Convert` method, by following these steps:\n\n1.  First, check whether the `value` parameter is `null`. If so, we should return `null`.\n2.  If the value is not `null`, cast it as `byte[]`.\n3.  Create a `MemoryStream` object from the `byte` array.\n4.  Return the result of the `ImageSource.FromStream` method to which we will pass the stream, as shown in the following code block:\n\n    ```", "```cs\n\nThe view will contain the photo, which will take up two-thirds of the screen. Under the photo, we will add a description of the result. Let’s set this up by going through the following steps:\n\n1.  In the `Views` folder, create a new file using the .NET MAUI ContentPage (XAML) file template, and name it `ResultView`.\n2.  Import the namespace for the converter.\n3.  Add `BytesToImageConverter` to `Resources` for the page and give it `“``ToImage”` key.\n4.  Bind the `Title` property of `ContentPage` as the `Title` property of `ViewModel`.\n5.  Add `Grid` to the page with two rows. The `Height` value for the first `RowDefinition` should be `2*`. The height of the second row should be `*`. These are relative values that mean that the first row will take up two-thirds of `Grid`, while the second row will take up one-third of `Grid`.\n6.  Add `Image` to `Grid`, and bind the `Source` property to the `PhotoBytes` property in `ViewModel`. Use the converter to convert the bytes to an `ImageSource` object and set the `Source` property.\n7.  Add `Label`, and bind the `Text` property to the `Description` property of `ViewModel`, as shown in the following code block:\n\n    ```", "```cs\n\nWe also need to set `BindingContext` of the view. We will do this in the same way as we did in `MainView` – in the code-behind file (`ResultView.xaml.cs`), as shown in the following code snippet:\n\n```", "```cs\n\n We are now ready to write the initialization code for the app.\nInitializing the app\nWe will set up `Shell`.\nOpen `App.xaml.cs`, and set `MainPage` to `MainView` by following these steps:\n\n1.  Delete the `MainPage.xaml` and `MainPage.xaml.cs` files from the root of the project, since we won’t be needing those.\n2.  Open the `AppShell.xaml` file in the root of the project, and modify it to look like the following code:\n\n    ```", "```cs\n\nNow, configure the `View` and `ViewModel` classes in the IoC container by following these steps:\n\n1.  Open the `MauiProgram.cs` file.\n2.  In the `CreateMauiApp` method before the `return` statement, add the following highlighted lines of code:\n\n    ```", "```cs\n\nThe very last thing we need to do is add the route to `ResultView` to enable navigation from `MainView`. We will do this by adding the following highlighted code to the constructor of `AppShell` in `AppShell.xaml.cs`:\n\n```", "```cs\n\n Now, we are ready to run the app. If we use the simulator/emulator, we can just drag and drop photos to it if we need photos to test with. When the app has started, we can now pick a photo and run it against the model. The following screenshot shows how the app will look if we upload a photo of a hot dog:\n![Figure 12.13 – HotdogOrNot running in an Android emulator](img/B19214_12_13.jpg)\n\nFigure 12.13 – HotdogOrNot running in an Android emulator\nNote\nThe prediction result for Android may not be as accurate as the web portal at [https://github.com/Azure-Samples/cognitive-services-android-customvision-sample/issues/12](https://github.com/Azure-Samples/cognitive-services-android-customvision-sample/issues/12). If you desire better, more consistent results, you can use the REST APIs.\nSummary\nIn this chapter, we built an app that can recognize whether a photo contains a hot dog or not. We accomplished this by training a machine learning model for image classification, using Azure Cognitive Services and the Custom Vision service.\nWe exported models for ML.NET, and we learned how to use it in an MAUI app that targets iOS, Mac Catalyst, Windows, and Android. In the app, a user can take a photo or pick one from their photo library. This photo will be sent to the model to be classified, and we will get a result that tells us whether the photo is of a hot dog.\nNow, we can continue to build other apps and use what we have learned in this chapter regarding machine learning, both on-device and in the cloud using Azure Cognitive Services. Even if we are building other apps, the concept will be the same.\nNow, we have completed all the chapters in this book. We have learned the following:\n\n*   What .NET MAUI is and how we can get started building apps\n*   How to use the basic layouts and controls of .NET MAUI\n*   How to work with navigation\n*   How to make the user experience better with animations\n*   How to use sensors such as the **Global Positioning System** (**GPS**) in the background\n*   How to build apps for multiple form factors\n*   How to build real-time apps powered by Azure\n*   How to make apps smarter with machine learning\n\nThe next step is to start to build your own apps. To stay up to date and learn more about .NET MAUI, our recommendation is to read the official Microsoft dev blogs and watch live streams on Twitch and YouTube videos from the .NET MAUI team.\nThank you for reading the book!\n\n```"]