- en: Chapter 7. Using PLINQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will review different parallel programming paradigms, such
    as task and data parallelism, and cover the basics of data parallelism and parallel
    LINQ queries. You will learn the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `Parallel` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallelizing a LINQ query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tweaking the parameters of a PLINQ query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling exceptions in a PLINQ query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing data partitioning in a PLINQ query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a custom aggregator for a PLINQ query
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In .NET Framework, there is a subset of libraries that is called Parallel Framework,
    often referred to as **Parallel Framework Extensions** (**PFX**), which was the
    name of the very first version of these libraries. Parallel Framework was released
    with .NET Framework 4.0 and consists of three major parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The Task Parallel Library (TPL)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrent collections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel LINQ or PLINQ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Until now, you have learned how to run several tasks in parallel and synchronize
    them with one another. In fact, we partitioned our program into a set of tasks
    and had different threads running different tasks. This approach is called **task
    parallelism**, and you have only been learning about task parallelism so far.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that we have a program that performs some heavy calculations over a
    big set of data. The easiest way to parallelize this program is to partition this
    set of data into smaller chunks, run the calculations needed over these chunks
    of data in parallel, and then aggregate the results of these calculations. This
    programming model is called **data parallelism**.
  prefs: []
  type: TYPE_NORMAL
- en: Task parallelism has the lowest abstraction level. We define a program as a
    combination of tasks, explicitly defining how they are combined. A program composed
    in this way could be very complex and detailed. Parallel operations are defined
    in different places in this program, and as it grows, the program becomes harder
    to understand and maintain. This way of making the program parallel is called
    **unstructured parallelism**. It is the price we have to pay if we have complex
    parallelization logic.
  prefs: []
  type: TYPE_NORMAL
- en: However, when we have simpler program logic, we can try to offload more parallelization
    details to the PFX libraries and the C# compiler. For example, we could say, "I
    would like to run those three methods in parallel, and I do not care how exactly
    this parallelization happens; let the .NET infrastructure decide the details".
    This raises the abstraction level as we do not have to provide a detailed description
    of how exactly we are parallelizing this. This approach is referred to as **structured
    parallelism** since the parallelization is usually a sort of declaration and each
    case of parallelization is defined in exactly one place in the program.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There could be an impression that unstructured parallelism is bad practice and
    structured parallelism should be always used instead. I would like to emphasize
    that this is not true. Structured parallelism is indeed more maintainable, and
    preferred when possible, but it is a much less universal approach. In general,
    there are many situations when we simply are not able to use it, and it is perfectly
    OK to use TPL task parallelism in an unstructured manner.
  prefs: []
  type: TYPE_NORMAL
- en: TPL has a `Parallel` class, which provides APIs for structured parallelism.
    This is still a part of TPL, but we will review it in this chapter because it
    is a perfect example of transition from a lower abstraction level to a higher
    one. When we use the `Parallel` class APIs, we do not need to provide the details
    of how we partition our work. However, we still need to explicitly define how
    we make one single result from partitioned results.
  prefs: []
  type: TYPE_NORMAL
- en: PLINQ has the highest abstraction level. It automatically partitions data in
    to chunks and decides whether we really need to parallelize the query or whether
    it will be more effective to use usual sequential query processing. Then, the
    PLINQ infrastructure takes care of combining the partitioned results. There are
    many options that programmers may tweak to optimize the query and achieve the
    best possible performance and result.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will cover the `Parallel` class API usage and many different
    PLINQ options, such as making a LINQ query parallel, setting up an execution mode
    and tweaking the parallelism degree of a PLINQ query, dealing with a query item
    order, and handling PLINQ exceptions. You will also learn how to manage data partitioning
    for PLINQ queries.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Parallel class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows you how to use the `Parallel` class APIs. You will learn how
    to invoke methods in parallel, how to perform parallel loops, and tweak parallelization
    mechanics.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter7\Recipe1`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To invoke methods in parallel, perform parallel loops, and tweak parallelization
    mechanics using the `Parallel` class, perform the given steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This program demonstrates different features of the `Parallel` class. The `Invoke`
    method allows us to run several actions in parallel without much trouble as compared
    to defining tasks in TPL. The `Invoke` method blocks the other thread until all
    actions are complete, which is quite a common and convenient scenario.
  prefs: []
  type: TYPE_NORMAL
- en: The next feature is parallel loops, which are defined with the `For` and `ForEach`
    methods. We will look closely at `ForEach` since it is very similar to `For`.
    With the `ForEach` parallel loop, you can process any `IEnumerable` collection
    in parallel by applying an action delegate to each collection item. We are able
    to provide several options, customizing parallelization behavior, and get a result
    that shows whether the loop completed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: To tweak our parallel loop, we provide an instance of the `ParallelOptions`
    class to the `ForEach` method. This allows us to cancel the loop with `CancellationToken`,
    restrict the maximum parallelism degree (how many maximum operations can be run
    in parallel), and provide a custom `TaskScheduler` class to schedule action tasks
    with it. Actions can accept an additional `ParallelLoopState` parameter, which
    is useful for breaking the loop or for checking what happens with the loop at
    this moment.
  prefs: []
  type: TYPE_NORMAL
- en: There are two ways of stopping the parallel loop with this state. We could use
    either the `Break` or `Stop` methods. The `Stop` method tells the loop to stop
    processing any more work and sets the `IsStopped` property of the parallel loop
    state to `true`. The `Break` method stops the iterations after it, but the initial
    ones will continue to work. In that case, the `LowestBreakIteration` property
    of the loop result will contain the number of lowest loop iteration where the
    `Break` method was called.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelizing a LINQ query
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe will describe how to use PLINQ to make a query parallel and how
    to go back from a parallel query to sequential processing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter7\Recipe2`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use PLINQ in order to make a query parallel and to go back from a parallel
    query to sequential processing, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the program runs, we create a LINQ query that uses the reflection API to
    get all types whose names start with *Web* from the assemblies loaded in the current
    application domain. We emulate delays for processing each item and for printing
    it with the `EmulateProcessing` and `PrintInfo` methods. We also use the `Stopwatch`
    class to measure each query's execution time.
  prefs: []
  type: TYPE_NORMAL
- en: First, we run a usual sequential LINQ query. There is no parallelization here,
    so everything runs on the current thread. The second version of the query uses
    the `ParallelEnumerable` class explicitly. `ParallelEnumerable` contains the PLINQ
    logic implementation and is organized as a number of extension methods to the
    `IEnumerable` collection's functionality. Normally, we do not use this class explicitly;
    we are using it here to illustrate how PLINQ actually works. The second version
    runs `EmulateProcessing` in parallel; however, by default, the results are merged
    on a single thread, so the query execution time should be a couple of seconds
    less than the first version.
  prefs: []
  type: TYPE_NORMAL
- en: The third version shows how to use the `AsParallel` method to run the LINQ query
    in parallel in a declarative manner. We do not care about implementation details
    here but just state that we want to run this in parallel. However, the key difference
    in this version is that we use the `ForAll` method to print out the query results.
    It runs the action to all items in the query on the same thread they were processed
    in, skipping the results-merging step. It allows us to run `PrintInfo` in parallel
    as well, and this version runs even faster than the previous one.
  prefs: []
  type: TYPE_NORMAL
- en: The last sample shows how to turn a PLINQ query back to sequential with the
    `AsSequential` method. We can see that this query runs exactly like the first
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Tweaking the parameters of a PLINQ query
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows how we can manage parallel processing options using a PLINQ
    query and what these options could affect during a query's execution.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter7\Recipe3`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand how to manage parallel processing options using a PLINQ query
    and their effects, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The program demonstrates different useful PLINQ options that programmers can
    use. We start with creating a PLINQ query, and then we create another query providing
    PLINQ tweaking.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with cancelation first. To be able to cancel a PLINQ query, there
    is a `WithCancellation` method that accepts a cancelation token object. Here,
    we signal the cancelation token after 3 seconds, which leads to `OperationCanceledException`
    in the query and cancelation of the rest of the work.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we are able to specify a parallelism degree for the query. It is the exact
    number of parallel partitions that will be used to execute the query. In the first
    recipe, we used the `Parallel.ForEach` loop, which has the maximum parallelism
    degree option. It is different because it specifies a maximum partitions value,
    but there could be fewer partitions if the infrastructure decides that it is better
    to use less parallelism to save resources and achieve optimal performance.
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting option is overriding the query execution mode with the `WithExecutionMode`
    method. The PLINQ infrastructure can process some queries in sequential mode if
    it decides that parallelizing the query will only add more overhead and it actually
    will run slower. Using `WithExecutionMode`, we can force the query to run in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: To tune up query result processing, we have the `WithMergeOptions` method. The
    default mode is used to buffer a number of results selected by the PLINQ infrastructure
    before returning them from the query. If the query takes a significant amount
    of time, it is more reasonable to turn off result buffering to get the results
    as soon as possible.
  prefs: []
  type: TYPE_NORMAL
- en: The last option is the `AsOrdered` method. It is possible that when we use parallel
    execution, the item order in the collection is not preserved. Later items in the
    collection could be processed before earlier ones. To prevent this, we need to
    call `AsOrdered` on a parallel query to explicitly tell the PLINQ infrastructure
    that we intend to preserve the item order for processing.
  prefs: []
  type: TYPE_NORMAL
- en: Handling exceptions in a PLINQ query
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe will describe how to handle exceptions in a PLINQ query.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter7\Recipe4`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand how to handle exceptions in a PLINQ query, perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we run a usual LINQ query over a range of numbers from -5 to 4\. When
    we divide by 0, we get `DivideByZeroException`, and we handle it as usual in a
    `try/catch` block.
  prefs: []
  type: TYPE_NORMAL
- en: However, when we use `AsParallel`, we get `AggregateException` instead because
    we are now running in parallel, leveraging the task infrastructure behind the
    scenes. `AggregateException` will contain all the exceptions that occurred while
    running the PLINQ query. To handle the inner `DivideByZeroException` class, we
    use the `Flatten` and `Handle` methods, which were explained in the *Handling
    exceptions in asynchronous operations* recipe in [Chapter 5](ch05.html "Chapter 5. Using
    C# 6.0"), *Using C# 6.0*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is very easy to forget that when we handle aggregate exceptions, having more
    than one inner exception inside is a very common situation. If you forget to handle
    all of them, the exception will bubble up and the application will stop working.
  prefs: []
  type: TYPE_NORMAL
- en: Managing data partitioning in a PLINQ query
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows you how to create a very basic custom partitioning strategy
    to parallelize a LINQ query in a specific way.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter7\Recipe5`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To learn how to create a very basic custom partitioning strategy to parallelize
    a LINQ query, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To illustrate that we are able to choose custom partitioning strategies for
    the PLINQ query, we created a very simple partitioner that processes strings of
    odd and even lengths in parallel. To achieve this, we derive our custom `StringPartitioner`
    class from a standard base class `Partitioner<T>` using `string` as a type parameter.
  prefs: []
  type: TYPE_NORMAL
- en: We declare that we only support static partitioning by overriding the `SupportsDynamicPartitions`
    property and setting it to `false`. This means that we predefine our partitioning
    strategy. This is an easy way to partition the initial collection but could be
    inefficient depending on what data we have inside the collection. For example,
    in our case, if we had many strings with odd lengths and only one string with
    even length, one of the threads would have finished early and would not have helped
    to process odd-length strings. On the other hand, dynamic partitioning means that
    we partition the initial collection on the fly, balancing the work load between
    the worker threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we implement the `GetPartitions` method, where we define the following
    logic: if there is only one partition, we simply process everything on it. However,
    if we have more than one partition, then we process strings with odd length on
    odd partitions and even-length strings on even-numbered partitions.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Please note that we need to create as many partitions as is stated in the `partitionCount`
    parameter, or else we will get the `Partitioner returned a wrong number of partitions`
    error.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we create an instance of our partitioner and perform a PLINQ query
    with it. We can see that different threads process the odd-length and even-length
    strings. Also, we can experiment with uncommenting the `WithDegreeOfParallelism`
    method and changing its parameter value. In the case of `1`, there will be a sequential
    work items processing, and when increasing the value, we can see that more work
    gets done in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom aggregator for a PLINQ query
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows you how to create a custom aggregation function for a PLINQ
    query.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter7\Recipe6`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the workings of a custom aggregation function for a PLINQ query,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we implement custom aggregation mechanics that are able to work with the
    PLINQ queries. To implement this, we have to understand that since a query is
    being processed in parallel by several tasks simultaneously, we need to provide
    mechanics to aggregate each task's result in parallel and then combine those aggregated
    values into one single result value.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we wrote an aggregating function that counts letters in a PLINQ
    query, which returns the `IEnumerable<string>` collection. It counts all the letters
    in each collection item. To illustrate the parallel aggregation process, we print
    out information about which thread processes each part of the aggregation.
  prefs: []
  type: TYPE_NORMAL
- en: We aggregate the PLINQ query results using the `Aggregate` extension method
    defined in the `ParallelEnumerable` class. It accepts four parameters, each of
    which is a function that performs different parts of the aggregation process.
    The first one is a factory that constructs the empty initial value of the aggregator.
    It is also called the seed value.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the first value provided to the `Aggregate` method is actually not
    an initial seed value for the aggregator function but a factory method that constructs
    this initial seed value. If you provide just an instance, it will be used in all
    partitions that run in parallel, which will lead to an incorrect result.
  prefs: []
  type: TYPE_NORMAL
- en: The second function aggregates each collection item into the partition aggregation
    object. We implement this function with the `AccumulateLettersInformation` method.
    It iterates the string and counts the letters inside it. Here, the aggregation
    objects are different for each query partition running in parallel, which is why
    we called them `taskTotal`.
  prefs: []
  type: TYPE_NORMAL
- en: The third function is a higher level aggregation function that takes an aggregator
    object from a partition and merges it into a global aggregator object. We implement
    it with the `MergeAccumulators` method. The last function is a selector function
    that specifies what exact data we need from the global aggregator object.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we print out the aggregation result, ordering it by the letters used
    most often in the collection items.
  prefs: []
  type: TYPE_NORMAL
