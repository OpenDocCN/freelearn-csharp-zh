- en: Chapter 10. Parallel Programming Patterns
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 10 章. 并行编程模式
- en: 'In this chapter, we will review the common problems that a programmer often
    faces while trying to implement a parallel workflow. You will learn the following
    recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾程序员在尝试实现并行工作流程时经常遇到的一些常见问题。你将学习以下技巧：
- en: Implementing Lazy-evaluated shared states
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现延迟评估的共享状态
- en: Implementing Parallel Pipeline with `BlockingCollection`
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `BlockingCollection` 实现并行管道
- en: Implementing Parallel Pipeline with TPL DataFlow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TPL DataFlow 实现并行管道
- en: Implementing Map/Reduce with PLINQ
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 PLINQ 实现Map/Reduce
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Patterns in programming means a concrete and standard solution to a given problem.
    Usually, programming patterns are the result of people gathering experience, analyzing
    the common problems, and providing solutions to these problems.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 编程模式意味着对给定问题的具体和标准解决方案。通常，编程模式是人们积累经验、分析常见问题并为这些问题提供解决方案的结果。
- en: Since parallel programming has existed for quite a long time, there are many
    different patterns that are used to program parallel applications. There are even
    special programming languages to make programming of specific parallel algorithms
    easier. However, this is where things start to become increasingly complicated.
    In this chapter, I will provide you with a starting point from where you will
    be able to study parallel programming further. We will review very basic, yet
    very useful, patterns that are quite helpful for many common situations in parallel
    programming.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于并行编程已经存在了很长时间，因此有许多不同的模式被用来编写并行应用程序。甚至还有专门的编程语言来简化特定并行算法的编程。然而，事情开始变得越来越复杂。在本章中，我将为你提供一个起点，从这里你可以进一步学习并行编程。我们将回顾一些非常基础但非常有用的模式，这些模式对于并行编程中的许多常见情况非常有帮助。
- en: First, we will be using a **shared-state object** from multiple threads. I would
    like to emphasize that you should avoid it as much as possible. As we discussed
    in previous chapters, a shared state is really bad when you write parallel algorithms,
    but on many occasions, it is inevitable. We will find out how to delay the actual
    computation of an object until it is needed and how to implement different scenarios
    to achieve thread safety.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用来自多个线程的 **共享状态对象**。我想强调的是，你应该尽可能避免使用它。正如我们在前面的章节中讨论的那样，当编写并行算法时，共享状态真的很糟糕，但在许多情况下，它是不可避免的。我们将找出如何延迟对象的实际计算直到它被需要，以及如何实现不同的场景以实现线程安全。
- en: Then, we will show you how to create a structured parallel data flow. We will
    review a concrete case of a producer/consumer pattern, which is called **Parallel
    Pipeline**. We are going to implement it by just blocking the collection first,
    and then we will see how helpful another library from Microsoft is for parallel
    programming—**TPL DataFlow**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将向你展示如何创建一个结构化的并行数据流。我们将回顾一个具体的案例，即生产者/消费者模式，被称为 **Parallel Pipeline**。我们计划通过首先阻塞集合来实现它，然后我们将看到来自微软的另一个库——**TPL
    DataFlow** 对于并行编程是多么有帮助。
- en: The last pattern that we will study is the **Map/Reduce** pattern. In the modern
    world, this name could mean very different things. Some people consider Map/Reduce
    not as a common approach to any problem, but as a concrete implementation for
    large, distributed cluster computations. We will find out the meaning behind the
    name of this pattern and review some examples of how it might work in cases of
    small parallel applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要研究的最后一个模式是 **Map/Reduce** 模式。在现代世界中，这个名字可能意味着非常不同的事情。有些人认为 Map/Reduce 不是一个通用的方法来解决任何问题，而是一个针对大型、分布式集群计算的具体实现。我们将找出这个模式名称背后的含义，并回顾一些在小规模并行应用中可能的工作方式。
- en: Implementing Lazy-evaluated shared states
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现延迟评估的共享状态
- en: This recipe shows how to program a Lazy-evaluated, thread-safe shared state
    object.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技巧展示了如何编程一个延迟评估、线程安全的共享状态对象。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To start this recipe, you will need to run Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter10\Recipe1`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个技巧，你需要运行 Visual Studio 2015。没有其他先决条件。这个技巧的源代码可以在 `BookSamples\Chapter10\Recipe1`
    中找到。
- en: How to do it...
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: 'To implement Lazy-evaluated shared states, perform the following steps:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现延迟评估的共享状态，执行以下步骤：
- en: Start Visual Studio 2015\. Create a new C# console application project.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 Visual Studio 2015。创建一个新的 C# 控制台应用程序项目。
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Program.cs` 文件中，添加以下 `using` 指令：
- en: '[PRE0]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下方添加以下代码片段：
- en: '[PRE1]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法内添加以下代码片段：
- en: '[PRE2]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Run the program.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The first example shows why it is not safe to use the `UnsafeState` object with
    multiple accessing threads. We see that the `Construct` method was called several
    times, and different threads use different values, which is obviously not right.
    To fix this, we can use a lock when reading the value, and if it is not initialized,
    create it first. This will work, but using a lock with every read operation is
    not efficient. To avoid using locks every time, we can use a traditional approach
    called the **double-checked locking** pattern. We check the value for the first
    time, and if is not null, we avoid unnecessary locking and just use the shared
    object. However, if it was not constructed, we use the lock and then check the
    value for the second time because it could be initialized between our first check
    and the lock operation. If it is still not initialized, only then do we compute
    the value. We can clearly see that this approach works with the second example—there
    is only one call to the `Construct` method, and the first-called thread defines
    the shared object state.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个示例显示了为什么在多个访问线程中使用`UnsafeState`对象是不安全的。我们看到`Construct`方法被多次调用，不同的线程使用不同的值，这显然是不正确的。为了修复这个问题，我们可以在读取值时使用一个锁，如果它尚未初始化，首先创建它。这将有效，但使用锁进行每次读取操作并不高效。为了避免每次都使用锁，我们可以使用一个传统的称为**双重检查锁定**模式的方法。我们第一次检查值，如果它不是null，我们避免不必要的锁定并直接使用共享对象。然而，如果它尚未构造，我们使用锁然后第二次检查值，因为它可能在我们的第一次检查和锁操作之间被初始化。如果它仍然未初始化，我们才计算值。我们可以清楚地看到这种方法在第二个示例中是有效的——只有一个`Construct`方法的调用，第一个调用的线程定义了共享对象状态。
- en: Note
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that if the Lazy-evaluated object implementation is thread-safe, it does
    not automatically mean that all its properties are thread-safe as well.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果延迟计算的对象实现是线程安全的，这并不意味着它的所有属性也都是线程安全的。
- en: If you add, for example, an `int` public property to the `ValueToAccess` object,
    it will not be thread-safe; you still have to use interlocked constructs or locking
    to ensure thread safety.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你向`ValueToAccess`对象添加一个`int`公共属性，它将不是线程安全的；你仍然必须使用互斥构造或锁定来确保线程安全。
- en: This pattern is very common, and that is why there are several classes in the
    Base Class Library to help us. First, we can use the `LazyInitializer.EnsureInitialized`
    method, which implements the double-checked locking pattern inside. However, the
    most comfortable option is to use the `Lazy<T>` class, which allows us to have
    thread-safe, Lazy-evaluated, shared state, out of the box. The next two examples
    show us that they are equivalent to the second one, and the program behaves in
    the same way. The only difference is that since `LazyInitializer` is a static
    class, we do not have to create a new instance of a class, as we do in the case
    of `Lazy<T>`, and therefore, the performance in the first case can be better in
    some rare scenarios.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式非常常见，这就是为什么在基类库中有几个类帮助我们。首先，我们可以使用`LazyInitializer.EnsureInitialized`方法，它在内部实现了双重检查锁定模式。然而，最舒适的选项是使用`Lazy<T>`类，它允许我们开箱即用就有线程安全、延迟计算的共享状态。接下来的两个示例表明，它们与第二个示例是等价的，程序的行为也是相同的。唯一的区别是，由于`LazyInitializer`是一个静态类，我们不需要创建一个新实例，就像在`Lazy<T>`的情况下，因此，在某些罕见场景中，第一种情况下的性能可能会更好。
- en: The last option is to avoid locking at all if we do not care about the `Construct`
    method. If it is thread-safe and has no side effects/serious performance impacts,
    we can just run it several times but use only the first constructed value. The
    last example shows the described behavior, and we can achieve this result using
    another `LazyInitializer.EnsureInitialized` method overload.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个选项是，如果我们不关心`Construct`方法，可以完全避免锁定。如果它是线程安全的并且没有副作用/严重的性能影响，我们只需运行几次，但只使用第一个构造的值。最后一个示例显示了描述的行为，我们可以使用另一个`LazyInitializer.EnsureInitialized`方法重载来实现这个结果。
- en: Implementing Parallel Pipeline with BlockingCollection
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用BlockingCollection实现并行管道
- en: This recipe will describe how to implement a specific scenario of a producer/consumer
    pattern, which is called Parallel Pipeline, using the standard `BlockingCollection`
    data structure.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方将描述如何使用标准的`BlockingCollection`数据结构实现生产者/消费者模式的一个特定场景，这被称为并行管道。
- en: Getting ready
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To begin this recipe, you will need to run Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter10\Recipe2`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个食谱，你需要运行 Visual Studio 2015。没有其他先决条件。这个食谱的源代码可以在`BookSamples\Chapter10\Recipe2`找到。
- en: How to do it...
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'To understand how to implement Parallel Pipeline using `BlockingCollection`,
    perform the following steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用`BlockingCollection`实现并行管道，请执行以下步骤：
- en: Start Visual Studio 2015\. Create a new C# console application project.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 Visual Studio 2015。创建一个新的 C# 控制台应用程序项目。
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program.cs`文件中添加以下`using`指令：
- en: '[PRE3]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下方添加以下代码片段：
- en: '[PRE4]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法内部添加以下代码片段：
- en: '[PRE5]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Run the program.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the preceding example, we implement one of the most common parallel programming
    scenarios. Imagine that we have some data that has to pass through several computation
    stages, which takes a significant amount of time. The latter computation requires
    the results of the former, so we cannot run them in parallel.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们实现了最常见的并行编程场景之一。想象一下，我们有一些数据需要通过几个计算阶段，这需要相当长的时间。后一个计算需要前一个计算的结果，所以我们不能并行运行它们。
- en: If we had only one item to process, there would not be many possibilities to
    enhance the performance. However, if we run many items through the same set of
    computation stages, we can use a Parallel Pipeline technique. This means that
    we do not have to wait until all items pass through the first computation stage
    to go to the next one. It is enough to have just one item that finishes the stage;
    we move it to the next stage, and meanwhile, the next item is being by the previous
    stage, and so on. As a result, we almost have parallel processing shifted by the
    time required for the first item to pass through the first computation stage.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只有一个项目要处理，那么提高性能的可能性并不多。然而，如果我们让许多项目通过相同的计算阶段，我们可以使用并行管道技术。这意味着我们不必等到所有项目都通过第一个计算阶段才能进入下一个阶段。只要有一个项目完成了阶段，我们就可以将其移动到下一个阶段；同时，下一个项目正在由前一个阶段处理，以此类推。结果，我们几乎实现了通过第一个项目通过第一个计算阶段所需的时间来实现的并行处理。
- en: Here, we use four collections for each processing stage, illustrating that we
    can process every stage in parallel as well. The first step that we do is to provide
    the possibility to cancel the whole process by pressing the *C* key. We create
    a cancelation token and run a separate task to monitor the *C* key. Then, we define
    our pipeline. It consists of three main stages. The first stage is where we put
    the initial numbers on the first four collections that serve as the item source
    to the latter pipeline. This code is inside the `Parallel.For` loop of the `CreateInitialValues`
    method, which in turn is inside the `Parallel.Invoke` statement, as we run all
    the stages in parallel; the initial stage runs in parallel as well.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们为每个处理阶段使用四个集合，说明我们可以并行处理每个阶段。我们首先提供通过按*C*键取消整个过程的可能性。我们创建了一个取消令牌，并运行一个单独的任务来监控*C*键。然后，我们定义我们的管道。它由三个主要阶段组成。第一个阶段是我们将初始数字放在前四个集合中，这些集合作为后续管道的项目源。这段代码位于`CreateInitialValues`方法的`Parallel.For`循环内部，而`Parallel.Invoke`语句则表示我们并行运行所有阶段；初始阶段也是并行运行的。
- en: The next stage is defining our pipeline elements. The logic is defined inside
    the `PipelineWorker` class. We initialize the worker with the input collection,
    provide a transformation function, and then run the worker in parallel with the
    other workers. This way, we define two workers, or filters, because they filter
    the initial sequence. One of them turns an integer into a decimal value, and the
    second one turns a decimal to a string. Finally, the last worker just prints every
    incoming string to the console. In all the places, we provide a running thread
    ID to see how everything works. Besides this, we added artificial delays, so the
    item's processing will be more natural, as we really use heavy computations.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个阶段是定义我们的管道元素。逻辑定义在`PipelineWorker`类内部。我们使用输入集合初始化工作者，提供一个转换函数，然后与其他工作者并行运行工作者。这样，我们定义了两个工作者，或者过滤器，因为它们过滤初始序列。其中一个将整数转换为十进制值，另一个将十进制转换为字符串。最后，最后一个工作者只是将每个传入的字符串打印到控制台。在所有地方，我们提供了一个运行线程ID，以查看一切是如何工作的。此外，我们还添加了人工延迟，以便项目的处理更加自然，因为我们实际上使用了重计算。
- en: As a result, we see the exact expected behavior. First, some items are created
    on the initial collections. Then, we see that the first filter starts to process
    them, and as they are being processed, the second filter starts to work. Finally,
    the item goes to the last worker that prints it to the console.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们看到了预期的确切行为。首先，在初始集合中创建了一些项目。然后，我们看到第一个过滤器开始处理它们，在它们被处理的同时，第二个过滤器开始工作。最后，项目被发送到最后一个工作器，它将项目打印到控制台。
- en: Implementing Parallel Pipeline with TPL DataFlow
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TPL DataFlow实现并行管道
- en: This recipe shows how to implement a Parallel Pipeline pattern with the help
    of the TPL DataFlow library.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱展示了如何使用TPL DataFlow库实现并行管道模式。
- en: Getting ready
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: To start this recipe, you will need to run Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter10\Recipe3`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个食谱，你需要运行Visual Studio 2015。没有其他先决条件。这个食谱的源代码可以在`BookSamples\Chapter10\Recipe3`中找到。
- en: How to do it...
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'To understand how to implement Parallel Pipeline with TPL DataFlow, perform
    the following steps:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用TPL DataFlow实现并行管道，请执行以下步骤：
- en: Start Visual Studio 2015\. Create a new C# console application project.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Visual Studio 2015。创建一个新的C#控制台应用程序项目。
- en: 'Add references to the **Microsoft TPL DataFlow** NuGet package. Follow these
    steps to do so:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将引用添加到**Microsoft TPL DataFlow** NuGet包。按照以下步骤操作：
- en: Right-click on the **References** folder in the project and select the **Manage
    NuGet Packages...** menu option.
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击项目中的**引用**文件夹，并选择**管理NuGet包...**菜单选项。
- en: 'Now, add your preferred references to the **Microsoft TPL DataFlow** NuGet
    package. You can use the search option in the **Manage NuGet Packages** dialog
    as follows:'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，将你喜欢的引用添加到**Microsoft TPL DataFlow** NuGet包中。你可以在**管理NuGet包**对话框中使用搜索选项，如下所示：
- en: '![How to do it...](img/B05292_10_01.jpg)'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![如何做...](img/B05292_10_01.jpg)'
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program.cs`文件中，添加以下`using`指令：
- en: '[PRE6]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下方添加以下代码片段：
- en: '[PRE7]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法内部添加以下代码片段：
- en: '[PRE8]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Run the program.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the previous recipe, we implemented a Parallel Pipeline pattern to process
    items through sequential stages. It is quite a common problem, and one of the
    proposed ways to program such algorithms is using a TPL DataFlow library from
    Microsoft. It is distributed via NuGet and is easy to install and use in your
    application.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的食谱中，我们实现了一个并行管道模式，通过顺序阶段处理项目。这是一个相当常见的问题，提出编程此类算法的方法之一是使用来自Microsoft的TPL
    DataFlow库。它通过NuGet分发，易于安装和使用。
- en: The TPL DataFlow library contains different types of blocks that can be connected
    with each other in different ways and form complicated processes that can be partially
    parallel and sequential where needed. To see some of the available infrastructure,
    let's implement the previous scenario with the help of the TPL DataFlow library.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: TPL DataFlow库包含不同类型的块，这些块可以用不同的方式相互连接，形成复杂的过程，可以在需要时部分并行和顺序执行。为了查看一些可用的基础设施，让我们使用TPL
    DataFlow库实现前面的场景。
- en: First, we define the different blocks that will be processing our data. Note
    that these blocks have different options that can be specified during their construction;
    they can be very important. For example, we pass the cancelation token into every
    block we define, and when we signal the cancelation, all of them stop working.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义了将处理我们的数据的不同块。请注意，这些块在构建时可以指定不同的选项；它们可能非常重要。例如，我们将取消令牌传递到我们定义的每个块中，当我们发出取消信号时，它们都会停止工作。
- en: We start our process with `BufferBlock`, we bound its capacity to 5 items maximum.
    This block holds items to pass them to the next blocks in the flow. We restrict
    it to the five-item capacity, specifying the `BoundedCapacity` option value. This
    means that when there will be five items in this block, it will stop accepting
    new items until one of the existing items passes to the next blocks.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`BufferBlock`开始我们的过程，将其容量绑定到最大5个项目。此块持有项目，以便将它们传递到流程中的下一个块。我们将其限制为五项容量，指定`BoundedCapacity`选项值。这意味着当此块中有五个项目时，它将停止接受新项目，直到现有项目中的一个传递到下一个块。
- en: The next block type is `TransformBlock`. This block is intended for a data transformation
    step. Here, we define two transformation blocks; one of them creates decimals
    from integers, and the second one creates a string from a decimal value. We can
    use the `MaxDegreeOfParallelism` option for this block, specifying the maximum
    simultaneous worker threads.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个块类型是`TransformBlock`。这个块用于数据转换步骤。在这里，我们定义了两个转换块；其中一个将整数转换为小数，另一个将小数值转换为字符串。我们可以使用`MaxDegreeOfParallelism`选项为此块指定最大同时工作线程数。
- en: The last block is of the `ActionBlock` type. This block will run a specified
    action on every incoming item. We use this block to print our items to the console.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个块是`ActionBlock`类型。这个块将在每个传入的项目上运行指定的操作。我们使用这个块将项目打印到控制台。
- en: Now, we link these blocks together with the help of the `LinkTo` methods. Here,
    we have an easy sequential data flow, but it is possible to create schemes that
    are more complicated. Here, we also provide `DataflowLinkOptions` with the `PropagateCompletion`
    property set to `true`. This means that when the step is complete, it will automatically
    propagate its results and exceptions to the next stage. Then, we start adding
    items to the buffer block in parallel, calling the block's `Complete` method,
    when we finish adding new items. Then, we wait for the last block to get completed.
    In the case of a cancelation, we handle `OperationCancelledException` and cancel
    the whole process.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用`LinkTo`方法将这些块连接起来。在这里，我们有一个简单的顺序数据流，但也可以创建更复杂的方案。在这里，我们还提供了`DataflowLinkOptions`，并将`PropagateCompletion`属性设置为`true`。这意味着当步骤完成时，它将自动将结果和异常传播到下一个阶段。然后，我们并行地向缓冲块添加项目，当我们完成添加新项目后，调用块的`Complete`方法。然后，我们等待最后一个块完成。在取消的情况下，我们处理`OperationCancelledException`并取消整个过程。
- en: Implementing Map/Reduce with PLINQ
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PLINQ实现Map/Reduce
- en: This recipe will describe how to implement the Map/Reduce pattern while using
    PLINQ.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱将描述如何在使用PLINQ的同时实现Map/Reduce模式。
- en: Getting ready
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To begin this recipe, you will need to run Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter10\Recipe4`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个食谱，你需要运行Visual Studio 2015。没有其他先决条件。这个食谱的源代码可以在`BookSamples\Chapter10\Recipe4`找到。
- en: How to do it...
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'To understand how to implement Map/Reduce with PLINQ, perform the following
    steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用PLINQ实现Map/Reduce，请执行以下步骤：
- en: Start Visual Studio 2015\. Create a new C# console application project.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Visual Studio 2015。创建一个新的C#控制台应用程序项目。
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program.cs`文件中，添加以下`using`指令：
- en: '[PRE9]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Add references to the `Newtonsoft.Json` NuGet package and the `System.Net.Http`
    assembly.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加对`Newtonsoft.Json` NuGet包和`System.Net.Http`组件的引用。
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下方添加以下代码片段：
- en: '[PRE10]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法内部添加以下代码片段：
- en: '[PRE11]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Add the following code snippet after the `Program` class definition:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program`类定义之后添加以下代码片段：
- en: '[PRE12]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Run the program.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `Map`/`Reduce` functions are another important parallel programming pattern.
    They are suitable for a small program and large multiserver computations. The
    meaning of this pattern is that you have two special functions to apply to your
    data. The first of them is the `Map` function. It takes a set of initial data
    in a key/value list form and produces another key/value sequence, transforming
    the data to a comfortable format for further processing. Then, we use another
    function, called `Reduce`. The `Reduce` function takes the result of the `Map`
    function and transforms it to the smallest possible set of data that we actually
    need. To understand how this algorithm works, let's look through the preceding
    recipe.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`Map`/`Reduce`函数是另一种重要的并行编程模式。它们适用于小型程序和大型多服务器计算。这种模式的意义在于，你拥有两个特殊函数可以应用于你的数据。第一个是`Map`函数。它接收一组以键/值列表形式存在的初始数据，并生成另一个键/值序列，将数据转换成便于进一步处理的形式。然后，我们使用另一个函数，称为`Reduce`。`Reduce`函数接收`Map`函数的结果，并将其转换为我们实际需要的最小数据集。为了理解这个算法是如何工作的，让我们回顾一下前面的食谱。'
- en: Here, we are going to analyze four classic books' text. We are going to download
    the books from the project Gutenberg's site ([www.gutenberg.org](http://www.gutenberg.org)),
    which can ask for a captcha if you issue many network requests and thus break
    the program logic of this sample. If you see HTML elements in the program's output,
    open one of the book URLs in the browser and complete the captcha. The next thing
    to do is to load a list of English words that we are going to skip when analyzing
    the text. In this sample, we try to load a JSON-encoded word list from GitHub,
    and in case of failure, we just get an empty list.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将分析四本经典书籍的文本。我们将从古腾堡计划网站([www.gutenberg.org](http://www.gutenberg.org))下载这些书籍，如果在发出大量网络请求时遇到验证码，可能会破坏本示例的程序逻辑。如果在程序的输出中看到HTML元素，请在浏览器中打开其中一个书籍URL并完成验证码。接下来要做的事情是加载一个我们将跳过分析文本的英文单词列表。在本示例中，我们尝试从GitHub加载一个JSON编码的单词列表，如果失败，我们只得到一个空列表。
- en: Now, let's pay attention to our `Map`/`Reduce` implementation as a PLINQ extension
    method in the `PLINQExtensions` class. We use `SelectMany` to transform the initial
    sequence to the sequence we need by applying the `Map` function. This function
    produces several new elements from one sequence element. Then, we choose how we
    group the new sequence with the `keySelector` function, and we use `GroupBy` with
    this key to produce an intermediate key/value sequence. The last thing we do is
    apply `Reduce` to the resulting grouped sequence to get the result.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们关注我们的`Map`/`Reduce`实现，作为`PLINQExtensions`类中的一个PLINQ扩展方法。我们使用`SelectMany`通过应用`Map`函数将初始序列转换为所需的序列。这个函数从一个序列元素中产生几个新元素。然后，我们使用`keySelector`函数选择如何对新的序列进行分组，并使用`GroupBy`和这个键来产生一个中间的键/值序列。最后，我们对结果分组序列应用`Reduce`以获得结果。
- en: Then, we run all our books processing in parallel. Each processing worker thread
    outputs the resulting information into a string, and after all workers are complete,
    we print this information to the console. We do this to avoid concurrent console
    output, when each worker text overlaps and makes the resulting information unreadable.
    In each worker process, we split the book text into a text lines sequence, chop
    each line into word sequences, and apply our `MapReduce` function to it. We use
    the `Map` function to transform each word into lowercase and use it as the grouping
    key. Then, we define the `Reduce` function as a transformation of the grouping
    element into a key value pair, which has the `Word` element that contains one
    unique word found in the text and the `Count` element, which has information about
    how many times this word has been used. The final step is our query materialization
    with the `ToList` method call, since we need to process this query twice. Then,
    we use our list of stop words to remove common words from our statistics and create
    a string result with the book's title, top 10 words used in the book, and a unique
    word's frequency in the book.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们并行运行所有书籍的处理过程。每个处理工作线程将结果信息输出到一个字符串中，当所有工作线程完成后，我们将这些信息打印到控制台。我们这样做是为了避免并发控制台输出，当每个工作线程的文本重叠时，会导致结果信息难以阅读。在每个工作进程中，我们将书籍文本分割成文本行序列，将每一行分割成单词序列，并对其应用我们的`MapReduce`函数。我们使用`Map`函数将每个单词转换为小写并用作分组键。然后，我们定义`Reduce`函数作为将分组元素转换为键值对的转换，其中包含一个包含在文本中找到的唯一单词的`Word`元素和一个包含有关该单词使用次数信息的`Count`元素。最后一步是通过调用`ToList`方法进行查询物化，因为我们需要处理这个查询两次。然后，我们使用我们的停用词列表从我们的统计数据中删除常见单词，并创建一个包含书籍标题、书籍中使用频率最高的10个单词以及书籍中唯一单词频率的字符串结果。
