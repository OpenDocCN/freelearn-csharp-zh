- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Entering Mixed Reality with the XR Interaction Toolkit
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 13*](B18347_13.xhtml#_idTextAnchor256), we made some changes to
    our 3D FPS game’s enemy NPCs. We upgraded them from 2D to 3D components while
    still using waypoints for navigation but utilized Unity’s NavMesh system to rapidly
    implement the patrolling behavior. We also enhanced the complexity of the NPC
    behavior by adding sensors that allow them to interact with the player and the
    environment in a more realistic way.
  prefs: []
  type: TYPE_NORMAL
- en: We continued by discussing how to create dynamic enemy behavior using our sensors
    as conditions within behavior trees. We then completed our AI discussion with
    an introduction to **machine learning** (**ML**) using Unity’s ML-Agents, which
    enables NPCs to learn and evolve. We can create remarkable experiences for our
    players by integrating advanced AI-based gameplay!
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll finish the journey that started with the 3D FPS game
    by creating the final boss room encounter in **mixed reality** (**MR**). We’ll
    accomplish this by using the **Unity XR Interaction Toolkit** along with assets,
    reusable components, and systems accumulated from previous efforts, all coming
    together to create a battle to take place in your own room!
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to MR and development frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing a boss room
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with AR planes (AR Foundation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Placing interactable objects in the world
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing the boss room mechanics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll be able to make an MR game or experience
    that incorporates the player’s physical space – such as walls, the floor, and
    tables – to create a novel experience for players. You’ll also learn how to create
    interactable objects and manage their instantiation, particularly with regard
    to detected surface planes that define the boundaries and objects of the physical
    space. The chapter completes the accumulation of knowledge required to rapidly
    build out features and behaviors when making games.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To follow along with this chapter, you’ll need a Meta Quest 2 or 3 headset and
    a USB-C cable to connect it to your computer. The cable lets you push the Unity
    project build to your device and test some functionality directly in the Unity
    Editor’s play mode.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t have an MR headset
  prefs: []
  type: TYPE_NORMAL
- en: 'You can still follow along in this chapter even without owning an MR headset
    – by using the Meta XR Simulator, available from the Unity Asset Store: [https://assetstore.unity.com/packages/tools/integration/meta-xr-simulator-266732](https://assetstore.unity.com/packages/tools/integration/meta-xr-simulator-266732).'
  prefs: []
  type: TYPE_NORMAL
- en: You can download the complete project from GitHub at [https://github.com/PacktPublishing/Unity-2022-by-Example](https://github.com/PacktPublishing/Unity-2022-by-Example).
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to MR and development frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Mixed reality** has only recently hit the forefront of what’s possible with
    the latest **head-mounted displays** (**HMDs**) to create environments where the
    physical and virtual worlds are blended to have digital and physical objects co-exist
    and appear to interact with one another. An MR gaming, educational, healthcare,
    or industrial application combines aspects of both **virtual reality** (**VR**)
    and **augmented reality** (**AR**) to offer an immersive experience where virtual
    content is anchored in the real world.'
  prefs: []
  type: TYPE_NORMAL
- en: One doesn’t need to look much further than popular VR adaptations of popular
    PC games such as **Skyrim VR** or **Resident Evil VR** to understand that VR-based
    technology has a strong outlook for the future of virtual entertainment. Additionally,
    games such as **Minecraft VR** and **Roblox VR**, with their enormous and engaged
    player base no less, offer immersive experiences that turn otherwise static surroundings
    into dynamic worlds that allow interaction and exploration in unprecedented ways
    never experienced before.
  prefs: []
  type: TYPE_NORMAL
- en: The breakout success of the original VR title **Beat Saber** also shows the
    diverse potential of the platform, not only for entertainment but also for physically
    involved gameplay. The future of VR, AR, and MR will continue to interest us,
    so let’s be sure we’re armed with the tools to succeed in this space.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll review the technology we’ll use to build our boss room
    game. The tech stack includes the Unity **XR Interaction Toolkit**, **AR Foundation**
    framework, and the **OpenXR** Meta package. These technologies on their own are
    powerful but combine one with another, and something new is created. They enable
    developers to create impressive MR experiences much more quickly when used in
    tandem.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s have a brief overview of each and see how they harmonize.
  prefs: []
  type: TYPE_NORMAL
- en: XR Interaction Toolkit (XRI)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unity’s XRI is a versatile interaction system for VR/AR that simplifies and
    streamlines cross-platform creation. It provides a common framework for various
    interactions such as poking, gazing (i.e., rays), and grabbing for controllers
    and hands. It also includes virtual hands, haptic feedback, and responses for
    selections using scaling, animation, or even blend shapes.
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | XR Interaction Toolkit (XRI)
  prefs: []
  type: TYPE_NORMAL
- en: 'XRI: [https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit%402.5/manual/index.xhtml](https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit%402.5/manual/index.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: 'XRI examples: [https://github.com/Unity-Technologies/XR-Interaction-Toolkit-Examples](https://github.com/Unity-Technologies/XR-Interaction-Toolkit-Examples).'
  prefs: []
  type: TYPE_NORMAL
- en: 'XR: [https://docs.unity3d.com/Manual/XR.xhtml](https://docs.unity3d.com/Manual/XR.xhtml).'
  prefs: []
  type: TYPE_NORMAL
- en: The XRI toolkit dramatically simplifies the process of developing interactive
    VR and AR experiences by providing a comprehensive set of interaction components
    and systems, minimizing the barrier to entry for developers looking to enter this
    space. It allows for easy implementation of common functions such as head tracking,
    locomotion (i.e., movement), object interactions, and the UI within the virtual
    space. The toolkit is also flexible and modular, which provides an excellent foundation
    for creating an MR game.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically for Unity 2022, Unity’s cross-platform MR development tools for
    the Meta Quest HMDs have moved from the experimental preview state to fully supported
    in the 2022 LTS release!
  prefs: []
  type: TYPE_NORMAL
- en: XRI provides the interaction part; now, let’s look at the environment part of
    these technologies.
  prefs: []
  type: TYPE_NORMAL
- en: AR Foundation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unity’s AR Foundation is a cross-platform framework that provides a unified
    API for simplifying building applications for mobile and head-worn AR/MR devices.
    The package is designed to work natively with XRI (and XR Hands), significantly
    reducing any hurdles for developers accessing the specific device features to
    support building AR applications.
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | AR Foundation
  prefs: []
  type: TYPE_NORMAL
- en: 'AR Foundation: [https://unity.com/unity/features/arfoundation](https://unity.com/unity/features/arfoundation)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unity documentation: [https://docs.unity3d.com/Packages/com.unity.xr.arfoundation%405.1/manual/index.xhtml](https://docs.unity3d.com/Packages/com.unity.xr.arfoundation%405.1/manual/index.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, AR Foundation is the layer that unifies **ARCore** (Google)
    and **ARKit** (Apple) APIs into a single higher-level API. This single API allows
    developers to write code once where the specific feature implementations of the
    underlying platforms are handled automagically.
  prefs: []
  type: TYPE_NORMAL
- en: AR Foundation simplifies building spatial awareness into applications, making
    digital objects appear interactable with the real world. This is crucial for creating
    MR experiences that seamlessly blend the virtual and the real world.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll be working specifically on the **Meta Quest HMD** platforms. Our boss
    room game will be compatible with Quest 2 and Quest 3 devices. The AR Foundation
    support for Meta Quest is built using a familiar industry-adopted standard interface
    for XR hardware and software, and that interface is called **OpenXR**.
  prefs: []
  type: TYPE_NORMAL
- en: AR Foundation provides the visual part; now, let’s look at the platform support
    part of these technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenXR: Meta package'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**OpenXR** is an open, royalty-free standard that enables high-performance
    access via a unified interface across multiple AR and VR hardware and software
    platforms and devices, collectively known as XR.'
  prefs: []
  type: TYPE_NORMAL
- en: Developing with OpenXR simplifies the development process by allowing developers
    to target any supporting OpenXR system without worrying about specific platform
    details. The Meta package (available since Unity 2022.3.11.f1) contains **Meta-specific
    OpenXR** extensions and Meta’s **AR Foundation provider plugin** for its Quest
    devices – it ensures compatibility and interoperability between the software and
    hardware to support its specific input devices, head-mounted displays, and other
    peripherals.
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | OpenXR
  prefs: []
  type: TYPE_NORMAL
- en: 'Kronos Group: OpenXR: [https://www.khronos.org/openxr/](https://www.khronos.org/openxr/)'
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, OpenXR is the glue that binds the interaction and visual systems
    to any supporting hardware devices – especially new devices that feature better
    graphics performance and sensors. The trio of technologies, when combined, enable
    developers to rapidly create prototypes and deploy production-ready MR games and
    experiences – XRI provides the foundation for interactive elements, AR Foundation
    builds on the ability to merge digital and physical-world visuals, and OpenXR
    ensures the experiences are accessible across different devices.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – Unity XR tech stack](img/B18347_14_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.1 – Unity XR tech stack
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned what Unity MR technologies are available to us and
    that this combination of MR-based technologies not only simplifies development
    but also enables the creation of complex, engaging MR applications to have broad
    end-user reach. This brings us right into the next section, where we’ll get down
    to the business of designing our MR boss room.
  prefs: []
  type: TYPE_NORMAL
- en: Designing a boss room
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Designing a boss room encounter is a critical part of game creation that combines
    aspects of narrative, mechanical, and environmental considerations to create an
    engaging and challenging experience for players.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several key areas to consider when designing a boss room encounter,
    and we’ll take a shallow dive into a few:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Narrative element**: The encounter should feel like a natural progression
    or even the story’s climax.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Boss mechanics**: The player’s battle with the boss element should stand
    out as a unique experience, separate from the player mechanics mainly being used,
    requiring players to adapt a strategy to overcome attack patterns and other behaviors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Environment design**: The layout of the boss room itself should complement
    the narrative and mechanics being implemented. This is a special consideration
    for MR because we’ll use the player’s own room (i.e., their physical space) to
    construct the gameplay environment and place the interactive elements, creating
    a novel challenge for each player.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Balancing**: Challenges presented by boss encounters should be demanding
    yet feel pretty balanced to avoid undue frustration while still providing a solvable
    challenge for the player.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By incorporating these elements into our boss room, we aim to offer players
    an enjoyable and unforgettable experience. Overcoming the *boss challenge* will
    give them a sense of satisfaction and accomplishment. Moreover, with MR included
    in our case, the experience becomes even more remarkable and rewarding.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s revisit our GDD for a moment to get a quick update for the boss room battle
    added that will provide the context we’ll follow when setting up our scene.
  prefs: []
  type: TYPE_NORMAL
- en: '| **What is the habitat interior’s** **boss encounter?** | In the game’s climax,
    players must infiltrate a heavily guarded central control room to re-energize
    the reactor that’s been turned off – its crystal modules have been ejected – by
    the evil alien plant entity that has taken over. The outcome of this battle will
    determine the future of the Kryk’zylx race on the planet. |'
  prefs: []
  type: TYPE_TB
- en: Table 14.1 – GDD snippet setting the scene for the boss battle
  prefs: []
  type: TYPE_NORMAL
- en: 'Very nice. The context has been set, and we have some story background for
    the purpose of the boss battle. You are not just some kid from a trailer park;
    you are a Kryk’zylx scout! As such, you are armed with the most advanced energy-based
    weaponry, such as this laser pistol: pew-pew!'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – XR interactable gun](img/B18347_14_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – XR interactable gun
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by first defining our physical space, then move on to creating the
    Unity project and testing our MR setup.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the physical space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Properly defining the physical space set up on the device for an MR game is
    of utmost importance, as it directly impacts the possibilities available in the
    immersive experience. It seamlessly blends virtual content, such as the horizontal
    AR surface planes defined for walls, the floor, the ceiling, tables, and seats,
    in addition to vertical AR surface planes, such as doors and windows. Having these
    virtual surface objects in place for their real-world counterparts enhances gameplay,
    ensures safety, and maximizes the player’s engagement. The physical space environment
    setup also serves as an interactive canvas for the game developer’s storytelling
    and exploration.
  prefs: []
  type: TYPE_NORMAL
- en: For Meta Quest 3, the headset includes a depth sensor to scan your room surroundings
    and detect the floor, walls, and ceiling to establish a starting point for your
    physical space setup. Once you’ve finished the room scan, you can manually confirm
    the walls and add furniture.
  prefs: []
  type: TYPE_NORMAL
- en: For Meta Quest 2, you’ll have to set up your physical space entirely manually.
  prefs: []
  type: TYPE_NORMAL
- en: Meta Quest room setup
  prefs: []
  type: TYPE_NORMAL
- en: For plane detection to function correctly on a Meta Quest device, you must first
    complete the new **Room Setup** feature found in **Settings** | **Physical Space**
    | **Space Setup** on the Quest headset before entering an MR game. To ensure optimal
    performance, it’s also recommended to include at least one piece of furniture
    with a horizontal surface, such as a table.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the MR game we’ll create relies on providing examples for the
    different surface planes established by either the physical scan or manual space
    setup. You must ensure your room includes at least four walls and a table.
  prefs: []
  type: TYPE_NORMAL
- en: You can perform the room setup any time before running an MR game or experience,
    so you can do this at your leisure. But for now, we’ll move on to creating and
    setting up our Unity project to get started with our boss room battle.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Unity project
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Install the latest Unity 2022.3 LTS release if you haven’t already – this is
    so we have access to the new VR and MR templates in **Unity Hub**. We’ll also
    require the **Android Build Support** module to be available, so ensure you have
    that, along with the **OpenJDK** and **Android SDK & NDK Tools** modules installed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.3 – Install the Android Build Support module](img/B18347_14_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.3 – Install the Android Build Support module
  prefs: []
  type: TYPE_NORMAL
- en: With the minimum required Unity Editor version and Android dependency modules
    now installed, we’re ready to rapidly set up our MR boss room project using Unity’s
    new **Mixed Reality** (Core) template. It’s built upon the core MR technologies
    outlined in the *Introduction to MR and development frameworks* section. How very
    convenient!
  prefs: []
  type: TYPE_NORMAL
- en: The MR template project simplifies XR development by streamlining the implementation
    of advanced features such as plane detection, device passthrough, and spatial
    UI creation alongside designer-friendly XR interactable components. It comes pre-configured
    with essential packages such as XRI, AR Foundation, Unity OpenXR Meta, and XR
    Hands, making project setup and package management a breeze. This MR project template
    approach targets the needs of MR creators for richer content and reduces developer
    friction in accessing advanced MR features.
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | Unity MR template
  prefs: []
  type: TYPE_NORMAL
- en: 'Mixed Reality Template Quick Start Guide: [https://docs.unity3d.com/Packages/com.unity.template.mixed-reality%401.0/manual/index.xhtml](https://docs.unity3d.com/Packages/com.unity.template.mixed-reality%401.0/manual/index.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Explore cross-platform MR development on Meta Quest 3: [https://blog.unity.com/engine-platform/cross-platform-mixed-reality-development-on-meta-quest-3](https://blog.unity.com/engine-platform/cross-platform-mixed-reality-development-on-meta-quest-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Open Unity Hub and click the **New Project** button (top-right corner) to create
    a new project. Then, referring to *Figure 14**.4*, follow these steps.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure the Unity 2022.3 LTS version previously installed is selected in the
    **Editor Version** dropdown at the top.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the center template list, scroll down and select **Mixed** **Reality** (Core).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the right pane, if you’re prompted with a **Download template** button, click
    to download the template.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the template finishes downloading, provide these options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`MR` `Boss Room`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Location**: Select the folder path for where to store your project files.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unity Cloud Organization**: You must select the organization to which this
    project will belong. When you create a new Unity ID account, Unity generates an
    organization associated with your username and ID. The base feature a Unity organization
    provides is the ability to organize your projects, services, and licenses.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Connect to Unity Cloud**: Only enable this if you wish to take advantage
    of gaming services for your project (generally, yes, you’ll want this).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use Unity Version Control**: Enable this option if you want to have Unity
    Cloud’s **version control system** (**VCS**) back up your project to the cloud
    and allow additional team members to collaborate on the project (we’ll cover Unity
    Version Control in [*Chapter 15*](B18347_15.xhtml#_idTextAnchor301)).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 14.4 – New Mixed Reality project from a template](img/B18347_14_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.4 – New Mixed Reality project from a template
  prefs: []
  type: TYPE_NORMAL
- en: To start creating the project, click the **Create project** button and relax
    for a few minutes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s finalize some essential setup steps once the project opens in the Unity
    Editor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open **File** | **Build Settings…** and follow these steps to configure the
    platform to support building to our Meta Quest device:'
  prefs: []
  type: TYPE_NORMAL
- en: Select **Android** in the **Platform** list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **ASTC** from the **Texture** **Compression** dropdown.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **Switch** **Platform** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Done!
  prefs: []
  type: TYPE_NORMAL
- en: ASTC
  prefs: []
  type: TYPE_NORMAL
- en: '**Adaptable Scalable Texture Compression** (**ASTC**) is a texture compression
    method that uses variable block sizes instead of a single fixed size and replaces
    older formats while also providing additional features.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now open the `SampleScene` scene located in the `Assets/Scenes` folder
    to examine the scene setup, including the following GameObjects responsible for
    managing the XR features, including controller and hand tracking, interaction
    with the UI and virtual objects, and AR features such as surface plane detection
    and passthrough: **MR Interaction Setup**, **UI**, and **Environment**.'
  prefs: []
  type: TYPE_NORMAL
- en: Universal RP renderer settings
  prefs: []
  type: TYPE_NORMAL
- en: Please note that the Meta Quest headset is sensitive to the Unity renderer settings
    being correctly configured for the platform. Therefore, I suggest keeping the
    URP renderer and quality settings at the default values provided by the MR project
    template (unless you really know what you’re doing).
  prefs: []
  type: TYPE_NORMAL
- en: 'Also note that standalone VR hardware, such as the Quest, requires additional
    consideration for performance optimization to sustain a minimum FPS (typically,
    not less than 72 FPS): this is to prevent vection (the visual perception of motion
    while the body is still), which can make people nauseous.'
  prefs: []
  type: TYPE_NORMAL
- en: With your Quest headset attached to your system with the USB-C cable, you can
    verify the device is recognized by Unity by going to the **Build Settings** window
    with the **Android** platform selected, in the **Run Device** field, and clicking
    the dropdown that currently shows **Default device**. Your Meta/Oculus Quest 3
    (or 2) device should be listed there.
  prefs: []
  type: TYPE_NORMAL
- en: Testing in Play Mode with Quest Link
  prefs: []
  type: TYPE_NORMAL
- en: To thoroughly test and play our game, we must build to the device because plane
    detection and passthrough are currently not supported with Quest Link when entering
    Play Mode in the Unity Editor. I would still recommend leveraging Quest Link for
    rapidly iterating on setting up object interactions independent of the gameplay
    and then building to the device for complete gameplay testing.
  prefs: []
  type: TYPE_NORMAL
- en: To use Quest Link, ensure you are connected to your system with the USB-C cable
    and have the Oculus app (Meta Quest Link) running, then click the Quest Link button
    on the Quest headset’s **Quick Settings** menu. Once established, you can enter
    Play Mode in Unity to playtest your scene.
  prefs: []
  type: TYPE_NORMAL
- en: Now, still in the **Build Settings** window, click **Build And Run**, or press
    *Ctrl/Cmd* + *B* and pop on that headset!
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: It’s vital to recenter or reset your orientation when you begin a MR environment.
    This ensures that virtual objects are placed correctly about your current position
    and facing direction. Doing this will enhance your experience, especially as device
    orientation detection technology continues to improve.
  prefs: []
  type: TYPE_NORMAL
- en: The MR template is configured to use either controllers or hands. Still, we’ll
    focus on using the controllers for our game, so I’d recommend you play around
    with using the controllers as input in the sample project.
  prefs: []
  type: TYPE_NORMAL
- en: This verifies your Quest headset device and Unity MR project setup for XR development
    are ready. So, let’s start building out the boss room!
  prefs: []
  type: TYPE_NORMAL
- en: Laying out the boss room scene
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: According to our GDD, we must clear the central control system from the evil
    plant entity infestation. So, to do that, we need to energize the sabotaged control
    console and restart the reactor (yes, believe me, that will do the trick). Therefore,
    the boss room’s layout requires objects related to this context to be present
    in our scene.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the objects we’ll need for our boss room setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Control console**: Maintains the state of all the habitation station’s primary
    systems, including the main power reactor. It has three crystal module slots for
    energizing the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Power reactor**: Provides power to the central systems, especially the ones
    in charge of environmental control and eradicating foreign entities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Corridors**: The habitat station comprises several rooms and connecting corridors
    – this should already be familiar from the 3D FPS project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are the primary objects we need in our scene, which, again, is your room,
    to provide the setting for the boss encounter. We’ll construct the layout to have
    the control console near the player and virtual corridors extending from the center
    of the room, providing a central focal point for the action.
  prefs: []
  type: TYPE_NORMAL
- en: With this layout in mind, in the following screenshot – from a Quest 3 with
    a passthrough visible – we can see the objects instantiated in this fashion in
    a real-world room.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.5 – Virtual objects spawned in a physical space](img/B18347_14_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.5 – Virtual objects spawned in a physical space
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first duplicate the provided MR template’s sample scene to start setting
    up the scene:'
  prefs: []
  type: TYPE_NORMAL
- en: Find the `SampleScene` scene in the `Assets/Scenes` folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Duplicate it by selecting and pressing *Crtl/Cmd* + *D*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename it to `Boss Room`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, open the scene, and we’ll deactivate some example content provided in
    the scene Hierarchy that we won’t use. Select and deactivate the following objects
    (using the checkbox at the top of the Inspector to the left of the object’s name):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Disable these two child objects of `MR` `Interaction Setup`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Goal Manager`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Object Spawner`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Disable these two child objects of `UI`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Coaching UI`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Hand` `Menu Setup`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Save the scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We’re done! We now have an empty scene with all the XR setup ready for us to
    create our MR game. Easy-peasy.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered the fundamental principles of designing a boss room
    and the steps required to set up our physical space with our Quest devices. Additionally,
    we learned how to create a basic starting project using Unity’s MR template and
    configuring it for our use.
  prefs: []
  type: TYPE_NORMAL
- en: When creating the virtual objects that construct our boss room, we use AR surface
    planes representing real-world objects in our physical space to spawn them dynamically.
    Let’s explore how to spawn virtual objects using detected AR planes next.
  prefs: []
  type: TYPE_NORMAL
- en: Working with AR planes (AR Foundation)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AR planes are virtual representations of flat planar surfaces, both horizontal
    and vertical, represented by dimensions and boundary points and detected by the
    AR Foundation technology. The planes provide a foundation for accurately placing
    digital objects and interacting with the surfaces.
  prefs: []
  type: TYPE_NORMAL
- en: As previously mentioned, these planes represent the walls, floor and ceiling,
    tables, and so on, and we’ll use the walls, floor, and table specifically in this
    example boss room to blend the gameplay seamlessly with the player’s physical
    surroundings.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: '**AR Plane Manager** allows you to specify a prefab for plane visualization.
    The **AR Plane** Prefab, provided by the MR template, uses a shader that occludes
    objects assigned a material with transparency, so if you want objects that are
    meant to be seen past the AR planes, ensure you don’t use a transparent material.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s start working with our first horizontal plane type, the table, to
    see how we can detect the plane type and use its properties to spawn an object.
  prefs: []
  type: TYPE_NORMAL
- en: Spawning using planes with AR Plane Manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `AR Plane Manager` component, located on the `XR Origin (XR Rig)` object
    as a child of the `MR Interaction Setup` root object, is responsible for the detection
    of the horizontal and vertical surfaces in the physical space and creates the
    virtual plane objects (`AR Plane` Prefab) that our virtual content can be placed
    and interacted with.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization note
  prefs: []
  type: TYPE_NORMAL
- en: With **AR Plane Manager**, in addition to specifying the **AR Plane** Prefab,
    you can choose between horizontal, vertical, or both for **Detection Mode**. Turning
    off vertical plane detection is recommended if you only need to detect horizontal
    planes.
  prefs: []
  type: TYPE_NORMAL
- en: One of the first things we’ll have to do is enable the `AR Plane Manager` component
    because it is deactivated by default within the MR sample scene. We’ll do that
    with our first script, the game manager.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new script named `GameManager` in the `Assets/Scripts` folder, and
    start with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now, create a GameObject in the scene and attach this script to it. As you can
    see, we’ve changed the method signature for the `Start()` method to be an `IEnumerator`
    (yes, you can do that), and we’ve delayed the execution of the `EnablePlaneManager()`
    method call for 2 seconds (to give XR components time to initialize).
  prefs: []
  type: TYPE_NORMAL
- en: 'Assign `_planeManager` in the Inspector by dragging in the `XR Origin (XR Rig)`
    object to the field on the `GameManager` component. We’re enabling the component
    in the `EnablePlaneManager()` method like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can now playtest the boss room scene by first ensuring the scene is added
    to **Scenes in Build** in the **Build Settings** window, connecting your Quest
    device to your system via the USB-C cable, and clicking **Build And Run** (*Ctrl/Cmd*
    + *B*, i.e., *build* *and run)*.
  prefs: []
  type: TYPE_NORMAL
- en: You should see something similar to the following figure, where the detected
    planes for the walls, floor and ceiling, and any horizontal surfaces such as tables
    have a fading dotted material. Note that I’ve manually added the magenta lines
    for better visibility of the planar surfaces (which include a table, the walls,
    and the floor).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.6 – Detected surface planes in the room](img/B18347_14_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.6 – Detected surface planes in the room
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve verified we have planes to work with, let’s start spawning in
    our virtual objects for the boss room.
  prefs: []
  type: TYPE_NORMAL
- en: Instantiating on a table plane
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Whoa, wait a second… we need the objects we’ll be spawning into the room. We
    can thank **Polypix Studios** again for providing 3D art for these assets: console,
    module, reactor, corridor, gun, and hover bot.'
  prefs: []
  type: TYPE_NORMAL
- en: Boss room virtual objects
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download **VirtualObjects-start.zip** from the book’s GitHub repo here:
    [https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Art-Assets](https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Art-Assets).'
  prefs: []
  type: TYPE_NORMAL
- en: Unzip the file to get the '**.unitypackage**' file and import it into your project
    – you can do that by dragging and dropping the file from your system’s file manager
    to Unity’s **Project** window.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first asset we’ll work with is the reactor model imported as the `Reactor`
    Prefab in the `Assets/Prefabs` folder, as seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.7 – Boss room 3D asset Prefabs](img/B18347_14_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.7 – Boss room 3D asset Prefabs
  prefs: []
  type: TYPE_NORMAL
- en: And we’ll spawn the `Reactor` Prefab on the first table detected in the room.
  prefs: []
  type: TYPE_NORMAL
- en: '`AR Plane Manager` provides a `planesChanged` event that we’ll subscribe to,
    and when a `PlaneClassification` is of the `Table` type, we know we should spawn
    the reactor. So, let’s add the listener in our `GameManager` class and the handler
    method for spawning the object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Don’t forget to unsubscribe from the listener in `OnDisable()` or `OnDestroy()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, add the handler method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, you can see we loop through all the detected planes (`ARPlane` type)
    provided by the handler’s `args` parameter with a `foreach` statement. Then, the
    `switch` statement allows us to work with the specific plane classification for
    our needs, which, again, is `Table`. We use a helper `SpawnPrefab()` method, which
    performs the instantiation – passing in the specific plane and Prefab:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You can see we’re using the regular `Instantiate()` method and the plane’s `position`
    and `rotation` values for the point of instantiation.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure we’re only spawning one reactor in the scene, if the physical space
    has multiple table surfaces defined, we’ll use the `_hasSpawnedPrefab_Reactor`
    Boolean to limit it to one and call the `SpawnPrefab()` method, specifying the
    `ARPlane` and `Reactor` Prefab as the parameters. Setting `_hasSpawnedPrefab_Reactor`
    to `true` after calling the spawn method ensures only one Prefab is spawned.
  prefs: []
  type: TYPE_NORMAL
- en: You must ensure you’ve declared the variables to assign the `Reactor` Prefab
    and *has spawned* bool. Then, assign the `Reactor` Prefab from the `GameManager`
    field in the Inspector.
  prefs: []
  type: TYPE_NORMAL
- en: If you build and run the project on your device now, you should see the reactor
    appear on your table!
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.8 – The reactor Prefab spawned on the table plane](img/B18347_14_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.8 – The reactor Prefab spawned on the table plane
  prefs: []
  type: TYPE_NORMAL
- en: Enabling passthrough
  prefs: []
  type: TYPE_NORMAL
- en: If you want to temporarily skip ahead to see the virtual objects sitting in
    your real-world surroundings, we’ll need to toggle the passthrough to be visible.
    In the *Toggling MR visuals with XR Input section*, we’ll add the ability to toggle
    passthrough visibility.
  prefs: []
  type: TYPE_NORMAL
- en: That takes care of demonstrating how to instantiate an object on the table plane.
    Let’s move on to spawning on the floor plane next.
  prefs: []
  type: TYPE_NORMAL
- en: Instantiating using the floor plane
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike the reactor’s placement, we’ll prioritize the orientation of the controller
    console object relative to the player’s forward direction (when the planes are
    detected) to ensure immediate interaction availability for the player.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process is relatively the same, except for said orientation. So, let’s
    first add to our `switch (plane.classification)` block to handle the `Floor` classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We have a similar Boolean check to ensure we don’t have multiple control consoles
    spawned into the room with the `_hasSpawnedPrefab_Console` variable and a method
    overload for `SpawnPrefab()`. The new spawn method signature takes an additional
    parameter for an offset – and we’ll assume that the offset is from the player’s
    location.
  prefs: []
  type: TYPE_NORMAL
- en: 'The new spawner method with the offset looks like the following – add it to
    the `GameManager` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The points of interest in the new spawn method are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`playerTransform`: We get the player’s current position in the world from the
    main camera, which is attached to `XR Origin (XR Rig)` to represent the player’s
    head.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`playerTransform.position`: We apply a new `Vector3` Y-value to `playerTransform`
    to anchor the instantiated model to the floor plane (its Y-value).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`worldOffset`: We take the player offset value provided and use the `TransformDirection()`
    method to ensure the player offset will be applied in the appropriate world space
    coordinates – there is no way we could know the world coordinates to pass into
    the spawn method since it is relative to the player’s current position.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spawnRotation`: We want to ensure the console faces the player when instantiated,
    so we use `Quaternion.LookRotation()` to accomplish that.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We finish by just calling the `Instantiate()` method, like before. Add the required
    variables and make the Inspector assignments. Then, save your changes and go ahead
    and do another *build and run* to see the console in your room. An example of
    the console placement can be seen in the virtual objects spawned into the actual
    room in the *Figure 14**.5*.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, we’re making great progress on the boss room layout! The last environmental
    object to get into our room is the corridor, which will virtually extend the reality
    of the room and set the stage for our enemy hover bots to engage the player.
  prefs: []
  type: TYPE_NORMAL
- en: Instantiating with wall planes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our last AR-detected plane instantiation example will still be relatively the
    same as the previous two, except we now have to account for spawning an object
    relative to a vertical surface. This will require a bit of additional care during
    positioning because the plane anchors are located in the center of the plane’s
    surface object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, we have access to all the basic `Bounds` properties, such as `extents`,
    but we still need the surface extent and orientation. So, let’s first add to our
    `switch (plane.classification)` block to handle the `Wall` classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: You can see the same pattern here as before, using the Boolean to determine
    whether we’ve spawned the corridor Prefab already and calling a spawn Prefab method,
    passing in just the plane and the Prefab again this time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `SpawnPrefabAtWallBase()` method looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Just a bit more calculation is required here to ensure we are anchoring the
    Prefab’s instantiation point to the vertical bottom of the surface plane – at
    the same Y-value as the floor – by using `plane.extents` and subtracting from
    the plane’s transform position (at the center of the plane).
  prefs: []
  type: TYPE_NORMAL
- en: For the rotation of the spawned Prefab, we’ll again use `LookRotation()`, but
    this time, instead of using the *direction to player* vector, we’ll use the plane’s
    surface normal vector. The plane’s surface normal is pointing away from the center
    of the room, so we want to invert it for the instantiation of the corridor Prefab
    that has its forward direction looking down the corridor (for your own 3D models,
    you can invert either the normal vector or rotate the pivot’s forward direction
    for the correct orientation).
  prefs: []
  type: TYPE_NORMAL
- en: Again, add the required script variables, save the script, make the corridor
    Prefab assignment to the field on `GameManager`, save your scene, and build and
    run the app to test the placement of the corridor addition to the boss room.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the layout of the boss room completed, with all the elements
    required for the battle, let’s see how we can work with the MR visuals to set
    a proper gameplay experience without AR planes being visible and passthrough enabled.
  prefs: []
  type: TYPE_NORMAL
- en: Toggling MR visuals with XR Input
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You know how much of a fan I am of reusable components to build out functionality
    that is also designer-friendly in our games. So, let’s approach input from our
    XR controllers similarly by adding an *on button press* component that relies
    on an `InputAction` input signal (courtesy of the new Input System) to identify
    the button presses.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get the `OnButtonPress` script file from the GitHub repo here: [https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Code-Assets](https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Code-Assets),
    then import it into your project in the `Assets/Scripts/Interaction` folder.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re going to wire up buttons for the following in-game actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Right controller, primary button (**A**) à Toggle passthrough visibility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Right controller, secondary button (**B**) à Toggle AR plane surfaces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Left controller, primary button (**X**) à Start game.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s see what the buttons for the Oculus controllers with Unity’s **XR Input**
    mappings look like in the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.9 – Oculus XR controller button mapping](img/B18347_14_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.9 – Oculus XR controller button mapping
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | XR Input
  prefs: []
  type: TYPE_NORMAL
- en: 'Unity XR Input mappings: [https://docs.unity3d.com/Manual/xr_input.xhtml#XRInputMappings](https://docs.unity3d.com/Manual/xr_input.xhtml#XRInputMappings)'
  prefs: []
  type: TYPE_NORMAL
- en: Okay, simple enough. Let’s start by wiring up the passthrough visibility toggle
    for when the **A** button is pressed.
  prefs: []
  type: TYPE_NORMAL
- en: Toggling passthrough
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The MR template showcases the ability to switch between the virtual environment
    and device passthrough. This is achieved by using a simple fade transition on
    an environment mesh. The mesh employs a vertex color **ShaderGraph**, which has
    an alpha property that can be smoothly transitioned.
  prefs: []
  type: TYPE_NORMAL
- en: We don’t even have to write a script to perform the fade transition. The MR
    template’s `Environment` Prefab already includes a `FadeMaterial` component with
    an exposed public method for fading!
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s hook into it quickly to toggle the fade, starting with making a new
    controller script named `SceneController` in the `Assets/Scripts` folder with
    the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Save the script and add it to the `GameManager` object. As you can see, we’ll
    use a `UnityEvent` to assign the reference to the `FadeMaterial` function, passing
    a Boolean parameter representing the visible state to fade to.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assign the `OnTogglePassthrough(Boolean)` callback in the Inspector and
    then finish by adding the toggle logic code afterward. So, start by clicking the
    **+** icon to add a new event callback entry. Then, using *Figure 14**.10* as
    a reference, find the **UI** | **Environment** object in the scene Hierarchy and
    drag it to the **Object** field.
  prefs: []
  type: TYPE_NORMAL
- en: Now, select the `FadeMaterial.FadeSkybox` function at the top in the `UnityEvent`’s
    `bool` parameter when the event is invoked.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.10 – SceneController component setup](img/B18347_14_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.10 – SceneController component setup
  prefs: []
  type: TYPE_NORMAL
- en: 'All that’s left to do is invoke the `OnTogglePassthrough` event when the player
    presses the right controller’s primary button (`SceneController` class for that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Straightforward, single-responsibility, and well-named methods. Add the private
    member variable `_isPassthroughVisible` for keeping track of the current toggle
    state, which defaults to `false` and is the correct default passthrough state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, referring to *Figure 14**.10* for these steps, to receive the player
    input when the controller’s button is pressed, let’s use the `OnButtonPress` component
    with the input action configured for the **A** button:'
  prefs: []
  type: TYPE_NORMAL
- en: Add the `OnButtonPress` component to the `SceneController`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **+** dropdown, then **Add binding**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Double-click **<****No Binding>**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Path** dropdown, select **XR Controller** | **XR Controller (Right
    Hand)** | **Optional Controls** | **primaryButton**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternatively, enter the following text (click the `<XRController>{RightHand}/primaryButton.`
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, assign the `OnPress()` `UnityEvent` function to `SceneController.TogglePassthrough`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Doing a *build and run* to your device now, you can toggle the passthrough visibility
    by pressing the **A** button on your right controller. This will be your first
    time seeing the boss room’s digital objects spawned within your real-world space
    – pretty awesome, right?
  prefs: []
  type: TYPE_NORMAL
- en: Camera setup to support passthrough
  prefs: []
  type: TYPE_NORMAL
- en: The MR template’s main camera comes preconfigured to enable device passthrough,
    but it’s worth mentioning the setup. The camera’s background type is **Solid Color**
    with the background color set to black, with **0** alpha. The **AR Camera Manager**
    component is also explicitly included to control passthrough on Meta Quest devices.
  prefs: []
  type: TYPE_NORMAL
- en: Passthrough, check! Now, let’s see about toggling the AR plane visibility when
    the **B** button is pressed.
  prefs: []
  type: TYPE_NORMAL
- en: Toggling AR plane visibility
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It shouldn’t be any surprise that we’ll mimic the passthrough toggle setup.
    We’ve already seen how to reference and use the `AR Plane Manager` to spawn the
    virtual objects for the different plane classifications. Well, we’ll be using
    it again here to access the current set of **trackables**.
  prefs: []
  type: TYPE_NORMAL
- en: A trackable is a component that represents AR objects detected in the real world.
    Examples include planes (you’re already familiar with these), point clouds, anchors,
    environment probes, faces, bodies, images, and 3D objects.
  prefs: []
  type: TYPE_NORMAL
- en: Trackables (AR Foundation)
  prefs: []
  type: TYPE_NORMAL
- en: 'Trackables and trackable managers: [https://docs.unity3d.com/Packages/com.unity.xr.arfoundation%405.1/manual/architecture/managers.xhtml#trackables-and-trackable-managers](https://docs.unity3d.com/Packages/com.unity.xr.arfoundation%405.1/manual/architecture/managers.xhtml#trackables-and-trackable-managers)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by adding the following toggle code to the `SceneController` class
    for plane visibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `foreach` loop in the `SetPlaneVisible()` method is responsible for implementing
    the fade on the planes found while iterating the trackable collection based on
    finding a `FadePlaneMaterial` component. If found, we simply call that plane’s
    `FadePlane()` method. The `FadePlaneMaterial` component provides us with the MR
    template’s `AR Plane` Prefab. Easy-peasy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s hook it up now to the controller button press – which will be the right
    controller’s secondary button (**B**):'
  prefs: []
  type: TYPE_NORMAL
- en: Add another `OnButtonPress` component to the `GameManager` object (just below
    the previous `OnButtonPress` component).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the **+** dropdown, then **Add binding**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Double-click **<****No Binding>**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the **Path** dropdown, select **XR Controller** | **XR Controller (Right
    Hand)** | **Optional Controls** | **secondaryButton**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternatively, enter the following text (click the `<XRController>{RightHand}/secondaryButton.`
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, assign the `OnPress()` `UnityEvent` function to `SceneController.` `TogglePlaneVisibility`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Doing a *build and run* to your device now, you can toggle the AR plane visibility
    by pressing the **B** button on your right controller. Toggling the plane visibility
    will mostly serve the purpose of debugging; in case objects spawn in unexpected
    ways, you can verify the plane detected in the physical space (any that do might
    indicate you need to revisit your Quest headset’s **Room** **Setup** configuration).
  prefs: []
  type: TYPE_NORMAL
- en: Mixed Reality template script fix!
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, the **/Assets/MRTemplateAssets/Scripts/FadePlaneMaterial.cs**
    script has an error with the **FadePlane()** method that must be corrected for
    the planes to fade in and out correctly after first being called in its **Awake()**
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'On *line 91*, within the **FadeAlpha()** method, replace the **k_DotViewRadius**
    variable with **k_Alpha**. The line should now read: **rend.material.SetFloat(k_Alpha,
    alphaValue);**.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that we’ll turn off the plane visibility when we start the game. Speaking
    of… let’s wire up starting the game now.
  prefs: []
  type: TYPE_NORMAL
- en: Starting the game
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Offering players a choice to start a game via a button or menu selection creates
    a sense of control and anticipation. In contrast, for MR and even VR, an automatic
    game start can be disorienting or, worse, jarring. Well, that is, unless you want
    to be hostile and throw players directly into unforgiving action without warning
    (ahem, *Dark Souls*, I see you).
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned, we won’t be so cruel and will provide a button press for the
    player to enter the MR environment to start the game. With that in mind, we need
    to make some additions to the `GameManager` class. Let’s add the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Here, we’re just getting a reference to the `SceneController` sibling component.
    Go ahead and add a `[RequireComponent]` attribute for the `SceneController` component,
    too.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the `StartGame()` method we’ll call from the button press:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we’ll do with the `EnablePlaneManager()` call is to enable the
    plane manager to spawn the virtual objects that make up our boss room game. We’ll
    then use a coroutine to delay calling the local `DelayStartGame()` function by
    1.5 seconds, setting planes invisible and the passthrough visible – this will
    ensure we see the virtual objects unobstructed in our real-world space.
  prefs: []
  type: TYPE_NORMAL
- en: Remove the IEnumerator Start() method
  prefs: []
  type: TYPE_NORMAL
- en: Don’t forget, we’ll have to remove the **Start()** method we started with to
    set up the object spawning in the earlier *Spawning using planes with AR Plane
    Manager* section. We’re now going to wait until the player presses the button
    to start the game to enable spawning the virtual objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, let’s finish things up by adding the **X** button press to start the
    game by following these steps again – but simplified this time (you got this):'
  prefs: []
  type: TYPE_NORMAL
- en: Add another `OnButtonPress` component to the `GameManager` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign input action binding for the XR left-hand controller’s primary button
    (`<XRController>{LeftHand}/primaryButton`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign the `OnPress()` function to `GameManager.StartGame`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This time, when you *build and run*, you’ll see yourself in the empty virtual
    environment until you press the **X** button to start the game and enter the boss
    room battle!
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to work with the generated AR planes to spawn
    objects in our rooms about their transform position and rotation. We also learned
    how to access the AR systems and pre-made components (provided by the MR template)
    to toggle the visual state of passthrough and AR planes.
  prefs: []
  type: TYPE_NORMAL
- en: We have the boss room environment taken care of now, and we have the game starting,
    but there’s still nothing for us to do or interact with. We’ll solve that problem
    now by adding XRI interactable objects to the room.
  prefs: []
  type: TYPE_NORMAL
- en: Placing interactable objects in the world
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In MR game design, interactive objects are essential to bridging the virtual
    and real worlds. Interactable objects are designed to respond to user input, even
    as basic as hand (or controller) movements that allow natural and intuitive interactions
    like pushing, grabbing, throwing, or even complex multi-hand manipulation (for
    example, rotating and scaling the object). They really help to sell the reality
    of the environment, and as a result, they significantly enhance the player’s engagement
    and overall gameplay experience.
  prefs: []
  type: TYPE_NORMAL
- en: For our game’s purposes, we’ll have examples of a simple grab and placement
    interaction and, with the gun, a secondary interactable event action for shooting.
    Note that while many MR games and experiences are built for use with hands (hand
    tracking), our boss room example game will use controllers.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by configuring the modules for grabbing – these will then be configured
    to be inserted into the slots on the control console (refer to the GDD in the
    *Designing a boss* *room* section).
  prefs: []
  type: TYPE_NORMAL
- en: Making objects XR interactables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first grabbable object we’ll work with is the crystal module. The player
    must be able to grab the module and insert it into the control console, so we’ll
    open up the provided `Module` Prefab asset in Prefab Mode (double-click on it
    in the `XR Grab Interactable` component to the root.
  prefs: []
  type: TYPE_NORMAL
- en: As seen in the following screenshot, grabbable objects should have a transform
    positioned and appropriately rotated for grabbing the item with the correct orientation
    for proper usage – here, we see both the `Module` and the `Gun` assets with their
    `Attach` object positioned and rotated for a good grab.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.11 – Configuring the XR grab attach transforms](img/B18347_14_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.11 – Configuring the XR grab attach transforms
  prefs: []
  type: TYPE_NORMAL
- en: Note from the screenshot that the forward direction (Z-axis, blue arrow) of
    the `Attach` transform is pointing away from the player holding the object. Some
    experimentation may be done to attain the desired grab position.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we just need to assign the `Attach` object to the `XR Grab Interactable`
    **Attach Transform** field to ensure it gets properly attached to the player’s
    controller. You can find the **Attach Transform** field hidden within the many
    options the interactable component provides.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.12 – XR Grab Interactable Attach Transform assignment](img/B18347_14_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.12 – XR Grab Interactable Attach Transform assignment
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | Affordance system
  prefs: []
  type: TYPE_NORMAL
- en: The XRI affordance system gives visual color and audio feedback cues when interacting
    with objects, especially when haptics are unavailable while using hands, using
    an **XR Interactable Affordance State Provider** component with the interactable
    source. Samples are provided in the XRI example project.
  prefs: []
  type: TYPE_NORMAL
- en: 'Affordance system: [https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit%402.5/manual/affordance-system.xhtml](https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit%402.5/manual/affordance-system.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: Save the module and temporarily add it to your `Boss Room` scene near the `MR
    Interaction Setup` object. Enter Play Mode and test grabbing the module and moving
    it around with the controller (by using the grip button on the side of the controller,
    with your middle finger). Notice I said *enter play mode* this time, not *build
    and run*. That’s because we want to iterate changes like grab point attachment
    positions more quickly. For details, refer to the Quest Link callout in the *Creating
    the Unity* *project* section.
  prefs: []
  type: TYPE_NORMAL
- en: Completed interactable objects
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the completed XR interactable objects are provided in the completed
    Unity project files for this chapter in the book’s GitHub repository here: [https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/XR-Assets](https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/XR-Assets).'
  prefs: []
  type: TYPE_NORMAL
- en: That’s all there is to making an object interactable in XR. XRI makes it very
    easy to get the minimum required interactions, such as grabbing in place for games
    and experiences. We saw how to dynamically place other digital objects in the
    world; let’s do the same for the modules, but with a twist.
  prefs: []
  type: TYPE_NORMAL
- en: Placing the modules in the room
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our boss room battle, our primary objective, besides just staying alive,
    is to collect the crystal modules to restore the functionality of the control
    console and energize the reactor to expel the evil plant entity. So, we have a
    sort of collection game here again! However, let’s add to the challenge of collecting
    and managing the modules.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting objects in an MR game can be made more engaging by having these objects
    move around the room. The player will need to rely on their spatial awareness
    and timing skills, which introduces a more dynamic and novel challenge requiring
    them to explore the room. With the objects reacting to not only the player’s actions
    but the physicality of the space, it also deepens the immersion of the MR gameplay
    experience.
  prefs: []
  type: TYPE_NORMAL
- en: If the collectible objects were to float somehow, the modules could also contribute
    to the game’s narrative or aesthetic theme. As it happens, crystal modules have
    a strange other-worldly property – gravity does not affect them, but forces do.
    ¯\_(ツ)_/¯
  prefs: []
  type: TYPE_NORMAL
- en: With that context set, let’s first create the three required modules, then spawn
    them into the room when the game starts.
  prefs: []
  type: TYPE_NORMAL
- en: Creating unique module variants
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The three `Module` Prefab variants we’ll create can be seen in *Figure 14**.7*,
    and each will have a unique identifier – the ID of the module will come into play
    when we configure the control console slots.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple ways to create a Prefab variant, but this time, we’ll use
    the following steps to create each unique module:'
  prefs: []
  type: TYPE_NORMAL
- en: Make a Prefab variant of `Module` by right-clicking on it in the **Project**
    window and selecting **Create** | **Prefab Variant**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name it `Module Variant A` (the proceeding variants will be `B` and `C`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Double-click on `Module Variant A` to open it in Prefab Mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the `Module` component, set it to `A` (followed by `B` and `C`). (The `Module`
    script is provided as part of the imported base assets.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the `Assets/Materials` folder, assign the `Module_A` material. You can
    easily do this by dragging the material from the **Project** window onto the model
    visible in the **Scene** view.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`false` on the `Rigidbody` component.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat these steps to create variants for modules `B` and `C`, respectively.
    Remember, any edits you make to a Prefab variant, such as modified property values
    or added/removed components, become overrides of the base Prefab, so you don’t
    want to apply these overrides, or you’ll be applying them to the base Prefab asset,
    and we don’t want that!
  prefs: []
  type: TYPE_NORMAL
- en: XR interactable required component
  prefs: []
  type: TYPE_NORMAL
- en: Adding an **XR Grab Interactable** component to our objects will automatically
    add a **Rigidbody** component with its default values.
  prefs: []
  type: TYPE_NORMAL
- en: Three unique modules, check! We can now add the necessary code to our game manager
    to spawn the modules when the game starts.
  prefs: []
  type: TYPE_NORMAL
- en: Spawning the modules to get things moving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is no sense in reinventing the wheel to spawn another Prefab into the
    scene; we can rely on the work we’ve already coded (as we should generally do).
    We will, however, change the spawning up just a bit because we don’t want to instantiate
    the objects about a plane object. We want a more arbitrary position in the world,
    but still in relation to the player position.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open up the `GameManager` script for editing. Let’s first create the serialized
    private member variable where we can assign all the module variants in the Inspector
    that need to be spawned into the scene:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create another method overload for the `SpawnPrefab()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In the method signature, we’ve made the `prefabs` parameter an array, `GameObject[]
    prefabs`, to accept any number of Prefabs to spawn, then added `forceDirection`
    and `force` parameters, which we’ll use to apply a force to the objects after
    instantiation.
  prefs: []
  type: TYPE_NORMAL
- en: The primary difference with this Prefab spawning method is that we’re using
    a `foreach` statement to iterate the array of Prefabs to ensure each one is instantiated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can add the call to `SpawnPrefab()` to do the module spawning. For
    simplicity’s sake, we’ll just tag it onto the console spawning. Add the following
    call to `SpawnPrefab()` in the `switch` statement’s floor plane classification
    `case` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: A new vector position is passed in as the offset from the player’s position
    (world space), the `Vector3.up` is the direction force, and `0.05f` is the force
    applied to the modules when they are instantiated. Simple.
  prefs: []
  type: TYPE_NORMAL
- en: 'Okay, we’ve talked about adding a force to the crystal modules so that they
    float about the room… now’s the time to implement it! Add the following lines
    to this iteration of the `SpawnPrefab()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If we have a force direction and amount passed as parameters to the `SpawnPrefab()`
    call that are not zero, we attempt to get the `Rigidbody` component of the instantiated
    Prefab. If the `Rigidbody` component reference is successfully retrieved, we call
    `ApplyForce()` and pass it in.
  prefs: []
  type: TYPE_NORMAL
- en: 'All that remains is to add the `ApplyForce()` method as a local function to
    work its physics magic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The physics API methods we’re taking advantage of here are `rb.AddForce()` and
    `rb.AddTorque()` to apply forces using an `Impulse` force mode.
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | Unity documentation
  prefs: []
  type: TYPE_NORMAL
- en: '**Rigidbody.AddForce**: [https://docs.unity3d.com/2022.3/Documentation/ScriptReference/Rigidbody.AddForce.xhtml](https://docs.unity3d.com/2022.3/Documentation/ScriptReference/Rigidbody.AddForce.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rigidbody.AddTorque**: [https://docs.unity3d.com/2022.3/Documentation/ScriptReference/Rigidbody.AddTorque.xhtml](https://docs.unity3d.com/2022.3/Documentation/ScriptReference/Rigidbody.AddTorque.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: Save the script and assign all the crystal module Prefab variants to the `GameManager`’s
    **Prefab Modules** field. Playtest and adjust the spawn position of the modules
    to your liking. Have fun chasing them down!
  prefs: []
  type: TYPE_NORMAL
- en: Applying impact force
  prefs: []
  type: TYPE_NORMAL
- en: The provided **Module** Prefab comes with an **ImpactApplyForce** script added
    to it that will apply an opposite force to the module when it collides with any
    other object with a collider. Combined with a very bouncy physics material assigned
    to the collider, this attempts to keep the modules moving about the room constantly.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we got the crystal modules floating about the room, adding
    the first challenge to the boss room battle mechanics. The second half of the
    challenge with the modules has to do with inserting them correctly into the slots
    of the control console. In the next section, we’ll perform the XR interactable
    configuration necessary for this interaction.
  prefs: []
  type: TYPE_NORMAL
- en: Making the module slots interactable
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To have objects that can work together to create an intuitive system that mimics
    how things work in the real world, we use an `XR Grab Interactable` object and
    an `XR Socket Interactor` object – we have an *interactable* and an *interactor*.
    The grab interactor allows players to pick up and interact with objects, while
    the socket interactor provides the designated spots to place them. This handshake
    between the two components makes it easier for users to interact with objects
    and provides a more seamless and immersive experience in virtual or MR environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means we’ll be configuring each control console slot with a socket interactor.
    Go ahead and open up the `Console` Prefab in Prefab Mode from the `Assets/Prefabs`
    folder. Add the `XR Socket Interactor` component for the `Slot A`, `Slot B`, and
    `Slot C` objects parented to the `ConsoleSlots` object. The object hierarchy can
    be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.13 – Console slot configuration](img/B18347_14_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.13 – Console slot configuration
  prefs: []
  type: TYPE_NORMAL
- en: An *attach* transform object can also be seen in the preceding screenshot; each
    slot has an object parented to it, and named `Socket Attach`. For each socket
    interactor added to the slot objects, assign the *attach* object to the interactor’s
    **Attach Transform** field (just like we did for the grab interactables).
  prefs: []
  type: TYPE_NORMAL
- en: We also want to ensure that only modules are inserted into the slots on the
    control console; we can do something about that. We can use the `Interaction Layer
    Mask` property of both `XR Grab Interactable` and `XR` `Socket Interactor`.
  prefs: []
  type: TYPE_NORMAL
- en: It doesn’t matter which one you start with, but it’s essential first to add
    a `Module` interaction layer. You can do that from any **Interaction Layer Mask**
    field by clicking the dropdown and selecting **Add layer…** (at the bottom), then
    going back to the component and selecting **Nothing**, then **Module** for each.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the interactive layer with the asset
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, find the interactive layer asset at **Assets/XRI/Settings/Resources/InteractionLayerSettings**,
    add the **Module** layer, then return to the components and set the layer.
  prefs: []
  type: TYPE_NORMAL
- en: The last part of the slot configuration is that the slots are configured with
    a `ConsoleSlot` component already, similar to how we configured the module’s `Module`
    component; ensure `A`, `B`, and `C` again.
  prefs: []
  type: TYPE_NORMAL
- en: 'Speaking of the `ConsoleSlot` component, let’s take a closer look at the code.
    It’s more than just a slot ID – it can detect when a module is inserted or removed.
    This allows it to tell the parent console controller when the specific slot is
    interacted with, which can then respond accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We declare our variables, then, in `Awake()`, once we have the references to
    the required components, we register the listeners for responding to the socket
    interactor `selectEntered` and `selectExited` events for handling inserting and
    removing modules, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the handler method declarations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The first thing we do is get the ID of the inserted module (remember, only modules
    can be inserted due to the interaction’s layer mask assignment). We then call
    a method of the `ConsoleController` instance for either the module being inserted,
    `InsertModule()`, or simply resetting the slots, `ResetSlots()`, when the module
    is removed.
  prefs: []
  type: TYPE_NORMAL
- en: You might be considering having `ConsoleController` subscribe to a `ConsoleSlot`
    exposed event. Since there are three slots, it is more efficient to have each
    slot handle its own interactions (objects should be responsible for their own
    state) and notify the controller (by passing its ID and the module’s ID). This
    is a more simplified approach.
  prefs: []
  type: TYPE_NORMAL
- en: Bonus activity
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to *flip the script* and experiment with the console controller listening
    to events on all three slots to compare the required code differences.
  prefs: []
  type: TYPE_NORMAL
- en: You should now be able to playtest the console slot interactions by grabbing
    a crystal module and placing it in any slot. Fun!
  prefs: []
  type: TYPE_NORMAL
- en: There’s more fun to be had… let’s get that laser pistol configured to provide
    us some protection against infiltrated hover bots.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the laser gun
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The configuration for the interactable gun object is pretty much the same as
    the crystal module; we already saw how to configure an attach transform in *Figure
    14**.11*. Except now, we’ll add a secondary action for shooting when the trigger
    is pulled.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing shooting with XR Interactable Events
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We only want shooting triggered when we’re actually grabbing the gun, so we
    won’t be relying on the reusable `OnButtonPress` component this time. Instead,
    we’ll use the `XR Grab Interactable` component, specifically, `Activated`. `Activated`
    is called when the interactor selecting the interactable sends a command to activate
    the interactable – precisely what we need.
  prefs: []
  type: TYPE_NORMAL
- en: Additional reading | Grab interactables
  prefs: []
  type: TYPE_NORMAL
- en: 'Both basic and advanced examples of grab interactions are available in the
    XRI examples: [https://github.com/Unity-Technologies/XR-Interaction-Toolkit-Examples/blob/main/Documentation/GrabInteractables.md](https://github.com/Unity-Technologies/XR-Interaction-Toolkit-Examples/blob/main/Documentation/GrabInteractables.md).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To set up the `Gun` Prefab, take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Either modify the provided `Gun` Prefab directly or make a Prefab variant to
    work with.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Prefab in **Prefab Mode**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add an `XR Grab Interactable` component to the root.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign the `Attach` object to the `Activated`, assign the `Gun.Shoot` function.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 14.14 – XR Grab Interactable event Activated assignment](img/B18347_14_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.14 – XR Grab Interactable event Activated assignment
  prefs: []
  type: TYPE_NORMAL
- en: 'For the `Rigidbody` component, use the following property values (the gun will
    stay floating in the air right where the player releases their grip; Kryk’zylx
    military tech is truly advanced!):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`false`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`true`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: And that’s all that’s required to configure the `Gun` Prefab to make it an interactable
    object that players can pick up and shoot. Pew-pew!
  prefs: []
  type: TYPE_NORMAL
- en: Gun sound FX
  prefs: []
  type: TYPE_NORMAL
- en: We also have sound FX added for the shooting, courtesy of **AudioManager** and
    the **AudioPlayerSFX3D** audio-playing component. So, add the audio manager to
    the boss room scene, create an audio mixer and the required mixer groups, and
    then assign the mixer groups to the audio manager. For a refresher, visit [*Chapter
    12*](B18347_12.xhtml#_idTextAnchor232).
  prefs: []
  type: TYPE_NORMAL
- en: All the code responsible for making the gun shoot a laser beam when the `Shoot()`
    method is called is contained entirely within the `Gun` class. It’s single-responsibility
    for its specific use case in this game, and the code is simple and straightforward,
    so I didn’t feel the need to overcomplicate the architecture here.
  prefs: []
  type: TYPE_NORMAL
- en: Code architecture philosophy
  prefs: []
  type: TYPE_NORMAL
- en: “*When you have a hammer, everything looks like a nail*” is a metaphor we can
    apply to a common pitfall in software development. People may use their favorite
    approaches to solve every problem they encounter, unintentionally leading to overcomplicated
    and inefficient code. Choosing the most appropriate solution for each problem
    or situation is important, rather than relying solely on a software doctrine.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, you just need to embrace simplicity. Knowing when to – or not to
    – is called experience.
  prefs: []
  type: TYPE_NORMAL
- en: When you examine the `Gun` script, you’ll see that we’re simply using `Physics.Raycast()`
    and `LineRenderer` with the two points for drawing the line set to the firing
    point and the end of the gun’s firing range, or the point at which the ray hits
    a damageable object (filtered by use of a **layer mask**).
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: Unity provides a specialized **XRLineRenderer** component for producing an XR-optimized
    line render compared to the regular **LineRenderer** component. It’s also capable
    of producing very inexpensive glow effects, which is fantastic for laser beams!
  prefs: []
  type: TYPE_NORMAL
- en: 'XR Line Renderer: [https://github.com/Unity-Technologies/XRLineRenderer](https://github.com/Unity-Technologies/XRLineRenderer)'
  prefs: []
  type: TYPE_NORMAL
- en: If the raycast hits a damageable object, we pass the damage amount specified
    in `_damageAmount` in a call to `TakeDamage()`. This is how we’ll work within
    our health system, from [*Chapter 8*](B18347_08.xhtml#_idTextAnchor151) (yes,
    reusable system for the win!), to cause damage to objects that have health (i.e.,
    a `HealthSystem` component added).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a functional self-defense weapon, let’s get it into the player’s
    hands.
  prefs: []
  type: TYPE_NORMAL
- en: Spawning the gun position
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Alright, this will be a piece of cake! We’re already pros at spawning virtual
    objects into the room. We’ll reuse most of what we already have in place for spawning
    objects because we’ll spawn the gun near the player, on their right-hand side
    (sorry, left-handers).
  prefs: []
  type: TYPE_NORMAL
- en: 'First things first, open up the `GameManager` script and add a declaration
    for a serialized private variable, `_prefabGun`, to hold the reference to the
    `Gun` Prefab:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We’re already using the `Console` Prefab spawning section to spawn other objects,
    so let’s tag the gun instantiation onto it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Notice this time, when we call `SpawnPrefab()`, we have another new method signature.
    This is very much like the method overload we used to spawn the modules, except
    we’re going to spawn a single Prefab and won’t apply any physics force in a specified
    direction to it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this version, let’s create a new method overload for spawning a single Prefab.
    This method will simply pass values to our previous `SpawnPrefab()` method, which
    requires an array of Prefabs. So, we just need to add the single Prefab to a *single
    item* *array* first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Notice we preset the parameter values for `forceDirection` and `force` to zeros
    to ensure no physics forces will be applied to the spawned object.
  prefs: []
  type: TYPE_NORMAL
- en: Save the script, assign `Gun` to the `GameManager`’s **Prefab Gun** field, save
    the scene, and playtest with all the elements in place for the start of our game.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned how to create interactable Prefab variants for the
    player and collect and place modules into slots on the control console, enhancing
    player engagement within the environment. We also learned how to implement shooting
    for the gun as a secondary activate action for objects held by the player. Now,
    with the added ability to shoot, let’s see how we bring everything together with
    the gameplay mechanics.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the boss room mechanics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In our climactic boss room battle, the player will collect the crystal module
    puzzle pieces while defending against virtual enemies – the patrolling hover bots
    the evil plant entity has so rudely infected. With the unique blend of a physical
    space for exploration and interactive gameplay with digital objects the MR technology
    provides, our players will be challenged to think strategically while physically
    exerting themselves. This innovative and novel approach to boss room mechanics
    pushes the boundaries of traditional video game design, and I’m very excited to
    see this technology continue to mature and break more boundaries!
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is dedicated to introducing the Unity technologies that enable
    game developers and creators to rapidly produce compelling and immersive MR experiences
    for players to consume and enjoy enthusiastically. As such, the concepts for the
    boss room mechanics will be discussed in a broader sense and we’ll only dive into
    the details where additional clarification is required.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll finalize the puzzle mechanic by implementing the logic
    required to solve it and energize the console. We’ll also set up the enemy bots
    to spawn and move toward the player, as well as their shooting behavior. Finally,
    we will complete the game loop by updating the game state.
  prefs: []
  type: TYPE_NORMAL
- en: So, first, concerning the crystal modules, let’s work with the problem of solving
    the control console puzzle.
  prefs: []
  type: TYPE_NORMAL
- en: Solving the crystal modules puzzle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As previously discussed, the crystal modules must be collected and placed back
    into the control console. Each console slot and module have corresponding IDs,
    but the order in which they must be placed is not apparent to us – the console
    just shows some garbled characters. Let’s have a look at the console controller
    script to set the correct combination for the modules and determine when they’ve
    been inserted successfully.
  prefs: []
  type: TYPE_NORMAL
- en: To complete the task of restoring the console and reenergizing the reactor successfully,
    the modules must be inserted in the exact order, starting with the first one –
    you cannot just randomly place them to end up in the correct order (that’s just
    how this tech works; I don’t think you should blame me for this). This makes the
    puzzle more challenging for the player because you must fend off the enemy hover
    bots while figuring this out!
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspecting the `ConsoleController` script, we first see the solution code as
    a serialized private `string` variable, `_consoleCode`, so we can inspect and
    set it in the Inspector at any time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `InsertModule()` code will efficiently handle modules inserted in a specific
    order, provide feedback for incorrect placement, and signal success for the correct
    sequence. The module insertion and solving logic should be carried out like so:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the current slot index, starting at zero, check the slot order against
    the inserted module.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment the slot index when the next correct module ID has been provided;
    otherwise, reset the slots (index set back to zero).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check for code completion and update UI or trigger events accordingly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bonus challenge
  prefs: []
  type: TYPE_NORMAL
- en: In the **ConsoleController** class, based on the above steps, code the puzzle-solving
    logic for the correct order of modules inserted into the console with the **InsertModule(_slotID,
    _moduleID)** method yourself first.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get just the completed console puzzle code in the **ConsoleController**
    script from the GitHub repo here: [https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Code-Assets](https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Code-Assets).'
  prefs: []
  type: TYPE_NORMAL
- en: These steps are designed to ensure that the modules are inserted in the correct
    order and that a module’s ID matches the expected ID for the current slot index.
    The console is activated if all modules are correctly inserted, while progress
    is displayed on the console screen (UI).
  prefs: []
  type: TYPE_NORMAL
- en: World space UI
  prefs: []
  type: TYPE_NORMAL
- en: For the console screen (UI) mentioned above, in step 3’s *update UI*, the control
    console Prefab includes a world space **uGUI Canvas**. A world space UI is a user
    interface that appears within the game’s 3D world instead of as a screen overlay.
    It is rendered on a canvas that can be positioned, rotated, and scaled just like
    any other 3D object in the scene. Developers use them to create interactive elements
    within the game world, such as control panels, information displays, or interactive
    menus.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'When the player has restored the console, we can notify the reactor to energize
    it via an event. And what better event implementation could we use than our very
    own global event system? Refer to [*Chapter 9*](B18347_09.xhtml#_idTextAnchor169)
    for a refresher on the event system’s setup and usage (just make sure to add the
    `EventSystem` component to the scene somewhere). But you can see how we trigger
    this event in the `ConsoleEnergized()` method here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in the `Reactor` script, we respond to the event by simply swapping the
    mesh renderer’s material to one with an emissive property to visually indicate
    that it has been energized (this can be much more than just a simple material
    change; think of a particle system, **VFX Graph**, or a custom **Shader Graph**):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: With the problem now solved to implement the puzzle mechanics, let’s move on
    to spawning the waves of hover bot enemies… since they are supposed to get in
    our way and make solving the puzzle even more challenging!
  prefs: []
  type: TYPE_NORMAL
- en: Spawning enemies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have a challenge. Now, let’s make it even more difficult for the player!
    Spawning waves of enemies in a boss room encounter dramatically enhances the player’s
    challenge and boosts the intensity of the gameplay. The approach of spawning an
    unrelenting number of adversaries not only heightens the excitement and satisfaction
    of overcoming the challenge but also deepens the player’s engagement with the
    mechanics of the battle.
  prefs: []
  type: TYPE_NORMAL
- en: The `Corridor` Prefab provided with the boss room starter assets includes game
    objects for the locations of the spawner and the target position at the doorway
    end of the hallway for where the hover bot will travel. So, let’s complete the
    setup by adding the `EnemySpawner` component and configuring its properties.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.15 – The enemy spawner component values](img/B18347_14_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.15 – The enemy spawner component values
  prefs: []
  type: TYPE_NORMAL
- en: Note on the starter assets provided
  prefs: []
  type: TYPE_NORMAL
- en: The assets included in the provided starter assets package already imported
    have been created using the techniques in previous chapters. You will find that
    the design patterns, code architecture, and all the components used will be familiar.
    Therefore, we won’t be covering everything again. However, I recommend taking
    some time to examine the components used for configuring these Prefabs, especially
    **Enemy Hover Bot A Shooting 1**, since it offers the most significant example.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may very well already be able to handle adding the spawner component and
    configuring it. If so, congrats! Still, for reference, here are the steps we can
    follow to configure it now:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `Corridor` Prefab in the `Assets/Prefabs` folder in Prefab Mode.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the `EnemySpawner` script to the `SpawnerLocation` child object. We add
    the script here because we’ll use the object’s transform forward as the direction
    of travel for the spawned hover bot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Assign the component’s field values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`2` (starting value – this is the time between checking if the currently instantiated
    bot has been destroyed).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`(2, 6)` (the time between instantiating the bot and sending it on its way
    down the corridor).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Exit Prefab Mode and save the changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, when we do the *build and run* drill, we’ll have enemy hover bots repeatedly
    spawning when destroyed, moving toward us in their menacing fashion, and when
    they get within range, they’ll start shooting (using our pooled shooting setup,
    of course).
  prefs: []
  type: TYPE_NORMAL
- en: We’ll have to ensure a few things are configured still because importing assets
    from `'.unitypackage'` is not the same as having a starting Unity project. Things
    such as **Layers** and **Tags**, **AI Navigation** settings, and **Build Settings**
    are not brought in with the imported assets.
  prefs: []
  type: TYPE_NORMAL
- en: Ensure the following layers are added to the project (`Projectile`, `Damageable`
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, within the `Assets/Prefabs` folder, make the following Prefab objects’
    assignments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PlasmaBall` Prefab: Select it and, in the Inspector, using the `Projectile`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, use **Layer Collision Matrix** at the bottom of the **Edit** | **Project
    Settings…** | **Physics** settings page to disable collisions between **Placeable
    Surface** and **Projectile** – we don’t want the two to have a physics interaction.
  prefs: []
  type: TYPE_NORMAL
- en: '`Gun` Prefab: Select it and, in the Inspector, for the `Gun` component, set
    `Damageable`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Enemy Hover Bot A Shooting 1`: Select it and, in the Inspector, set `Damageable`.
    You can probably recognize how this layer assignment correlates to the damage
    mask assignment for the preceding gun.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete code
  prefs: []
  type: TYPE_NORMAL
- en: 'For reference, the complete code and project setup for this section can be
    found in the Unity project files provided for this chapter in the book’s GitHub
    repository here: [https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Unity-Project](https://github.com/PacktPublishing/Unity-2022-by-Example/tree/main/ch14/Unity-Project).'
  prefs: []
  type: TYPE_NORMAL
- en: This time, playing the game will have the proper interactions between the interactable
    objects and the virtual room surfaces where the gun damages and destroys the hover
    bots, and the bot’s projectile weaponry, the plasma ball, approaches the player
    – you – fully. All that’s left to do is complete the game loop for win-and-lose
    conditions… making it an actual game challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Completing the game loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Completing a game loop with clear conditions for winning or losing is fundamental
    in game design. Winning conditions often culminate in overcoming a final challenge
    like our boss room and reward players with an enormous sense of accomplishment
    for winning, while losing conditions such as depleting health increases the game’s
    challenge. The fragile balance between these conditions is critical to ensure
    the experience is engaging, rewarding, and fair in terms of the time players invest
    in your game.
  prefs: []
  type: TYPE_NORMAL
- en: I’m not going to make the claim that I have accomplished perfect, or even near
    perfect, game balance in the boss room battle we’ve created with the default values
    provided in this chapter. It’s simply the foundation for what’s possible when
    creating an immersive, engaging, and fun MR game experience.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s finish up the boss room MR game by looking at how we tie in the winning
    and losing conditions from the gameplay created, starting with losing.
  prefs: []
  type: TYPE_NORMAL
- en: Losing the battle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When it comes to playing video games, losing is just as common as winning –
    anyone who’s played a video game has experienced losing. For our MR boss room
    battle, with enemy hover bots shooting at us, the apparent game-losing scenario
    is we run out of health to continue playing. So, that’s just what we’re going
    to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'To complete the setup in our scene to support losing by player health depletion,
    we first need to ensure we have a `Player` object in the scene – a GameObject
    tagged `Player` with the `Player` script added. Follow these steps to complete
    the player setup:'
  prefs: []
  type: TYPE_NORMAL
- en: Add the `Player` Prefab as a child of `MR` `Interaction Setup`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure it’s tagged as `Player`. Add the `Player` tag for assigning it now if
    it’s not already there.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure the `Player` object’s layer is set to `Damageable`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Player` implements the `IHaveHealth` interface for the health system, so also
    ensure the enemy’s `PlasmaBall` Prefab’s `ProjectileDamage` component has `Damageable`
    set for **Damage Mask**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the `Player` class, we have an event system event triggered when the
    player’s health has fully diminished after taking too many plasma ball hits from
    the enemy hover bots:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Our `GameManager` class will listen to the event and respond by setting the
    `_isConditionMetLose` condition variable for losing and responding accordingly.
    With `true` being passed as the Boolean value for the event, we use it to set
    the condition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the individual event to update the UI, turn the passthrough off,
    or fade to black. However, the `GameManager` will respond to the condition change
    by ending the game:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: FSM refactor
  prefs: []
  type: TYPE_NORMAL
- en: 'The best solution to keep track of our game states is, of course, a state pattern.
    We previously used a simple **finite state machine** (**FSM**) in our **EnemyController**
    class; you can also find it here. A refactor of the enum-based FSM was beyond
    the scope of what I had planned for the book, so I’ve left the refactor to you,
    but with a provided example using the **UnityHFSM** (**Unity Hierarchical Finite
    State Machine**) package available on GitHub here: [https://github.com/Inspiaaa/UnityHFSM?tab=readme-ov-file#simple-state-machine](https://github.com/Inspiaaa/UnityHFSM?tab=readme-ov-file#simple-state-machine).'
  prefs: []
  type: TYPE_NORMAL
- en: In the project files provided by the book’s GitHub repo, inspect and evaluate
    the refactored **Assets/Scripts/Refactored/GameManager_HFSM** script for an example
    implementation compared to the enum-based **switch** statements in **GameManager**
    and implement it in your project.
  prefs: []
  type: TYPE_NORMAL
- en: Losing the battle is not fun, but if you don’t succeed… what’s the saying “*try,
    try again*?” I’m sure if you do, you will win. Let’s see how the win condition
    is wired; it’s really just like the lose condition – the global event system really
    makes this easy.
  prefs: []
  type: TYPE_NORMAL
- en: Winning the battle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For our MR boss room battle, with enemy hover bots as the primary adversaries,
    the winning scenario is clearly defeating all waves of enemies, right? No. That’s
    not what we’ve laid the groundwork for here; as you already know, we win the game
    when we solve the puzzle of the control console slots and reenergize the reactor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since everything is already in place for reenergizing the reactor with a global
    event system event, we’re just going to add another listener to the `OnConsoleEnergized`
    event in `GameManager` to set the win condition variable, exactly like we did
    for losing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: And that’s it! Setting the game state to `State.GameOver` handles the rest!
  prefs: []
  type: TYPE_NORMAL
- en: By carefully setting up the game states and defining a clear path to victory,
    we create a rewarding gameplay loop that challenges players to develop strategies
    to overcome the game’s challenges and ultimately achieve success in their MR boss
    room battle.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we explored a basic set of boss room mechanics for our MR game.
    We learned how to integrate and solve a puzzle mechanic that players must figure
    out under pressure and introduced how to spawn waves of enemies equipped with
    projectile weaponry. Learning about the player’s laser pistol configuration allows
    for damaging and destroying the hover bots. Then, we further understood how to
    connect the win and lose conditions in the game manager state machine to complete
    the game design, emphasizing the strategic balance between solving puzzles and
    surviving.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the Unity MR technologies that streamline development
    and empower developers to create immersive MR experiences. We took a dive into
    the design principles of crafting a captivating boss room while setting up our
    physical space with Quest devices and configuring Unity’s MR template to suit
    our needs. Furthermore, we gained insights into leveraging AR planes and components
    to manipulate AR visual elements and spawn virtual objects dynamically within
    our environment.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we honed our skills in creating interactive Prefab variants and
    integrating shooting mechanics to support core gameplay. By enabling players to
    collect and place modules into control console slots, we deepened the XR interactive
    potential of our game world. Bringing together all the various MR elements, we
    crafted a compelling MR gaming experience.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll see what it means to operate a published game by
    exploring Games as a Service, including Unity DevOps and LiveOps, look at safeguarding
    the investment you make in your projects through robust source code management
    and strategies for engaging players through in-game economies, and touch on some
    essentials of platform distribution. This overview will equip you with the tools
    and knowledge to effectively manage, maintain, expand, and distribute your finished
    games.
  prefs: []
  type: TYPE_NORMAL
