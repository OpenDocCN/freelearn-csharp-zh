<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-88"><a id="_idTextAnchor087"/>6</h1>
<h1 id="_idParaDest-89"><a id="_idTextAnchor088"/>Applying Event Sourcing Patterns</h1>
<p>In the previous chapter, we explored a prolific pattern in CQRS. This pattern encourages us to create a clear separation between code and data sources that govern read and write operations. With this kind of separation, we risk having our data out of sync in between operations, which introduces the need for additional techniques to ensure data consistency.</p>
<p>Even without CQRS, we must contend with the typical microservices pattern where each service is expected to have its own data store. Recall that there will be situations where data needs to be shared between services. There needs to be some mechanism that will adequately transport data between services so that they will remain in sync.</p>
<p><strong class="bold">Event sourcing</strong> is touted as a solution to this issue, where a new data store is introduced that keeps track of all the command operations as they happen. The records in this data store are considered events and contain enough information for the system to track what happens with each command operation. These records are called events and they act as an intermediary store for event-driven or asynchronous services architecture. They can also act as an audit log as they will store all the necessary details for replaying changes being made against the domain.</p>
<p>In this chapter, we will explore the event sourcing pattern and justify its use as a solution to our potentially out-of-sync databases.</p>
<p>After reading this chapter, you will be able to do the following:</p>
<ul>
<li>Understand what events are and what event sourcing can do for you</li>
<li>Apply event sourcing patterns in your application code</li>
<li>Use the CQRS pattern to create events and read states in between events</li>
<li>Create an event store using a relational or non-relational database</li>
</ul>
<h1 id="_idParaDest-90"><a id="_idTextAnchor089"/>Technical requirements</h1>
<p>Code references used in this chapter can be found in the project repository, which is hosted on GitHub at <a href="https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch06">https://github.com/PacktPublishing/Microservices-Design-Patterns-in-.NET/tree/master/Ch06</a>.</p>
<h1 id="_idParaDest-91"><a id="_idTextAnchor090"/>What are events?</h1>
<p>An event, within the<a id="_idIndexMarker240"/> context of software development, refers to something that happens because of an action being completed. Events are then used to carry out actions in the background, such as the following:</p>
<ul>
<li>Storing data for analytics purposes</li>
<li>Notification of completed actions</li>
<li>Database auditing</li>
</ul>
<h2 id="_idParaDest-92"><a id="_idTextAnchor091"/>Key attributes of events</h2>
<p>Events can be used to build the<a id="_idIndexMarker241"/> foundation of any application’s core functionality. While the concept can be suitable for many situations, it is important for us to understand some key attributes of events and properly scope the need for their introduction, as well as uphold certain standards in our implementations:</p>
<ul>
<li><strong class="bold">Immutability</strong>: This word refers to the unchangeable nature of an object. Within the context of an event, once <a id="_idIndexMarker242"/>something has happened, it becomes a fact. That means we cannot change it or the outcome in the real world. We extend this same feature to our events and ensure that they cannot be changed after they are generated.</li>
<li><strong class="bold">Single occurrence</strong>: Each event<a id="_idIndexMarker243"/> is unique. Once it has been generated, it cannot be repeated. Even if the same thing happens later, it should be recognized as a new event.</li>
<li><strong class="bold">Historical</strong>: An event <a id="_idIndexMarker244"/>should always represent a point in time. This way, we can trace what happened and when in the past. This discipline is also displayed in the way that we name our events, where we use the past tense to describe the event.</li>
</ul>
<p>Events at their best do <a id="_idIndexMarker245"/>not contain any behavior or business logic. They generally only serve as a point-in-time data collection unit and help us to track what is happening at different points in our application.</p>
<p>Now that we have a good idea of what events are and why they are used at a high level, let us focus on more practical uses of events and event sourcing patterns.</p>
<h1 id="_idParaDest-93"><a id="_idTextAnchor092"/>What can event sourcing patterns do for me?</h1>
<p>Applications built with <a id="_idIndexMarker246"/>microservices architecture are structured to have a set of loosely coupled and independent services. Using the <strong class="bold">database-per-service pattern</strong>, we further <a id="_idIndexMarker247"/>segregate each service by giving it an individual data store. This now presents a unique challenge to keep the data in sync between services. It becomes more difficult given that we need to compromise on our ACID principles. We can recall that the acronym <strong class="bold">ACID</strong> stands for <strong class="bold">atomicity, consistency, isolation, and durability</strong>. We are most concerned about the <a id="_idIndexMarker248"/>principle of atomicity in this context. We cannot guarantee that all our write operations will be completed as a unit. The atomic principle dictates that all data operations should complete or fail as a unit. Given the allowance for different technologies to be used for the data stores, we cannot absolutely guarantee that.</p>
<p>Considering all these factors, we<a id="_idIndexMarker249"/> turn to a new pattern called event sourcing, which allows us to persist messages that keep track of all the activities occurring against data in each service. This pattern is especially useful for asynchronous communication between services where we can keep track of all changes in the form of <strong class="bold">events</strong>. These events can act as the following:</p>
<ul>
<li><strong class="bold">Persistent events</strong>: Events contain<a id="_idIndexMarker250"/> enough detail to inform and recreate domain objects</li>
<li><strong class="bold">Audit log</strong>: Events are <a id="_idIndexMarker251"/>generated with each change, so they can double as audits</li>
<li><strong class="bold">Entity state identification</strong>: We can <a id="_idIndexMarker252"/>use events to view the point-in-time state of an entity on demand</li>
</ul>
<p>The idea of tracking changes <a id="_idIndexMarker253"/>against entities is called <strong class="bold">replaying</strong>. We can replay events in two steps:</p>
<ol>
<li>Grab all or partial events stored for a given aggregate.</li>
<li>Iterate through all events and extract the relevant information to freshen up the instance of the aggregate.</li>
</ol>
<p>Event sourcing is essentially all about querying records in some way using an <strong class="bold">aggregate ID</strong> and <strong class="bold">timestamp</strong>. The aggregate ID<a id="_idIndexMarker254"/> represents the unique identifier column, or primary <a id="_idIndexMarker255"/>key value, for the original record for which the event was raised. The timestamp represents the <a id="_idIndexMarker256"/>point in time that the event was raised. The queries required for this look similar for relational and non-relational event stores. The event replay operation requires that we iterate through all the events, grab information, and then change the state of the target aggregate. In addition to the aggregate ID and timestamp, we will also have all the information needed to fill in the bits of data needed for the aggregate.</p>
<p>Now, let us review some of the benefits of using events in our systems.</p>
<h2 id="_idParaDest-94"><a id="_idTextAnchor093"/>Pros of event sourcing</h2>
<p>We have been looking<a id="_idIndexMarker257"/> into the idea of tracking the history of operations that happen against our data, particularly our aggregates. We have encountered the concepts of events and replays. Now let us look at what event replays are, how they may benefit us, and what other benefits exist from using events.</p>
<p>Event replays and the way that we conduct our updates depend on whether the aggregate is a domain class or not. If the aggregate relies on domain services for manipulation, we need to be clear that replays are not about repeating or redoing commands. A command, based on our understanding of CQRS, changes the state and data in the database. This also has the potential of being a long-running operation with event-data-generating side effects, which we may not want. A replay is about looking at data and performing logic to extract information. On the other hand, event replays copy the effects of events and apply them to fresh instances of the aggregate. Altogether, stored events may be processed differently relative to the application employing the technique.</p>
<p>Events are bits of data that are stored at a lower level than the plain state. This means that we can reuse them to build any projection of the data that we need. Ad hoc projects of the data can be used for the read data store in a CQRS project structure, data analytics, business intelligence, and even artificial intelligence and simulations. Contextually, if we have a stream of events and can extract a specific subset, then we can replay them and perform ad hoc calculations and processes to generate custom and potentially new<a id="_idIndexMarker258"/> information. Events are constant and will always be the same now and later. This is an additional benefit in that we can always be sure that we will be able to count on the data for consistency.</p>
<p>As in life, for every set of benefits, there is a lingering set of downsides. Let us explore some of the general concerns around event sourcing.</p>
<h2 id="_idParaDest-95"><a id="_idTextAnchor094"/>Cons of event sourcing</h2>
<p>In exploring event <a id="_idIndexMarker259"/>sourcing, we must bear in mind that we need to introduce an additional data store and additional services that might impede the application’s performance. Let us review some concerns.</p>
<p>Performance is always important in an application. So, when introducing a new pattern or set of processes, it is prudent of us to ensure that the performance impact is minimal. What happens when we need to process too many events to rebuild data? This can quickly become an intensive operation based on the number of logged events, which is only going to grow since the event<a id="_idIndexMarker260"/> store will be an <strong class="bold">append-only</strong> data store.</p>
<p>To address this, we take snapshots of the aggregate state and business entities that have recently been amended. We can then use these snapshots as a stored version of the record and use them as a recent version of the data, sparing the need to iterate through potentially many events. This operation is best complimented by having a <strong class="bold">read-only</strong> data store to <a id="_idIndexMarker261"/>pair with our CQRS pattern. The snapshot will be used for read operations going forward.</p>
<p>Now that we have looked at some of the more serious implications of this pattern and techniques that can be used to reduce the impact it might have on our application, let us review how event sourcing and domain events relate to each other so that we can strengthen our foundational knowledge.</p>
<h1 id="_idParaDest-96"><a id="_idTextAnchor095"/>What are domain events?</h1>
<p>Earlier in this book, we<a id="_idIndexMarker262"/> discussed the use of DDD as a design pattern that helps us to scope the different services that might be required as we develop our microservices application. Events can be employed in the implementation of this pattern to help us to model expected outcomes within our bounded contexts. Events are scoped based on the ubiquitous language that has been established within the bounded context and is informed by decisions within the domain.</p>
<p>Within the domain, aggregates are responsible for creating domain events and our domain events are usually raised based on the outcome of some user action, or command. It is important to<a id="_idIndexMarker263"/> note that domain events are not raised based on actions such as the following:</p>
<ul>
<li>Button clicks, mouse moves, page scroll events, or simple application exceptions. Events should be based on the established ubiquitous language of the bounded context.</li>
<li>Events from other systems or outside of the current context. It is important to properly establish the boundaries between each domain context.</li>
<li>Simple user requests to the system. A user request at this point is a command. The event is raised based on the outcome of the command.</li>
</ul>
<p>Now let us get a better understanding of why domain events are integral to implementing event sourcing patterns.</p>
<h2 id="_idParaDest-97"><a id="_idTextAnchor096"/>Domain events and event sourcing</h2>
<p>Event sourcing is<a id="_idIndexMarker264"/> implemented to provide a single point of reference for the history of what has happened within a bounded context. Simply put, event sourcing uses domain events to store the states that an aggregate has gone through. We have already seen that event sourcing will have us store the record ID, a timestamp, and details that help us to understand what the data looked like at that moment. Properly implementing <strong class="bold">domain events</strong> within a bounded context will lay a foundation for a good implementation of event sourcing and so proper scoping and implementation are important.</p>
<p>Implementing domain events in code can be done relatively<a id="_idIndexMarker265"/> simply using the <strong class="bold">MediatR</strong> library, which was so integral in our CQRS pattern implementation. In the next section, we will look at adjusting our application to implement domain events.</p>
<h2 id="_idParaDest-98"><a id="_idTextAnchor097"/>Exploring domain events in our application</h2>
<p>Now, let us <a id="_idIndexMarker266"/>consider introducing domain events to our appointment booking system. As far as we can see, we have several activities that need to be completed when an appointment is booked in our system. We might also need to extend the capabilities of our system to support the idea that changes might be needed to the original appointment and should be tracked.</p>
<p>Let us use the email dispatching activity. This needs to happen when an appointment is accepted into the system and saved. As it stands, our <code>CreateAppointmentHandler</code> will handle everything that is needed in the situation. We then run into the challenge of separating concerns since we probably don’t want our handler to be responsible for too many actions. We would do well to separate our email dispatch operation into its own handler.</p>
<p>Using MediatR, we can introduce a new type of handler called <code>INotificationHandler&lt;T&gt;</code>. This new base type allows us to define handlers relative to data types modeled from events that inherit from another MediatR base type, called <code>INotification</code>. These event types should be named according to the action that it is created to facilitate and will be used as the generic parameter in our <code>INotificationHandler&lt;T&gt;</code>. Our <code>INotificationHandler&lt;T&gt;</code> base type will be inherited by a handler or handlers that will carry out any specific actions relative to the additional actions required.</p>
<p>In code, we would want to start with some fundamental base types that will help us to define our concrete event types. The first would be <code>IDomainEvent</code>, which will serve as a base type for all our domain events that will follow. Its definition looks something like this:</p>
<pre class="source-code">
public interface IDomainEvent : INotification
{}</pre>
<p>Our interface inherits from MediatR’s built-in <code>INotification</code> interface so that any derived data type will automatically also be a notification type. This <code>IDomainEvent</code> interface also helps us to enforce any mandatory data that must be present with any event object, such as the date and time of the action.</p>
<p>Now that we have our base types, let us define our derived event class for when an appointment gets created. We want to<a id="_idIndexMarker267"/> ensure that we name our event type in a manner that accurately depicts the action that raised the event. So, we will call this event type <code>AppointmentCreated</code>. We simply inherit from our <code>IDomainEvent</code> interface and then define additional fields that correspond with the data that is needed for the event to adequately carry out additional work:</p>
<pre class="source-code">
public class AppointmentCreated : IDomainEvent
    {
        public Appointment { get; set; }
        public DateTime ActionDate { get; private set; }
        public AppointmentCreated(Appointment appointment,
          DateTime dateCreated)
        {
            Appointment = appointment;
            ActionDate = dateCreated;
        }
        public AppointmentCreated(Appointment appointment)
          : this(appointment, DateTime.Now)
        {
        }
    }</pre>
<p>In our <code>AppointmentCreated</code> derived event type, we have defined a property for our appointment and a constructor that makes sure that an object of <code>Appointment</code> is present at the time of creation. In this case, it is up to you to decide how much or little information you would require for the event to effectively be handled. For instance, some types of events might only need the appointment’s ID value. Be very sure to scope this properly however, and send as much information as is needed. You do not want to send only the ID and then need to query for additional details and risk potentially many event handlers trying to fetch details from just an ID value.</p>
<p>Now let us look at defining handlers for our event type. Note that I said <em class="italic">handlers</em> as it is possible and viable to define multiple event handlers based on the event that has occurred. For instance, when an appointment gets created, we might have a handler that will update the event <a id="_idIndexMarker268"/>store with the new record, or have one that dispatches<a id="_idIndexMarker269"/> an email alert, separate from one that updates<a id="_idTextAnchor098"/> a <a id="_idTextAnchor099"/><strong class="bold">SignalR</strong> hub, for example.</p>
<p>To facilitate updating an event store, we would need to first have a handler defined that would look something like this:</p>
<pre class="source-code">
public class UpdateAppointmentEventStore :
  INotificationHandler&lt;AppointmentCreated&gt;
    {
        private readonly AppointmentsEventStoreService
          _appointmentsEventStore;
        public UpdateAppointmentEventStore
          (AppointmentsEventStoreService
            appointmentsEventStore)
        {
            this._appointmentsEventStore =
              appointmentsEventStore;
        }
        public async Task Handle(AppointmentCreated
         notification, CancellationToken cancellationToken)
        {
            await _appointmentsEventStore.CreateAsync
              (notification.Appointment);
        }
    }</pre>
<p>Our <code>AppointmentCreated</code> event type is used as the target type for our <code>INotificationHandler</code>. This is all it takes to add specific logic sequences to a raised event. This also helps us to separate concerns and better isolate bits of code associated with raised events. Our notification ob<a id="_idTextAnchor100"/>ject contains the appointment record, and we can easily use <a id="_idIndexMarker270"/>the data we need.</p>
<p>This code will automatically get fired when the event occurs and handle the event-store-update operation accordingly.</p>
<p>Let us look at our event handler that will dispatch our email alert:</p>
<pre class="source-code">
public class NotifyAppointmentCreated :
  INotificationHandler&lt;AppointmentCreated&gt;
    {
        private readonly IEmailSender _emailSender;
        private readonly IPatientsRepository
          _patientsRepository;
        public NotifyAppointmentCreated(IEmailSender
          emailSender, IPatientsRepository
            patientsRepository)
        {
            this._emailSender = emailSender;
            this._patientsRepository = patientsRepository;
        }
        public async Task Handle(AppointmentCreated
         notification, CancellationToken cancellationToken)
        {
            // Get patient record via Patients API call
            var patient = await _patientsRepository.Get
              (notification.Appointment.
                PatientId.ToString());
            string emailAddress = patient.EmailAddress;
            // Send Email Here
            var email = new Email
            {
                Body = $"Appointment Created for
                  {notification.Appointment.Start}",
                From = "noreply@appointments.com",
                Subject = "Appointment Created",
                To = emailAddress
            };
            await _emailSender.SendEmail(email);
        }
    }</pre>
<p>Notice as well that <a id="_idIndexMarker271"/>even though we did not have direct access to the patient’s record, we had their ID. With that value, we could make a synchronous API call to retrieve additional details that can assist us in crafting and dispatching the notification email.</p>
<p>In the same way, if we wanted to define an event handler for SignalR operations, we could simply define a<a id="_idIndexMarker272"/> second handler for the same event type:</p>
<pre class="source-code">
public class NotifySignalRHubsAppointmentCreated :
  INotificationHandler&lt;AppointmentCreated&gt;
{
  public Task Handle(AppointmentCreated notification,
    CancellationToken cancellationToken)
  {
    // SignalR awesomeness here
    return Task.CompletedTask;
  }
}</pre>
<p>Now that we can raise an event, we can refactor our application a bit to reflect this. We can refactor our <code>CreateAppointmentHandler</code> and <code>CreateAppointmentCommand</code> classes to return an object of <code>Appointment</code> instead of the previously defined string value:</p>
<pre class="source-code">
public record CreateAppointmentCommand(int
  AppointmentTypeId, Guid DoctorId, Guid PatientId, Guid
    RoomId, DateTime Start, DateTime End, string Title) :
      IRequest&lt;Appointment&gt;;
public class CreateAppointmentHandler :
  IRequestHandler&lt;CreateAppointmentCommand, Appointment&gt;
public async Task&lt;Appointment&gt; Handle
  (CreateAppointmentCommand request, CancellationToken
    cancellationToken){ … }</pre>
<p>With this adjustment, we can now retrieve an object of the created appointment and publish an event from the original calling code, which was in the controller. Our <code>POST</code> method for our appointments <a id="_idIndexMarker273"/>API now looks like this:</p>
<pre class="source-code">
// POST api/&lt;AppointmentsController&gt;
        [HttpPost]
        public async Task&lt;ActionResult&gt; Post([FromBody]
         CreateAppointmentCommand createAppointmentCommand)
        {
            // Send appointment information to create
               handler
            var appointment = await
              _mediator.Send(createAppointmentCommand);
            //Publish AppointmentCreated event to all
              listeners
            await _mediator.Publish(new AppointmentCreated
              (appointment));
            // return success code to caller
            return StatusCode(201);
        }</pre>
<p>Now we use the <code>Publish</code> method from the MediatR library to raise an event, and all handlers that have been defined to watch for the specified event type will be called into action.</p>
<p>These refactors to our code will introduce even more code and files, but they do assist in helping us maintain a distributed and loosely coupled code base. With this activity, we have reviewed how we can cleanly introduce domain events to our application, and now we need to appreciate how we can store our events.</p>
<h1 id="_idParaDest-99"><a id="_idTextAnchor101"/>Creating an event store</h1>
<p>Before we get to the scoping phase of<a id="_idIndexMarker274"/> creating an event store, it is important for us to fully understand what one is. A simple search on the topic might yield many results from various sources, with each citing varied definitions. For this book, we will conclude that an event store <em class="italic">is an ordered, easily queryable, and persistent source of long-term records that represents events that have happened against entities in a data store.</em></p>
<p>In exploring the implementation of a data store, let us break out the key parts and how they connect to give the resulting event store. An event record will have an aggregate ID, a timestamp, an <code>EventType</code> flag, and data representing the state at that point in time. An application will persist event records in a data store. This data store has an API or some form of interface that allows for adding and retrieving events for an entity or aggregate. The event store might also behave like a message broker allowing for other services to subscribe to events as they are published by the source. It provides an API that enables services to subscribe to events. When a service saves an event in the event store, it is delivered to all interested subscribers. <em class="italic">Figure 6.1</em> shows a typical event store architecture.</p>
<div><div><img alt="Figure 6.1 – An event store sits between the command handlers of an API and the query handler, which may require a different projection of the originally stored data" src="img/Figure_6.1_B19100.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 6.1 – An event store sits between the command handlers of an API and the query handler, which may require a different projection of the originally stored data</p>
<p>Let us review event <a id="_idIndexMarker275"/>storage strategies that we can employ.</p>
<h2 id="_idParaDest-100"><a id="_idTextAnchor102"/>How to store events</h2>
<p>We have already<a id="_idIndexMarker276"/> established that events should be immutable, and the data store should be append-only. Armed with these two requirements, we can deduce that our dos and don’ts need to be at a minimum as we scope the data store.</p>
<p>Each change that takes place in the domain needs to be recorded in the event store. Since events need to contain certain details relevant to the event being recorded, we need to maintain some amount of flexibility with the structure of the data. An event might contain data from multiple sources in the domain. That means that we need to leverage possible relationships between tables in order to grab all the details required to log the event.</p>
<p>This makes the standard relational database model less feasible as a data store for events since we want to be as efficient as possible in retrieving our event records for auditing, replay, or analytics later. If we are using a relational data store, then we would do well to have denormalized tables modeled from the event data that we intend to store. An alternative and more efficient manner to handle event storage is the use of a non-relational or NoSQL database. This will allow us to store the relevant event data as documents in a far<a id="_idIndexMarker277"/> more dynamic manner.</p>
<p>Let us explore some options regarding storing events in a relational database.</p>
<h2 id="_idParaDest-101"><a id="_idTextAnchor103"/>Implementing event sourcing using a relational database</h2>
<p>We have already reviewed some of the drawbacks of using a relational database as the event store. In truth, the way <a id="_idIndexMarker278"/>you design this storage, alongside the technology that is used, can have a major bearing on how future-proofed your implementation will be.</p>
<p>If we go the route of using<a id="_idIndexMarker279"/> denormalized table representations of the events, then we will end up going down a rabbit hole of modeling several tables based on several different events. This might not be sustainable in the long run, since we would need to introduce new tables with each newly scoped event and constantly change designs as the events evolve.</p>
<p>An alternative would be that we create a singular log table that has columns that match the data points we just outlined. For example, this table and the matching data types would be as follows:</p>
<div><div><table class="No-Table-Style" id="table001-1">
<colgroup>
<col/>
<col/>
</colgroup>
<tbody>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">Column Name</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><strong class="bold">Data Type</strong></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">Id</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><code>Int</code></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">AggregateId</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><code>Guid</code></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">Timestamp</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><code>DateTime</code></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">EventType</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><code>Varchar</code></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">Data</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><code>Varchar</code></p>
</td>
</tr>
<tr class="No-Table-Style">
<td class="No-Table-Style T---Body">
<p><strong class="bold">VersionNumber</strong></p>
</td>
<td class="No-Table-Style T---Body">
<p><code>Int</code></p>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li><strong class="bold">Id</strong>: Unique identifier for the event record.</li>
<li><strong class="bold">AggregateId</strong>: Unique identifier for the aggregate record to which the event is related.</li>
<li><strong class="bold">Timestamp</strong>: The date and time that this event was logged.</li>
<li><strong class="bold">EventType:</strong> This is a string representation of the name of the event that is being logged.</li>
<li><strong class="bold">Data:</strong> This is a serialized representation of the data associated with the event record. This serialization is best done in an easy-to-manipulate format such as <strong class="bold">JSON</strong>.</li>
<li><strong class="bold">VersionNumber</strong>: The version number helps us to know how to sort events. It represents the sequence in<a id="_idIndexMarker280"/> which each new event was logged in the stream and should be unique to each aggregate.We can <a id="_idIndexMarker281"/>add constraints to our records by introducing a <strong class="bold">UNIQUE</strong> index on both the <strong class="bold">AggregateId</strong> and <strong class="bold">VersionNumber</strong> columns. This will help us with speedier queries and ensure that we do not repeat any combination of these values.</li>
</ul>
<p>The type of database <a id="_idIndexMarker282"/>technology that is employed does play a part in how flexibly and efficiently we can store and retrieve data. The use of <strong class="bold">PostgreSQL</strong> and later versions of <strong class="bold">Microsoft SQL Server</strong> will see us reap the advantages of being able to manipulate the serialized representation of the data more efficiently.</p>
<p>Now let us look at how we can model our NoSQL data stores.</p>
<h2 id="_idParaDest-102"><a id="_idTextAnchor104"/>Implementing event sourcing using a non-relational database</h2>
<p><strong class="bold">NoSQL databases</strong> are also called <strong class="bold">document databases </strong>and are characterized<a id="_idIndexMarker283"/> by their ability to effectively<a id="_idIndexMarker284"/> store <a id="_idIndexMarker285"/>unstructured data. This means the following:</p>
<ul>
<li>Records do not need <a id="_idIndexMarker286"/>to meet any minimum structure. Columns are not mandated in the design phase, so it is easy enough to extend and contract the data based on the immediate need.</li>
<li>Data types are not strictly implemented, so the data structure can evolve at any point in time without having detrimental effects on previously stored records.</li>
<li>Data can be nested and can contain sequences. This is significant since we do not need to spread related data across multiple documents. One document can represent a denormalized representation of data from several sources.</li>
</ul>
<p>Popular examples of<a id="_idIndexMarker287"/> document stores are <strong class="bold">MongoDB</strong>, <strong class="bold">Microsoft Azure Cosmos DB</strong>, and <strong class="bold">Amazon DynamoDB</strong>, to name a few. Outside of the specific querying and integration requirements for each of these database options, the concepts of how documents are formed and <a id="_idIndexMarker288"/>stored are the<a id="_idIndexMarker289"/> same.</p>
<p>We can outline the properties of the document in a very similar manner to how a table would look. In a document data store, however, the data is stored in JSON format (unless specifically requested or implemented otherwise). An event entry would look something like this:</p>
<pre class="source-code">
{
    "type":"AppointmentCreated",
    "aggregateId":"aggregateId-guid-value",
    "data": {
        "doctorId": "doctorId-guid-value",
        "customerId": "customerId-guid-value",
        "dateTime": "recorded-date-time",
        ...
    },
    "timestamp":"2022-01-01T21:00:46Z"
}</pre>
<p>Another advantage to using a document data store is that we can more easily represent a record with its<a id="_idIndexMarker290"/> event history in a materialized <a id="_idIndexMarker291"/>view. That could look something like this:</p>
<pre class="source-code">
{
    "type":"AppointmentCreated",
    "aggregateId":"aggregateId-guid-value",
    "doctorId": "doctorId-guid-value",
    "customerId": "customerId-guid-value",
    "dateTime": "recorded-date-time",
    ...
    "history": [
        {
            "type":"AppointmentCreated",
            "data": {
                "doctorId": "doctorId-guid-value",
                "customerId": "customerId-guid-value",
                "dateTime": "recorded-date-time",
                ...
            },
            "timestamp":"2022-01-01T21:00:46Z"
        },
        {
            "type":"AppointmentUpdated",
            "data": {
                "doctorId": "different-doctorId-guid-value",
                "customerId": "customerId-guid-value",
                "comment":"Update comment here"
            },
            "timestamp":"2022-01-01T21:00:46Z",
            ...
        },
        ...
    ],
    "createdDate":"2022-01-01T21:00:46Z",
    ...
}</pre>
<p>This type of data representation can be advantageous for retrieving a record with all its events, especially if we intend to display this data on a user interface. We have generated a view that acts as both<a id="_idIndexMarker292"/> a snapshot of the current state of the aggregate data and the stream of events that have<a id="_idIndexMarker293"/> affected it. This form of data aggregation helps us to reduce some complexity and keep the concept of event retrieval simple.</p>
<p>Now that we see how we can implement a read-only and denormalized data store, let us review how we can use the CQRS pattern to retrieve the latest state of the data.</p>
<h2 id="_idParaDest-103"><a id="_idTextAnchor105"/>Reading state with CQRS</h2>
<p>We have reviewed the CQRS pattern, and<a id="_idIndexMarker294"/> we see where we can create handlers that will perform write operations. Earlier in this chapter, we enhanced our command handler functionality with the ability to trigger events, which are capable of performing triggering additional actions after a command has been completed.</p>
<p>In the context of the event sourcing pattern, this additional action involves updating our read-only data stores with the appropriate data per view. When creating our query handlers, we can rely on these tables for the latest version of the data that is available. This ties in perfectly with the ideal implementation of the CQRS pattern where separate data stores are to be used for read and write operations.</p>
<p>It also presents an excellent <a id="_idIndexMarker295"/>opportunity for us to provide more specific representations of the data we wish to present from our read operations. This approach, however, introduces the risk that our data stores might become out of sync in between operations, which is a risk that we must accept and mitigate as best as possible.</p>
<p>Now that we have explored events, event sourcing patterns, and event storage options, let us review these concepts.</p>
<h1 id="_idParaDest-104"><a id="_idTextAnchor106"/>Summary</h1>
<p>Event sourcing and event-driven design patterns bring a whole new dimension to what is required in our software implementation. These patterns involve additional code but do assist in helping us to implement additional business logic for completed commands while maintaining a reliable log of all the changes happening in our data store.</p>
<p>In this chapter, we explored what events are, various factors of event sourcing patterns, how we can implement certain aspects in a real application, and the pros and cons of using relational or non-relational storage options.</p>
<p>In our next chapter, we will explore the Database Per Service pattern and look at best practices when implementing the data access layer in each microservice.</p>
</div>


<div><h1 id="_idParaDest-105"><a id="_idTextAnchor107"/>Part 2: Database and Storage Design Patterns</h1>
<p>Understanding and implementing data management patterns and techniques is vital when designing a microservices application. Each microservice might need its database, and we need to understand the intricacies surrounding managing each database and how we coordinate efforts across services. By the end of this part, you will come to appreciate the tough decisions that need to be made surrounding databases in a microservices application. </p>
<p>This part has the following chapters:</p>
<ul>
<li><a href="B19100_07.xhtml#_idTextAnchor108"><em class="italic">Chapter 7</em></a>, <em class="italic">Handling Data for Each Microservice with the Database per Service Pattern</em></li>
<li><a href="B19100_08.xhtml#_idTextAnchor127"><em class="italic">Chapter 8</em></a>, <em class="italic">Implement Transactions across Microservices Using the Saga Pattern </em></li>
</ul>
</div>
<div><div></div>
</div>
</body></html>