- en: Chapter 5. Cameras, Rendering, and Scenes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章. 相机、渲染和场景
- en: This chapter focuses on some of the many things you can do with cameras, rendering,
    and scenes, as well as interesting combinations of them. Generally speaking, the
    camera is an eye point from which a scene is rendered. It is a point in 3D space
    from which a view of the scene, from a given perspective and field of view, is
    captured and rasterized to a texture in the form of pixels. After this, it's rendered
    to the screen by being blended and composited on top of any previous renders from
    any other cameras. Thus, cameras, rendering, and scenes are intimately connected
    processes. In this chapter, we'll see how to animate cameras and build fly-through
    animations, move cameras along curved paths, and see how objects can know whether
    they are being seen and when they are being seen by any specific camera. In addition,
    we'll see how to manually edit and process camera renders to create a postprocess
    effect, and we'll also see how to configure orthographic cameras to render pixel
    perfect 2D textures for 2D games and graphic user interfaces. So let's get started.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍你可以使用相机、渲染和场景以及它们之间有趣的组合做的一些事情。一般来说，相机是一个视点，从该视点渲染场景。它是一个3D空间中的点，从该点以特定的视角和视场捕捉场景视图，并将其光栅化成像素形式的纹理。然后，它通过与其他任何相机的渲染混合和合成渲染到屏幕上。因此，相机、渲染和场景是紧密相连的过程。在本章中，我们将了解如何动画化相机和构建飞行动画，如何沿着曲线路径移动相机，以及如何了解对象是否被看到以及何时被特定相机看到。此外，我们还将了解如何手动编辑和处理相机渲染以创建后处理效果，以及如何配置正交相机以渲染用于2D游戏和图形用户界面的像素完美的2D纹理。那么，让我们开始吧。
- en: Camera gizmos
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相机Gizmo
- en: 'When a camera is selected in the **Scene** tab and the **Gizmo** display is
    enabled, it displays a frustum gizmo that indicates clearly where the camera is
    positioned in the scene and what the camera can see from that view, given its
    other properties such as field of view, as shown in the following screenshot:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 当在**场景**选项卡中选择相机并且启用** Gizmo**显示时，它显示一个截锥体Gizmo，清楚地指示相机在场景中的位置以及从该视角可以看到的内容，考虑到其其他属性，如视场，如下截图所示：
- en: '![Camera gizmos](img/0655OT_05_01.jpg)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![相机Gizmo](img/0655OT_05_01.jpg)'
- en: Camera displays the frustum when selected in the Scene view
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景视图中选择相机时，相机显示截锥体
- en: 'This gizmo is especially helpful to position selected cameras to get the best
    possible view of the scene. However, there are times when you want to achieve
    almost the reverse, that is, to position objects in the view of unselected cameras.
    Specifically, you''ll want to move particular objects in the frustum of a camera
    and make sure it''s visible to that camera. This can be tedious to achieve under
    normal circumstances, because, by default, cameras don''t display their frustum
    gizmo when deselected. This means that as you move objects around, you''ll need
    to continually select and reselect your cameras to check whether the moved objects
    are really in the camera frustum, and adjust and tweak their positions if required.
    To solve this issue, it''d be great if Unity allowed you to view the frustum gizmo
    permanently, even when the camera was deselected, but it doesn''t, at least, not
    at the time of writing this book. To work around this, however, you can write
    a script, as shown in the following code sample 5-1:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这个Gizmo特别有助于定位选定的相机以获得场景的最佳视图。然而，有时你想要实现几乎相反的效果，即定位未选中的相机视图中的对象。具体来说，你希望将特定对象移动到相机的截锥体内，并确保它对该相机可见。在正常情况下，这可能会很繁琐，因为默认情况下，相机在未选中时不显示其截锥体Gizmo。这意味着当你移动对象时，你需要不断地选择和重新选择你的相机来检查移动的对象是否真的在相机截锥体内，并在必要时调整和微调它们的位置。为了解决这个问题，如果Unity允许你永久查看截锥体Gizmo，即使相机被选中，那将非常棒，但至少在撰写本书时，它并没有这样做。然而，为了解决这个问题，你可以编写一个脚本，如下面的代码示例
    5-1 所示：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following are the comments in code sample 5-1:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在代码示例 5-1 中的注释：
- en: '**Lines 27-31**: The `Gizmos.DrawFrustum` function accepts arguments such as
    position and rotation in world space and not local space. This means all positional
    arguments must first be transformed using a matrix from local space to world space.
    This is achieved with the `localToWorldMatrix` member of the `Transform` class.
    Additionally, the aspect argument requires further calculation between the actual
    viewport height and width, and the size of the game window in width and height.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第27-31行**：`Gizmos.DrawFrustum` 函数接受诸如位置和旋转等参数，这些参数是在世界空间中而不是局部空间中。这意味着所有位置参数必须首先使用从局部空间到世界空间的矩阵进行转换。这是通过
    `Transform` 类的 `localToWorldMatrix` 成员实现的。此外，宽高比参数还需要在实际视口的高度和宽度以及游戏窗口的宽度和高度之间进行进一步计算。'
- en: '**Lines 35-40**: The `GetGameViewSize` function returns a 2D vector that express
    the actual pixel dimensions of the **Game** tab view. It retrieves these values
    using undocumented editor features. The "undocumented" nature of the function
    call should be emphasized; this means that the code can easily be broken or invalidated
    by future and even minor releases.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第35-40行**：`GetGameViewSize` 函数返回一个二维向量，表示“游戏”标签视图的实际像素尺寸。它通过未记录的编辑器功能检索这些值。应强调函数调用的“未记录”性质；这意味着代码很容易被未来的版本甚至小版本更新所破坏或失效。'
- en: 'The following screenshot shows the frustum:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了棱台：
- en: '![Camera gizmos](img/0655OT_05_02.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![相机工具](img/0655OT_05_02.jpg)'
- en: Frustum is shown even when the camera is deselected
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 即使相机未被选中，也会显示棱台
- en: Being seen
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 被看到
- en: There are many occasions during gameplay when questions of object visibility
    arise, some actual and some hypothetical. Concerning the actual occasion, there
    are several questions we could ask, including whether object X is visible to camera
    Y right now, whether object X is visible to any camera right now, or when does
    object X become visible or nonvisible to a specific camera or to any camera. With
    regard to hypotheticals, we would ask whether object X would be visible if camera
    Y were moved to position Z. In the actual occasion case, we're concerned with
    the real visibility of objects for the current frame, based on the positions of
    all cameras, and concerning hypotheticals, we're concerned with what would be
    the case if a camera were moved to a specific position. Both these cases are important
    for games. Knowing whether objects (such as enemy characters) are really visible
    to the camera is important to define behavior and AI. This is because when objects
    are not visible, there are many behaviors and calculations we could suspend to
    save the processing workload. Further, knowing whether an object would become
    visible if the camera were moved is helpful because it lets us anticipate which
    objects, if any, will enter visibility for the next frame so that we can prepare
    them ahead of time. Now, before moving on to consider how these questions can
    be answered in script, it's worth considering the visibility in its narrowest
    sense.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在游戏过程中，经常会出现关于对象可见性的问题，有些是实际的，有些是假设性的。关于实际场合，我们可以提出几个问题，包括对象X是否现在对相机Y可见，对象X是否现在对任何相机可见，或者对象X何时对特定相机或任何相机变得可见或不可见。至于假设性，我们会问如果将相机移动到位置Z，对象X是否会可见。在实际场合的情况下，我们关注的是基于所有相机的位置，当前帧中对象的实际可见性，而对于假设性，我们关注的是如果将相机移动到特定位置会发生什么。这两种情况对游戏都很重要。知道对象（如敌人角色）是否真正对相机可见对于定义行为和AI很重要。这是因为当对象不可见时，我们可以暂停许多行为和计算以节省处理工作量。此外，知道如果移动相机对象是否会变得可见是有帮助的，因为它让我们能够预测哪些对象（如果有的话）将在下一帧进入可见范围，这样我们就可以提前做好准备。现在，在考虑如何在脚本中回答这些问题之前，值得考虑的是可见性的最狭义含义。
- en: 'In terms of visibility, there are two main concepts: frustum and occlusion.
    Each perspective camera has a viewing frustum, as we saw earlier; this frustum
    is a trapezoidal volume extended outwards from the camera lens and contains a
    region defined by field of view and clipping plane distance properties. The frustum,
    in essence, mathematically defines the horizons of a camera—the region of a scene
    that the camera can potentially observe right now. The word, potentially, is significant,
    because even when an active and visible object is within the camera frustum, it
    doesn''t necessarily mean that it''s visible to the camera. This is because objects
    within the frustum can occlude others also inside the frustum; that is, nearer
    objects can obscure or conceal objects behind them either fully or partially.
    For this reason, true visibility tests involve at least two processes: first,
    determining whether an object is in the frustum, and second, determining whether
    it is occluded or not. Only if an object passes both tests can it be classified
    as visible to the camera, and even then, only on the assumption that an object
    is not concealed or rendered invisible by custom shaders or other postprocess
    effects. In short, there are many reasons why true visibility testing is an intricate
    process, but here, I''ll take the two-stage test as good enough for most purposes.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在可见性的方面，有两个主要概念：视锥体和遮挡。每个透视相机都有一个视锥体，正如我们之前所看到的；这个视锥体是从相机镜头向外延伸的梯形体积，它包含一个由视野和裁剪平面距离属性定义的区域。从本质上讲，视锥体在数学上定义了相机的视野——场景中相机现在可以潜在观察到的区域。这个词“潜在”很重要，因为即使一个活跃且可见的对象位于相机视锥体内，也不一定意味着它对相机是可见的。这是因为视锥体内的对象可以遮挡视锥体内的其他对象；也就是说，较近的对象可以完全或部分地遮挡或隐藏它们后面的对象。因此，真正的可见性测试至少涉及两个过程：首先，确定对象是否在视锥体内，其次，确定它是否被遮挡。只有当一个对象通过这两个测试时，才能将其归类为对相机可见，即使在那时，也只是在假设对象没有被自定义着色器或其他后处理效果隐藏或渲染为不可见的情况下。简而言之，有许多原因说明真正的可见性测试是一个复杂的过程，但在这里，我会将两阶段测试视为大多数目的足够好了。
- en: Detecting the object visibility
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测对象的可视性
- en: 'Perhaps, the simplest and more direct visibility test for objects in Unity
    is determining when an object becomes visible and invisible to any camera. The
    two companion events, `OnBecameVisible` and `OnBecameInvisible`, are called automatically
    on any object with a renderer component, including `MeshRenderer` and `SkinnedMeshRenderer`.
    It''s not, of course, called on empty game objects even if they fall within the
    view of the camera, as they (technically speaking) contain no visible parts, despite
    all parts being spatially located. You can handle these events, as shown in the
    following code sample 5-2:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 也许，在Unity中对对象进行的最简单、最直接的可见性测试就是确定对象何时对任何相机变得可见或不可见。两个伴随事件，`OnBecameVisible`和`OnBecameInvisible`，会在任何具有渲染器组件的对象上自动调用，包括`MeshRenderer`和`SkinnedMeshRenderer`。当然，即使这些空游戏对象位于相机的视野内，也不会调用它们，因为（从技术上讲）它们不包含任何可见的部分，尽管所有部分都在空间上有位置。你可以像以下代码示例5-2中所示那样处理这些事件：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: There are several important caveats worth noting with the events `OnBecameVisible`
    and `OnBecameInvisible`. First, visibility here only means that an object has
    come within the camera frustum; thus, it can still be occluded by other, nearer
    objects, and so, it might not be truly visible at all. Second, the events pertain
    to all cameras and not to specific cameras. `OnBecameVisible` is called once to
    tell you that the object, while previously not visible, has now entered the frustum
    of at least one camera. Likewise, `OnBecameInvisible` is called once and tells
    you that the object, while previously visible, has now left the frustum of all
    cameras. Finally, and rather unhelpfully, these functions also include the visibility
    of the scene camera. This means that if you're testing your game with the **Scene**
    tab open and visible and the object is visible to you in the **Scene** tab, this
    will count as being visible. In short, the methods `OnBecameVisible` and `OnBecameInvisible`
    would be useful only if your behavior depends on the total visibility or invisibility
    in the scene, where visibility just corresponds to the frustum's presence. In
    other words, these events are a great place to toggle behaviors such as AI behaviors
    that depend on visibility, for example, NPC panic behaviors and other kinds of
    NPC-to-NPC interactions.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件 `OnBecameVisible` 和 `OnBecameInvisible` 中，有几个重要的注意事项值得注意。首先，这里的可见性仅指一个对象已经进入摄像机的视锥体内；因此，它仍然可能被其他更近的对象遮挡，所以它可能根本不可见。其次，这些事件适用于所有摄像机，而不是特定摄像机。`OnBecameVisible`
    只调用一次，告诉你对象之前不可见，现在已进入至少一个摄像机的视锥体。同样，`OnBecameInvisible` 也只调用一次，告诉你对象之前可见，现在已离开所有摄像机的视锥体。最后，而且相当不实用，这些函数还包括场景摄像机的可见性。这意味着如果你在打开并可见的
    **场景** 选项卡中测试你的游戏，并且对象在 **场景** 选项卡中对你可见，这将算作可见。简而言之，`OnBecameVisible` 和 `OnBecameInvisible`
    方法只有在你的行为依赖于场景中的总可见性或不可见性时才有用，其中可见性仅对应于视锥体的存在。换句话说，这些事件是切换依赖于可见性的行为的好地方，例如，AI
    行为，例如 NPC 惊慌行为和其他类型的 NPC 之间的交互。
- en: Tip
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: More information on the functions `OnBecameVisible` and `OnBecameInvisible`
    can be found online in the Unity documentation at [http://docs.unity3d.com/ ScriptReference/MonoBehaviour.OnBecameVisible.html](http://docs.unity3d.com/
    ScriptReference/MonoBehaviour.OnBecameVisible.html) and [http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameInvisible.html](http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameInvisible.html).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 关于函数 `OnBecameVisible` 和 `OnBecameInvisible` 的更多信息，可以在 Unity 文档中在线找到，网址为 [http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameVisible.html](http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameVisible.html)
    和 [http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameInvisible.html](http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameInvisible.html)。
- en: More on the object visibility
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于对象可见性的更多内容
- en: 'Another check that''s important, besides testing when an object enters and
    leaves camera visibility, is to test whether an object is visible right now to
    a specific camera. Unlike `OnBecameVisible` and `OnBecameInvisible`, which were
    called on a one-off basis when an object enters or leaves the frustum, this kind
    of test is about the current state of an object that assumes no prior knowledge
    of it. To achieve this, the `OnWillRenderObject` event can be used. This event
    is called continuously on an object, once per frame for each camera to which it
    is visible as long as the object is visible to that camera. "Visible" here is
    taken to mean "within the camera frustum". Again, no occlusion testing is applied.
    Refer to the following code sample 5-3, and notice that inside this event, the
    `Camera.current` member can be used to retrieve a reference to the camera to which
    the object is currently visible, including the scene view camera:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了测试对象何时进入和离开摄像机可见性之外，另一个重要的检查是测试对象是否现在对特定摄像机可见。与在对象进入或离开视锥体时一次性调用的 `OnBecameVisible`
    和 `OnBecameInvisible` 不同，这种测试是关于对象当前状态的一种假设，没有关于它的先验知识。为了实现这一点，可以使用 `OnWillRenderObject`
    事件。只要对象对该摄像机可见，这个事件就会在每个帧上连续调用一次，每次调用都是针对它可见的每个摄像机。这里的“可见”是指“在摄像机视锥体内”。同样，不应用遮挡测试。参考以下代码示例
    5-3，并注意在这个事件内部，可以使用 `Camera.current` 成员来获取当前对象可见的摄像机的引用，包括场景视图摄像机：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Frustum testing – renderers
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视锥体测试 – 渲染器
- en: 'There are many times when the Unity native camera events, as we saw earlier,
    are not sufficient for your visibility and frustum-testing requirements. Specifically,
    you might simply want to test whether just one specific camera can see a renderer,
    whether an invisible object would be seen if it were visible, whether a specified
    point in space is seen by the camera, or whether a camera would see a specific
    object if it were moved to a new location. All of these cases can be important
    visibility tests in different situations, and all of them require some degree
    of manual testing. To meet these camera visibility needs, we''ll need to code
    more intensively. The functions in the following sections will be compiled together
    as static functions in a dedicated `CamUtility` class. Let''s start by creating
    a function to test whether a specific renderer component is within the frustum
    of a specific `Camera` object, as shown in the following code sample 5-4:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多时候，Unity 本地相机事件，正如我们之前所看到的，不足以满足你的可见性和视锥测试需求。具体来说，你可能只想测试是否只有一个特定的相机可以看到渲染器，如果它是可见的，一个不可见对象是否会被看到，空间中指定的一点是否被相机看到，或者如果将相机移动到新位置，相机是否会看到特定的对象。所有这些情况在不同的场景中都可以作为重要的可见性测试，并且所有这些都需要一定程度的手动测试。为了满足这些相机可见性需求，我们需要更密集地编写代码。以下章节中的函数将被编译为在专门的
    `CamUtility` 类中的静态函数。让我们首先创建一个函数来测试特定渲染器组件是否位于特定 `Camera` 对象的视锥体内，如下面的代码示例 5-4
    所示：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: From lines 10–17, the `GeometryUtility` class is used to generate an array of
    plane objects that describe the camera frustum. Planes are to 3D space what lines
    are to 2D space; they mark out a flat, imaginary surface in 3D. The frustum planes
    are a collection of six planes that are rotated and aligned in 3D space to represent
    the complete trapezoidal camera frustum. This array is then used by the `TestPlanesAABB`
    function, **Axially Aligned Bounding Box** (**AABB**), which determines whether
    the collision boundary of a mesh renderer exists inside the frustum as defined
    by the planes.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从第 10-17 行，`GeometryUtility` 类被用来生成一个描述相机视锥体的平面对象数组。平面在 3D 空间中的作用类似于线在 2D 空间中的作用；它们在
    3D 中标记出一个平坦的、想象中的表面。视锥体平面是一组六个平面，它们在 3D 空间中旋转并对齐，以表示完整的梯形相机视锥体。然后，这个数组被 `TestPlanesAABB`
    函数（**轴对齐边界框**（**AABB**））使用，该函数确定网格渲染器的碰撞边界是否存在于由这些平面定义的视锥体内。
- en: Frustum testing – points
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视锥测试 – 点
- en: Of course, you don't always want to test renderers for visibility. Instead,
    you might simply want to test for a point. This might be for two main reasons.
    First, you might want to know whether an object, such as a particle or a gun target
    location, is actually visible. Second, you might not only want to know whether
    a point is visible but also where in the screen space; this will be rendered by
    the camera. The following code sample 5-5 will do this. It will test whether a
    point is within the camera frustum, and if so, it would further return where the
    point would be rendered on screen in a normalized viewport space (between 1-0).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你并不总是想测试渲染器的可见性。相反，你可能只想测试一个点。这可能有两个主要原因。首先，你可能想知道一个对象，例如粒子或枪靶位置，是否实际上是可见的。其次，你可能不仅想知道一个点是否可见，还想知道它在屏幕空间中的位置；这将由相机渲染。下面的代码示例
    5-5 将执行此操作。它将测试一个点是否在相机视锥体内，如果是的话，它还会进一步返回该点在标准化视口空间（介于 1-0 之间）中屏幕上的渲染位置。
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Frustum testing – occlusion
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视锥测试 – 遮挡
- en: 'As mentioned earlier, visibility in its strictest sense is primarily a two-stage
    and not a one-stage process. All visibility testing so far has consisted only
    of checking for an object''s presence within the frustum of a camera. Typically,
    this is enough, and it should always be preferred. However, sometimes, it''s really
    not enough, because even among objects within the frustum, it''s possible for
    one object to occlude another, as nearer objects can conceal objects further away,
    either fully or partially. This, in itself, is not always a problem though, because
    more often than not, the main interest in determining object visibility is simply
    to know whether the camera is near enough for a set of performance-intensive behaviors
    (such as AI behaviors) to be enabled. The aim is not truly visibility testing,
    but to know whether the camera is close enough. In these cases, it doesn''t matter
    whether the objects are occluded; it only matters whether they are in the frustum.
    Yet, occasionally, occlusion matters, such as when displaying GUI elements or
    pop-up notifications as the player looks at specific objects. In these cases,
    occlusion is important, because GUI elements should not pop up for objects on
    the other side of a wall, for example. Sometimes, you can even get around these
    situations with an inventive use of colliders, triggers, and careful object placement,
    and sometimes, there''s really no choice but to further filter objects in the
    frustum with occlusion testing. Now, occlusion testing among objects within the
    frustum is a deep subject that can, via some implementations, have a significant
    performance overhead. For this reason, one of the best methods is to use a simple
    `Physics.LineCast` method call to determine whether an imaginary line drawn between
    the camera and destination object is intersected by other colliders. This method
    usually works well, but its limitations should be recognized. First, it assumes
    that all visible objects have colliders; any exceptions to this rule will not
    be detected by the `LineCast` method. Second, as colliders only approximate the
    bounds of a mesh and do not wrap around the mesh vertex for vertex, it''s possible
    for the `LineCast` method to fail when meshes have internal holes, as the surrounding
    collider will prevent `LineCast` from penetrating them. Finally, meshes with transparent
    materials that reveal objects behind them will always fail the `LineCast` method.
    Consider the following code sample 5-6:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在严格意义上，可见性主要是一个两阶段过程，而不是一个单阶段过程。迄今为止的所有可见性测试都仅限于检查物体是否位于摄像机的视锥体内。通常情况下，这已经足够了，并且应该始终优先考虑。然而，有时这真的不够，因为即使在视锥体内的物体中，一个物体也可能遮挡另一个物体，因为较近的物体可能会完全或部分地遮挡较远的物体。尽管如此，这本身并不总是问题，因为通常情况下，确定物体可见性的主要兴趣只是要知道摄像头是否足够近，以便启用一组性能密集型行为（如AI行为）。目的是不是真正的可见性测试，而是要知道摄像头是否足够近。在这些情况下，物体是否被遮挡并不重要；重要的是它们是否在视锥体内。然而，偶尔遮挡确实很重要，例如当玩家查看特定物体时显示GUI元素或弹出通知。在这些情况下，遮挡很重要，因为GUI元素不应该在墙的另一侧的物体上弹出。有时，你可以通过创造性地使用碰撞体、触发器和仔细放置物体来绕过这些情况，有时，除了进一步通过遮挡测试过滤视锥体内的物体外，别无选择。现在，视锥体内物体的遮挡测试是一个深奥的主题，通过某些实现，它可能会产生显著的性能开销。因此，最好的方法之一是使用简单的`Physics.LineCast`方法调用来确定从摄像头到目标物体之间绘制的想象线是否被其他碰撞体相交。这种方法通常效果很好，但其局限性应该被认识到。首先，它假设所有可见物体都有碰撞体；任何违反此规则的例外都不会被`LineCast`方法检测到。其次，由于碰撞体仅近似网格的边界，并且不围绕网格顶点进行包裹，因此当网格有内部空洞时，`LineCast`方法可能会失败，因为周围的碰撞体会阻止`LineCast`穿透它们。最后，具有透明材质的网格，这些材质会揭示其后面的物体，将始终失败`LineCast`方法。考虑以下代码示例5-6：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Camera vision – front and back
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摄像头视觉 – 前视和后视
- en: 'In some games, such as RTS games or casual games, the camera horizon (or far
    clipping plane) does not have so great a significance, because the camera always
    sees everything that is in front of it. In these cases, when objects are outside
    the frustum, they are only outside in the *x* and *y* planes but not in the local
    *z* axis; that is, the hidden objects are only hidden because the camera is not
    directly looking at them. However, when the camera is appropriately orientated,
    objects can never be too far away in the distance to be seen beyond the far clipping
    plane. In situations like these, visibility tests can often be reduced to faster
    and simpler orientation tests. Thus, the question changes from, "Is the object
    within the frustum and not occluded?" to "Is the object in front of the camera
    or is it behind?" Here, the answer we need is different; the question is not one
    of visibility but of orientation, whether the camera and its subject are so oriented
    that the subject is in front of the camera or behind it. To test for this, the
    vector dot product can be used. The dot product accepts two vectors as input and
    reduces them to a single dimensional, numerical value as output. This value describes
    the angular relationship between the two input vectors. In the following code
    sample 5-7, the `CamFieldView` class can be attached to a camera, and it detects
    whether the camera can see a target object, that is, whether the target object
    is within a limited field of view in front of the camera:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些游戏中，例如RTS游戏或休闲游戏，相机地平线（或远裁剪平面）并不那么重要，因为相机总是能看到它前面的所有东西。在这些情况下，当对象在视锥体之外时，它们只在*x*和*y*平面上之外，但不在局部的*z*轴上；也就是说，隐藏的对象之所以被隐藏，仅仅是因为相机没有直接看向它们。然而，当相机适当定位时，对象在远处永远不会太远而看不到远裁剪平面之外。在这种情况下，可见性测试通常可以简化为更快的简单方向测试。因此，问题从“对象是否在视锥体内且未被遮挡？”转变为“对象是在相机前面还是后面？”在这里，我们需要的是不同的答案；这不是一个可见性问题，而是一个方向问题，即相机及其主题是否定位得如此，以至于主题在相机前面或后面。为了测试这一点，可以使用向量点积。点积接受两个向量作为输入，并将它们减少为一个单维的数值输出。这个值描述了两个输入向量之间的角度关系。在以下代码示例5-7中，可以将`CamFieldView`类附加到相机上，并检测相机是否可以看到目标对象，即目标对象是否在相机前方有限视野内：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Orthographic cameras
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正交相机
- en: 'Every newly created camera object in Unity is, by default, configured as a
    perspective camera, unless you change the default settings. This type of camera
    most closely corresponds to real-life cameras that have a position within the
    3D space, a curved lens, and employ methods to convert captured images onto a
    flat, 2D surface, like a screen. The chief symptom of such a camera is foreshortening,
    the name given to the distortion applied to rendered objects. Specifically, rendered
    objects grow smaller as they recede into the distance, the shape and appearance
    of objects change as they move further from the center of vision, and all parallel
    lines converge at a vanishing point somewhere in the distance, whether on the
    horizon line itself or on a secondary line. In contrast to perspective cameras,
    however, there are orthographic cameras. These are useful for the creation of
    2D and truly isometric games and not just for the semblance of isometric. With
    orthographic cameras, the lens is flattened out to a plane, and the result is
    a loss of foreshortening, that is, parallel lines remain parallel, objects don''t
    shrink with distance, 2D remains 2D even when moved away from the center of the
    view, and so on. You can easily switch a camera from **Perspective** to **Orthographic**
    using the **Projection** type setting from the Object Inspector, as shown in the
    following screenshot:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在Unity中，每个新创建的相机对象默认配置为透视相机，除非你更改默认设置。这种相机类型最接近现实生活中的相机，它们在3D空间中有一个位置，有一个弯曲的镜头，并采用将捕获的图像转换到平坦的二维表面（如屏幕）的方法。这种相机的典型症状是透视缩短，这是对渲染对象施加的畸变的名称。具体来说，随着渲染对象向远处退去，它们会变得越来越小，随着它们从视线的中心点远离，它们的形状和外观会发生变化，并且所有平行线都会在远处的某个消失点汇聚，无论是地平线本身还是次要的线条上。然而，与透视相机相对的是正交相机。这些相机对于创建2D和真正等距的游戏非常有用，而不仅仅是模仿等距。使用正交相机时，镜头被压扁成一个平面，结果是透视缩短的消失，即平行线保持平行，对象不会随着距离的增加而缩小，二维在远离视线的中心时仍然是二维，等等。你可以通过从对象检查器中的**投影**类型设置轻松地将相机从**透视**切换到**正交**，如下面的截图所示：
- en: '![Orthographic cameras](img/0655OT_05_03.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![正交相机](img/0655OT_05_03.jpg)'
- en: Changing a Perspective camera to an Orthographic one
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将透视摄像机更改为正交摄像机
- en: After changing the **Perspective** type to **Orthographic**, the camera frustum
    will also change from a trapezoidal volume to a box. Everything within the box
    will be visible, and nearer objects will continue to obscure more distant ones,
    but all other senses of depth will be lost, as shown in the following screenshot.
    Hence, this camera is considered suitable for 2D games.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在将**透视**类型更改为**正交**后，摄像机视锥体也将从梯形体积变为盒子。盒子内的所有内容都将可见，并且靠近的对象将继续遮挡更远处的对象，但所有其他深度感知都将消失，如下面的截图所示。因此，这种摄像机被认为适合用于2D游戏。
- en: '![Orthographic cameras](img/0655OT_05_04.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![正交摄像机](img/0655OT_05_04.jpg)'
- en: The frustum for an Orthographic camera is a box
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正交摄像机的视锥体是一个盒子
- en: 'The central problem when working with the **Orthographic** cameras is how to
    create a 1:1 relationship between world units (in the scene) and pixels (on screen).
    This problem arises because in 2D games and GUIs, it''s useful to show graphics
    on screen at their default and correct sizes, as defined in the texture files.
    In most 3D games, by contrast, texture mapping, foreshortening, and perspective
    means textures are seen distorted, that is, projected onto the surface of 3D objects
    where they are viewed not directly as though in a photo-editing program, but in
    perspective. With 2D games and sprites, the situation is different. These graphics
    are typically viewed head on. For this reason, it''s desirable to display them
    in their default sizes, pixel for pixel. This kind of display is called pixel
    perfection, because each pixel in the texture will be shown onscreen and in the
    game, unchanged. Achieving this in practice, however, requires a specific approach.
    In short, to map 1 world unit to 1 pixel, the **Size** field in the **Camera**
    tab should be set to half the vertical resolution of the game. Thus, if your game
    runs at 1024 x 768, the **Size** field should be `364`, because 768 / 2 = 364,
    as shown here:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用**正交**摄像机工作时，中心问题是如何在场景中的世界单位（单位）和屏幕上的像素之间创建1:1的关系。这个问题产生的原因是在2D游戏和GUI中，显示在屏幕上的图形以默认和正确的尺寸显示是有用的，正如在纹理文件中定义的那样。相比之下，在大多数3D游戏中，纹理映射、透视和缩放意味着纹理看起来是扭曲的，即投影到3D对象的表面上，它们不是直接看到的，就像在照片编辑程序中一样，而是在透视中看到的。对于2D游戏和精灵来说，情况是不同的。这些图形通常正面观看。因此，最好以默认大小显示它们，像素对像素。这种显示称为像素完美，因为纹理中的每个像素都将显示在屏幕和游戏中，且不发生变化。然而，在实践中实现这一点需要特定的方法。简而言之，要将1个世界单位映射到1个像素，应在**摄像机**选项卡中将**大小**字段设置为游戏垂直分辨率的一半。因此，如果你的游戏以1024
    x 768运行，则**大小**字段应设置为`364`，因为768 / 2 = 364，如下所示：
- en: '![Orthographic cameras](img/0655OT_05_05.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![正交摄像机](img/0655OT_05_05.jpg)'
- en: The Size field controls how world units map to pixels on screen
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 大小字段控制世界单位如何映射到屏幕上的像素
- en: 'You can set the **Size** field directly in the editor, but this would only
    work if your game resolution is constant and never changes. If the user can resize
    the game window or change the game resolution, then you would need to update the
    camera size in script, as shown in the following code sample 5-8:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接在编辑器中设置**大小**字段，但这仅在游戏分辨率恒定且永不更改的情况下才有效。如果用户可以调整游戏窗口大小或更改游戏分辨率，那么您就需要在脚本中更新摄像机大小，如下面的代码示例5-8所示：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Notice that the member variable `PixelsToWorldUnits` has been added to line
    13 to scale the orthographic size according to the **Pixels To Units** field of
    imported sprite textures, as shown in the following screenshot. This helps ensure
    that sprites will appear in their correct pixel sizes when shown on screen. This
    is so because all sprites are necessarily scaled by this value to map pixels in
    the texture to units in the world.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，成员变量`PixelsToWorldUnits`已添加到第13行，以根据导入的精灵纹理的**像素到单位**字段缩放正交大小，如下面的截图所示。这有助于确保精灵在屏幕上显示时将具有正确的像素大小。这是因为所有精灵都必须按此值缩放，以将纹理中的像素映射到世界中的单位。
- en: '![Orthographic cameras](img/0655OT_05_06.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![正交摄像机](img/0655OT_05_06.jpg)'
- en: Setting the Pixels to Units scale for sprite textures
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 设置精灵纹理的像素到单位缩放
- en: Camera rendering and postprocessing
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摄像机渲染和后期处理
- en: The official Unity documentation concerning camera rendering and postprocessing
    is comparatively sparse. However, this should not be taken as an indication that
    there's little to be said on the subject. On the contrary, Unity cameras and objects
    offer extensive flexibility over how the scene is rendered. These topics fall
    under the umbrella term of postprocessing. Specifically, this refers to all the
    additional edits and amendments made to a camera's rendered output that is not
    included as part of the normal render. This includes blur effects, color adjustments,
    fish-eye effects, and so on. It should be said here that access to these features
    is included only in the professional version of Unity and not in the free version.
    For this reason, free users will not be able to follow along and complete this
    section. However, for professional version users, there is a wide range of camera-rendering
    features available, as shown in the following screenshot. This section considers
    them by creating a camera change system in which one camera will cross-fade smoothly
    into another. By cross-fade, I don't simply mean that one camera will cut to another,
    which (incidentally) can be achieved by changing a camera's depth field, as higher-order
    cameras are rendered above lower-order cameras. I rather mean that the rendered
    output of the first camera will gradually dissolve in opacity to reveal the output
    of the second camera. So, let's get started.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 官方Unity文档关于相机渲染和后期处理的内容相对较少。然而，这并不意味着关于这个主题没有太多可说的。相反，Unity相机和对象在如何渲染场景方面提供了广泛的灵活性。这些主题属于后期处理的范畴。具体来说，这指的是对相机渲染输出所做的所有额外编辑和修改，这些编辑和修改不包括在正常渲染中。这包括模糊效果、颜色调整、鱼眼效果等等。应该指出的是，这些功能的访问仅限于Unity的专业版本，而不是免费版本。因此，免费用户将无法跟随并完成本节。然而，对于专业版本用户，有广泛的相机渲染功能可用，如图中所示。本节通过创建一个相机切换系统来考虑这些功能，其中一个相机将平滑地淡入到另一个相机。通过交叉淡入，我并不是简单地指一个相机会切换到另一个相机，这（顺便提一下）可以通过改变相机的深度场来实现，因为高级相机渲染在低级相机之上。我更指的是第一个相机的渲染输出将逐渐在透明度上溶解，以揭示第二个相机的输出。那么，让我们开始吧。
- en: '![Camera rendering and postprocessing](img/0655OT_05_07.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![相机渲染和后期处理](img/0655OT_05_07.jpg)'
- en: Creating a scene with multiple cameras
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 创建具有多个相机的场景
- en: Start the project with a scene that contains two separate areas or regions,
    as shown in the preceding screenshot. The sample project is included in the book's
    companion files (code bundle) inside the `Cameras` folder of this chapter. Each
    region of the scene should be assigned a separate camera; this makes a total of
    two cameras in the scene, and each camera component should be disabled. This will
    prevent the cameras from rendering themselves automatically. Here, we'll be rendering
    the cameras manually; this will allow the render from each camera to be composited
    and faded on top of the other.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以包含两个独立区域或区域的场景开始项目，如图中所示的前一个屏幕截图。示例项目包含在本书的配套文件（代码包）中，位于本章 `Cameras` 文件夹内。场景的每个区域应分配一个单独的相机；这样，场景中就有两个相机，每个相机组件都应该被禁用。这将防止相机自动渲染自身。在这里，我们将手动渲染相机；这将允许每个相机的渲染结果组合并淡入到其他相机之上。
- en: Tip
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: For each camera, the `AudioListener` component was removed, because a Unity
    scene can have only one `AudioListener` active at any one time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个相机，都移除了 `AudioListener` 组件，因为Unity场景在任何时候只能有一个活动的 `AudioListener`。
- en: 'Next, create a third camera tagged as `MainCamera` at the scene''s origin and
    set with a culling mask of nothing, making sure that the camera is active but
    can render nothing. This will represent the central main scene camera that composites
    together renders from all other cameras, as shown here:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在场景的原点创建一个标记为 `MainCamera` 的第三个相机，并设置一个空的剔除遮罩，确保相机处于活动状态但不能渲染任何内容。这将代表中央主场景相机，它将组合来自所有其他相机的渲染结果，如图所示：
- en: '![Camera rendering and postprocessing](img/0655OT_05_08.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![相机渲染和后期处理](img/0655OT_05_08.jpg)'
- en: Creating a third main camera for rendering
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 创建用于渲染的第三个主相机
- en: 'Now, the scene should have three cameras: two separate and disabled cameras
    at different locations (cameras **X** and **Y**), and one main camera at the scene''s
    origin (camera **Z**). On this basis, the following code sample 5-9 can be assigned
    to camera **Z**, and this allows fading between cameras **X** and **Y** when Space
    bar is pressed:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，场景应该有三个相机：两个位于不同位置的不同和禁用的相机（相机 **X** 和 **Y**），以及一个位于场景原点的主相机（相机 **Z**）。在此基础上，以下代码示例
    5-9 可以分配给相机 **Z**，这允许在按下空格键时在相机 **X** 和 **Y** 之间进行淡入淡出。
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following are comments in code sample 5-9:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对代码示例 5-9 的注释：
- en: '**Lines 011-020**: The `CamerFader` class is responsible for cross fading between
    `Camera[0]` and `Camera[1]`. To achieve this, several variables are created. The
    `Cameras` array maintains a list of cameras: two cameras in this case. The `CamCols`
    array is linked to `Cameras`. It describes the color by which the render from
    the camera will be multiplied; this allows the alpha value to make the render
    transparent. The `FadeTime` variable defines the total time in seconds for a camera
    fade in one direction, either fade-out or fade-in. Finally, the `Mat` variable
    references any valid material that will be applied to the final render from the
    main camera, that is, the pixels of the completed render, including everything
    composited from all the other cameras.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行 011-020**: `CamerFader` 类负责在 `Camera[0]` 和 `Camera[1]` 之间进行交叉淡入淡出。为了实现这一点，创建了几个变量。`Cameras`
    数组维护了一个相机列表：在这种情况下是两个相机。`CamCols` 数组与 `Cameras` 相关联。它描述了通过哪种颜色将相机渲染进行乘法；这允许通过
    alpha 值使渲染透明。`FadeTime` 变量定义了相机在一个方向上淡入或淡出的总时间（以秒为单位）。最后，`Mat` 变量引用任何将应用于主相机最终渲染的有效材质，即完成渲染的像素，包括从所有其他相机复合的所有内容。'
- en: '**Lines 023-038**: The `Start` method creates `RenderTexture` for each camera
    that assigns the texture to its `TargetTexture` member. In essence, this means
    each camera is assigned an internal texture to which its render is locally composited.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行 023-038**: `Start` 方法为每个相机创建 `RenderTexture`，并将纹理分配给其 `TargetTexture` 成员。从本质上讲，这意味着每个相机都被分配了一个内部纹理，其渲染将在本地进行复合。'
- en: '**Lines 033-052**: The `OnPostRender` event is called automatically by Unity
    for any active camera objects in the scene, once for each frame and after the
    camera has completed its render as normal. It gives the object an opportunity
    to render additional cameras or elements on top of the normal rendered data. Here,
    the `Render` method of each camera in the `Cameras` array is called; this method
    manually renders the camera, not directly on screen but to its render texture.
    Once rendered to the texture, the `Graphics.DrawTexture` function draws `RenderTexture`
    for each camera onto the screen in the order of the array, one atop the other.
    Notice that each `DrawTexture` call multiplies the `CamCols` color to the texture;
    this also factors in the alpha component for transparency.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行 033-052**: Unity 会自动调用 `OnPostRender` 事件，针对场景中任何活动的相机对象，每帧一次，在相机完成正常渲染之后。这给对象一个机会在正常渲染数据之上渲染额外的相机或元素。在这里，调用
    `Cameras` 数组中每个相机的 `Render` 方法；此方法手动渲染相机，不是直接在屏幕上，而是在其渲染纹理上。一旦渲染到纹理上，`Graphics.DrawTexture`
    函数按照数组的顺序将每个相机的 `RenderTexture` 绘制到屏幕上，一个叠一个。请注意，每个 `DrawTexture` 调用都会将 `CamCols`
    颜色乘以纹理；这也考虑了 alpha 成分以实现透明度。'
- en: '**Lines 059-063**: Like `OnPostRender`, the `OnRenderImage` event is called
    automatically on active camera objects by Unity, once per frame. It''s called
    after `OnPostRender` and just before the camera render is presented on screen.
    This event provides two arguments, namely, `src` and `dst`. The `src` argument
    is a reference to a render texture that contains the completed render from the
    camera, which was output from `OnPostRender`, and the `dst` argument reference
    defines the render texture that will be shown on screen when the `OnRenderImage`
    event completes. In short, this function gives us an opportunity to edit the pixels
    of the render either manually in code or via shader. Here, the `Graphics.Blit`
    function is called to copy the source to the destination render texture using
    the shader associated with the material reference `Mat`.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 059-063 行**：与 `OnPostRender` 类似，Unity 会自动在每一帧调用活动相机对象的 `OnRenderImage`
    事件。它在 `OnPostRender` 之后和相机渲染显示在屏幕上之前被调用。此事件提供两个参数，即 `src` 和 `dst`。`src` 参数是对包含从
    `OnPostRender` 输出的相机完成渲染的渲染纹理的引用，而 `dst` 参数引用定义了当 `OnRenderImage` 事件完成时将在屏幕上显示的渲染纹理。简而言之，此函数为我们提供了手动在代码中或通过着色器编辑渲染像素的机会。在这里，调用
    `Graphics.Blit` 函数使用与材质引用 `Mat` 关联的着色器将源复制到目标渲染纹理。 '
- en: '**Lines 067-085**: `Fade` is a `CoRoutine` that transitions a `From` color
    to a `To` color over the time (`TotalTime`). This `CoRoutine` method is used to
    transition the alpha of a camera color between `0` and `1`, which refer to transparent
    and opaque, respectively.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第 067-085 行**：`Fade` 是一个 `CoRoutine`，它将 `From` 颜色过渡到 `To` 颜色，过渡时间为 `TotalTime`。此
    `CoRoutine` 方法用于在相机颜色之间过渡 `0` 和 `1` 的 alpha 值，分别代表透明和不透明。'
- en: 'The following screenshot shows the cross-fading camera effect:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了交叉淡入淡出相机效果：
- en: '![Camera rendering and postprocessing](img/0655OT_05_09.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![相机渲染和后期处理](img/0655OT_05_09.jpg)'
- en: Cross-fading cameras
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 混合相机
- en: Camera shake
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相机抖动
- en: 'Now, here''s an effect we can achieve with the Unity free version: camera shake!
    For fighting, shooting, and action games generally, a camera shake effect can
    be important. It conveys impact, danger, action, dynamism, and excitement—a form
    of kinetic feedback. It can, in fact, be used to stand in for lots of other animations
    too that simulate a pervasive motion and emotion where there really isn''t any
    to be found elsewhere in the scene. To this extent, camera shakes can save us
    lots of work by creating an overarching animation, as shown here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是我们可以使用 Unity 免费版本实现的效果：相机抖动！对于战斗、射击和动作游戏通常来说，相机抖动效果可能很重要。它传达了冲击、危险、动作、动态和兴奋——一种动态反馈。实际上，它还可以用来代替许多其他动画，这些动画模拟了普遍的运动和情感，而在场景的其他地方找不到这些运动和情感。在这方面，相机抖动可以通过创建一个总动画来节省我们大量的工作，就像这里所展示的那样：
- en: '![Camera shake](img/0655OT_05_10.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![相机抖动](img/0655OT_05_10.jpg)'
- en: Camera shake effects
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 相机抖动效果
- en: 'There are many ways to create camera shakes, but all of them involve fluctuation
    of the camera position between a minimum and maximum range using some kind of
    "randomness" function. Sometimes, the "randomness" is left raw, and sometimes,
    it''s smoothened using the damping functionality to create a slower or more "flowing"
    shake. Refer to the following code sample 5-10 that can be attached to any camera
    to create a shake effect:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 创建相机抖动有许多方法，但它们都涉及使用某种“随机”函数在最小和最大范围之间波动相机位置。有时，“随机性”保持原始状态，有时则使用阻尼功能来平滑，以创建更慢或更“流畅”的抖动。请参考以下代码示例
    5-10，该示例可以附加到任何相机上以创建抖动效果：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Cameras and animation
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相机和动画
- en: Camera fly-throughs are animations in which the camera is moved and rotated
    over time across specific positions to create a cinematic. Their importance is
    primarily to create cut-scenes, though not exclusively. It can be useful for the
    creation of stylized third-person cameras and other top-down views in which the
    camera motion must be mapped in a specific and deliberated way. One of the most
    common methods to create a camera motion like this is to predefine them either
    using Unity's animation editor or third-party tools such as Maya, Blender, and
    3DS Max. However, there are times when more programmatic control is required over
    the camera to adjust its position manually, away from an average center, using
    smooth, curved motions, passing through a series of points or following a specific
    and predefined route. This section considers three approaches.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 相机飞行动画是一种动画，其中相机在特定位置随时间移动和旋转，以创建电影效果。它们的重要性主要是为了创建过场动画，尽管并非仅限于此。这对于创建需要以特定和深思熟虑的方式映射的相机运动，如风格化的第三人称相机和其他俯视视角非常有用。创建此类相机运动的最常见方法是在Unity的动画编辑器中使用预定义，或者使用第三方工具，如Maya、Blender和3DS
    Max。然而，有时需要对相机进行更程序化的控制，以手动调整其位置，远离平均中心，使用平滑的曲线运动，通过一系列点或遵循特定的预定义路线。本节考虑了三种方法。
- en: Follow cameras
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟随相机
- en: Perhaps, one of the most common camera needs is a follow camera, that is, a
    camera that tracks a specified object in the scene and follows it. This camera
    maintains some distance between the object and the camera, as shown in the following
    screenshot. This is useful for third-person cameras, such as over-the-shoulder
    views and top-down views for RTS games.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 也许，最常见的相机需求之一就是跟随相机，即跟踪场景中指定物体的相机，并跟随它。这种相机在物体和相机之间保持一定的距离，如下面的截图所示。这对于第三人称相机非常有用，例如肩上视角和俯视视角的即时战略游戏。
- en: '![Follow cameras](img/0655OT_05_11.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![跟随相机](img/0655OT_05_11.jpg)'
- en: Making a camera smoothly follow an object
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使相机平滑地跟随一个物体
- en: Tip
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: This project can be found in the book's companion files (code bundle) inside
    the `Camera_Smooth_Damp` folder of this chapter.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目可以在本书配套文件（代码包）中找到，位于本章`Camera_Smooth_Damp`文件夹内。
- en: 'For such cameras, a simple follow behavior is usually not enough for your purposes.
    If it were, you could simply parent the camera to the object and leave it at that.
    However, typically, you''ll want some degree of smoothing or damping to the camera
    motion, that is, a falling-off of speed that allows the camera to gradually slow
    down to a stop on reaching the target, as opposed to a sudden and immediate stop
    in which the camera is either travelling at full speed or not at all. To achieve
    this, the `Quaternion.Slerp` and `Vector3.SmoothDamp` functions can be used. Consider
    the following code sample 5-11 for a class that can be attached to any camera
    to smoothly follow an object:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这类相机，简单的跟随行为通常不足以满足你的需求。如果是这样，你只需将相机作为对象的父对象并保持即可。然而，通常你希望相机运动有一定的平滑或阻尼，也就是说，速度逐渐减慢直到停止，而不是突然立即停止，这时相机要么以全速行驶，要么完全不移动。为了实现这一点，可以使用`Quaternion.Slerp`和`Vector3.SmoothDamp`函数。考虑以下代码示例5-11，这是一个可以附加到任何相机上以平滑跟随物体的类：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Tip
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: More information on `Quaternion.Slerp` can be found online at [http://docs.unity3d.com/ScriptReference/Quaternion.Slerp.html](http://docs.unity3d.com/ScriptReference/Quaternion.Slerp.html),
    and more information on `Vector3.SmoothDamp` can be found online at [http://docs.unity3d.com/ScriptReference/Vector3.SmoothDamp.html](http://docs.unity3d.com/ScriptReference/Vector3.SmoothDamp.html).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`Quaternion.Slerp`的更多信息可以在网上找到，链接为[http://docs.unity3d.com/ScriptReference/Quaternion.Slerp.html](http://docs.unity3d.com/ScriptReference/Quaternion.Slerp.html)，关于`Vector3.SmoothDamp`的更多信息可以在网上找到，链接为[http://docs.unity3d.com/ScriptReference/Vector3.SmoothDamp.html](http://docs.unity3d.com/ScriptReference/Vector3.SmoothDamp.html)。
- en: Cameras and curves
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相机和曲线
- en: 'For cut-scenes, menu backgrounds, or simpler camera fly-throughs, you might
    just need the camera to travel roughly in a straight line that allows some curvature
    and fluctuation in speed as the camera moves using a smooth-in and smooth-out
    motion. This means that the camera picks up speed at the beginning and slowly
    drops in speed towards the end of the path. To achieve this, you can use a prescripted
    animation via Unity''s animation editor, or you can use animation curves, which
    offer a high degree of flexibility and control over object transformations across
    time, as shown here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于过场动画、菜单背景或更简单的相机飞行镜头，你可能只需要让相机大致沿直线移动，允许相机移动时有一定的曲线和速度波动，使用平滑进入和平滑结束的运动。这意味着相机在路径开始时加速，并在路径结束时逐渐减速。为了实现这一点，你可以通过Unity的动画编辑器使用预定义的动画，或者你可以使用动画曲线，它提供了对对象随时间变换的高度灵活性和控制，如下所示：
- en: '![Cameras and curves](img/0655OT_05_12.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![相机和曲线](img/0655OT_05_12.jpg)'
- en: Moving cameras with animation curves
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用动画曲线移动相机
- en: 'To create a camera control script that allows you to control object speed and
    motion over time, including curved motion and smoothing or damping of speed, the
    following code sample 5-12 can be used:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个允许你控制对象速度和随时间运动的脚本，包括曲线运动和速度的平滑或阻尼，可以使用以下代码示例5-12：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Tip
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: A sample project using animation curves for camera movement can be found in
    the book's companion files (code bundle) inside the `Camera_Anim_Curves` folder
    of this chapter.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的`Camera_Anim_Curves`文件夹中，可以在本书的配套文件（代码包）中找到一个使用动画曲线进行相机移动的示例项目。
- en: 'To use the `CameraMover` class, attach the script to a camera, and from the
    Object Inspector, click on each of the **X**, **Y**, and **Z** curve fields to
    plot the distance and speed of the camera over time. By clicking on a **Graph**
    swatch, you can edit the graph, thus adding points and defining a motion curve
    to apply for that axis. Notice that the **X**, **Y**, and **Z** motion is plotted
    to the object''s local axes (forward, up, and right) and not to the world axes
    (*x*, *y*, and *z*). This allows the object motion to apply relatively that offers
    you root-level control of object motion while honoring the relevance of animation
    data, as shown here:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`CameraMover`类，将脚本附加到相机上，并在对象检查器中点击每个**X**、**Y**和**Z**曲线字段来绘制相机随时间变化的距离和速度。通过点击一个**Graph**色块，你可以编辑图表，从而添加点并定义应用于该轴的运动曲线。请注意，**X**、**Y**和**Z**运动是绘制到对象的局部轴（前方、向上和向右）而不是世界轴（*x*、*y*和*z*）。这允许对象运动相对于局部轴进行，从而为你提供了对对象运动的根级控制，同时尊重动画数据的相关性，如下所示：
- en: '![Cameras and curves](img/0655OT_05_13.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![相机和曲线](img/0655OT_05_13.jpg)'
- en: Plotting motion curves using animation curves
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用动画曲线绘制运动曲线
- en: Tip
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: More information on animation curves can be found online in the Unity documentation
    at [http://docs.unity3d.com/Manual/AnimatorCurves.html](http://docs.unity3d.com/Manual/AnimatorCurves.html).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 更多有关动画曲线的信息可以在Unity文档中找到，请访问[http://docs.unity3d.com/Manual/AnimatorCurves.html](http://docs.unity3d.com/Manual/AnimatorCurves.html)。
- en: Camera paths – iTween
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相机路径 – iTween
- en: One very common feature request that, strangely, has not yet been implemented
    as a native Unity feature is programmable motion paths. This refers to the ability
    to have a `GameObject`, such as a camera, smoothly follow a path or spline using
    spherical interpolation, where the path is defined by a series of connected game
    objects. This feature already exists in the sense that camera motion can be defined
    through prescripted animations that are created using Unity's animation editor.
    However, there is a desire for more flexible and programmatic control over a motion
    path in which the path is defined by a set of waypoints that can be adjusted in
    code over time. This functionality is especially useful, for example, for space-shooter
    games where the trajectory of enemy ships clearly follows smooth, curved flight
    paths that sometimes change according to the position of the player's space ship,
    as shown in the following screenshot. There are many ways to achieve this in Unity,
    but a quick and easy solution is to use the freely available add-on, iTween by
    Bob Berkebile; this can be downloaded and imported directly from Unity's Asset
    Store. More information on iTween can be found at [http://itween.pixelplacement.com/index.php](http://itween.pixelplacement.com/index.php).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常常见的功能请求，奇怪的是，它尚未作为原生 Unity 功能实现，那就是可编程的运动路径。这指的是一个 `GameObject`，例如相机，能够通过球形插值平滑地跟随路径或样条曲线，其中路径由一系列连接的游戏对象定义。这个功能已经存在，因为相机运动可以通过使用
    Unity 的动画编辑器创建的预定义动画来定义。然而，人们希望对运动路径有更多灵活和程序化的控制，其中路径由一组航点定义，这些航点可以在代码中随时间调整。这种功能特别有用，例如，在太空射击游戏中，敌舰的轨迹明显遵循平滑的曲线飞行路径，有时根据玩家太空船的位置而改变，如以下截图所示。在
    Unity 中实现这一点的有许多方法，但一个快速简便的解决方案是使用 Bob Berkebile 提供的免费插件 iTween；这可以直接从 Unity 的
    Asset Store 下载和导入。更多关于 iTween 的信息，请访问 [http://itween.pixelplacement.com/index.php](http://itween.pixelplacement.com/index.php)。
- en: '![Camera paths – iTween](img/0655OT_05_14.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![Camera paths – iTween](img/0655OT_05_14.jpg)'
- en: Creating camera motion paths with iTween
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 iTween 创建相机运动路径
- en: In addition to the default iTween package, you can also download the freely
    available extension for iTween, namely, the Visual iTween Path Editor, which is
    accessible from [http://pixelplacement.com/2010/12/03/visual-editor-for-itween-motion-paths/](http://pixelplacement.com/2010/12/03/visual-editor-for-itween-motion-paths/).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了默认的 iTween 包之外，您还可以下载免费提供的 iTween 扩展，即 Visual iTween Path Editor，可通过 [http://pixelplacement.com/2010/12/03/visual-editor-for-itween-motion-paths/](http://pixelplacement.com/2010/12/03/visual-editor-for-itween-motion-paths/)
    访问。
- en: 'After importing both iTween packages, the next step is to start using it to
    create an object animated along a path. To take the example of a camera fly-through,
    drag-and-drop the script `iTweenPath` onto a camera object. This script allows
    you to create an independent and named path that consists of multiple waypoints,
    as shown here:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入两个 iTween 包之后，下一步是开始使用它来创建沿路径动画的对象。以相机飞行为例，将脚本 `iTweenPath` 拖放到相机对象上。此脚本允许您创建一个由多个航点组成的独立且命名的路径，如下所示：
- en: '![Camera paths – iTween](img/0655OT_05_15.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![Camera paths – iTween](img/0655OT_05_15.jpg)'
- en: The iTweenPath script allows you to define a path of waypoints
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: iTweenPath 脚本允许您定义一个航点路径
- en: 'To define multiple waypoints for a path, enter the total number of waypoints
    to create inside the **Node Count** field and then select each node gizmo in the
    **Scene** viewport that transforms each into place. Notice the curved path drawn
    between the points that outline the path for the camera to take:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要为路径定义多个航点，请在**节点计数**字段中输入要创建的总航点数，然后选择**场景**视图中每个节点的小工具，将其转换到适当的位置。注意，在定义相机行进路径的点之间绘制的曲线路径：
- en: '![Camera paths – iTween](img/0655OT_05_16.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![Camera paths – iTween](img/0655OT_05_16.jpg)'
- en: Defining the waypoints for a path
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 定义路径的航点
- en: 'Then, to make the camera follow the path at runtime, add the following code
    sample 5-13 script to the camera :'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了在运行时使相机跟随路径，将以下代码示例 5-13 脚本添加到相机中：
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Tip
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小贴士
- en: More information on iTween and its usage can be found online at [http://itween.pixelplacement.com/gettingstarted.php](http://itween.pixelplacement.com/gettingstarted.php).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于 iTween 及其使用的详细信息，可在网上找到，请访问 [http://itween.pixelplacement.com/gettingstarted.php](http://itween.pixelplacement.com/gettingstarted.php)。
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter concentrated on many common tasks expected or needed of cameras.
    Cameras are essential in Unity and in any game engine, because they represent
    the perspective from which the scene is rendered to the screen. Most of the camera
    functionality is commonly taken for granted in Unity, and as a result, much of
    the flexibility and control that cameras offer us is lost and not discussed. Specifically,
    here, we first considered gizmo rendering, that is, how to permanently render
    the camera gizmo in the scene viewport even when the camera is deselected. Second,
    we saw how to determine which objects are visible to the camera and which are
    not. This included several kinds of important tests such as frustum presence and
    occlusion testing. Third, we saw how to create and configure orthographic cameras
    that render 2D elements without perspective distortion. Fourth, we saw how to
    edit and enhance a camera render through render textures. This involved overriding
    a series of camera-critical events and blending renders from other cameras to
    create a camera cross-fade effect. Fifth, we saw how to create more advanced camera
    motions, such as camera shake. Finally, you learned about camera paths, that is,
    the ability for a camera to follow a specified path, whether this path was defined
    by a series of game object waypoints or was simply an object to follow. Next up,
    we'll explore the Mono Framework further.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本章主要集中讨论了相机常见的许多预期或必需的任务。在Unity和任何游戏引擎中，相机都是必不可少的，因为它们代表了场景渲染到屏幕上的视角。在Unity中，大多数相机功能通常被视为理所当然，因此，相机为我们提供的许多灵活性和控制性都丢失了，并且没有被讨论。具体来说，在这里，我们首先考虑了gizmo渲染，即如何在场景视图中永久渲染相机gizmo，即使相机被取消选择。其次，我们看到了如何确定哪些对象对相机是可见的，哪些是不可见的。这包括了几种重要的测试，如视锥体存在性和遮挡测试。第三，我们看到了如何创建和配置正交相机，这些相机可以渲染没有透视畸变的2D元素。第四，我们看到了如何通过渲染纹理编辑和增强相机渲染。这涉及到覆盖一系列相机关键事件，并将来自其他相机的渲染混合以创建相机交叉淡入淡出效果。第五，我们看到了如何创建更高级的相机运动，例如相机抖动。最后，你学习了关于相机路径的知识，即相机能够跟随指定路径的能力，无论这条路径是由一系列游戏对象航点定义的，还是简单地跟随一个对象。接下来，我们将进一步探索Mono框架。
