- en: '18'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Performance Wizardry: Optimizing Your Game with Profiler Tools'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Welcome to the fourth part of this book—I am glad you have reached this part
    as it means that you have almost completed a full game! So far, we have developed
    a game while focusing on implementing different gameplay features and effects,
    but we didn’t consider how well they were performing in terms of our game’s **frames
    per second** (**FPS**). In this chapter, we are going to discuss optimization
    techniques to review your game’s performance and improve it, as having a good
    and constant frame rate is vital to any game.
  prefs: []
  type: TYPE_NORMAL
- en: Performance is a broad topic that requires a deep understanding of several Unity
    systems and could span several books. We are going to look at how to measure performance
    and explore the effects of our changes to systems to learn how they work through
    testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will examine the following performance concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing graphics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will be able to gather performance data on the
    three main pieces of hardware that run your game—the GPU, CPU, and RAM. You will
    be able to analyze that data to detect possible performance issues and understand
    how to solve the most common ones.
  prefs: []
  type: TYPE_NORMAL
- en: We will start by learning how to optimize the graphics side of our game.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing graphics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most common cause of performance issues is related to the misuse of assets,
    especially on the graphics side, due to not having enough knowledge of how Unity’s
    graphics engines work. We are going to explore how a GPU works at a high level
    and how to improve its usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will examine the following graphics optimization concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to graphics engines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Frame Debugger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using batching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other optimizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start by looking at a high-level overview of how graphics are rendered
    to better understand the performance data that we will gather later in Frame Debugger.
    Based on the debugger’s results, we are going to identify the areas where we can
    apply **batching** (which is a technique to combine the rendering process of several
    objects, reducing its cost), along with other common optimizations to keep in
    mind.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to graphics engines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Nowadays, every gaming device, whether it is a computer, a mobile device, or
    a console, has a video card—a set of hardware that specializes in graphics processing.
    It differs from a CPU in a subtle but important way. Graphics processing involves
    the processing of thousands of mesh vertices and the rendering of millions of
    pixels in a single frame. This is in charge of calculating the color and lighting
    of your objects’ pixels and moving and animating your objects’ geometry. The GPU
    is designed to run short programs a massive number of times, while the CPU can
    handle programs of any length but with limited parallelization capabilities. The
    reason for having those processing units (CPU and GPU) is so that our program
    can use each one when needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem here is that graphics don’t just rely on the GPU. The CPU is also
    involved in the process, making calculations and issuing commands to the GPU,
    so they must work together. For that to happen, both processing units need to
    communicate, and because they are (usually) physically separated, they need another
    piece of hardware to allow this: a bus, with the most common type being the **Peripheral
    Component Interconnect Express** (**PCI Express**) bus.'
  prefs: []
  type: TYPE_NORMAL
- en: '**PCI** **Express** is a type of connection that allows massive amounts of
    data to be moved between the GPU and CPU, but the problem is that even if it’s
    very fast, the communication time can be noticeable if you issue a lot of commands
    between both units. So, the key concept here is that graphics performance is improved
    mainly by reducing the communications between the GPU and CPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, font, screenshot, line  Description automatically
    generated](img/B21361_18_01_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.1: CPU/GPU communication through a PCI Express bus'
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, new hardware architecture allows the CPU and GPU to coexist in the
    same chipset, reducing communication time and even sharing memory. Sadly, that
    architecture doesn’t allow the processing power needed for video games, as having
    those two pieces separated allows them to have enough space for a large number
    of cores.
  prefs: []
  type: TYPE_NORMAL
- en: The basic responsibility of a graphics engine is to determine which objects
    are visible using culling algorithms, sorting and grouping them according to their
    similarities, and then issuing drawing commands to the GPU to render those groups
    of objects, sometimes more than once. The main form of communication between the
    CPU and GPU is the **drawing commands**, usually called **draw calls**, and our
    main task when optimizing graphics is to reduce them as much as we can. The problem
    is that there are several sources of draw calls that need to be considered, such
    as the lighting or certain special effects. Studying every single one of them
    will take a long time, and even so, new versions of Unity can introduce new graphics
    features with their own draw calls. Instead, we will explore a way to discover
    these draw calls using Frame Debugger.
  prefs: []
  type: TYPE_NORMAL
- en: Using Frame Debugger
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Frame Debugger** is a tool that allows us to see a list of all the draw calls
    that the Unity rendering engine sends to the GPU. It not only lists them but also
    provides information about each draw call, including the data needed to detect
    optimization opportunities. By using Frame Debugger, we can see how our changes
    modify the number of draw calls, giving us immediate feedback on our efforts.'
  prefs: []
  type: TYPE_NORMAL
- en: Note that reducing draw calls is sometimes not enough to improve performance,
    as each draw call can have different processing times, but usually, that difference
    is not big enough to consider. Also, in certain special rendering techniques,
    such as ray tracing or ray marching, a single draw call can drain all of our GPU
    power. This won’t be the case in our game, so we won’t take that into account
    right now.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use Frame Debugger to analyze the rendering process of our game by doing
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Open Frame Debugger (**Window | Analysis | Frame Debugger**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Play the game, and when you want to analyze the performance, click the **Enable**
    button in the top-left corner of Frame Debugger (press *Esc* to regain control
    of the mouse while playing):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B21361_18_02_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.2: Enabling Frame Debugger'
  prefs: []
  type: TYPE_NORMAL
- en: Click on the **Game** tab to open the **Game** view.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Drag the slider to the right of the **Disable** button slowly from left to
    right to see how the scene is rendered. Each step is a draw call that is being
    executed in the CPU for that given game frame. You can also observe how the list
    in the left part of the window highlights the name of the executed draw call at
    that moment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B21361_18_03_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.3: Analyzing our frame’s draw calls'
  prefs: []
  type: TYPE_NORMAL
- en: If some of the draw calls in the list output a gray image in the **Game** panel,
    alongside a warning in the console, a temporary fix for this is selecting your
    scene’s main camera and setting the **MSAA** property in the **Output** section
    of its **Camera** component to **Off**. Remember to revert this change afterward
    using Frame Debugger.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on any draw call from the list and observe the details in the right part
    of the window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Most of them can be confusing to you if you are not used to coding engines
    or shaders, but you can see that some of them have a human-readable part that
    says why this draw call can’t be batched with the previous one, which tells you
    why two objects weren’t drawn together in a single draw call. We will examine
    those reasons later:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B21361_18_04.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 18.4: The batching break reasons in Frame Debugger'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With the window open in **Play** mode, disable the terrain and see how the amount
    of draw calls changes immediately. Sometimes, just turning objects on and off
    can be enough to detect what is causing performance issues. Also, try disabling
    post-processing and other graphics-related objects, such as particles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Even if we are not fully aware of where each one of these draw calls came from,
    we can at least start by modifying the settings throughout Unity to see the impact
    of those changes. There’s no better way of discovering how something as massive
    as Unity works than going through every toggle and seeing the impact of those
    changes through a measuring tool. Of course, sometimes we just need to pay the
    price of certain draw calls to achieve certain effects, like in the case of the
    terrain, although you can always wonder whether it’s worth it or not; that would
    require a case-by-case analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Even if Frame Debugger gives us lots of info, sometimes you can take an extra
    step and use more advanced tools, like RenderDoc or NVIDIA Nsight, some of which
    work similarly to Frame Debugger in the sense that they show all the draw calls
    but also show info like the timings of each draw call, meshes, shaders, textures
    being used by each one of them, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s discuss the basic techniques for reducing draw calls and see their
    effects in Frame Debugger.
  prefs: []
  type: TYPE_NORMAL
- en: Using batching
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discussed several optimization techniques in previous chapters, with lighting
    being the most important one. If you measure the draw calls as you implement the
    techniques, you will notice the impact of those actions on the draw call count.
    However, in this section, we will focus on another graphics optimization technique
    known as batching. **Batching** is the process of grouping several objects to
    draw them together in a single draw call.
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering why we can’t just draw everything in a single draw call,
    and while that is technically possible, there is a set of conditions that need
    to be met in order to combine two objects, with the usual case being combining
    materials.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that materials act as graphic presets, specifying a **Material** mode
    or shader and a set of parameters to customize the aspect of our objects, like
    the object’s color and texture. If Unity has to draw an object with a different
    material than the previous one, a `SetPass` call needs to be called before issuing
    its draw call, which is another form of CPU/GPU communication used to set the
    **Material** properties in the GPU, such as its textures and colors. If two objects
    use the same materials, this step can be skipped. The `SetPass` call from the
    first object is reused by the second, and that opens the opportunity to batch
    the objects. If they share the same settings, Unity can combine the meshes into
    a single one in the CPU, and then send the combined mesh in a single draw call
    to the GPU.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to reduce the number of materials, such as removing duplicates,
    but the most effective way is through a concept called **texture atlasing**. This
    means merging textures from different objects into a single one. This way, several
    objects can use the same material due to the fact that the texture used there
    can be applied to several objects and an object that has its own texture requires
    its own material. Sadly, there’s no automatic system in Unity to combine the textures
    of three-dimensional objects, such as the Texture Atlasobject we used in 2D. There
    are probably some systems in the Asset Store, but automatic systems can have several
    side effects.
  prefs: []
  type: TYPE_NORMAL
- en: 'This work is usually done by an artist, so just keep this technique in mind
    when working with a dedicated 3D artist (or if you are your own artist):'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing screenshot  Description automatically generated](img/B21361_18_05_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.5: Pieces of different metallic objects'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s explore batching with Frame Debugger by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to **Edit** | **Preferences** | **Core Render Pipeline** and set **Visibility**
    to **All Visible**. This will allow us to see both basic and advanced graphics
    settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B21361_18_06_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.6: Enabling the display of all available graphics settings'
  prefs: []
  type: TYPE_NORMAL
- en: 'Search for the **Scriptable Render Pipeline Settings** asset that we currently
    want to use (**Edit** | **Project Settings** | **Graphics** | **Scriptable Render
    Pipeline Settings**):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B21361_18_07_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.7: Scriptable Render Pipeline Settings'
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, uncheck **SRP Batcher** in the **Rendering** section and check **Dynamic
    Batching**. We will re-enable this later in this chapter to better understand
    why we should always use **SRP Batcher**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B21361_18_08_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.8: Disabling SRP Batcher'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new empty scene for testing (**File** | **New Scene**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create two materials of different colors.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create two cubes and put one material into the first and the other into the
    second.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open Frame Debugger and click **Enable** to see the call list for the draw
    calls of our cubes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B21361_18_09_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.9: The draw calls for the cubes'
  prefs: []
  type: TYPE_NORMAL
- en: Select the second **Draw Mesh Cube** call and look at the batch-breaking reason.
    It should say that the objects have different materials.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use one of the materials on both cubes and look at the list again. You will
    notice that now we just have one **Draw Mesh Cube** call. You might need to disable
    and enable Frame Debugger again for it to refresh properly if you are not playing
    the game.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, I challenge you to try the same steps but create spheres instead of cubes.
    While performing this challenge, note your observations and hypotheses about why
    the results differ between cubes and spheres. If you do that, you will probably
    notice that even with the same materials, the spheres are not batched! Here is
    where we need to introduce the concept of **dynamic batching**.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that GameObjects have a **Static** checkbox, which serves to notify
    several Unity systems that the object won’t move so that they can apply several
    optimizations. Objects that don’t have this checkbox checked are considered dynamic.
    So far, the cubes and spheres we used for our tests have been dynamic, so Unity
    needed to combine them in every frame because they can move, and combining is
    not “free.” Its cost is associated directly with the number of vertices in the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can get the exact numbers and all the required considerations from the
    Unity manual, which will appear if you search for `Unity Batching` on the internet,
    or they can be accessed with this link: [https://docs.unity3d.com/Manual/DrawCallBatching.html](https://docs.unity3d.com/Manual/DrawCallBatching.html).
    However, it is enough to say that if the number of vertices of an object is big
    enough, that object won’t be batched, and doing so would require more than issuing
    two draw calls. That’s why our spheres weren’t batched; a sphere has too many
    vertices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, things are different if we have static objects because they use a second
    batching system—the **static batcher**. The concept of this is the same. Merge
    objects to render them in one draw call, and again, these objects need to share
    the same material. The main difference is that this batcher will batch more objects
    than the dynamic batcher because the merging is done once at the time that the
    scene loads and is then saved in memory to use in the next frames, costing memory
    but saving lots of processing time with each frame. You can use the same approach
    as we used to test the dynamic batcher to test the static version just by checking
    the **Static** checkbox of the spheres this time and seeing the result in **Play**
    mode; in **Edition** mode (when it is not playing), the static batcher won’t work:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B21361_18_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.10: A static sphere and its static batch'
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on, let’s discuss why we disabled SRP Batcher and how that changes
    what we just discussed. In its 2020 edition, Unity introduced the **Universal
    Render Pipeline** (**URP**), a new render pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with several improvements, one that is relevant right now is SRP Batcher,
    a new batcher that works on dynamic objects with no vertex or material limits
    (but with other limits). Instead of relying on sharing the same material with
    batch objects, SRP Batcher can have a batch of objects with materials that use
    the same shader, meaning we can have, for example, 100 objects with 100 different
    materials for each one, and they will be batched regardless of the number of vertices,
    as long as the material uses the same shader and variant:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, sign, screenshot  Description automatically generated](img/B21361_18_11_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.11: GPU data persistence for materials, which allows SRP Batcher
    to exist'
  prefs: []
  type: TYPE_NORMAL
- en: One shader can have several versions or variants, and the selected variant is
    chosen based on the settings. We can have a shader that doesn’t use normal mapping
    and a variant that doesn’t calculate normals will be used, so that can affect
    SRP Batcher. So, there’s basically no drawback to using SRP Batcher, so go ahead
    and turn it on again. Try creating lots of spheres with as many materials as you
    can and check the number of batches it will generate in Frame Debugger. Just consider
    that if you need to work on a project done in a pre-URP era, this won’t be available,
    so you will need to know the proper batching strategy to use.
  prefs: []
  type: TYPE_NORMAL
- en: Other optimizations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned before, there are lots of possible graphics optimizations, so let’s
    discuss briefly the basic ones, starting with **Level of Detail** (**LOD**). LOD
    is the process of changing the mesh of an object based on its distance to the
    camera. This can reduce draw calls if you replace, for example, a house with several
    parts and pieces with a single combined mesh with reduced detail when the house
    is far away. Another benefit of using LOD is that you reduce the cost of a draw
    call because of the reduction in the vertex count.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use this feature, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an empty object and parent the two versions of the model. You need to
    use models that have several versions with different levels of detail, but for
    now, we are just going to test this feature using a cube and a sphere:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A picture containing diagram  Description automatically generated](img/B21361_18_12_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.12: A single object with two LOD meshes'
  prefs: []
  type: TYPE_NORMAL
- en: Add a **LOD Group** component to the parent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The default LOD group is prepared to support three LOD meshe groups, but as
    we only have two, right-click on one and click **Delete**. You can also select
    **Insert Before** to add more LOD groups:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Funnel chart  Description automatically generated with low confidence](img/B21361_18_13_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.13: Removing a LOD group'
  prefs: []
  type: TYPE_NORMAL
- en: Select **LOD 0**, the highest-detail LOD group, and click on the **Add** button
    in the **Renderers** list below this to add the sphere to that group. You can
    add as many mesh renderers as you want.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B21361_18_14_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.14: Adding renderers to LOD groups'
  prefs: []
  type: TYPE_NORMAL
- en: Select **LOD 1** and add the cube.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the line between the two groups to control the distance range that each
    group will occupy. As you drag it, you will see a preview of how far the camera
    needs to be to switch groups. Also, you have the **Culled** group, which is the
    distance from where the camera will not render any group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Just move around the scene in the **Scene** panel to see how the meshes are
    swapped.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Something to consider here is that the colliders of the objects won’t be disabled,
    so just have the renderers in the LOD sub-objects. Put the collider with the shape
    of LOD 0 in the parent object, or just remove the colliders from the LOD group
    objects, except group 0.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Another optimization to consider is **frustum culling**. By default, Unity
    will render any object that falls into the view area or frustum of the camera,
    skipping the ones that don’t. The algorithm is cheap enough to always use, and
    there’s no way to disable it. However, it does have a flaw. If we have a wall
    hiding all the objects behind it, even if they are occluded, they fall inside
    the frustum, so they will be rendered anyway. Detecting whether every pixel of
    a mesh occludes every pixel of the other mesh is almost impossible to do in real
    time, but luckily, we have a workaround: occlusion culling.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Occlusion culling** is a process that analyzes a scene and determines which
    objects can be seen in different parts of the scene, dividing them into sectors
    and analyzing each one. As this process can take quite a long time, it is done
    in the editor, similar to lightmapping. As you can imagine, it only works on static
    objects given that it’s calculated in editor time. To use it, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Mark the objects that shouldn’t move as static, or if you only want this object
    to be considered static for the occlusion culling system, check the **Occluder
    Static** and **Occludee Static** checkboxes of the arrow to the right of the **Static**
    checkbox. Occluder means that the object can occlude other objects, and occludee
    means that this object can be occluded by other occluder objects. We are setting
    out objects to occlude and be occluded likewise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For extra performance, you might want to think about which objects are occluders
    and which ones occludees. Small objects are unlikely to occlude other objects,
    so it might be worth not checking the occluder flag on those. Likewise, big objects
    that might not get occluded at all depending on your scene’s setup might be good
    candidates to not be occludees.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Open the **Occlusion Culling** window (**Window | Rendering | Occlusion Culling**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the scene, hit the **Bake** button at the bottom of the window, and then
    wait for the baking process. If you don’t save the scene before the baking process,
    it won’t be executed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the **Visualization** tab in the **Occlusion Culling** window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With the **Occlusion Culling** window visible, select the camera (or virtual
    camera in the case of a Cinemachine-controlled camera) and drag it around, seeing
    how objects are occluded as the camera moves:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A picture containing outdoor, aircraft  Description automatically generated](img/B21361_18_15_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.15: On the left is the normal scene and on the right is the scene
    with occlusion culling'
  prefs: []
  type: TYPE_NORMAL
- en: Take into account that if you move the camera outside the calculated area, the
    process won’t take place, and Unity will only calculate areas near the static
    objects. You can extend the calculation area by creating an empty object and adding
    an **Occlusion Area** component, setting its position and size to cover the area
    that the camera will reach, and, finally, rebaking the culling. Try to be sensible
    with the size of the cube. The larger the area to calculate, the larger the space
    needed in your disk to store the generated data.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use several of these areas to be more precise—for example, in an L-shaped
    scene, you can use two of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated with medium confidence](img/B21361_18_16_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.16: Occlusion Area'
  prefs: []
  type: TYPE_NORMAL
- en: If you see that the objects are not being occluded, it can be that the occluder
    object (the wall in this case) is not big enough to be considered. You can increase
    the size of the object or reduce the **Smallest Occluder** setting in the **Bake**
    tab of the window. Doing that will subdivide the scene further to detect small
    occluders, but that will take more space in the disk to store more data. So again,
    be sensible with this setting.
  prefs: []
  type: TYPE_NORMAL
- en: There are still some more techniques that we can apply to our game, but the
    ones we have discussed are enough for our game. So, in this section, we learned
    about the process of rendering graphics in a video card, the concept of batches,
    how to profile them to know exactly how many of them we have and what they are
    doing, and finally, how to reduce them as much as we can. Now, let’s start discussing
    other optimization areas, such as the processing area.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While graphics usually take up most of the time that a frame needs to be generated,
    we should never underestimate the cost of badly optimized code and scenes. There
    are several parts of the game that are still calculated in the CPU, including
    part of the graphics process (such as the batching calculations), physics, audio,
    and our code. Here, we have a lot more causes of performance issues than on the
    graphics side, so again, instead of discussing every optimization, let’s learn
    how to discover them.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will examine the following CPU optimization concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting CPU- and GPU-bound
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the **CPU Usage** Profiler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: General CPU optimization techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will start by discussing the concepts of CPU- and GPU-bound, which focus
    on the optimization process, determining whether the problem is GPU- or CPU-related.
    Later, as with the GPU optimization process, we will look at how to gather the
    performance data of the CPU and interpret it to detect possible optimization techniques
    to be applied.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting CPU- and GPU-bound
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with Frame Debugger, the Unity Profiler allows us to gather data about the
    performance of our game through a series of Profiler modules, each one designed
    to gather data about different Unity systems per frame, such as physics, audio,
    and, most importantly, **CPU usage**. This last module allows us to see the most
    important operations that Unity executed to process the frame—which range from
    our scripts to systems such as physics and graphics (the CPU part).
  prefs: []
  type: TYPE_NORMAL
- en: Before exploring the **CPU usage**, one important bit of data that we can gather
    in this module is whether we are CPU- or GPU-bound. As explained before, a frame
    is processed using both the CPU and GPU, and those pieces of hardware can work
    in parallel. While the GPU is executing a frame’s drawing commands, the CPU can
    execute the next frame physics, our scripts, and other non-graphic processes in
    a very efficient way. But now, let’s say that the CPU finishes that work while
    the GPU is still working on the previous frame. Can the CPU start to work on the
    next frame graphics processing? The answer is no. This would lead to a de-synchronization,
    so in this scenario, the CPU will need to wait. This wait is not necessarily bad
    if your game is already running at the desired frame rate (usually 60 fps), but
    if it isn’t, your game’s performance is limited or bound. The case we described
    about the CPU waiting for the GPU is known as GPU-bound, and we also have the
    opposite case, CPU-bound, when the GPU finishes earlier than the CPU. While the
    CPU and the GPU work in parallel, there’s a moment where the CPU needs the GPU
    but it is busy, and vice versa, leading to waiting times that are just a waste
    of the hardware capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to concentrate our optimization efforts, so if we detect that
    our game is GPU-bound, we will focus on GPU graphics optimization (like reduction
    of mesh and shader complexity), and if it is CPU-bound, then we will focus on
    the rest of the systems and the CPU side of graphics processing. To detect whether
    our game is one or the other, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Open Profiler (**Window | Analysis | Profiler**).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the **Profiler Modules** dropdown in the top-left corner, tick **GPU Usage**
    to enable the GPU Profiler:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated](img/B21361_18_17_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.17: Enabling the GPU profiler'
  prefs: []
  type: TYPE_NORMAL
- en: Play the game and select the **CPU Usage** profiler, clicking on its name in
    the left part of the **Profiler** window.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click the **Last Frame** button, the one with the double arrow pointing to
    the right, to always display info on the last frame being rendered:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A picture containing calendar  Description automatically generated](img/B21361_18_18.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.18: Last frame button (double arrow to the right)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Also click the **Live** button to enable **Live** mode, which allows you to
    see the results of profiling in real time. This can have an impact on performance,
    so you can disable it later:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application  Description automatically generated](img/B21361_18_19.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.19: Enabling Live mode'
  prefs: []
  type: TYPE_NORMAL
- en: 'Observe the bar with the **CPU** and **GPU** labels in the middle of the window.
    It should say how many milliseconds are being consumed by the CPU and GPU. The
    one with the higher number will be the one that is limiting our frame rate and
    will determine whether we are GPU- or CPU-bound:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![A picture containing table  Description automatically generated](img/B21361_18_20.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.20: Determining whether we are CPU- or GPU-bound'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is a chance that when you try to open the GPU profiler, you will see
    a not supported message, and this can happen in certain cases (such as on Mac
    devices that use the Metal graphics API). In that scenario, another way to see
    whether we are GPU-bound is by searching for `waitforpresent` in the search bar
    right next to the CPU/GPU labels while selecting the **CPU Usage** profiler. If
    you don’t see the search bar, click the drop-down menu at the left of **Live**
    (which should say **Timeline**) and select **Hierarchy**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_21_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.21: Searching for waitforpresent'
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can see how long the CPU has been waiting for the GPU. Check the **Time
    ms** column to get the number. If you see **0.00**, it is because the CPU is not
    waiting for the GPU, meaning we are CPU-bound. In the preceding screenshot, you
    can see that my screen displays **0.00,** while the CPU is taking **6.42ms** and
    the GPU is taking **2.17ms**. So, my device is CPU-bound, but consider your device
    and project can bring different results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we can detect whether we are CPU- or GPU-bound, we can focus our optimization
    efforts, either on CPU-side optimizations or GPU-side. So far, we have discussed
    how to profile and optimize part of the GPU process in the *Optimizing graphics*
    section. Now, if we detect that we are CPU-bound, let’s see how to profile the
    CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Using the CPU Usage Profiler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Profiling the CPU is done in a similar way to profiling the GPU. We need to
    get a list of actions the CPU executes and try to reduce the number of them, or
    at least reduce their cost. Here is where the **CPU Usage Profiler** module comes
    in—a tool that allows us to see all the instructions that the CPU executed in
    one frame. The main difference is that the GPU mostly executes draw calls, and
    we have a few types of them, while the CPU can have hundreds of different instructions
    to execute, and sometimes some of them cannot be deleted, such as physics or audio
    processing. In these scenarios, we are looking to reduce the cost of these functions
    so that they do not consume too much time. So, again, an important note here is
    to detect which function is taking too much time and then reduce its cost or remove
    it, which requires a deeper understanding of the underlying system. Let’s start
    detecting the function first.
  prefs: []
  type: TYPE_NORMAL
- en: When you play the game with the **Profiler** tab open, you will see a series
    of graphics showing the performance of your game, and in the **CPU Usage** profiler,
    you will see that the graphic is split into different colors, each one referring
    to different parts of frame processing. You can check the information to the left
    of the Profiler to see what each color means, but let’s discuss the most important
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the following Unity manual page to see how to enable color blind modes
    for the profiler: [https://docs.unity3d.com/2023.1/Documentation/Manual/ProfilerWindow.html](https://docs.unity3d.com/2023.1/Documentation/Manual/ProfilerWindow.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you can see how the graphic should look:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated](img/B21361_18_22.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.22: Analyzing the CPU Usage graph'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you see the graphic, you will probably assume that the dark green part of
    the graph is taking up most of the performance time, and while that is true, you
    can also see from the legend that dark green means **Others**, and that’s because
    we are profiling the game in the Editor. The editor won’t behave exactly like
    the final game. In order for it to run, it has to do lots of extra processing
    that won’t be executed in the game, so the best you can do is profile directly
    in the build of the game. There, you will gather more accurate data. We are going
    to discuss how to do builds in the next chapter, so for now, we can ignore that
    area. What we can do now is simply click on the colored square to the left of
    the **Others** label to disable that measurement from the graph in order to clean
    it up a little bit. If you also see a large section of yellow, it refers to **VSync**,
    which is basically the time spent waiting for our processing to match the monitor’s
    refresh rate. This is also something that we can ignore, so you should also disable
    it. In the next screenshot, you can check the graphic color categories and how
    to disable them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B21361_18_23.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.23: Disabling VSync and Others from the Profiler'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have cleaned up the graph, we can get a good idea of our game’s
    potential frame rate by looking at the line with the **ms** label (in our case,
    **5ms (200FPS)**), which indicates that frames below that line have more than
    200 FPS, and frames above that line have less.
  prefs: []
  type: TYPE_NORMAL
- en: In my case, I have excellent performance, but remember, I am testing this on
    a powerful machine. The best way to profile is not only in the build of the game
    (as an executable) but also in the target device, which should be the lowest-spec
    hardware we intend our game to run on. Our target device depends a lot on the
    target audience of the game. If we are making a casual game, we are probably targeting
    mobile devices, so we should test the game on the lowest-spec phone we can, but
    if we are targeting hardcore gamers, they will probably have a powerful machine
    to run our game on.
  prefs: []
  type: TYPE_NORMAL
- en: If you are targeting hardcore gamers, of course, this doesn’t mean that we can
    just make a very unoptimized game because of that, but it will give us enough
    processing space to add more detail. Anyway, I strongly recommend you avoid those
    kinds of games if you are a beginner as they are more difficult to develop, which
    you will probably realize. Stick to simple games to begin with.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the graphics colors, you can observe the cost on the CPU side of
    rendering in light green, which the graph shows is taking up a significant portion
    of the processing time, which is actually normal. Then, in blue, we can see the
    cost of our scripts’ and other systems’ execution, which is also taking up a significant
    portion, but again, this is quite normal. Also, we can observe a little bit of
    orange, which is physics, and also a little bit of light blue, which is animations.
    Remember to check the colored labels in the Profiler to remember which color refers
    to what.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, those colored bars represent a group of operations, so if we consider
    the **Rendering** bar to be representing 10 operations, how do we know which operations
    that includes? Also, how do we know which of these operations is taking up the
    most performance time? Out of those 10 operations, a single one could be causing
    these issues. Here is where the bottom part of the profiler is useful. It shows
    a list of all the functions being called in the frame. To use it, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Click any part of the **CPU Usage** section in the Profiler and check that the
    button at the top-left part of the bottom bar of the Profiler says **Hierarchy**.
    If not (for example, if it says **Timeline**), click it and select **Hierarchy**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Clear the search bar we used earlier. It will filter function calls by name,
    and we want to see them all.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **Time ms** column until you see an arrow pointing downward. This
    will order the calls by cost in descending order.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_24.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.24: The profiler Time ms column'
  prefs: []
  type: TYPE_NORMAL
- en: Click on a frame that catches your attention in the graph—probably one of the
    ones with the biggest height that consumes more processing time. This will make
    the Profiler stop the game straight away and show you information about that frame.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are two things to consider when looking at the graph. If you see peaks
    that are significantly higher than the rest of the frames, that can cause a hiccup
    in your game—a very brief moment where the game is frozen—which can break the
    performance. Also, you can look for a long series of frames with higher time consumption.
    Try to reduce them as well. Even if this is only temporary, the impact of it will
    be easily perceived by the player, especially in VR games, as that could induce
    nausea.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**PlayerLoop** will probably appear as the most time-consuming frame, but that’s
    not very informative. You can explore it further by expanding it by clicking on
    the arrow to its left.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on each function to highlight it in the graph. Functions with higher
    processing times will be highlighted with thicker bars, and those are the ones
    we will focus on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated with medium confidence](img/B21361_18_25.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.25: The Render Camera function highlighted in the graph'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can keep clicking on the arrows to further explore the functions until
    you hit a limit. If you want to go deeper, enable the **Deep Profile** mode in
    the top bar of the Profiler. This will give you more details, but take into account
    that this process is expensive and will make the game go slower, altering the
    time shown in the graph, and making it appear much higher than the real time.
    Here, ignore the numbers and look at how much of the process a function is taking
    up based on the graph. You will need to stop, enable **Deep Profile**, and play
    it again to make it work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, chat or text message  Description
    automatically generated](img/B21361_18_26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.26: Enabling Deep Profile'
  prefs: []
  type: TYPE_NORMAL
- en: With this knowledge, we can start improving our game performance (if it’s below
    the target frame rate), but each function is called by the CPU and is improved
    in its own unique way, which requires greater knowledge about Unity’s internal
    workings. That could span several books, and anyway, the internals change on a
    version-to-version basis. Instead, you could study how each function works by
    looking up data about that specific system on the internet and official documentation,
    or again, by just disabling and enabling objects or parts of our code to explore
    the impact of our actions, as we did with Frame Debugger.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling requires creativity and inference to interpret and react accordingly
    to the data obtained, so you will need some patience here.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have discussed how to get the profiling data relating to the CPU,
    let’s discuss some common ways to reduce **CPU usage**.
  prefs: []
  type: TYPE_NORMAL
- en: General CPU optimization techniques
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In terms of CPU optimization, there are lots of possible causes of high performance,
    including the abuse of Unity’s features, a large number of physics or audio objects,
    improper asset/object configurations, and so on. Our scripts can also be coded
    in an unoptimized way, abusing or misusing expensive Unity API functions. So far,
    we have discussed several good practices of using Unity systems, such as audio
    configurations, texture sizes, batching, and finding functions such as `GameObject.Find`
    and replacing them with managers. So, let’s discuss some specific details about
    common cases.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by seeing how a large amount of objects impacts our performance.
    Here, you can just create lots of objects with `Rigidbody` (at least 200) configured
    in **Dynamic Profile**, and observe the results in the Profiler.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will notice, in the following screenshot, how the orange part of the profiler
    just got bigger and that the `Physics.RunSimulationStage` function is responsible
    for this increase:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing table  Description automatically generated](img/B21361_18_27.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.27: The Physics processing of several objects'
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the Profiler has other modules that you can activate by clicking
    the **Profiler Modules** button, and there’s one for physics. Consider enabling
    it and checking the info it gives you. Also check the official documentation for
    the profiler for more info on those modules.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another test to see the impact of several objects could be creating lots of
    audio sources. In the following screenshot, you can see that we needed to re-enable
    **Others** because part of the audio processing comes under that category. We
    mentioned earlier that **Others** belongs to the editor, but it can encompass
    other processes as well, so keep that in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Chart  Description automatically generated with low confidence](img/B21361_18_28.png)Figure
    18.28: The audio processing of several audio sources'
  prefs: []
  type: TYPE_NORMAL
- en: So, to discover these kinds of problems, you can just start disabling and enabling
    objects and see whether they increase the time or not. A final test is on particles.
    Create a system that spawns a big enough number of particles to affect our frame
    rate and check the Profiler.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, you can check how the particle processing function
    is highlighted in the graph, showing that it takes a large amount of time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Timeline  Description automatically generated](img/B21361_18_29_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.29: Particle processing'
  prefs: []
  type: TYPE_NORMAL
- en: Then, on the scripting side, we have other kinds of things to consider, some
    of which are common to all programming languages and platforms, such as iterating
    long lists of objects, the misuse of data structures, and deep recursion. However,
    in this section, I will mainly be discussing Unity-specific APIs, starting with
    `print` or `Debug.Log`.
  prefs: []
  type: TYPE_NORMAL
- en: This function is useful to get debugging information in the console, but it
    can also be costly because all logs are written onto the disk immediately to avoid
    losing valuable information if our game crashes. Disk writes are a very slow operation,
    even if using SSDs, so we want to avoid them as much as possible. Of course, we
    also want to keep those valuable logs in the game but we don’t want it to affect
    the performance, so what can we do?
  prefs: []
  type: TYPE_NORMAL
- en: 'One possible approach is to keep those messages but disable the non-essential
    ones in the final build, such as informative messages, keeping the error-reporting
    function active. One way to do this is through compiler directives, such as the
    ones used in the following screenshot. Remember that this kind of `if` statement
    is executed by the compiler and can exclude entire portions of code when compiling
    if its conditions are not met:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, font, screenshot, line  Description automatically
    generated](img/B21361_18_30_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.30: Disabling code'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, you can see how we are asking whether this code
    is being compiled by the editor or for a development build, which is a special
    kind of build intended to be used for testing (more on that in the next chapter).
    You can also create your own kind of logging system with functions with the compiler
    directives, so you don’t need to use them in every log that you want to exclude.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we learned about the tasks a CPU faces when processing a video
    game, how to profile them to see which ones are not necessary, and how to reduce
    the impact of those processes. There are a few other script aspects that can affect
    performance not only on the processing side but also on the memory side, so let’s
    discuss them in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We discussed how to profile and optimize two pieces of hardware—the CPU and
    GPU—but there is another piece of hardware that plays a key role in our game—RAM.
    This is the place where we put all of our game’s data. Games can be memory-intensive
    applications, and unlike several other applications, they are constantly executing
    code, so we need to be especially careful about that. The problem is that if we
    consume too much memory, we risk slowing down our game performance due to more
    costly memory accesses, or even making our game crash on non-PC platforms, like
    mobile or even consoles.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we will examine the following memory optimization concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Memory allocation and the garbage collector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using the Memory Profiler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start discussing how memory allocation works and what role garbage collection
    plays here.
  prefs: []
  type: TYPE_NORMAL
- en: Memory allocation and the garbage collector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each time we instantiate an object, we are allocating memory in RAM, and in
    a game, we will be allocating memory constantly. In other programming languages,
    aside from allocating the memory, you need to manually deallocate it, but C# has
    a garbage collector, which is a system that tracks unused memory and cleans it.
    This system works with a reference counter, which tracks how many references to
    an object exist, and when that counter reaches `0`, it means all references have
    become null and the object can be deallocated. This deallocation process can be
    triggered in several situations, the most common situation being when we reach
    the maximum assigned memory and want to allocate a new object. In that scenario,
    we can release enough memory to allocate our object, and if that is not possible,
    the memory is expanded.
  prefs: []
  type: TYPE_NORMAL
- en: In any game, you will probably be allocating and deallocating memory constantly,
    which can lead to memory fragmentation, meaning there are small spaces between
    alive object memory blocks that are mostly useless because they aren’t big enough
    to allocate an object, or maybe the sum of the spaces is big enough, but we need
    continuous memory space to allocate our objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following diagram, you can see a classic example of trying to fit a
    big chunk of memory into the little gaps generated by fragmentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated with low confidence](img/B21361_18_31_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.31: Trying to instantiate an object in a fragmented memory space'
  prefs: []
  type: TYPE_NORMAL
- en: Some types of garbage collection systems, such as the one in regular C#, are
    generational, meaning memory is split into generation buckets according to the
    “age” of its memory. Newer memory will be placed in the first bucket, and this
    memory tends to be allocated and deallocated frequently. Because this bucket is
    small, working within it is fast. The second bucket has the memory that survived
    a previous deallocation sweep process in the first bucket. That memory is moved
    to the second bucket to prevent it from being checked constantly for whether it
    survived the process, and it is possible that that memory will last the length
    of our program’s lifetime. The third bucket is just another layer of bucket 2\.
    The idea is that most of the time, the allocation and deallocation system will
    be working in bucket 1, and as it is small enough, it is quick to allocate, deallocate,
    and compact memory in a continuous fashion.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more detailed information about how Unity manages memory and what memory
    fragmentation is, please refer to the following link: [https://docs.unity3d.com/Manual/performance-managed-memory.html](https://docs.unity3d.com/Manual/performance-managed-memory.html)'
  prefs: []
  type: TYPE_NORMAL
- en: The problem here is that Unity uses its own version of the garbage collection
    system, and that version is non-generational and non-compacting, meaning memory
    is not split into buckets and memory won’t be moved to fill the gaps. This suggests
    that allocating and deallocating memory in Unity will still result in the fragmentation
    problem, and if you don’t regulate your memory allocation, you might end up with
    an expensive garbage collection system being executed very often, producing hiccups
    in our game, which you can see in the **Profiler CPU Usage** module as a pale-yellow
    color.
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to deal with this is by preventing memory allocation as much as you
    can, avoiding it when it is not necessary. There are a few tweaks here and there
    that you can make to prevent memory allocation, but before looking at those, again,
    it is important to first get data about the problem before you start fixing things
    that may not be an issue. This advice applies to any type of optimization process.
    Here, we can still use the **CPU Usage** profiler to see how much memory is allocated
    to each function call that the CPU executes in each frame, and that is simply
    done by looking at the **GC Alloc** column, which indicates the amount of memory
    that the function allocated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table  Description automatically generated with medium confidence](img/B21361_18_32_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.32: The memory allocation of the Update event function of Sight'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, we can see how our function is allocating too much
    memory, which is produced because there are many enemies in the scene. But that’s
    no excuse; we are allocating that much RAM at every frame, so we need to improve
    this. There are several things that can contribute to our memory being claimed
    by allocations, so let’s discuss the basic ones, starting with array-returning
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: If we review the `Sight` script code, we can see that the only moment where
    we are allocating memory is in the call to `Physics.OverlapSphere`, and that is
    evident because it is an array-returning function, which is a function that returns
    a varying amount of data. To do this, it needs to allocate an array and return
    that array to us. This needs to be done on the side that created the function,
    Unity, but in this case, Unity gives us two versions of the function—the one that
    we are using and the `NonAlloc` version. It is usually recommended to use the
    second version, but Unity uses the other one to make coding simpler for beginners.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `NonAlloc` version looks as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screen shot of a computer code  Description automatically generated with
    low confidence](img/B21361_18_33_PE.png)Figure 18.33: Memory allocation of the
    Update event function of Sight'
  prefs: []
  type: TYPE_NORMAL
- en: This version requires us to allocate an array with enough space to save the
    largest amount of colliders our `OverlapSphere` variable can find and pass it
    as the third parameter. This allows us to allocate the array just once and reuse
    it on every occasion that we need it. In the preceding screenshot, you can see
    how the array is static, which means it is shared between all the `Sight` variables
    as they won’t execute in parallel (no `Update` function will). This will work
    fine. Keep in mind that the function will return the number of objects that were
    detected, so we just iterate on that count. The array can have previous results
    stored within it.
  prefs: []
  type: TYPE_NORMAL
- en: Now, check your Profiler and notice how the amount of memory allocated has been
    reduced greatly. There might be some remaining memory allocation within our function,
    but sometimes there is no way to keep it at `0`. However, you can try to look
    at the reasons for this using deep profiling or by commenting some code and seeing
    which comment removes the allocation. I challenge you to try this and observe
    which changes lead to reduced memory allocation values. Also, `OverlapSphere`
    is not the only case where this could occur. You have others, such as the `GetComponents`
    functions family, which, unlike `GetComponent`, finds all the components of a
    given type, not just the first one, so pay attention to any array-returning function
    of Unity and try to replace it with a non-allocating version, if there is one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another common source of memory allocation is string concatenation. Remember
    that strings are immutable, meaning they cannot change if you concatenate two
    strings. A third one needs to be generated with enough space to hold the first
    ones. If you need to concatenate a large number of times, consider using `string.Format`
    if you are just replacing placeholders in a template string, such as putting the
    name of the player and the score they got in a message or using `StringBuilder`,
    a class that just holds all the strings to be concatenated in a list and, when
    necessary, concatenates them together, instead of concatenating them one by one
    as the **+** operator does. Also, consider using the new string interpolation
    functionality of C#. You can see some examples in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer code  Description automatically generated with
    low confidence](img/B21361_18_34_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.34: String management in C#'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a classic technique to consider is object pooling, which is suitable
    in cases where you need to instantiate and destroy objects constantly, such as
    with bullets or effects. In that scenario, the use of regular `Instantiate` and
    `Destroy` functions will lead to memory fragmentation, but object pooling fixes
    that by allocating the maximum amount of required objects possible. It replaces
    `Instantiate` by taking one of the preallocated functions and it replaces `Destroy`
    by returning the object to the pool.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple pool can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer program  Description automatically generated with
    medium confidence](img/B21361_18_35_PE.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.35: A simple object pool'
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to improve this pool, but it is fine as it is for now.
    Note that objects need to be reinitialized when they are taken out of the pool,
    and you can do that with the `OnEnable` event function or by creating a custom
    function to inform the object to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please note that Unity has recently added an Object Pool class that you can
    investigate at the following link: [https://docs.unity3d.com/2023.1/Documentation/ScriptReference/Pool.ObjectPool_1.html](https://docs.unity3d.com/2023.1/Documentation/ScriptReference/Pool.ObjectPool_1.html),
    but I still recommend making your own first to grasp the idea of pools.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have explored some basic memory allocation reduction techniques,
    let’s look at the new **Memory Profiler** tool, introduced in the previous version
    of Unity but now finally not a preview package anymore but available as a 1.0.0
    version, to explore memory in greater detail.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Memory Profiler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this Profiler, we can detect memory allocated on a frame-per-frame basis,
    but it won’t show the total memory allocated so far, which would be useful to
    study how we are using our memory. This is where the **Memory Profiler** can help
    us. This relatively new Unity package allows us to take memory snapshots of every
    single object allocated both on the native and managed side—*native* meaning the
    internal C++ Unity code and *managed* meaning anything that belongs to the C#
    side (that is, both our code and Unity’s C# engine code). We can explore snapshots
    with a visual tool and rapidly see which type of object is consuming the most
    RAM and how they are referenced by other objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'To start using the **Memory Profiler**, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the **Package Manager** (**Window | Package Manager**) and look for the
    Memory Profiler package. At the time of writing this book, you can see that the
    latest stable version available is 1.1.0:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.36: Enabling preview packages'
  prefs: []
  type: TYPE_NORMAL
- en: Once installed, open the Memory Profiler in **Window | Analysis | Memory Profiler**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Play the game and click on the **Capture** button in the **Memory Profiler**
    window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_37.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.37: Capturing a snapshot'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the snapshot that appeared in the list (the one below the **Session
    1** label) to see a summary of the memory consumption at the moment of taking
    a snapshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_38_.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.38: Memory summary'
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we can see that we are consuming 2.76 GB of memory, split between
    **Managed** (C# code variables), **Executables & Mapped** (built code of the application)**,
    Native** (Unity’s C++ memory), **Graphics** (Graphics Driver and GPU memory usage
    to render our scene)**, Profiler** (because we are profiling our session), **Audio**,
    and **Unknown** (memory that can’t be categorized, like allocations made by third-party
    native plugins). There are different things that are accounted for in these categories,
    but for now, we are good. Open the package documentation in the **Package Manager**
    to get more info about them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click the **Unity Objects** tab at the top part of the middle section of the
    **Memory Profiler** window. This will open the **Unity Objects View**, which allows
    you to visually see which types of assets are the more demanding in terms of memory
    in a table format:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_39_.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.39: Memory tree view'
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we can see that `RenderTexture` uses up the most memory, which
    belongs to the image that is displayed in the scene, as well as some textures
    used by post-processing effects. Try to disable the `PPVolume` object and take
    another snapshot to detect the difference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In my case, that dropped off 56 MB. There are other textures needed for other
    effects, such as HDR. If you want to explore where those remaining MB came from,
    click on the arrow at the left of **RenderTexture** to see a list of its objects
    and take your own guesses based on the names of the textures:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_40_.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.40: Memory blocks in detail'
  prefs: []
  type: TYPE_NORMAL
- en: You can repeat the same process in the `Texture2D` list, which belongs to the
    textures used in the materials of our models. You can look at the biggest one
    and detect its usage—maybe it is a big texture that is never seen close enough
    to justify its size. Then, we can reduce its size using the **Max Size of the
    Texture** import settings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can also use the two checkboxes at the bottom of the **Unity Objects View**
    to flatten all the objects appearing in the Hierarchy without any group or category
    and find any possible duplicate object (i.e., by mistakenly duplicating the same
    asset in the project).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B21361_18_41_.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18.41: Filter the Unity Object groups’ appearances'
  prefs: []
  type: TYPE_NORMAL
- en: As with any profiler, it is always useful to carry out the profiling directly
    in the build (more on that in the next chapter) because taking snapshots in the
    editor will capture lots of memory that is used by the editor and will not be
    used in the build. An example of this is the loading of unnecessary textures because
    the editor probably loaded them when you clicked them to see their previews in
    the **Inspector** window.
  prefs: []
  type: TYPE_NORMAL
- en: Consider that due to the **Memory Profiler** being a package, its UI can change
    often, but its basic idea will remain. You can use this tool to detect whether
    you are using the memory in unexpected ways. Something useful to consider here
    is how Unity loads assets when loading a scene, which consists of loading all
    assets referenced in the scene at load time. This means that you can have, as
    an example, an array of prefabs that have references to materials that have references
    to textures, and even if you don’t instantiate a single instance of them, the
    prefabs must be loaded in memory, causing them to occupy space. In this scenario,
    I recommend that you explore the use of `Addressables`, which provide a way to
    load assets dynamically. But let’s keep things simple for now.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Memory Profiler also has a feature to compare two snapshots. This is useful
    for detecting memory leaks (which, in C#, can be caused by non-nullified references)
    and unreleased assets between two specific moments in the game (such as before
    starting a level and after starting the next one). See this documentation for
    more details: [https://docs.unity3d.com/Packages/com.unity.memoryprofiler@1.0/manual/snapshots-comparison.html](mailto:https://docs.unity3d.com/Packages/com.unity.memoryprofiler@1.0/manual/snapshots-comparison.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Optimizing a game is not an easy task, especially if you are not familiar with
    the internals of how each Unity system works. Sadly, this is a titanic task, and
    no one knows every single system down to its finest details, but with the tools
    learned about in this chapter, we have a way to explore how changes affect systems
    through exploration. We learned how to profile the CPU, GPU, and RAM and what
    the key hardware in any game is. We also covered some common good practices to
    avoid abusing them.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you can diagnose performance issues in your game, gathering data about
    the performance of the three main pieces of hardware—the CPU, GPU, and RAM—and
    then using that data to focus your optimization efforts on applying the correct
    optimization technique. Performance is important as your game needs to run smoothly
    to give your users a pleasant experience.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to see how to create a build of our game to
    share with other people, without needing to install Unity. This is also very useful
    for profiling, given that profiling builds are going to give us more accurate
    data than profiling in the editor.
  prefs: []
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Read this book alongside other users, Unity game development experts, and the
    author himself. Ask questions, provide solutions to other readers, chat with the
    author via Ask Me Anything sessions, and much more. Scan the QR code or visit
    the link to join the community:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/unitydev](https://packt.link/unitydev)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1498477041053909218.png)'
  prefs: []
  type: TYPE_IMG
