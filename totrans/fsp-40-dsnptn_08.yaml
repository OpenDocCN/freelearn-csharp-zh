- en: Chapter 8. Data Crunching – Data Transformation Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After dealing with advanced patterns of the function definition and application
    in the previous chapter, I want to revisit the topic that was just slightly scratched
    in [Chapter 6](text00053.html#ch06 "Chapter 6.  Sequences - The Core of Data Processing
    Patterns") , *Sequences - The Core of Data Processing Patterns* in connection
    with sequences. There, I claimed that the quite bulky `Collection.seq` library
    absorbs and implements just a handful of universal data processing patterns. Then
    I regrouped the library members by assigning to one of these patterns.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter digs deeper into these patterns of data transformation that are
    applicable not only to sequences, but also to other data collections. The goal
    of this chapter is to help you develop the skill to convey your data processing
    needs with functions belonging to a handful of typical polymorphic transformation
    categories composed of a handful of combinators, and by operating upon data collection
    types that are best suitable for the task at hand. This approach allows you to
    uniformly cover the widest assortment of specific data transformations. Sticking
    to the above approach is essential for F# programmer practitioners as it effectively
    curbs the development of lengthy custom solutions without compelling reasons and
    overall adds to the positive properties of F# programs, such as succinctness,
    correctness, and performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will inspect:'
  prefs: []
  type: TYPE_NORMAL
- en: How normalization of data transformation libraries in F# 4.0 reflects upon underlying
    transformation patterns commonalities. These commonalities have a polymorphic
    nature being applicable to the various data collections that the libraries aim.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How the transformation patterns scooped in [Chapter 6](text00053.html#ch06 "Chapter 6. 
    Sequences - The Core of Data Processing Patterns") , *Sequences - The Core of
    Data Processing Patterns* reveal themselves over various data collections.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It will be a long trip, so please stay with me, cool and hydrated.
  prefs: []
  type: TYPE_NORMAL
- en: Core data transformation libraries in F# 4.0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the enhancements to the FSharp.Core run-time brought by F# 4.0 is **normalized
    data collection modules** ([https://blogs.msdn.microsoft.com/fsharpteam/2014/11/12/announcing-a-preview-of-f-4-0-and-the-visual-f-tools-in-vs-2015/](https://blogs.msdn.microsoft.com/fsharpteam/2014/11/12/announcing-a-preview-of-f-4-0-and-the-visual-f-tools-in-vs-2015/)
    ). It is quite interesting that this development:'
  prefs: []
  type: TYPE_NORMAL
- en: Confirms the commonality of data processing patterns across data processing
    platforms. Functions such as `map` or `filter` can be found in functional programming
    languages such as F#, query tools such as **LINQ** , and scripting engines such
    as **PowerShell** , to name a few.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizes that concrete functions belonging to these patterns are polymorphic
    and may be uniformly apply across different data collection types. F# 4.0 successfully
    delivers this polymorphism over the most frequently used data collection types,
    namely for `Array` , `List` , and `Seq` modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, this library normalization added 95 new optimized per collection type
    function implementations to F# 4.0 data crunching offering. This addition bumps
    the overall amount of individual functions in the previously mentioned three collection
    modules to 309 (as of April 2016), which is definitely a sizable result. However,
    it would be really challenging for a random developer to memorize and recall this
    arrangement by heart without recognizing some formative principles.
  prefs: []
  type: TYPE_NORMAL
- en: Considering that most of the functions apply uniformly to three base collection
    types (some of them naturally do not apply to some concrete collections; for example,
    `toList` does not apply to `List` ), this still leaves 117 (as of April 2016)
    *different function names* just for the base data collections. And do not forget
    about a certain number of functions related to less widely used data collections,
    such as `set` , `IDictionary` , or `Array2D` . How should you approach this variety?
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, the number of data transformation patterns is just a handful. Recognizing
    the underlying pattern most often imposes an order on associated library functions,
    leaving just a dozen or so functions associated with each pattern. Such categorized
    amounts are much easier to recall.
  prefs: []
  type: TYPE_NORMAL
- en: In the rest of the chapter, we will examine these concealed patterns and their
    correspondent cohesive function groups. The provided idiomatic code examples facilitate
    the pattern retention, recognition, and reuse.
  prefs: []
  type: TYPE_NORMAL
- en: Data transformation patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A good question about data transformation libraries richness would be: Where
    does such an overwhelming variety come from in the first place? Why do designers
    of F# include as many as hundred-something functions over base data collections
    into the *core* library?'
  prefs: []
  type: TYPE_NORMAL
- en: 'I believe a single "right" answer to this question simply does not exist. However,
    some clues may come from considering a typical **ETL - Extract, Transform, Load**
    ([https://en.wikipedia.org/wiki/Extract,_transform,_load](https://en.wikipedia.org/wiki/Extract,_transform,_load)
    ) enterprise data crunching process. In the world of mutable collections and arbitrarily
    changing states, this operation can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This C#-like pseudocode demonstrates how literally gazillions of possible data
    transformations can be hidden behind the same few opaque lines of code. We cannot
    say anything about the details until we meticulously delve into the implementation
    of each of the above pieces, find out what it does, how it gets to the data, and
    how it shares the mutating state with other involved pieces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s express the semantically similar chain of activities in a more functional
    manner as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The preceding snippet tells a better story than its imperative sibling. We can
    see right away that `extractData` is a collection generator function that is based
    on certain input parameters `params` that produce the initial `inputCollection`
    function out of some sort of persistent store. This collection is given as an
    input parameter to the transformation function `transformData` that produces as
    a result the output collection `outputCollection` . Finally, this collection is
    given to the data loader function `loadData` , and it ends up being stored back
    into the persistent store. Given that the communication with the persistent store
    is implemented in an *idempotent* manner and the involved functions are referentially
    transparent, this chain of transformations can be replayed an arbitrary number
    of times with the same results.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can even take another step toward idiomatic use and rewrite the last snippet
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now we really deal with the code, transforming immutable data. This code does
    not dependent on the side effects of an internal state. Its components are better
    composable and it can be easily extended, if necessary. Finally, this code is
    simply more elegant now, it is easier to read and comprehend.
  prefs: []
  type: TYPE_NORMAL
- en: You may ask how this rather simplistic passage relates to significant library
    members' variety?
  prefs: []
  type: TYPE_NORMAL
- en: 'First of all, there are a few dozen of typical transformations that exist in
    correspondence with the widely accepted ways in which data processing algorithms
    are captured in computer science. For example, if we are going to provide a library
    function to split a collection into a pair of partitions, we cannot make it much
    differently than with a higher-order function of the following pseudo-signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here, `predicate` is a function that takes a single collection member of type
    `'T` and returns `bool` , where `true` signifies that the input element will go
    to the first collection of the result tuple, and `false` means it will go to the
    second collection. The  `source`  parameter represents the input collection to
    be split. I intentionally put "generic" `collection` into the preceding signature,
    and I will explain the reason in a bit. The result is a tuple carrying `source`
    elements being partitioned into two collections by the `predicate` values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many known algorithms of computer science can be succinctly implemented almost
    barely using the above `partition` function. For example, the famous **QuickSort**
    ([https://en.wikipedia.org/wiki/Quicksort](https://en.wikipedia.org/wiki/Quicksort)
    ) representing the broad **Divide and Conquer** ([https://en.wikipedia.org/wiki/Divide_and_conquer_algorithms](https://en.wikipedia.org/wiki/Divide_and_conquer_algorithms)
    ) class of algorithms. Let''s look at how **QuickSort** may be elegantly implemented
    using `partition` as shown by the following snippet (`Ch8_1.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The `qsort` function (somewhat simplistically) partitions a non-empty input
    list argument into two groups: one containing only elements that are less than
    one `x` in the head of the list, and the other containing the rest. The result
    would be to append the list that has `x` prepended to `qsortgreater` to the list
    `qsortless` . Beautiful! Let''s look at how this plays out in FSI in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Data transformation patterns](img/Image00038.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Implementing quicksort with the partition function
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let me return to the reason I used `collection` in the signature of the
    preceding `partition` function. Coincidentally, this is another piece of the consideration
    prompting the variety of library members, which is *performance* . You can bet
    the farm on the assertion that in order to be effective, `partition` should be
    implemented separately for `array` and `list` collections, yielding the pair of
    functions, each belonging to their respective module as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Along these lines, an interesting point is the lack of the `Seq.partition` function
    in F# 4.0 core libraries. The root cause for this artifact comes down to the performance.
    I refer those of you who are curious to to **pertinent piece of F# design specs**
    ([https://github.com/fsharp/FSharpLangDesign/blob/5cec1d3f524240f063b6f9dad2f23ca5a9d7b158/FSharp-4.0/ListSeqArrayAdditions.md#regular-functional-operators-producing-two-or-more-output-collections](https://github.com/fsharp/FSharpLangDesign/blob/5cec1d3f524240f063b6f9dad2f23ca5a9d7b158/FSharp-4.0/ListSeqArrayAdditions.md#regular-functional-operators-producing-two-or-more-output-collections)
    ) and a more mundane **explanation on StackOverflow Q&A website** ([http://stackoverflow.com/a/31750808/917053](http://stackoverflow.com/a/31750808/917053)
    ) that gives of the exact reason.
  prefs: []
  type: TYPE_NORMAL
- en: 'Summing up, F# language designers, when defining and implementing the F# core
    library of data transformation functions, are continually looking for equilibrium
    between the following factors:'
  prefs: []
  type: TYPE_NORMAL
- en: Good coverage of typical use cases distilled by many years of functional programming
    practice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not bloating the size of the library above reasonable limits
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making each library-provided function optimized to the extent that makes nonsensical
    any custom implementation of the same
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equipped with this holistic view, let me turn to covering patterns per se. In
    cases where the demonstration of a function representing a pattern can fit a one-liner
    I'll provide the result of the evaluation in the upcoming line as a comment for
    the sake of saving space.
  prefs: []
  type: TYPE_NORMAL
- en: The generation pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This pattern is very easy to recognize: it represents a transition from the
    state without any collection to the state where a collection has been created.
    Generation pattern is represented by library functions that have a generic signature
    structure as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This generalized signature leads to some concrete use cases depending on the
    specific shape of the result collection.
  prefs: []
  type: TYPE_NORMAL
- en: Generating an empty collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To generate an empty collection of a generic type, the core library function,
    `empty` , exists, allowing you to produce a strongly typed empty collection for
    any of the base collection types as shown here (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The same can be also achieved using corresponding constant expressions for
    each base collection type (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Generating a single element collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This simple task belonging to a generation pattern can be achieved by the core
    library function `singleton` that exists for each of the base collection types.
    It does not need explicit declaration of collection elements type as it can be
    easily inferred from the typed literal given for the single collection element
    as shown in the following code (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, this can be also achieved using corresponding constant expressions for
    each base collection type as shown here (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Generating a collection of a known size
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This task of the generation pattern is represented by two different cases:
    the case where all elements in the collection are of the same value and the case
    where they can be of different values.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating a collection of a known size - all elements of the same value
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The F# 4.0 core library provides functions to replicate each base collection
    type that has the following signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Examples of this usage are as following (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'As I discussed earlier, this can be achieved using literals and comprehension
    expressions as shown here (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition to `replicate` , F# core library for **array** collections exclusively
    provides the `create` and `zeroCreate` functions as shown below (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that `zeroCreate` , by design, does not give any clue about the type of
    the target array to the F# compiler. So, in order to avoid the infamous `error
    FS0030: Value restriction` error message that is going to take place if the matter
    of the target array type is delegated to the type inference, the type annotation
    can be added to the value itself, such as `string[]` for `fazc` , or a type argument
    can be added to the function name itself, such as `<int>` for `fazci` in the preceding
    code.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating a collection of a known size - elements may have different values
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'What if elements of the collection need to be of different values? The F# core
    library comes to our help with the `init` function for each base collection type
    that has signatures as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Examples of this usage are given as following (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that `initializer` is given the implicit index of each element that transforms
    it into the element value. This transformation can be very simple, such as `vs`
    , or quite complex, such as `va` , where it is closed around `src` and de-facto
    transforms a `string` to the array of `char` of its characters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the case of the same value elements, the alternative to `init` in
    order to generate lists and arrays may be literals, and for all three base collection
    types, the alternative could be comprehension expressions. Examples follow-`vll`
    and `val` for literals and the rest for a comprehension expression having (`vlcy`
    , `vacy` , `vscy` ) or not using (`vlc` , `vac` , `vsc` ) of the `yield` construction
    as shown here (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that the expression initializing the collection element value within comprehension
    expressions can be arbitrarily complex; for example, in the case of `vacy` , it
    takes a value from the `src` closure indexed by the element place and converts
    the corresponding `char` array element into uppercase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before further proceeding with the rest of the use cases, let me drill deeper
    into comprehension expressions. They are much more powerful than what has been
    shown so far. I''ve already mentioned this in [Chapter 6](text00053.html#ch06
    "Chapter 6.  Sequences - The Core of Data Processing Patterns") , *Sequences -
    The Core of Data Processing Patterns* when talking about sequences in which sequence
    expressions may contain multiple occurrences of `yield` as well as `yield!` .
    You are free to use this feature when creating comprehension expressions for lists
    and arrays as well as use recursion to your taste. To prove this, let me demonstrate
    all these features in one quick example, building a generator for a list of pseudo-random
    integers in a range between `lo` and `hi` of length `len` as shown in the following
    code (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The results of smoke testing `randoms` in FSI by modeling three series of 20
    throws of a dice are given in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating a collection of a known size - elements may have different values](img/Image00039.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Modelling series of throwing dice with pseudo-random number generator
  prefs: []
  type: TYPE_NORMAL
- en: Generating a collection of an unknown size
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From time to time, you may get into a situation where you should generate a
    collection with the size that is to be found along the generation. In such situations,
    the following F# core library function `unfold` comes to help as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: I have already provided a very simple example of this function workings in [Chapter
    6](text00053.html#ch06 "Chapter 6.  Sequences - The Core of Data Processing Patterns")
    , *Sequences - The Core of Data Processing Patterns* ; here, I describe its inner
    workings to the full extent. The `unfold` function produces result collection
    elements one by one. For each element, the `generator` function takes a `'State`
    value as an input parameter and produces the result as an **option** value. If
    the returned option is of the form `Some('T * 'State)`  consisting of the current
    generated collection element value `'T` and the `'State` value for the next iteration
    this return value indicates that sequence unfolding will continue. Otherwise,
    when `generator` function returns `None` this means that the collection unfolding
    has been completed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let me offer you a loaded example for this use case: the so-called **Collatz
    conjecture** ([https://en.wikipedia.org/wiki/Collatz_conjecture](https://en.wikipedia.org/wiki/Collatz_conjecture)
    ). Let us consider an integral sequence built by a simple rule of moving from
    an element `n` to the next element `nn` : if `n` is even, then `nn` is `n` divided
    by `2` ; otherwise, it is `3 * n + 1` . The conjecture itself is that for any
    initial `n` , this sequence named by German mathematician Lothar Collatz eventually
    reaches `1` . For example,'
  prefs: []
  type: TYPE_NORMAL
- en: 42 -> 24 -> 12 -> 6 -> 3 -> 10 -> 5 -> 16 -> 8 -> 4 -> 2 -> 1
  prefs: []
  type: TYPE_NORMAL
- en: To this day, no starting number has been found that leads to an unbound number
    of elements in the Collatz sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'For starters, I begin with an idiomatic implementation of the Collatz sequence
    generator `collatzLib` function that relies upon the `unfold` library function
    as shown here (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Note the trick I used in order to deliver the value 1 to the collection that,
    if the generation is continued beyond it, leads to the cycle `...1 -> 4 -> 2 ->
    1...` `.` For the state of `1L` , I produced the `Some` option that has `1L` as
    the current value and an impossible marker value, `0L` . For the marker value,
    the generator produces `None` and the collection growth terminates. Another precaution
    is to operate in the field of `int64` numbers because even some not-that-big initial
    numbers may bring `'State` outside of the `int` field, which I was able to find
    by switching to **checked** F# arithmetic from the default **unchecked** when
    the generator started taking a suspiciously long time to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, so good. I''m going to give this implementation a try shortly. But
    some of you may already have this question: what''s the point if this can be achieved
    with a sequence expression? And the answer was already given in the beginning
    of this chapter -  *performance* . To prove this statement experimentally, let
    me put down the custom Collatz sequence generator implementation without using
    the `unfold` library function (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s run `collatzLib` and `collatzCustom` against each other in order
    to identify the difference. For this purpose, let''s find out what the longest
    Collatz sequence collection for initial numbers between 2 and 1000 would be. This
    exercise is a variation of **Project Euler problem 14** ([https://projecteuler.net/problem=14](https://projecteuler.net/problem=14)
    ). Composing the performance measuring code is not that difficult as shown here
    (`Ch8_2.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s compare the performance of the preceding code to this one (`Ch8_2.fsx`
    ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'by the running time. Comparison is given in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Generating a collection of an unknown size](img/Image00040.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Comparing the performance of library function-based and custom implementations
  prefs: []
  type: TYPE_NORMAL
- en: The lesson to take home is that the run using library-based `collatzLib` function
    takes **only 63%** of the time required for the run that uses custom-implemented
    `collatzCustom` function.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Do not spend time re-implementing functionality that F# core library functions
    offer unless you are in need for speed and absolutely sure that your custom implementation
    would improve the performance!
  prefs: []
  type: TYPE_NORMAL
- en: Generating a collection of an infinite size
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, I''ve reached the last use case under the Generation pattern: collections
    of infinite size. Apparently, when we consider this case, the underlying collection
    type can be the only sequence as we cannot rely on infinite memory resources yet.
    The F# core library function signature for the purpose of generating a sequence
    of infinite length is as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: It does not differ from `init` that much; it just lacks the input argument setting
    the collection size. Side by side with the `initInfinite` library function go
    custom implementations of infinite size sequences with sequence expressions.
  prefs: []
  type: TYPE_NORMAL
- en: 'I already covered the pattern of infinite size sequences in [Chapter 6](text00053.html#ch06
    "Chapter 6.  Sequences - The Core of Data Processing Patterns") , *Sequences -
    The Core of Data Processing Patterns* and provided some examples there as well
    as some advanced examples in [Chapter 7](text00058.html#ch07 "Chapter 7.  Advanced
    Techniques: Functions Revisited") , *Advanced Techniques: Functions Revisited*
    so I will not repeat myself here. This use case concludes the variety that Generation
    data transformation pattern covers.'
  prefs: []
  type: TYPE_NORMAL
- en: The aggregation pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The aggregation pattern can be recognized by the following kind of activity
    when the collection is traversed to end up with a value of type `'T` , similar
    to the collection elements' type `'T` , which carries some cumulative impact of
    all traversed elements.
  prefs: []
  type: TYPE_NORMAL
- en: Generic aggregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The generic aggregation data transformation pattern signature is conveniently
    similar to the pair of concrete library functions that represent aggregation:
    `reduce` and `reduceBack` as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'If you recall [Chapter 7](text00058.html#ch07 "Chapter 7.  Advanced Techniques:
    Functions Revisited") , *Advanced Techniques: Functions Revisited* , the preceding
    code is almost as generic as `folds` ; the difference is that the state threaded
    through the collection by `fold` can be of any arbitrary type that does not necessarily
    coincide with the type of collection elements, while `reduce` deals with the same
    type. It is easy to implement `reduce` with `fold` but not the other way around.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `reduce` function applies the `reduction` operation from the beginning
    to the end of the collection; if I denote the `reduction` function as `r` , then
    for the special case of `reduce` over array collection `c` it will be equivalent
    to this expression as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'On the contrary, `reduceBack` applies the `reduction` operation from the right-hand
    side to the left of the collection; if I denote the `reduction` function as `r`
    again, then for the special case of `reduceBack` over array collection `c` of
    `n+1` elements it will be equivalent to this expression as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'It is quite easy to notice that for the **associative** ([https://en.wikipedia.org/wiki/Associative_property](https://en.wikipedia.org/wiki/Associative_property)
    ) `reduction` operation, the results of `reduce` and `reduceBack` over the same
    collection would be the same, which is confirmed by simple tests as shown here
    (`Ch8_3.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'I''d like to point at the asymmetry taking place: there is no `reduceBack`
    for sequences in the library out of the box.'
  prefs: []
  type: TYPE_NORMAL
- en: 'All other library aggregate functions are just specific implementations of
    aggregations that can be expressed by `reduce` . Before turning to their consideration,
    I want to point out just another pattern: performing aggregation not on the original
    element type `''T` but projecting each collection element to some other type `''U`
    and aggregating upon `''U` .'
  prefs: []
  type: TYPE_NORMAL
- en: Direct aggregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Members of this group of aggregating library functions perform aggregation
    directly on the type of collection elements `''T` , such as the library members
    that have the following signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Based on signatures, you may notice that the library's aggregate functions introduce
    static constraints upon the collection type `'T` for the aggregations to make
    sense. For example, apparently, the max aggregation cannot be performed upon type
    `'T` if `'T` does not support comparison.
  prefs: []
  type: TYPE_NORMAL
- en: Projected aggregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The projected aggregation library function, instead of performing aggregations
    upon original collection elements, first projects them from type `''T` into some
    other type `''U` , and only then it performs the aggregation over `''U` values.
    Here go the signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'There is a little intricacy that should be mentioned when considering projected
    aggregations-while `averageBy` and `sumBy` return a result of type `''U` , `maxBy`
    and `minBy` return `''T` . Refer to the following code sample that highlights
    the mentioned detail (`Ch8_3.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Counting aggregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The left-over two functions of aggregation data transformation pattern perform
    the counting of collection elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is the good old `length` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: There are no hidden surprises here. Just recognize that `Seq.length` traverses
    the `source` sequence and, being applied to a sequence of infinite length will
    eventually blow up.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other one, `countBy` , is trickier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This higher-order function applies `projection` to each element value `'T` ,
    converting it into a `'Key` value, counts the number of elements projected to
    each unique `'Key` , and in the end, delivers the distribution as a collection
    of tuples (`'Key` , amount). Let me make quite an interesting observation. At
    the beginning of this chapter, in  *Generating a collection of a known size* we
    implemented a pseudo-random number sequence generator `randoms` . Let's look at
    roughly how "random" it is in emulating the throwing of a dice by building a long
    series of throws and then binning each score, expecting that the deviation of
    bin sizes is not statistically significant.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following snippet emulates the throwing of a dice 10 million times; so,
    the expected number of hits of each of the six bins for outcomes should be somewhere
    around 1,666,000\. Let''s see... (`Ch8_3.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The results of running the preceding code in FSI are presented in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Counting aggregation](img/Image00041.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Checking the quality of a pseudo-random number generator with countBy
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on results reflected by preceding screenshot, my gut feeling is that
    the underlying pseudo-random number generator is not bad for the purpose of emulating
    the dice. And it is pretty fast too: it took a bit more than 2 seconds to generate
    and bin the series of 10 million trials.'
  prefs: []
  type: TYPE_NORMAL
- en: The wrapping and type conversion pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Library functions belonging to this data transformation pattern split into
    two groups as following:'
  prefs: []
  type: TYPE_NORMAL
- en: Ones that wrap the entire collection, changing its behavior
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ones that simply transform the collection from one base type to another
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The collection wrapping pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are only three functions that belong to this pattern. All of them are
    applicable only to sequences and have the following signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'I have already covered the `Seq.cache` function in [Chapter 6](text00053.html#ch06
    "Chapter 6.  Sequences - The Core of Data Processing Patterns") , *Sequences -
    The Core of Data Processing Patterns* and also used it in [Chapter 7](text00058.html#ch07
    "Chapter 7.  Advanced Techniques: Functions Revisited") , *Advanced Techniques:
    Functions Revisited* in the prime number generator sample, so let me not spend
    any more time on it and move on to the other pair.'
  prefs: []
  type: TYPE_NORMAL
- en: '`Seq.delay` allows you to postpone an eager evaluation of the wrapped `generator`
    function. The evaluation is postponed until the wrapper gets enumerated. In the
    following code snippet, there is an eager list comprehension present that, if
    being evaluated, immediately prints `"Evaluating eagerList"` and then returns
    the list of `strings` . However, being wrapped into `Seq.delay` , it does not
    evaluate until the wrapper itself gets materialized (`Ch8_4.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The commented lines of the preceding script demonstrate that the expected behavior
    described earlier is actually taking place.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Seq.readonly` builds a wrapper sequence around the original collection,
    which does not allow you to rediscover and mutate it via a type cast. In the following
    snippet, it is possible via an upcast followed by a downcast, to create a backdoor,
    and mutate with its help the original mutable collection (`Ch8_4.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Now if `src` gets wrapped into `Seq.readonly` , an attempt to downcast the
    sequence back to `int []` will incur cast exception as shown in the following
    code (`Ch8_4.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The type conversion pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Library functions that belong to the type conversion pattern provide symmetric
    conversions between base collection types as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: These functions are very straightforward and do not require additional comments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from them stands function that converts a loosely-typed sequence from
    legacy pre-generic `System.Collections` namespace into a typed sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This casting is often needed in interoperability scenarios between F# and legacy
    Microsoft systems in order to convert them into F#-friendly strongly typed sequences.
    As an example of this, let''s take a look at the following snippet (`Ch8_4.fsx`
    ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, you can see that a `Stack` loosely typed collection was casted to a strongly
    typed F# sequence and printed out. The output shows the F# sequence containing
    elements of different types: `string` , `char` , `int` . But the sequence is strongly
    typed, isn''t it? Can you determine the type of the preceding sequence?'
  prefs: []
  type: TYPE_NORMAL
- en: The selection pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This kind of data transformation pattern can be recognized by segregating one
    or more elements from the collection based on certain characteristic(s). These
    traits can be very diverse: a position of element(s), an element value matching
    criteria, to name a few.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The genuine trait that distinguishes the selection transformation pattern from
    the rest of the crowd is the following: *selection result is always either a single
    element or a single collection carrying from zero to all elements of the original
    collection; the selection comes as-is, without any additional projection* .'
  prefs: []
  type: TYPE_NORMAL
- en: 'Such a seemingly broad transformation class lays out into surprisingly few
    subclasses: positional selection, search, and filtering.'
  prefs: []
  type: TYPE_NORMAL
- en: Position-based **selection** ties the element pick criteria with the element(s)
    position in the original collection; for example, take up to the first 10 elements
    of a collection.
  prefs: []
  type: TYPE_NORMAL
- en: '**Searching** and **filtering** are ubiquitous data collection transformations
    indeed. Although these two transformations strongly resemble each other, there
    is a subtle difference has place between them, which is outlined below.'
  prefs: []
  type: TYPE_NORMAL
- en: Filtering is usually associated with taking a source collection and copying
    it to the result collection element by element sifting out *all* elements that
    do not match given criteria.
  prefs: []
  type: TYPE_NORMAL
- en: 'Turning to searching, it is usually associated with a more sophisticated process.
    The initial state for the search is composed of the original collection, initially
    empty search result, and search criteria. The search process also traverses the
    original collection element by element applying search criteria and shaping the
    search result. However, searching may carry not only the matching criteria, but
    also a stop condition of a sort and maybe some ranking. A typical example of searching
    would be this: "find *any* collection element that fulfills the condition(s)".'
  prefs: []
  type: TYPE_NORMAL
- en: Based on this difference, I place searching in a separate selection pattern,
    but consider the filtering a part of the *element group selection* pattern.
  prefs: []
  type: TYPE_NORMAL
- en: The position-based selection pattern
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'F# core library functions that constitute this pattern can be further broken
    down into two groups: single element selections and element group selections.'
  prefs: []
  type: TYPE_NORMAL
- en: Single element selection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This group of functions determines the single desired element by the position
    it occupies in the collection. The position may be requested either explicitly
    via an input argument or implicitly by the associated function name. To see what
    I mean please compare "give me the third element" with "give me the last element".
    Single element selection returns either the desired element or an indication that
    such an element does not exist:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Note how members of this group differ by the manner of indicating an unsuccessful
    selection. Some simply throw an exception, while the others wrap the selection
    result into an `option` , where `None` indicates the absence of the sought-for
    element: (`Ch8_5.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Further on functions with names that begin with `try...` : these allow to alleviate
    the lurking possibility of the requested element being missing and handle such
    unfortunate cases nicely.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Use the *imperative* forms of selection with caution. If you are not ABSOLUTELY
    sure that the existence of requested element is invariant, fall back to *try*
    forms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, note that for data collections that support element indexing, often the
    simple use of index does the job of dedicated library function, like in the following
    code (`Ch8_5.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: The element group selection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This collection transformation sub-pattern arranges the procurement of a group
    of elements from a collection based on the whole slew of criteria: it can be an
    element counter, a predicate peeking at an element''s value, a collection of undesired
    values, or an exclusion of repeated values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Notice that the constituent of *element group selection* pattern is the ubiquitous
    `filter` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly to the previous sub-pattern for collections implementing index slicing,
    this is an alternative way of element group selection (`Ch8_5.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'You may also notice that the more generic `filter` function is accompanied
    by more specific filtering cases, such as `takeWhile` , `skipWhile` , or just
    a `where` synonym as shown here (`Ch8_5.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The searching pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The F# 4.0 core library offer a very normalized set of functions that constitute
    the **search** pattern, where the name of the function carries exhaustive characteristics
    of the function workings indeed.
  prefs: []
  type: TYPE_NORMAL
- en: All the functions that have `...find...` in the name perform the search for
    the first single element that occurs while having `...findIndex...` do the search
    for the same element but returning its ordinal number in the collection.
  prefs: []
  type: TYPE_NORMAL
- en: Functions that have `...Back...` in the name perform the search in the opposite
    direction of the natural order of elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly to the already examined selection pattern groups, the library functions
    of the search pattern implement two approaches to represent the *"not found"*
    search outcome: those without the `try...` prefix throw an exception if the search
    comes back empty, while others with the `try...` prefix in this situation return
    the `None` option; otherwise, it returns the found element wrapped into `Some...`
    option as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s demonstrate the listed above instruments in action (`Ch8_5.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Slightly apart from this very logical arrangement stands the `(try)pick` group
    of functions. Functions that belong to this group combine both search and transform
    functionalities together: the `chooser` function applies to each element of type
    `''T` , producing `None` until the first element matches the search criteria somehow
    expressed within `chooser` . Then, `Some` is wrapped around potentially different
    type `''U` and is returned, and the higher-order function returns the result of
    type `''U` . If `chooser` does not find any suitable element, then `pick` throws
    an exception, while `tryPick` returns `None` (`Ch8_5.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Please pay attention how the above functions fuse together to some extent selection
    and transformation by applying both actions while traversing the collection only
    once.
  prefs: []
  type: TYPE_NORMAL
- en: The partitioning pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'F# core library elements of **partitioning** pattern consume a single collection,
    usually returning more than one result collections as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Examples of simple usage of the preceding functions are as following (`Ch8_6.fsx`
    ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The reordering pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This group of F# core library functions represents the **reordering** data
    transformation pattern of changing the order of the elements in the collection
    using many forms of sorting, reversing, and permuting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Some examples of the reordering transformations are as following (`Ch8_7.fsx`
    ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Take into account that some functions perform the reordering by mutating the
    input collection. These are limited to `ArraysortInPlace` , `sortInPlaceBy` ,
    and `sortInPlaceWith` .
  prefs: []
  type: TYPE_NORMAL
- en: The testing pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a very straightforward pattern. **Testing** library functions instead
    of transforming the input collection, always returning the `bool` result: `true`
    if certain properties have place, otherwise `false` . They may check whether the
    given collection contains the given element, whether an element exists with the
    value, turning the given predicate to `true` , whether all elements of the collection
    turn the given predicate to `true` , or whether the input collection is empty
    as their signatures reflect below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The functions representing this pattern have so obvious an intent that I didn't
    even provide the usage samples for them; the samples can be easily found in F#
    core library documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The iterating pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is another very straightforward data transformation pattern. In fact, **iterating**
    pattern *does not introduce any noticeable transformations* , merely denoting
    instead the collection traversal. Its member functions always return `unit` .
    On each single traversal step the operations performed upon the current element
    are hidden behind the `action` function.
  prefs: []
  type: TYPE_NORMAL
- en: This manner of data transformations must vividly remind us of imperative and
    object-oriented paradigms as `action` effectively hides what's going on and also
    must exploit some side effects in order to be of any practical use. Such F# programs
    that massively (ab) use the iterating data transformation pattern usually indicate
    that their authors are still captives of a non-functional way of thinking.
  prefs: []
  type: TYPE_NORMAL
- en: 'The signatures of functions representing iterating pattern are given below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Note that library member functions of this pattern demonstrate a certain level
    of regularization. The actions may involve elements (`iter` , `iter2` ), or elements
    and the index (`iteri` , `iteri2` ), and also may involve a single collection
    (`iter` , `iteri` ) or pair of collections (`iter2` , `iteri2` ).
  prefs: []
  type: TYPE_NORMAL
- en: As with the testing pattern, finding samples of these function's use on the
    Internet is not a problem.
  prefs: []
  type: TYPE_NORMAL
- en: The mapping pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Mappings constitute the gist of data transformations, projecting one or more
    input elements to the single result and then applying this projection to the entire
    input collection(s) producing the result collection(s) as the following member
    function signatures indicate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Note that the group of functions belonging to the mapping pattern is normalized
    fairly well. Functions with names resembling `map` (`map` , `map2` , `map3` )
    project elements of a single, a pair, or a triple of input collections to the
    elements of the single result collection. Functions with names resembling `mapi`
    (`mapi` , `mapi2` ) also add the ordinal number of element(s) as an additional
    input parameter to the projection.
  prefs: []
  type: TYPE_NORMAL
- en: The `collect` function does not fit the same approach. Instead, it projects
    each element of the input collection into a matching collection and then flattens
    all these element-matching collections into a single result collection. It's a
    bit complicated, so I'd better provide an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume we are given an array of words and we want to convert it into
    a list of characters constituting input words (`Ch8_7.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'The `indexed` function is a helper function; it converts any collection into
    a collection of tuples, each combining an ordinal number of the original element
    and the element itself (`Ch8_7.fsx` ):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: The folding pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I''ve already mentioned on multiple occasions the `fold` function as a representation
    of the most universal and generic data transformation pattern of functional programming.
    As it has already been covered fairly well, I will not get into details here and
    will just list the multiple variations of this extremely versatile **folding**
    pattern as shown by the following member function signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: In addition to multiple `fold` usage examples sprinkled around the book and
    readily available on the Internet I provide a few more in the script `Ch8_8.fsx`
    .
  prefs: []
  type: TYPE_NORMAL
- en: The merge/split pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our long journey into the world of data transformation patterns captured by
    F# 4.0 core library has reached the last stop. Here, functions residing with **merge/split**
    pattern either merge some collections into one, or perform the opposite by splitting
    one collection into many:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: The `append` function is the simplest form of merge pattern as it combines a
    pair of collections into the single one. Elements of the second argument collection
    just follow the elements of the first argument collection in the result collection.
  prefs: []
  type: TYPE_NORMAL
- en: The `concat` function is the generalization of `append` to any number of input
    collections just wrapped into a sequence.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, zippers (`zip` , `zip3` ) take two or three collections and turn them
    into a single collection of corresponding tuples. Unzippers (`unzip` , `unzip3`
    ) do the opposite, taking a collection of tuples and turning it into the tuple
    of collections. Note that the library does not provide unzippers for `seq` .
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This was a long chapter, but it was an essential step into the universal patterns
    of data transformations and their reflection in the F# 4.0 core library. The knowledge
    you acquired will support the process of idiomatic blueprinting of an arbitrary
    data transformation by prompting you to build your F# code around the handful
    of retained reference points. When you mentally dissect your task at hand into
    a composition of functions along the patterns covered here, the high-quality library
    functions are always available for you to quickly compose from them an error-free
    and adequately performant solution.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will continue with the data transformation theme, looking into
    F# data queries and the subject of data parsing.
  prefs: []
  type: TYPE_NORMAL
