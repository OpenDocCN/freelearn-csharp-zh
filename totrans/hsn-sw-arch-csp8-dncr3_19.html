<html><head></head><body>
        

                            
                    <h1 class="header-title">Testing Your Code with Unit Test Cases and TDD</h1>
                
            
            
                
<p>When developing software, it is essential that you ensure that an application is bug-free and that it satisfies all specifications. This can be done by testing all the modules while they are being developed or when the overall application has been either completely or partially implemented.</p>
<p>Performing all the tests manually is not a feasible option since most of the tests must be executed each time the application is modified, and, as explained throughout this book, modern software is being continuously modified to adapt the applications to the needs of a fast-changing market. This chapter discusses all the types of tests needed to deliver reliable software, and how to organize and automate them.</p>
<p>More specifically, this chapter covers the following topics:</p>
<ul>
<li>Understanding automated tests and their usage</li>
<li>Understanding the basics of <strong>test-driven development</strong> (<strong>TDD</strong>)</li>
<li>Optimizing a software investment using TDD</li>
<li>Defining C# test projects in Visual Studio</li>
</ul>
<p>In this chapter, we'll see which types of tests are worth implementing, and what unit tests are. We'll see the different types of projects available and how to write unit tests in them. By the end of the chapter, the book use case will help us to execute our tests in Azure DevOps during the <strong>Continuous Integration/Continuous Delivery</strong> (<strong>CI/CD</strong>) cycle of our applications automatically.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter requires the 2019 free Community Edition with all database tools installed. It also requires a free Azure account; if you have not already created one, see the <em>Creating an Azure account</em> section in <a href="14b5c5da-4042-439e-9e5a-2e19ba4c4930.xhtml">Chapter 1</a>, <em>Understanding the Importance of Software Architecture.</em> </p>
<p>All concepts in this chapter are clarified with practical examples based on the WWTravelClub book use case. The code for this chapter is available at: <a href="https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8">https://github.com/PacktPublishing/Hands-On-Software-Architecture-with-CSharp-8</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding automated tests</h1>
                
            
            
                
<p>Delaying the application testing until immediately after most of its functionalities have been completely implemented must be avoided for the following reasons:</p>
<ul>
<li>If a class or module has been incorrectly designed or implemented, it might have already influenced the way other modules were implemented. Therefore, at this point, fixing the problem might have a very high cost.</li>
<li>The possible combination of input that is needed to test all possible paths that execution can take grows exponentially with the number of modules or classes that are tested together. Thus, for instance, if the execution of a class method <kbd>A</kbd> can take three different paths, while the execution of another method <kbd>B</kbd> can take four paths, then testing <kbd>A</kbd> and <kbd>B</kbd> together would require 3 x 4 different inputs. In general, if we test several modules together, the total number of paths to test is the product of the number of paths to test in each module. If modules are tested separately, instead, the number of inputs required is just the sum of the paths needed to test each module.</li>
<li>If a test of an aggregate made of N modules fails, then locating the origin of the bug among the N modules is usually a very time consuming activity.</li>
<li>When N modules are tested together, we have to redefine all tests involving the N modules, even if just one of the N modules changes during the application's CI/CD cycle.</li>
</ul>
<p>The preceding considerations show that it is more convenient to test each module method separately. Unluckily, a battery of tests that verifies all methods independently from their context is incomplete because some bugs may be caused by incorrect interactions between modules.</p>
<p class="mce-root"/>
<p>Therefore, tests are organized into two stages: </p>
<ul>
<li><strong>Unit tests</strong>: These verify that all execution paths of each module behave properly. They are quite complete and usually cover all possible paths. This is feasible because there are not very many possible execution paths of each method or module compared to the possible execution paths of the whole application.</li>
<li><strong>Integration tests</strong>: These are executed once the software passes all its unit tests. Integration tests verify all modules interact properly to get the expected results. Integration tests do not need to be complete since unit tests will have already verified that all execution paths of each module work properly. They need to verify all patterns of interaction, that is, all the possible ways the various modules may cooperate.</li>
</ul>
<p style="padding-left: 60px">Usually, each interaction pattern has more than one test associated with it: a typical activation of a pattern, and some extreme cases of activation. For instance, if a whole pattern of interaction receives an array as input, we will write a test for the typical size of the array, a test with a <kbd>null</kbd> array, a test for an empty array, and a test with a very big array. This way we verify that the way the single module was designed is compatible with the needs of the whole interaction pattern.</p>
<p>With the preceding strategy in place, if we modify a single module without changing its public interface, we need to change the unit tests for that module.</p>
<p>If, instead, the change involves the way some modules interact, then we also have to add new integration tests or to modify existing ones. However, usually, this is not a big problem since most of the tests are unit tests, so rewriting a large percentage of all integration tests does not require too big an effort. Moreover, if the application was designed according to the <strong>Single Responsibility, Open/Closed, Liskov Substitution, Interface Segregation, Dependency Inversion</strong> (<strong>SOLID</strong>) principles, then the number of integration tests that must be changed after a single code modification should be small since the modification should affect just a few classes that interact directly with the modified method or class.</p>
<p>At this point, it should be clear that both unit tests and integration tests must be reused during the entire lifetime of the software. That is why it is worth automating them. Automation of unit and integration tests avoids possible errors of manual test execution and saves time. A whole battery of several thousand automated tests can verify software integrity after each small modification in a few minutes, thus enabling the frequent changes needed in the CI/CD cycles of modern software.</p>
<p class="mce-root"/>
<p>As new bugs are found, new tests are added to discover them so that they cannot reappear in future versions of the software. This way automated test always become more reliable and protect the software more form bugs added by new changes. Thus, the probability of adding new bugs (that are not immediately discovered) is greatly reduced.</p>
<p>The next section will give us the basics for organizing and designing automated unit and integration tests, as well as practical details on how to write a test in C# in the <em>C# Test Projects</em> section.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing automated (unit and integration) tests</h1>
                
            
            
                
<p>Tests are not written from scratch; all software development platforms have tools that help us to both write tests and launch them (or some of them). Once the selected tests have been executed, all tools show a report and give the possibility to debug the code of all failed tests.</p>
<p>More specifically, all unit and integration test frameworks are made of three important parts:</p>
<ul>
<li><strong>Facilities for defining all tests: </strong>They verify if the actual results correspond to expected results. Usually, a test is organized into test classes, where each test calls tests either a single application class or a single class method. Each test is split into three stages: 
<ol>
<li><strong>Test preparation</strong>: The general environment needed by the test is prepared. This stage doesn't prepare the single input each method to test must be called with, but just the global environment, such as objects to inject in class constructors or simulations of database tables. Usually, the same preparation procedure is used in several tests, so test preparations are factored out into dedicated modules.</li>
<li><strong>Test execution</strong>: The methods to test are invoked with adequate input and all results of their executions are compared with expected results with constructs such as <kbd>Assert.Equal(x, y)</kbd>, <kbd>Assert.NotNull(x)</kbd>, and so on.</li>
<li><strong>Tear-down</strong>: The whole environment is cleaned up to avoid the execution of a test influencing other tests. This step is the converse of step 1.</li>
</ol>
</li>
<li><strong>Mock facilities</strong>: While integration tests use all (or almost all) classes involved in a pattern of objects cooperation, in unit tests the use of other application classes is forbidden. Thus, if a class under test, say, <kbd>A</kbd>, uses a method of another application class, <kbd>B</kbd>, that is injected in its constructor in one of its methods, <kbd>M</kbd>, then in order to test <kbd>M</kbd> we must inject a fake implementation of <kbd>B</kbd>. It is worth pointing out that only classes that do some processing are not allowed to use another class during unit tests, while pure data classes can. Mock frameworks contain facilities to define fake implementations of interfaces and interface methods that return data that can be defined in tests. Typically, fake implementations are also able to report information on all fake method calls. Such fake implementations do not need the definition of actual class files but are done online in the test code by calling methods such as <kbd>new Mock&lt;IMyInterface&gt;()</kbd>.</li>
<li><strong>Execution and reporting tool</strong>: This is a visual configuration-based tool that the developer may use to decide which tests to launch and when to launch them. Moreover, it also shows the final outcome of the tests as a report containing all successful tests, all failed tests, each test's execution time, and other information that depends on the specific tool and on how it was configured. Usually, execution and reporting tools that are executed in development IDEs such as Visual Studio also give you the possibility of launching a debug session on each failed test.</li>
</ul>
<p>Since mock frameworks can only create fake implementations of interfaces but not of classes, we should inject interfaces or pure data classes (that don't need to be mocked) in class constructors and methods; otherwise, classes cannot be unit tested. Therefore, for each cooperating class that we want to inject into another class, we must define a corresponding interface.<br/>
<br/>
Moreover, classes should use instances that are injected in their constructors or methods, and not class instances available in the public static fields of other classes; otherwise, the hidden interactions might be forgotten while writing tests, and this might complicate the <em>preparation</em> step of tests.</p>
<p>The next section describes other types of test used in software development.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Writing acceptance and performance tests</h1>
                
            
            
                
<p>Acceptance tests define the contract between the project stakeholders and the development team. They are used to verify that the software developed actually behaves as agreed with them. Acceptance tests verify not only functional specifications but also constraints on the software usability and user interface. Since they also have the purpose of showing how the software appears and behaves on actual computer monitors and displays, they are never completely automatic but consist mainly of lists of recipes and verifications that must be followed by an operator.</p>
<p>Sometimes, automatic tests are developed to verify just the functional specifications, but such tests usually bypass the user interface and inject the test input directly in the logic that is immediately behind the user interface. For instance, in the case of an ASP.NET Core MVC application, the whole website is run in a complete environment that includes all the needed storage filled with test data; input is not provided to HTML pages but is injected directly in the ASP.NET Core controllers. Tests that bypass the user interface are called subcutaneous tests. ASP.NET Core supplies various tools to perform subcutaneous tests and also tools that automate the interaction with HTML pages.</p>
<p>Subcutaneous tests are usually preferred in the case of automated tests, while full tests are executed manually for the following reasons:</p>
<ul>
<li>No automatic test can verify how the user interface appears and how usable it is.</li>
<li>Automating the actual interaction with the user interface is a very time-consuming task.</li>
<li>User interfaces are changed frequently to improve their usability and to add new features, and also small changes in a single application screen, may force a complete rewrite of all tests that operate on that screen. </li>
</ul>
<p>In a few words, user interface tests are very expansive and have low reusability, so it's rarely worth automating them. However, ASP.NET Core supplies the <kbd>Microsoft.AspNetCore.Mvc.Testing</kbd> NuGet package to run the whole website in a testing environment. Using it together with the <kbd>AngleSharp</kbd> NuGet package, which parses HTML pages into DOM trees, you can write automated full tests with an acceptable programming effort. The automated ASP.NET Core acceptance tests will be described in detail in <a href="e61b3c5d-3abd-4442-9c9c-e12fd3acedcc.xhtml">Chapter 20</a>, <em>Automation for Software Testing</em>.</p>
<p>Performance tests apply a fake load to an application to see if it is able to handle the typical production load, to discover its load limits, and to locate bottlenecks. The application is deployed in a staging environment that is a copy of the actual production environment in terms of hardware resources. Then, fake requests are created and applied to the system, and response times and other metrics are collected. Fake request batches should have the same composition as the actual production batches. They can be generated from the actual production request logs if they are available.</p>
<p>If response times are not satisfactory, other metrics are collected to discover possible bottlenecks (low memory, slow storages, or slow software modules). Once located, a software component that is responsible for the problem can be analyzed in the debugger to measure the execution time of the various method calls involved in a typical request.</p>
<p>Failures in the performance tests may lead either to a redefinition of the hardware needed by the application or to the optimization of some software modules, classes or methods.</p>
<p>Both Azure and Visual Studio offer tools to create fake loads and to report execution metrics. However, they have been declared obsolete and will be discontinued in quite a short time (about one year from writing this book), and so we will not describe them. As an alternative, there are both open source and third-party tools that can be used. Some of them are listed in the <em>Further reading</em> section.</p>
<p>The next section describes a software development methodology that gives a central role to tests.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding test-driven development (TDD)</h1>
                
            
            
                
<p><strong>Test-driven development</strong> (<strong>TDD</strong>) is a software development methodology that gives a central and central role to unit tests. According to this methodology, unit tests are a formalization of the specifications of each class, so they must be written before the code of the class. Actually, a full test that covers all code paths univocally defines the code behavior, so it can be considered a specification for the code. It is not a formal specification that defines the code behavior through some formal language, but a specification based on behavior examples.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The ideal way to test software would be to write formal specifications of the whole software behavior and to verify with some completely automatic tools if the software that was actually produced conforms with them. In the past, some research effort was spent defining formal languages for describing code specifications, but expressing the behavior the developer has in mind with similar languages was a very difficult and error-prone task. Therefore, these attempts were quickly abandoned in favor of approaches based on examples. At that time, the main purpose was the automatic generation of code. Nowadays, automatic code generation has been substantially abandoned and survives in small application areas, such as the creation of device drivers. In these areas, the effort of formalizing the behavior in a formal language is worth the time saved in trying to test difficult-to-reproduce behaviors of parallel threads.</p>
<p>Unit tests were initially conceived as a way to encode example-based specifications in a completely independent way, as a part of a specific agile development methodology called <strong>Extreme Programming</strong>. However, nowadays, TDD is used independently of Extreme Programming and is included as an obligatory prescription in other agile methodologies.</p>
<p>While it is undoubtedly true that unit tests refined after finding hundreds of bugs act as reliable code specifications, it is not obvious that developers can easily design unit tests that can be immediately used as reliable specifications for the code to be written. In fact, generally, you need an infinite or at least an immense number of examples to univocally define a code's behavior if examples are chosen at random. </p>
<p>The behavior can be defined with an acceptable number of examples only after you have understood all possible execution paths. In fact, at this point, it is enough to select a typical example for each execution path. Therefore, writing a unit test for a method after that method has been completely coded is easy: it simply requires selecting a typical instance for each execution path of the already existing code. However, writing unit tests this way does not protect from errors in the design of the execution paths themselves. For instance, it doesn't prevent the typical error of forgetting to test a variable for the <kbd>null</kbd> value before invoking a member. That is why TDD suggests writing unit tests before the application code.</p>
<p>We may conclude that, while writing unit tests, the developer must forecast somehow all execution paths by looking for extreme cases and by possibly adding more examples than strictly needed. However, the developer can make mistakes while writing the application code, and he or she can also make mistakes in forecasting all possible execution paths while designing the unit tests. </p>
<p>We have found the main drawback of TDD: unit tests themselves may be wrong. That is, not only application code, but also its associated TDD unit tests may be incoherent with the behavior the developer has in mind. Therefore, in the beginning, unit tests can't be considered software specifications, but rather a possible wrong and incomplete description of the software behavior. Therefore, we have two descriptions of the behavior we have in mind, the application code itself and its TDD unit tests that were written before the application code. </p>
<p>What makes TDD work is that the probability of making exactly the same error while writing the tests and while writing the code is very low. Therefore, whenever a test fails there is an error either in the tests or in the application code, and, conversely, if there is an error either in the application code or in the test, there is a very high probability a test will fail. That is, the usage of TDD ensures that most of the bugs are immediately found!</p>
<p>Writing a class method or a chunk of code with TDD is a loop composed of three stages:</p>
<ul>
<li>Red stage: In this stage, the developer designs new unit tests that must necessarily fail because at this time there is no code that implements the behavior they describe.</li>
<li>Green stage: In this stage, the developer writes the minimum code or makes the minimum modifications to existing code that are necessary to pass all unit tests.</li>
<li>Refactoring stage: Once the test is passed, code is refactored to ensure good code quality and the application of best practices and patterns. In particular, in this stage, some code can be factored out in other methods or in other classes. During this stage, we may also discover the need for other unit tests, because new execution paths or new extreme cases are discovered or created.</li>
</ul>
<p>The loop stops as soon as all tests pass without writing new code or modifying the existing code.</p>
<p>Sometimes, it is very difficult to design the initial unit tests because it is quite difficult to imagine how the code might work and the execution paths it might take. In this case, you can get a better understanding of the specific algorithm to use by writing an initial sketch of the application code. In this initial stage, we need to focus just on the main execution path, completely ignoring extreme cases and input verifications. Once we get a clear picture of the main ideas behind an algorithm that should work we can enter the standard three-stage TDD loop.</p>
<p>In the next section, we will list all test projects available in Visual Studio and describe xUnit in detail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Defining C# test projects</h1>
                
            
            
                
<p>Visual Studio contains project templates for three types of unit testing frameworks, namely, MSTest, xUnit, and NUnit. Once you start the new project wizard, in order to visualize the version of all of them that is adequate for .NET Core C# applications, set Project type as Test, Language as C#, and Platform as Linux, since .NET Core projects are the only ones that can be deployed on Linux.</p>
<p>The following screenshot shows the selection that should appear:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/e137b957-4a21-44f1-8824-b7e36823e952.png" style="width:34.75em;height:25.25em;"/></p>
<p>All the preceding projects automatically include the NuGet package for running all the tests in the Visual Studio test user interface (Visual Studio test runner). However, they do not include any facility for mocking interfaces, so you need to add the <kbd>Moq</kbd> NuGet package that contains a popular mocking framework. </p>
<p>All test projects must contain a reference to the project to be tested.</p>
<p class="mce-root"/>
<p>In the next section, we will describe xUnit, since it is probably the most popular of the three frameworks. However, all three frameworks are quite similar and differ mainly in the names of the methods and in the names of the attributes used to decorate various testing stuff.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using the xUnit test framework</h1>
                
            
            
                
<p>In xUnit, tests are methods decorated with either with the <kbd>[Fact]</kbd> or with the <kbd>[Theory]</kbd> attributes. Tests are automatically discovered by the test runner that lists all of them in the user interface so the user can run either all of them or just a selection of them. </p>
<p>A new instance of the test class is created before running each test, so the <em>test preparation</em> code contained in the class constructor is executed before each test of the class. If you also need <em>tear-down</em> code, the test class must implement the <kbd>IDisposable</kbd> interface so that the tear-down code can be included in the <kbd>IDisposable.Dispose</kbd> method.</p>
<p>The test code invokes the methods to be tested and then tests the results with methods of the <kbd>Assert</kbd> static class, such as <kbd>Assert.NotNull(x)</kbd>, <kbd>Assert.Equal(x, y)</kbd>, and <kbd>Assert.NotEmpty(IEnumerable x)</kbd>. There are also methods that verify if a call throws an exception of a specific type, for instance:</p>
<pre> Assert.Throws&lt;MyException&gt;(() =&gt; {/* test code */ ...}).</pre>
<p>When an assertion fails, an exception is thrown. A test fails if a not-intercepted exception is thrown either by the test code or by an assertion.</p>
<p>The following is an example of a method that defines a single test:</p>
<pre>[Fact]<br/>public void Test1()<br/>{<br/>    var myInstanceToTest = new ClassToTest();<br/>    Assert.Equal(5,     myInstanceToTest.MethodToTest(1));<br/>}</pre>
<p>The <kbd>[Fact]</kbd> attribute is used when a method defines just one test, while the <kbd>[Theory]</kbd> attribute is used when the same method defines several tests, each on a different tuple of data. Tuples of data can be specified in several ways and are injected in the test as method parameters.</p>
<p class="mce-root"/>
<p>The previous code can be modified to test <kbd>MethodToTest</kbd> on several input as follows:</p>
<pre>[Theory]<br/>[InlineData(1, 5)]<br/>[InlineData(3, 10)]<br/>[InlineData(5, 20)]<br/>public void Test1(int testInput, int testOutput)<br/>{<br/>    var myInstanceToTest = new ClassToTest();<br/>    Assert.Equal(testOutput, <br/>        myInstanceToTest.MethodToTest(testInput);<br/>}</pre>
<p>Each <kbd>InlineData</kbd> attribute specifies a tuple to be injected in the method parameters. Since just simple constant data can be included as attribute arguments, xUnit gives you also the possibility to take all data tuples from a class that implements <kbd>IEnumerable</kbd>, as shown in the following example:</p>
<pre>public class Test1Data: IEnumerable&lt;object[]&gt;<br/>{<br/>    public IEnumerator&lt;object[]&gt; GetEnumerator()<br/>    {<br/>        yield return new object[] { 1, 5};<br/>        yield return new object[] { 3, 10 };<br/>        yield return new object[] { 5, 20 };<br/>        <br/>    }<br/><br/>    IEnumerator IEnumerable.GetEnumerator()<br/>    {<br/>        return GetEnumerator();<br/>    }<br/>}<br/>...<br/>...<br/>[Theory]<br/>[ClassData(typeof(Test1Data))]<br/>public void Test1(int testInput, int testOutput)<br/>{<br/>    var myInstanceToTest = new ClassToTest();<br/>    Assert.Equal(testOutput, <br/>        myInstanceToTest.MethodToTest(testInput);<br/>}</pre>
<p>The type of the class that provides the test data is specified with the <kbd>ClassData</kbd> attribute.</p>
<p class="mce-root"/>
<p>It is also possible to take data from a static method of a class that returns an <kbd>IEnumerable</kbd> with the <kbd>MemberData</kbd> attribute, as shown in the following example:</p>
<pre>[Theory]<br/>[MemberData(nameof(MyStaticClass.Data), <br/>    MemberType= typeof(MyStaticClass))]<br/>public void Test1(int testInput, int testOutput)<br/>{<br/>    ...</pre>
<p>The <kbd>MemberData</kbd> attribute is passed the method name as the first parameter, and the class type in the <kbd>MemberType</kbd> named parameter. If the static method is part of the same test class the <kbd>MemberType</kbd> parameter can be omitted.</p>
<p>The next section shows how to deal with some advanced preparation and tear-down scenarios.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Advanced test preparation and tear-down scenarios</h1>
                
            
            
                
<p>Sometimes the preparation code contains very time-consuming operations, such as opening a connection with a database, that don't need to be repeated before each test but can be executed once before all the tests contained in the same class. In xUnit, this kind of test preparation code can't be included in the test class constructor; since a different instance of the test class is created before every single test, it must be factored out in a separate class called a fixture class.</p>
<p>If we also need a corresponding tear-down code, the fixture class must implement <kbd>IDisposable</kbd>. In other test frameworks, such as NUnit, the test class instances are created just once instead, so they don't need the fixture code to be factored out in other classes. However, test frameworks that, like NUnit, do not create a new instance before each test may suffer from bugs because of unwanted interactions between test methods. </p>
<p>The following is an example of an xUnit fixture class that opens and closes a database connection:</p>
<pre>public class DatabaseFixture : IDisposable<br/>{<br/>    public DatabaseFixture()<br/>    {<br/>        Db = new SqlConnection("MyConnectionString");<br/>    }<br/><br/>    public void Dispose()<br/>    {<br/>        Db.Close()<br/>    }<br/>    public SqlConnection Db { get; private set; }<br/>}</pre>
<p>Since a fixture class instance is created just once before all tests associated with the fixture are executed and the same instance is disposed of immediately after the tests, then the database connection is created just once when the fixture class is created and is disposed of immediately after the tests when the fixture object is disposed of.</p>
<p>The fixture class is associated with each test class by letting the test class implement the empty <kbd>IClassFixture&lt;T&gt;</kbd> interface, as follows:</p>
<pre>public class MyTestsClass : IClassFixture&lt;DatabaseFixture&gt;<br/>{<br/>    DatabaseFixture fixture;<br/><br/>    public MyDatabaseTests(DatabaseFixture fixture)<br/>    {<br/>        this.fixture = fixture;<br/>    }<br/>    ...<br/>    ...<br/>}</pre>
<p>A fixture class instance is automatically injected in the test class constructor in order to make all data computed in the fixture test preparation available for the tests. This way, for instance, in our previous example we can get the database connection instance so that all test methods of the class can use it.</p>
<p>If we want to execute some test preparation code on all tests contained in a collection of test classes instead of a single test class, we must associate the fixture class to an empty class that represents the collection of test classes, as follows:</p>
<pre>[CollectionDefinition("My Database collection")]<br/>public class DatabaseCollection : ICollectionFixture&lt;DatabaseFixture&gt;<br/>{<br/>    // this class is empty, since it is just a placeholder<br/>}</pre>
<p>The <kbd>CollectionDefinition</kbd> attribute declares the name of the collection, and the <kbd>IClassFixture&lt;T&gt;</kbd> interface has been replaced with <kbd>ICollectionFixture&lt;T&gt;</kbd>.</p>
<p class="mce-root"/>
<p>Then we declare that a test class belongs to the previously defined collection by applying it to the <kbd>Collection</kbd> attribute with the name of the collection, as follows:</p>
<pre>[Collection("My Database collection")]<br/>public class MyTestsClass <br/>{<br/>    DatabaseFixture fixture;<br/><br/>    public MyDatabaseTests(DatabaseFixture fixture)<br/>    {<br/>        this.fixture = fixture;<br/>    }<br/>    ...<br/>    ...<br/>}</pre>
<p>The <kbd>Collection</kbd> attribute declares which collection to use, while the <kbd>DataBaseFixture</kbd> argument in the test class constructor provides an actual fixture class instance, so it can be used in all class tests.</p>
<p>The next section shows how to mock interfaces with the Moq framework.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Mocking interfaces with Moq</h1>
                
            
            
                
<p>Mocking capabilities are not included in any of the test frameworks we listed in this section as they are not included in xUnit. Therefore, they must be provided by installing a specific NuGet package. The Moq framework available in the <kbd>Moq</kbd> NuGet package is the most popular mock framework available for .NET and .NET Core. It is quite easy to use and will be briefly described in this section.</p>
<p>Once we've installed the NuGet package, we need to add a <kbd>using Moq</kbd> statement in our test files. A mock implementation is easily defined, as follows:</p>
<pre>  var myMockDependency = new Mock&lt;IMyInterface&gt;();</pre>
<p>The behavior of the mock dependency on specific input of the specific method can be defined with the <kbd>Setup/Return</kbd> method pair as follows:</p>
<pre>myMockDependency.Setup(x=&gt;x.MyMethod(5)).Returns(10);</pre>
<p>After <kbd>Return</kbd>, we may place another <kbd>Setup/Return</kbd> pair that defines either the behavior of different input of the same method or the behavior of a different method. This way we can specify an indefinite number of input/output behaviors.</p>
<p class="mce-root"/>
<p>Instead of specific input values, we may also use wildcards that match a specific type as follows:</p>
<pre>myMockDependency.Setup(x =&gt; x.MyMethod(It.IsAny&lt;int&gt;))<br/>                  .Returns(10);</pre>
<p>Once configured the mock dependency we may extract the mocked instance from its <kbd>Object</kbd> property and use it as if it were an actual implementation, as follows:</p>
<pre>var myMockedInstance=myMockDependency.Object;<br/>...<br/>myMockedInstance.MyMethod(10);</pre>
<p>However, mocked methods are usually called by the code under test, so we just need to extract the mocked instance and use it as an input in our tests.</p>
<p>We may also mock properties and async methods as follows:</p>
<pre>myMockDependency.Setup(x =&gt; x.MyProperty)<br/>                  .Returns(42);<br/>...<br/>myMockDependency.Setup(p =&gt; p.MyMethodAsync(1))<br/>                    .ReturnsAsync("aasas");<br/>var res=await myMockDependency.Object<br/>    .MyMethodAsync(1);</pre>
<p>With async methods, <kbd>Returns</kbd> must be replaced by <kbd>ReturnsAsync</kbd>.</p>
<p>Each mocked instance records all calls to its methods and properties, so we may use this information in our tests. The following code shows an example:</p>
<pre>myMockDependency.Verify(x =&gt; x.MyMethod(1), Times.AtLeast(2))</pre>
<p>The preceding statement asserts <kbd>MyMethod</kbd> that has been invoked with the given arguments at least twice. There are also <kbd>Times.Never</kbd>, a <kbd>Times.Once</kbd> (that asserts the method was called just once), and more.</p>
<p>The Moq documentation summarized up to now should cover 99% of the needs that may arise in your tests, but Moq also offers more complex options. The <em>Further reading</em> section contains the link to the complete documentation.</p>
<p>The next section shows how to define in practice unit tests and how to run them both in Visual Studio and in Azure DevOps with the help of the book use case.</p>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Use case – automating unit tests in DevOps Azure</h1>
                
            
            
                
<p>In this section, we add some unit test projects to the example application we built in <a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml">Chapter 13</a>, <em>Presenting ASP.NET Core MVC</em>. If you don't have it, you can download it from the <a href="003ee8cb-5995-4364-8772-73d73df29cf8.xhtml">Chapter 13</a>, <em>Presenting ASP.NET Core MVC</em>, section of the GitHub repository associated with the book. The <a href="049a0a4b-74b6-41a1-92db-87a4f8af9fd1.xhtml">Chapter 4</a>, <em>Deciding The Best Cloud-Based Solution</em>, section of the GitHub repository contains the code we will add in this section and all the instructions to add it.</p>
<p>As a first step, let's make a new copy of the solution folder and name it <kbd>PackagesManagementWithTests</kbd>. Then open the solution and add it to xUnit .NET Core C# test project named <kbd>PackagesManagementTest</kbd>. Finally, add a reference to the ASP.NET Core project (<kbd>PackagesManagement</kbd>), since we will test it, and a reference to the last version of the <kbd>Moq</kbd> NuGet package, since we need mocking capabilities. At this point, we are ready to write our tests. </p>
<p>As an example, we will write unit tests for the <kbd>Edit</kbd> method decorated with <kbd>[HttpPost]</kbd> of the <kbd>ManagePackagesController</kbd> controller, which is shown as follows:</p>
<pre>[HttpPost]<br/>public async Task&lt;IActionResult&gt; Edit(<br/>    PackageFullEditViewModel vm,<br/>    [FromServices] ICommandHandler&lt;UpdatePackageCommand&gt; command)<br/>{<br/>    if (ModelState.IsValid)<br/>    {<br/>        await command.HandleAsync(new UpdatePackageCommand(vm));<br/>        return RedirectToAction(<br/>            nameof(ManagePackagesController.Index));<br/>    }<br/>    else<br/>        return View(vm);<br/>}</pre>
<p>Before writing our test methods, let's rename the test class that was automatically included in the test project as <kbd>ManagePackagesControllerTests</kbd>.</p>
<p class="mce-root"/>
<p>The first test verifies that in case there are errors in <kbd>ModelState</kbd> the action method renders a view with the same model it received as an argument so that the user can correct all errors. Let's delete the existing test method and write an empty <kbd>DeletePostValidationFailedTest</kbd> method, as follows:</p>
<pre>[Fact]<br/>public async Task DeletePostValidationFailedTest()<br/>{<br/>}</pre>
<p>The method must be <kbd>async</kbd> since the <kbd>Edit</kbd> method that we have to test is <kbd>async</kbd>. In this test, we don't need mocked objects since no injected object will be used. Thus, as a preparation for the test we just need to create a controller instance, and we must add an error to <kbd>ModelState</kbd> as follows:</p>
<pre>var controller = new ManagePackagesController();<br/>controller.ModelState<br/>    .AddModelError("Name", "fake error");</pre>
<p>Then we invoke the method, injecting <kbd>ViewModel</kbd> and a <kbd>null</kbd> command handler as its arguments since the command handler will not be used:</p>
<pre>var vm = new PackageFullEditViewModel();<br/>var result = await controller.Edit(vm, null);</pre>
<p>In the verification stage, we verify that the result is <kbd>ViewResult</kbd> and that it contains the same model that was injected in the controller:</p>
<pre>Assert.IsType&lt;ViewResult&gt;(result);<br/>Assert.Equal(vm, (result as ViewResult).Model);</pre>
<p>Now we also need a test to verify that in case there are no errors the command handler is called, and then the browser is redirected to the <kbd>Index</kbd> controller action method. We call the <kbd>DeletePostSuccessTest</kbd> method:</p>
<pre>[Fact]<br/>public async Task DeletePostSuccessTest()<br/>{<br/>}</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>This time the preparation code must include the preparation of a command handler mock, as follows:</p>
<pre>var controller = new ManagePackagesController();<br/>var commandDependency =<br/>    new Mock&lt;ICommandHandler&lt;UpdatePackageCommand&gt;&gt;();<br/>commandDependency<br/>    .Setup(m =&gt; m.HandleAsync(It.IsAny&lt;UpdatePackageCommand&gt;()))<br/>    .Returns(Task.CompletedTask);<br/>var vm = new PackageFullEditViewModel();</pre>
<p>Since the handler <kbd>HandleAsync</kbd> method returns no <kbd>async</kbd> value, we can't use <kbd>ReturnsAsync</kbd>, but we have to return just a completed <kbd>Task</kbd> (<kbd>Task.Complete</kbd>) with the <kbd>Returns</kbd> method. The method to test is called with both <kbd>ViewModel</kbd> and the mocked handler:</p>
<pre>var result = await controller.Edit(vm, <br/>    commandDependency.Object);</pre>
<p>In this case, the verification code is as follows:</p>
<pre>commandDependency.Verify(m =&gt; m.HandleAsync(<br/>    It.IsAny&lt;UpdatePackageCommand&gt;()), <br/>    Times.Once);<br/>Assert.IsType&lt;RedirectToActionResult&gt;(result);<br/>var redirectResult = result as RedirectToActionResult;<br/>Assert.Equal(nameof(ManagePackagesController.Index), <br/>    redirectResult.ActionName);<br/>Assert.Null(redirectResult.ControllerName);</pre>
<p>As the first step, we verify that the command handler has actually been invoked once. A better verification should also include a check that it was invoked with a command that includes <kbd>ViewModel</kbd> passed to the action method. This can be done by extracting this information from <kbd>commandDependency.Invocations</kbd>. We will take it up as an exercise.</p>
<p>Then we verify that the action method returns <kbd>RedirectToActionResult</kbd> with the right action method name and with no controller name specified.</p>
<p>Once all tests are ready, if the test windows don't appear on the left bar of Visual Studio, we may simply select the Run all tests item from Visual Studio Test menu. Once the test window appears, further invocations can be launched from within this window.</p>
<p>If a test fails, we can add a breakpoint to its code, so we can launch a debug session on it by right-clicking on it in the test window and then by selecting Debug selected tests.</p>
<p class="mce-root"/>
<p>The following steps show how to connect our solution with an Azure DevOps repository, and we will define an Azure DevOps pipeline that builds the project and launches its tests. In this way, every day after that all developers have pushed their changes we can launch the pipeline to verify that the repository code compiles and passes all the tests:</p>
<ol>
<li>As a first step, we need a free DevOps subscription. If you don't already have one, please create one by clicking the Start Free button on this page: <a href="https://azure.microsoft.com/en-us/services/devops/">https://azure.microsoft.com/en-us/services/devops/</a>. Here, let's define an organization but stop before creating a project, since we will create the project from within Visual Studio.</li>
<li>Ensure you are logged into Visual Studio with your Azure account (the same used in the creation of the DevOps account). At this point, you may create a DevOps repository for your solution by right-clicking on the solution and by selecting Configure continuous delivery to Azure.... In the window that appears, an error message will inform you that you have no repository configured for your code:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/dbc6d39a-7382-45bc-9bc0-9a16480889fd.png" style="width:47.50em;height:10.25em;"/></p>
<ol start="3">
<li>Click the Add to source control now link. After that, the DevOps screen will appear in the Visual Studio Team Explorer tab:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/ea638c5d-f9df-4efb-9900-55e2d82f91ac.png" style="width:28.83em;height:15.83em;"/></p>
<ol start="4">
<li>Once you click the Publish Git Repo button, you will be prompted to select your DevOps organization and a name for the repository. After you successfully publish your code to a DevOps repository, the DevOps screen should change as follows:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/fee29f8b-e302-4bba-a4c0-f5e238a8360f.png" style="width:28.58em;height:4.83em;"/></p>
<p style="padding-left: 60px">The DevOps screen shows a link to your online DevOps project. In future when you open your solution, if the link does not appear, please click the DevOps screen Connect button or the Manage connections link (whichever appears) to select and connect your project.</p>
<ol start="5">
<li>Click this link to go to the online project. Once there, if you click the Repos item, on the left-hand menu, you will see the repository you just published. </li>
<li>Now, click the Pipelines menu item to create a DevOps pipeline to build and test your project. In the window that appears, click the button to create a new pipeline:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/d6b38797-da24-4450-9375-88d70a784da6.png" style="width:22.83em;height:16.67em;"/></p>
<ol start="7">
<li>You will be prompted to select where your repository is:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/312d6a6e-71f3-4f9e-945c-df13b556ad9d.png" style="width:26.33em;height:18.00em;"/></p>
<ol start="8">
<li>Select Azure Repos Git and then your repository. Then you will be prompted about the kind of project:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/dd35e542-279e-473b-9f8a-a6212f4fa607.png" style="width:28.42em;height:11.83em;"/></p>
<ol start="9">
<li>Select ASP.NET Core. A pipeline for building and testing your project will be automatically created for you. Save it by committing the newly created <kbd>.yaml</kbd> file to your repository:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/c97e7062-e8f8-4ee0-a7f9-ae78f5c77746.png" style="width:26.42em;height:22.50em;"/></p>
<ol start="10">
<li>The pipeline can be run by selecting the Queue button, but since the standard pipeline scaffolded by DevOps has a trigger on the master branch of the repository, it is automatically launched each time changes to this branch are committed and each time the pipeline is modified. The pipeline can be modified by clicking the Edit button:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/9d650049-a388-41e8-8617-ac1603d5b610.png" style="width:37.00em;height:22.33em;"/></p>
<ol start="11">
<li>Once in edit mode, all pipeline steps can be edited by clicking the Settings link that appears above each of them. New pipeline steps can be added as follows:
<ol>
<li>Write <kbd>task:</kbd> where the new step must be added and then accept one of the suggestions that appear while you are typing the task name.</li>
<li>After you have written a valid task name a Settings link appears above the new step, click it.</li>
<li>Insert the desired task parameters in the window that appears and save.</li>
</ol>
</li>
<li>In order to have our test working, we need to specify the criteria to locate all assemblies that contain tests. In our case, since we have a unique <kbd>.dll</kbd> file containing the tests, it is enough to specify its name. Click the Settings link of the <kbd>VSTest@2</kbd> test task, and replace the content that is automatically suggested for the Test files field with the following:</li>
</ol>
<pre style="padding-left: 60px">**\PackagesManagementTest.dll<br/>!**\*TestAdapter.dll<br/>!**\obj\**</pre>
<ol start="13">
<li>Then click Add to modify the actual pipeline content. As soon as you confirm your changes in the Save and run dialog, the pipeline is launched, and if there are no errors, test results are computed. The results of tests launched during a specific build can be analyzed by selecting the specific build in the pipeline History tab and by clicking the Tests tab on the page that appears. In our case, we should see something like the following screenshot:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/2f00596e-c2af-4fa5-94f6-fea25143eb4e.png" style="width:40.50em;height:21.17em;"/></p>
<ol start="14">
<li>If you click the Analytics tab of the pipeline page, you will see analytics about all builds, including analytics about the test results:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/3826cfb0-e925-40f6-b796-29ea9865b12a.png" style="width:37.00em;height:16.42em;"/></p>
<ol start="15">
<li>Clicking the test area of the Analytics page gets us a detailed report about all pipeline test results.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we explained why it is worth automating software tests, and then we focused on the importance of unit tests. We also listed all types of tests and their main features, focusing mainly on unit tests. We analyzed the advantages of TDD, and how to use it in practice. With this knowledge, you should be able to produce software that is both reliable and easy to modify.</p>
<p>Finally, we analyzed all test tools available for .NET Core projects, focusing on the description of xUnit and Moq and showed how to use them in practice both in Visual Studio and in Azure DevOps with the help of the book use case.</p>
<p>The next chapter looks at how to test and measure the quality of the code.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<ol>
<li>Why is it worth automating unit tests?</li>
<li>What is the main reason TDD is able immediately to discover most bugs?</li>
<li>What is the difference between the <kbd>[Theory]</kbd> and <kbd>[Fact]</kbd> attributes of xUnit?</li>
<li>Which xUnit static class is used in test assertions?</li>
<li>Which methods allow the definition of the Moq mocked dependencies?</li>
<li>Is it possible to mock async methods with Moq? If yes, how?</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>While the documentation on xUnit included in the chapter is quite complete, it doesn't include the few configuration options offered by xUnit. The full xUnit documentation is available at <a href="https://xunit.net/">https://xunit.net/</a>. Documentation for MSTest and NUnit can be found at <a href="https://github.com/microsoft/testfx">https://github.com/microsoft/testfx</a> and at <a href="https://github.com/nunit/docs/wiki/NUnit-Documentation">https://github.com/nunit/docs/wiki/NUnit-Documentation</a> respectively.</p>
<p>Moq full documentation is at <a href="https://github.com/moq/moq4/wiki/Quickstart">https://github.com/moq/moq4/wiki/Quickstart</a>.</p>
<p>Here are some links to performance test frameworks for web applications:</p>
<ul>
<li><a href="https://jmeter.apache.org/">https://jmeter.apache.org/</a> (free and open source)</li>
<li><a href="https://www.neotys.com/neoload/overview">https://www.neotys.com/neoload/overview</a></li>
<li><a href="https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview">https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview</a></li>
<li><a href="https://www.microfocus.com/en-us/products/silk-performer/overview">https://www.microfocus.com/en-us/products/silk-performer/overview</a></li>
</ul>


            

            
        
    </body></html>