- en: Monitoring Microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When something goes wrong in a system, stakeholders will want to know what has
    happened, why it has happened, any hint or clue you can give for how it might
    be fixed, and how to prevent the same problem from occurring again in the future.
    This is one of the primary uses of monitoring. However, monitoring can also do
    much more.
  prefs: []
  type: TYPE_NORMAL
- en: In .NET monoliths, there are multiple monitoring solutions available to choose
    from. The monitoring target is always centralized, and monitoring is certainly
    easy to set up and configure. If something breaks down we know what to look for
    and where to look for it, since only a finite number of components participate
    in a system, and they have a fairly long lifespan.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, microservices are distributed systems and, by nature, more complex
    than monoliths. So resource utilization and health and performance monitoring
    are quite essential in a microservice production environment. We can use this
    diagnostic piece of information to detect and correct issues, and to also spot
    potential problems and prevent them from occurring. Monitoring microservices presents
    different challenges. In this chapter, we will primarily discuss the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The need for monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and logging challenges in microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Available tools and strategies for microservices in the .NET monitoring space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of Azure diagnostics and application insight
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A brief overview of the ELK stack and Splunk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What does monitoring really mean? There is no formal definition of monitoring; however,
    the following is appropriate:'
  prefs: []
  type: TYPE_NORMAL
- en: '''''Monitoring provides information around the behavior of an entire system
    or different parts of a system in their operational environment. This information
    can be used for diagnosing and gaining insight into the different characteristics
    of a system.'''''
  prefs: []
  type: TYPE_NORMAL
- en: Instrumentation and telemetry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A monitoring solution is dependent upon instrumentation and telemetry. So it
    is natural that when we speak about monitoring microservices, we also discuss
    instrumentation and telemetry data. Logs are nothing more than an instrumentation
    mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumentation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now let''s look at what instrumentation is. Instrumentation is one of the ways
    through which you can add diagnostic features to applications. It can be formally
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '''''Most applications will include diagnostic features that generate custom
    monitoring and debugging information, especially when an error occurs. This is
    referred to as instrumentation and is usually implemented by adding event and
    error handling code to the application."'
  prefs: []
  type: TYPE_NORMAL
- en: -MSDN
  prefs: []
  type: TYPE_NORMAL
- en: Under normal conditions, data from informational events may not be required,
    thus reducing the cost of storage and the transactions required to collect it.
    However, when there is an issue with the application, you have to update the application
    configuration so that the diagnostic and instrumentation systems can collect informational
    event data as well as error and warning messages to assist in isolating and fixing
    faults. It may be necessary to run the application in this extended reporting
    mode for some time if the problem appears only intermittently.
  prefs: []
  type: TYPE_NORMAL
- en: Telemetry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Telemetry, in its most basic form, is the process of gathering information
    generated by instrumentation and logging systems. Typically, it is performed using
    asynchronous mechanisms that support massive scaling and the wide distribution
    of application services. It can be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '"The process of gathering remote information that is collected by instrumentation
    is usually referred to as telemetry."'
  prefs: []
  type: TYPE_NORMAL
- en: -MSDN
  prefs: []
  type: TYPE_NORMAL
- en: In large and complex applications, information is usually captured in a data
    pipeline and stored in a form that makes it easier to analyze and display at different
    levels of granularity. This information is used to discover trends, gain insight
    into usage and performance, and detect and isolate faults.
  prefs: []
  type: TYPE_NORMAL
- en: Azure has no built-in system that directly provides a telemetry and reporting
    system of this type. However, a combination of the features exposed by all the
    Azure services, Azure diagnostics, and application insights allows you to create
    telemetry mechanisms that span the range of simple monitoring mechanisms to comprehensive
    dashboards. The complexity of the telemetry mechanism you require usually depends
    on the size of the application. This is based on several factors, such as the
    number of roles or virtual machine instances, the number of ancillary services
    it uses, the distribution of the application across different data centers, and
    other related factors.
  prefs: []
  type: TYPE_NORMAL
- en: The need for monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices are complex, distributed systems. Microservice implementation
    is the backbone of any modern IT business. Understanding the internals of the
    services along with their interactions and behaviors will help you make the overall
    business more flexible and agile. The performance, availability, scale, and security
    of microservices can directly affect a business and also its revenue. Hence, monitoring
    microservices is vital. It helps us observe and manage the quality of the service
    attributes. Let's discuss the scenarios where it is required.
  prefs: []
  type: TYPE_NORMAL
- en: Health monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With health monitoring, we monitor the health of a system and its various components
    at a certain frequency, typically a few seconds. This ensures that the system
    and its components behave as expected. With the help of an exhaustive health monitoring
    system, we can keep tabs on the overall system health, including the CPU, memory
    utilization, and so on. It might be in the form of pings or extensive health monitoring
    endpoints, which emit the health status of services along with some useful metadata
    at that point in time.
  prefs: []
  type: TYPE_NORMAL
- en: For health monitoring, we can use the rate of request failures and successes;
    we can also utilize techniques such as synthetic user monitoring. We will see
    synthetic user monitoring a little later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The metrics for health monitoring are based on the threshold values of success
    or failure rates. If the parameter value goes beyond the configured threshold,
    an alert is triggered. It is quite possible that some preventive action to maintain
    the health of the system would be triggered due to this failure. This action could
    be restarting the service in the failure state, or provisioning some server resource.
  prefs: []
  type: TYPE_NORMAL
- en: Availability monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Availability monitoring is quite similar to health status monitoring, which
    we just discussed. However, the subtle difference is that in availability monitoring,
    the focus is on the availability of systems rather than a snapshot of the health
    at that point in time.
  prefs: []
  type: TYPE_NORMAL
- en: Availability of systems is dependent on various factors, such as the overall
    nature and domain of the application, services, and service dependencies as well
    as infrastructure or environment. The availability monitoring system captures
    low-level data points related to these factors and represents them so as to make
    a business-level feature available. Many times, availability monitoring parameters
    are used to track business metrics and **service-level agreements** (**SLA**).
  prefs: []
  type: TYPE_NORMAL
- en: Performance monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The performance of a system is often measured by key performance indicators.
    Some of the key performance indicators of any large web-based system are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The number of requests served per hour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of concurrent users served per hour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The average processing time required by users to perform business transactions,
    for example, placing an order
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, performance is also gauged by system-level parameters, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I/O rates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of queued messages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If any of these key performance indicators are not met by the system, an alert
    is raised.
  prefs: []
  type: TYPE_NORMAL
- en: Often, while analyzing performance issues, historical data from previous benchmarks
    captured by the monitoring system is used to troubleshoot.
  prefs: []
  type: TYPE_NORMAL
- en: Security monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring systems can detect unusual data pattern requests, unusual resource
    consumption patterns, and detect attacks on the system. Specifically, in the case
    of DoS, attacks or injection attacks can be identified beforehand and teams can
    be alerted. Security monitoring also keeps audit trails of authenticated users
    and keeps a history of users who have checked in and out of the system. It also
    comes in handy for satisfying compliance requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Security is a cross-cutting concern of distributed systems, including microservices,
    so there are multiple ways of generating this data in the system. Security monitoring
    can get data from various tools that are not part of the system but may be part
    of the infrastructure or environment in which the system is hosted. Different
    types of logs and database entries can serve as data sources. However, this really
    depends upon the nature of the system.
  prefs: []
  type: TYPE_NORMAL
- en: SLA monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Systems with SLAs basically guarantee certain characteristics, such as performance
    and availability. For cloud-based services, this is a pretty common scenario.
    Essentially, SLA monitoring is all about monitoring those guaranteed SLAs for
    the system. SLA monitoring is enforced as a contractual obligation between a service
    provider and consumer.
  prefs: []
  type: TYPE_NORMAL
- en: It is often defined on the basis of availability, response time, and throughput.
    Data points required for SLA monitoring can come from performance endpoint monitoring
    or logging and availability of monitoring parameters. For internal applications,
    many organizations track the number of incidences raised due to server downtime.
    The action taken against these incidences' **Root Cause Analysis** (**RCA**) mitigates
    the risk of repeating those issues and helps meet the SLAs.
  prefs: []
  type: TYPE_NORMAL
- en: For internal purposes, an organization might also track the number and nature
    of incidents that had caused the service to fail. Learning how to resolve these
    issues quickly or eliminate them completely helps reduce downtime and meet SLAs.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing sensitive data and critical business transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For any legal obligations or compliance reasons, the system might need to keep
    audit trails of user activities in the system, and record all their data accesses
    and modifications. Since audit information is highly sensitive in nature, it might
    be disclosed only to a few privileged and trusted individuals in the system. Audit
    trails can be part of a security subsystem or separately logged. You may need
    to transfer and store audit trails in a specific format, as stated by the regulation
    or compliance specifications.
  prefs: []
  type: TYPE_NORMAL
- en: End user monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In end user monitoring, the usage of the features of the system and/or the overall
    system usage by end users is tracked and logged. Usage monitoring can be done
    using various user-tracking parameters, such as the features used, the time required
    to complete a critical transaction for the specified user, or even enforced quotas.
    Enforced quotas are constraints or limits put on an end user in regard to system
    usage. In general, various pay-as-you-go services use enforced quotas; for example,
    a free trial, where you can upload files only up to 25 MB. The data source for
    this type of monitoring is typically collected in terms of logs and tracking user
    behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting system failures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The end users of a system might experience system failures. This can be in the
    form of either a system failure or a situation where users are not able to perform
    a certain activity. These kinds of issues are monitored using system logs; if
    not, the end user will need to provide a detailed information report. Also, sometimes
    server crash dumps or memory dumps can be immensely helpful. However, in the case
    of distributed systems, it will be a bit difficult to understand the exact root
    cause of the failures.
  prefs: []
  type: TYPE_NORMAL
- en: In many monitoring scenarios, using only one monitoring technique is not effective.
    It is better to use multiple monitoring techniques and tools for diagnostics.
    In particular, monitoring a distributed system is quite challenging and requires
    data from various sources. In addition to analyzing the situation properly and
    deciding on the action points, we must consider a holistic view of monitoring
    rather than looking into only one type of system perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a better idea about what needs to be done for general purpose
    monitoring, let's revisit the microservice perspective. So we will discuss the
    different monitoring challenges presented by the microservice architectural style.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservice monitoring presents different challenges. There will be scenarios
    where one service could depend upon another service, or a client sends a request
    to one service and the response comes from another service that would make the
    operation complex; hence scaling a microservice would be a challenging task here.
    Similarly, process implementation, let's say DevOps, would be a challenging job
    while implementing a huge enterprise microservice application. So, let's discuss
    these challenges in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Scale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One service could be dependent upon the functionality provided by various other
    microservices. This yields complexity, which is not usual in the case of .NET
    monolith systems. Instrumenting all these dependencies is quite difficult. Another
    problem that comes along with scale is the rate of change. With the advancement
    of continuous deployment and container-based microservices, the code is always
    in a deployable state. Containers only live for minutes, if not seconds. The same
    is true for virtual machines. Virtual machines have a life of around a couple
    of minutes to a couple of hours.
  prefs: []
  type: TYPE_NORMAL
- en: In such a case, measuring regular signals, such as CPU usage and memory consumption
    usage per minute, does not make sense. Sometimes, container instances might not
    even be alive for a minute. Within a minute, the container instance might have
    already been disposed of. This is one of the challenges of microservice monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: DevOps mindset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditionally, services or systems, once deployed, are owned and cared for by
    the operational teams. However, DevOps breaks down the silos between developers
    and operations teams. It comes with lots of practices, such as continuous integration
    and continuous delivery, as well as continuous monitoring. Along with these new
    practices come new tool sets.
  prefs: []
  type: TYPE_NORMAL
- en: However, DevOps is not just a set of practices or tools; it is, more importantly,
    a mindset. It is always a difficult and slow process to change the mindset of
    people. Microservice monitoring also requires a similar mindset shift.
  prefs: []
  type: TYPE_NORMAL
- en: With the emergence of autonomy of services, developer teams now have to own
    services. This also means that they have to work through and fix development issues
    as well as keep an eye on all the operational parameters and SLAs of the services.
    Development teams will not be transformed overnight just by using state-of-the-art
    monitoring tools. This is true for operational teams as well. It won't suddenly
    become a *core platform team* (or whatever fancy name you prefer) overnight.
  prefs: []
  type: TYPE_NORMAL
- en: To make microservices successful and meaningful for organizations, developers,
    and operations, teams need to help each other understand their own pain points
    and also think in the same direction, that is, how they can deliver value to the
    business together. Monitoring cannot happen without the instrumentation of services,
    which is where developer teams can help. Likewise, alerting and setting up of
    operational metrics and running books won't happen without the operational team's
    help. This is one of the challenges in delivering microservice monitoring solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Data flow visualization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of tools present on the market for data flow visualization.
    Some of them are AppDynamics, New Relic, and so on. These tools are capable of
    handling visualizations of 10 to, maybe, 100s of microservices. However, in larger
    settings, where there are thousands of microservices, these tools are unable to
    handle visualization. This is one of the challenges in microservice monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Testing of monitoring tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We trust monitoring tools with the understanding that they depict a factual
    representation of the big picture of our microservice implementation. However,
    to make sure that they remain true to this understanding, we will have to test
    the monitoring tools. This is never a challenge in monolith implementations. However,
    when it comes to microservices, visualization of microservices is required for
    monitoring purposes. This means generating fake/synthetic transactions and time
    and utilizing the entire infrastructure rather than serving the customer. Hence,
    the testing of monitoring tools is a costly affair and presents a significant
    challenge in microservice monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will take a look at the monitoring strategies that make
    microservices observable. It is common to implement the following or more strategies
    to create a well-defined and holistic monitoring solution.
  prefs: []
  type: TYPE_NORMAL
- en: Application/system monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This strategy is also called a **framework-based strategy**. Here, the application,
    or in our case microservice, itself generates the monitoring information within
    the given context of execution. The application can be dynamically configured
    based on the thresholds or trigger points in the application data, which can generate
    tracing statements. It is also possible to have a probe-based framework (such
    as .NET CLR, which provides hooks to get more information) to generate monitoring
    data. So, effective instrumentation points themselves can be embedded into the
    application to facilitate this kind of monitoring. On top of this, the underlying
    infrastructure, where microservices are hosted, can also raise critical events.
    These events can be listened to and recorded by the monitoring agents present
    on the same host as that of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Real user monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This strategy is based on a real end user's transactional flow across the system.
    While the end user is using the system in real time, the parameters related to
    response time and latency, as well as the number of errors experienced by the
    user, can be captured using it.
  prefs: []
  type: TYPE_NORMAL
- en: This is useful for specific troubleshooting and issue resolution. With this
    strategy, the system's hotspots and bottlenecks for service interactions can be
    captured as well. It is possible to record the entire end-to-end user flow or
    transactions to replay it at a later time. The benefits of this are that these
    kinds of recorded plays can be used for troubleshooting of issues as well as for
    various types of testing purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic monitoring and synthetic transactions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The semantic monitoring strategy focuses on business transactions; however,
    it is implemented through the use of synthetic transactions. In semantic monitoring,
    as the name suggests, we try to emulate end user flows. However, this is done
    in a controlled fashion and with dummy data so you can differentiate the output
    of the flow from the actual end user flow data. This strategy is typically used
    for service dependency, health checking, and diagnostics of problems occurring
    across the system. To implement synthetic transactions, we need to be careful
    while planning the flow; also, we need to be careful enough not to stress the
    system out. Here's an example: creating fake orders for fake product catalogs
    and observing the response time and output across this whole transaction propagating
    in the system.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This approach is specifically focused on solving performance bottlenecks across
    the system. This approach is different from the preceding approaches. Real and
    semantic monitoring focuses on business transactions or functional aspects of
    the system and collects data around it. Rather, profiling is all about system-level
    or low-level information capture. A few of these parameters are response time,
    memory, or threads. This approach uses a probing technique in the application
    code or framework and collects data. Utilizing the data points captured during
    the profiling, the relevant DevOps team can identify the cause of the performance
    problem. Profiling using probing should be avoided in production environments.
    However, it is perfectly fine for generating call times and so on without overloading
    the system at runtime. A good example of profiling, in general, is an ASP.NET
    MVC application profiled with an ASP.NET MiniProfiler, or even with Glimpse.
  prefs: []
  type: TYPE_NORMAL
- en: Endpoint monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this approach, we expose one or more endpoints of a service to emit diagnostic
    information related to the service itself as well as the infrastructure parameters.
    Generally, different endpoints focus on providing different information. For example,
    one endpoint can give the health status of the service, while the other could
    provide the HTTP 500 error information that occurred in that service execution.
    This is a very helpful technique for microservices since it inherently changes
    the monitoring from being a push model to a pull model and reduces the overhead
    of service monitoring. We can scrap data from these endpoints at a certain time
    interval and build a dashboard and collect data for operational metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logging is a type of instrumentation made available by the system, its various
    components, or the infrastructure layer. In this section, we will first visit
    logging challenges and then discuss strategies to reach a solution for these challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Logging challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will first try to understand the problem with log management in microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: To log the information related to a system event and parameter as well as the
    infrastructure state, we will need to persist log files. In traditional .NET monoliths,
    log files are kept on the same machine where the application is deployed. In the case
    of microservices, they are hosted either on virtual machines or containers. But
    virtual machines and containers are both ephemeral, which means they do not persist
    states. In this situation, if we persist log files with virtual machines or containers,
    we will lose them. This is one of the challenges of log management in microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the microservice architecture, there are a number of services that constitute
    a transaction. Let's assume we have an order placement transaction where service
    A, service B, and service C take part in the transaction. If, say, service B fails
    during the transaction, how are we going to understand and capture this failure
    in the logs? Not only that but more importantly, how are we going to understand
    that a specific instance of service B has failed and it was taking part in a said
    transaction? This scenario presents another challenge to microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this section, we have discussed logging, its challenges, and why we
    should implement logging. Multiple calls at the same time are possible so when
    we implement logging, we should implement it in such a way that we know the exact
    source of the logged transaction. We would go with correlation ID for logging.
  prefs: []
  type: TYPE_NORMAL
- en: Logging is not related to microservices specifically; it is also important for
    monolithic applications.
  prefs: []
  type: TYPE_NORMAL
- en: To implement logging in microservices, we can use the keylogging strategies
    discussed in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Centralized logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is a difference between centralized logging and centralized monitoring.
    In centralized logging, we log all the details about the events that occur in
    our system—they may be errors or warnings or just for informational purposes—whereas
    in centralized monitoring, we monitor critical parameters, that is, specific information.
  prefs: []
  type: TYPE_NORMAL
- en: With logs, we can understand what has actually happened in the system or a specific
    transaction. We will have all the details about the specific transaction, such
    as why it started, who triggered it, what kind of data or resources it recorded,
    and so on. In a complex distributed system, such as microservices, this is really
    the key piece of information with which we can solve the entire puzzle of information
    flow or errors. We also need to treat timeouts, exceptions, and errors as events
    that we need to log.
  prefs: []
  type: TYPE_NORMAL
- en: The information we record regarding a specific event should also be structured,
    and this structure should be consistent across our system. So, for example, our
    structured log entry might contain level-based information to state whether the
    log entry is for information, an error, or whether it's debugged information or
    statistics that have been recorded as log entry events. The structured log entry
    must also have a date and time so we know when the event happened. We should also
    include the hostname within our structured log so that we know where exactly the
    log entry came from. We should also include the service name and the service instance
    so we know exactly which microservice made the log entry.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we should also include a message in our structured logging format,
    which is the key piece of information associated with the event. So, for example,
    for an error, this might be the call stack or details regarding the exception.
    The key thing is that we keep our structured logging format consistent. A consistent
    format will allow us to query the logging information. Then, we can basically
    search for specific patterns and issues using our centralized logging tool. Another
    key aspect of centralized logging within a microservice architecture is to make
    distributed transactions more traceable.
  prefs: []
  type: TYPE_NORMAL
- en: Using a correlation ID in logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A correlation ID is a unique ID that is assigned to every transaction. So, when
    a transaction becomes distributed across multiple services, we can follow that
    transaction across different services using the logging information. The correlation
    ID is basically passed from service to service. All services that process that
    specific transaction receive the correlation ID and pass it to the next service,
    and so on, so that they can log any events associated with that transaction to
    our centralized logs. This helps us hugely when we have to visualize and understand
    what has happened with this transaction across different microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic logging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Event Tracing for Windows** (**ETW**) is a structural logging mechanism where
    you can store a structured payload with the log entry. This information is generated
    by event listeners and may include typed metadata about the event. This is merely
    an example of semantic logging. Semantic logging passes additional data along
    with the log entry so that the processing system can get the context structured
    around the event. Hence, semantic logging is also referred to as structured logging
    or typed logging.'
  prefs: []
  type: TYPE_NORMAL
- en: For more information, refer to [https://docs.microsoft.com/en-us/windows-hardware/drivers/devtest/event-tracing-for-windows--etw-](https://docs.microsoft.com/en-us/windows-hardware/drivers/devtest/event-tracing-for-windows--etw-)
  prefs: []
  type: TYPE_NORMAL
- en: As an example, an event that indicates an order was placed can generate a log
    entry that contains the number of items as an integer value, the total value as
    a decimal number, the customer identifier as a long value, and the city for delivery
    as a string value. An order monitoring system can read the payload and easily
    extract the individual values. ETW is the standard, shipped feature with Windows.
  prefs: []
  type: TYPE_NORMAL
- en: In Azure Cloud, it is possible to get your log data source from ETW. The Semantic
    Logging Application Block developed by Microsoft's patterns and practices team
    is an example of a framework that makes comprehensive logging easier. When you
    write events to the custom event source, the Semantic Logging Application Block
    detects this and allows you to write the event to other logging destinations,
    such as a disk file, database, email message, and more. You can use the Semantic
    Logging Application Block in Azure applications that are written in .NET and run
    on Azure websites, cloud services, and virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring in Azure Cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is no single, off-the-shelf solution or offering in Azure, or for that
    matter any cloud provider, to the monitoring challenges presented by microservices.
    Interestingly enough, there are not too many open source tools available that
    can work with .NET-based microservices.
  prefs: []
  type: TYPE_NORMAL
- en: We are utilizing Microsoft Azure Cloud and cloud services for building our microservices,
    so it is useful to look for the monitoring capability it comes with. If you are
    looking to manage approximately a couple of hundred microservices, you can utilize
    a custom monitoring solution (mostly interweaving PowerShell scripts) based on
    a Microsoft Azure-based solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be primarily focusing on the following logging and monitoring solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Microsoft Azure Diagnostics: This helps in collecting and analyzing resources
    through resource and activity logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Application Insights: This helps in collecting all of the telemetry data about
    our microservices and analyzing them. This is a framework-based approach for monitoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Log Analytics: Log Analytics analyzes and displays data and provides scalable
    querying capability over collected logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at these solutions from a different perspective. This perspective
    will help us visualize our Azure-based microservice monitoring solution. A microservice
    is composed of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Infrastructure layer: A virtual machine or an application container (for example,
    Docker container)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Application stack layer: Constitutes the operating system, .NET CLR, and the
    microservice application code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of these layer components can be monitored as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Virtual machine: Using Azure Diagnostics Logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker containers: Using container logs and Application Insights or a third-party
    container monitoring solution, such as cAdvisor, Prometheus, or Sensu'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Windows operating system: Using Azure Diagnostics Logs and Activity Logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A microservice application: Using Application Insights'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data visualization and metric monitoring: Using Log Analytics or third-party
    solutions, such as Splunk or ELK stack'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Various Azure services come with an activity ID in their log entries. This activity
    ID is a unique GUID assigned for each request, which can be utilized as a correlation
    ID during log analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure Diagnostics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure diagnostics logs give us the ability to collect diagnostic data for a
    deployed microservice. We can also use a diagnostic extension to collect data
    from various sources. Azure Diagnostics is supported by web and worker roles,
    Azure virtual machines, and all Azure App services. Other Azure services have
    their own separate diagnostics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enabling Azure diagnostics logs and exploring various settings in the Azure
    app service is easy and available as a toggle switch, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c18c643-fb74-4a97-a371-5427ddef4ec5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Azure diagnostics can collect data from the following sources:'
  prefs: []
  type: TYPE_NORMAL
- en: Performance counters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows event logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: .NET event sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IIS logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manifest-based ETW
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Crash dumps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom error logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure diagnostic infrastructure logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storing diagnostic data using Azure storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure diagnostics logs are not permanently stored. They are rollover logs, that
    is, they are overwritten by newer ones. So, if we want to use them for any analysis
    work, we have to store them. Azure diagnostics logs can be either stored in a file
    system or transferred via FTP; better still, it can be stored in an Azure storage
    container.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different ways to specify an Azure storage container for diagnostics
    data for the specified Azure resource (in our case, microservices hosted on the
    Azure app service). These are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: CLI tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PowerShell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Resource Manager
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual Studio 2017 with Azure SDK 2.9 or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure portal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Azure portal
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following screenshot depicts the Azure storage container provisioned through
    the Azure portal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/be4d9ee8-fc83-4d1a-845c-02b930ab472b.png)'
  prefs: []
  type: TYPE_IMG
- en: Specifying a storage account
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another way to specify the storage account for storing application-specific
    diagnostic data is by specifying the storage account in the `ServiceConfiguration.cscfg`
    file. This is also convenient as during development time itself, you can specify
    the storage account. It is also possible to specify an altogether different storage
    account during development and production. The Azure storage account might also
    be configured as one of the dynamic environment variables during the deployment
    process.
  prefs: []
  type: TYPE_NORMAL
- en: 'The account information is defined as a connection string in a configuration
    setting. The following example shows the default connection string created for
    a new microservice project in Visual Studio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can change this connection string to provide account information for an
    Azure storage account.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's see how Azure storage stores the diagnostic data. All the log entries
    are stored in either a blob or table storage container. The storage choice can
    be specified while we create and associate the Azure storage container.
  prefs: []
  type: TYPE_NORMAL
- en: Azure storage schema for diagnostic data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The structure of Azure table storage for storing diagnostic data is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the storage is in the form of tables, we will see the following tables schema:'
  prefs: []
  type: TYPE_NORMAL
- en: WadLogsTable: This table stores the log statements written during code execution,
    using the trace listener.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WADDiagnosticInfrastructureLogsTable: This table specifies the diagnostic monitor
    and configuration changes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WADDirectoriesTable: This table includes the directories that the diagnostic
    monitor is monitoring. This includes IIS logs, IIS-failed request logs, and custom
    directories. The location of the blob log file is specified in the container field
    and the name of the blob is in the RelativePath field. The AbsolutePath field
    indicates the location and the name of the file as it existed on the Azure virtual
    machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WADPerformanceCountersTable: This table contains data related to the configured
    performance counters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WADWindowsEventLogsTable: This table contains Windows' event tracing log entries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a blob storage container, the diagnostic storage schema is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'wad-control-container: This is only for SDK 2.4 and previous versions. It contains
    the XML configuration files that control Azure diagnostics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: wad-iis-failedreqlogfiles: This contains information from the IIS-failed request
    logs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: wad-iis-logfiles: This contains information about IIS logs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: custom: This is a custom container based on the configuring directories that
    are monitored by the diagnostic monitor. The name of this blob container will
    be specified in WADDirectoriesTable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An interesting fact to note here is that the WAD suffix, which can be seen on
    these container tables or blobs, comes from Microsoft Azure Diagnostics's previous
    product name, which is Windows Azure Diagnostics.
  prefs: []
  type: TYPE_NORMAL
- en: You can use *Cloud Explorer* from Visual Studio to explore the stored Azure
    diagnostics data.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction of Application Insights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Application Insights is an **application performance management** (**APM**)
    offering from Microsoft. It is a useful service offering for monitoring the performance
    of .NET-based microservices. It is useful for understanding the internal, operational
    behavior of individual microservices. Instead of just focusing on detecting and
    diagnosing issues, it will tune the service performance and understand the performance
    characteristics of your microservice. It is an example of the framework-based
    approach to monitoring. What that means is that during the development of a microservice,
    we will add the Application Insights package to the Visual Studio solution of
    our microservice. This is how Application Insights instruments your microservice
    for telemetry data. This might not always be an ideal approach for every microservice;
    however, it comes in handy if you have not given any good, thorough thought to
    monitoring your microservices. This way, monitoring comes out-of-the-box with
    your service.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the help of Application Insights, you can collect and analyze the following
    types of telemetry data types:'
  prefs: []
  type: TYPE_NORMAL
- en: HTTP request rates, response times, and success rates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependency (HTTP and SQL) call rates, response times, and success rates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exception traces from both server and client
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diagnostic log traces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Page view counts, user and session counts, browser load times, and exceptions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AJAX call rates, response times, and success rates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server performance counters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom client and server telemetry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Segmentation by client location, browser version, OS version, server instance,
    custom dimensions, and more
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Availability tests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Along with the preceding types, there are associated diagnostic and analytics
    tools available for alerting and monitoring with various different customizable
    metrics. With its own query language and customizable dashboards, Application
    Insights forms a good monitoring solution for .NET microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Other microservice monitoring solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let's look at some of the popular monitoring solutions that can be used
    to build a custom microservice monitoring solution. Obviously, these solutions
    do not come out of-the-box; however, they are definitely time-tested by the open
    source community and can be easily integrated within .NET-based environments.
  prefs: []
  type: TYPE_NORMAL
- en: A brief overview of the ELK stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw, one of the fundamental tools for monitoring is logging. For microservices,
    there will be an astounding number of logs generated that are sometimes not even
    comprehensible to humans. The ELK stack (also referred to as the elastic stack)
    is the most popular log management platform. It is also a good candidate for microservice
    monitoring because of its ability to aggregate, analyze, visualize, and monitor.
    The ELK stack is a toolchain that includes three distinct tools, namely Elasticsearch,
    Logstash, and Kibana. Let's look at them one by one to understand their role in
    the ELK stack.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Elasticsearch is a full-text search engine based on the Apache Lucene library.
    The project is open source and developed in Java. Elasticsearch supports horizontal
    scaling, multitenancy, and clustering approaches. The fundamental element of Elasticsearch
    is its search index. This index is stored in forms of JSON internally. A single
    Elasticsearch server stores multiple indexes (each index represents a database),
    and a single query can search data with multiple indexes.
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch can really provide near real-time searches and can scale with
    very low latency. The search and results programming model is exposed through
    the Elasticsearch API and available over HTTP.
  prefs: []
  type: TYPE_NORMAL
- en: Logstash
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logstash plays the role of a log aggregator in the ELK stack. It is a log aggregation
    engine that collects, parses, processes, and persists the log entries in its persistent
    store. Logstash is extensive due to its data-pipeline-based architecture pattern.
    It is deployed as an agent, and it sends the output to Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: Kibana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kibana is an open source data visualization solution. It is designed to work
    with Elasticsearch. You use Kibana to search, view, and interact with the data
    stored in the Elasticsearch indices.
  prefs: []
  type: TYPE_NORMAL
- en: It is a browser-based web application that lets you perform advanced data analysis
    and visualize your data in a variety of charts, tables, and maps. Moreover, it
    is a zero-configuration application. Therefore, it neither needs any coding nor
    additional infrastructure after the installation.
  prefs: []
  type: TYPE_NORMAL
- en: Splunk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Splunk is one of the best commercial log management solutions. It can handle
    terabytes of log data very easily. Over time, it has added many additional capabilities
    and is now recognized as a full-fledged leading platform for operational intelligence.
    Splunk is used to monitor numerous applications and environments.
  prefs: []
  type: TYPE_NORMAL
- en: It plays a vital role in monitoring any infrastructure and application in real
    time and is essential for identifying issues, problems, and attacks before they
    impact customers, services, and profitability. Splunk's monitoring abilities,
    specific patterns, trends and thresholds, and so on can be established as events
    for Splunk to look out for. This is so that specific individuals don't have to
    do this manually.
  prefs: []
  type: TYPE_NORMAL
- en: Splunk has an alerting capability included in its platform. It can trigger alert
    notifications in real time so that appropriate action can be taken to avoid application
    or infrastructure downtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on a trigger of alert and action configured, Splunk can:'
  prefs: []
  type: TYPE_NORMAL
- en: Send an email
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execute a script or trigger a runbook
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create an organizational support or action ticket
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Typically, Splunk monitoring marks might include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Application logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Active Directory changes event data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows event logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows performance logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WMI-based data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Windows registry information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data from specific files and directories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance monitoring data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scripted input to get data from the APIs and other remote data interfaces and
    message queues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As with any monitoring solution, Splunk also has alert functionalities. It can
    be configured to set an alert based on any real-time or historical search patterns.
    These alert queries can be run periodically and automatically, and alerts can
    be triggered by the results of these real-time or historical queries.
  prefs: []
  type: TYPE_NORMAL
- en: You can base your Splunk alerts on a wide range of threshold-and trend-based
    situations, such as conditions, critical server or application errors, or threshold
    amounts of resource utilization.
  prefs: []
  type: TYPE_NORMAL
- en: Reporting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Splunk can report on alerts that have been triggered and executed as well as
    if they meet certain conditions. Splunk's alert manager can be used to create
    a report based on the preceding alert data.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Debugging and monitoring of microservices is not simple; it''s a challenging
    problem. We have used the word *challenging* on purpose: there is no silver bullet
    for this. There is no single tool that you can install that works like magic.
    However, with Azure Diagnostics and Application Insights, or with ELK stack or
    Splunk, you can come up with solutions that will help you solve microservice monitoring
    challenges. Implementing microservice monitoring strategies, such as application/system
    monitoring, real user monitoring, synthetic transactions, centralized logging,
    semantic logging block, and implementation of correlation ID throughout transactional
    HTTP requests, is a helpful way to monitor microservice implementations.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how we can scale microservices, and the solutions
    and strategies for scaling microservice solutions.
  prefs: []
  type: TYPE_NORMAL
