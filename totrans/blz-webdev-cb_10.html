<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-350">
    <a id="_idTextAnchor350">
    </a>
    
     10
    
   </h1>
   <h1 id="_idParaDest-351">
    <a id="_idTextAnchor351">
    </a>
    
     Integrating with OpenAI
    
   </h1>
   <p>
    
     In this chapter, we will explore how to integrate advanced AI capabilities into your applications using OpenAI’s powerful language models.
    
    
     You will learn to set up the Azure OpenAI service and deploy models, laying the foundation for integrating AI into your applications.
    
    
     By implementing AI-enhanced features in web applications, such as smart-pasting and smart text areas, you will enhance the user experience with intelligent data processing and content generation.
    
    
     Additionally, you’ll build and integrate a ChatGPT-like chatbot for interactive AI-driven conversations.
    
    
     Finally, you will enable seamless data analysis by connecting your Azure OpenAI service to an existing Azure Search service
    
    
     
      data index.
     
    
   </p>
   <p>
    
     Before we dive into recipes, it’s crucial to highlight the ethical implications of using AI models, particularly concerning user data.
    
    
     In some cases, by using and deploying AI models, you consent to training those models on your application content.
    
    
     You must be vigilant about the privacy and security of your users’ data and implement clear warnings and acceptance forms within your applications, allowing users to consent to or opt out of data sharing.
    
    
     By prioritizing transparency and user autonomy, you safeguard user trust and adhere to responsible
    
    
     
      AI practices.
     
    
   </p>
   <p>
    
     Here are the recipes we will cover in
    
    
     
      this chapter:
     
    
   </p>
   <ul>
    <li>
     
      Setting up an Azure
     
     
      
       OpenAI service
      
     
    </li>
    <li>
     
      Implementing
     
     
      
       smart pasting
      
     
    </li>
    <li>
     
      Implementing a smart
     
     
      
       text area
      
     
    </li>
    <li>
     
      Adding
     
     
      
       a ChatBot
      
     
    </li>
    <li>
     
      Connecting an Azure OpenAI service to an existing
     
     
      
       data index
      
     
    </li>
   </ul>
   <h1 id="_idParaDest-352">
    <a id="_idTextAnchor352">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     In this chapter, we will rely heavily on the Azure services and a few NuGet packages that may still be in preview when you install them.
    
    
     You will find all the details and warnings described in detail in each of the impacted recipes, so you have nothing to worry about.
    
    
     Before you dive in, make sure you have
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      An active Azure account with access to the Azure Portal (if you don’t have one yet, you can start with a time-limited, free account
     
     
      
       at
      
     
     <a href="https://azure.microsoft.com/en-us/free">
      
       
        https://azure.microsoft.com/en-us/free
       
      
     </a>
     
      
       )
      
     
    </li>
    <li>
     
      A pre-created resource group
     
     
      
       in Azure
      
     
    </li>
    <li>
     
      A pre-installed Npm package manager, with globally available
     
     
      <strong class="source-inline">
       
        npm
       
      </strong>
     
     
      
       command
      
     
    </li>
    <li>
     
      A Blazor Web App project with per component/page
     
     
      
       render modes
      
     
    </li>
   </ul>
   <p>
    
     You can find all the code examples (and data samples) from the following recipes in a dedicated GitHub repository at
    
    <a href="https://github.com/PacktPublishing/Blazor-Web-Development-Cookbook/tree/main">
     
      https://github.com/PacktPublishing/Blazor-Web-Development-Cookbook/tree/main
     
    </a>
    
     .
    
    
     Just be aware that we will implement some recipes only on the server side – you’ll understand why as you read through
    
    
     
      the chapter.
     
    
   </p>
   <h1 id="_idParaDest-353">
    <a id="_idTextAnchor353">
    </a>
    
     Setting up an Azure OpenAI service
    
   </h1>
   <p>
    
     Azure OpenAI Service is
    
    <a id="_idIndexMarker479">
    </a>
    
     a cloud-based offering from Microsoft Azure that provides access to OpenAI’s powerful language models.
    
    
     A
    
    <strong class="bold">
     
      large language model
     
    </strong>
    
     (
    
    <strong class="bold">
     
      LLM
     
    </strong>
    
     ) is an optimized
    
    <a id="_idIndexMarker480">
    </a>
    
     cost-function, trained on human texts, that can generate human-like text, allowing you to take chatbots, content generation, or language translation to the next level.
    
    
     By leveraging the Azure OpenAI service, you can integrate advanced AI capabilities into your Blazor application without managing the underlying infrastructure.
    
    
     You’re also getting access to existing
    
    
     
      GPT models.
     
    
   </p>
   <p>
    
     Let’s set up an Azure OpenAI service in the Azure cloud using the Azure portal, deploy a dedicated GPT-4 model, and locate access details required for integration on the
    
    
     
      application side.
     
    
   </p>
   <h2 id="_idParaDest-354">
    <a id="_idTextAnchor354">
    </a>
    
     Getting ready
    
   </h2>
   <p>
    
     In this recipe, we won’t write any code just yet; instead, we will focus on setting up the Azure OpenAI service.
    
    
     To get started, here are
    
    
     
      some prerequisites:
     
    
   </p>
   <ul>
    <li>
     
      You will need an Azure account and access to the
     
     
      
       Azure Portal
      
     
    </li>
    <li>
     
      You should create a resource group beforehand; we will use one named
     
     <strong class="source-inline">
      
       blazor-cookbook
      
     </strong>
     
      dedicated to
     
     
      
       this chapter
      
     
    </li>
   </ul>
   <p>
    
     At the time of writing, the process of setting up the Azure OpenAI service consists of
    
    
     
      two phases.
     
    
   </p>
   <ol>
    <li>
     
      In the first phase, do
     
     
      
       the following:
      
     
     <ol>
      <li class="upper-roman">
       
        You must complete a request form to gain access to the Azure OpenAI service.
       
       
        To find the request form, follow the first two steps outlined in the
       
       <em class="italic">
        
         How to do it
        
       </em>
       
        section
       
       
        
         that follows.
        
       
      </li>
      <li class="upper-roman">
       
        After submitting the form, you will need to wait for approval from the
       
       <strong class="bold">
        
         Azure Cognitive Services team
        
       </strong>
       
        .
       
       
        You will receive a confirmation email once your
       
       <a id="_idIndexMarker481">
       </a>
       
        request has been approved, marking the end of the
       
       
        
         first phase.
        
       
      </li>
     </ol>
    </li>
    <li>
     
      We will walk through the second phase in the
     
     <em class="italic">
      
       How to do
      
     </em>
     
      <em class="italic">
       
        it
       
      </em>
     
     
      
       section.
      
     
    </li>
   </ol>
   <h2 id="_idParaDest-355">
    <a id="_idTextAnchor355">
    </a>
    
     How to do it…
    
   </h2>
   <p>
    
     Follow these steps to
    
    <a id="_idIndexMarker482">
    </a>
    
     add the Azure OpenAI service to your
    
    
     
      Azure resources:
     
    
   </p>
   <ol>
    <li>
     
      Open your resource group in Azure Portal and navigate to the Azure Marketplace by clicking the
     
     <strong class="bold">
      
       Create
      
     </strong>
     
      button in the top
     
     
      
       navigation bar.
      
     
    </li>
   </ol>
   <div><div><img alt="Figure 10.1: Navigating to Azure Marketplace from the resource group overview" src="img/B22020_10_1.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.1: Navigating to Azure Marketplace from the resource group overview
    
   </p>
   <ol>
    <li value="2">
     
      In the Azure Marketplace, use the search bar in the top panel to find the
     
     <strong class="bold">
      
       Azure OpenAI
      
     </strong>
     
      service and start the creation process by clicking the
     
     <strong class="bold">
      
       Create
      
     </strong>
     
      button on the
     
     
      
       resulting tab.
      
     
    </li>
   </ol>
   <div><div><img alt="Figure 10.2: Navigating to the Azure OpenAI service creation panel" src="img/B22020_10_2.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.2: Navigating to the Azure OpenAI service creation panel
    
   </p>
   <ol>
    <li value="3">
     
      In the
     
     <strong class="bold">
      
       Create Azure OpenAI
      
     </strong>
     
      panel, provide the necessary details to create an Azure
     
     <a id="_idIndexMarker483">
     </a>
     
      
       OpenAI instance:
      
     
     <ol>
      <li class="Alphabets">
       
        Select the subscription for the service in the
       
       
        <strong class="bold">
         
          Subscription
         
        </strong>
       
       
        
         field.
        
       
      </li>
      <li class="Alphabets">
       
        Select the resource group where you want to create the service in the
       
       <strong class="bold">
        
         Resource
        
       </strong>
       
        <strong class="bold">
         
          Group
         
        </strong>
       
       
        
         field.
        
       
      </li>
      <li class="Alphabets">
       
        Select the hosting region in the
       
       
        <strong class="bold">
         
          Region
         
        </strong>
       
       
        
         field.
        
       
      </li>
      <li class="Alphabets">
       
        Provide a unique name for the service in the
       
       
        <strong class="bold">
         
          Name
         
        </strong>
       
       
        
         field.
        
       
      </li>
      <li class="Alphabets">
       
        Select the pricing plan in the
       
       <strong class="bold">
        
         Pricing
        
       </strong>
       
        <strong class="bold">
         
          tier
         
        </strong>
       
       
        
         field.
        
       
      </li>
     </ol>
    </li>
   </ol>
   <div><div><img alt="Figure 10.3: First step of the Azure OpenAI service creation process – defining instance details" src="img/B22020_10_3.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.3: First step of the Azure OpenAI service creation process – defining instance details
    
   </p>
   <p class="list-inset">
    
     After reviewing
    
    <a id="_idIndexMarker484">
    </a>
    
     the terms and conditions, click
    
    <strong class="bold">
     
      Next
     
    </strong>
    
     
      to proceed.
     
    
   </p>
   <ol>
    <li value="4">
     
      In the
     
     <strong class="bold">
      
       Network
      
     </strong>
     
      step, select the network availability for the service that best suits your needs and confirm by
     
     
      
       clicking
      
     
     
      <strong class="bold">
       
        Next
       
      </strong>
     
     
      
       .
      
     
    </li>
   </ol>
   <div><div><img alt="Figure 10.4: Second step of the Azure OpenAI service creation process – configuring network" src="img/B22020_10_4.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.4: Second step of the Azure OpenAI service creation process – configuring network
    
   </p>
   <ol>
    <li value="5">
     
      Leave the
     
     <strong class="bold">
      
       Tags
      
     </strong>
     
      step
     
     <a id="_idIndexMarker485">
     </a>
     
      unchanged unless you have tag policies to follow in your organization and proceed by
     
     
      
       clicking
      
     
     
      <strong class="bold">
       
        Next
       
      </strong>
     
     
      
       .
      
     
    </li>
    <li>
     
      In the
     
     <strong class="bold">
      
       Review + submit
      
     </strong>
     
      step, review the service summary and confirm the creation request by clicking the
     
     
      <strong class="bold">
       
        Create
       
      </strong>
     
     
      
       button.
      
     
    </li>
   </ol>
   <div><div><img alt="Figure 10.5: Last step of the Azure OpenAI creation process – reviewing instance details" src="img/B22020_10_5.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.5: Last step of the Azure OpenAI creation process – reviewing instance details
    
   </p>
   <ol>
    <li value="7">
     
      Once the deployment
     
     <a id="_idIndexMarker486">
     </a>
     
      completes, open your resource group overview and select the
     
     <strong class="bold">
      
       Azure
      
     </strong>
     
      <strong class="bold">
       
        OpenAI
       
      </strong>
     
     
      
       service.
      
     
    </li>
   </ol>
   <div><div><img alt="Figure 10.6: Selecting the Azure OpenAI instance from the resource group overview" src="img/B22020_10_6.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.6: Selecting the Azure OpenAI instance from the resource group overview
    
   </p>
   <ol>
    <li value="8">
     
      Find the
     
     <strong class="bold">
      
       Model deployments
      
     </strong>
     
      feature in the
     
     <strong class="bold">
      
       Resource Management
      
     </strong>
     
      section in the left
     
     <a id="_idIndexMarker487">
     </a>
     
      menu.
     
     
      Open the Azure OpenAI Studio by clicking the
     
     <strong class="bold">
      
       Manage
      
     </strong>
     
      <strong class="bold">
       
        deployments
       
      </strong>
     
     
      
       button.
      
     
    </li>
   </ol>
   <div><div><img alt="Figure 10.7: Navigating to Azure OpenAI Studio to manage model deployments" src="img/B22020_10_7.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.7: Navigating to Azure OpenAI Studio to manage model deployments
    
   </p>
   <ol>
    <li value="9">
     
      In the Azure OpenAI Studio, find the
     
     <strong class="bold">
      
       Deployments
      
     </strong>
     
      feature in the
     
     <strong class="bold">
      
       Management
      
     </strong>
     
      section on the left menu and start the deployment process by clicking the
     
     <strong class="bold">
      
       Create new
      
     </strong>
     
      <strong class="bold">
       
        deployment
       
      </strong>
     
     
      
       button.
      
     
    </li>
   </ol>
   <div><div><img alt="Figure 10.8: Initiating model deployment through the Azure OpenAI Studio" src="img/B22020_10_8.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.8: Initiating model deployment through the Azure OpenAI Studio
    
   </p>
   <ol>
    <li value="10">
     
      Fill out
     
     <a id="_idIndexMarker488">
     </a>
     
      the
     
     <strong class="bold">
      
       Deploy model
      
     </strong>
     
      form with the details of the model you intend
     
     
      
       to use:
      
     
     <ol>
      <li class="Alphabets">
       
        Name the deployment in the
       
       <strong class="bold">
        
         Deployment
        
       </strong>
       
        <strong class="bold">
         
          name
         
        </strong>
       
       
        
         field.
        
       
      </li>
      <li class="Alphabets">
       
        Choose the model you want to deploy from the
       
       <strong class="bold">
        
         Select a
        
       </strong>
       
        <strong class="bold">
         
          model
         
        </strong>
       
       
        
         dropdown.
        
       
      </li>
      <li class="Alphabets">
       
        Select a specific model version or the
       
       <strong class="bold">
        
         Auto-update to default
        
       </strong>
       
        option in the
       
       <strong class="bold">
        
         Model
        
       </strong>
       
        <strong class="bold">
         
          version
         
        </strong>
       
       
        
         dropdown.
        
       
      </li>
      <li class="Alphabets">
       
        Choose the type of deployment in the
       
       <strong class="bold">
        
         Deployment
        
       </strong>
       
        <strong class="bold">
         
          type
         
        </strong>
       
       
        
         dropdown.
        
       
      </li>
     </ol>
    </li>
   </ol>
   <div><div><img alt="Figure 10.9: Filling the model deployment details and deploying the model" src="img/B22020_10_9.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.9: Filling the model deployment details and deploying the model
    
   </p>
   <p class="list-inset">
    
     After filling out
    
    <a id="_idIndexMarker489">
    </a>
    
     all required fields, confirm the deployment by
    
    
     
      clicking
     
    
    
     <strong class="bold">
      
       Create
      
     </strong>
    
    
     
      .
     
    
   </p>
   <h2 id="_idParaDest-356">
    <a id="_idTextAnchor356">
    </a>
    
     How it works…
    
   </h2>
   <p>
    
     In
    
    <em class="italic">
     
      step 1
     
    </em>
    
     , we open the Azure Portal and find the resource group where we want to deploy the Azure OpenAI service.
    
    
     From the top bar of the overview panel, we select the
    
    <strong class="bold">
     
      Create
     
    </strong>
    
     option.
    
    
     Azure will redirect us to the Azure Marketplace, where we can choose the services
    
    
     
      to install.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 2
     
    </em>
    
     , we utilize the search bar at the top of the Azure Marketplace to look for Azure OpenAI.
    
    
     The result tab has a
    
    <strong class="bold">
     
      Create
     
    </strong>
    
     button, which we use to start the
    
    
     
      creation process.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 3
     
    </em>
    
     , we arrive at the first step of the Azure OpenAI creation –
    
    <strong class="bold">
     
      Basics
     
    </strong>
    
     .
    
    
     In this step, we fill out all the basic details of the instance we’re about to create.
    
    
     We choose the Azure subscription to define the owner of the service.
    
    
     Then, we select the appropriate resource group from the list assigned to the subscription.
    
    
     Next, we define the instance details, such as the hosting region and pricing tier.
    
    
     Be careful, as different areas have different AI models available.
    
    
     Also, depending on the pricing tier you select, you may incur service usage costs.
    
    
     To avoid that, opt for a free pricing tier (it has restricted scalability and request limits but will be enough for the recipes in this chapter).
    
    
     You can review the availability and pricing details by clicking the
    
    <strong class="bold">
     
      View full pricing details
     
    </strong>
    
     link.
    
    
     Then, we provide the instance name and a pricing tier.
    
    
     Once we have filled in all required fields, we move to the next step by
    
    
     
      clicking
     
    
    
     <strong class="bold">
      
       Next
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 4
     
    </em>
    
     , we arrive at the
    
    <strong class="bold">
     
      Network
     
    </strong>
    
     step of the Azure OpenAI creation.
    
    
     In the
    
    <strong class="bold">
     
      Network
     
    </strong>
    
     tab, we define the discoverability of the service.
    
    
     We can disable network access entirely, configure private endpoints, set up network security within Azure, or make the instance publicly accessible.
    
    
     To keep it simple, we allow the instance access from any network, including the internet, and confirm by clicking
    
    <strong class="bold">
     
      Next
     
    </strong>
    
     
      to proceed.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 5
     
    </em>
    
     , we arrive
    
    <a id="_idIndexMarker490">
    </a>
    
     at the
    
    <strong class="bold">
     
      Tags
     
    </strong>
    
     step of the Azure OpenAI creation.
    
    
     The
    
    <strong class="bold">
     
      Tags
     
    </strong>
    
     tab allows defining custom tags describing services.
    
    
     Unless you have tag-based policies defined in your organization, tags won’t have any functional impact.
    
    
     Hence, we leave the
    
    <strong class="bold">
     
      Tags
     
    </strong>
    
     panel unchanged and proceed to the last step by
    
    
     
      clicking
     
    
    
     <strong class="bold">
      
       Next
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 6
     
    </em>
    
     , we arrive at the
    
    <strong class="bold">
     
      Review + submit
     
    </strong>
    
     panel, where we get the last chance to review the details of the instance we’re about to create.
    
    
     When everything checks out, we confirm the creation by
    
    
     
      clicking
     
    
    
     <strong class="bold">
      
       Create
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     It will take some time for the service deployment to complete.
    
    
     When completed, we proceed to
    
    <em class="italic">
     
      step 7
     
    </em>
    
     .
    
    
     We navigate to the overview panel of the resource group and select the Azure
    
    
     
      OpenAI instance.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 8
     
    </em>
    
     , we find the
    
    <strong class="bold">
     
      Resource Management
     
    </strong>
    
     submenu and navigate to the
    
    <strong class="bold">
     
      Model deployments
     
    </strong>
    
     feature.
    
    
     In that panel, we click the
    
    <strong class="bold">
     
      Manage Deployments
     
    </strong>
    
     button and get redirected to the Azure OpenAI Studio for
    
    
     
      further steps.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 9
     
    </em>
    
     , in the Azure OpenAI Studio, we find the
    
    <strong class="bold">
     
      Management
     
    </strong>
    
     submenu and navigate to the
    
    <strong class="bold">
     
      Deployments
     
    </strong>
    
     panel.
    
    
     In the
    
    <strong class="bold">
     
      Deployments
     
    </strong>
    
     navigation bar, we click the
    
    <strong class="bold">
     
      Create new deployment
     
    </strong>
    
     button to initialize a model deployment for the Azure
    
    
     
      OpenAI service.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 10
     
    </em>
    
     , we arrive at the
    
    <strong class="bold">
     
      Deploy model
     
    </strong>
    
     submission form, where we must configure the deployment details.
    
    
     First, we define the deployment name – we will later use that name to specify which model to use for executing requests from the Blazor app.
    
    
     Next, we choose the model to deploy.
    
    
     Depending on the region where the Azure OpenAI instance is hosted, we can choose from a different set of AI models provided by Azure.
    
    
     To keep it simple, we opt to deploy GPT-4o.
    
    
     After choosing the model, we specify the version to use.
    
    
     From the dropdown, we can select a specific GPT model version or choose
    
    <strong class="bold">
     
      Auto-update to default
     
    </strong>
    
     to use the latest stable model.
    
    
     In the deployment form, we can fine-tune a rate limit for requests and a content filter, which we leave at default values.
    
    
     We can also enable
    
    <strong class="bold">
     
      Dynamic quota
     
    </strong>
    
     , allowing Azure to automatically scale up the
    
    <a id="_idIndexMarker491">
    </a>
    
     tokens per minute limit when there’s higher traffic.
    
    
     When we have filled in all deployment details, we can start the process by
    
    
     
      clicking
     
    
    
     <strong class="bold">
      
       Create
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     When the deployment completes, you’ll see the model in the
    
    <strong class="bold">
     
      Deployments
     
    </strong>
    
     panel of Azure
    
    
     
      OpenAI Studio:
     
    
   </p>
   <div><div><img alt="Figure 10.10: Azure OpenAI model deployments overview, showing the deployed model" src="img/B22020_10_10.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.10: Azure OpenAI model deployments overview, showing the deployed model
    
   </p>
   <h2 id="_idParaDest-357">
    <a id="_idTextAnchor357">
    </a>
    
     There’s more…
    
   </h2>
   <p>
    
     To communicate with the Azure OpenAI instance and the deployed AI model, you will need the model deployment name (which we set in
    
    <em class="italic">
     
      step 10
     
    </em>
    
     ) and the Azure OpenAI API
    
    
     
      access details.
     
    
   </p>
   <p>
    
     To find those details, navigate to the resource group and the created Azure OpenAI instance.
    
    
     In the menu on the left, select the
    
    <strong class="bold">
     
      Keys and Endpoint
     
    </strong>
    
     item in the
    
    <strong class="bold">
     
      Resource
     
    </strong>
    
     <strong class="bold">
      
       Management
      
     </strong>
    
    
     
      section.
     
    
   </p>
   <div><div><img alt="Figure 10.11: Navigating to the panel with the Azure OpenAI instance API access details" src="img/B22020_10_11.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.11: Navigating to the panel with the Azure OpenAI instance API access details
    
   </p>
   <p>
    
     You’ll arrive at the
    
    <a id="_idIndexMarker492">
    </a>
    
     API details panel, which includes the
    
    <strong class="bold">
     
      Endpoint
     
    </strong>
    
     pointing to the Azure OpenAI instance, the location where it’s hosted, and two API keys.
    
    
     Having two API keys ensures continuous service availability when you need to regenerate one
    
    
     
      of them.
     
    
   </p>
   <div><div><img alt="Figure 10.12: API access details panel, with API keys and URI" src="img/B22020_10_12.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.12: API access details panel, with API keys and URI
    
   </p>
   <p>
    
     You will need the endpoint, API key, and deployed model name for all the upcoming recipes, so store them securely in your secrets storage or keep them handy in a notepad for quick access as
    
    <a id="_idIndexMarker493">
    </a>
    
     we proceed through
    
    
     
      the implementations.
     
    
   </p>
   <h2 id="_idParaDest-358">
    <a id="_idTextAnchor358">
    </a>
    
     See also
    
   </h2>
   <p>
    
     We’ve only touched on the Azure OpenAI service, covering the scope required to integrate OpenAI into a Blazor application.
    
    
     If you’d like to learn more, access the Microsoft Learn
    
    
     
      resource here:
     
    
   </p>
   <p>
    <a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/overview ">
     
      
       https://learn.microsoft.com/en-us/azure/ai-services/openai/overview
      
     
    </a>
   </p>
   <h1 id="_idParaDest-359">
    <a id="_idTextAnchor359">
    </a>
    
     Implementing smart pasting
    
   </h1>
   <p>
    
     One common
    
    <a id="_idIndexMarker494">
    </a>
    
     challenge in web development is dealing with unstandardized data, such as when you receive an email or other data that needs to be accurately input into a claim form.
    
    
     This task can quickly become tedious and frustrating, as manually copying and pasting data into the correct fields is time-consuming and prone
    
    
     
      to errors.
     
    
   </p>
   <p>
    
     The
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     repository is an open-source repository with components enabling you to add AI-driven features to your .NET applications quickly and without an in-depth knowledge of prompt engineering.
    
    
     Among other features,
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     can enhance the pasting of the unstructured data to fit the expected form.
    
    
     Even though
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     is not in the
    
    <strong class="source-inline">
     
      Microsoft
     
    </strong>
    
     namespace, it is under the official .NET Platform GitHub account and is fully endorsed, developed, and maintained by the
    
    
     
      Microsoft Team.
     
    
   </p>
   <p>
    
     Let’s implement a smart-pasting feature allowing users to paste copied text directly into designated fields without
    
    
     
      any preprocessing.
     
    
   </p>
   <h2 id="_idParaDest-360">
    <a id="_idTextAnchor360">
    </a>
    
     Getting ready
    
   </h2>
   <p>
    
     Before we dive into making the pasting smarter, do
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      Create a
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Recipe02
      
     </strong>
     
      directory – this will be your
     
     
      
       working directory
      
     
    </li>
    <li>
     
      Copy the
     
     <strong class="source-inline">
      
       Models
      
     </strong>
     
      file from the
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Data
      
     </strong>
     
      directory in the GitHub repository to the
     
     
      
       working directory
      
     
    </li>
    <li>
     
      Copy the
     
     <strong class="source-inline">
      
       SmartComponents
      
     </strong>
     
      folder from the GitHub repository to your solution folder, and add all projects inside to your solution.
     
     
      The
     
     <strong class="source-inline">
      
       SmartComponents
      
     </strong>
     
      folder contains a clone of the
     
     <strong class="source-inline">
      
       SmartComponents
      
     </strong>
     
      repository, updated to support the latest Azure
     
     
      
       OpenAI updates
      
     
    </li>
    <li>
     
      Have the Azure OpenAI details ready (you can see how to get them in the
     
     <em class="italic">
      
       There’s more…
      
     </em>
     
      section of the
     
     <em class="italic">
      
       Setting up Azure OpenAI
      
     </em>
     
      <em class="italic">
       
        service
       
      </em>
     
     
      
       recipe)
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-361">
    <a id="_idTextAnchor361">
    </a>
    
     How to do it…
    
   </h2>
   <p>
    
     Follow these instructions to enhance pasting in your application
    
    
     
      with AI:
     
    
   </p>
   <ol>
    <li>
     
      Navigate to
     
     <a id="_idIndexMarker495">
     </a>
     
      the
     
     <strong class="source-inline">
      
       csproj
      
     </strong>
     
      file of the server-side project and include two required
     
     
      <strong class="source-inline">
       
        SmartComponents
       
      </strong>
     
     
      
       projects:
      
     
     <pre class="source-code">
&lt;ItemGroup&gt;
  &lt;ProjectReference
    Include= "..\SmartComponents\
    SmartComponents.AspNetCore\
    SmartComponents.AspNetCore.csproj" /&gt;
  &lt;ProjectReference
    Include= "..\SmartComponents\
    SmartComponents.Inference.OpenAI\
    SmartComponents.Inference.OpenAI.csproj" /&gt;
&lt;/ItemGroup&gt;</pre>
    </li>
    <li>
     
      Still on the server side, open the
     
     <strong class="source-inline">
      
       Program.cs
      
     </strong>
     
      file and register
     
     <strong class="source-inline">
      
       SmartComponents
      
     </strong>
     
      with the
     
     
      
       OpenAI backend:
      
     
     <pre class="source-code">
using SmartComponents.Inference.OpenAI;
//...other service registrations
builder.Services
    .AddSmartComponents()
    .WithInferenceBackend&lt;OpenAIInferenceBackend&gt;();</pre>
    </li>
    <li>
     
      Locate the
     
     <strong class="source-inline">
      
       appSettings
      
     </strong>
     
      file of the server-side project and extend the application settings with an area for
     
     
      <strong class="source-inline">
       
        SmartComponents
       
      </strong>
     
     
      
       configuration:
      
     
     <pre class="source-code">
{
  "SmartComponents": {
    "ApiKey": "YOUR_API_KEY",
    "Endpoint": "YOUR_ENDPOINT",
    "DeploymentName": "YOUR_MODEL_DEPLOYMENT"
  }
}</pre>
    </li>
    <li>
     
      Navigate to the
     
     <strong class="source-inline">
      
       csproj
      
     </strong>
     
      file of the client-side project and include the
     
     <strong class="source-inline">
      
       SmartComponents
      
     </strong>
     
      project
     
     <a id="_idIndexMarker496">
     </a>
     
      required by the
     
     
      
       WebAssembly renderer:
      
     
     <pre class="source-code">
&lt;ItemGroup&gt;
  &lt;ProjectReference
    Include="..\SmartComponents\
    SmartComponents.AspNetCore.Components\
    SmartComponents.AspNetCore.Components.csproj" /&gt;
&lt;/ItemGroup&gt;</pre>
    </li>
    <li>
     
      Create a new routable
     
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
     
      component, referencing the
     
     
      <strong class="source-inline">
       
        SmartComponents
       
      </strong>
     
     
      
       assembly:
      
     
     <pre class="source-code">
@page "/ch10r02"
@using SmartComponents</pre>
    </li>
    <li>
     
      In the
     
     <strong class="source-inline">
      
       @code
      
     </strong>
     
      block of the
     
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
     
      component, declare a
     
     <strong class="source-inline">
      
       Claim
      
     </strong>
     
      form parameter of the
     
     
      <strong class="source-inline">
       
        ClaimViewModel
       
      </strong>
     
     
      
       type:
      
     
     <pre class="source-code">
@code {
    [SupplyParameterFromForm]
    public ClaimViewModel Claim { get; set; } = new();
}</pre>
    </li>
    <li>
     
      In the
     
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
     
      markup, construct an
     
     <strong class="source-inline">
      
       EditForm
      
     </strong>
     
      frame, binding it to the
     
     <strong class="source-inline">
      
       Claim
      
     </strong>
     
      parameter.
     
     
      If
     
     <strong class="source-inline">
      
       EditForm
      
     </strong>
     
      is not recognized as a component, include a
     
     <strong class="source-inline">
      
       @using Microsoft.AspNetCore.Components.Forms
      
     </strong>
     
      reference at the top of the
     
     
      <strong class="source-inline">
       
        FillClaim
       
      </strong>
     
     
      
       component:
      
     
     <pre class="source-code">
&lt;EditForm Model="@Claim" FormName="claim-form"&gt;
    @* we will continue here *@
&lt;/EditForm&gt;</pre>
    </li>
    <li>
     
      Inside the
     
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
     
      form, add
     
     <a id="_idIndexMarker497">
     </a>
     
      fields for entering event and
     
     
      
       customer details:
      
     
     <pre class="source-code">
&lt;p&gt;
    Event name:
    &lt;InputText @bind-Value="@Claim.Event" /&gt;
&lt;/p&gt;
&lt;p&gt;Date: &lt;InputText @bind-Value="@Claim.Date" /&gt;&lt;/p&gt;
&lt;p&gt;
    Customer name:
    &lt;InputText @bind-Value="@Claim.Customer.Name" /&gt;
&lt;/p&gt;
&lt;p&gt;
    Customer email:
    &lt;InputText @bind-Value="@Claim.Customer.Email" /&gt;
&lt;/p&gt;</pre>
    </li>
    <li>
     
      Add a submit button within the form to confirm
     
     
      
       the input:
      
     
     <pre class="source-code">
&lt;button type="submit"&gt;Submit&lt;/button&gt;</pre>
    </li>
    <li>
     
      Lastly, below the submit button, embed a
     
     <strong class="source-inline">
      
       SmartPasteButton
      
     </strong>
     
      component with a
     
     
      
       default icon:
      
     
     <pre class="source-code">
&lt;SmartPasteButton DefaultIcon /&gt;</pre>
    </li>
   </ol>
   <h2 id="_idParaDest-362">
    <a id="_idTextAnchor362">
    </a>
    
     How it works…
    
   </h2>
   <p>
    
     In
    
    <em class="italic">
     
      step 1
     
    </em>
    
     , we start by configuring the server side of the application.
    
    
     We navigate to the project configuration file and add references to two projects required to make
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     work on the server.
    
    
     The
    
    <strong class="source-inline">
     
      SmartComponents.AspNetCore
     
    </strong>
    
     project contains server components powered by AI, while the
    
    <strong class="source-inline">
     
      SmartComponents.Inference.OpenAI
     
    </strong>
    
     project contains an implementation of services to communicate with
    
    
     
      OpenAI backend.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 2
     
    </em>
    
     , we navigate to the
    
    <strong class="source-inline">
     
      Program.cs
     
    </strong>
    
     file in the server-side project and register
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     in the dependency-injection container.
    
    
     We also register an
    
    <strong class="source-inline">
     
      OpenAIInferenceBackend
     
    </strong>
    
     implementation as the default prompts configuration for
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     to use.
    
    
     Custom inference implementations come in handy when you leverage the AI to generate texts.
    
    
     We will explore that later, in the
    
    <em class="italic">
     
      Implementing a smart text
     
    </em>
    
     <em class="italic">
      
       area
      
     </em>
    
    
     
      recipe.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 3
     
    </em>
    
     , we complete the setup of
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     by navigating to the
    
    <strong class="source-inline">
     
      appSettings.json
     
    </strong>
    
     file on the server side.
    
    
     As
    
    <strong class="source-inline">
     
      appSettings.json
     
    </strong>
    
     is a configuration source of the application, we extend the JSON with a
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     section
    
    <a id="_idIndexMarker498">
    </a>
    
     and key nodes, representing the API key and endpoint and the model deployment name that the
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     components
    
    
     
      must use.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 4
     
    </em>
    
     , we jump to the client side of the application.
    
    
     In-line with default Blazor component packages,
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     also has component counterparts for rendering in WebAssembly mode.
    
    
     We navigate to the configuration file of the client-side project and add a
    
    <strong class="source-inline">
     
      SmartComponents.AspNetCore.Components
     
    </strong>
    
     project
    
    
     
      reference there.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 5
     
    </em>
    
     , we create a routable
    
    <strong class="source-inline">
     
      FillClaim
     
    </strong>
    
     component and reference the
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     assembly.
    
    
     Next, we build a form where the support team can fill in claim details with the help
    
    
     
      of AI.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 6
     
    </em>
    
     , we initialize an
    
    <strong class="source-inline">
     
      @code
     
    </strong>
    
     block and declare a
    
    <strong class="source-inline">
     
      Claim
     
    </strong>
    
     parameter that will also act as the backing model of the claim form.
    
    
     If you’re new to form creation in Blazor, we covered that in detail in
    
    <a href="B22020_06.xhtml#_idTextAnchor203">
     
      <em class="italic">
       
        Chapter 6
       
      </em>
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 7
     
    </em>
    
     , we construct a form frame using
    
    <strong class="source-inline">
     
      EditForm
     
    </strong>
    
     and bind it to the
    
    
     <strong class="source-inline">
      
       Claim
      
     </strong>
    
    
     
      model.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 8
     
    </em>
    
     , we build a simple form body, allowing the user to fill in an event name, date, customer name, and email – enough to identify and process
    
    
     
      the claim.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 9
     
    </em>
    
     , we complete the form by adding a
    
    
     
      submit button.
     
    
   </p>
   <p>
    
     Lastly, in
    
    <em class="italic">
     
      step 10
     
    </em>
    
     , we enhance the form with AI by embedding the
    
    <strong class="source-inline">
     
      SmartPasteButton
     
    </strong>
    
     component within the form’s body.
    
    
     We also declare the
    
    <strong class="source-inline">
     
      SmartPasteButton
     
    </strong>
    
     component to render with a default icon.
    
    
     With that simple setup, you can now transform unstructured data into a ready-to-send form with the help of a (
    
    
     
      smart) button.
     
    
   </p>
   <div><div><img alt="Figure 10.13: A result of smart pasting an e-mail with a claim into a form" src="img/B22020_10_13.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.13: A result of smart pasting an e-mail with a claim into a form
    
   </p>
   <h2 id="_idParaDest-363">
    <a id="_idTextAnchor363">
    </a>
    
     There’s more…
    
   </h2>
   <p>
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     can also work with the OpenAI API key.
    
    
     If you already have an OpenAI account, navigate to the
    
    
     
      following URL:
     
    
   </p>
   <p>
    <a href="https://platform.openai.com/api-keys">
     
      
       https://platform.openai.com/api-keys
      
     
    </a>
   </p>
   <p>
    
     Here, you’ll be able to create an API key that allows you to access the
    
    
     
      ChatGPT API:
     
    
   </p>
   <div><div><img alt="Figure 10.14: Creating an API key to access the OpenAI API" src="img/B22020_10_14.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.14: Creating an API key to access the OpenAI API
    
   </p>
   <p>
    
     Once you have the API key, open the
    
    <strong class="source-inline">
     
      appSettings.json
     
    </strong>
    
     file of the server-side application and update the
    
    
     <strong class="source-inline">
      
       SmartComponents
      
     </strong>
    
    
     
      section:
     
    
   </p>
   <pre class="source-code">
{
  "SmartComponents": {
    "ApiKey": "YOUR_API_KEY",
    "DeploymentName": "gpt-4o"
  }
}</pre>
   <p>
    
     In the preceding
    
    <a id="_idIndexMarker499">
    </a>
    
     configuration, the
    
    <strong class="source-inline">
     
      ApiKey
     
    </strong>
    
     node still represents your API key, while the
    
    <strong class="source-inline">
     
      DeploymentName
     
    </strong>
    
     node now defines the GPT model you want to use.
    
    
     Notice that the
    
    <strong class="source-inline">
     
      Endpoint
     
    </strong>
    
     node is no longer needed.
    
    
     When you don’t provide an
    
    <strong class="source-inline">
     
      Endpoint
     
    </strong>
    
     value explicitly,
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     will fall back to the default OpenAI
    
    
     
      API URI.
     
    
   </p>
   <h1 id="_idParaDest-364">
    <a id="_idTextAnchor364">
    </a>
    
     Implementing a smart text area
    
   </h1>
   <p>
    
     You’ve probably
    
    <a id="_idIndexMarker500">
    </a>
    
     seen the generative power of AI in action – you provide a context, and a wall of sensible text appears.
    
    
     No more writer’s block, right?
    
    
     Generative AI is a game-changer for all text-driven features in your application.
    
    
     You can take store item descriptions or event descriptions from a list of bullet points into well-written copy in seconds.
    
    
     With
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     , we can easily connect to an AI model and leverage the generative power, making content creation faster and
    
    
     
      more intuitive.
     
    
   </p>
   <p>
    
     Let’s implement a text area where the support team can fill in a message attached to a response to a
    
    
     
      client’s claim.
     
    
   </p>
   <h2 id="_idParaDest-365">
    <a id="_idTextAnchor365">
    </a>
    
     Getting ready
    
   </h2>
   <p>
    
     Before we explore the AI-powered text area implementation, we must do
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      Create a
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Recipe03
      
     </strong>
     
      directory – this will be our
     
     
      
       working directory
      
     
    </li>
    <li>
     
      Copy the
     
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
     
      component from the
     
     <em class="italic">
      
       Implementing smart pasting
      
     </em>
     
      recipe or from the
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Recipe02
      
     </strong>
     
      directory in the
     
     
      
       GitHub repository
      
     
    </li>
    <li>
     
      Copy the
     
     <strong class="source-inline">
      
       Models
      
     </strong>
     
      from the
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Data
      
     </strong>
     
      directory in the
     
     
      
       GitHub repository
      
     
    </li>
    <li>
     
      If you’re starting
     
     <a id="_idIndexMarker501">
     </a>
     
      here, review instructions from
     
     <em class="italic">
      
       step 1
      
     </em>
     
      to
     
     <em class="italic">
      
       step 4
      
     </em>
     
      of the
     
     <em class="italic">
      
       Implementing smart pasting
      
     </em>
     
      recipe for an initial
     
     
      <strong class="source-inline">
       
        SmartComponents
       
      </strong>
     
     
      
       configuration
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-366">
    <a id="_idTextAnchor366">
    </a>
    
     How to do it…
    
   </h2>
   <p>
    
     Follow these instructions to add a smart text area to
    
    
     
      your application:
     
    
   </p>
   <ol>
    <li>
     
      Navigate to the
     
     <strong class="source-inline">
      
       @code
      
     </strong>
     
      block of the
     
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
     
      component and add a
     
     <strong class="source-inline">
      
       replier
      
     </strong>
     
      variable that defines the person filling out the
     
     
      
       claim form:
      
     
     <pre class="source-code">
const string replier =
    "An event organizer support team member replying
    to a claim request.";</pre>
    </li>
    <li>
     
      Jump to the
     
     <strong class="source-inline">
      
       EditForm
      
     </strong>
     
      body in the
     
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
     
      markup and extend the form by embedding a
     
     <strong class="source-inline">
      
       SmartTextArea
      
     </strong>
     
      component above the submission button.
     
     
      Attach the
     
     <strong class="source-inline">
      
       replier
      
     </strong>
     
      variable to the
     
     <strong class="source-inline">
      
       UserRole
      
     </strong>
     
      parameter of the
     
     <strong class="source-inline">
      
       SmartTextArea
      
     </strong>
     
      component and bind the text area value to the
     
     <strong class="source-inline">
      
       Message
      
     </strong>
     
      property of the
     
     
      <strong class="source-inline">
       
        Claim
       
      </strong>
     
     
      
       instance:
      
     
     <pre class="source-code">
&lt;p&gt;
    &lt;SmartTextArea
        @bind-Value="@Claim.Message"
        rows="5" cols="50"
        UserRole="@replier" /&gt;
&lt;/p&gt;</pre>
    </li>
   </ol>
   <h2 id="_idParaDest-367">
    <a id="_idTextAnchor367">
    </a>
    
     How it works…
    
   </h2>
   <p>
    
     In
    
    <em class="italic">
     
      step 1
     
    </em>
    
     , we jump straight to the
    
    <strong class="source-inline">
     
      FillClaim
     
    </strong>
    
     component.
    
    
     First, we move to the
    
    <strong class="source-inline">
     
      @code
     
    </strong>
    
     block and declare a
    
    <strong class="source-inline">
     
      replier
     
    </strong>
    
     variable, where we put a brief but detailed description of the persona that we want the AI to represent.
    
    
     Considering that AI models learn from content written by humans, you should strive to make the
    
    <strong class="source-inline">
     
      replier
     
    </strong>
    
     description as natural as you would sound when speaking to
    
    
     
      a friend.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 2
     
    </em>
    
     , we locate the
    
    <strong class="source-inline">
     
      EditForm
     
    </strong>
    
     markup in the
    
    <strong class="source-inline">
     
      FillClaim
     
    </strong>
    
     markup.
    
    
     Above the submission button, we embed a
    
    <strong class="source-inline">
     
      SmartTextArea
     
    </strong>
    
     component.
    
    
     The
    
    <strong class="source-inline">
     
      SmartTextArea
     
    </strong>
    
     component supports the bind-value binding pattern (you can learn more about binding in
    
    <a href="B22020_03.xhtml#_idTextAnchor095">
     
      <em class="italic">
       
        Chapter 3
       
      </em>
     
    </a>
    
     ) and allows
    
    <a id="_idIndexMarker502">
    </a>
    
     defining standard
    
    <strong class="source-inline">
     
      textarea
     
    </strong>
    
     attributes, such as
    
    <strong class="source-inline">
     
      rows
     
    </strong>
    
     or
    
    <strong class="source-inline">
     
      cols
     
    </strong>
    
     , representing the default size of the text box.
    
    
     It also allows setting a
    
    <strong class="source-inline">
     
      UserRole
     
    </strong>
    
     parameter – that’s where we attach our persona definition stored
    
    
     
      in
     
    
    
     <strong class="source-inline">
      
       replier
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     That’s all it takes to add a generative field to
    
    
     
      your application:
     
    
   </p>
   <div><div><img alt="Figure 10.15: AI helping to write a claim response as user types the message" src="img/B22020_10_15.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.15: AI helping to write a claim response as user types the message
    
   </p>
   <h2 id="_idParaDest-368">
    <a id="_idTextAnchor368">
    </a>
    
     There’s more…
    
   </h2>
   <p>
    
     So far, we used the default inference configuration provided by the
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     package.
    
    
     However, you can customize the prompt and AI behavior by implementing a custom
    
    <strong class="source-inline">
     
      SmartTextAreaInference
     
    </strong>
    
     logic.
    
    
     Since AI communication and processing only happen on the server, you must keep prompt customization in the
    
    
     
      server-side project.
     
    
   </p>
   <p>
    
     Let’s create a
    
    <strong class="source-inline">
     
      ClaimReplyInference
     
    </strong>
    
     class, inheriting from
    
    <strong class="source-inline">
     
      SmartTextAreaInference
     
    </strong>
    
     , and
    
    <a id="_idIndexMarker503">
    </a>
    
     customize suggestions coming in the
    
    
     <strong class="source-inline">
      
       FillClaim
      
     </strong>
    
    
     
      form:
     
    
   </p>
   <pre class="source-code">
public class ClaimReplyInference : SmartTextAreaInference
{
    public override ChatParameters BuildPrompt(
        SmartTextAreaConfig config,
        string textBefore, string textAfter
    )
    {
        var prompt = base.BuildPrompt(
            config, textBefore, textAfter
        );
        var systemMessage = new ChatMessage(
            ChatMessageRole.System,
            "Make suggestions in a professional tone."
        );
        prompt.Messages.Add(systemMessage);
        prompt.Temperature = 0.7f;
        return prompt;
    }
}</pre>
   <p>
    
     In
    
    <strong class="source-inline">
     
      ClaimReplyInference
     
    </strong>
    
     , we override the
    
    <strong class="source-inline">
     
      BuildPrompt()
     
    </strong>
    
     method.
    
    
     We leverage the base implementation to build the prompt but customize it afterward.
    
    
     First, we append an additional
    
    <strong class="source-inline">
     
      ChatMessage
     
    </strong>
    
     instance to the
    
    <strong class="source-inline">
     
      Messages
     
    </strong>
    
     collection the
    
    <strong class="source-inline">
     
      prompt
     
    </strong>
    
     already has.
    
    
     We define that new
    
    <strong class="source-inline">
     
      ChatMessage
     
    </strong>
    
     role as
    
    <strong class="source-inline">
     
      System
     
    </strong>
    
     .
    
    
     The
    
    <strong class="source-inline">
     
      System
     
    </strong>
    
     message sets the overall behavior of the AI model, indicating that we expect a professional tone of suggestions.
    
    
     Lastly, we customize the value of the prompt’s
    
    <strong class="source-inline">
     
      Temperature
     
    </strong>
    
     property.
    
    
     The
    
    <strong class="source-inline">
     
      Temperature
     
    </strong>
    
     setting controls the randomness of the AI responses, with lower values making the output more focused and deterministic and higher values making it more creative
    
    
     
      and varied.
     
    
   </p>
   <p>
    
     Having
    
    <strong class="source-inline">
     
      ClaimReplyInference
     
    </strong>
    
     in place, we must add it to the dependency
    
    
     
      injection container:
     
    
   </p>
   <pre class="source-code">
builder.Services.AddSingleton&lt;SmartTextAreaInference,
    ClaimReplyInference&gt;()</pre>
   <p>
    
     In the
    
    <strong class="source-inline">
     
      Program
     
    </strong>
    
     entry
    
    <a id="_idIndexMarker504">
    </a>
    
     class, we register the
    
    <strong class="source-inline">
     
      SmartTextAreaInference
     
    </strong>
    
     class as a singleton.
    
    
     The
    
    <strong class="source-inline">
     
      SmartTextArea
     
    </strong>
    
     component will automatically discover the
    
    
     
      new implementation.
     
    
   </p>
   <p>
    
     Now, users will get more
    
    
     
      official-sounding suggestions:
     
    
   </p>
   <div><div><img alt="Figure 10.16: AI generating suggestions in a professional tone, to help a user replay to a claim" src="img/B22020_10_16.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.16: AI generating suggestions in a professional tone, to help a user replay to a claim
    
   </p>
   <h2 id="_idParaDest-369">
    <a id="_idTextAnchor369">
    </a>
    
     See also
    
   </h2>
   <p>
    
     You can customize all available
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     components and fine-tune the AI behavior to your application needs.
    
    
     If you want to learn more, check out the official
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     docs on GitHub
    
    
     
      at
     
    
    <a href="https://github.com/dotnet-smartcomponents/smartcomponents/tree/main">
     
      
       https://github.com/dotnet-smartcomponents/smartcomponents/tree/main
      
     
    </a>
    
     
      .
     
    
   </p>
   <h1 id="_idParaDest-370">
    <a id="_idTextAnchor370">
    </a>
    
     Adding a ChatBot
    
   </h1>
   <p>
    
     ChatGPT, developed
    
    <a id="_idIndexMarker505">
    </a>
    
     by OpenAI, is an advanced conversational AI model that has gained significant attention since its release.
    
    
     It’s designed to understand and generate human-like text based on the input it receives, making interactions with it feel natural and intuitive.
    
    
     The versatility of the GPT models enables their application in numerous contexts, from customer support and personal assistants to educational tools
    
    
     
      and entertainment.
     
    
   </p>
   <p>
    
     Let’s construct a primitive chat UI and connect it to the Azure OpenAI service to embed a ChatGPT-like chat functionality in the
    
    
     
      Blazor application.
     
    
   </p>
   <h2 id="_idParaDest-371">
    <a id="_idTextAnchor371">
    </a>
    
     Getting ready
    
   </h2>
   <p>
    
     Similar to
    
    <strong class="source-inline">
     
      SmartComponents
     
    </strong>
    
     , which we explored in previous chapters, the chat will require Azure OpenAI API access.
    
    
     To avoid leaking API access details, we move to the server side of
    
    
     
      the application.
     
    
   </p>
   <p>
    
     Before we dive into building AI-powered chat, we must do
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      Create a
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Recipe04
      
     </strong>
     
      directory – this will be your
     
     
      
       working directory
      
     
    </li>
    <li>
     
      Copy the
     
     <strong class="source-inline">
      
       InputModel
      
     </strong>
     
      from the
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Data
      
     </strong>
     
      directory in the
     
     
      
       GitHub repository
      
     
    </li>
    <li>
     
      Prepare the Azure OpenAI Service connection details (you can see how to get them in the
     
     <em class="italic">
      
       There’s more…
      
     </em>
     
      section of the
     
     <em class="italic">
      
       Setting up an Azure OpenAI
      
     </em>
     
      <em class="italic">
       
        service
       
      </em>
     
     
      
       recipe)
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-372">
    <a id="_idTextAnchor372">
    </a>
    
     How to do it…
    
   </h2>
   <p>
    
     Follow these steps to add an AI-powered chat to
    
    
     
      an application:
     
    
   </p>
   <ol>
    <li>
     
      Navigate to the configuration file of the server-side project and include the latest version of the
     
     <strong class="source-inline">
      
       Azure.AI.OpenAI
      
     </strong>
     
      package (at the time of writing, it’s still
     
     
      
       in preview):
      
     
     <pre class="source-code">
&lt;ItemGroup&gt;
  &lt;PackageReference
    Include="Azure.AI.OpenAI"
    Version="2.0.0-beta.2" /&gt;
&lt;/ItemGroup&gt;</pre>
    </li>
    <li>
     
      Open the
     
     <strong class="source-inline">
      
       appsettings.json
      
     </strong>
     
      file with the server project configuration and add a
     
     <strong class="source-inline">
      
       ChatBot
      
     </strong>
     
      section with the
     
     
      
       required nodes:
      
     
     <pre class="source-code">
{
  "ChatBot": {
    "ApiKey": "YOUR_API_KEY",
    "Endpoint": "YOUR_ENDPOINT",
    "DeploymentName": "YOUR_MODEL_DEPLOYMENT"
  }
}</pre>
    </li>
    <li>
     
      Move to the
     
     <strong class="source-inline">
      
       Program.cs
      
     </strong>
     
      entry
     
     <a id="_idIndexMarker506">
     </a>
     
      file of the server-side project, and right after the
     
     <strong class="source-inline">
      
       builder
      
     </strong>
     
      instance is initialized, intercept the chat configuration
     
     
      
       into variables:
      
     
     <pre class="source-code">
var endpoint = builder
    .Configuration["ChatBot:Endpoint"];
var apiKey = builder
    .Configuration["ChatBot:ApiKey"];
var deploymentName = builder
    .Configuration["ChatBot:DeploymentName"];</pre>
    </li>
    <li>
     
      Below the configuration variables, register an
     
     <strong class="source-inline">
      
       AzureOpenAIClient
      
     </strong>
     
      service as a singleton by passing the
     
     <strong class="source-inline">
      
       endpoint
      
     </strong>
     
      and
     
     <strong class="source-inline">
      
       apiKey
      
     </strong>
     
      variables into the
     
     
      
       service constructor:
      
     
     <pre class="source-code">
builder.Services.AddSingleton(
    new AzureOpenAIClient(
        new Uri(endpoint),
        new AzureKeyCredential(apiKey)
));</pre>
    </li>
    <li>
     
      After registering
     
     <strong class="source-inline">
      
       AzureOpenAIClient
      
     </strong>
     
      , add a
     
     <strong class="source-inline">
      
       ChatClient
      
     </strong>
     
      service to the dependency injection container as scoped.
     
     
      Leverage the
     
     <strong class="source-inline">
      
       AzureOpenAIClient
      
     </strong>
     
      API
     
     <a id="_idIndexMarker507">
     </a>
     
      and
     
     <strong class="source-inline">
      
       deploymentName
      
     </strong>
     
      to construct the
     
     
      <strong class="source-inline">
       
        ChatClient
       
      </strong>
     
     
      
       instance:
      
     
     <pre class="source-code">
builder.Services
    .AddScoped(services =&gt;
    {
        var openAI = services
            .GetRequiredService&lt;AzureOpenAIClient&gt;();
        return openAI.GetChatClient(deploymentName);
    });</pre>
    </li>
    <li>
     
      Create a routable
     
     <strong class="source-inline">
      
       ChatBot
      
     </strong>
     
      component, rendering in the
     
     <strong class="source-inline">
      
       InteractiveServer
      
     </strong>
     
      mode and referencing the
     
     
      <strong class="source-inline">
       
        OpenAI.Chat
       
      </strong>
     
     
      
       assembly:
      
     
     <pre class="source-code">
@page "/ch10r04"
@rendermode InteractiveServer
@using OpenAI.Chat</pre>
    </li>
    <li>
     
      Initialize the
     
     <strong class="source-inline">
      
       @code
      
     </strong>
     
      block in the
     
     <strong class="source-inline">
      
       ChatBot
      
     </strong>
     
      component and inject the
     
     <strong class="source-inline">
      
       ChatClient
      
     </strong>
     
      service
     
     
      
       as
      
     
     
      <strong class="source-inline">
       
        Chat
       
      </strong>
     
     
      
       :
      
     
     <pre class="source-code">
@code {
    [Inject] private ChatClient Chat { get; init; }
}</pre>
    </li>
    <li>
     
      Below the service injection, initialize a
     
     <strong class="source-inline">
      
       Model
      
     </strong>
     
      instance to bind to the input form and
     
     <strong class="source-inline">
      
       Messages
      
     </strong>
     
      collection to persist chat messages to display on
     
     
      
       the UI:
      
     
     <pre class="source-code">
protected InputModel Model = new();
protected List&lt;string&gt; Messages = [];</pre>
    </li>
    <li>
     
      Below the
     
     <strong class="source-inline">
      
       Messages
      
     </strong>
     
      collection, initialize a
     
     <strong class="source-inline">
      
       _messages
      
     </strong>
     
      collection to hold messages in a form transferable to the Azure OpenAI Service.
     
     
      Start the
     
     <strong class="source-inline">
      
       _messages
      
     </strong>
     
      collection
     
     <a id="_idIndexMarker508">
     </a>
     
      with a system prompt, defining the
     
     
      
       chatbot’s persona:
      
     
     <pre class="source-code">
private List&lt;ChatMessage&gt; _messages =
[
    new SystemChatMessage(
        "Act as a friendly salesman for the Blazor Web
        Development Cookbook written by Pawel
        Bazyluk."
    )
];</pre>
    </li>
    <li>
     
      Next to the backing variables, implement a
     
     <strong class="source-inline">
      
       SendMessage()
      
     </strong>
     
      method.
     
     
      Start by checking the validity of the
     
     <strong class="source-inline">
      
       Model
      
     </strong>
     
      state.
     
     
      If the input is valid, convert it to the
     
     <strong class="source-inline">
      
       UserChatMessage
      
     </strong>
     
      object and add the message to the
     
     
      
       backing collections:
      
     
     <pre class="source-code">
private async Task SendMessage()
{
    if (!Model.IsValid) return;
    var message = new UserChatMessage(Model.Value);
    Messages.Add($"You: {Model.Value}");
    _messages.Add(message);
    //continue here...
}</pre>
    </li>
    <li>
     
      Still within the
     
     <strong class="source-inline">
      
       SendMessage()
      
     </strong>
     
      method, request chat completion by passing the
     
     <strong class="source-inline">
      
       _messages
      
     </strong>
     
      collection to the
     
     <strong class="source-inline">
      
       CompleteChatAsync()
      
     </strong>
     
      method of the
     
     <strong class="source-inline">
      
       Chat
      
     </strong>
     
      service and resolve the
     
     
      
       response payload:
      
     
     <pre class="source-code">
var chatResponse = await Chat
    .CompleteChatAsync(_messages);
var response = chatResponse.Value.Content[0].Text;
// continue here...</pre>
    </li>
    <li>
     
      Complete the
     
     <strong class="source-inline">
      
       SendMessage()
      
     </strong>
     
      method by persisting the received response in the
     
     <strong class="source-inline">
      
       Messages
      
     </strong>
     
      collection
     
     <a id="_idIndexMarker509">
     </a>
     
      and in the
     
     <strong class="source-inline">
      
       _messages
      
     </strong>
     
      collection as an
     
     <strong class="source-inline">
      
       AssistantChatMessage
      
     </strong>
     
      object.
     
     
      Lastly, reset
     
     <strong class="source-inline">
      
       Value
      
     </strong>
     
      of the
     
     
      <strong class="source-inline">
       
        Model
       
      </strong>
     
     
      
       object:
      
     
     <pre class="source-code">
_messages.Add(new AssistantChatMessage(response));
Messages.Add($"OpenAI: {response}");
Model.Value = string.Empty;</pre>
    </li>
    <li>
     
      Move to the
     
     <strong class="source-inline">
      
       ChatBot
      
     </strong>
     
      markup and construct a simple
     
     <strong class="source-inline">
      
       EditForm
      
     </strong>
     
      form with a single input field bound to the
     
     <strong class="source-inline">
      
       Model
      
     </strong>
     
      variable, triggering
     
     <strong class="source-inline">
      
       SendMessage()
      
     </strong>
     
      when submitted.
     
     
      If
     
     <strong class="source-inline">
      
       EditForm
      
     </strong>
     
      is not recognized as a component, include a
     
     <strong class="source-inline">
      
       @using Microsoft.AspNetCore.Components.Forms
      
     </strong>
     
      reference at the top of the
     
     
      <strong class="source-inline">
       
        FillClaim
       
      </strong>
     
     
      
       component:
      
     
     <pre class="source-code">
&lt;h3&gt;What can I help you with?&lt;/h3&gt;
&lt;EditForm Model="@Model" FormName="chat-input"
          OnSubmit="@SendMessage"&gt;
    &lt;InputText @bind-Value="@Model.Value" /&gt;
    &lt;button type="submit"&gt;Send&lt;/button&gt;
&lt;/EditForm&gt;</pre>
    </li>
    <li>
     
      Below the input form, iterate over the elements in the
     
     <strong class="source-inline">
      
       Messages
      
     </strong>
     
      collection and render them in
     
     
      
       separate paragraphs:
      
     
     <pre class="source-code">
&lt;hr /&gt;
@foreach (var message in Messages)
{
    &lt;p&gt;@message&lt;/p&gt;
}</pre>
    </li>
   </ol>
   <h2 id="_idParaDest-373">
    <a id="_idTextAnchor373">
    </a>
    
     How it works…
    
   </h2>
   <p>
    
     In
    
    <em class="italic">
     
      step 1
     
    </em>
    
     , we start by adding the
    
    <strong class="source-inline">
     
      Azure.AI.OpenAI
     
    </strong>
    
     package to the server side of the application.
    
    
     If you’ve
    
    <a id="_idIndexMarker510">
    </a>
    
     been using the
    
    <strong class="bold">
     
      NuGet Package Manager
     
    </strong>
    
     , you’ll have to include prerelease versions of the packages, as
    
    <strong class="source-inline">
     
      Azure.AI.OpenAI
     
    </strong>
    
     is still in preview at the time
    
    
     
      of writing.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 2
     
    </em>
    
     , we add a chatbot configuration section to the
    
    <strong class="source-inline">
     
      appsettings.json
     
    </strong>
    
     file.
    
    
     We will need an
    
    <strong class="source-inline">
     
      ApiKey
     
    </strong>
    
     node, an API
    
    <strong class="source-inline">
     
      Endpoint
     
    </strong>
    
     node, and a
    
    <strong class="source-inline">
     
      DeploymentName
     
    </strong>
    
     node, to specify the name of the model we want
    
    
     
      to use.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 3
     
    </em>
    
     , we navigate to the
    
    <strong class="source-inline">
     
      Program.cs
     
    </strong>
    
     file of the server-side project, where we register the necessary services in the dependency injection container.
    
    
     First, we intercept the chatbot configuration values into
    
    <strong class="source-inline">
     
      endpoint
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      apiKey
     
    </strong>
    
     , and
    
    <strong class="source-inline">
     
      deploymentName
     
    </strong>
    
     by accessing the configuration reader from the
    
    
     <strong class="source-inline">
      
       builder
      
     </strong>
    
    
     
      instance.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 4
     
    </em>
    
     , we register the
    
    <strong class="source-inline">
     
      AzureOpenAIClient
     
    </strong>
    
     service as a singleton, passing the
    
    <strong class="source-inline">
     
      endpoint
     
    </strong>
    
     value as the Azure OpenAI URI and initializing
    
    <strong class="source-inline">
     
      AzureKeyCredentials
     
    </strong>
    
     with an
    
    <strong class="source-inline">
     
      apiKey
     
    </strong>
    
     value.
    
    
     We can have a shared instance of the
    
    <strong class="source-inline">
     
      AzureOpenAIClient
     
    </strong>
    
     service as it’s thread- and scope-safe by design but consider the memory impact in
    
    
     
      your implementations.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 5
     
    </em>
    
     , we add one more service to the dependency injection container – we register a
    
    <strong class="source-inline">
     
      ChatClient
     
    </strong>
    
     service as scoped.
    
    
     We construct the
    
    <strong class="source-inline">
     
      ChatClient
     
    </strong>
    
     object by resolving the
    
    <strong class="source-inline">
     
      AzureOpenAIClient
     
    </strong>
    
     instance from the services collection and invoking its
    
    <strong class="source-inline">
     
      GetChatClient()
     
    </strong>
    
     method with the
    
    <strong class="source-inline">
     
      deploymentName
     
    </strong>
    
     value.
    
    
     Having services in place, we construct the
    
    
     
      UI part.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 6
     
    </em>
    
     , we create a routable
    
    <strong class="source-inline">
     
      ChatBot
     
    </strong>
    
     component that references the
    
    <strong class="source-inline">
     
      OpenAI.Chat
     
    </strong>
    
     assembly, as we will need access to the
    
    <strong class="source-inline">
     
      ChatClient
     
    </strong>
    
     class definition.
    
    
     We also need the
    
    <strong class="source-inline">
     
      ChatBot
     
    </strong>
    
     component to render in
    
    <strong class="source-inline">
     
      InteractiveServer
     
    </strong>
    
     mode, since our users will interact with
    
    
     
      the chat.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 7
     
    </em>
    
     , we initialize the
    
    <strong class="source-inline">
     
      @code
     
    </strong>
    
     block and inject the
    
    <strong class="source-inline">
     
      ChatClient
     
    </strong>
    
     service from the
    
    
     
      dependency injection.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 8
     
    </em>
    
     , we initialize a
    
    <strong class="source-inline">
     
      Model
     
    </strong>
    
     instance to bind the input form where users fill in their messages, as well as a
    
    <strong class="source-inline">
     
      Messages
     
    </strong>
    
     collection, where we persist the text representation of the chat and user messages to render them in
    
    
     
      the markup.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 9
     
    </em>
    
     , we initialize one more collection –
    
    <strong class="source-inline">
     
      _messages
     
    </strong>
    
     .
    
    
     In
    
    <strong class="source-inline">
     
      _messages
     
    </strong>
    
     , we persist messages in the form of
    
    <strong class="source-inline">
     
      ChatMessage
     
    </strong>
    
     objects.
    
    
     With that, we can easily provide the full context of the conversation when requesting a new response from the Azure OpenAI service; without the history of the messages, we would limit the chat context to the last message the user
    
    <a id="_idIndexMarker511">
    </a>
    
     sends.
    
    
     We also start off
    
    <strong class="source-inline">
     
      _messages
     
    </strong>
    
     with a predefined
    
    <strong class="source-inline">
     
      SystemChatMessage
     
    </strong>
    
     object.
    
    
     The
    
    <strong class="source-inline">
     
      SystemChatMessage
     
    </strong>
    
     object allows us to inject a prompt, where we define how the chatbot should behave, but the prompt itself is not a part of
    
    
     
      the conversation.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 9
     
    </em>
    
     , we implement a
    
    <strong class="source-inline">
     
      SendMessage()
     
    </strong>
    
     method where all the chatting logic goes.
    
    
     At the beginning, we check whether the submitted
    
    <strong class="source-inline">
     
      Model
     
    </strong>
    
     value is valid and fast-return when there’s nothing to process.
    
    
     Then, we wrap the user input into a
    
    <strong class="source-inline">
     
      UserChatMessage
     
    </strong>
    
     object.
    
    
     We must use the
    
    <strong class="source-inline">
     
      UserChatMessage
     
    </strong>
    
     objects when sending user inputs so the AI can interpret them accordingly.
    
    
     Next, we add the
    
    <strong class="source-inline">
     
      UserChatMessage
     
    </strong>
    
     instance to the
    
    <strong class="source-inline">
     
      _messages
     
    </strong>
    
     context collection and format the user input into a chat-like version to add it to the renderable
    
    
     <strong class="source-inline">
      
       Messages
      
     </strong>
    
    
     
      collection.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 10
     
    </em>
    
     , we leverage the
    
    <strong class="source-inline">
     
      Chat
     
    </strong>
    
     instance and its
    
    <strong class="source-inline">
     
      CompleteChatAsync()
     
    </strong>
    
     method to request a new chat response from the Azure OpenAI.
    
    
     Notice that we send the entire
    
    <strong class="source-inline">
     
      _messages
     
    </strong>
    
     collection as part of the request so that GPT in the cloud has the full context of the conversation.
    
    
     Then, we unpack the message from the received response
    
    
     <strong class="source-inline">
      
       Content
      
     </strong>
    
    
     
      property.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 11
     
    </em>
    
     , we push the unpacked payload to the backing variables.
    
    
     This time, we wrap the received message in an
    
    <strong class="source-inline">
     
      AssistantChatMessage
     
    </strong>
    
     object before adding it to the
    
    <strong class="source-inline">
     
      _messages
     
    </strong>
    
     collection.
    
    
     The
    
    <strong class="source-inline">
     
      AssistantChatMessage
     
    </strong>
    
     type represents responses from the AI itself.
    
    
     Next, we construct a chat-like message to add to the
    
    <strong class="source-inline">
     
      Messages
     
    </strong>
    
     collection to render it for the user to see.
    
    
     Finally, we clear the
    
    <strong class="source-inline">
     
      Model
     
    </strong>
    
     value to accept another message from
    
    
     
      the user.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 12
     
    </em>
    
     , we implement a primitive markup so the user can interact with the chat.
    
    
     We add a call to action at the top and construct an
    
    <strong class="source-inline">
     
      EditForm
     
    </strong>
    
     form.
    
    
     We bind the form to the
    
    <strong class="source-inline">
     
      Model
     
    </strong>
    
     instance and attach the
    
    <strong class="source-inline">
     
      SendMessage()
     
    </strong>
    
     method to its submission callback.
    
    
     Within the
    
    <strong class="source-inline">
     
      EditForm
     
    </strong>
    
     markup, we add a single
    
    <strong class="source-inline">
     
      InputText
     
    </strong>
    
     field where the user provides their chat requests and a button allowing them to submit the form and trigger the
    
    
     
      chat generation.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 13
     
    </em>
    
     , below the
    
    <strong class="source-inline">
     
      EditForm
     
    </strong>
    
     component, we construct a simple loop where we iterate over the chat-like messages in the
    
    <strong class="source-inline">
     
      Messages
     
    </strong>
    
     collection and render them in
    
    
     
      separate paragraphs.
     
    
   </p>
   <p>
    
     With that simple
    
    <a id="_idIndexMarker512">
    </a>
    
     implementation, you already get a ready-to-talk
    
    
     
      chat prototype:
     
    
   </p>
   <div><div><img alt="Figure 10.17: Primitive chat UI with a powerful AI-powered backend in action" src="img/B22020_10_17.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 10.17: Primitive chat UI with a powerful AI-powered backend in action
    
   </p>
   <h2 id="_idParaDest-374">
    <a id="_idTextAnchor374">
    </a>
    
     There’s more…
    
   </h2>
   <p>
    
     Depending on the session or message length that you expect to handle with the chat, you should consider cleaning the context of the conversation periodically.
    
    
     This will help maintain the efficiency and effectiveness of the chat functionality.
    
    
     Managing the length of the chat context impacts both the cost and responsiveness of the chat.
    
    
     Longer contexts can lead to higher costs due to increased API usage and potentially slower response times as more data
    
    
     
      is processed.
     
    
   </p>
   <p>
    
     One effective strategy is to
    
    <a id="_idIndexMarker513">
    </a>
    
     implement a
    
    <strong class="bold">
     
      circular buffer
     
    </strong>
    
     of a fixed size.
    
    
     In a circular buffer, new elements
    
    <a id="_idIndexMarker514">
    </a>
    
     are added to the end of the buffer while the oldest elements are overwritten when the buffer reaches its capacity.
    
    
     This approach ensures that the chat context remains within a manageable size, keeping the conversation relevant
    
    
     
      and efficient.
     
    
   </p>
   <h2 id="_idParaDest-375">
    <a id="_idTextAnchor375">
    </a>
    
     See also
    
   </h2>
   <p>
    
     If you’d want to explore the
    
    <strong class="source-inline">
     
      Azure.AI.OpenAI
     
    </strong>
    
     possibilities further, visit the package docs
    
    
     
      at
     
    
    <a href="https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md">
     
      
       https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md
      
     
    </a>
    
     
      .
     
    
   </p>
   <h1 id="_idParaDest-376">
    <a id="_idTextAnchor376">
    </a>
    
     Connecting an Azure OpenAI service to an existing 
data index
    
   </h1>
   <p>
    
     In Azure, you can
    
    <a id="_idIndexMarker515">
    </a>
    
     have multiple existing
    
    <a id="_idIndexMarker516">
    </a>
    
     data sources, ranging from Azure Cosmos DB to various Azure Cognitive services with tokenized and indexed data.
    
    
     While the Azure OpenAI service works with commonly available GPT models, it also allows you to connect a chosen model to your specific data source.
    
    
     With this integration, you can analyze and extract data more intuitively by interacting with your application through
    
    
     
      natural language.
     
    
   </p>
   <p>
    
     Let’s connect the Azure OpenAI service to an existing Azure Search service data index.
    
    
     By doing so, we will leverage the power of AI to analyze our internal
    
    
     
      data seamlessly.
     
    
   </p>
   <h2 id="_idParaDest-377">
    <a id="_idTextAnchor377">
    </a>
    
     Getting ready
    
   </h2>
   <p>
    
     Before we explore connecting Azure Search data to Azure OpenAI, we must do
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      On the server-side on your application, create a
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Recipe05
      
     </strong>
     
      directory – this will be your
     
     
      
       working directory
      
     
    </li>
    <li>
     
      Copy the
     
     <strong class="source-inline">
      
       ChatBot
      
     </strong>
     
      component from the
     
     <em class="italic">
      
       Adding a ChatBot
      
     </em>
     
      recipe or from the
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Recipe04
      
     </strong>
     
      directory in the
     
     
      
       GitHub repository
      
     
    </li>
    <li>
     
      If you’re starting here, register all the Azure services as shown in the
     
     <strong class="source-inline">
      
       Configure
      
     </strong>
     
      file, in the
     
     <strong class="source-inline">
      
       Chapter10
      
     </strong>
     
      /
     
     <strong class="source-inline">
      
       Recipe04
      
     </strong>
     
      directory in the
     
     
      
       GitHub repository
      
     
    </li>
   </ul>
   <h2 id="_idParaDest-378">
    <a id="_idTextAnchor378">
    </a>
    
     How to do it…
    
   </h2>
   <p>
    
     Follow these
    
    <a id="_idIndexMarker517">
    </a>
    
     instructions
    
    <a id="_idIndexMarker518">
    </a>
    
     to connect Azure OpenAI to the Azure Search data and enable analyzing
    
    
     
      the data:
     
    
   </p>
   <ol>
    <li>
     
      Open the
     
     <strong class="source-inline">
      
       appsettings.json
      
     </strong>
     
      file on the server side and add a new
     
     <strong class="source-inline">
      
       Search
      
     </strong>
     
      section with
     
     <strong class="source-inline">
      
       ApiKey
      
     </strong>
     
      ,
     
     <strong class="source-inline">
      
       Endpoint
      
     </strong>
     
      ,
     
     
      
       and
      
     
     
      <strong class="source-inline">
       
        Index
       
      </strong>
     
     
      
       :
      
     
     <pre class="source-code">
"Search": {
  "ApiKey": "YOUR_API_KEY",
  "Endpoint": "YOUR_ENDPOINT",
  "Index": "YOUR_INDEX_NAME"
}</pre>
    </li>
    <li>
     
      Move to the
     
     <strong class="source-inline">
      
       Program.cs
      
     </strong>
     
      file of the server-side project.
     
     
      Below the builder and Azure OpenAI services initializations, intercept the search data access details into
     
     <strong class="source-inline">
      
       searchEndpoint
      
     </strong>
     
      ,
     
     <strong class="source-inline">
      
       searchApiKey
      
     </strong>
     
      , and
     
     
      <strong class="source-inline">
       
        searchIndex
       
      </strong>
     
     
      
       variables:
      
     
     <pre class="source-code">
var searchEndpoint = builder
    .Configuration["Search:Endpoint"];
var searchApiKey = builder
    .Configuration["Search:ApiKey"];
var searchIndex = builder
    .Configuration["Search:Index"];</pre>
    </li>
    <li>
     
      Below the intercepted search configuration, register
     
     <strong class="source-inline">
      
       ChatCompletionOptions
      
     </strong>
     
      as a singleton.
     
     
      As part of the
     
     <strong class="source-inline">
      
       ChatCompletionOptions
      
     </strong>
     
      initialization, build an
     
     <strong class="source-inline">
      
       AzureSearchChatDataSource
      
     </strong>
     
      instance and attach it to the constructed
     
     
      
       completion options:
      
     
     <pre class="source-code">
builder.Services.AddSingleton(services =&gt;
{
    var dataSource = new AzureSearchChatDataSource
    {
        Endpoint = new Uri(searchEndpoint),
        IndexName = searchIndex,
        Authentication = DataSourceAuthentication
            .FromApiKey(searchApiKey)
    };
    ChatCompletionOptions completionOptions = new();
    completionOptions.AddDataSource(dataSource);
    return completionOptions;
});</pre>
    </li>
    <li>
     
      At the time
     
     <a id="_idIndexMarker519">
     </a>
     
      of
     
     <a id="_idIndexMarker520">
     </a>
     
      writing, the
     
     <strong class="source-inline">
      
       Azure.AI.OpenAI
      
     </strong>
     
      package is in preview and your IDE may interpret using the
     
     <strong class="source-inline">
      
       AddDataSource()
      
     </strong>
     
      method of the
     
     <strong class="source-inline">
      
       ChatCompletionOptions
      
     </strong>
     
      class as a compilation error.
     
     
      To suppress the error, add the required
     
     <strong class="source-inline">
      
       #pragma
      
     </strong>
     
      directive at the top of the
     
     
      <strong class="source-inline">
       
        Program.cs
       
      </strong>
     
     
      
       file:
      
     
     <pre class="source-code">
#pragma warning disable AOAI001</pre>
    </li>
    <li>
     
      Navigate to the
     
     <strong class="source-inline">
      
       @code
      
     </strong>
     
      block of the
     
     <strong class="source-inline">
      
       ChatBot
      
     </strong>
     
      component and inject the
     
     <strong class="source-inline">
      
       ChatCompletionOptions
      
     </strong>
     
      instance next to the
     
     
      <strong class="source-inline">
       
        Chat
       
      </strong>
     
     
      
       client:
      
     
     <pre class="source-code">
[Inject]
private ChatCompletionOptions ChatOptions
{
    get; init;
}</pre>
    </li>
    <li>
     
      Still within the
     
     <strong class="source-inline">
      
       @code
      
     </strong>
     
      block, inside the
     
     <strong class="source-inline">
      
       SendMessage()
      
     </strong>
     
      method, locate where we invoke the
     
     <strong class="source-inline">
      
       CompleteChatAsync()
      
     </strong>
     
      method of the
     
     <strong class="source-inline">
      
       Chat
      
     </strong>
     
      service and pass
     
     <strong class="source-inline">
      
       ChatOptions
      
     </strong>
     
      as a
     
     
      
       second parameter:
      
     
     <pre class="source-code">
var chatResponse = await Chat
    .CompleteChatAsync(_messages, ChatOptions);</pre>
    </li>
   </ol>
   <h2 id="_idParaDest-379">
    <a id="_idTextAnchor379">
    </a>
    
     How it works…
    
   </h2>
   <p>
    
     In
    
    <em class="italic">
     
      step 1
     
    </em>
    
     , we navigate to the
    
    <strong class="source-inline">
     
      appsettings.json
     
    </strong>
    
     configuration file of the server-side project.
    
    
     We extend the configuration file with a
    
    <strong class="source-inline">
     
      Search
     
    </strong>
    
     section where we require the
    
    <strong class="source-inline">
     
      ApiKey
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      Endpoint
     
    </strong>
    
     , and
    
    
     <strong class="source-inline">
      
       Index
      
     </strong>
    
    
     
      values.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 2
     
    </em>
    
     , we stay on
    
    <a id="_idIndexMarker521">
    </a>
    
     the
    
    <a id="_idIndexMarker522">
    </a>
    
     server side but move to the
    
    <strong class="source-inline">
     
      Program.cs
     
    </strong>
    
     project entry file.
    
    
     We intercept the search configuration into
    
    <strong class="source-inline">
     
      searchEndpoint
     
    </strong>
    
     ,
    
    <strong class="source-inline">
     
      searchApiKey
     
    </strong>
    
     , and
    
    <strong class="source-inline">
     
      searchIndex
     
    </strong>
    
     variables, so we can use them to connect data to the
    
    
     
      Azure OpenAI.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 3
     
    </em>
    
     , we register a singleton
    
    <strong class="source-inline">
     
      ChatCompletionOptions
     
    </strong>
    
     object in the application’s dependency injection container.
    
    <strong class="source-inline">
     
      ChatCompletionOptions
     
    </strong>
    
     is used to configure the behavior of chat completions, allowing us to customize and extend the functionality of our chat service.
    
    
     As part of the
    
    <strong class="source-inline">
     
      ChatCompletionOptions
     
    </strong>
    
     initialization logic, we construct an instance of
    
    <strong class="source-inline">
     
      AzureSearchChatDataSource
     
    </strong>
    
     , which represents the search data connection details and requires providing an endpoint, API key, and index name.
    
    
     We’ve intercepted this from the
    
    <strong class="source-inline">
     
      appsettings.json
     
    </strong>
    
     file.
    
    
     We use the
    
    <strong class="source-inline">
     
      AddDataSource()
     
    </strong>
    
     method of the
    
    <strong class="source-inline">
     
      ChatCompletionOptions
     
    </strong>
    
     instance to attach the search
    
    
     
      data access.
     
    
   </p>
   <p>
    
     As
    
    <strong class="source-inline">
     
      Azure.AI.OpenAI
     
    </strong>
    
     is still in preview at the time of writing, your IDE may flag the use of the
    
    <strong class="source-inline">
     
      AddDataSource()
     
    </strong>
    
     method as a compilation error – that’s nothing to worry about.
    
    
     The Azure team will adjust this before releasing the stable package.
    
    
     For now, we can suppress the warning by adding a
    
    <strong class="source-inline">
     
      #pragma
     
    </strong>
    
     directive at the top of the
    
    <strong class="source-inline">
     
      Program.cs
     
    </strong>
    
     file with the
    
    <strong class="source-inline">
     
      AOAI001
     
    </strong>
    
     validation code we need to suppress, as we do in
    
    <em class="italic">
     
      step 4
     
    </em>
    
     .
    
    
     Next, we move to the
    
    <strong class="source-inline">
     
      ChatBot
     
    </strong>
    
     component and attach the enhanced completion options to
    
    
     
      our chatbot.
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 5
     
    </em>
    
     , we go straight to the
    
    <strong class="source-inline">
     
      @code
     
    </strong>
    
     block of the
    
    <strong class="source-inline">
     
      ChatBot
     
    </strong>
    
     component and inject the
    
    <strong class="source-inline">
     
      ChatCompletionOptions
     
    </strong>
    
     instance from the dependency injection container
    
    
     
      as
     
    
    
     <strong class="source-inline">
      
       ChatOptions
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     In
    
    <em class="italic">
     
      step 6
     
    </em>
    
     , we locate the
    
    <strong class="source-inline">
     
      SendMessage()
     
    </strong>
    
     method and find where we invoke the
    
    <strong class="source-inline">
     
      CompleteChatAsync()
     
    </strong>
    
     method of the
    
    <strong class="source-inline">
     
      Chat
     
    </strong>
    
     service to get a response from the Azure OpenAI.
    
    
     We’re already passing a
    
    <strong class="source-inline">
     
      _messages
     
    </strong>
    
     collection to the
    
    <strong class="source-inline">
     
      CompleteChatAsync()
     
    </strong>
    
     method, but it also accepts a second parameter of the
    
    <strong class="source-inline">
     
      ChatCompletionOptions
     
    </strong>
    
     type – that’s where we pass the injected
    
    <strong class="source-inline">
     
      ChatOptions
     
    </strong>
    
     instance
    
    <a id="_idIndexMarker523">
    </a>
    
     with
    
    <a id="_idIndexMarker524">
    </a>
    
     access to the Azure
    
    
     
      Search data.
     
    
   </p>
   <h2 id="_idParaDest-380">
    <a id="_idTextAnchor380">
    </a>
    
     There’s more…
    
   </h2>
   <p>
    
     You don’t have to have the data source and Azure OpenAI in the same resource group.
    
    
     In fact, you don’t even have to own the data source.
    
    
     Azure OpenAI will work correctly and generate contextualized results as long as you provide a valid set of configuration details.
    
    
     This flexibility allows you to leverage existing data sources and integrate them with Azure OpenAI seamlessly, enhancing the functionality of your applications without needing to consolidate or
    
    
     
      migrate resources.
     
    
   </p>
   <h2 id="_idParaDest-381">
    <a id="_idTextAnchor381">
    </a>
    
     See also
    
   </h2>
   <p>
    
     In the recipe implementation, we’ve used a
    
    <strong class="source-inline">
     
      #pragma
     
    </strong>
    
     preprocessor directive.
    
    
     Preprocessor directives have different purposes and allow adjusting your code behavior on a lower level.
    
    
     If
    
    <a id="_idIndexMarker525">
    </a>
    
     you’re
    
    <a id="_idIndexMarker526">
    </a>
    
     curious to learn more, check out this Microsoft
    
    
     
      Learn resource:
     
    
   </p>
   <p>
    <a href="https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/preprocessor-directives">
     
      
       https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/preprocessor-directives
      
     
    </a>
   </p>
  </div>
 </body></html>