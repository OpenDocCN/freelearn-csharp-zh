<html><head></head><body>
		<div><h1 id="_idParaDest-374" class="chapter-number"><a id="_idTextAnchor373"/>16</h1>
			<h1 id="_idParaDest-375"><a id="_idTextAnchor374"/>Running Applications On-Premises and in the Cloud</h1>
			<p>Up to the last chapter, we added additional functionality to the Codebreaker application; in <a href="B21217_15.xhtml#_idTextAnchor349"><em class="italic">Chapter 15</em></a>, we added services communicating with asynchronous communication. We used Azure Storage queues and Azure Event Hubs with the Azure Codebreaker variant; with the on-premises version, we added a Kafka container.</p>
			<p>In this chapter, we look at what needs to be known when deploying the solution to Microsoft Azure and to on-premises environments. Using Azure, we deployed the solution to an Azure Container Apps environment from <a href="B21217_05.xhtml#_idTextAnchor110"><em class="italic">Chapter 5</em></a> onward. The Azure Container Apps environment uses Kubernetes behind the scenes. In this chapter, we directly deploy to a Kubernetes cluster, which can easily be used in on-premises environments and in any cloud.</p>
			<p>In this chapter, you will learn about the following:</p>
			<ul>
				<li>Customizing deployment with C# and Aspire</li>
				<li>Creating a Kubernetes cluster with Azure</li>
				<li>Deploying the application to Kubernetes with Aspir8</li>
			</ul>
			<h1 id="_idParaDest-376"><a id="_idTextAnchor375"/>Technical requirements</h1>
			<p>With this chapter, like the previous chapters, you need an Azure subscription, .NET 8 with .NET Aspire, and Docker Desktop. In this chapter, we’ll use a new tool, Aspir8, to deploy the application to a Kubernetes cluster.</p>
			<p>The code for this chapter can be found in this GitHub repository: <a href="https://github.com/PacktPublishing/Pragmatic-Microservices-with-CSharp-and-Azure/">https://github.com/PacktPublishing/Pragmatic-Microservices-with-CSharp-and-Azure/</a>.</p>
			<p>In the <code>ch16</code> folder, you’ll see the projects that can be deployed. The most important project for this chapter is <code>Codebreaker.AppHost</code>, which defines the app model using Azure native cloud services, as well as a configuration that can be used with an on-premises environment. This configuration is also used to deploy the solution to a Kubernetes cluster.</p>
			<h1 id="_idParaDest-377"><a id="_idTextAnchor376"/>Thinking about deployment in production</h1>
			<p>The Codebreaker solution uses several different native Azure cloud services. In <a href="B21217_08.xhtml#_idTextAnchor183"><em class="italic">Chapter 8</em></a>, you saw how we can use <strong class="bold">GitHub Actions</strong> to<a id="_idIndexMarker1221"/> deploy to different environments, such as development, testing, staging, and production environments using approvals. As more and more services have been added in the last chapters, the deployments need to be updated as well.</p>
			<p>With many organizations, deployments<a id="_idIndexMarker1222"/> to production environments are somewhat disconnected from the development environment. Often, a different team from the development organization manages these deployments using different tools.</p>
			<p><strong class="bold">Continuous Integration</strong> (<strong class="bold">CI</strong>) and <strong class="bold">Continuous Development</strong> (<strong class="bold">CD</strong>) are often used in repositories<a id="_idIndexMarker1223"/> separated<a id="_idIndexMarker1224"/> from the source code. Different products such as GitHub Actions, Azure DevOps pipelines, and many third-party offerings are used.</p>
			<p>From the pipelines, it’s possible to trigger the Azure Developer CLI (azd), use Bicep scripts, directly use the Azure CLI or PowerShell scripts, or use third-party offerings such as Terraform, Ansible, Chef, and Puppet.</p>
			<p>When deciding between the different products, it’s also necessary to think about the requirements for the production environment, and what’s different from the development environment. With the production environment, different loads are expected. For a load test, it’s useful to run the same infrastructure as used with the production environment. With this, it’s important that the complete infrastructure for an environment needs to be easily creatable.</p>
			<p>The infrastructure needs to map the needs of the business – what income is lost if things are not working as expected? We need to think about these topics:</p>
			<ul>
				<li><strong class="bold">Scalability</strong>: Adapting to changing demands. Demand might increase slightly over time, or there might also be spikes in demand.</li>
				<li><strong class="bold">Reliability</strong>: Making sure that the services work as expected.</li>
				<li><strong class="bold">Availability</strong>: Making sure that the services are available from where the customers are. Availability metrics are <strong class="bold">Mean Time Between Failures</strong> (<strong class="bold">MTBF</strong>) – how<a id="_idIndexMarker1225"/> long until a failure happens – and <strong class="bold">Mean Time To Repair </strong>(<strong class="bold">MTTR</strong>) – how <a id="_idIndexMarker1226"/>long it takes until it’s running again.</li>
				<li><strong class="bold">Recovery</strong>: If there’s an <a id="_idIndexMarker1227"/>outage, recovery metrics that can be used are <strong class="bold">Recovery Point Time</strong> (<strong class="bold">RTO</strong>) – the acceptable time for apps to <a id="_idIndexMarker1228"/>be unavailable – and <strong class="bold">Recovery Point Objective</strong> (<strong class="bold">RPO</strong>) – the maximum allowed time for a data loss.</li>
			</ul>
			<p>These requirements need to be compared to the business needs. With <strong class="bold">redundancy</strong>, resources <a id="_idIndexMarker1229"/>are replicated, and multiple services are running. There’s not a single point of failure. Data can be replicated within one data center in an Azure region, between different data centers in an Azure region (Azure <strong class="bold">availability zones</strong>), and across different Azure regions (using a <strong class="bold">multi-region</strong> architecture).</p>
			<p>Another <a id="_idIndexMarker1230"/>requirement for the production environment is to enhance security. Data protection needs to make sure personal user data is safe. With <strong class="bold">encryption at rest</strong>, data is stored encrypted in the database. Instead of a service-managed key, customer-managed keys can be used. Using customer-managed keys is possible with many Azure services, but usually, different (more expensive) SKUs are required to enable customer-managed keys. Virtual networks are another option to enhance security. With subnets, it’s possible to restrict access to the database server. <strong class="bold">Private endpoints</strong> can be used to restrict<a id="_idIndexMarker1231"/> access only to a specific service and prevent data exfiltration. IP firewall rules can be configured.</p>
			<p>We can’t discuss all the different requirements here, but an important takeaway is that with production environments, we might need some additional Azure resources (such as virtual networks), different configurations, and other SKUs. See <em class="italic">Figure 16</em><em class="italic">.1</em> for the Codebreaker application making use of multiple Azure regions.</p>
			<div><div><img src="img/B21217_16_01.jpg" alt="Figure 16.1 – Codebreaker with virtual networks"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.1 – Codebreaker with virtual networks</p>
			<p>This<a id="_idIndexMarker1232"/> figure shows Azure regions in the US, Europe, and Asia, and Azure Cosmos DB replicated across the regions. The database is accessed from Container Apps running in the same region of the database. The frontends (Blazor) and backends (Game APIs) in one region can run in one Azure Container Apps environment, with the Game APIs service only accessible internally. Azure Application Gateway with a firewall configured is used to access the Blazor web application. Azure Traffic Manager can route across different regions.</p>
			<p>How does <a id="_idIndexMarker1233"/>the Codebreaker solution fulfill all the requirements? With scalability, reliability, and security, all the resources used by the application need to be verified. In <a href="B21217_12.xhtml#_idTextAnchor294"><em class="italic">Chapter 12</em></a>, we added a huge load on the Codebreaker services to test scaling up and scaling out. Due to the stateless nature of the developed services, the resources used also scale accordingly, and we anticipate no issues in meeting all the requirements. The Azure Cosmos DB database can replicate worldwide, even with multi-region writes to store games near the user for the best performance. We paid attention to the partition key, which doesn’t block other gamers’ writes to the database. Azure Event Hubs (added in <a href="B21217_15.xhtml#_idTextAnchor349"><em class="italic">Chapter 15</em></a>) offers a lot more performance than needed. The Standard SKU supports 1,000 events per second with one throughput unit. Additional throughput units can be added, and a switch to the Premium tier, which offers even more, could be done. An important aspect is to see what’s going on to react early, which was covered in <a href="B21217_11.xhtml#_idTextAnchor263"><em class="italic">Chapter 11</em></a>.</p>
			<p>While many organizations have separate teams for development and infrastructure, this has some disadvantages.</p>
			<p>Using the .NET Aspire <a id="_idIndexMarker1234"/>manifest created from the app model, we covered creating Bicep scripts in <a href="B21217_06.xhtml#_idTextAnchor137"><em class="italic">Chapter 6</em></a>. These Bicep scripts can be customized to fulfill the requirements of the production environment. Using customized Bicep scripts has the disadvantage that changes on the app model don’t automatically reflect with the Bicep script. The Bicep script needs to be manually updated again.</p>
			<p>It would be great to use C# code to completely define the Azure infrastructure configuration with all the different aspects needed. When the app model is updated with this, the infrastructure configuration is changed at the same time.</p>
			<h2 id="_idParaDest-378"><a id="_idTextAnchor377"/>Customizing deployments with C# and .NET Aspire</h2>
			<p>At the time of <a id="_idIndexMarker1235"/>this writing, enhancements are in progress to make this happen. Currently, it’s just in experimental mode, and the APIs available are likely to change, thus we will only look briefly into this.</p>
			<p>To define the .NET Aspire app model, APIs have an overload with a delegate parameter. For example, the <code>AddAzureKeyVault</code> method we used so far is an extension method for the <code>IDistributedApplicationBuilder</code> interface and uses a <code>name</code> parameter. A second overload specifies an additional <code>Action</code> delegate parameter. This overload has the <code>Experimental</code> attribute applied to mark that the API may change. The parameters used with this delegate are <code>IResourceBuilder&lt;AzureKeyVaultResource&gt;</code>, <code>ResourceModuleConstruct</code>, and <code>KeyVault</code>. This allows us to configure a secret retrieved from a parameter when creating Azure Key Vault:</p>
			<pre class="source-code">
#pragma warning disable AZPROVISION001
var aSecret = builder.AddParameter("aSecret", secret: true);
var keyVault = <strong class="bold">builder.AddAzureKeyVault("keyvault",</strong>
<strong class="bold">  (_, construct, _)</strong> =&gt;
  {
    var secret = new KeyVaultSecret(construct,
      name: "secret1");
    secret.AssignProperty(p =&gt; p.Properties.Value,
      aSecret);
  });
#pragma warning restore AZPROVISION001</pre>
			<p>With<a id="_idIndexMarker1236"/> the method used here, the first and third parameters of the delegate are ignored. The second parameter of the <code>ResourceModuleConstruct</code> type specifies the scope of creating <code>KeyVaultSecret</code> – it’s created for this Azure Key Vault.</p>
			<p>Another sample shows configuring properties and invoking method of a builder with an Azure Storage Account:</p>
			<pre class="source-code">
var storage = <strong class="bold">builder.AddAzureStorage</strong>("storage",
<strong class="bold">  (builder, _, account) =&gt;</strong>
  {
<strong class="bold">    builder.AddQueues("botqueue");</strong>
<strong class="bold">    builder.AddBlobs("checkpoints");</strong>
<strong class="bold">    account.AssignProperty(p =&gt; p.AccessTier, "Hot");</strong>
<strong class="bold">    account.AssignProperty(p =&gt; p.Sku.Name,</strong>
<strong class="bold">      "Standard_LRS");</strong>
  });</pre>
			<p>When creating the Azure Storage account, the <code>IResourceBuilder&lt;AzureStorageAccount&gt;</code> and <code>StorageAccount</code> parameters are used with the <code>Action</code> delegate, and the second parameter is ignored. <code>IResourceBuilder</code> is used to create a queue and a blob container with the storage account. We used these <code>AddQueues</code> and <code>AddBlobs</code> methods already without the experimental API invoking these methods with the return of <code>AddStorageAccount</code>. The <code>AddAzureStorage</code> method returns a builder. This is just for convenience defining this within this code block. The <code>StorageAccount</code> parameter is used to specify properties, setting the SKU to local redundancy, and the access tier to hot, which is cheaper for operations but more expensive for the storage.</p>
			<p>Many <a id="_idIndexMarker1237"/>organizations are in the process of changing the way to deploy and manage their infrastructure. Knowing about these developments can be useful to decide what direction should be taken, and what tools best fit the needs of the organization.</p>
			<p>For now, it’s very likely that the API will change – so use it with care. With the fast development pace of .NET Aspire, new features can improve fast, and this feature might be released not too far away (at the time of this writing). Check the README file of this chapter for updates.</p>
			<p>Next, we’ll look into easy deployment to Kubernetes.</p>
			<h1 id="_idParaDest-379"><a id="_idTextAnchor378"/>Creating a Kubernetes cluster with Microsoft Azure</h1>
			<p>While the Azure Container<a id="_idIndexMarker1238"/> Apps environment is based on Kubernetes, the Kubernetes tool (<strong class="bold">kubectl</strong>) cannot be used; the Kubernetes functionality is abstracted for simplification. Kubernetes is an open source system to scale and manage containerized applications and is used by many companies in their on-premises environment. With this, for many companies, it’s important to have the possibility to run services on-premises and in any cloud environment. See the <em class="italic">Further reading</em> section for links to learn more about Kubernetes.</p>
			<p>The Codebreaker application has been built with two launch profiles. We’ll publish the <code>OnPremises</code> launch profile to a Kubernetes cluster. With this launch profile, for example, Kafka is used instead of Azure Event Hubs.</p>
			<p>By having Docker Desktop installed, you can enable Kubernetes. This single-node cluster is just for a small test scenario. Instead, we’ll use a managed version of Kubernetes: The <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>). Compared to a self-installed cluster, installation and management <a id="_idIndexMarker1239"/>are a lot easier.</p>
			<p>Before creating the cluster, we need a new resource <a id="_idIndexMarker1240"/>group, and an <strong class="bold">Azure Container </strong><strong class="bold">Registry</strong> (<strong class="bold">ACR</strong>).</p>
			<p>Using the Azure CLI, create a new resource group:</p>
			<pre class="console">
az group create -l westeurope -n rg-codebreaker-kubernetes</pre>
			<p>Specify<a id="_idIndexMarker1241"/> an Azure region of your choice and specify a resource group name. Then, create a new ACR using <code>az </code><code>acr create</code>:</p>
			<pre class="console">
az acr create -g rg-codebreaker-kubernetes --sku Basic -l &lt;yourregion&gt; -n &lt;youracr&gt;</pre>
			<p>Use the previously created resource group, specify an SKU (the cheapest version, <code>Basic</code>, fits the purpose), and use a unique name for the registry.</p>
			<p> With this, create a new AKS in the <a id="_idIndexMarker1242"/>Azure portal (<a href="https://portal.azure.com">https://portal.azure.com</a>) – see <em class="italic">Figure 16</em><em class="italic">.2</em>.</p>
			<div><div><img src="img/B21217_16_02.jpg" alt="Figure 16.2 – Basic AKS configuration"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.2 – Basic AKS configuration</p>
			<p>Select the<a id="_idIndexMarker1243"/> resource group just created with the first dialog. With <strong class="bold">Cluster details</strong>, you can choose a preset configuration of either <strong class="bold">Production Standard</strong>, <strong class="bold">Dev/Test</strong>, <strong class="bold">Production Economy</strong>, and <strong class="bold">Production Enterprise</strong>. The virtual machine sizes are different based on the presets, and some features are differently configured. For example, <strong class="bold">Production Enterprise</strong> has a <strong class="bold">private cluster</strong> where <a id="_idIndexMarker1244"/>the API server is only accessible from an internal network. Select the <strong class="bold">Dev/Test</strong> preset for our test environment. Enter a cluster name and select the region of the cluster. All the other <strong class="bold">Basics</strong> settings can stay as their defaults – including the AKS pricing tier, <strong class="bold">Free</strong>. With the <strong class="bold">Free</strong> offering, a cost only applies for the nodes where our built Docker images are running and other services configured, such as managed Prometheus and Grafana. Be aware that every node instance you configure is a virtual machine that needs to be paid for. The <strong class="bold">Dev/Test</strong> preset setting is best for experimenting and testing with fewer than 10 nodes. With the <strong class="bold">Standard</strong> pricing tier, you can run up to 5,000 nodes in a cluster.</p>
			<p>After the configuration of the <strong class="bold">Basics</strong> settings, click <strong class="bold">Next</strong> to configure the node pools (<em class="italic">Figure 16</em><em class="italic">.3</em>).</p>
			<div><div><img src="img/B21217_16_03.jpg" alt="Figure 16.3 – AKS node pools"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.3 – AKS node pools</p>
			<p>The <a id="_idIndexMarker1245"/>default configuration for the node pool is <code>1</code>. System node pools need Linux for the operating system. These node pools run system pods. To run the applications, user node pools are preferred. For a cheaper test, we just use one node pool – a system node pool.</p>
			<p>When selecting the configuration of the pool, you can select the OS, the VM size, auto or manual scaling, the minimum and maximum node count, and the maximum pods per node. The allowed range is from 30–250 pods per node. One pod can run one or more containers. In most Kubernetes configurations, a pod runs one container. If the pod or the node where the pod runs fails, Kubernetes creates a replica.</p>
			<p>With the <strong class="bold">Node pools</strong> configuration, you can also enable virtual nodes. Virtual nodes make use of Azure Container Instances, which allow the fast startup of containers if more load is needed.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Creating user node pools allows you to select Windows for a node pool. This allows running legacy applications on Kubernetes. This is a difference AKS has to offer that’s not available with Azure Container Apps.</p>
			<p>After <a id="_idIndexMarker1246"/>the <strong class="bold">Node pools</strong> configuration, clicking <strong class="bold">Next</strong> leads to the <strong class="bold">Networking</strong> configuration. Leave this with the default settings. Clicking <strong class="bold">Next</strong> again opens the <strong class="bold">Integrations</strong> settings (see <em class="italic">Figure 16</em><em class="italic">.4</em>).</p>
			<div><div><img src="img/B21217_16_04.jpg" alt="Figure 16.4 – AKS Integrations settings"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.4 – AKS Integrations settings</p>
			<p>With the <strong class="bold">Integrations</strong> settings, select the previously created ACR. With AKS, a direct integration with the registry is offered.</p>
			<p>Clicking <code>OnPremises</code> launch profile, Docker containers for Grafana and Prometheus are configured. Alternatively, the Azure services Managed Prometheus and Managed Grafana could be used.</p>
			<p>Leave the remaining settings as default. By clicking on <strong class="bold">Review + create</strong>, the final checks are done. If this succeeds, click the <strong class="bold">Create</strong> button. Creating an AKS takes several minutes – but it’s a lot faster than creating a Kubernetes cluster manually.</p>
			<p>After deployment to the Kubernetes cluster succeeds, connect the Kubernetes command-line client, <code>kubectl</code>, to AKS. With Docker Desktop, this tool is installed with it. To connect <code>kubectl</code> to this AKS installation, use the following:</p>
			<pre class="console">
az aks get-credentials --resource-group &lt;your resource group&gt; --name &lt;your aks name&gt;</pre>
			<p>This<a id="_idIndexMarker1247"/> adds the connection to AKS to the <code>%HOMEPATH%/.kube/config</code> configuration file. Now, you can use the <code>kubectl</code> tool:</p>
			<pre class="console">
kubectl get nodes</pre>
			<p>This returns the running nodes from the AKS service.</p>
			<p>Next, let’s publish our application.</p>
			<h1 id="_idParaDest-380"><a id="_idTextAnchor379"/>Using Aspir8 to deploy to Kubernetes</h1>
			<p>With .NET Aspire, we <a id="_idIndexMarker1248"/>created the app model to define all the dependencies between the different resources that are used. First, in <a href="B21217_01.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, you saw the Aspire manifest that’s created from an app model. This manifest file is independent of any technology where to deploy it. The Azure Developer CLI creates Bicep scripts for deploying the solution (see <a href="B21217_06.xhtml#_idTextAnchor137"><em class="italic">Chapter 6</em></a> and <a href="B21217_08.xhtml#_idTextAnchor183"><em class="italic">Chapter 8</em></a>). The open source tool <strong class="bold">Aspirate</strong> (<strong class="bold">Aspir8</strong>) (see <a href="https://github.com/prom3theu5/aspirational-manifests">https://github.com/prom3theu5/aspirational-manifests</a>) converts the Aspire manifest file to Docker Compose or <a id="_idIndexMarker1249"/>Kubernetes with <strong class="bold">Helm</strong> charts <a id="_idIndexMarker1250"/>or <strong class="bold">kustomize</strong> manifests.</p>
			<p>You can create an Aspire manifest for every launch profile, like so:</p>
			<pre class="console">
cd Codebreaker.AppHost
dotnet run --launch-profile OnPremises -- --publisher manifest --output-path onpremises-manifest.json</pre>
			<p>Our app model is defined with two different versions. One version uses cloud-native Azure services, while the other option is independent of any cloud environment. The second one is configured by starting the application with the <code>OnPremises</code> launch profile.</p>
			<p>With <code>dotnet run</code>, we pass the <code>--launch-profile OnPremises</code> option to start the application using the profile as specified with the <code>launchprofiles.json</code> file. The <code>--</code> option is a separator to specify arguments to the running application. The <code>--publisher manifest</code> option creates the Aspire manifest file.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">We have a strict separation with the Codebreaker app model definition. It’s also possible in a somehow mixed mode. For example, you can use a solution running on-premises to use Azure Application Insights running within Azure to get the advantages of this cloud service offering. You can also use Azure Functions to run on an on-premises Kubernetes cluster. Many options are available to choose the service that best fits your needs.</p>
			<p>Before using the <code>aspirate</code> tool, it needs to be installed:</p>
			<pre class="console">
dotnet tool install -g aspirate --prerelease</pre>
			<p>At the<a id="_idIndexMarker1251"/> time of this writing, this tool is not released, thus it’s necessary to set the <code>--prerelease</code> option. The <code>-g</code> option installs this tool as a global tool.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">At the time of this writing, the <code>aspirate</code> tool is in a prerelease state, and changes are expected. Check the README file of <a href="B21217_16.xhtml#_idTextAnchor373"><em class="italic">Chapter 16</em></a> from the book’s repository for the latest updates deploying the Codebreaker application to Kubernetes.</p>
			<p>Optionally, you can specify an initial configuration with Aspir8:</p>
			<pre class="console">
cd Codebreaker.AppHost
aspirate init --launch-profile OnPremises</pre>
			<p>The <code>aspirate</code> tool allows specifying a launch profile similar to the .NET CLI to customize the configuration accordingly. By using <code>aspirate init</code>, you can specify a container builder and select between Docker Desktop and Podman. The default setting is Docker Desktop. With a fallback value for the container registry, enter the URL of the ACR you created. <code>aspirate init</code> creates the <code>aspirate-state.json</code> file with the configuration specified. You can rerun <code>aspirate init</code>, which overwrites this configuration file.</p>
			<h2 id="_idParaDest-381"><a id="_idTextAnchor380"/>Creating Kubernetes manifests</h2>
			<p>Let’s now use<a id="_idIndexMarker1252"/> the app model with the launch profile to generate manifests for publishing to Kubernetes:</p>
			<pre class="console">
aspirate generate --launch-profile OnPremises --output-path ./kustomize-output --skip-build --namespace codebreakerns</pre>
			<p><code>aspirate generate</code> can create Kubernetes manifests for deployment, as well as build and publish Docker images. Here, we don’t build Docker images by using the <code>--skip-build</code> option. With the <code>--launch-profile</code> option, the <code>AppHost</code> project with the app model is directly used. <code>aspirate generate</code> can also reference the previously generated .NET Aspire manifest with the <code>--aspirate-manifest</code> option instead. By setting <code>--output-path</code>, a different folder is specified to create the output result. The <code>--namespace</code> option is Kubernetes-related to define a namespace for the services deployed. This makes it easier to differentiate between the different services running on the cluster.</p>
			<p class="callout-heading">Note</p>
			<p class="callout"><code>aspirate</code> supports generating manifests using Helm and <code>kustomize</code>. Helm is a package manager that uses a packaging format named <code>kustomize</code> is a configuration manager natively built into <code>kubectl</code> with a template-free approach to patch and merge YAML files.</p>
			<p>Check the result of the <code>kustomize-output</code> folder. For every project specified, a folder is created (e.g., <code>gameapis</code>, <code>bot</code>, and <code>redis</code>) that contains <code>deployment.yaml</code>, <code>service.yaml</code>, and <code>kustomization.yaml</code>.</p>
			<p>A deployment defines a declarative configuration for a pod and a replica set. The “desired state” of a pod is described by the deployment. In this file, you can read and change the number of replicas used, and the containers running in a pod.</p>
			<p>A service defines a network application. This specifies the ports used with the application. A service runs in one or more pods.</p>
			<p>The <code>kustomization.yaml</code> file references both <code>deployment.yaml</code> and <code>service.yaml</code>, and specifies configuration values such as the environment variables you’ve seen <a id="_idIndexMarker1253"/>with the .NET Aspire dashboard.</p>
			<p>Having the manifest files ready, we can create Docker images and push them to the ACR.</p>
			<h2 id="_idParaDest-382"><a id="_idTextAnchor381"/>Creating and pushing Docker images</h2>
			<p>Using <code>aspirate build</code>, we can build and publish Docker images to the registry. With<a id="_idIndexMarker1254"/> the <code>aspirate</code> tool, it’s possible to specify username and password values to push images to private registries. When using ACR, this is not necessary because Aspir8 makes use of <code>dotnet publish</code>. Just make sure to log in to the ACR using the following:</p>
			<pre class="console">
az acr login –name &lt;yourregistry&gt;</pre>
			<p>Then, you can use <code>aspirate build</code>:</p>
			<pre class="console">
aspirate build --launch-profile OnPremises --container-image-tag 3.8 --container-image-tag latest --container-registry &lt;yourregistry&gt;.azurecr.io</pre>
			<p>Starting this command, specify the name of your registry. Specifying multiple tags will add them to the repository as shown in <em class="italic">Figure 16</em><em class="italic">.5</em>.</p>
			<div><div><img src="img/B21217_16_05.jpg" alt="Figure 16.5 – AKS repository"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.5 – AKS repository</p>
			<p>The <a id="_idIndexMarker1255"/>images are pushed to the ACR and show the <code>latest</code> and <code>3.8</code> tags, as specified with <code>aspirate build</code>. Next, deploy the images with the Kubernetes manifests to the cluster.</p>
			<h2 id="_idParaDest-383"><a id="_idTextAnchor382"/>Deploying to Kubernetes</h2>
			<p>Now, we<a id="_idIndexMarker1256"/> can apply the manifests to the Kubernetes cluster:</p>
			<pre class="console">
aspirate apply --input-path kustomize-output</pre>
			<p>The <code>aspirate apply</code> command uses the previously created manifest files to apply the services and deployments to the Kubernetes cluster by using the <code>kubectl apply</code> command. Just make sure to have AKS configured as the default Kubernetes environment (using the previously used command after creating AKS: <code>az </code><code>aks get-credentials</code>).</p>
			<p>Now, you can use the following command:</p>
			<pre class="console">
kubectl get deployments --namespace codebreakerns</pre>
			<p>This command shows the deployments from the <code>codebreakerns</code> namespace. You can see the deployments that are available and ready.</p>
			<p>Similarly, use this command to see the services:</p>
			<pre class="console">
kubectl get services --namespace codebreakerns</pre>
			<p>Here, you see the services with the IP addresses running, and the ports registered.</p>
			<p>Now, you <a id="_idIndexMarker1257"/>can configure an <code>aspirate</code>. For now, check the <em class="italic">Further reading</em> section to see how this can be done.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Aspir8 also supports Docker Compose besides Kubernetes with <code>kustomize</code> and Helm. By using <code>aspirate generate</code>, you can supply <code>compose</code> with the <code>--output-format</code> option. This creates a simple Docker Compose file that you can start with the Docker CLI.</p>
			<h1 id="_idParaDest-384"><a id="_idTextAnchor383"/>Summary</h1>
			<p>In this chapter, you learned about some final considerations for deploying applications using a microservices architecture in a production environment. You now have awareness of running the solution in multiple regions and using availability zones and can discuss the impact in your organization.</p>
			<p>You learned about AKS as a managed option to host a Kubernetes cluster and deploy the solution by using the .NET Aspire manifest to create deployments with Aspir8.</p>
			<p>By reaching <a href="B21217_16.xhtml#_idTextAnchor373"><em class="italic">Chapter 16</em></a> of this book, you’ve done an impressive tour, starting with minimal APIs, and adding more services from chapter to chapter using different technologies.</p>
			<p>With the book’s repository, the solution is planned to be updated to newer .NET and .NET Aspire versions. As newer versions become available, the book version will stay available in the <code>dotnet8</code> branch.</p>
			<p>To see more developments with Codebreaker, check the <a href="https://github.com/codebreakerapp">https://github.com/codebreakerapp</a> organization. There, you can see further developments of the solution, as well as a list of client applications. Also, check <a href="https://codebreaker.app">https://codebreaker.app</a> to play a few games – of course, now you can also use a version running in your (hosted) Kubernetes cluster.</p>
			<h1 id="_idParaDest-385"><a id="_idTextAnchor384"/>Further reading</h1>
			<p>To learn more about the topics discussed in this chapter, you can refer to the following links:</p>
			<ul>
				<li><em class="italic">Business continuity and disaster </em><em class="italic">recovery</em>: <a href="https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/management-business-continuity-disaster-recovery">https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/management-business-continuity-disaster-recovery</a></li>
				<li><em class="italic">Azure load-balancing </em><em class="italic">options</em>: <a href="https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview">https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview</a></li>
				<li>Kubernetes: <a href="https://kubernetes.io/">https://kubernetes.io/</a></li>
				<li>Learn Kubernetes basics: <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">https://kubernetes.io/docs/tutorials/kubernetes-basics/</a></li>
				<li>Helm – the package manager for Kubernetes: <a href="https://helm.sh">https://helm.sh</a></li>
				<li>The <code>kubectl</code> command-line tool: <a href="https://kubernetes.io/docs/reference/kubectl/">https://kubernetes.io/docs/reference/kubectl/</a></li>
				<li>Aspirate GitHub repository: <a href="https://github.com/prom3theu5/aspirational-manifests">https://github.com/prom3theu5/aspirational-manifests</a></li>
				<li><em class="italic">aspir8 from </em><em class="italic">scratch</em>: <a href="https://github.com/devkimchi/aspir8-from-scratch">https://github.com/devkimchi/aspir8-from-scratch</a></li>
				<li><em class="italic">Configure ingress with Azure Kubernetes </em><em class="italic">Services</em>: <a href="https://learn.microsoft.com/en-us/azure/aks/app-routing">https://learn.microsoft.com/en-us/azure/aks/app-routing</a></li>
				<li><em class="italic">Deploy a .NET microservice to Kubernetes </em><em class="italic">manually</em>: <a href="https://learn.microsoft.com/en-us/training/modules/dotnet-deploy-microservices-kubernetes/">https://learn.microsoft.com/en-us/training/modules/dotnet-deploy-microservices-kubernetes/</a></li>
				<li><code>kubectl</code> – the definitive pronunciation guide: <a href="https://www.youtube.com/watch?v=2wgAIvXpJqU">https://www.youtube.com/watch?v=2wgAIvXpJqU</a></li>
			</ul>
		</div>
	</body></html>