- en: Evaluating Performance Problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance evaluation for most software products is a very scientific process.
    First, we determine the maximum/minimum supported performance metrics, such as
    the allowed memory usage, acceptable CPU consumption, and the number of concurrent
    users. Next, we perform load testing against the application in scenarios with
    a version of the application built for the target platform, and test it while
    gathering instrumentation data. Once this data is collected, we analyze and search
    it for performance bottlenecks. If problems are discovered, we complete a **Root
    Cause Analysis** (**RCA**), and then make changes in the configuration or application
    code to fix the issue and repeat it.
  prefs: []
  type: TYPE_NORMAL
- en: Although game development is a very artistic process, it is still exceptionally
    technical. Our game should have a target audience in mind, which can tell us what
    hardware limitations our game might be operating under and, perhaps, tell us exactly
    what performance targets we need to meet (particularly in the case of console
    and mobile games). We can perform runtime testing on our application, gather performance
    data from multiple subsystems (CPU, GPU memory, the physics engine, the Rendering
    Pipeline, and so on), and compare them against what we consider to be acceptable.
    We can then use this data to identify bottlenecks in our application, perform
    additional instrumentation measurements, and determine the root cause of the issue.
    Finally, depending on the type of problem, we should be capable of applying a
    number of solutions to improve our application's performance.
  prefs: []
  type: TYPE_NORMAL
- en: However, before we spend even a single moment making performance fixes, we will
    first need to prove that a performance problem exists. It is unwise to spend time
    rewriting and refactoring code until there is a good reason to do so since pre-optimization
    is rarely worth the hassle. Once we have proof of a performance issue, the next
    task is figuring out exactly where the bottleneck is located. It is important
    to ensure that we understand why the performance issue is happening; otherwise,
    we could waste even more time applying fixes that are little more than educated
    guesses. Doing so often means that we only fix a symptom of the issue, not its
    root cause, and so we risk it manifesting itself in other ways in the future,
    or in ways we haven't yet detected.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will explore the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How to gather profiling data using the Unity Profiler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to analyze Profiler data for performance bottlenecks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Techniques to isolate a performance problem and determine its root cause
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With a thorough understanding of the problems you're likely to face, you will
    then be ready for the information presented in the remaining chapters, where you
    will learn what solutions are available for the types of issue we detect.
  prefs: []
  type: TYPE_NORMAL
- en: Gathering profiling data using the Unity Profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Unity Profiler is built into the Unity Editor itself and provides an expedient
    way of narrowing down our search for performance bottlenecks by generating usage
    and statistics reports on a multitude of Unity3D subsystems during runtime. The
    different subsystems for which it can gather data are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU consumption (per-major subsystem)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic and detailed rendering and GPU information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runtime memory allocations and overall consumption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Audio source/data usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Physics engine (2D and 3D) usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network messaging and operation usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Video playback usage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic and detailed user interface performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Global Illumination** (**GI**) statistics'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are generally two approaches to making use of a profiling tool: **instrumentation** and
    **benchmarking** (although, admittedly, the two terms are often used interchangeably).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Instrumentation** typically means taking a close look into the inner workings
    of the application by observing the behavior of targeted function calls, where/how
    much memory is being allocated, and, generally getting an accurate picture of
    what is happening with the hope of finding the root cause of a problem. However,
    this is normally not an efficient way of starting to identify performance problems
    because profiling of any application comes with a performance cost of its own.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When a Unity application is compiled in Development Mode (determined by the
    Development Build flag in the Build Settings menu), additional compiler flags
    are enabled causing the application to generate special events at runtime, which
    get logged and stored by the Profiler. Naturally, this will cause additional CPU
    and memory overhead at runtime due to all of the extra workload the application
    takes on. Even worse, if the application is being profiled through the Unity Editor,
    then even more CPU and memory use will be incurred, ensuring that the Editor updates
    its interface, renders additional windows (such as the Scene window), and handles
    background tasks. This profiling cost is not always negligible. In excessively
    large projects, it can sometimes cause all kinds of inconsistent and unexpected
    behavior when the Profiler is enabled: Unity can go out of memory, some scripts
    may refuse to run, physics may stop being updated (the time used for a frame may
    be so large that the physics engine reaches the maximum allowed updates per frame),
    and more. This is a necessary price we pay for a deep analysis of our code''s
    behavior at runtime, and we should always be aware of its implications. Therefore,
    before we get ahead of ourselves and start analyzing every line of code in our
    application, it would be wiser to do some **benchmarking.**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Benchmarking** involves performing a surface-level measurement of the application.
    We should gather some rudimentary data and perform test scenarios during a runtime
    session of our game while it runs on the target hardware; the test case could
    simply be, for example, a few seconds of gameplay, playback of a cutscene, or
    a partial playthrough of a level. The idea of this activity is to get a general
    feel for what the user might experience and keep watching for moments when performance
    becomes noticeably worse. Such problems may be severe enough to warrant further
    analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The important metrics we''re interested in when we carry out a benchmarking
    process are often the number of **frames per-second** (**FPS**) being rendered,
    overall memory consumption, how CPU activity behaves (looking for large spikes
    in activity), and sometimes CPU/GPU temperature. These are all relatively simple
    metrics to collect and can be used as a go-to first approach to performance analysis
    for one important reason: it will save us an enormous amount of time in the long
    run. It ensures that we only spend our time investigating problems that users
    would notice.'
  prefs: []
  type: TYPE_NORMAL
- en: We should dig deeper into instrumentation only after a benchmarking test indicates
    that further analysis is required. It is also very important to benchmark by simulating
    actual platform behavior as much as possible if we want a realistic data sample.
    As such, we should never accept benchmarking data that was generated through Editor
    mode as being representative of real gameplay, since Editor mode comes with some
    additional overhead costs that might mislead us, or hide potential race conditions
    in a real application. Instead, we should hook the profiling tool into the application
    while it is running in a standalone format on the target hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Many Unity developers are surprised to find that the Editor sometimes calculates
    the results of operations much faster than a standalone application does. This
    is particularly common when dealing with serialized data such as audio files,
    Prefabs, and scriptable objects. This is because the Editor will cache previously
    imported data and is able to access it much faster than a real application would.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's cover how to access the Unity Profiler and connect it to the target
    device so that we can start to make accurate benchmarking tests.
  prefs: []
  type: TYPE_NORMAL
- en: Users who are already familiar with connecting the Unity Profiler to their applications
    can skip to the section entitled *The Profiler window*.
  prefs: []
  type: TYPE_NORMAL
- en: Launching the Profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will begin with a brief tutorial on how to connect our game to the Unity
    Profiler within a variety of contexts:'
  prefs: []
  type: TYPE_NORMAL
- en: Local instances of the application, either through the Editor or a standalone
    instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local instances of a WebGL application running in a browser
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote instances of the application on an iOS device (for example, iPhone or
    iPad)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote instances of the application on an Android device (for example, an Android
    tablet or phone)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling the Editor itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will briefly cover the requirements for setting up the Profiler in each of
    these contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Editor or standalone instances
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this instance, the only way to access the Profiler is to launch it through
    the Unity Editor and connect it to a running instance of our application. We will
    use the same Profiler windows irrespective of whether we execute our game in Playmode
    within the Editor, running a standalone application on the local or remote device,
    or wish to profile the Editor itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'To open Profiler, navigate to Window | Analysis | Profiler within the Editor
    or use *Ctrl *+ *7* (or *cmd* + *7* on macOS):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1530dce-4911-423e-914d-10a6f3dd19c5.png)'
  prefs: []
  type: TYPE_IMG
- en: If the Editor is already running in Playmode, then we should see profiling data
    continuously populating the Profiler window.
  prefs: []
  type: TYPE_NORMAL
- en: To profile standalone projects, ensure that the Development Build and Autoconnect
    Profiler flags are enabled when the application is built.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing whether to profile an Editor-based instance (through the Editor''s
    Playmode) or a standalone instance (built and running separately from the Editor)
    can be achieved through the **Connected Player** option in the Profiler window:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e7529962-08ce-4474-85ed-d192f8e7178f.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that switching back to the Unity Editor while profiling a separate standalone
    project will halt all data collection since the application will not be updated
    while it is in the background.
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to a WebGL instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Profiler can also be connected to an instance of the Unity WebGL Player.
    This can be achieved by ensuring that the Development Build and Autoconnect Profiler flags
    are enabled when the WebGL application is built and run from the Editor. The application
    will then be launched through the operating system's default browser. This enables
    us to profile our web-based application in a more real-world scenario through
    the target browser and test multiple browser types for inconsistencies in behavior
    (although this requires us to keep changing the default browser).
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the Profiler connection can only be established when the application
    is first launched from the Editor. It currently cannot be connected to a standalone
    WebGL instance already running in a browser. This limits the accuracy of benchmarking
    WebGL applications since there will be some Editor-based overhead, but it's the
    only option we have available for the moment.
  prefs: []
  type: TYPE_NORMAL
- en: Remote connection to an iOS device
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Profiler can also be connected to an active instance of an application running
    remotely on an iOS device, such as an iPad or iPhone. This can be achieved through
    a shared Wi-Fi connection.
  prefs: []
  type: TYPE_NORMAL
- en: Note that remote connection to an iOS device is only possible when Unity (and
    hence the Profiler) is running on an Apple Mac device.
  prefs: []
  type: TYPE_NORMAL
- en: 'Observe the following steps to connect the Profiler to an iOS device:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that the Development Build and Autoconnect Profiler flags are enabled
    when the application is built
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect both the iOS device and macOS device to a local Wi-Fi network, or to
    an ad hoc Wi-Fi network
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Attach the iOS device to the macOS via the USB or Lightning Cable
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Begin building the application with the Build & Run option as usual
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Profiler window in the Unity Editor and select the device under Connected
    Player
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should now see the iOS device's profiling data gathering in the Profiler
    window.
  prefs: []
  type: TYPE_NORMAL
- en: The Profiler uses ports `54998` to `55511` to broadcast profiling data. Ensure
    that these ports are available for outbound traffic if there is a firewall on
    the network.
  prefs: []
  type: TYPE_NORMAL
- en: To troubleshoot problems with building iOS applications and connecting the Profiler
    to them, consult the following documentation page: [https://docs.unity3d.com/Manual/TroubleShootingIPhone.html](https://docs.unity3d.com/Manual/TroubleShootingIPhone.html).
  prefs: []
  type: TYPE_NORMAL
- en: Remote connection to an Android device
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two different methods for connecting an Android device to the Unity
    Profiler: either through a Wi-Fi connection or by using the **Android Debug Bridge**
    (**ADB**) tool. Either of these approaches will work from an Apple macOS, or a
    Windows PC.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to connect an Android device over a Wi-Fi connection:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that the Development Build and Autoconnect Profiler flags are enabled
    when the application is built
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect both the Android and desktop devices to a local Wi-Fi network
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Attach the Android device to the desktop device via a USB cable
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Begin building the application with the Build & Run option as usual
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Profiler window in the Unity Editor and select the device under Connected
    Player
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application should then be built and pushed to the Android device through
    the USB connection, and the Profiler should connect through the Wi-Fi connection.
    You should then see the Android device's profiling data gathering in the Profiler
    window.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second option is to use ADB. This is a suite of debugging tools that comes
    bundled with the Android **Software Development Kit** (**SDK**). For ADB profiling,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that the Android SDK is installed by following Unity's guide for Android
    SDK/NDK setup: [https://docs.unity3d.com/Manual/android-sdksetup.html](https://docs.unity3d.com/Manual/android-sdksetup.html)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the Android device to your desktop machine via the USB cable
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that the Development Build and Autoconnect Profiler flags are enabled
    when the application is built
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Begin building the application with the Build & Run option as usual
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the Profiler window in the Unity Editor and select the device under Connected
    Player
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should now see the Android device's profiling data gathering in the Profiler
    window.
  prefs: []
  type: TYPE_NORMAL
- en: To troubleshoot problems with building Android applications and connecting the
    Profiler to them, consult the following documentation page: [https://docs.unity3d.com/Manual/TroubleShootingAndroid.html](https://docs.unity3d.com/Manual/TroubleShootingAndroid.html).
  prefs: []
  type: TYPE_NORMAL
- en: Editor profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can profile the Editor itself. This is normally used when trying to profile
    the performance of custom editor scripts. This can be achieved by enabling the
    Profile Editor option in the Profiler window and configuring the Connected Player
    option to Editor, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/53496738-08bf-402c-a280-93be2f816519.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that both options must be configured if we want to profile the Editor: if
    nothing happens in the graph, then it is possible you have not selected the Profile
    Editor button, or you may accidentally be connected to another game build!
  prefs: []
  type: TYPE_NORMAL
- en: The Profiler window
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now cover the essential features of the Profiler as they can be found
    within the interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Profiler window is split into four main sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Profiler Controls**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timeline View**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Breakdown View Controls**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Breakdown View**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These sections are shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/eb1c0875-e544-4354-b637-6defaad06c16.png)'
  prefs: []
  type: TYPE_IMG
- en: We'll now cover each of these sections in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Timeline View has a lot of colors, but not everyone sees colors in the same
    way. Luckily, if you are colorblind, Unity has thought of you! In the top-right
    hamburger menu, you can enable Color Blind Mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66f6144d-0dfd-4b8c-889a-df58c9552b2d.png)'
  prefs: []
  type: TYPE_IMG
- en: Profiler controls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The top bar in the previous screenshot contains multiple drop-down and toggle
    buttons we can use to affect what is being profiled and how deeply in the subsystem
    that data is gathered from. These are covered in the next subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Add Profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By default, the Profiler will collect data for several different subsystems
    that cover the majority of the Unity engine's subsystems in Timeline View. These
    subsystems are organized into various areas containing relevant data. The Add
    Profiler option can be used to add additional areas or restore them if they have
    been removed. Refer to the Timeline View section for a complete list of subsystems
    we can profile.
  prefs: []
  type: TYPE_NORMAL
- en: Playmode
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Playmode drop-down lets us select the target instance of Unity we want to
    profile. This can be the current Editor application, a local standalone instance
    of our application, or an instance of our application running on a remote device.
  prefs: []
  type: TYPE_NORMAL
- en: Record
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enabling the Record option (the record icon) makes the Profiler record profiling
    data. This will happen continuously while this option is enabled. Note that runtime
    data can only be recorded if the application is actively running. For an app running
    in the Editor, this means that Playmode must be enabled and it should not be paused;
    alternatively, for a standalone app, it must be the active window. If Profile
    Editor is enabled, then the data that appears will be collected for the Editor
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Profile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ordinary profiling will only record the time and memory allocations made by
    common Unity callback methods, such as `Awake()`, `Start()`, `Update()`, and `FixedUpdate()`.
    Enabling the Deep Profile option recompiles our scripts with a much deeper level
    of instrumentation, allowing it to measure each and every invoked method. This
    causes a significantly greater instrumentation cost during runtime than normal,
    and uses substantially more memory since data is being collected for the entire
    callstack at runtime. As a consequence, deep profiling may not even be possible
    in large projects, as Unity may run out of memory before testing even begins,
    or the application may run so slowly as to make the test pointless.
  prefs: []
  type: TYPE_NORMAL
- en: Note that toggling Deep Profile requires the entire project to be completely
    recompiled before profiling can begin again, so it is best to avoid toggling the
    option back and forth between tests.
  prefs: []
  type: TYPE_NORMAL
- en: Since this option blindly measures the entire callstack, it would be unwise
    to keep it enabled during most of our profiling tests. This option is best reserved
    for when default profiling does not provide sufficient detail to figure out the
    root cause, or if we're testing the performance of a small test scene, which we're
    using to isolate certain activities.
  prefs: []
  type: TYPE_NORMAL
- en: If deep profiling is required for larger projects and scenes, but the Deep Profile
    option is too much of a hindrance during runtime, then there are alternative approaches
    that can be used to perform more detailed profiling; see the upcoming section
    entitled *Targeted profiling of code segments*.
  prefs: []
  type: TYPE_NORMAL
- en: Allocation Callstack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By activating the Allocation Callstack option, Unity Profiler will collect
    more info about the game''s memory allocations without requiring Deep Profile:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/501b0f1a-c916-4fd5-9122-f885a8edcf1d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If the option is enabled, you can click on the red boxes representing memory
    allocations and Profiler will show you the origin and the cause of that memory
    allocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e335a8b7-6a99-45be-ada0-4839996ffc9d.png)'
  prefs: []
  type: TYPE_IMG
- en: In Hierarchy view, instead, you still need to select an allocation call. Then,
    you need to switch to Show Related Objects in the drop-down menu in the upper-right
    corner and then select one of the N/A objects. After that, you'll see Callstack
    info in the box underneath.
  prefs: []
  type: TYPE_NORMAL
- en: We will talk more about memory allocations in [Chapter 8](eb7d9924-d92d-4cfa-ae68-ddd0f77a15a0.xhtml), *Masterful
    Memory Management*.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, in Unity 2019.1, Allocation Callstack works only when
    profiling in the Editor.
  prefs: []
  type: TYPE_NORMAL
- en: Clear
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Clear button clears all profiling data from Timeline View.
  prefs: []
  type: TYPE_NORMAL
- en: Load
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Load icon button will open up a dialog window to load in any previously
    saved profiling data (by using the Save option).
  prefs: []
  type: TYPE_NORMAL
- en: Save
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Save icon button saves any Profiler data currently presented in Timeline
    View to a file. Only 300 frames of data can be saved in this fashion at a time,
    and a new file must be manually created for any more data. This is typically sufficient
    for most situations, since, when a performance spike occurs, we then have about
    five to ten seconds to pause the application and save the data for future analysis
    (such as attaching it to a bug report) before it gets pushed off the left-hand
    side of Timeline View. Any saved Profiler data can be loaded into the Profiler
    for future examination using the Load option.
  prefs: []
  type: TYPE_NORMAL
- en: Frame Selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The frame selection area is composed of several sub-elements. The Frame Counter
    shows how many frames have been profiled and which frame is currently selected
    in Timeline View. There are two buttons to move the currently selected frame forward
    or backward by one frame and a third button (the Current button) that resets the
    selected frame to the most recent frame and keeps that position. This will cause
    Breakdown View to always show profiling data for the current frame during runtime
    profiling; it will display the word Current.
  prefs: []
  type: TYPE_NORMAL
- en: Timeline View
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Timeline View reveals during runtime,
  prefs: []
  type: TYPE_NORMAL
- en: A graphical representation of profiling data on the right
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A series of checkboxes (the colored squares in the following screenshot) to
    enable/disable different activities/data types on the left:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/3d14efc5-d723-440e-a9b2-b6fed6dddede.png)'
  prefs: []
  type: TYPE_IMG
- en: These colored boxes can be toggled, which changes the visibility of the corresponding
    data types within the graphical section of Timeline View.
  prefs: []
  type: TYPE_NORMAL
- en: When an area is selected in Timeline View, more detailed information for that
    subsystem will be revealed in Breakdown View (beneath Timeline View) for the currently
    selected frame. The kind of information displayed in Breakdown View varies depending
    on which area is currently selected in Timeline View.
  prefs: []
  type: TYPE_NORMAL
- en: Areas can be removed from Timeline View by clicking on the X in the top-right
    corner of an area. If you want to show an area that you removed again, you can
    use the Add Profiler option in the Controls bar.
  prefs: []
  type: TYPE_NORMAL
- en: At any time, we can click a location in the graphical part of Timeline View
    to reveal information about a given frame. A large vertical white bar will appear
    (usually with some additional information on either side coinciding with the line
    graphs), showing us which frame is selected.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on which area is currently selected (determined by which area is currently
    highlighted in blue), different information will be available in Breakdown View,
    and different options will be available in Breakdown View Controls. Changing the
    area that is selected is as simple as clicking on the relevant box on the left-hand
    side of Timeline View or on the graphical side; however, clicking inside the graphical
    area might also change which frame has been selected, so be careful clicking in
    the graphical area if you wish to see Breakdown View information for the same
    frame.
  prefs: []
  type: TYPE_NORMAL
- en: Breakdown View Controls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Different dropdowns and toggle button options will appear within Breakdown View
    Controls, depending on which area is currently selected in Timeline View. Different
    areas offer different controls, and these options dictate what information is
    available, and how that information is presented in Breakdown View.
  prefs: []
  type: TYPE_NORMAL
- en: Breakdown View
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The information revealed in Breakdown View will vary enormously based on which
    area is currently selected and which Breakdown View Controls options are selected.
    For instance, some areas offer different modes in a dropdown within Breakdown
    View Controls, which can provide Simple or Detailed views of the information or
    even a graphical layout of the same information so that it can be parsed more
    easily.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's cover each area and the different kinds of information and options
    available in Breakdown View.
  prefs: []
  type: TYPE_NORMAL
- en: The CPU Usage area
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This area shows data for all CPU Usage and statistics. It is perhaps the most
    complex and useful since it covers a large number of Unity subsystems, such as
    `MonoBehaviour` components, cameras, some rendering and physics processes, the
    user interface (including the Editor's interface, if we're running through the
    Editor), audio processing, the Profiler itself, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three different modes for displaying CPU Usage data in Breakdown
    View:'
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchy mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raw Hierarchy mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timeline mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s take a look at each of these modes individually:'
  prefs: []
  type: TYPE_NORMAL
- en: Hierarchy mode reveals most callstack invocations, while grouping similar data
    elements and global Unity function calls together for convenience. For instance,
    rendering delimiters, such as `BeginGUI()` and `EndGUI()` calls, are combined
    together in this mode. Hierarchy mode is helpful as an initial first step for
    determining which function calls take the most CPU time to execute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raw Hierarchy mode is similar to Hierarchy mode, except it will separate global
    Unity function calls into separate entries rather than their being combined into
    one bulk entry. This will tend to make Breakdown View more difficult to read,
    but may be helpful if we're trying to count how many times a particular global
    method is invoked, or for determining whether one of these calls is costing more
    CPU/memory than anticipated. For example, each `BeginGUI()` and `EndGUI()` call
    will be separated into different entries, making it clearer how many times each
    is being called compared to the Hierarchy mode.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perhaps the most useful mode for the CPU Usage area is the Timeline mode option
    (not to be confused with the main Timeline View). This mode organizes CPU Usage
    during the current frame in line with how the callstack expanded and contracted
    during processing.
  prefs: []
  type: TYPE_NORMAL
- en: Timeline mode organizes Breakdown View vertically into different sections that
    represent different threads at runtime, such as Main Thread, Render Thread, and
    various background job threads called the Unity Job System, used for loading activities
    such as scenes and other assets. The horizontal axis represents time, so wider
    blocks are consuming more CPU time than narrower blocks. The horizontal size also
    represents relative time, making it easy to compare how much time one function
    call took compared to another. The vertical axis represents the callstack, so
    deeper chains represent more calls in the callstack at that time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Under Timeline mode, blocks at the top of Breakdown View are functions (or,
    technically, callbacks) called by the Unity Engine at runtime (such as `Start()`,
    `Awake()`, or `Update()` ), whereas blocks beneath them are functions that those
    functions had called into, which can include functions on other components or
    regular C# objects.
  prefs: []
  type: TYPE_NORMAL
- en: The Timeline mode offers a very clean and organized way to determine which particular
    method in the callstack consumes the most time and how that processing time measures
    up against other methods being called during the same frame. This allows us to
    gauge the method that is the biggest cause of performance problems with minimal
    effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s assume that we are looking at a performance problem in
    the following screenshot. We can tell, with a quick glance, that there are three
    methods that are causing a problem, and they each consume similar amounts of processing
    time, due to their similar widths:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/23efdf47-d188-4d77-95dc-00c75d64bb89.png)'
  prefs: []
  type: TYPE_IMG
- en: In the previous screenshot, we have exceeded our 16.667 ms budget with calls
    to three different `MonoBehaviour` components. The good news is that we have three
    possible methods through which we can find performance improvements, which means
    lots of opportunities to find code that can be improved. The bad news is that
    increasing the performance of one method will only improve about one-third of
    the total processing for that frame. Hence, all three methods may need to be examined
    and optimized in order get back under budget.
  prefs: []
  type: TYPE_NORMAL
- en: It's a good idea to collapse the Unity Job System list when using Timeline mode,
    as it tends to obstruct the visibility of items shown in the Main Thread block,
    which is probably what we're most interested in.
  prefs: []
  type: TYPE_NORMAL
- en: In general, the CPU Usage area will be most useful for detecting issues that
    can be solved by solutions that will be explored in Chapter 2, *Scripting Strategies*.
  prefs: []
  type: TYPE_NORMAL
- en: The GPU Usage area
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The GPU Usage area is similar to the CPU Usage area, except that it shows method
    calls and processing time as it occurs on the GPU. Relevant Unity method calls
    in this area will relate to cameras, drawing, opaque and transparent geometry,
    lighting and shadows, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: The GPU Usage area offers hierarchical information similar to the CPU Usage
    area and estimates the time spent calling into various rendering functions such
    as `Camera.Render()` (provided rendering actually occurs during the frame currently
    selected in Timeline View).
  prefs: []
  type: TYPE_NORMAL
- en: The GPU Usage area will be a useful tool to refer to when you go through Chapter
    6, *Dynamic Graphics*.
  prefs: []
  type: TYPE_NORMAL
- en: The Rendering area
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Rendering area provides some generic rendering statistics that tend to focus
    on activities related to preparing the GPU for rendering, which involves a set
    of activities that occur on the CPU (as opposed to the act of rendering, which
    is an activity handled within the GPU and is detailed in the GPU Usage area).
    Breakdown View offers useful information, such as the number of SetPass calls
    (otherwise known as draw calls), the total number of batches used to render the
    scene, the number of batches saved from dynamic batching and static batching and
    how they are being generated, and memory consumed for textures.
  prefs: []
  type: TYPE_NORMAL
- en: The Rendering area also offers a button to open Frame Debugger, which will be
    explored more in Chapter 3, *The Benefits of Batching*. The remainder of this
    area's information will prove useful when you go through Chapter 3, *The Benefits
    of Batching*, and Chapter 6, *Dynamic Graphics*.
  prefs: []
  type: TYPE_NORMAL
- en: The Memory area
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Memory area allows us to inspect the memory usage of the application in
    Breakdown View in the following two modes:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple mode provides only a high-level overview of the memory consumption of
    subsystems. This include Unity's low-level Engine, the Mono framework (total heap
    size that is being watched by the garbage collector), graphical assets, audio
    assets and buffers, and even memory used to store data collected by the Profiler.
  prefs: []
  type: TYPE_NORMAL
- en: Detailed mode shows memory consumption of individual GameObjects and MonoBehaviours for
    both their native and managed representations. It also has a column explaining
    the reason why an object may be consuming memory and when it might be deallocated.
  prefs: []
  type: TYPE_NORMAL
- en: The garbage collector is a common feature provided by C#—the Unity's scripting
    language of choice—that automatically releases any memory we have allocated to
    store data; but, if it is handled poorly, it has the potential to stall our application
    for brief moments. This topic, and many more related topics, such as native and
    managed memory spaces, will be explored in Chapter 8, *Masterful Memory Management*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that information only appears in Detailed mode through manual sampling
    by clicking on the Take Sample <TargetName> button. This is the only way to gather
    information when using Detailed mode, since performing this kind of analysis automatically
    for each update would be prohibitively expensive:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/03671341-5f59-4a15-83b8-2ecce6434164.png)'
  prefs: []
  type: TYPE_IMG
- en: Breakdown View also provides a button labelled Gather Object References, which
    can gather more in-depth memory information pertaining to some objects.
  prefs: []
  type: TYPE_NORMAL
- en: The Memory area will be a useful tool to use when we dive into the complexities
    of memory management, native versus managed memory, and the garbage collector
    in Chapter 8, *Masterful Memory Management*.
  prefs: []
  type: TYPE_NORMAL
- en: The Audio area
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Audio area grants an overview of audio statistics and can be used both to
    measure CPU Usage from the audio system and total memory consumed by audio sources
    (both for those that are playing or paused) and audio clips.
  prefs: []
  type: TYPE_NORMAL
- en: Breakdown View provides lots of useful insights into how the audio system is
    operating and how various audio channels and groups are being used.
  prefs: []
  type: TYPE_NORMAL
- en: The Audio area may come in handy as we explore art assets in Chapter 4, *Optimizing
    Your Art Assets*.
  prefs: []
  type: TYPE_NORMAL
- en: Audio is often overlooked when it comes to performance optimization, but audio
    can become a surprisingly large source of bottlenecks if it is not managed properly
    due to the potential amount of hard disk access and CPU processing required. Don't
    neglect it!
  prefs: []
  type: TYPE_NORMAL
- en: The Physics 3D and Physics 2D areas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two different physics areas, one for Physics 3D  (NVIDIA 's PhysX),
    and another for the Physics 2D system (**Box2D**). This area provides various
    physics statistics, such as Rigidbody, Collider, and Contact counts.
  prefs: []
  type: TYPE_NORMAL
- en: The Breakdown View for each physics area provides some rudimentary insight into
    the subsystem's inner workings, but we can gain further insight by exploring the
    physics debugger, which we will introduce in Chapter 5, *Faster Physics*.
  prefs: []
  type: TYPE_NORMAL
- en: The network messages and network operations areas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These two areas provide information about Unity's networking system, which was
    introduced during the Unity 5 release cycle. The information present will depend
    on whether the application is using the **High-Level API** (**HLAPI**) or **Transport
    Layer API** (**TLAPI**) provided by Unity. HLAPI is an easier-to-use system for
    managing player and `GameObject` network synchronization automatically, whereas
    TLAPI is a thin layer that operates just above the socket level, allowing Unity
    developers to conjure up their own networking system.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing network traffic is a subject that fills an entire book all by itself,
    where the right solution is typically very dependent on the particular needs of
    the application. This will not be a Unity-specific problem, and, as such, the
    topic of network traffic optimization will not be explored in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The Video area
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If our application happens to make use of Unity's VideoPlayer API, then we might
    find this area useful for profiling video playback behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization of media playback is also a complex, non-Unity-specific topic and
    will not be explored in this book.
  prefs: []
  type: TYPE_NORMAL
- en: The UI and UI Details areas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These areas provide insight into applications making use of Unity's built-in
    user interface system. If we're using a custom-built or third-party user interface
    system (such as the popular Asset Store plugin **Next-Gen UI** (**NGUI**)), then
    these areas will probably provide little benefit.
  prefs: []
  type: TYPE_NORMAL
- en: A poorly optimized user interface can often affect one or both of the CPU and
    GPU, so we will investigate some code optimization strategies for UIs in Chapter
    2, *Scripting Strategies*, and graphics-related approaches in Chapter 6, *Dynamic
    Graphics*.
  prefs: []
  type: TYPE_NORMAL
- en: The Global Illumination area
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Global Illumination area gives us a very detailed insight into Unity's GI system.
    If our application makes use of GI, then we should refer to this area to verify
    that it is performing properly.
  prefs: []
  type: TYPE_NORMAL
- en: This area may prove useful as we explore lighting and shadowing in Chapter 6,
    *Dynamic Graphics*.
  prefs: []
  type: TYPE_NORMAL
- en: Best approaches to performance analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Good coding practices and project asset management often make finding the root
    cause of a performance issue relatively simple, at which point the only real problem
    is figuring out how to improve the code. For instance, if the method only processes
    a single gigantic `for` loop, then it will be a pretty safe assumption that the
    problem is either with how many iterations the loop is performing, whether or
    not the loop is causing cache misses by reading memory in a non-sequential fashion,
    how much work is done in each iteration, or how much work it takes to prepare
    for the next iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, whether we're working individually or in a group setting, a lot of
    our code is not always written in the cleanest way possible, and we should expect
    to have to profile some poor coding work from time to time. Sometimes, we are
    forced to implement a hacky solution for the sake of speed, and we don't always
    have the time to go back and refactor everything to keep up with our best coding
    practices. In fact, many code changes made in the name of performance optimization
    tend to appear very strange or arcane, often making our code base more difficult
    to read. The common goal of software development is to make code that is clean,
    feature-rich, and fast. Achieving one of these is relatively easy, but the reality
    is that achieving two will cost significantly more time and effort, while achieving
    all three is a near-impossibility.
  prefs: []
  type: TYPE_NORMAL
- en: At its most basic level, performance optimization is just another form of problem
    solving, and when we overlook the obvious while problem solving, it can be an
    expensive mistake. Our goal is to use benchmarking to observe our application
    looking for instances of problematic behavior, and to then use instrumentation
    to hunt through the code for clues about where the problem originates. Unfortunately,
    it's often very easy to get distracted by invalid data or jump to conclusions
    because we're being too impatient or have overlooked a subtle detail. Many of
    us have run into occasions during software debugging where we could have found
    the root cause of the problem much faster if we had simply challenged and verified
    our earlier assumptions. Hunting down performance issues is no different.
  prefs: []
  type: TYPE_NORMAL
- en: 'A checklist of tasks would be helpful to keep us focused on the issue, and
    ensure we don''t waste time by trying to implement any possible optimization that
    has no effect on the main performance bottleneck. Of course, every project is
    different, with its own unique challenges to overcome, but the following checklist
    is general enough that it should be able to apply to any Unity project:'
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the target script is present in the scene
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verify that the script appears in the scene the correct number of times
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verify the correct order of events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize ongoing code changes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize internal distractions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize external distractions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verifying script presence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, there are things we expect to see, but don't. These are usually easy
    to spot because the human brain is very good at pattern recognition and spotting
    differences we didn't expect. However, there are also times where we assume that
    something has been happening, but it didn't. These are generally more difficult
    to notice, because we're often scanning for the first kind of problem, and we’re
    assuming that the things we don't see are working as intended. In the context
    of Unity, one problem that manifests itself this way is verifying that the scripts
    we expect to be operating are actually present in the scene.
  prefs: []
  type: TYPE_NORMAL
- en: 'Script presence can be quickly verified by typing the following into the Hierarchy
    window textbox:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For example, typing `t:mytestmonobehaviour` (note that it is not case-sensitive)
    into the Hierarchy textbox will show a shortlist of all GameObjects that currently
    have at least one `MyTestMonoBehaviour` script attached as a component.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this shortlist feature also includes any GameObjects with components
    that derive from the given script name.
  prefs: []
  type: TYPE_NORMAL
- en: We should also double check that the GameObjects they are attached to are still
    enabled, since we may have disabled them during earlier testing since someone
    or something may have accidentally deactivated the object.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying script count
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we're looking at our Profiler data and note that a certain `MonoBehaviour`
    method is being executed more times than expected, or is taking longer than expected,
    we might want to double-check that it only occurs as many times in the scene as
    we expect it to. It's entirely feasible that someone created the object more times
    than expected in the scene file, or that we accidentally instantiated the object
    more than the expected number of times from code. If so, the problem could be
    due to conflicting or duplicated method invocations generating a performance bottleneck.
    We can verify the count using the same shortlist method used in the *Best approaches
    to performance analysis* section.
  prefs: []
  type: TYPE_NORMAL
- en: If we expected a specific number of components to appear in the scene, but the
    shortlist revealed more (or  fewer!) of these components, then it might be wise
    to write some initialization code that prevents this from ever happening again.
    We could also write some custom Editor helpers to display warnings to any level
    designers who might be making this mistake.
  prefs: []
  type: TYPE_NORMAL
- en: Preventing casual mistakes such as this is essential for good productivity,
    since experience tells us that, if we don't explicitly disallow something, then
    someone, somewhere, at some point, for whatever reason, will do it anyway. This
    is likely to cost us a frustrating afternoon hunting down a problem that eventually
    turned out to be caused by human error.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying the order of events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unity applications mostly operate as a series of callbacks from *Native code*
    to *Managed code*. This concept will be explained in more detail in Chapter 8,
    *Masterful Memory Management*, but for the sake of a brief summary, Unity's main
    thread doesn't operate as a simple console application would. In such applications,
    code would be executed with some obvious starting point (usually a `main()` function),
    and we would then have direct control of the game engine, where we initialize
    major subsystems, and then the game runs in a big `while` loop (often called the
    game loop) that checks for user input, updates the game, renders the current scene,
    and repeats. This loop only exits once the player chooses to quit the game.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, Unity handles the game loop for us, and we expect callbacks such as `Awake()`,
    `Start()`, `Update()`, and `FixedUpdate()` to be called at specific moments. The
    big difference is that we don't have fine-grained control over the order in which
    events of the same type are called. When a new scene is loaded (whether it's the
    first scene of the game or a later scene), every `MonoBehaviour` component's `Awake()`
    callback gets called, but there's no way of predicting the order in which this
    will happen.
  prefs: []
  type: TYPE_NORMAL
- en: So, if we take one set of objects that configure some data in their `Awake()`
    callback, and then another set of objects does something with that configured
    data in its own `Awake()` callback, some reorganization or recreation of scene
    objects or a random change in the code base or compilation process (it's unclear
    what exactly causes it) may cause the order of these `Awake()` calls to change,
    and then the dependent objects will probably try to do things with data that wasn't
    initialized how we expected. The same goes for all other callbacks provided by
    `MonoBehaviour` components, such as `Start()` and `Update()`.
  prefs: []
  type: TYPE_NORMAL
- en: In any sufficiently complex project, there's no way of telling the order in
    which the same type of callback gets called among a group of `MonoBehaviour` components,
    so we should be very careful not to assume that object callbacks are happening
    in a specific order. In fact, it is essential practice to never write code in
    a way that assumes these callbacks will need to be called in a certain order because
    it could break at any time.
  prefs: []
  type: TYPE_NORMAL
- en: A better place to handle late-stage initialization is in a `MonoBehaviour` component's
    `Start()` callback, which is always called after every object's `Awake()` callback
    is called and just before its first `Update()` call. Late-stage updates can also
    be done in the `LateUpdate()` callback.
  prefs: []
  type: TYPE_NORMAL
- en: If you're having trouble determining the actual order of events, then this is
    best handled by either step-through debugging with an IDE (MonoDevelop, Visual
    Studio, and so on) or by printing simple logging statements with `Debug.Log()`.
  prefs: []
  type: TYPE_NORMAL
- en: Be warned that Unity's logger is notoriously expensive. Logging is unlikely
    to change the order of the callbacks, but it can cause some unwanted spikes in
    performance if used too aggressively. Be smart and do targeted logging only on
    the most relevant parts of the code base.
  prefs: []
  type: TYPE_NORMAL
- en: Coroutines are typically used to script some sequence of events, and when they're
    triggered will depend on what `yield` types are being used. The most difficult
    and unpredictable type to debug is perhaps the `WaitForSeconds` yield type. The
    Unity Engine is non-deterministic, meaning that you'll get a slightly different
    behavior from one session to the next, even on the same hardware. For example,
    you might get 60 updates called during the first second of application runtime
    during one session, 59 in the next, and 62 in the one after that. In another session,
    you might get 61 updates in the first second, followed by 60, and then 59.
  prefs: []
  type: TYPE_NORMAL
- en: A variable number of `Update()` callbacks will be called between when the coroutine
    starts and when it ends, and so if the coroutine depends on the `Update()` function
    of something being called a specific number of times, we will run into problems.
    It's best to keep a coroutine's behavior dead simple and dependency-free of other
    behavior once it begins. Breaking this rule may be tempting, but it's essentially
    guaranteed that some future change is going to interact with the coroutine in
    an unexpected way, leading to a long, painful debugging session for a game-breaking
    bug that's very hard to reproduce.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing ongoing code changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Making code changes to the application in order to hunt down performance issues
    is best done carefully, as the changes are easy to forget as time wears on. Adding
    debug logging statements to our code can be tempting, but remember that it costs
    us time to introduce these calls, recompile our code, and remove these calls once
    our analysis is complete. In addition, if we forget to remove them, then they
    can incur unnecessary runtime overhead in the final build since Unity's debug
    Console window logging can be prohibitively expensive in terms of both CPU and
    memory.
  prefs: []
  type: TYPE_NORMAL
- en: A good way to combat this problem is to add a flag or comment anywhere we made
    a change with our name so that it's easy to find and remove it later. Hopefully,
    we're also wise enough to use a source control tool for our code base, making
    it easy to differentiate between the content of any modified files and revert
    them to their original state. This is an excellent way to ensure that unnecessary
    changes don't make it into the final version. Of course, this is by no means a
    guaranteed solution if we also applied a fix at the same time and didn't double-check
    all of our modified files before committing the change.
  prefs: []
  type: TYPE_NORMAL
- en: Making use of breakpoints during runtime debugging is the preferred approach,
    as we can trace the full callstack, variable data, and conditional code paths
    (for example, `if-else` blocks), without risking any code changes or wasting time
    on recompilation. Of course, this is not always an option if, for example, we're
    trying to figure out what causes something strange to happen in one out of a thousand
    frames. In this case, it's better to determine a threshold value to look for and
    add an `if` statement, with a breakpoint inside, which will be triggered when
    the value has exceeded the threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing internal distractions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Unity Editor has its own little quirks and nuances, which can sometimes
    make it confusing to debug some kinds of problems.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, if a single frame takes a long time to process, such that our game
    noticeably freezes, then the Profiler may not be capable of picking up the results
    and recording them in the Profiler window. This can be especially annoying if
    we wish to catch data during application/scene initialization. The *Custom CPU
    profiling*, section later will offer some alternatives to explore with a view
    to solving this problem.
  prefs: []
  type: TYPE_NORMAL
- en: One common mistake (that I have admittedly fallen victim to multiple times during
    the writing of this book) is that if we are trying to initiate a test with a keystroke
    and have the Profiler window open, we should not forget to click back into the
    Editor's Game window before triggering the keystroke. If the Profiler is the most
    recently clicked window, then the Editor will send keystroke events to that, instead
    of the runtime application, and hence, no `GameObject` will catch the event for
    that keystroke. This can also apply to the GameView for rendering tasks and even
    coroutines using the `WaitForEndOfFrame` yield type. If the Game window is not
    visible and active in the Editor, then nothing is being rendered to that view,
    and therefore, no events that rely on Game window rendering will be triggered.
    Be warned!
  prefs: []
  type: TYPE_NORMAL
- en: Vertical sync (otherwise known as VSync) is used to match the application's
    frame rate to the frame rate of the device it is being displayed to; for example,
    a monitor may run at 60 Hertz (60 cycles per second, about 16 ms). If a rendering
    loop in our game is running faster than a monitor cycle – for instance, 10 ms
    – then the game will sit and wait for another 6 ms before outputting the rendered
    frame. This feature reduces screen tearing, which occurs when a new image is pushed
    to the monitor before the previous image was finished, and, for a brief moment,
    part of the new image overlaps the old image.
  prefs: []
  type: TYPE_NORMAL
- en: Executing the Profiler with VSync enabled will probably generate a lot of noisy
    spikes in the CPU Usage area under the WaitForTargetFPS heading, as the application
    intentionally slows itself down to match the frame rate of the display. These
    spikes often appear very large in Editor mode, since the Editor is typically rendering
    to a very small window, which doesn’t take a lot of CPU or GPU work to render.
  prefs: []
  type: TYPE_NORMAL
- en: This will generate unnecessary clutter, making it harder to spot the real issue(s).
    We should ensure that we disable the VSync checkbox under the CPU Usage area when
    we're on the lookout for CPU spikes during performance tests. We can disable the
    VSync feature entirely by navigating to Edit | Project Settings | Quality and
    then to the sub-page for the currently selected platform.
  prefs: []
  type: TYPE_NORMAL
- en: We should also ensure that a drop in performance isn't a direct result of a
    massive number of exceptions and error messages appearing in the Editor Console
    window. Unity's `Debug.Log()` and similar methods, such as `Debug.LogError()` and
  prefs: []
  type: TYPE_NORMAL
- en: '`Debug.LogWarning()`, are notoriously expensive in terms of CPU Usage and heap
    memory consumption, which can then cause garbage collection to occur resulting
    in even more lost CPU cycles (refer to Chapter 8, *Masterful Memory Management*,
    for more information on these topics).'
  prefs: []
  type: TYPE_NORMAL
- en: This overhead is usually unnoticeable to a human being looking at the project
    in Editor mode, where most errors come from the compiler or misconfigured objects.
    However, they can be problematic when used during any kind of runtime process,
    especially during profiling, where we wish to observe how the game runs in the
    absence of external disruptions. For example, if we are missing an object reference
    that we were supposed to assign through the Editor, and it is being used in an
    `Update()` callback, then a single `MonoBehaviour` instance could throw new exceptions
    every single update. This adds lots of unnecessary noise to our profiling data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that we can hide different log level types with the buttons shown in the
    next screenshot. The extra logging still costs CPU and memory to execute, even
    though they are not being rendered, but it does allow us to filter out the junk
    we don''t want. However, it is often good practice to keep all of these options
    enabled to verify that we''re not missing anything important:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc862c86-4275-48b0-9ebc-e547a0490e38.png)'
  prefs: []
  type: TYPE_IMG
- en: Minimizing external distractions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This one is simple, but absolutely necessary. We should double-check that there
    are no background processes eating away CPU cycles or consuming vast swathes of
    memory. Being low on available memory will generally interfere with our testing,
    as it can cause more cache misses, hard drive access for virtual memory page-file
    swapping, and generally slow responsiveness on the part of the application. If
    our application is suddenly behaving significantly worse than anticipated, double-check
    the system's task manager (or equivalent) for any CPU/memory/hard disk activity
    that might be causing problems.
  prefs: []
  type: TYPE_NORMAL
- en: Targeted profiling of code segments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If our performance problem isn't resolved by the checklist mentioned previously,
    then we probably have a real issue on our hands that demands further analysis.
    The Profiler window is effective at showing us a broad overview of performance;
    it can help us find specific frames to investigate and can quickly inform us which
    `MonoBehaviour` and/or method may be causing issues. We would then need to figure
    out whether the problem is reproducible, under what circumstances a performance
    bottleneck arises, and from where exactly within the problematic code block the
    issue is originating.
  prefs: []
  type: TYPE_NORMAL
- en: 'To accomplish these, we will need to perform some profiling of targeted sections
    of our code, and there are a handful of useful techniques we can employ for this
    task. For Unity projects, they essentially fit into two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Controlling the Profiler from script code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom timing and logging methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the next section focuses on how to investigate scripting bottlenecks
    through C# code. Detecting the source of bottlenecks in other engine subsystems
    will be discussed in their related chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Profiler script control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Profiler can be controlled in script code through the `Profiler` class.
    There are several useful methods in this class that we can explore within the
    Unity documentation, but the most important methods are the delimiter methods
    that activate and deactivate profiling at runtime. These can be accessed through
    the `UnityEngine.Profiling.Profiler` class through its `BeginSample()` and `EndSample()` methods.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the delimiter methods, `BeginSample()` and `EndSample()`, are only
    compiled in development builds, and, as such, they will not be compiled or executed
    in release builds where Development Mode is unchecked. This is commonly known
    as **non-operation**, or **no-op**, code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `BeginSample()` method has an overload that allows a custom name for the
    sample to appear in the CPU Usage area''s Hierarchy mode. For example, the following
    code will profile invocations of this method and make the data appear in Breakdown
    View under a custom heading, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can download the example code files from your account at [http://www.packtpub.com](http://www.packtpub.com)
    for all the *Packt Publishing* books you have purchased. If you purchased this
    book elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should expect that invoking this poorly designed method (which generates
    a `List` containing a million integers, and then does absolutely nothing with
    it) will cause a huge spike in CPU Usage, chew up several megabytes of memory,
    and appear in the Profiler Breakdown View under the My Profiler Sample heading, as
    shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d8dc0c20-ec0f-44a7-80e9-21dd1dec1d94.png)'
  prefs: []
  type: TYPE_IMG
- en: Custom CPU profiling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Profiler is just one tool at our disposal. Sometimes, we may want to perform
    customized profiling and logging of our code. Maybe we're not confident that the
    Unity Profiler is giving us the right answer, maybe we consider its overhead cost
    too great, or maybe we just like having complete control of every single aspect
    of our application. Whatever our motivations, knowing some techniques to perform
    an independent analysis of our code is a useful skill to have. It's unlikely we'll
    only be working with Unity for the entirety of our game development careers, after
    all.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling tools are generally very complex, so it's unlikely we would be able
    to generate a comparable solution on our own within a reasonable time frame. When
    it comes to testing CPU Usage, all we should really need is an accurate timing
    system, a fast, low-cost way of logging that information, and some piece of code
    to test against. It just so happens that the .NET library (or, technically, the
    Mono framework) comes with a `Stopwatch` class under the `System.Diagnostics`
    namespace. We can stop and start a `Stopwatch` object at any time, and we can
    easily acquire a measure of how much time has passed since the `Stopwatch` object
    was started.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, this class is not perfectly accurate; it is accurate only to
    milliseconds, or tenths of a millisecond, at best. Counting in a high-precision,
    real-time manner with a CPU clock can be a surprisingly difficult task when we
    start to get into it. So, in order to avoid a detailed discussion of the topic,
    we should try to find a way for the `Stopwatch` class to satisfy our needs.
  prefs: []
  type: TYPE_NORMAL
- en: If precision is important, then one effective way to increase it is by running
    the same test multiple times. Assuming that the test code block is both easily
    repeatable and not exceptionally long, we should be able to run thousands, or
    even millions, of tests within a reasonable time frame and then divide the total
    elapsed time by the number of tests we just performed to get a more accurate time
    for a single test.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get obsessed with the topic of high precision, we should first ask
    ourselves if we even need it. Most games expect to run at 30 FPS or 60 FPS, which
    means that they only have around 33 ms or 16 ms, respectively, to compute everything
    for the entire frame. So, hypothetically, if we need to bring only the performance
    of a particular code block under 10 ms, then repeating the test thousands of times
    to get microsecond precision is too many orders of magnitude away from the target
    to be worthwhile.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a class definition for a custom timer that uses a `Stopwatch` object
    to count time for a given number of tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Adding an underscore before member variable names is a common and useful way
    of distinguishing a class's member variables (also known as fields) from a method's
    arguments and local variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of `CustomTimer` class usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'There are three things to note when using this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, we are only making an average of multiple method invocations. If processing
    time varies enormously between invocations, then that will not be well represented
    in the final average.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, if memory access is common, then repeatedly requesting the same blocks
    of memory will result in an artificially higher cache hit rate (where the CPU
    can find data in memory very quickly because it's accessed the same region recently),
    which will bring the average time down when compared to a typical invocation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thirdly, the effects of **Just-In-Time** (**JIT**) compilation will be effectively
    hidden for similarly artificial reasons, as it only affects the first invocation
    of the method. JIT compilation is a .NET feature that will be covered in more
    detail in Chapter 8, *Masterful Memory Management*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `using` block is typically used to safely ensure that unmanaged resources
    are properly destroyed when they go out of scope. When the `using` block ends,
    it will automatically invoke the object's `Dispose()` method to handle any cleanup
    operations. In order to achieve this, the object must implement the `IDisposable`
    interface, which forces it to define the `Dispose()` method.
  prefs: []
  type: TYPE_NORMAL
- en: However, the same language feature can be used to create a distinct code block,
    which creates a short-term object, which then automatically processes something
    useful when the code block ends; this is how it is being used in the preceding
    code block.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `using` block should not be confused with the `using` statement,
    which is used at the start of a script file to pull in additional namespaces.
    It's extremely ironic that the keyword for managing namespaces in C# has a naming
    conflict with another keyword.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, the `using` block and the `CustomTimer` class give us a clean way
    of wrapping our test code that makes it obvious when and where it is being used.
  prefs: []
  type: TYPE_NORMAL
- en: Something else to worry about is application warm-up time. Unity has a significant
    start-up cost when a scene begins, given the amount of data that needs to be loaded
    from disk, the initialization of complex subsystems, such as the physics and rendering
    systems, and the number of calls to various `Awake()` and `Start()` callbacks
    that need to be resolved before anything else can happen. This early overhead
    might only last a second, but that can have a significant effect on the results
    of our testing if the code is also executed during this early initialization period.
    This makes it crucial that, if we want an accurate test, then any runtime testing
    should begin only after the application has reached a steady state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ideally, we would be able to execute the target code block in its own scene
    after its initialization has completed. This is not always possible; so, as a
    backup plan, we could wrap the target code block in an `Input.GetKeyDown()` check
    in order to assume control over it when it is invoked. For example, the following
    code will execute our test method only when the spacebar is pressed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As mentioned previously, Unity's Console window logging mechanism is prohibitively
    expensive. As a result, we should try not to use these logging methods in the
    middle of a profiling test (or during gameplay, for that matter). If we find ourselves
    absolutely in need of detailed profiling data that prints out lots of individual
    messages (such as performing a timing test on a loop to figure out which iteration
    is costing more time than the rest), then it would be wiser to cache the logging
    data and print it all out at the end, as the `CustomTimer` class does. This will
    reduce runtime overhead, at the cost of some memory consumption. The alternative
    is that many milliseconds are lost to printing each `Debug.Log()` message in the
    middle of the test, which pollutes the results.
  prefs: []
  type: TYPE_NORMAL
- en: The `CustomTimer` class also makes use of `string.Format()`. This will be covered
    in more detail in Chapter 8, *Masterful Memory Management*, but a short explanation
    is that this method is used because generating a custom `string` object using
    the `+` operator (for example, code such as `Debug.Log("Test: " + output);`) can
    result in a surprisingly large number of memory allocations, which attracts the
    attention of the garbage collector. Doing otherwise would conflict with our goal
    of achieving accurate timing and analysis and should be avoided.
  prefs: []
  type: TYPE_NORMAL
- en: Final thoughts on profiling and analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way of thinking about performance optimization is *the act of stripping
    away unnecessary tasks that waste valuable resources*. We can do the same and
    maximize our own productivity by minimizing any wasted effort. Effective use of
    the tools we have at our disposal is of paramount importance. It would serve us
    well to optimize our own workflow by remaining aware of some best practices and
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most, if not all, advice for using any kind of data-gathering tool properly
    can be summarized into three different strategies:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the tool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing noise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focusing on the issue
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the Profiler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Profiler is a well-designed and intuitive tool, so understanding the majority
    of its feature set can be gained by simply spending an hour or two exploring its
    options with a test project and reading its documentation. The more we know about
    a tool in terms of its benefits, pitfalls, features, and limitations, the more
    sense we can make of the information it is giving us, so it is worth spending
    the time to use it in a playground setting. We don't want to be two weeks away
    from release, with a hundred performance defects to fix, with no idea how to do
    performance analysis efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: For example, always remain aware of the relative nature of Timeline View graphical
    display. Timeline View does not provide values on its vertical axis and automatically
    readjusts this axis based on the content of the last 300 frames; it can make small
    spikes appear to be a bigger problem than they really are because of the relative
    change. So, just because a spike or resting state in the timeline seems large
    and threatening does not necessarily mean there is a performance issue.
  prefs: []
  type: TYPE_NORMAL
- en: Several areas in Timeline View provide helpful benchmark bars, which appear
    as horizontal lines with a timing and FPS value associated with them. These should
    be used to determine the magnitude of the problem. Don't let the Profiler trick
    us into thinking that big spikes are always bad. As always, it's only important
    if the user will notice it.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, if a large CPU Usage spike does not exceed the 60 FPS or 30 FPS
    benchmark bars (depending on the application's target frame rate), then it would
    be wise to ignore it and search elsewhere for CPU performance issues, since no
    matter how much we improve the offending piece of code, it will probably never
    be noticed by the end user, and therefore isn't a critical issue that affects
    user experience.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing noise
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The classical definition of noise (at least in the realm of computer science)
    is meaningless data, and a batch of profiling data that was blindly captured with
    no specific target in mind is always full of data that won't interest us. More
    sources of data take more time to mentally process and filter, which can be very
    distracting. One of the best methods to avoid this is to simply reduce the amount
    of data we need to process by stripping away any data deemed non-vital to the
    current situation.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the clutter in the Profiler's graphical interface will make it easier
    to determine which subsystems are causing a spike in resource usage. Remember
    to use the colored checkboxes in each Timeline View area to narrow the search.
  prefs: []
  type: TYPE_NORMAL
- en: Be warned that these settings are autosaved in the Editor, so ensure that you
    re-enable them for the next profiling session, as this might cause us to miss
    something important next time.
  prefs: []
  type: TYPE_NORMAL
- en: Also, GameObjects can be deactivated to prevent them from generating profiling
    data, which will also help to reduce clutter in our profiling data. This will
    naturally cause a slight performance boost for each object we deactivate. However,
    if we're gradually deactivating objects and performance suddenly becomes significantly
    more acceptable when a specific object is deactivated, then clearly that object
    is related to the root cause of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on the issue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This category may seem redundant, given that we've already covered reducing
    noise. All we should have left is the issue at hand, right? Not exactly. Focus
    is the skill of not letting ourselves become distracted by inconsequential tasks
    and wild-goose chases.
  prefs: []
  type: TYPE_NORMAL
- en: You will recall that profiling with the Unity Profiler comes with a minor performance
    cost. This cost is even more severe when using the Deep Profile option. We might
    even introduce more minor performance costs into our application with additional
    logging. It's easy to forget when and where we introduced profiling code if the
    hunt continues for several hours.
  prefs: []
  type: TYPE_NORMAL
- en: We are effectively changing the result by measuring it. Any changes we implement
    during data sampling can sometimes lead us to chase after non-existent bugs in
    the application when we could have saved ourselves a lot of time by attempting
    to replicate the scenario without additional profiling instrumentation. If the
    bottleneck is reproducible and noticeable without profiling, then it's a candidate
    for beginning an investigation. However, if new bottlenecks keep appearing in
    the middle of an existing investigation, then keep in mind that they could be
    bottlenecks we introduced with our test code and not an existing problem that's
    been newly exposed.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, when we have finished profiling, completed our fixes, and are now ready
    to move on to the next investigation, we should make sure to profile the application
    one last time to verify that the changes have had the intended effect.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You learned a great deal throughout this chapter on how to detect and analyze
    performance issues within your applications. You learned about many of the Profiler's
    features and secrets, explored a variety of tactics to investigate performance
    issues with a more hands-on approach, and have been introduced to a variety of
    different tips and strategies to follow. You can use these to improve your productivity
    immensely, so long as you appreciate the wisdom behind them and remember to exploit
    them when the situation makes it possible.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has introduced us to the tips, tactics, and strategies we need
    in order to identify a performance issue that requires improvement. In the remaining
    chapters, we will explore methods on how to fix issues and improve performance
    whenever possible. So, give yourself a pat on the back for getting through the
    boring part first. We will now move on to best practices for C# development and
    how to avoid common performance pitfalls in your Unity scripts.
  prefs: []
  type: TYPE_NORMAL
