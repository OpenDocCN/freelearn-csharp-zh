- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Building Advanced XR Techniques
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建高级XR技术
- en: Up until now, you have explored various parts of XR development, crafting immersive
    and interactive XR applications suited for a wide array of use cases. As you venture
    further into mastering XR development, it’s essential to not only be proficient
    at creating basic to intermediate XR applications but also master advanced techniques
    that elevate the commercial viability and influence of your XR offerings.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，您已经探索了XR开发的各个方面，制作了适合广泛用例的沉浸式和交互式XR应用程序。随着您进一步掌握XR开发，不仅要熟练创建从基础到中级的应用程序，还要掌握提升您XR产品商业可行性和影响力的高级技术至关重要。
- en: This chapter is designed to familiarize you with crucial, high-level XR methods,
    all through a hands-on approach. You will dive into hand-tracking integration,
    use eye- and head-tracking for complex interactions, and discover how to establish
    a multiplayer server to create an engaging multiplayer XR experience.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在通过实践方法使您熟悉关键的高级XR方法。您将深入了解手部追踪集成，使用眼动和头动进行复杂交互，并了解如何建立多人服务器以创建引人入胜的多人XR体验。
- en: The content of this chapter might sound intimidating but don’t worry – we’re
    here to guide you every step of the way as you incorporate these sophisticated
    XR strategies into various scenes. Leveraging the solid XR foundation you’ve built
    from earlier chapters, you’ll find these advanced techniques more intuitive than
    anticipated.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的内容可能听起来令人畏惧，但请放心——我们将全程指导您将这些复杂的XR策略融入各种场景。利用您在前几章中建立的稳固XR基础，您会发现这些高级技术比预期的更直观。
- en: Regardless of the XR equipment you possess, this chapter promises a wealth of
    knowledge, with all techniques being adaptable to different setups. We’ll delve
    deeper into this in the *Technical* *requirements* section.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您拥有哪种XR设备，本章都承诺提供丰富的知识，所有技术都适用于不同的设置。我们将在*技术要求*部分深入探讨这一点。
- en: 'This chapter includes the following sections:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括以下部分：
- en: Adding hand-tracking to XR experiences
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将手部追踪添加到XR体验中
- en: Interacting with objects in XR experiences via eye- or head-tracking
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过眼动或头动在XR体验中与对象交互
- en: Building a VR multiplayer application
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建VR多人应用程序
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Navigating the hand-tracking, eye-tracking, and multiplayer aspects of this
    chapter requires understanding both shared and unique technical prerequisites.
    For a seamless development experience, we recommend acquainting yourself with
    all listed requirements. Though this chapter delves into advanced topics and may
    initially seem daunting compared to earlier sections, you can be sure that all
    tutorials in this chapter are designed for straightforward execution – even if
    you don’t have a VR headset at hand.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '要导航本章中的手部追踪、眼动和多人方面，需要了解共享和独特的技术先决条件。为了获得无缝的开发体验，我们建议您熟悉所有列出的要求。尽管本章深入探讨了高级主题，并且与早期章节相比可能最初显得有些令人生畏，但您可以确信本章中的所有教程都是为简单执行而设计的——即使您手头没有VR头显。 '
- en: 'First, let’s address the overarching technical requirements. To follow along
    with the tutorials in this chapter, you’ll need Unity *2021.3 LTS* or a newer
    version. Validate your hardware’s suitability by comparing it to the system requirements
    described on Unity’s website: [https://docs.unity3d.com/Manual/system-requirements.html](https://docs.unity3d.com/Manual/system-requirements.html).
    Depending on your VR headset’s specifications, ensure that your setup supports
    *Windows*/*Linux*/*Mac* or *Android* *Build Support*.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们解决整体的技术要求。为了跟随本章中的教程，您需要Unity *2021.3 LTS* 或更高版本。通过将您的硬件与Unity网站上描述的系统要求进行比较来验证其适用性：[https://docs.unity3d.com/Manual/system-requirements.html](https://docs.unity3d.com/Manual/system-requirements.html)。根据您的VR头显规格，确保您的设置支持
    *Windows*/*Linux*/*Mac* 或 *Android* *构建支持*。
- en: Most contemporary VR headsets, particularly those with inside-out camera tracking,
    incorporate hand-tracking capabilities. Examples include the Meta Quest series,
    HTC Vive Cosmos Elite, PlayStation VR2, Pico Neo 2 Eye, the Lynx-R1, Valve Index,
    HP Reverb G2, Varjo VR-3, and the soon-to-be-released Apple Vision Pro. Always
    refer to the technical specifications of your VR headset to find out whether it
    supports hand-tracking.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代VR头显，尤其是具有内向外置摄像头追踪的头显，都集成了手部追踪功能。例如，包括Meta Quest系列、HTC Vive Cosmos Elite、PlayStation
    VR2、Pico Neo 2 Eye、Lynx-R1、Valve Index、HP Reverb G2、Varjo VR-3以及即将发布的Apple Vision
    Pro。请始终参考您VR头显的技术规格，以了解它是否支持手部追踪。
- en: If you don’t have access to a headset that supports hand-tracking, you can still
    follow this chapter as the XR Device Simulator can replicate the hand-tracking
    features of a VR headset flawlessly.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你无法访问支持手部追踪的头显，你仍然可以遵循本章，因为XR设备模拟器可以完美地复制VR头显的手部追踪功能。
- en: Eye-tracking in VR is an evolving field, and interestingly, you can delve into
    the eye-tracking tutorials of this chapter’s eye- and head-gaze-tracking section
    regardless of your VR headset’s specifications. Even if you’re working solely
    with the XR Device Simulator without a physical VR headset, you’ll find our tutorial
    accessible. While we won’t spoil all the details now, it’s worth noting that the
    XR Interaction Toolkit provides innovative solutions for situations where a VR
    headset lacks standard eye-tracking capabilities. As of the time of this book’s
    publication, VR headsets that offer eye-tracking include the PlayStation VR2,
    HP Reverb G2 Omnicept Edition, Pico Neo 3 Pro Eye, HTC Vive Pro Eye, Pico Neo
    2 Eye, and Meta Quest Pro. Furthermore, the upcoming Apple Vision Pro is anticipated
    to feature eye-tracking. This list might not cover all available options by the
    time you read this book, so always check the specifications of your VR headset
    to confirm eye-tracking support.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟现实中的眼动追踪是一个不断发展的领域，有趣的是，无论你的VR头显规格如何，你都可以深入了解本章眼和头部注视追踪部分的眼动追踪教程。即使你仅使用XR设备模拟器而没有物理VR头显，你也会发现我们的教程易于访问。虽然我们现在不会透露所有细节，但值得注意的是，XR交互工具包为那些VR头显缺乏标准眼动追踪功能的情况提供了创新解决方案。截至本书出版时，提供眼动追踪功能的VR头显包括PlayStation
    VR2、HP Reverb G2 Omnicept Edition、Pico Neo 3 Pro Eye、HTC Vive Pro Eye、Pico Neo
    2 Eye和Meta Quest Pro。此外，即将推出的Apple Vision Pro预计也将具备眼动追踪功能。这个列表可能在你阅读本书时不会涵盖所有可用选项，所以请始终检查你的VR头显规格以确认是否支持眼动追踪。
- en: Now that your hardware is all set up, let’s start exploring hand-tracking using
    the XR Interaction Toolkit.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在硬件都设置好了，让我们开始使用XR交互工具包探索手部追踪。
- en: Adding hand-tracking to XR experiences
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为XR体验添加手部追踪
- en: In this section, you will learn how to add a hand-tracking functionality to
    your XR experiences. Before creating a new Unity project, however, you must understand
    the technical concept of hand-tracking and how far it can enrich an XR experience
    compared to regular controllers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何将手部追踪功能添加到你的XR体验中。然而，在创建新的Unity项目之前，你必须了解手部追踪的技术概念以及它如何比常规控制器更丰富XR体验。
- en: Understanding hand-tracking and potential use cases
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解手部追踪和潜在用例
- en: At its core, **hand-tracking** in VR refers to the technological capability
    of directly detecting, capturing, and interpreting the nuanced movements and positioning
    of a user’s bare hands and fingers within a virtual environment.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在虚拟现实中，**手部追踪**的核心是指直接检测、捕捉和解释用户在虚拟环境中裸手和手指的细微动作和定位的技术能力。
- en: Unlike controller-based tracking, which relies on external devices to mediate
    and translate user inputs into VR actions such as an Xbox controller, hand-tracking
    operates without intermediary hardware, offering a direct mapping of real-world
    hand gestures and movements into the virtual realm. This approach leverages sophisticated
    sensors, cameras, and algorithms to construct a real-time, dynamic model of the
    user’s hand. From grabbing objects to casting spells with finger gestures, hand-tracking
    provides a vast array of potential interactions. It facilitates complex and subtle
    interactions that are hard to replicate with traditional controllers, permitting
    more organic and intuitive interactions within VR.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于控制器的追踪不同，后者依赖于外部设备来调解和将用户输入转换为VR动作，如Xbox控制器，手部追踪无需中介硬件，直接将现实世界的手势和动作映射到虚拟领域。这种方法利用了复杂的传感器、摄像头和算法来构建用户手的实时动态模型。从抓取物体到用手指手势施法，手部追踪提供了一系列潜在交互。它促进了复杂和细微的交互，这些交互难以用传统控制器复制，允许在VR中实现更自然和直观的交互。
- en: For a VR headset to harness the potential of hand-tracking, it should be equipped
    with high-resolution sensors and cameras capable of capturing detailed movements,
    down to the subtle motions of individual fingers. These cameras often need to
    be oriented in a manner that provides a wide field of view to consistently track
    hands as they move.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要使VR头显能够利用手部追踪的潜力，它应该配备高分辨率传感器和摄像头，能够捕捉到详细的动作，包括单个手指的细微动作。这些摄像头通常需要以提供宽阔视野的方式定位，以便持续追踪手部的移动。
- en: Hand-tracking requires real-time interpretation of complex hand and finger movements,
    necessitating robust processing power. The VR headset should have an onboard processor
    or be connected to a machine that can handle these computations without latency.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 手部追踪需要实时解释复杂的手部和手指动作，这需要强大的处理能力。VR头显应该有一个内置处理器或连接到一台可以无延迟处理这些计算的机器。
- en: Beyond hardware, the headset’s software must be designed or adaptable to recognize
    and interpret hand movements effectively. This includes having algorithms capable
    of differentiating between intentional gestures and inadvertent hand motions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 除了硬件之外，头显的软件必须设计或可适应以有效地识别和解释手部动作。这包括拥有能够区分有意手势和无意手部动作的算法。
- en: Building on these foundational requirements, the next section will guide you
    through setting up our Unity project to effectively utilize and enable hand-tracking,
    unlocking a richer, more immersive experience for users of your XR experiences.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些基础要求的基础上，下一节将指导你设置Unity项目，以便有效地利用和启用手部追踪，为你的XR体验用户提供更丰富、更沉浸式的体验。
- en: Implementing hand-tracking with the XR Interaction Toolkit
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用XR交互工具包实现手部追踪
- en: 'To kick off our process of adding hand-tracking capabilities to an XR project,
    we must perform the following steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启动我们将手部追踪功能添加到XR项目的流程，我们必须执行以下步骤：
- en: Go to Unity Hub and create a new project by navigating to the `AdvancedXRTechniques`,
    and clicking the **Create** **project** button.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往Unity Hub，通过导航到`AdvancedXRTechniques`并点击**创建项目**按钮来创建一个新项目。
- en: In the **Scene Hierarchy** window, you will see that your scene only contains
    **Main Camera** and **Directional Light**. You can delete **Main Camera** as it
    is not needed.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**场景层次结构**窗口中，你会看到你的场景只包含**主相机**和**方向光**。你可以删除**主相机**，因为它不是必需的。
- en: Import `com.unity.xr.interaction.toolkit`, and hitting *Enter*. The toolkit
    should now be automatically added to your project. Staying in the **Package Manager**
    window, navigate to the **Samples** tab of the newly added **XR Interaction Toolkit**
    package and import **Starter Assets**, **XR Device Simulator**, and **Hands Interaction
    Demo** by clicking the **Import** button next to each of them.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`com.unity.xr.interaction.toolkit`，然后按*Enter*键。工具包现在应该会自动添加到你的项目中。在**包管理器**窗口中，导航到新添加的**XR交互工具包**包的**示例**选项卡，并通过点击每个旁边的**导入**按钮来导入**入门资产**、**XR设备模拟器**和**手部交互演示**。
- en: To enable hand-tracking in our scene, we don’t only need `com.unity.xr.hands`,
    and hitting *Enter*. Once the package has been added to your project, navigate
    to the **Samples** tab of the **XR Hands** package in the **Package Manager**
    window and click the **Import** button next to the **HandVisualizer** sample.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在我们的场景中启用手部追踪，我们不仅需要`com.unity.xr.hands`，还需要按*Enter*键。一旦该包被添加到你的项目中，导航到**包管理器**窗口中**XR手部**包的**示例**选项卡，并点击**HandVisualizer**示例旁边的**导入**按钮。
- en: Now, we would typically drag and drop the `XR Interaction Hands Setup` into
    the search bar of the `0`,`0`,`0`).
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们通常会拖放`XR Interaction Hands Setup`到`0`,`0`,`0`的搜索栏中。
- en: It is time to set up **XR Plug-in Management** correctly to enable hand-tracking.
    Navigate to **Edit** | **Project Settings** | **XR Plug-in Management** and select
    the **OpenXR** checkbox on either the **Windows/Mac/Linux** tab or **Android**,
    depending on the needs of your VR headset.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是时候正确设置**XR插件管理**以启用手部追踪了。导航到**编辑** | **项目设置** | **XR插件管理**，并根据你的VR头显需求，在**Windows/Mac/Linux**选项卡或**Android**上选择**OpenXR**复选框。
- en: Once the **OpenXR** plugin has been installed, navigate to its subtab underneath
    the **XR Plug-in Management** tab on the left-hand side. Here, go to either the
    **Windows/Mac/Linux** or **Android** tab. Select the **+** button to add an **Interaction
    Profile** item to your project. Besides selecting the controllers of your VR headset
    in the newly opened menu, you should also add another **Interaction Profile**
    called **Hands Interaction Profile**. At its core, **Hand Interaction Profile**
    in **OpenXR** provides a standardized way to interpret hand gestures and movements
    across different VR headsets. Different VR headsets might have their own technology
    and methods for tracking hands. Without a standardized system, developers would
    need to write unique code for each headset’s hand-tracking system, which can be
    time-consuming and impractical.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦安装了**OpenXR**插件，导航到左侧**XR Plug-in Management**标签下的子标签页。在这里，转到**Windows/Mac/Linux**或**Android**标签。点击**+**按钮将**Interaction
    Profile**项目添加到你的项目中。除了在新建菜单中选择你的VR头盔的控制器外，你还应该添加另一个名为**Hands Interaction Profile**的**Interaction
    Profile**。在**OpenXR**的核心中，**Hand Interaction Profile**提供了一种标准化的方式来解释不同VR头盔之间的手势和动作。不同的VR头盔可能有自己追踪手部的技术和方法。如果没有标准化的系统，开发者需要为每个头盔的手部追踪系统编写独特的代码，这可能会非常耗时且不切实际。
- en: Staying in the **OpenXR** subtab, select the **Hand Interaction Poses** and
    **Hand Tracking Subsystem** checkboxes, regardless of which VR headset you have.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持处于**OpenXR**子标签页，勾选**Hand Interaction Poses**和**Hand Tracking Subsystem**复选框，无论你使用哪种VR头盔。
- en: When you check **Hand Interaction Poses**, you are telling Unity to use a standard
    set of poses or gestures defined by the **OpenXR** standard. These include grabbing
    (grip), pointing (aim), pinching, and poking. So, instead of manually coding the
    detection of these gestures, Unity does it for you based on this standard. By
    selecting the **Hand Tracking Subsystem** checkbox, Unity uses the **OpenXR**
    standard to keep track of where the hands are and how they move. This subsystem
    is like the engine under the hood that keeps an eye on hand movements.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当你勾选**Hand Interaction Poses**时，你是在告诉Unity使用由**OpenXR**标准定义的标准姿势或手势集。这些包括抓取（握持）、指向（瞄准）、捏合和戳击。因此，你不需要手动编写这些手势的检测代码，Unity会根据这个标准为你完成。通过勾选**Hand
    Tracking Subsystem**复选框，Unity使用**OpenXR**标准来跟踪手的位置和移动方式。这个子系统就像引擎盖下的引擎，时刻关注手部的移动。
- en: If you have a Meta Quest device, you must also select the **Meta Hand Tracking
    Aim** checkbox. This feature enhances the existing hand-tracking by also understanding
    the direction or aim of the hands, giving your VR app a better sense of where
    users are pointing or what they might be trying to interact with. While our **Hand
    Interaction Profile** provides a base layer of understanding hand movements, these
    checkboxes dive deeper into gesture specifics, actual tracking, and device-specific
    features.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你有一个Meta Quest设备，你还必须勾选**Meta Hand Tracking Aim**复选框。这个功能通过理解手的方向或瞄准，增强了现有的手部追踪，给你的VR应用提供了更好的用户指向感或用户可能试图交互的对象感。虽然我们的**Hand
    Interaction Profile**提供了对手部动作的基础理解，但这些复选框深入到具体的手势、实际追踪和特定设备的功能。
- en: Now, let’s add a simple plane to the scene functioning as a ground floor and
    a cube to interact with testing out hand-tracking. You can achieve this by right-clicking
    in the hierarchy and selecting `Ground Floor` and position it at the origin (`0``0``0`).
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在场景中添加一个简单的平面作为地面，并添加一个立方体来进行交互测试手部追踪。你可以通过在层次结构中右键单击，选择`Ground Floor`并将其定位在原点(`0``0``0`)来实现。
- en: Repeat the previous step but instead of selecting `Hand Tracking Cube`. Position
    it at (`0`, `1.25`, `1`) and scale it to (`0.1`, `0.1`, `0.1`). In the `Hand Tracking
    Cube`, click the `XR Grab Interactable` in the search bar. Select the **XR Grab
    Interactable** script by double-clicking on it. You should see that a **Rigidbody**
    component has been automatically added to **InteractableCube**, alongside the
    **XR Grab Interactable** script. Inside the **Rigidbody** component, make sure
    that the **Use Gravity** and **Is Kinematic** checkboxes are selected so that
    our interaction with the cube is possible while obeying the laws of gravity.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 重复上一步，但不要选择`Hand Tracking Cube`。将其定位在(`0`, `1.25`, `1`)，并缩放到(`0.1`, `0.1`, `0.1`)。在`Hand
    Tracking Cube`中，在搜索栏中点击`XR Grab Interactable`。通过双击选择**XR Grab Interactable**脚本。你应该能看到一个**Rigidbody**组件已经自动添加到**InteractableCube**中，与**XR
    Grab Interactable**脚本并列。在**Rigidbody**组件内部，确保选中了**Use Gravity**和**Is Kinematic**复选框，这样我们的与立方体的交互就可以在遵守重力定律的情况下进行。
- en: Important note
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you don’t have access to a VR headset with hand-tracking capabilities, you
    can simply test this feature by using the XR Device Simulator, as detailed in
    the *Installing the XR Device Simulator* and *Using the XR Device Simulator* sections
    of [*Chapter 3*](B20869_03.xhtml#_idTextAnchor009). To switch to hand-tracking
    mode, simply press the *H* key.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有访问具有手势追踪功能的VR头盔，你可以简单地通过使用XR设备模拟器来测试此功能，如[*第3章*](B20869_03.xhtml#_idTextAnchor009)中的*安装XR设备模拟器*和*使用XR设备模拟器*部分所述。要切换到手势追踪模式，只需按下*H*键。
- en: It’s time to test out the scene using your VR headset. Start the scene as you
    typically would. You don’t even need to have the VR headset’s controllers on hand.
    Once the scene is running, adjust your head so that the external cameras on the
    VR headset are directed at your hands.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候使用你的VR头盔测试场景了。像平时一样启动场景。你甚至不需要手头有VR头盔的控制器。一旦场景开始运行，调整你的头部，使VR头盔上的外部摄像头指向你的手。
- en: You should notice that the controller visuals have been replaced by hand visuals,
    mirroring the exact position and movements of your real hands, as shown in *Figure
    8**.1*.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该注意到控制器视觉已经被手部视觉所取代，精确地反映了你真实手的准确位置和动作，如图*图8.1*所示。
- en: '![Figure 8.1 – The hand visuals you will see once you put away your controllers
    and direct your gaze toward your hands](img/B20869_08_01.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – 当你放下控制器并将目光转向你的手时，你将看到的视觉](img/B20869_08_01.jpg)'
- en: Figure 8.1 – The hand visuals you will see once you put away your controllers
    and direct your gaze toward your hands
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 当你放下控制器并将目光转向你的手时，你将看到的视觉
- en: Try moving each finger separately, shift your hands around, and even hide one
    hand behind your back. If everything was set up correctly and your VR headset
    fully supports hand-tracking, the virtual hands should mimic your real hand movements
    accurately. If you hide one hand behind your back, its corresponding virtual hand
    should vanish too.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试分别移动每个手指，转动你的手，甚至将一只手藏在背后。如果一切设置正确，并且你的VR头盔完全支持手势追踪，虚拟手应该能够准确模仿你的真实手部动作。如果你将一只手藏在背后，对应的虚拟手也应该消失。
- en: Finally, let’s test the interaction with the cube in your scene using only hand-tracking.
    Aim your right hand’s laser pointer at the cube. Touch the tips of your right
    thumb and right index finger together, forming a near triangle shape, as shown
    in *Figure 8**.2*.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用仅手势追踪的方式测试场景中的立方体交互。将右手激光笔对准立方体。将右手拇指和食指指尖相触，形成一个近似的三角形形状，如图*图8.2*所示。
- en: '![Figure 8.2 – The overlayed hand visuals as you touch your right thumb and
    right index finger together in real life](img/B20869_08_02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 在现实生活中，当你将右手拇指和右手食指指尖相触时的叠加手部视觉](img/B20869_08_02.jpg)'
- en: Figure 8.2 – The overlayed hand visuals as you touch your right thumb and right
    index finger together in real life
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 在现实生活中，当你将右手拇指和右手食指指尖相触时的叠加手部视觉
- en: You are now grabbing the cube. While maintaining this position, point in various
    directions and observe the cube moving correspondingly.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你正在抓取立方体。在保持这个位置的同时，指向各个方向，观察立方体相应地移动。
- en: Congratulations! You’ve now achieved a similar interactive experience in your
    VR scene with hand-tracking as you would have using standard VR controllers.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你现在已经在你的VR场景中实现了与使用标准VR控制器相似的手势交互体验。
- en: 'To explore how the hand-tracking features of the XR Interaction Toolkit work
    with other types of objects such as UI elements or buttons, delve into **Hands
    Interaction Demo**, which is available within the toolkit’s **Samples** area that
    we imported at the beginning. To access it, follow these steps:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 要探索XR交互工具包的手势追踪功能如何与其他类型的对象（如UI元素或按钮）协同工作，请深入了解**手部交互演示**，它位于我们最初导入的工具包的**样本**区域中。要访问它，请按照以下步骤操作：
- en: Head to **Assets** in the **Project** window. From there, navigate to **Samples**
    | **XR Interaction Toolkit** | **Version Number** | **Hands Interaction Demo**
    | **Runtime**.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往**项目**窗口中的**资产**。从那里，导航到**样本** | **XR交互工具包** | **版本号** | **手部交互演示** | **运行时**。
- en: Then, double-click on the **HandsDemoScene** Unity scene. If you prefer, you
    can quickly locate **HandsDemoScene** using the search bar in the **Project**
    window.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，双击**HandsDemoScene** Unity场景。如果你喜欢，可以使用**项目**窗口中的搜索栏快速定位**HandsDemoScene**。
- en: Once you’ve opened the scene in the Unity Editor, hit the **Play** button. This
    will let you experience firsthand how to engage with UI elements, press buttons,
    and even manipulate 3D objects using just your hands.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你在Unity编辑器中打开场景，点击**播放**按钮。这将让你亲身体验如何与UI元素互动、按按钮，甚至仅用双手操纵3D对象。
- en: 'By now, you should feel like a hand-tracking expert. The next section will
    introduce you to another advanced concept of XR development: eye-tracking.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该感觉自己已经是一名手部追踪专家了。下一节将向你介绍XR开发中的另一个高级概念：眼动追踪。
- en: Interacting with objects in XR experiences via eye- or head-tracking
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过眼动或头动在XR体验中与物体交互
- en: In this section, you will not only learn about eye-tracking itself and how it
    can enrich your XR experience, but you will also implement eye-tracking functionalities
    to your XR experiences, regardless of whether your VR headset supports eye-tracking
    or not.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你不仅将了解眼动追踪本身及其如何丰富你的XR体验，你还将实现眼动追踪功能到你的XR体验中，无论你的VR头盔是否支持眼动追踪。
- en: Understanding eye-tracking and potential use cases
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解眼动追踪及其潜在应用场景
- en: From reading a person’s intent to enhancing digital interactions, eye-tracking
    technology is revolutionizing how technologies of all kinds perceive and interpret
    human behavior.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从读取人的意图到增强数字交互，眼动技术正在改变各种技术感知和解释人类行为的方式。
- en: 'The eyes are often dubbed the “windows to the soul” due to their ability to
    express and convey emotions, intent, and attention. Biologically speaking, several
    key aspects of the eyes play into this:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于眼睛能够表达和传达情绪、意图和注意力，它们通常被称为“灵魂之窗”。从生物学的角度来看，眼睛的几个关键方面对此有所贡献：
- en: '**Pupil dilation**: Often a subconscious response, the pupils can dilate or
    contract based on emotional states, levels of attention, or reactions to stimuli.
    For instance, someone’s pupils might dilate upon seeing someone they’re attracted
    to or contract when exposed to bright light.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**瞳孔扩张**：通常是一种无意识的反应，瞳孔可以根据情绪状态、注意力水平或对刺激的反应而扩张或收缩。例如，当看到吸引他们的人时，某人的瞳孔可能会扩张，而在暴露在明亮光线中时可能会收缩。'
- en: '**Saccades**: These are rapid, jerky movements of the eyes when they change
    focus from one point to another. Often unnoticed by us, saccades play a pivotal
    role in how we gather visual information from our surroundings.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**眼跳**：这些是在眼球从一个点转向另一个点时发生的快速、突然的运动。我们往往没有注意到眼跳，但它在我们从周围环境中收集视觉信息方面起着关键作用。'
- en: '**Blinking and micro-expressions**: The rate of blinking can indicate various
    states, from relaxation to stress. Furthermore, subtle movements around the eyes
    can give away fleeting emotions – these are known as micro-expressions.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**眨眼和微表情**：眨眼的频率可以表明各种状态，从放松到压力。此外，眼睛周围的微妙动作可以透露瞬间的情绪——这些被称为微表情。'
- en: 'Eye-tracking technology revolves around monitoring and recording the eye’s
    movement and gaze points. Here’s how it typically works:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 眼动技术围绕监测和记录眼球运动和注视点展开。以下是它通常的工作原理：
- en: '**Light source**: Infrared light is directed toward the eyes. This light reflects
    off the cornea and retina.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**光源**：红外光指向眼睛。这种光从角膜和视网膜反射。'
- en: '**Sensors and cameras**: These detect the reflected light off the eyes. Advanced
    systems might use multiple cameras from different angles to capture a three-dimensional
    view of the eye’s movement.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**传感器和摄像头**：这些检测眼睛反射的光。先进的系统可能会使用来自不同角度的多个摄像头来捕捉眼睛运动的立体视图。'
- en: '**Data processing**: The raw data captured by the sensors is processed using
    algorithms to deduce the direction of the gaze and the point of focus.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据处理**：传感器捕获的原始数据通过算法处理，以推断注视方向和焦点点。'
- en: '**Representation**: The gaze data is usually represented as a heatmap or gaze
    plot on the observed medium, be it a computer screen or a physical environment.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**表示**：注视数据通常以热图或注视图的形式表示在观察介质上，无论是计算机屏幕还是物理环境。'
- en: Eye-tracking bridges the gap between the digital and real worlds by making virtual
    interactions more human-like. When social avatars in XR mimic real eye movements
    by blinking, gazing, and showing emotions, it deepens the sense of presence and
    immersion for the user.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 眼动技术通过使虚拟交互更接近人类行为，弥合了数字世界和现实世界之间的差距。当XR中的社交虚拟形象通过眨眼、注视和展示情绪来模仿真实的眼球运动时，它加深了用户的临场感和沉浸感。
- en: Likewise, eye-tracking can drastically improve the understanding of user intent
    in the XR space. This means that XR environments can adapt in real time to the
    user’s focus. For example, a horror game could trigger a scare only when the user
    is looking in the right direction, maximizing the emotional impact. By analyzing
    where users look, how often, and for how long, developers can glean valuable insights.
    This can guide design choices, ensure important elements capture attention, and
    refine user interfaces.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，眼动追踪可以极大地提高XR空间中对用户意图的理解。这意味着XR环境可以实时适应用户的焦点。例如，一个恐怖游戏只有在用户看向正确的方向时才会触发惊吓，从而最大化情感冲击。通过分析用户注视的位置、频率和持续时间，开发者可以获取有价值的见解。这可以指导设计选择，确保重要元素吸引注意力，并优化用户界面。
- en: Eye-tracking paves the way for more intuitive user interfaces. For instance,
    instead of navigating through menus using clunky hand controllers, users can simply
    gaze at a menu option to select it.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 眼动追踪为更直观的用户界面铺平了道路。例如，用户无需使用笨拙的手控制器在菜单中导航，只需凝视菜单选项即可选择它。
- en: Fortunately, you can enrich your XR scene with eye-tracking, regardless of whether
    your VR headset supports it or not. If this sparks your curiosity, follow along
    with the tutorial in the next section.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，无论您的VR头盔是否支持眼动追踪，您都可以通过眼动追踪来丰富您的XR场景。如果这激发了您的兴趣，请跟随下一节的教程。
- en: Setting up an XR scene to support eye- and head-tracking
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置XR场景以支持眼动和头动追踪
- en: The XR Interaction Toolkit supports eye- and head-tracking, enhancing user engagement
    in XR apps. While eye-tracking specifically captures where the user’s eyes are
    focused, head-tracking determines the direction the user’s head is pointing or
    gazing. Let’s try out these tracking techniques ourselves by revisiting the basic
    VR scene we created in our last session.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: XR交互工具包支持眼动和头动追踪，增强XR应用的用户参与度。虽然眼动追踪专门捕捉用户的目光焦点，但头动追踪确定用户头部指向或注视的方向。让我们通过回顾我们在上一会话中创建的基本VR场景来亲自尝试这些追踪技术。
- en: Some key components of the XR Interaction Toolkit’s eye- and head-tracking functionalities
    are already inside of our scene. To observe them, click on the arrow button next
    to the **XR Interaction Hands Setup** prefab in the **Scene Hierarchy** window
    of your project to see its children. Navigate to **XR Origin (XR Rig)** | **Camera
    Offset** and enable the **XR Gaze Interactor** and **Gaze Stabilized** prefabs.
    These prefabs are not only part of the **XR Interaction Hands Setup** prefab,
    but also the **XR Interaction Setup** prefab, which you would use in your scene
    if you don’t include hand-tracking.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: XR交互工具包的眼动和头动追踪功能的关键组件已经包含在我们的场景中。要观察它们，请在项目的**场景层次结构**窗口中点击**XR Interaction
    Hands Setup**预制件旁边的箭头按钮，以查看其子项。导航到**XR Origin (XR Rig)** | **Camera Offset**并启用**XR
    Gaze Interactor**和**Gaze Stabilized**预制件。这些预制件不仅是**XR Interaction Hands Setup**预制件的一部分，也是**XR
    Interaction Setup**预制件的一部分，如果您不包含手部追踪，您将在场景中使用它。
- en: These prefabs work with all kinds of VR headsets, regardless of whether they
    support eye-tracking or not. If your headset doesn’t support eye-tracking, it
    will use the built-in head-tracking feature of the VR headset to estimate the
    head gaze.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些预制件与所有类型的VR头盔一起工作，无论它们是否支持眼动追踪。如果您的头戴式设备不支持眼动追踪，它将使用VR头戴式设备的内置头动追踪功能来估计头部注视。
- en: 'While incorporating eye- and head-tracking into our scene is a significant
    step forward, it’s only part of the equation for crafting intuitive gaze-based
    interactions in XR. If it were that simple, there would be no need for this chapter,
    especially considering we’ve utilized this prefab in every VR scene throughout
    this book. To truly harness the capabilities of eye-tracking, we must also populate
    our scene with objects that can interact with the **XR Gaze Interactor** prefab.
    Let’s create these objects:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然将眼动和头动追踪纳入我们的场景是一个重要的进步，但这只是XR中构建直观的基于注视交互方程的一部分。如果事情这么简单，那么就没有必要写这一章了，尤其是考虑到我们在本书中的每个VR场景都使用了这个预制件。要真正利用眼动追踪的能力，我们还必须在场景中添加可以与**XR
    Gaze Interactor**预制件交互的对象。让我们创建这些对象：
- en: To keep our scene organized, right-click on `Hand Tracking Cube` in the `Eye
    Tracking and Hand Tracking Interactables`. This GameObject will store two more
    cubes enabling different kinds of eye-tracking interactions alongside the cube
    we already created.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了保持我们的场景井然有序，在“眼动追踪和手部追踪交互”中的“Hand Tracking Cube”上右键单击。这个GameObject将存储两个额外的立方体，使我们能够创建与已创建的立方体不同的眼动追踪交互。
- en: Let’s place all of the cubes on a very simple table. Create the table by clicking
    the `Table`, position it at (`0`, `0.5`, `0`), and scale it to (`3`, `1`, `1`).
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们把所有的立方体都放在一个非常简单的桌子上。通过点击`Table`创建桌子，将其定位在(`0`, `0.5`, `0`)，并将其缩放到(`3`, `1`,
    `1`)。
- en: Scale `Hand Tracking Cube` to (`0.5`, `0.5`, `0.5`) and position it on `Table`
    by changing the values to (`-1`, `0`, `0`). Also, make sure you uncheck the `Hand
    Tracking Cube` and select the `Hand Tracking Cube`. Rename the two cubes `Eye
    Tracking Cube 1` and `Eye Tracking Cube 2`. Change the position of `Eye Tracking
    Cube 1` to (`0`, `0`, `0`) and the position of `Eye Tracking Cube 2` to (`1`,
    `0`, `0`).
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Hand Tracking Cube`缩放到(`0.5`, `0.5`, `0.5`)，并通过将值更改为(`-1`, `0`, `0`)将其放置在`Table`上。同时，确保你取消选中`Hand
    Tracking Cube`并选择`Hand Tracking Cube`。将两个立方体重命名为`Eye Tracking Cube 1`和`Eye Tracking
    Cube 2`。将`Eye Tracking Cube 1`的位置更改为(`0`, `0`, `0`)，将`Eye Tracking Cube 2`的位置更改为(`1`,
    `0`, `0`)。
- en: Next, let’s add the function that when the user’s gaze is pointing at `Eye Tracking
    Cube 1`, a sphere will appear on top of it. We can add a sphere to our scene by
    selecting `Eye Tracking Cube 1` in the `0`, `1`, `0`) and scale it to (`0.5`,
    `0.5`, `0.5`).
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们添加一个功能，当用户的注视点指向`Eye Tracking Cube 1`时，在其上方会出现一个球体。我们可以通过在`0`、`1`、`0`)中选择`Eye
    Tracking Cube 1`并将它缩放到(`0.5`, `0.5`, `0.5`)来向场景中添加一个球体。
- en: Similar to `Eye Tracking Cube 1`, some text should appear when the user of our
    VR scene looks at `Eye Tracking Cube 2`. To make the interaction more complex,
    the text should change, depending on whether the user looks at the cube and whether
    the cube is selected or deselected via a controller button press. To create the
    needed UI elements, right-click on `Eye Tracking Cube 2` in the `0`, `-1`, `-1.01`)
    and its `1`. Now, right-click on `No state detected!` in the `Interactable Text`,
    scale it to `0.005` in all directions, and position it at (`0.1`, `0.1`, `0`).
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与`Eye Tracking Cube 1`类似，当我们的VR场景的用户看向`Eye Tracking Cube 2`时，应该出现一些文本。为了使交互更加复杂，文本应根据用户是否看向立方体以及是否通过控制器按钮按下选择或取消选择立方体而改变。为了创建所需的UI元素，在`Eye
    Tracking Cube 2`的`0`、`-1`、`-1.01`)上右键单击并选择其`1`。现在，在`Interactable Text`中的`No state
    detected!`上右键单击，将其所有方向上的缩放设置为`0.005`，并将其定位在(`0.1`, `0.1`, `0`)。
- en: 'Let’s add some colorful materials to our scene to make it more visually appealing.
    Specifically, we want to add two materials for our cubes – one for their default
    appearance and one if they are hovered over. So, we will create a material for
    `Table` and one for `Materials` and double-click on it to open it. Create a new
    material inside the `Materials` folder by right-clicking, selecting `HighlightedCube`.
    In the `HighlightedCube`, click on the colored cell next to the `240`, G: `240`,
    B: `140`) with an `70`.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '让我们在场景中添加一些彩色材料，使其更具视觉吸引力。具体来说，我们想要为我们的立方体添加两种材料——一种用于它们的默认外观，另一种用于它们被悬停时。因此，我们将为`Table`创建一个材料，并为`Materials`创建一个材料，然后双击它以打开它。通过右键单击，选择`HighlightedCube`在`Materials`文件夹内创建一个新的材料。在`HighlightedCube`中，点击旁边带有`240`、G:
    `240`、B: `140`的彩色单元格，并设置`70`。'
- en: 'Right-click inside the `Materials` folder and select `CubeMaterial`, `TableMaterial`,
    and `SphereMaterial` materials. For `CubeMaterial`, we chose a sophisticated red
    color (R: `186`, G: `6`, B: `6`); `TableMaterial` has been assigned a dark brown
    color (R: `58`, G: `40`, B: `3`); and for `SphereMaterial`, we selected a blue
    color (R: `29`, G: `120`, B: `241`) and made it appear metallic by setting the
    `1`. All of these materials have an `255`. Apply `CubeMaterial` to all three cubes
    in the scene by simply dragging and dropping the material from the `TableMaterial`
    and `SphereMaterial`.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '在`Materials`文件夹内右键单击并选择`CubeMaterial`、`TableMaterial`和`SphereMaterial`材料。对于`CubeMaterial`，我们选择了一种复杂的红色（R:
    `186`、G: `6`、B: `6`）；`TableMaterial`已被分配了一种深棕色（R: `58`、G: `40`、B: `3`）；而对于`SphereMaterial`，我们选择了一种蓝色（R:
    `29`、G: `120`、B: `241`）并通过设置`1`使其看起来像金属。所有这些材料都有`255`。通过简单地从`TableMaterial`和`SphereMaterial`拖放材料，将`CubeMaterial`应用到场景中的所有三个立方体上。'
- en: '*Figure 8**.3* shows what your VR scene should currently look like.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*图8**.3*显示了你的VR场景当前应该看起来是什么样子。'
- en: '![Figure 8.3 – The current status of the VR scene for eye-tracking](img/B20869_08_03.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3 – 眼睛追踪的VR场景当前状态](img/B20869_08_03.jpg)'
- en: Figure 8.3 – The current status of the VR scene for eye-tracking
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – 眼睛追踪的VR场景当前状态
- en: In the next section, you will learn how you can interact with these cubes via
    eye or head gaze.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何通过眼神或头部注视与这些立方体进行交互。
- en: Interacting with objects via eye and head gaze using the XR Interaction Toolkit
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用XR交互工具包通过眼神和头部注视与对象交互
- en: When a user looks at one of the two cubes we created for gaze-tracking, they
    should be able to interact with them as described in the previous section. To
    accomplish this, we need to adjust some components of our scene.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户注视我们为注视跟踪创建的两个立方体之一时，他们应该能够像上一节所述那样与之交互。为了实现这一点，我们需要调整场景中的某些组件。
- en: The **XR Gaze Interactor** prefab will only interact with objects in a scene
    that have either an **XR Simple Interactable** or **XR Grab Interactable** script
    attached to them and that have the **Allow Gaze Interaction** checkbox of the
    respective script enabled. This means we must add either one of these two scripts
    to our two new cubes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**XR Gaze Interactor** 预制件只会与场景中具有 **XR Simple Interactable** 或 **XR Grab Interactable**
    脚本的对象交互，并且相应的脚本启用了 **Allow Gaze Interaction** 复选框。这意味着我们必须将这两个脚本之一添加到我们的两个新立方体上。'
- en: 'In our case, we will add the **XR Simple Interactable** script to each of the
    two eye-tracking cubes. We need to perform the following three steps to achieve
    this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们将为每个眼动立方体添加 **XR Simple Interactable** 脚本。为了实现这一点，我们需要执行以下三个步骤：
- en: Press *Ctrl*/*Cmd* and select both cubes in the **Scene** **Hierarchy** window.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按 *Ctrl*/*Cmd* 并在 **Scene Hierarchy** 窗口中选择两个立方体。
- en: Click the `XR Simple Interactable` into the search bar, and double-click on
    the script to add it to both cubes.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `XR Simple Interactable` 点击到搜索栏中，然后双击脚本将其添加到两个立方体上。
- en: Click the arrow next to the **Gaze Configuration** property of the **XR Simple
    Interactable** script component to open the gaze-related properties. Select the
    **Allow Gaze** **Interaction** checkbox.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `XR Simple Interactable` 脚本组件旁边的 **Gaze Configuration** 属性旁边的箭头以打开与注视相关的属性。选择
    **Allow Gaze Interaction** 复选框。
- en: 'Now, we need to specify how we can interact with our two cubes via gaze. Let’s
    start with the first cube. Remember that our goal is to make the blue sphere appear
    on top of the first cube only when our eyes, head, or controllers are directed
    toward it. We can add this logic to the cube by following these steps:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要指定如何通过注视与我们的两个立方体交互。让我们从第一个立方体开始。记住，我们的目标是只有当我们的眼睛、头部或控制器指向它时，蓝色球体才出现在第一个立方体的顶部。我们可以通过以下步骤将此逻辑添加到立方体中：
- en: In the `Eye Tracking Cube 1`, navigate to the end of the **XR Simple Interactable**
    script component. Click on the arrow next to **Interactable Events** to open it.
    Add two new events to the **First Hover Entered** function of **First/Last** **Hover**
    by clicking on the **+** button two times.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Eye Tracking Cube 1` 中，导航到 **XR Simple Interactable** 脚本组件的末尾。点击 **Interactable
    Events** 旁边的箭头以打开它。通过点击 **+** 按钮两次，向 **First/Last Hover** 的 **First Hover Entered**
    函数添加两个新事件。
- en: Let’s fill in the missing information of our newly created interactable events.
    As indicated by the `Eye Tracking Cube 1` from the **Scene Hierarchy** window
    into the first **None (Object)** cell. Repeat this for the second event by assigning
    it to **Sphere**.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们填写我们新创建的交互事件的缺失信息。根据 **Scene Hierarchy** 窗口中的 `Eye Tracking Cube 1` 将其指示到第一个
    **None (Object)** 单元格。通过将第二个事件分配给 **Sphere** 重复此操作。
- en: To change the material of `Eye Tracking Cube 1` when it is hovered over via
    controllers, the eyes, or the head, we must assign the necessary functions to
    each interactable event and provide them with the needed parameters. Select `HighlightedCube`
    material via the search bar and select it. For the `Eye Tracking Cube 1` with
    your controllers, eyes, or head, you will see the blue sphere appearing on top
    of it.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在通过控制器、眼睛或头部悬停在 `Eye Tracking Cube 1` 上时更改其材质，我们必须为每个交互事件分配必要的函数并提供所需的参数。通过搜索栏选择
    `HighlightedCube` 材质并选择它。对于使用控制器、眼睛或头部悬停在 `Eye Tracking Cube 1` 上的情况，你将看到蓝色球体出现在其顶部。
- en: Once your controllers, eyes, or head are no longer directed toward `Eye Tracking
    Cube 1`, the cube’s material should change back to its default color and the sphere
    should disappear. To accomplish this, go to the `Eye Tracking Cube 1` and `CubeMaterial`,
    and select it. Repeat this process for **Sphere** by assigning it to the **GameObject**
    | **SetActive (bool)** function again and ensuring the newly appeared checkbox
    is not checked this time.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你的控制器、眼睛或头部不再指向 `Eye Tracking Cube 1`，立方体的材质应恢复到默认颜色，球体应消失。为了实现这一点，转到 `Eye
    Tracking Cube 1` 和 `CubeMaterial`，并选择它。通过将 **GameObject** | **SetActive (bool)**
    函数分配给 **Sphere** 重复此过程，并确保这次新出现的复选框未勾选。
- en: To evaluate the logic we’ve put in place so far, it’s necessary to either disable
    or hide the blue **Sphere** object in our scene. This ensures that upon initial
    entry into the scene, the user doesn’t see it. You can achieve this by selecting
    **Sphere** within the **Scene Hierarchy** window and then deselecting the checkbox
    next to its name at the top of the **Inspector** window.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了评估我们迄今为止放置的逻辑，有必要在我们的场景中禁用或隐藏蓝色的**球体**对象。这确保了当用户首次进入场景时，看不到它。你可以通过在**场景层次结构**窗口中选择**球体**，然后在**检查器**窗口顶部取消选中其名称旁边的复选框来实现这一点。
- en: Voilà – we’ve completed all the required steps to add a powerful eye-tracking
    capability to our first cube. *Figure 8**.4* shows what the cube should look like
    once your eyes or head are directed toward it.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 哇哦——我们已经完成了所有必要的步骤，为我们的第一个立方体添加了强大的眼动追踪功能。*图8.4*显示了当你将眼睛或头部指向立方体时，立方体应该看起来是什么样子。
- en: '![Figure 8.4 – The highlighted cube and blue sphere appear because of your
    eyes or head hovering over the cube](img/B20869_08_04.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图8.4 – 由于你的眼睛或头部在立方体上方悬停，因此出现了高亮的立方体和蓝色球体](img/B20869_08_04.jpg)'
- en: Figure 8.4 – The highlighted cube and blue sphere appear because of your eyes
    or head hovering over the cube
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 – 由于你的眼睛或头部在立方体上方悬停，因此出现了高亮的立方体和蓝色球体
- en: If you are working with head gaze, you will only see the blue sphere when the
    cube is positioned at the center of your current field of view when you are wearing
    a VR headset or using the XR Device Simulator. You can observe the same effect
    when your controllers are pointing at the cube.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用头部注视功能，当你戴着VR头盔或使用XR设备模拟器时，只有当立方体位于你当前视野的中心时，你才会看到蓝色的球体。当你控制器指向立方体时，你也可以观察到相同的效果。
- en: 'We will add an even more powerful interaction to our second cube. Like the
    first cube, a text element will appear underneath the second cube when the eyes,
    head, or controllers are directed toward it. This time, however, the displayed
    text itself will change based on whether the cube is hovered over, selected, or
    deselected using a combination of eye, head, and controller interactions. Follow
    these steps to accomplish this goal:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为第二个立方体添加更强大的交互功能。与第一个立方体一样，当眼睛、头部或控制器指向第二个立方体时，会在其下方出现一个文本元素。然而，这次显示的文本本身将根据是否使用眼睛、头部和控制器交互悬停、选择或取消选择立方体而改变。按照以下步骤完成此目标：
- en: 'Repeat all the steps you performed for `Eye Tracking Cube 1` with the following
    modification: drag and drop `Eye Tracking Cube 2` and **Canvas** into the two
    events of the **First Hover Entered** function and the **Last Hover** **Exited**
    function.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下修改重复为`Eye Tracking Cube 1`执行的步骤：将`Eye Tracking Cube 2`和**画布**拖放到**First
    Hover Entered**函数和**Last Hover Exited**函数的两个事件中。
- en: So far, the cube’s color changes and the text element becomes visible once the
    cube is hovered over. However, the text itself should also change to `Interactable
    Text` from the `Hovered` into the newly appeared empty text cell.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到目前为止，当立方体被悬停时，立方体的颜色会改变，文本元素也会变得可见。然而，文本本身也应该从`Hovered`变为新出现的空白文本单元格中的`Interactable
    Text`。
- en: When the cube is hovered over and selected by pressing the controller button,
    which is typically reserved for moving objects around, the text displayed underneath
    the cube should change. To implement this logic, scroll down to `Interactable
    Text` element from the `Selected` into the empty text field.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你悬停在立方体上方并通过按下控制器按钮（通常用于移动物体）选择立方体时，立方体下方的文本应该改变。要实现这个逻辑，请滚动到`Selected`中的`Interactable
    Text`元素，并将其拖放到空白的文本字段中。
- en: Once the cube is no longer selected via controllers, the text should change
    again. This can be accomplished by adding a new event to the `Interactable Text`
    to the `Deselected` into the newly created text cell.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当立方体不再通过控制器选择时，文本应该再次改变。这可以通过向`Interactable Text`添加一个新事件到`Deselected`并拖放到新创建的文本单元格中来实现。
- en: Before testing out the logic of the second cube, hide it in the scene by deselecting
    it in its **Inspector** window, as you did with the first cube.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试第二个立方体的逻辑之前，通过在**检查器**窗口中取消选中它，就像对第一个立方体所做的那样，在场景中隐藏它。
- en: It is time to try out interacting with this cube. *Figure 8**.5* shows the cube
    in its three interactable states – being hovered over, being hovered over plus
    selected, and being hovered over but deselected.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候尝试与这个立方体进行交互了。*图8.5*显示了立方体的三种交互状态——悬停、悬停并选择，以及悬停但取消选择。
- en: '![Figure 8.5 – The cube in its three interactable states](img/B20869_08_05.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图8.5 – 立方体的三种交互状态](img/B20869_08_05.jpg)'
- en: Figure 8.5 – The cube in its three interactable states
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 – 立方体的三种可交互状态
- en: Hurray – you have successfully added different eye-tracking interactions to
    your scene! In the next section, you will learn how to set up a multiplayer XR
    game in Unity.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 欢呼——你已经成功地为场景添加了不同的眼动交互！在下一节中，你将学习如何在Unity中设置多人XR游戏。
- en: Building a VR multiplayer application
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建VR多人游戏应用
- en: In this section, you’ll craft your first VR multiplayer application. Though
    it involves a fair amount of C# coding, you’ve gained enough knowledge to smoothly
    navigate this tutorial. But before we dive in, let’s pause and delve into the
    nuances of constructing multiplayer applications, the necessary components, and
    the appeal of multiplayer experiences within the XR context.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将构建你的第一个VR多人游戏应用。尽管这涉及到相当数量的C#编程，但你已经获得了足够的知识来顺利地导航这个教程。但在我们深入之前，让我们暂停一下，深入探讨构建多人游戏应用的细微差别、必要组件以及XR环境中多人体验的吸引力。
- en: Understanding multiplayer applications and multiplayer networking systems
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解多人应用和多人网络系统
- en: At its core, a **multiplayer** experience allows multiple users to interact
    within a shared digital environment simultaneously. This environment can range
    from simple text-based interfaces to complex virtual realities. The key components
    of a multiplayer experience typically include servers that host the game environment,
    networking systems that handle data synchronization and communication, player
    avatars, and game logic that governs interaction rules.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本质上，**多人**体验允许多个用户同时在一个共享的数字环境中交互。这个环境可以从简单的基于文本的界面到复杂的虚拟现实。多人体验的关键组件通常包括托管游戏环境的服务器、处理数据同步和通信的网络系统、玩家化身以及管理交互规则的游戏逻辑。
- en: Adding a multiplayer mode to a game can make it more unpredictable due to human
    behaviors and decision-making. By contrast, **single-player** modes are typically
    more controlled and can be designed around a predefined narrative.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 将多人模式添加到游戏中可以使游戏更具不可预测性，因为人类的行为和决策。相比之下，**单人**模式通常更加可控，并且可以围绕预定义的叙事来设计。
- en: By adding multiplayer capabilities to XR, users are encouraged to jointly engage
    in tasks, challenges, or experiences, making the environment feel more alive and
    dynamic. Examples include cooperative puzzle-solving, virtual team-building exercises,
    and joint exploration.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将多人功能添加到XR中，用户被鼓励共同参与任务、挑战或体验，使环境感觉更加生动和动态。例如，包括合作解谜、虚拟团队建设练习和联合探索。
- en: Important note
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you are serious about becoming an XR developer, you should feel comfortable
    creating multiplayer XR experiences. Virtual meetups in forums such as VR Chat
    are among the most popular XR applications to date. These meetups underline the
    desire of people to hang out with other real humans in virtual worlds, instead
    of being only surrounded by virtual assets.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认真考虑成为一名XR开发者，你应该感到舒适地创建多人XR体验。在VR Chat等论坛上的虚拟聚会是目前最受欢迎的XR应用之一。这些聚会凸显了人们希望在虚拟世界中与其他真实人类聚会的愿望，而不是仅仅被虚拟资产所包围。
- en: The most crucial part of any multiplayer game is the **multiplayer networking
    system**. At its essence, a multiplayer networking system is the digital backbone
    that enables various players to interact seamlessly within a shared environment.
    This system ensures that actions performed by one player are reflected accurately
    and consistently for all other players, creating a harmonized virtual experience.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 任何多人游戏中最关键的部分是**多人网络系统**。本质上，多人网络系统是数字骨架，使得各种玩家能够在共享环境中无缝交互。该系统确保一个玩家执行的动作能够被其他所有玩家准确且一致地反映出来，从而创造出一个和谐的虚拟体验。
- en: A key component of every multiplayer networking system is **servers**. These
    are powerful computers that host the game’s digital environment. They are the
    central point that players connect to, and they maintain the authoritative state
    of the game. In some configurations, one of the players might act as a server,
    termed **peer-to-peer**, but dedicated servers are more common in larger games
    due to stability and scalability.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 每个多人网络系统的关键组件是**服务器**。这些是强大的计算机，它们托管游戏的数字环境。它们是玩家连接的中心点，并维护游戏的主权状态。在某些配置中，一个玩家可能充当服务器，称为**对等网络**，但在大型游戏中，由于稳定性和可扩展性，专用服务器更为常见。
- en: The individual devices or computers used by players are called **client systems**.
    They send data such as player movements or actions to the server and receive updates
    about the game world and other players.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 玩家使用的单个设备或计算机被称为**客户端系统**。它们将玩家动作或行为等数据发送到服务器，并接收有关游戏世界和其他玩家的更新。
- en: In real-time games, even slight delays can affect gameplay. Multiplayer networking
    systems use techniques such as **lag compensation** to make sure players have
    smooth experiences. This involves predicting movements or actions and then reconciling
    differences once actual data arrives.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时游戏中，即使是微小的延迟也可能影响游戏体验。多人网络系统使用诸如**延迟补偿**等技术，以确保玩家拥有流畅的体验。这涉及到预测动作或行为，然后在实际数据到达后进行协调。
- en: To avoid multiplayer games becoming targets for cheating or hacking, networking
    systems employ measures such as data encryption, authoritative servers, and cheat
    detection tools.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免多人游戏成为作弊或黑客的目标，网络系统采用诸如数据加密、权威服务器和作弊检测工具等措施。
- en: Beyond gameplay, players often wish to communicate, be it through text, voice,
    or other mediums. Networking systems provide the infrastructure for these interactions,
    ensuring real-time and clear communication.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 除了游戏本身之外，玩家经常希望进行沟通，无论是通过文本、语音还是其他媒介。网络系统为这些交互提供了基础设施，确保实时且清晰的沟通。
- en: 'Here is an overview of the three main multiplayer network providers that are
    interesting for Unity developers:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是三个对Unity开发者来说有趣的主要多人网络提供商的概述：
- en: '**Photon Unity Networking** (**PUN**): PUN is a solution tailored for Unity’s
    multiplayer games. Its cloud-based approach means that developers don’t need to
    worry about server creation or maintenance. PUN offers a free tier. Although it
    comes with certain restrictions, the free version is heavily used by indie developers
    and hobbyists who are starting their journey into multiplayer game development.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Photon Unity Networking** (**PUN**): PUN是为Unity多人游戏量身定制的解决方案。其基于云的方法意味着开发者无需担心服务器的创建或维护。PUN提供免费层。尽管它附带某些限制，但免费版本被许多刚开始多人游戏开发旅程的独立游戏开发者和小型项目爱好者广泛使用。'
- en: '**Mirror**: Mirror offers a community-powered, open source networking tool
    tailored for Unity. It’s an evolution of the deprecated Unity networking system.
    Being open source, it doesn’t impose licensing fees, making it an economical choice.
    Mirror is renowned for its flexibility and provides developers with a greater
    degree of control over their multiplayer logic. However, its customizable nature
    means that it presents a slightly more challenging learning curve for beginners.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**镜面反射**: 镜面反射提供了一款由社区驱动的开源网络工具，专为Unity量身定制。它是已废弃的Unity网络系统的进化版本。作为开源软件，它不收取许可费用，这使得它成为一个经济实惠的选择。镜面反射因其灵活性而闻名，为开发者提供了对其多人游戏逻辑的更高控制度。然而，其可定制性意味着对于初学者来说，学习曲线稍微有些挑战。'
- en: '**Netcode**: Netcode is Unity’s proprietary solution for game networking, formerly
    known as *MLAPI*. This evolution and rebranding signifies Unity’s commitment to
    continuous improvement and its dedication to providing developers with top-tier
    tools for multiplayer game development. Being an intrinsic Unity solution, Netcode
    promises seamless integration with Unity’s ecosystem.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络代码**: 网络代码是Unity的专有游戏网络解决方案，之前被称为*MLAPI*。这一演变和品牌重塑标志着Unity对持续改进的承诺，以及其致力于为开发者提供顶级多人游戏开发工具的奉献。作为Unity的内在解决方案，网络代码承诺与Unity生态系统无缝集成。'
- en: In the following sections, we’ll create a multiplayer game of our own. For this,
    we’ll be leveraging Photon PUN 2 using the free tier. Its zero-cost barrier, combined
    with an intuitive setup process for beginners, makes it an ideal candidate for
    rapid prototyping and smaller-scale projects.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将创建自己的多人游戏。为此，我们将利用Photon PUN 2的免费层。其零成本障碍，加上对初学者直观的设置过程，使其成为快速原型设计和较小规模项目的理想选择。
- en: The next section will teach you how to set up PUN for the VR multiplayer game
    we are about to create.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将教授您如何为即将创建的VR多人游戏设置PUN。
- en: Setting up PUN for our VR multiplayer game
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为我们的VR多人游戏设置PUN
- en: Our objective for this VR multiplayer game is both straightforward and robust,
    encompassing all essential elements needed for a multiplayer experience. We aim
    to design a VR scene where multiple users can join concurrently. Users should
    see themselves and each other through avatars that consist of a head and two controller
    components. They should witness the movements of others in this shared space in
    real time, observing how they maneuver or rotate their controllers. Moreover,
    through hand animations, they should be able to discern when others are pressing
    their hands.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这个 VR 多人游戏的目的是既简单又稳健，涵盖了多人体验所需的所有基本元素。我们的目标是设计一个 VR 场景，其中多个用户可以同时加入。用户应该通过由头部和两个控制器组件组成的化身看到自己和他人。他们应该实时观察在这个共享空间中他人的动作，观察他们如何操纵或旋转控制器。此外，通过手部动画，他们应该能够辨别出他人何时按下他们的手。
- en: 'Before we start importing Photon PUN 2 into our project, let’s create a new
    scene for this part of this chapter. Follow these steps to get started:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将 Photon PUN 2 导入项目之前，让我们为这一章节的这一部分创建一个新的场景。按照以下步骤开始：
- en: Open the `AdvancedXRTechniques` project, which we created in the previous sections
    of this chapter. Save the current scene using an expressive name such as `HandAndEyeTrackingScene`
    by navigating to **File** | **Save As** and typing in the scene name of your choice.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开我们在本章前几节中创建的 `AdvancedXRTechniques` 项目。通过导航到 **文件** | **另存为** 并输入您选择的场景名称，例如
    `HandAndEyeTrackingScene` 来保存当前场景。
- en: Go to `MultiplayerScene`.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 `MultiplayerScene`。
- en: In the Unity Editor of your new scene, delete `XR Interaction Setup` via the
    search bar of the `0`,`0`,`0`).
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您新场景的 Unity 编辑器中，通过搜索栏删除 `XR Interaction Setup`（位置为 `0`,`0`,`0`）。
- en: 'Now that we’ve set up our scene, follow these steps to install and set up our
    networking system, PUN:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了场景，按照以下步骤安装和设置我们的网络系统，PUN：
- en: We can install PUN like any other package via the Unity Asset Store. Visit [https://assetstore.unity.com/packages/tools/network/pun-2-free-119922](https://assetstore.unity.com/packages/tools/network/pun-2-free-119922)
    or search for `PUN 2 – FREE` via the Unity Asset Store (**Window** | **Asset Store**).
    Click the **Add to my Assets** button to add the package to your assets. Once
    the package has been added, a new button called **Open in Unity** will appear
    on the Asset Store’s website. Click it to open the package in the **Package Manager**
    window of your project. Press the **Download** and **Import** buttons to import
    the asset into your project.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以通过 Unity Asset Store 安装 PUN，就像安装其他包一样。访问 [https://assetstore.unity.com/packages/tools/network/pun-2-free-119922](https://assetstore.unity.com/packages/tools/network/pun-2-free-119922)
    或在 Unity Asset Store 中搜索 `PUN 2 – FREE`（**窗口** | **资产商店**）。点击**添加到我的资产**按钮将包添加到您的资产中。一旦包被添加，Asset
    Store 网站上会出现一个名为**在 Unity 中打开**的新按钮。点击它以在项目的**包管理器**窗口中打开包。按下**下载**和**导入**按钮将资产导入到您的项目中。
- en: The **PUN Wizard** window shown in *Figure 8**.6* will pop up in the Unity Editor.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *图 8.6* 中显示的**PUN 向导**窗口将在 Unity 编辑器中弹出。
- en: '![Figure 8.6 – The PUN Wizard pop-up window](img/B20869_08_06.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – PUN 向导弹出窗口](img/B20869_08_06.jpg)'
- en: Figure 8.6 – The PUN Wizard pop-up window
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – PUN 向导弹出窗口
- en: If you already have a Photon account, you can simply type in your **AppId**
    here. Otherwise, input your email and click on the **Setup Project** button once
    you are done. This will create an account and forward you to a web page where
    you can set your password.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经有了 Photon 账户，您可以直接在这里输入您的**AppId**。否则，完成输入您的电子邮件并点击**设置项目**按钮。这将创建一个账户并将您转发到一个网页，您可以在那里设置您的密码。
- en: Important note
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you accidentally close this pop-up window, simply head to [https://www.photonengine.com/](https://www.photonengine.com/)
    and sign up there.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您意外关闭了这个弹出窗口，只需前往 [https://www.photonengine.com/](https://www.photonengine.com/)
    并在那里注册。
- en: Once you have signed in to your account, head to [https://dashboard.photonengine.com/](https://dashboard.photonengine.com/)
    and click on the **Create A New App** button. You will be forwarded to the page
    shown in *Figure 8**.7*.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您登录到您的账户，前往 [https://dashboard.photonengine.com/](https://dashboard.photonengine.com/)
    并点击**创建新应用**按钮。您将被转发到 *图 8.7* 中显示的页面。
- en: '![Figure 8.7 – The web page you will be forwarded to once you create a new
    application on the Photon website](img/B20869_08_07.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.7 – 在 Photon 网站上创建新应用后将被转发的网页](img/B20869_08_07.jpg)'
- en: Figure 8.7 – The web page you will be forwarded to once you create a new application
    on the Photon website
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – 在 Photon 网站上创建新应用后将被转发的网页
- en: Choose the `My first Multiplayer Game`. Click the **CREATE** button – notice
    your newly created application in the dashboard. As shown in *Figure 8**.8*, you
    can find your Photon **App ID** in one of the layout elements of the dashboard.
    Copy it to connect to the server later.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`我的第一个多人游戏`。点击**创建**按钮 – 注意您在仪表板中新建的应用程序。如图*图8**.8*所示，您可以在仪表板的布局元素之一中找到您的Photon
    **App ID**。将其复制以稍后连接到服务器。
- en: '![Figure 8.8 – The dashboard element containing your App ID](img/B20869_08_08.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图8.8 – 包含您的App ID的仪表板元素](img/B20869_08_08.jpg)'
- en: Figure 8.8 – The dashboard element containing your App ID
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 – 包含您的App ID的仪表板元素
- en: Head back to your Unity project. If you still see the **PUN Wizard** window,
    you can directly paste your **App Id** inside of it and click the **Setup Project**
    button. Alternatively, you can type your **App Id** directly into **Photon Server
    Settings** by navigating to **Window** | **Photon Unity Networking** | **Highlight
    Server Settings**, as shown in *Figure 8**.9*.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回到您的Unity项目。如果您仍然看到**PUN向导**窗口，您可以直接将其中的**App Id**粘贴进去，然后点击**设置项目**按钮。或者，您可以直接在**Photon服务器设置**中输入您的**App
    Id**，方法是导航到**窗口** | **Photon Unity Networking** | **高亮服务器设置**，如图*图8**.9*所示。
- en: '![Figure 8.9 – How to add the App Id to Photon Server Settings in Unity](img/B20869_08_09.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图8.9 – 如何在Unity中将App Id添加到Photon服务器设置中](img/B20869_08_09.jpg)'
- en: Figure 8.9 – How to add the App Id to Photon Server Settings in Unity
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 – 如何在Unity中将App Id添加到Photon服务器设置中
- en: Now, it’s time to connect our Unity project to the server. The next section
    will show you how to do this.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候将我们的Unity项目连接到服务器了。下一节将向您展示如何做到这一点。
- en: Connecting to the server via Network Manager
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过网络管理器连接到服务器
- en: 'To connect our Unity project to the PUN server, we must add a new GameObject
    with an associated C# script to our scene. Let’s go through this process step
    by step:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 要将我们的Unity项目连接到PUN服务器，我们必须在我们的场景中添加一个新的GameObject，并关联一个C#脚本。让我们一步一步地完成这个过程：
- en: Create a new empty GameObject by right-clicking in the `Network Manager`.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在`网络管理器`中右键单击来创建一个新的空GameObject。
- en: Now, we want to add a script to this GameObject that we can use to connect to
    the PUN server and check whether someone else joined the server. To create this
    script, navigate to the `Network Manager` and click the **Add** **Component**
    button.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们想要添加一个脚本到这个GameObject，我们可以使用它来连接到PUN服务器并检查是否有人加入了服务器。要创建这个脚本，导航到`网络管理器`并点击**添加**
    **组件**按钮。
- en: Search for `NetworkManager`, select the **New Script** option, and press the
    **Create and Add** button to create a C# script called **NetworkManager.cs** that
    is automatically added to **NetworkManager** as a component. Double-click on the
    script to open it in your preferred IDE.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索`NetworkManager`，选择**新建脚本**选项，然后按**创建并添加**按钮来创建一个名为**NetworkManager.cs**的C#脚本，该脚本将自动添加到**NetworkManager**作为组件。双击脚本以在您首选的IDE中打开它。
- en: The **NetworkManager** script serves as a foundational element for initiating
    and managing network interactions in a VR multiplayer application using the PUN
    framework. Delete everything that is currently inside of the **NetworkManager**
    script so that you can start on a clean foundation.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**NetworkManager**脚本作为在VR多人应用程序中使用PUN框架启动和管理网络交互的基础元素。删除**NetworkManager**脚本中当前的所有内容，以便您可以从一个干净的基础开始。'
- en: 'Let’s start adding our code logic by importing the following libraries:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过导入以下库来开始添加我们的代码逻辑：
- en: '[PRE0]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `Photon.Pun` and `Photon.Realtime` libraries are vital for any PUN application
    as they grant access to core multiplayer networking functionalities.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`Photon.Pun`和`Photon.Realtime`库对于任何PUN应用程序都是至关重要的，因为它们提供了访问核心多人网络功能的能力。'
- en: 'Next, let’s define the `NetworkManager` class and some important constants:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义`NetworkManager`类和一些重要的常量：
- en: '[PRE1]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `NetworkManager` class inherits from `MonoBehaviourPunCallbacks`. This inheritance
    means that it’s not just a standard Unity script (`MonoBehaviour`), but that it
    also has special callback functions provided by PUN that notify our script of
    various networking events.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '`NetworkManager`类继承自`MonoBehaviourPunCallbacks`。这种继承意味着它不仅仅是一个标准的Unity脚本（`MonoBehaviour`），而且它还拥有PUN提供的特殊回调函数，这些函数会通知我们的脚本各种网络事件。'
- en: While `ROOM_NAME` represents the name of the room players will join or create,
    `MAX_PLAYERS` defines the maximum number of players allowed in a room, which in
    this case is `5` players. We will need both constants later in the script.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`ROOM_NAME`代表玩家将加入或创建的房间名称，但`MAX_PLAYERS`定义了房间中允许的最大玩家数，在这个例子中是`5`名玩家。我们稍后需要在脚本中使用这两个常量。
- en: 'Let’s continue by connecting our application to Photon servers:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续，将我们的应用程序连接到Photon服务器：
- en: '[PRE2]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Once the `Awake()` method is invoked, it initiates the connection to the PUN
    server by calling the `InitiateServerConnection()` method. If the client isn’t
    already connected to Photon, the `InitiateServerConnection()` method will attempt
    to connect to the server space using the **App Id** value that we inserted before.
    Refer to *Figure 8**.9* in case you missed this step. The second line of this
    method logs our attempt via a debug message.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦调用`Awake()`方法，它将通过调用`InitiateServerConnection()`方法来启动与PUN服务器的连接。如果客户端尚未连接到Photon，`InitiateServerConnection()`方法将尝试使用我们之前插入的**App
    Id**值连接到服务器空间。请参阅*图8**.9，以防您错过了这一步。此方法的第二行通过调试消息记录了我们的尝试。
- en: 'If the connection attempt is successful, the following method will be executed:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果连接尝试成功，以下方法将被执行：
- en: '[PRE3]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This method is an override of the `OnConnectedToMaster` callback from Photon.
    It is triggered once the application successfully connects to the Photon Master
    Server. This method is an integral part of the PUN framework, allowing us to execute
    specific logic after a successful connection. Inside this method, we log the successful
    connection to the Master Server. We also call the `JoinOrCreateGameRoom()` method,
    which uses the constants we defined at the beginning of our script:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法是对Photon的`OnConnectedToMaster`回调的重写。一旦应用程序成功连接到Photon主服务器，它就会被触发。此方法是PUN框架的一个组成部分，允许我们在成功连接后执行特定的逻辑。在此方法内部，我们记录了成功连接到主服务器。我们还调用了`JoinOrCreateGameRoom()`方法，它使用了我们在脚本开头定义的常量：
- en: '[PRE4]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the last line of this method, the client attempts to join or create a room,
    called **Multiplayer Room**, with five being the maximum allowed number of players
    in the room. If the room doesn’t exist, it creates one with the provided options.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法的最后一行，客户端尝试加入或创建一个名为**多人房间**的房间，房间内最多允许五名玩家。如果房间不存在，它将使用提供的选项创建一个。
- en: 'The next method in our code is an override:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们代码中的下一个方法是重写：
- en: '[PRE5]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This method is an override of the `OnJoinedRoom` callback from Photon. It’s
    triggered when the client successfully joins a room. In the last line, a debug
    message is printed to confirm successful room entry.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法是对Photon的`OnJoinedRoom`回调的重写。当客户端成功加入房间时，它会被触发。在最后一行，打印了一条调试消息以确认成功进入房间。
- en: 'To manage new players, we can use the following method:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理新玩家，我们可以使用以下方法：
- en: '[PRE6]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This `OnPlayerEnteredRoom()` method is also an override of the `OnPlayerEnteredRoom`
    callback from Photon. It’s called whenever a new player enters the room. Once
    again, a debug message is printed in the last line to notify that another player
    has joined.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 此`OnPlayerEnteredRoom()`方法也是对Photon的`OnPlayerEnteredRoom`回调的重写。每当有新玩家进入房间时，它就会被调用。同样，在最后一行打印了一条调试消息，通知另一个玩家已加入。
- en: Hurray, you have implemented all the necessary components into the `NetworkManager`
    script! As you can see, it provides a foundational structure to connect to Photon’s
    servers, manage multiplayer rooms, and handle player interactions in a VR environment.
    Let’s see whether our code logic works. In the next section, you will find out
    how you can test a multiplayer application on a single device.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 欢呼，您已经将所有必要的组件实现到了`NetworkManager`脚本中！正如您所看到的，它提供了一个连接到Photon服务器、管理多人房间以及在VR环境中处理玩家交互的基础结构。让我们看看我们的代码逻辑是否工作。在下一节中，您将了解到如何在单个设备上测试多人应用程序。
- en: Testing the multiplayer scene from one device
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从一个设备测试多人场景
- en: 'To test a multiplayer scene from a single device, we need to run the scene
    twice. This can be accomplished by first building and running the scene on the
    computer and subsequently launching it from within the Editor. Here’s a step-by-step
    breakdown:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 要从单个设备测试多人场景，我们需要运行场景两次。这可以通过首先在计算机上构建和运行场景，然后从编辑器内部启动它来实现。以下是逐步分解：
- en: In the Unity Editor, head to **Files** | **Build Settings** and select the **Windows/
    Mac/ Linux** tab. Add the open scene you want to test, click the **Build** button,
    and choose a folder for the executable file you are about to build.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Unity编辑器中，转到**文件** | **构建设置**并选择**Windows/ Mac/ Linux**选项卡。添加您想要测试的打开场景，点击**构建**按钮，并为即将构建的可执行文件选择一个文件夹。
- en: Once the file has been built, click on the **Play** button in the Unity Editor
    to start the scene.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文件构建完成后，点击Unity编辑器中的**播放**按钮以启动场景。
- en: Now, open the executable file that you just built.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，打开您刚刚构建的可执行文件。
- en: Head to the **Console** window in the Unity Editor and check the **Debug** statements.
    If you did everything correctly, you will see the debug lines we defined in the
    scripts previously, as shown in *Figure 8**.10*.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往 Unity 编辑器的 **控制台** 窗口并检查 **调试** 语句。如果你一切都做得正确，你将看到我们在脚本中之前定义的调试线条，如图 *8.10*
    所示。
- en: '![Figure 8.10 – The debug lines you should see if everything works as expected](img/B20869_08_10.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.10 – 如果一切按预期工作，你应该看到的调试线条](img/B20869_08_10.jpg)'
- en: Figure 8.10 – The debug lines you should see if everything works as expected
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 – 如果一切按预期工作，你应该看到的调试线条
- en: To ensure that our scene functions optimally, we must test its VR features thoroughly.
    From our assessments, navigating the scene is smooth, and both the headset and
    controllers are accurately tracked and positioned. Currently, our scene establishes
    a server connection as soon as the initial player activates it, and we have set
    up methods to detect the entry of new players.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们的场景功能最优，我们必须彻底测试其 VR 功能。根据我们的评估，场景导航流畅，头戴式设备和控制器都被准确追踪和定位。目前，我们的场景在初始玩家激活时立即建立服务器连接，并且我们已经设置了检测新玩家进入的方法。
- en: However, our **XR Interaction Setup** isn’t entirely primed for multiplayer
    operations. It excels at managing locomotion and interactions, but it doesn’t
    feature animated models for different body parts. In simpler terms, if someone
    were to enter our multiplayer scene at this moment, they might only see the controller.
    Worse, they might not detect any part of our avatar because the controller models
    aren’t network-conscious. This means that the objects present aren’t synchronized
    across all players in the session. But don’t worry, we’ll tackle this issue in
    the upcoming section.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的 **XR 交互设置** 并非完全适合多人操作。它在管理移动和交互方面表现出色，但并没有为不同身体部位提供动画模型。简单来说，如果有人此时进入我们的多人场景，他们可能只能看到控制器。更糟糕的是，他们可能检测不到我们化身的一部分，因为控制器模型没有网络意识。这意味着当前场景中的对象没有在会话中的所有玩家之间同步。但别担心，我们将在下一节中解决这个问题。
- en: Using scripts to display our avatar’s hands and face
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用脚本显示我们的化身的手和脸
- en: Our next objective is to display an avatar’s hands and face when it connects
    to a server. To achieve this, let’s append a new script to `Network Manager` by
    selecting it in the `NetworkPlayerPlacer` after clicking the `NetworkPlayerPlacer`.
    Open the script by double-clicking on it.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一个目标是当化身连接到服务器时显示其手和脸。为了实现这一点，让我们在点击 `NetworkPlayerPlacer` 后选择 `Network Manager`
    并在 `NetworkPlayerPlacer` 中添加一个新的脚本。通过双击打开脚本。
- en: Managing player presence
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理玩家存在
- en: 'The `NetworkPlayerPlacer` script we are about to dive into is tailored for
    overseeing player presence, a core element in multiplayer VR applications. Specifically,
    this means to create and delete player avatars or their in-game representations.
    The `NetworkPlayerPlacer` script is tailored for this exact role. It begins with
    the following declarations:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将深入探讨的 `NetworkPlayerPlacer` 脚本专门用于监控玩家存在，这是多人虚拟现实应用的核心元素。具体来说，这意味着创建和删除玩家化身或其在游戏中的表示。`NetworkPlayerPlacer`
    脚本专门为此角色定制。它从以下声明开始：
- en: '[PRE7]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The import statements and class declarations bear a close resemblance to those
    in the `NetworkManager` script. Both classes are derived from `MonoBehaviourPunCallbacks`.
    `playerInstance` serves as a reference to the instantiated player object within
    the scene. Meanwhile, `PLAYER_PREFAB_NAME` is a constant string that holds the
    name of the player prefab set for instantiation. It’s anticipated that this prefab
    is registered and accessible in the Photon resources directory.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 导入语句和类声明与 `NetworkManager` 脚本中的非常相似。这两个类都继承自 `MonoBehaviourPunCallbacks`。`playerInstance`
    作为场景中实例化玩家对象的引用。同时，`PLAYER_PREFAB_NAME` 是一个常量字符串，它保存了为实例化设置的玩家预制件的名称。预计这个预制件已在
    Photon 资源目录中注册并可访问。
- en: 'Let’s create the first method of the `NetworkPlayerPlacer` script:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建 `NetworkPlayerPlacer` 脚本的第一个方法：
- en: '[PRE8]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `OnJoinedRoom()` method overrides the `OnJoinedRoom` callback from Photon,
    which gets triggered when the local player successfully joins a room.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`OnJoinedRoom()` 方法覆盖了 Photon 的 `OnJoinedRoom` 回调，当本地玩家成功加入房间时会被触发。'
- en: 'The base class implementation of `OnJoinedRoom` is called with `base.OnJoinedRoom()`.
    In the last line, the `SpawnPlayer()` method is called, which looks like this:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `base.OnJoinedRoom()` 调用 `OnJoinedRoom` 的基类实现。在最后一行，调用了 `SpawnPlayer()` 方法，其外观如下：
- en: '[PRE9]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This method instantiates a new player object using Photon’s networked instantiation
    method. The new player will be spawned at the position and rotation of the `NetworkPlayerPlacer`
    object. This ensures that the player object is networked and synchronized across
    all clients in the room.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用Photon的网络实例化方法创建一个新的玩家对象。新玩家将在`NetworkPlayerPlacer`对象的位置和旋转处生成。这确保了玩家对象在网络上是网络化的，并且在房间中的所有客户端上都是同步的。
- en: 'The next method in our script overrides the `OnLeftRoom` callback from Photon,
    which is called when the local player leaves a room:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们脚本中的下一个方法覆盖了Photon的`OnLeftRoom`回调，当本地玩家离开房间时调用：
- en: '[PRE10]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `OnLeftRoom()` method consists of two calls: one to the base class implementation
    of `OnLeftRoom` and one to `DespawnPlayer()`, a method to despawn the player.
    Let’s have a look at the `DespawnPlayer()` method next:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`OnLeftRoom()`方法包含两个调用：一个是对`OnLeftRoom`基类实现的调用，另一个是对`DespawnPlayer()`的调用，这是一个销毁玩家的方法。让我们看看`DespawnPlayer()`方法：'
- en: '[PRE11]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This method handles the despawning of the player object.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法处理玩家对象的销毁。
- en: The `if` statement checks whether the `playerInstance` reference is not null.
    If this is true, a player object exists. The `PhotonNetwork.Destroy(playerInstance);`
    line destroys the networked player object. This will ensure that the object is
    removed not just locally but across all clients.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`if`语句检查`playerInstance`引用是否不为空。如果是这样，则存在玩家对象。`PhotonNetwork.Destroy(playerInstance);`这一行销毁了网络玩家对象。这将确保对象不仅在本地上被移除，而且在所有客户端上都被移除。'
- en: In essence, the `NetworkPlayerSpawner` script, with its two key callback functions,
    `OnJoinedRoom()` and `OnLeftRoom()`, seamlessly handles the appearance and disappearance
    of player avatars in our VR multiplayer space, complementing the functionalities
    offered by the `NetworkManager` script.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，`NetworkPlayerSpawner`脚本，通过其两个关键回调函数`OnJoinedRoom()`和`OnLeftRoom()`，无缝地处理了玩家在VR多人空间中的出现和消失，补充了`NetworkManager`脚本提供的功能。
- en: Creating a face and hands
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建面部和双手
- en: Earlier, we noted that the script anticipates a prefab called `Resources` folder.
    Unity uses this default naming convention when referencing objects by their name.
    To create the needed folder, click on the `Resources`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们提到脚本预期一个名为`Resources`的预制件。Unity在通过名称引用对象时使用此默认命名约定。要创建所需的文件夹，请点击`Resources`。
- en: 'Next, we need to create the **Network Player** prefab, which will represent
    our avatar via the network. Follow these steps to achieve this:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建代表我们角色的**网络玩家**预制件。按照以下步骤完成此操作：
- en: Right-click in the `Network Player`.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`网络玩家`上右键点击。
- en: Add the **Photon View** component to it in the **Inspector** window by pressing
    the **Add Component** button and searching for it. Photon requires this component
    to instantiate the player on the server. Without it, the system wouldn’t recognize
    ownership or synchronize the player’s body parts accurately.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过按下**添加组件**按钮并在**检查器**窗口中搜索它，将**光子视图**组件添加到其中。光子需要此组件在服务器上实例化玩家。如果没有它，系统将无法识别所有权或准确同步玩家的身体部位。
- en: Add three other empty GameObjects as children to `Network Player` by selecting
    `Network Player` in the `Head`, `Left Hand`, and `Right Hand`.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在`Head`、`左手`和`右手`中选择`Network Player`，将其他三个空GameObject作为子对象添加到`Network Player`中。
- en: Now, we need to create 3D objects to represent the three components of our avatar.
    For `Head`, we can use a simple `Head` in the `Head` and scale it to (`0.1`, `0.1`,
    `0.1`)
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要创建3D对象来表示我们角色的三个组成部分。对于`Head`，我们可以在`Head`中使用一个简单的`Head`并将其缩放到（`0.1`，`0.1`，`0.1`）
- en: We could also use primitives for the hands of our avatar. However, since there
    are a lot of animated hand models available on the internet, we can simply use
    one of them. For this project, we used the **Oculus Hands** sample from the **Oculus
    Integration** package on Unity’s Asset Store ([https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022](https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022)).
    However, we suggest cloning the hands directly from this book’s GitHub repository.
    This avoids unnecessary additional content and missing assets due to frequent
    updates in the **Oculus** **Integration** package.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们也可以为我们的角色双手使用原始形状。然而，由于互联网上有许多可用的动画手模型，我们可以简单地使用其中之一。对于这个项目，我们使用了Unity资产商店上的**Oculus双手**示例，该示例来自**Oculus集成**包（[https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022](https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022)）。然而，我们建议直接从这本书的GitHub仓库克隆双手。这避免了由于**Oculus**
    **集成**包频繁更新而导致的额外内容和不必要的资产丢失。
- en: Now, select `Network Player` in the `Resources` folder in the `Network Player`
    in our **Scene Hierarchy** window anymore and can delete it.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在`Scene Hierarchy`窗口中，不再需要选择`Resources`文件夹中的`Network Player`，可以将其删除。
- en: We must add another script to `Network Manager` to make sure the `Head`, `Left
    Hand`, and `Right Hand` components follow the position of the user’s headset and
    controllers. To do this, select `Network Manager` in the `NetworkPlayer` into
    the search bar, and create a new script with this name.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须在`Network Manager`中添加另一个脚本，以确保`Head`、`Left Hand`和`Right Hand`组件跟随用户头戴式设备和控制器的位置。为此，在`NetworkPlayer`中选择`Network
    Manager`并输入到搜索栏中，然后创建一个具有此名称的新脚本。
- en: Now that our script has been created, let’s learn how we can use it to track
    the player’s position and movement.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了脚本，让我们学习如何使用它来跟踪玩家的位置和移动。
- en: Tracking player position and movements
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪玩家位置和移动
- en: The `NetworkPlayer` script controls how a player’s movements are tracked and
    represented within the multiplayer VR environment. The script encapsulates functionalities
    that ensure the position and rotation of the avatar’s head, left hand, and right
    hand are accurately tracked and updated.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '`NetworkPlayer`脚本控制玩家在多玩家VR环境中的移动跟踪和表示。该脚本封装了确保角色头部、左手和右手的准确跟踪和更新的功能。'
- en: 'Let’s have a look at the beginning of this script:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个脚本的开始部分：
- en: '[PRE12]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Besides importing the regular Unity and PUN namespaces, a class named `NetworkPlayer`
    inheriting from `MonoBehaviour` is declared. The `Transform` variables, `head`,
    `leftHand`, and `rightHand`, represent the 3D position, rotation, and scale of
    a player’s VR avatar components in the game. The `PhotonView` component is fundamental
    for PUN, determining ownership and synchronization of objects in multiplayer.
    `InputActionAsset`, called `xriInputActions`, is a Unity-configured set of input
    definitions tailored for VR headsets. The `InputActionMap` variables, such as
    `headActionMap`, group related input actions, allowing for organized handling
    of inputs such as head or hand movements. Finally, the `InputAction` variables
    such as `headPositionAction` and `headRotationAction` detect individual input
    movements from the VR headset. To synchronize the player’s real-world VR movements
    with their in-game avatar, we need methods in our script. Let’s start with the
    first one:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 除了导入常规的Unity和PUN命名空间外，还声明了一个名为`NetworkPlayer`的类，该类继承自`MonoBehaviour`。`Transform`变量，如`head`、`leftHand`和`rightHand`，代表玩家在游戏中的VR角色组件的3D位置、旋转和缩放。`PhotonView`组件对于PUN至关重要，它决定了多玩家游戏中对象的拥有权和同步。`InputActionAsset`，称为`xriInputActions`，是Unity配置的一组针对VR头戴式设备的输入定义。`InputActionMap`变量，例如`headActionMap`，将相关的输入动作分组，以便有组织地处理如头部或手部动作等输入。最后，`InputAction`变量，如`headPositionAction`和`headRotationAction`，检测来自VR头戴式设备的单个输入动作。为了同步玩家的现实世界VR动作与其游戏中的角色，我们需要在脚本中实现方法。让我们从第一个方法开始：
- en: '[PRE13]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In the `Start()` method, `photonView` is initialized. Then, action maps of the
    head, left hand, and right hand are retrieved using their names. These names (`XRI
    Head`, `XRI LeftHand`, and `XRI RightHand`) are predefined in `Position` and `Rotation`
    actions for the head and each hand are retrieved. Lastly, all these actions are
    enabled so that they begin reading input values.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Start()`方法中，初始化`photonView`。然后，使用它们的名称检索头部、左手和右手的动作图。这些名称（`XRI Head`、`XRI
    LeftHand`和`XRI RightHand`）在头部的`Position`和`Rotation`动作以及每个手的动作中是预定义的。最后，启用所有这些动作，以便它们开始读取输入值。
- en: 'The next method in our script is the `Update()` method:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们脚本中的下一个方法是`Update()`方法：
- en: '[PRE14]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In a Photon-powered multiplayer environment, numerous `NetworkPlayer` instances
    will emerge, representing each player in the game. However, on every player’s
    device, only a single instance genuinely represents that specific player, while
    the rest signify remote players. The `photonView.IsMine` property, when checked
    within the `Update()` method’s `if` statement, determines whether the `NetworkPlayer`
    instance on a given machine corresponds to the player using that machine. This
    differentiation is pivotal in multiplayer scenarios to identify who has control
    over certain activities or decisions. If it returns true, then the `NetworkPlayer`
    instance pertains to the local player of that device. Consequently, the visual
    representation of that player’s head and hands is deactivated, ensuring a seamless
    user experience.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个由光子驱动的多人游戏环境中，将出现许多 `NetworkPlayer` 实例，代表游戏中的每个玩家。然而，在每个玩家的设备上，只有一个实例真正代表该特定玩家，其余的则表示远程玩家。在
    `Update()` 方法的 `if` 语句中检查 `photonView.IsMine` 属性，可以确定给定机器上的 `NetworkPlayer` 实例是否对应于使用该机器的玩家。这种区分在多人场景中至关重要，用于识别谁控制某些活动或决策。如果返回值为
    `true`，则表示该 `NetworkPlayer` 实例属于该设备的本地玩家。因此，该玩家头部和手部的视觉表示被禁用，确保用户体验的流畅性。
- en: 'Within our multiplayer scene, two primary players exist: our local player (via
    `Network Player`). This remote player is visible to all other participants in
    the multiplayer environment. As the local player already has hand models, introducing
    an additional hand model from the remote player can lead to a disorienting experience,
    particularly given network update latencies, as you can see in *Figure 8**.11*.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的多人场景中，存在两个主要玩家：我们的本地玩家（通过 `Network Player`）。这个远程玩家对所有其他多人环境中的参与者都是可见的。由于本地玩家已经有了手部模型，引入远程玩家的额外手部模型可能会导致令人困惑的体验，尤其是在网络更新延迟的情况下，如
    *图 8.11* 所示。11*。
- en: '![Figure 8.11 – What happens when the SetActive(false) statements are not implemented](img/B20869_08_11.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.11 – 当未实现 SetActive(false) 语句时会发生什么](img/B20869_08_11.jpg)'
- en: Figure 8.11 – What happens when the SetActive(false) statements are not implemented
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 – 当未实现 SetActive(false) 语句时会发生什么
- en: Thus, we ensure the elements of `Network Player` remain invisible to the user.
    Conversely, if the property returns `false`, it means the instance represents
    another participant as viewed from that device. Finally, the `if` statement also
    updates the position and rotation of the hands and head based on VR headset or
    VR controller movements using the `MapPosition()` method.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们确保 `Network Player` 的元素对用户不可见。相反，如果属性返回 `false`，则表示该实例代表从该设备看到的另一个参与者。最后，`if`
    语句还使用 `MapPosition()` 方法根据 VR 头盔或 VR 控制器的移动更新手部和头部位置和旋转。
- en: 'Now, let’s have a look at the `MapPosition()` method:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 `MapPosition()` 方法：
- en: '[PRE15]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The purpose of the `MapPosition()` method is to assign the correct position
    and rotation to the passed-in `if` statement and reads the corresponding input
    values. For example, if the node is `XRNode.Head`, it reads the position and rotation
    values from `headPositionAction` and `headRotationAction`, respectively. These
    `InputAction` variables fetch the latest position and rotation values from the
    VR headset at every frame. Finally, the `MapPosition()` method assigns the fetched
    position and rotation to the passed-in target transform.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`MapPosition()` 方法的目的是为传入的 `if` 语句分配正确的位置和旋转，并读取相应的输入值。例如，如果节点是 `XRNode.Head`，它分别从
    `headPositionAction` 和 `headRotationAction` 读取位置和旋转值。这些 `InputAction` 变量在每一帧从
    VR 头盔获取最新的位置和旋转值。最后，`MapPosition()` 方法将获取到的位置和旋转分配给传入的目标变换。'
- en: In essence, this method ensures that the in-game representation of the player
    moves in sync with their real-world movements in VR.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，此方法确保玩家在游戏中的表示与他们在现实世界中的 VR 移动同步。
- en: 'The last method in this script is the `OnDestroy()` method:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本中的最后一个方法是 `OnDestroy()` 方法：
- en: '[PRE16]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `OnDestroy()` method simply disables all the input actions when the script
    is destroyed, ensuring no unwanted input readings are occurring in the background.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`OnDestroy()` 方法在脚本被销毁时简单地禁用所有输入动作，确保在后台没有发生不想要的输入读取。'
- en: Overall, the `NetworkPlayer` script serves as a bridge, translating a player’s
    real-world VR movements into the virtual multiplayer space. By adding this script
    to our scene, players can experience a synchronous and immersive VR multiplayer
    environment.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，`NetworkPlayer`脚本充当一座桥梁，将玩家的现实世界VR动作转换为虚拟多玩家空间。通过将此脚本添加到我们的场景中，玩家可以体验同步和沉浸式的VR多玩家环境。
- en: When we test the application now, we can see the head and both of the hands
    somewhere in the scene aligned with our controller position. Next, we’ll animate
    our hands when we press the trigger and grip button.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们现在测试应用程序时，我们可以在场景中某个位置看到头部和两只手与我们的控制器位置对齐。接下来，我们将当按下扳机和握持按钮时动画化我们的手。
- en: Animating the hand models
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手部模型动画
- en: Your multiplayer application has come a long way. Now, let’s take the immersion
    one step further with hand animations. By mapping controller inputs to these animations,
    users will experience a heightened realism within the virtual world. If animations
    sound foreign to you, we recommend a quick detour to the *Understanding animations
    and animator systems* section of [*Chapter 5*](B20869_05.xhtml#_idTextAnchor016).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 您的多玩家应用程序已经取得了长足的进步。现在，让我们通过手部动画进一步增加沉浸感。通过将这些控制器输入映射到这些动画，用户将在虚拟世界中体验到更高的真实感。如果您对动画感到陌生，我们建议您快速浏览[*第五章*](B20869_05.xhtml#_idTextAnchor016)中的*理解动画和动画系统*部分。
- en: 'Within the `Prefabs` folder and then follow these steps:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Prefabs`文件夹中，然后按照以下步骤操作：
- en: Attach an `Animator`.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个`Animator`。
- en: In [*Chapter 5*](B20869_05.xhtml#_idTextAnchor016), we touched on **Animator**
    in Unity, which is essential for controlling character animations. **Animator**
    needs **Animator Controller** to manage how animations transition and interact.
    It also requires **Avatar**, which is a map of the character’s skeletal structure,
    ensuring animations fit and move realistically on the character.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在[*第五章*](B20869_05.xhtml#_idTextAnchor016)中，我们提到了Unity中的**Animator**，这对于控制角色动画至关重要。**Animator**需要**Animator
    Controller**来管理动画的过渡和交互。它还需要**Avatar**，这是一个映射角色骨骼结构的图，确保动画适合并在角色上真实地移动。
- en: 2. For our avatars, we can select the **L_hand_skeletal_lowres** and **R_hand_skeletal_lowres**
    options from **Multiplayer Scene** | **Oculus** **Hands** | **Models**.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 对于我们的头像，我们可以从**Multiplayer Scene** | **Oculus Hands** | **Models**中选择**L_hand_skeletal_lowres**和**R_hand_skeletal_lowres**选项。
- en: 3. However, we’re yet to acquire `Left Hand Animator` and `Right` `Hand Animator`.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 然而，我们还没有获得`Left Hand Animator`和`Right Hand Animator`。
- en: 'Double-click on `Left Hand Animator` to reveal an **Animator** window showcasing
    **Layers** and a **Parameters** tab. Start with the **Parameters** tab and introduce
    **Grip** and **Trigger** parameters, both of the *float* type. They indicate the
    pressure intensity of the trigger and grip actions:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 双击`Left Hand Animator`以显示一个**Animator**窗口，展示**Layers**和**Parameters**选项卡。从**Parameters**选项卡开始，引入**Grip**和**Trigger**参数，它们都是*float*类型。它们表示扳机和握持动作的压力强度：
- en: '**Trigger** determines the degree of the hand’s pinch'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Trigger**确定手部捏合的程度'
- en: '**Grip** governs the degree of the fist’s bend'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grip**控制拳头的弯曲程度'
- en: 'However, simply having these parameters won’t magically animate the fingers.
    To bring them to life, we need to bind these parameters to specific animation
    states or integrate them within blend trees. These concepts have different approaches
    to connecting animation states, so let’s compare them to see which approach fits
    our needs the best:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅拥有这些参数并不能神奇地让手指活动起来。为了让它们栩栩如生，我们需要将这些参数绑定到特定的动画状态或集成到混合树中。这些概念在连接动画状态方面有不同的方法，所以让我们比较一下，看看哪种方法最适合我们的需求：
- en: '`0.5`, the hand might transition to **HandClosed**; otherwise, it will remain
    in the **HandOpen** state.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0.5`，手可能会过渡到**HandClosed**状态；否则，它将保持在**HandOpen**状态。'
- en: '**Blend trees** enable seamless transitioning between multiple animations depending
    on one or more parameters. It’s analogous to using a music mixer to blend songs.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合树**可以根据一个或多个参数在多个动画之间实现无缝过渡。这就像使用音乐混音器混合歌曲一样。'
- en: 'For hand animations, it is useful to have three states: **HandOpen**, **HandHalfClosed**,
    and **HandFullyClosed**. Instead of basic transitions, which can feel abrupt,
    a blend tree can be used to fluidly move between these states, all based on the
    **Grip** value. This is why it is the best choice for our needs.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 对于手部动画，拥有三个状态很有用：**HandOpen**、**HandHalfClosed**和**HandFullyClosed**。而不是基本过渡，这可能会感觉生硬，可以使用混合树在状态之间流畅地移动，所有这些都基于**Grip**值。这就是为什么它是我们需求的最佳选择。
- en: To set up a blend tree, right-click in the **Base Layer** window’s center and
    opt for **Create State** | **From New Blend Tree**. Your **Baser Layer** window
    should be similar to what’s shown in *Figure 8**.12*.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置混合树，在**基础层**窗口的中心处右键单击，并选择**创建状态**|**从新混合树**。你的**基础层**窗口应该类似于*图8.12*中所示。
- en: '![Figure 8.12 – Base Layer in the Animator window](img/B20869_08_12.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图8.12 – 动画器窗口中的基础层](img/B20869_08_12.jpg)'
- en: Figure 8.12 – Base Layer in the Animator window
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 – 动画器窗口中的基础层
- en: 'By double-clicking on **Blend Tree** and selecting it afterward, you’ll be
    prompted to select a **Blend Type** property, which includes the following:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 通过双击**混合树**并随后选择它，你会被提示选择一个**混合类型**属性，它包括以下内容：
- en: '**1D**: This pivots around a single parameter, such as pacing, to transition
    between animations such as walking and running'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1D**：这围绕一个单一参数旋转，例如步伐，以在行走和跑步等动画之间切换'
- en: '**2D Freeform Cartesian**: This employs two separate parameters – for instance,
    determining animation intensity based on a character’s mood and energy levels'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2D自由形式笛卡尔坐标系**：这使用两个独立的参数，例如，根据角色的情绪和能量水平确定动画强度'
- en: '**2D Freeform Directional**: Here, two parameters act as directional vectors,
    such as aiming a weapon in horizontal and vertical directions'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2D自由形式方向性**：在这里，两个参数作为方向向量，例如，在水平和垂直方向上瞄准武器'
- en: '**2D Simple Directional**: Typically, this uses two parameters, often *X* and
    *Y* inputs, resembling a joystick’s movements, to determine character direction'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2D简单方向性**：通常，这使用两个参数，通常是*X*和*Y*输入，类似于摇杆的运动，以确定角色方向'
- en: 'For nuanced hand animations using both **Grip** and **Trigger**, **2D Freeform
    Cartesian** is ideal. Each parameter operates autonomously: **Grip** dictates
    the intensity of the fist, while **Trigger** oversees the pinching gesture. Adjust
    **Blend Type** to **2D Freeform Cartesian**, then designate **Grip** for the *X*-axis
    and **Trigger** for the *Y*-axis in the **Inspector** window. In the same window,
    we need to define some key motions.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用**握把**和**扳机**的细微手部动画，**2D自由形式笛卡尔坐标系**是理想的。每个参数独立操作：**握把**决定了拳头强度，而**扳机**则负责捏合手势。将**混合类型**调整为**2D自由形式笛卡尔坐标系**，然后在**检查器**窗口中将**握把**指定为*X*轴，将**扳机**指定为*Y*轴。在同一个窗口中，我们需要定义一些关键动作。
- en: 'For a solid setup, you should consider the following four key motions depicting
    the extremities of the hand movements:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个固定位置，你应该考虑以下四个关键动作，描述手部动作的极限：
- en: '`0`. Fortunately, we don’t need to create such an animation clip ourselves
    as the `Multiplayer Scene` | `Oculus Hands` | `Animations`folder.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0`。幸运的是，我们不需要自己创建这样的动画剪辑，因为`Multiplayer Scene`|`Oculus Hands`|`Animations`文件夹中已经有了。'
- en: '`0` and the `1`. This would be the **l_hand_pinch_anim** animation clip, which
    is in the same folder as **Take 001**.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0`和`1`。这将是在同一文件夹中**Take 001**的**l_hand_pinch_anim**动画剪辑。'
- en: '`1` and a `0`. That would be the `Animations` folder as before.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`和`0`。这将是之前的`Animations`文件夹。'
- en: '`1` for both cases. This would also be the `1`.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这两种情况下都是`1`。这也会是`1`。
- en: If you did everything correctly, your **Blend Tree** should look as shown in
    *Figure 8**.13*.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你一切操作正确，你的**混合树**应该看起来像*图8.13*中所示的那样。
- en: '![Figure 8.13 – The Blend Tree settings in Unity](img/B20869_08_13.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图8.13 – Unity中的混合树设置](img/B20869_08_13.jpg)'
- en: Figure 8.13 – The Blend Tree settings in Unity
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13 – Unity中的混合树设置
- en: Repeat this process for the **Right Hand** animator controller. Once we’ve done
    this, we can drag the just-created **Left Hand** and **Right Hand** animator controllers
    into the corresponding fields of the **Left Hand Model** and **Right Hand** **Model**
    prefabs.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 为**右手**动画控制器重复此过程。一旦我们完成这个，我们可以将刚刚创建的**左手**和**右手**动画控制器拖入**左手模型**和**右手模型**预制件的相应字段。
- en: Next, we just need to create a script that will link the **Grip** and **Trigger**
    variables’ float values to the button inputs of our controller.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们只需要创建一个脚本，将**握把**和**扳机**变量的浮点值链接到控制器的按钮输入。
- en: Enabling the hand animations at runtime
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在运行时启用手部动画
- en: In this section, we’ll be delving into the process of enabling hand animations
    in real time within our multiplayer VR application. This means that during the
    actual gameplay, as users interact with the virtual environment and other players,
    they can witness and experience hand gestures such as pinching or making a fist.
    This real-time interaction enhances the immersion and interactivity of our multiplayer
    VR game. By integrating these animations at runtime, users can seamlessly respond
    to game mechanics or communicate non-verbally with other players.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨在多人 VR 应用程序中实时启用手部动画的过程。这意味着在实际游戏过程中，当用户与虚拟环境和其他玩家互动时，他们可以见证并体验捏合或攥拳等手势。这种实时交互增强了我们的多人
    VR 游戏的沉浸感和交互性。通过在运行时集成这些动画，用户可以无缝地响应游戏机制或与其他玩家进行非语言交流。
- en: 'We are going to do this by creating a script to hold our `HandControllerPresence`
    into the search bar, create a new script with the same name, and then open it.
    We’ll start by defining the necessary variables:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过创建一个脚本将我们的 `HandControllerPresence` 放入搜索栏，创建一个具有相同名称的新脚本，然后打开它。我们将首先定义必要的变量：
- en: '[PRE17]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`handVisualizationPrefab` is a public GameObject variable that refers to the
    hand model prefab that will be animated based on the user’s VR controller inputs.
    In our case, this will be the `triggerAction` and `gripAction` are serialized
    fields, meaning they can be assigned in the Unity Editor but remain private in
    the script. They are designed to fetch the current values of the trigger and grip
    inputs, respectively.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '`handVisualizationPrefab` 是一个公共的 GameObject 变量，它引用了基于用户 VR 控制器输入将要被动画化的手部模型预制体。在我们的案例中，这将包括
    `triggerAction` 和 `gripAction` 序列化字段，这意味着它们可以在 Unity 编辑器中分配，但在脚本中保持私有。它们被设计用来获取触发和握持输入的当前值。'
- en: '`instantiatedHandVisual` and `handMotionController` are private variables that
    are used internally. The former stores the instantiated hand model in the scene,
    while the latter is a reference to the `Awake()` and `InitializeHandController()`
    methods:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '`instantiatedHandVisual` 和 `handMotionController` 是内部使用的私有变量。前者存储场景中的实例化手部模型，而后者是
    `Awake()` 和 `InitializeHandController()` 方法的引用：'
- en: '[PRE18]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `Awake()` method is called when the script instance is loaded. Here, it
    calls the `InitializeHandController()` method to set up the hand visuals and animations.
    This method instantiates the hand model prefab in the scene and attaches it to
    the object to which this script is attached. Then, it fetches and stores the `handMotionController`
    variable. This `AdjustHandMotion()` method:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 当脚本实例被加载时，会调用 `Awake()` 方法。在这里，它调用 `InitializeHandController()` 方法来设置手部视觉和动画。此方法在场景中实例化手部模型预制体并将其附加到脚本所附加的对象上。然后，它获取并存储
    `handMotionController` 变量。此 `AdjustHandMotion()` 方法：
- en: '[PRE19]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This method fetches the current values of the trigger and grip inputs using
    the `triggerAction` and `gripAction` variables, respectively. These values are
    in the range of 0 (not pressed) to 1 (fully pressed).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用 `triggerAction` 和 `gripAction` 变量分别获取触发和握持输入的当前值。这些值在 0（未按下）到 1（完全按下）的范围内。
- en: 'The fetched values (`triggerIntensity` and `gripIntensity`) are then passed
    to the hand’s `SetFloat()` method. This effectively adjusts the hand’s animation
    based on the real-time inputs from the VR controller. Finally, we just need to
    call this method once per frame to ensure that the hand’s animations are updated
    in real time to match the user’s VR controller inputs. This is done in the `Update()`
    method:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 获取的值（`triggerIntensity` 和 `gripIntensity`）随后传递给手的 `SetFloat()` 方法。这实际上根据 VR
    控制器的实时输入调整手的动画。最后，我们只需每帧调用此方法一次，以确保手的动画能够实时更新以匹配用户的 VR 控制器输入。这是在 `Update()` 方法中完成的：
- en: '[PRE20]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now, we just need to assign the corresponding `handVisualiationPrefab` and the
    controller actions to the **Trigger Action** and **Grip Action** fields for both
    controllers, as shown in *Figure 8**.14* for the left controller.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需要将相应的 `handVisualiationPrefab` 和控制器动作分配给两个控制器的 **触发动作** 和 **握持动作** 字段，如图
    *图 8**.14* 所示的左侧控制器。
- en: "![Figure 8.14 – \uFEFFThe HandControllerPresence script and its references\uFEFF\
    ](img/B20869_08_14.jpg)"
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.14 – 手部控制器存在脚本及其引用](img/B20869_08_14.jpg)'
- en: Figure 8.14 – The HandControllerPresence script and its references
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.14 – 手部控制器存在脚本及其引用
- en: You might be wondering why exactly are we using the **XRI LeftHand** references
    shown in *Figure 8**.14*. In our scene, we are using **XR Interaction Setup**,
    which comes with the XR Interaction Toolkit’s **Starter Assets**. This **XR Interaction
    Setup** uses **XRI Default Input Actions** as controller input handling.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想知道为什么我们使用*图8.14*中显示的**XRI左手**引用。在我们的场景中，我们使用**XR交互设置**，这是XR交互工具包的**起始资源**的一部分。这个**XR交互设置**使用**XRI默认输入动作**作为控制器输入处理。
- en: Let’s have a look at them by heading to **Samples** | **XR Interaction Toolkits**
    | **Your** **Version** | **Starter Assets** and double-clicking on **XRI Default
    Input Actions**. This will open the window shown in *Figure 8**.15*.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 通过转到**样本** | **XR交互工具包** | **您的** **版本** | **起始资源**并双击**XRI默认输入动作**来查看它们。这将打开*图8.15*所示的窗口。
- en: '![Figure 8.15 – The XRI Default Input Actions of the XR Interaction Toolkit](img/B20869_08_15.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图8.15 – XR交互工具包的XRI默认输入动作](img/B20869_08_15.jpg)'
- en: Figure 8.15 – The XRI Default Input Actions of the XR Interaction Toolkit
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.15 – XR交互工具包的XRI默认输入动作
- en: 'The XR Interaction Toolkit action-based input system in Unity allows for device-agnostic
    control setups. It uses **Action Maps** to group related actions, such as **XRI
    LeftHand Interaction**, to handle specific actions such as **Select Value** or
    **Activate Value**. These actions are then tied to specific inputs, called **bindings**,
    such as the **Grip** button or the **Trigger** button of an XR controller, allowing
    for flexible and intuitive control configurations across various XR devices. You
    can add additional action maps, actions, and bindings or change existing ones.
    You can even build a complete Input Actions setup of your own under **Assets**
    | **Create** | **Input Actions**. However, you’ll need to link this new Input
    Actions setup in the **Inspector** window of **Input Action Manager** under **Action
    Assets**. With that, we have implemented the animation of the hand models. To
    begin testing the application with a friend, follow these simple steps:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: Unity中的XR交互工具包基于动作的输入系统允许设备无关的控制设置。它使用**动作映射**来分组相关的动作，例如**XRI左手交互**，以处理特定的动作，如**选择值**或**激活值**。然后，这些动作与特定的输入相关联，称为**绑定**，例如XR控制器的**握把**按钮或**扳机**按钮，从而允许在各种XR设备上实现灵活直观的控制配置。您可以添加额外的动作映射、动作和绑定，或更改现有的绑定。您甚至可以在**资产**
    | **创建** | **输入动作**下构建自己的完整的输入动作设置。然而，您需要在**输入动作管理器**的**动作资产**下的**检查器**窗口中链接此新的输入动作设置。有了这个，我们就实现了手模型动画。要开始与朋友测试应用程序，请按照以下简单步骤操作：
- en: Open your Unity project and navigate to **File**, then **Build Settings**.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开您的Unity项目，然后转到**文件**，然后**构建设置**。
- en: Add the currently open scene to **Build Settings**.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将当前打开的场景添加到**构建设置**中。
- en: Click on the **Build** option. When prompted, choose a directory that you can
    easily access and remember.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**构建**选项。当提示时，选择一个您可以轻松访问并记住的目录。
- en: This action will generate an executable file along with other vital scene-related
    files in the chosen directory. For your friend to join in, share the entire folder
    with them.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此操作将在所选目录中生成可执行文件以及其他与场景相关的关键文件。为了让您的朋友加入，请与他们分享整个文件夹。
- en: Initiate your connection to the server by pressing the **Play** button. As you
    await your connection, instruct your friend to launch the executable file.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过按下**播放**按钮来启动到服务器的连接。在您等待连接时，指示您的朋友启动可执行文件。
- en: And voilà! You’ve successfully set up your first multiplayer environment. Now,
    both you and your friend can interact, as depicted in *Figure 8**.16*.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！您已经成功设置了您的第一个多人游戏环境。现在，您和您的朋友可以像*图8.16*所示的那样互动。
- en: '![Figure 8.16 – Me and my friend in our multiplayer environment](img/B20869_08_16.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![图8.16 – 我和我的朋友在我们的多人游戏环境中](img/B20869_08_16.jpg)'
- en: Figure 8.16 – Me and my friend in our multiplayer environment
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.16 – 我和我的朋友在我们的多人游戏环境中
- en: Note
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You might have noticed a stunning deep-space background with a picturesque planet.
    This aesthetic touch is provided by the Skybox Volume 2 package, which we imported
    from the Unity Asset Store ([https://assetstore.unity.com/packages/2d/textures-materials/sky/skybox-volume-2-nebula-3392](https://assetstore.unity.com/packages/2d/textures-materials/sky/skybox-volume-2-nebula-3392)).
    It significantly enhances the ambiance of our environment.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到了一个令人惊叹的深空背景和一幅如画的星球。这种美学效果是由我们从Unity Asset Store导入的Skybox Volume 2包提供的（[https://assetstore.unity.com/packages/2d/textures-materials/sky/skybox-volume-2-nebula-3392](https://assetstore.unity.com/packages/2d/textures-materials/sky/skybox-volume-2-nebula-3392)）。它显著增强了我们环境的氛围。
- en: As we approach the end of this chapter, you should now feel capable and confident
    in enhancing your XR experiences using advanced techniques. However, this doesn’t
    imply that every feature, such as eye-tracking or hand-tracking, should be mindlessly
    applied to all your projects. Nor does it imply that all your subsequent XR endeavors
    must be multiplayer applications.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 随着本章接近尾声，你现在应该能够自信地使用高级技术来增强你的XR体验。然而，这并不意味着你应该不加思考地将每个功能，例如眼动追踪或手势追踪，应用到所有项目中。同样，这也不意味着你后续的所有XR努力都必须是多玩家应用。
- en: 'What it does mean is that you’ve broadened your horizons. You now possess a
    richer repertoire of interaction techniques to create your XR applications. Instead
    of indiscriminately applying eye-tracking to every scene element, for instance,
    you can selectively use it for components that would truly benefit from it. Imagine
    a virtual exhibition of firefighter vehicles: rather than overloading the user
    with information, you could seamlessly display technical specifications when the
    user’s gaze settles on a particular vehicle. Interactive components such as animated
    firefighters or explorable vehicle interiors can be activated based on the user’s
    visual focus, providing an engaging and dynamic user experience. Similarly, in
    a treasure-hunting game, a hint might reveal itself when a player’s gaze meets
    a mystical mirror. The possibilities are endless!'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 它真正意味着的是，你的视野已经拓宽。你现在拥有更丰富的交互技巧来创建你的XR应用程序。例如，你不再可以不加区分地将眼动追踪应用到每个场景元素上，而是可以选择性地将其用于真正从中受益的组件。想象一下消防车虚拟展览：你不必让用户负担过多的信息，当用户的目光停留在特定的车辆上时，可以无缝地显示技术规格。基于用户的视觉焦点，可以激活交互式组件，如动画消防员或可探索的车辆内部，从而提供引人入胜且动态的用户体验。同样，在寻宝游戏中，当玩家的目光遇到神秘的镜子时，可能会出现提示。可能性是无限的！
- en: Summary
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to implement hand-tracking, gaze-tracking,
    and multiplayer capabilities into your XR scenes. Incorporating these high-level
    XR methods into your future XR projects will enable you to create much more intuitive,
    immersive, and fun experiences for users. Combined with the knowledge you gained
    in the previous chapters on how to create and deploy interactive XR experiences,
    you should feel comfortable developing a wide range of XR projects yourself, no
    matter if they involve coding, animations, particles, audio, or multiplayer support.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何将手势追踪、注视追踪和多玩家功能集成到你的XR场景中。将这些高级XR方法融入你未来的XR项目中，将使你能够为用户创造更加直观、沉浸和有趣的体验。结合你在前几章中学到的如何创建和部署交互式XR体验的知识，你应该能够自信地开发各种XR项目，无论它们涉及编码、动画、粒子、音频还是多玩家支持。
- en: Now that you have a firm grip on the technical and programming aspects of XR,
    the next chapter will shift the spotlight to the business realm of XR. There,
    you’ll explore powerful XR plugins and toolkits beyond the XR Interaction Toolkit,
    ARKit, ARCore, and AR Foundation that could be valuable additions to your XR development
    skills moving forward. The subsequent chapter won’t just keep you up to date on
    the latest trends in XR but will also equip you with industry best practices to
    ensure the success of your projects.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经掌握了XR的技术和编程方面，下一章将聚焦于XR的商业领域。在那里，你将探索XR Interaction Toolkit、ARKit、ARCore和AR
    Foundation之外的强大XR插件和工具包，这些可以作为你未来XR开发技能的有价值补充。下一章不仅会让你了解XR的最新趋势，还会为你提供行业最佳实践，以确保你项目的成功。
