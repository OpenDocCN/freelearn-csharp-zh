- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Service Orientation and APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have explained many principles and several methods, we are going
    to move on to chapters that will be a bit more technical and thus will show more
    examples being applied to our demonstration application. In this chapter, we will
    explain the notion of *service* from the IT perspective and will try to place
    services in the history of IT to give you a good understanding of what they are
    for and what they have brought to the industry. There are still shortcomings,
    of course, but web-oriented architecture and web services in general bring huge
    value to the software industry when they are correctly designed (which, sadly,
    is far from being common).
  prefs: []
  type: TYPE_NORMAL
- en: After this examination of the history of services, we will detail the characteristics
    of a good service-based architecture (I am not using the expression *Service-Oriented
    Architecture* for a precise reason, as you will discover shortly) and explain
    how their current evolution, namely REST APIs, can be of benefit to many software
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will show how the architecture patterns seen in the previous chapter
    apply to the definition of services for the demo application. To do so, we will
    of course use REST APIs since they are at the core of every modern approach to
    IT system architecture. We will come back to the notion of standards, which was
    heavily discussed in [*Chapter 2*](B21293_02.xhtml#_idTextAnchor038), and explain
    which ones can be used in our demonstration system. Finally, we will explain what
    we can do when no standards exist or apply, and this will form the transition
    point to the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll cover the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the history of service orientation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Characteristics of a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application to our demonstration system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at the history of service orientation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First of all, let’s start with a bit of history. it may be because I am an
    old-timer and have been programming for the past 37 years, with 25 of them in
    industrial contexts, but I think it is always interesting to know where we are
    coming from as this explains a lot of what technologies today have been created
    for, and what they still miss. This way, not only can we anticipate the shortcomings
    of certain techniques and software artifacts, but we also avoid the risk of not
    using them to their full potential, as intended by their creators. Unrolling the
    history of technologies has yet another advantage: while strolling along this
    path, you may stumble upon an old but still interesting technology that may better
    fit your context than the new kid on the block. This does not happen so often,
    but when it does and you can solve your IT problem with a battle-hardened, yet
    simpler technology than the tools generally used at present, it can provide you
    a huge boost in maintenance time and performance. For example, files-based interop
    may seem laughable to someone using web APIs every day, but in particular, contexts
    where asynchronous is better, security is not a problem, independence of the process
    is an advantage, and avoiding the deployment of a web server is a time-saver,
    they can be the perfect solution.'
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s start this journey with interop techniques, and in particular begin
    with why we need them.
  prefs: []
  type: TYPE_NORMAL
- en: The long-awaited reusability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Making two parts of a software entity interop with each other is a concept
    almost as old as programming itself since it is related to reusability. For a
    common function to not need to be typed twice, there needs to be a way to separate
    it from the rest of the code that is different, and make it callable, one way
    or another, by these pieces of code. This can be easily schematized as shown in
    *Figure 8**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Reusing common code](img/B21293_08_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Reusing common code
  prefs: []
  type: TYPE_NORMAL
- en: Code duplication is a problem (although the Don’t Repeat Yourself principle
    may have its own shortcomings and every programming choice is always a compromise),
    so putting some code in common is generally a valuable orientation. There are
    lots of ways to organize this, and reusability has been sought after like the
    Graal in IT for many years, even decades.
  prefs: []
  type: TYPE_NORMAL
- en: Routines and avoiding punching additional paper cards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first attempt at reusability came from an era that most of you will not
    even know about, where programs existed in the form of paper cards punched with
    holes to provide instructions to the computer. This actually came from the Jacquard
    weaving mechanisms where these paper cards were used to control cloth threads
    in semi-automated machines to make certain figures and weaving patterns appear
    in the resulting cloth. Repeatability was already possible by using the same card
    again and again, but the reuse of a pattern on a given card was done by punching
    the card many times in the exact same way, resulting in a long manual process
    and involving the risk of errors. Also, each application, composed of boxes with
    punched cards in the exact order, had to contain every single instruction. Due
    to the fixed number of instructions that could fit on a card, it was practically
    impossible that a card could be reused in another stack. Even if it was possible,
    extracting the right card, using it, and then returning it to the right position
    in the stack would have been too dangerous for both applications involved, particularly
    with regard to duplicating the paper card, even if it was a manual operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then came the idea of routines and sending the code back to a given address
    of the program to make it repeat some part of its instructions. The notion associated
    with the infamous (but still worthy) `GOTO` instruction was born, and it saved
    many instructions in the programs that followed. But there was a problem: routines
    could only be used inside a single program. Admittedly, it helped reduce their
    size. Nonetheless, when creating a new program, it was still necessary to type
    in the same code – and we’re talking about a time when copy-paste simply did not
    exist. So, there was a need for something better. This is what we are going to
    explore in the coming sections.'
  prefs: []
  type: TYPE_NORMAL
- en: Libraries and the capacity to share instructions between programs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next evolution of reuse was the concept of `.dll` files, or Java modules
    in `.jar` archives, are still the foundations of reuse, and universality is not
    far when Base Class Libraries like the one from Microsoft are evidence for all
    .NET programmers. For this particular framework that started under the strict
    control of Microsoft and progressively flourished into open-source availability,
    history has been a blessing, since lots of libraries are simply implemented once
    and for all. Java, on the other side, started as a more open platform but became
    progressively more closed after the buying of Sun by Oracle. Though things start
    to unify a bit (at the price of a slower evolution), there still are many libraries
    to do the same thing within the Java ecosystem. I remember being flabbergasted
    with my first professional developments in Java, after five years of .NET, by
    the fact that there was not a single XML parser library, but many of them, each
    being the best at one thing: Xerces being good at streaming analysis; Xalan recognized
    as the quickest at fully loading an XML DOM; some other library handling the DTD
    schemas and validation better; and so on. For someone used to having only `System.Xml`
    to think about, that was a huge surprise and a big disappointment, since it made
    the learning curve all of a sudden dramatically steeper than the closeness of
    the platform and language led me to expect.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyhow, libraries are certainly the most widespread approach for reuse in programming
    platforms and exist in almost all modern languages, be it JavaScript, Python,
    C or C++, and so on. Though libraries also have their difficulties, not only in
    the versioning and forward-compatibility areas but also in the ease of copying
    a file, which sometimes ends up in multiple copies in a code base (which goes
    against the initial goal of reuse), they remain the go-to approach when reuse
    is necessary. Of course, as far as interop is needed, they have pronounced shortcomings
    since they are only usable in their own execution platforms: though bridges may
    exist, a Java library can only be used by a Java program, a .NET assembly can
    only be called by another .NET assembly, and so on. This is a problem that has
    occupied IT engineers for a long time and is where lots of solutions have appeared.'
  prefs: []
  type: TYPE_NORMAL
- en: Attempts at general interoperability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main solution to the aforementioned limitation was to create libraries
    that contained code in a compiled form, in such a way that the machine code was
    usable from any caller, whatever language was used to create the calling program,
    as long as it was also compiled in machine-readable code. The difficulty there
    was mostly technical: calling one such library was not as simple as using a function
    name and attributes. Also, there was still a limitation due to the platform of
    compilation. There was indeed no way to execute a Windows library inside a Linux
    operating system and vice versa.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Microsoft actually tried to go a bit further in this direction by introducing
    the notion of OS-controlled components. These reusable units were not directly
    available as files but as entities known by the operating system itself: their
    concrete form was still filed, with the `.dll` extension, but when *registered*,
    Windows would make the functions available to any program even if it did not have
    access to the original file. In addition to being a repository for application
    customization, the registry also stores the necessary information for the **Component
    Object Model** (**COM**); in fact, it even started its career in Windows 3.11
    mostly for this use. Together with COM, a Microsoft technology called Dynamic
    Data Exchange allowed application components to be inserted into one another.
    This is what you use today when you open an Excel worksheet inside a Word document
    and see the menus adapt.'
  prefs: []
  type: TYPE_NORMAL
- en: After COM came extensions such as COM+, then for **Distributed COM** (**DCOM**),
    which was an attempt at breaking out of the perimeter of the local computer and
    introducing remote execution of components. These did not have the same success
    as the latest innovation in this vein of components, called ActiveX. ActiveX was
    a technology built on COM to make it easier to integrate graphical components
    into applications, instead of just functions. It was even possible to embed these
    in web applications by delivering them within the browser. At a time when browser
    security was not as extended as today, it provided lots of interesting features,
    but the technology is now outdated.
  prefs: []
  type: TYPE_NORMAL
- en: Other technologies for distributed components existed, such as Enterprise Java
    Beans and all platforms using CORBA, but they had the same limitations as DCOM
    and did not exhibit the level of low coupling that was initially promised. Version
    control was left to the maintainer of the platform, no capacity existed for a
    relationship with the presentation layer, and other shortcomings made for a limited
    future for these technologies that are nowadays pure legacy.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, interoperation in the form of components might have been too humble
    to really reach the state of an ever-lasting technology such as ASCII, Unicode,
    HTTP, and some other norms that are so widely used, including as the basis for
    new approaches, that they will be around for the foreseeable future of software.
    Components started inside the perimeter of a single machine and never found a
    way to step out. A completely universal approach was necessary to make the next
    step, and it concerned bringing interoperability and reuse to a whole network
    of computers – and to be worth it, this had to be in the biggest network of all,
    the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: Using web standards to try and get universal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next milestone in our history of interop concerns web services, in the general
    acceptance of the term, meaning providing a service through web standards. The
    web was the obvious way to make this next step since its foundations of HTTP,
    TCP/IP, Unicode, and XML were already available and offered a good part of the
    foundation such a universal interop technology would need.
  prefs: []
  type: TYPE_NORMAL
- en: The first attempt at web services (or what we could call *reusable functions
    over the internet*) was implemented with technologies such as **Simple Object
    Access Protocol (SOAP)** and **Web Service Description Language (WSDL)**, and
    since these standards were alone in the field, they simply preempted the term
    *web service*, which became the accepted jargon for SOAP- and WSDL-compatible
    expositions. SOAP was about standardizing the XML content of requests and responses
    over HTTP to make them look like function calls, with an envelope, attributes
    with types, possible metadata, and so on. WSDL was the norm used to express the
    associated contract, in short, the grammar that was supposed to be used in SOAP
    messages. There were additional norms such as **Universal Description, Discovery,
    and Integration (UDDI)**, for example, but these fell short of their objectives
    and quickly declined. This was also the case for lots of the so-called *WS-**
    standards – WS-Authentication, WS-Routing, and other syntax additions to the web-service
    grammar that were intended to allow for complementary features.
  prefs: []
  type: TYPE_NORMAL
- en: These solutions gained a lot of momentum in the industry in the 2000s and were
    at their strongest in the early 2010s. In fact, they generated a whole architecture
    known as **Service Oriented Architecture (SOA)**. SOA should have remained a generic
    term, but it has become associated with particular architectures and software.
    Also, software manufacturers heavily invested in *SOA tools*, making companies
    believe that central middleware was all they needed to reach interop, while people
    knowledgeable in interoperability knew that this was only one part of the deal,
    with semantic and functional interoperability being, in fact, more critical and
    more complex to obtain than technical interoperability, which is generally the
    last mile in the process.
  prefs: []
  type: TYPE_NORMAL
- en: This of course led to lots of critics of SOA, and many articles in the mid-2010s
    announced the death of SOA and its failure to reach its goals. In the meantime,
    its spread was still huge in the industry and lots of technologies had a rebirth
    due to SOA.
  prefs: []
  type: TYPE_NORMAL
- en: The steps in middleware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Middleware applications in particular were pumped up by the SOA architecture
    and, even when they were not based on SOAP and WSDL, they were able to adapt to
    it. **Enterprise Application Integration** (**EAI**) was an old dream and supposed
    that centralized adapters made it possible for many applications in a system to
    talk to each other, with the EAI platform translating every message from one format
    to the target format. Of course, its centralized aspect was a **Single Point of
    Failure** (**SPoF**) and quite a drawback. If you add to this an update of the
    EAI bricks, which is needed every time any of the applications change its version,
    it is no wonder that these customized systems never reached maturity.
  prefs: []
  type: TYPE_NORMAL
- en: '**Extract, Transform, Load** (**ETL**) is a set of data manipulation tools,
    but they can be classified as middleware applications, particularly since lots
    of interoperability streams between applications in common information systems
    are really pure data transfer, and not business function calls. Of course, this
    is a crude middleware, but the quality of the data is more important than the
    sophistication of the tool, and a well-controlled ETL can go a long way in structuring
    streams of information. Still, ETLs are not completely adapted to digital transformation,
    and it can be easy to lose control of them. One of the companies I have consulted
    for had such a messy system of ETL jobs, with more than a thousand of them kicking
    up every night, that the whole system needed a dedicated tool to orchestrate the
    jobs in a precise sequence for them to end up in clean data in the morning. With
    the never-ending addition of new jobs, time started to become scarce during the
    low-activity periods, and after using simple solutions such as adding more server
    power and parallelizing what could be parallelized, it reached a point where the
    whole system would finish its work only after the offices had opened. This, of
    course, became an important problem that had to be dealt with using radical decisions.
    To make it worse, the jobs were so interdependent and brittle that there was never
    a night where all jobs passed and it was necessary to run a few correcting jobs
    during operations, or—for the riskiest ones—to simply wait for the next night
    to, hopefully, get the clean data. For informational purposes (and may it serve
    as a warning as well, since the sheer number of jobs makes the diagram almost
    unreadable), the following diagram shows a graph of the chronological execution
    of the jobs. This diagram is meant to be an overview of complex jobs; text readability
    is not intended.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Complex job orchestration](img/B21293_08_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Complex job orchestration
  prefs: []
  type: TYPE_NORMAL
- en: '**Message-Oriented Middlewares (MOMs)** already existed for some time but got
    a kick from SOA and AMQP, ActiveMQ, MSMQ, and RabbitMQ gaining some market visibility
    by introducing robustness in message delivery (the WS-Reliability and WS-ReliableMessaging
    standards never really made it to the top, particularly because reliability needs
    to be ensured at the application level and not only in the messaging layer). Even
    in today’s architecture, which does not use SOAP web services anymore, a MOM is
    useful to ensure full-featured transportation of particularly important messages
    in the system. Some MOM proponents argue that all messages should pass through
    the middleware, preventing applications from talking directly from one to the
    other, but this has a toll on performance and we will show that functional standards
    for messages allow the removal of the mediation layer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As far as the mediation layer is concerned, MOMs benefited a lot from a standard
    way of manipulating messages that were defined by Hohpe and Wolf ([https://www.enterpriseintegrationpatterns.com/](https://www.enterpriseintegrationpatterns.com/)),
    called **Enterprise Integration Patterns** (**EIP**). EIP defines some standard
    bricks for handling software messages, such as Multiplex, Content-Based Router,
    Enrich, and so on. By combining these basic bricks of message transformation or
    routing, a MOM was able to handle almost all possible functional situations. Apache
    Camel is the reference open-source EIP implementation, and it is used in many
    middlewares. The term *bricks* is particularly adapted to these patterns, as they
    can be explained with actual, concrete, Lego™ bricks: I have often used these
    to visually explain the concepts of software system architecture and in particular,
    how to make it evolve with minimal impact by introducing a mediation layer with
    composable actions, each of them handled by a simple assembly of Technical Lego™
    bricks, as shown in *Figure 8**.3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Enterprise Integration Patterns simulated with Lego(TM) bricks](img/B21293_08_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Enterprise Integration Patterns simulated with Lego(TM) bricks
  prefs: []
  type: TYPE_NORMAL
- en: '**Enterprise Service Buses** (**ESBs**) are the natural evolution of MOM and
    SOA, colliding with the principles of the internet. An ESB integrates all the
    technologies we have talked about in a system where there is no centralization
    anymore: the network (in TCP/UDP) is the only thing that remains central and its
    ability to adapt delivery is used to improve robustness to a node failure. At
    the same time, the *Store & Forward* pattern is used to make sure that the messages
    can almost never be lost since they are persisted and only deleted when the next
    destination has confirmed that they persisted under their control. ESBs had just
    about everything that was needed to reach the complete functional goal of interoperability
    in systems that were internet-scaled. But still, they failed, or at least did
    not succeed as much as would be expected for the ideal solution to such an important
    problem in the IT industry. In fact, ESBs added all the necessary features, but
    this was their doom. Since they could make everything, their heavy, complex machinery
    required extensive expertise to run and maintain.'
  prefs: []
  type: TYPE_NORMAL
- en: The most recent evolution – REST APIs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Then came REST, which is a much lighter way of creating web-based APIs, and
    this changed the ecosystem quite radically again. **REpresentational State Transfer
    (REST)** had been defined before 2000 but became really famous in the early 2010s.
    In the 2020s, though the part of the legacy software is huge and SOAP web services
    continue to be exploited, no new project would start based on these old technologies
    and virtually every new API project is using REST, or at least some degraded,
    not really “RESTful” approach.
  prefs: []
  type: TYPE_NORMAL
- en: In a few words, REST is about going back to the basic mechanisms of HTTP to
    allow function calls on the web. For example, instead of sending the code of the
    operation in the envelope as SOAP does, REST uses HTTP verbs such as `GET`, `POST`,
    `PUT`, `PATCH`, and `DELETE` to instruct the server on what should be done. Instead
    of sending function calls, it deals with resources just as HTTP does with the
    more-known HTML pages or images that are served through the web; it just happens
    that these resources are functionally oriented, such as a customer or a contract.
    Each of these business entities has URLs just like a web page or resource has.
    Their representation can be in HTML but is more suited to XML or JSON, the latter
    of which is also lighter than its predecessor XML. Hypermedia, format negotiation,
    and headers are also used for the equivalent interop function. Authorization is
    simply left to the equivalent feature in any HTTP call, using Basic Authentication,
    Bearer tokens, and so on. In short, REST stripped the web-based interop to the
    bone and eliminated every ounce of fat to focus on the pure and complete use of
    existing standards. REST does not actually need anything else beyond existing
    standards such as HTTP, JSON or XML, and Unicode. In this way, it is more a practice
    than a new protocol.
  prefs: []
  type: TYPE_NORMAL
- en: 'And it worked… It actually worked so well that commentators on the internet
    did not hesitate to talk about SOA 2.0, or even *SOA made right*. Some introduced
    new architectural terms such as *Web-Oriented Application* to separate this approach
    from the original SOA. The best proof of success for REST is that no editor has
    built on its fame to try and impose a proprietary implementation: REST works well
    because it does not add anything but reduces any software layer to nil since everything
    already exists, and engineers only have to use it in the way it was intended.'
  prefs: []
  type: TYPE_NORMAL
- en: What we are missing to reach actual service reusability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is where we are at the moment of writing this book, and there is absolutely
    no doubt that the situation will keep evolving, but we have reached a point where
    actual web-based interop, including between two separate entities, is an everyday
    reality for lots of companies, which is already a huge victory in itself. Sure,
    we can always go further, but the main path has been paved and the remaining tasks
    now are mostly about spreading good practices in this way of interoperating rather
    than imagining a new approach that overcomes any current shortcomings.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, most of the remaining problems are the presence of mediation connectors
    due to the lack of accepted formats for functional data exchange. If we want to
    reach the ideal place where global, universal interop will not be an issue anymore
    but rather a problem of the past, we would need to have an indisputable standard
    for each of the data streams. This is of course not possible and we are very far
    from such a satisfying state, but some precise, very widespread, and technically
    easy forms of exchange are currently covered. For example, authentication and
    identification are now well implemented by OpenID Connect, SAML, JSON Web Tokens,
    SCIM, and a few other norms. Sure, there are lots of legacy software and even
    expert engineers that do not use these, but the general orientation is that they
    are the future and everyone globally accepts this and works towards these norms,
    which will become convenience standards in the future, just as ASCII and Unicode
    are for text binary representations. A few other domains are covered, or at least
    have nice, fully-featured norms that could solve the problem, such as CMIS for
    electronic document exchanges or BPMN 2.0 for workflow modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'But the vast majority of exchanges are not covered by an indisputable standard
    and legions of connectors are still developed to establish correspondence between
    applications. This is a major waste of resources in global IT today, as these
    mediation connectors do not add any additional value to customers and end users.
    But the reality is that crafting a standard takes a lot of time, as we have seen
    in [*Chapter 2*](B21293_02.xhtml#_idTextAnchor038). Let’s try to focus on the
    positive, though: the movement is now active and the situation is getting better
    every year, with a strong interop foundation where the technical bits are now
    considered solved. Only the semantics and functional interop remain to be handled.
    This will be the subject of the next chapter but, before talking about this, we
    need to come back to the very notion of *service* and explain how a good service
    should be defined. We will then use these principles to draft the first services
    for our demonstration system using the architecture principles shown in the previous
    chapter and applying them to the demo application that has been shown previously
    and that we will develop in greater detail throughout the rest of the book.'
  prefs: []
  type: TYPE_NORMAL
- en: Characteristics of a service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Service** is such a blurry designation that a complete section will be necessary
    to give a good sense—rather than a single definition—of this concept.'
  prefs: []
  type: TYPE_NORMAL
- en: As a service explained
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The expression *as a service* is used in many formulations: **SaaS** for **Software
    as a Service**, **PaaS** for **Platform as a Service**, **CaaS** for **Containers
    as a Service**, and so on. Have you ever considered why such different things
    use this common denomination? This in itself gives maybe the best definition of
    what a service is: something that benefits from the advantages of something else
    without having to deal with the usually-associated externalities. A hotel room
    is a service because you benefit from a bed and a roof without needing to buy
    and maintain a house, or even clean the room. SaaS is a service because you can
    use the software (manipulating its interface, storing data and retrieving it,
    realizing complex computations, and exporting the results) without having to install
    the software, buy a long-term license, operate it, install new versions, and so
    on. IaaS is a service because it offers what you expect from infrastructure (CPU
    power, RAM, I/O, storage, network bandwidth, and use) without you needing to worry
    about the hardware aspect of buying servers, operating them, renting some room,
    sorting electricity and cooling, securing them physically, renewing the hardware
    when there is a failure, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This explanation of the *as a service* expression was necessary because the
    word *service* by itself is very generic and one may be a bit lost as to why we
    talk about *service-oriented architecture*, then web services in the sense of
    SOAP web services, then services in the context of the web, and so on. When we
    talk about service in this book, we really mean service as a software function
    that is proposed to a user without them having to work on its implementation:
    the user does not have to know which platform is used, where the servers are,
    and so on. They only have to know the minimal information possible, namely a URL
    and the contract defining the exchange grammar, to interoperate with the service.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Does this remind you of something? Depending on only the functional definition
    of something, without any software-associated constraint? This is something that
    has already been exposed in the book, in particular where we talked about the
    four-layer CIGREF map model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Decoupling illustrated with the CIGREF map](img/B21293_08_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Decoupling illustrated with the CIGREF map
  prefs: []
  type: TYPE_NORMAL
- en: When talking about providing a *function* *as a service*, one can view it as
    having something in the second layer from the top (the Business Capability Map)
    without having to worry about how it is implemented in the third and fourth layers
    (the technical ones).
  prefs: []
  type: TYPE_NORMAL
- en: Getting rid of middleware altogether
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The nice advantage of the *as-a-service* approach is that it allows us to get
    rid of the middleware altogether. Indeed, what we really want to avoid is the
    direct, point-to-point interop that causes a lot of coupling, as shown in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Point-to-point interoperation](img/B21293_08_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Point-to-point interoperation
  prefs: []
  type: TYPE_NORMAL
- en: 'But the middleware, while introducing an indirection layer, poses two problems.
    The first one is that it introduces an additional software complexity, which can
    be hard to maintain. The second one is that we are still in the software layer
    of the CIGREF map, and this means that, if done badly (without standardizing the
    messages), we could very well end up with two steps of coupling instead of simplifying
    it! The following schema expresses this potential danger:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Interoperation through a middleware](img/B21293_08_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Interoperation through a middleware
  prefs: []
  type: TYPE_NORMAL
- en: 'ESBs are often presented as a solution to avoid a centralized entity, but the
    way they actually work still implies the presence—though distributed—of software
    agents that can cause coupling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Interoperation with Enterprise Service Bus](img/B21293_08_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Interoperation with Enterprise Service Bus
  prefs: []
  type: TYPE_NORMAL
- en: 'One way to avoid this coupling is to standardize the messages from a functional
    point of view:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Interoperation with standardized decoupled functions](img/B21293_08_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – Interoperation with standardized decoupled functions
  prefs: []
  type: TYPE_NORMAL
- en: 'But if we reach this state where a functional standard has been created, the
    middleware actually does not need to map data anymore or translate any format,
    because the `f` and `f''` functions are actually the same (otherwise they would
    not have been included in a single stream of data). The middleware’s sole functions
    remain routing, authentication, and some other features that can simply be realized
    by HTTP and do not need any middleware. Thus, the intermediate simply disappears
    and we reach the ideal situation that was expressed previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Principle of decoupling by indirection](img/B21293_08_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – Principle of decoupling by indirection
  prefs: []
  type: TYPE_NORMAL
- en: Here, the only difficulty remaining is a functional one, that of describing
    the business-related need. Admittedly, this can be a very difficult thing to do,
    but the main difference is that this is intrinsic complexity that we need to overcome
    in any case (otherwise the software will simply not work correctly) and not accidental,
    technical complexity that steps into our design phase and adds unnecessary problems
    of versioning, maintenance, and so on. This is the essence of decoupling and making
    it easier for the system to evolve.
  prefs: []
  type: TYPE_NORMAL
- en: Again, even though this is something we should strive to achieve in as many
    cases as possible and definitely a way to create some low-coupling interop, this
    kind of interaction is not always easy to realize. MOM and other middleware systems
    will not be retired any time soon, as they remain a good choice to interoperate
    complex messages, apply mediation, and ensure robustness of delivery when it is
    not possible to put in place a complete standardization of messages in the information
    system.
  prefs: []
  type: TYPE_NORMAL
- en: External interop finally becoming a reality
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All of this may sound a bit theoretical, but this approach is what enables us
    to finally reach the stage where the interop between software `A` and software
    `B` in the preceding diagrams (*Figures 8.5* to *8.9*) does not depend on middleware
    or other artifacts that get in the way and make it complicated. The best way to
    show this is to provide a few practical examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a company I worked for in the past, two customers (a regional council and
    a town) wanted to interop in such a way that, when the regional council added
    an association to its list, the city would automatically receive the information
    and store it in its own database, provided that it was the given city of registration.
    The way this was done necessitated some important preliminary work that had been
    done by my employer, which was to define a standard format for French associations.
    Since we knew the subject well, this took only a few days and we proposed this
    format to the French government for publication in their open source forge as
    they did not have any existing standard for this. This format was the functional
    contract between the two customers. They agreed that, whatever changes they might
    make to their software, the content of the association JSON would always be the
    following (this extract is highly simplified and translated into English for improved
    readability):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'It happened that the regional council was already a customer before this project,
    so they already were using our moral person referential software based on this
    format. So, on this side, we only had to customize the event management system
    to call the second customer callback address whenever the events of creation,
    modification, or removal of an association happened. This was done with the following
    grammar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: To give a bit of explanation, webhooks are registrations of an external system
    to events emitted by the given application. In our case, when the regional council
    actors’ referential service received data of a new organization or a change in
    existing data, through the referential service’s API methods, associated events
    were raised and the aforementioned customization file extract associated these
    with calls of the provided URL. This URL was exposed by the second customer (the
    city of Saint-Nazaire) using PHP (but the specific technology doesn’t matter).
    When, for example, we applied `POST` to a new organization, the callback URL was
    called with the identifier of the created entity along with the `PUT` verb. This
    is also where we introduced the fact that the city was only interested in associations
    (not all organizations), and in particular, the ones based in their territory,
    with the `filter` attribute.
  prefs: []
  type: TYPE_NORMAL
- en: The URL implementation was then free to work as it pleased, without any dependence
    on the emitter. In some operations, the fact that there was an event on a given
    identifier was enough (for example, to deactivate the association in case of a
    `DELETE` order in the regional council information system). In some other cases,
    for example when an association was created, the JSON content—the exact grammar
    of which was agreed upon between the two participants—would be retrieved through
    a `GET` operation owing to the identifier obtained in the callback (where there
    was a use for all information of the association) or simply read in the body of
    the callback call (as the most important data were sent there, using the same
    contractual grammar, of course).
  prefs: []
  type: TYPE_NORMAL
- en: 'This example proved to be a successful experiment, as each of the customers
    was then free to evolve their systems in the way they wanted, changing technologies
    or other parameters without their partner even needing to know about it. At some
    point, the city would be interested in associations outside its own zip-code area
    and could simply register a new webhook content with the updated filter. This
    did not impact the emitter of the event, not even in its authorization scheme:
    if the city had requested to be called for associations outside its department
    (a French geographical unit between a region and a city), the event would have
    been sent, but reading the information with the help of the identifier received
    would simply end up in a `403 Forbidden` HTTP status code. This particular mechanism
    was something that initially made us decide to never send any data in the callback
    request in order to simplify authorization mechanisms. But, at some point, it
    was decided that forcing the called entity to always reply with a `GET` call to
    obtain the name and basic information of a new association was a waste of bandwidth.
    Performance was not so much an issue, but simplicity was more important in this
    context than the risk of authorization mishaps, since this data is public in France
    and easy to obtain.'
  prefs: []
  type: TYPE_NORMAL
- en: Interop made real with standards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The preceding example demonstrated a case where a particular data schema (we
    call this a *pivotal format*, but we will come back to this in more detail at
    the end of this chapter and in the next one) had to be devised to exchange data
    in a free and decoupled manner. But an even better case is where this contract
    already exists in the industry. This is another practical case I had the pleasure
    of dealing with, in particular, because the small company I worked for by then
    forced a much bigger one to comply with our way of working, simply because we
    used a recognized standard. Let me explain the situation better…
  prefs: []
  type: TYPE_NORMAL
- en: Our flagship application, a kind of ERP, generates PDF documents and other binary
    files, and these should be stored. For quite some time, those would be stored
    alongside the database in a network share or, sometimes, in a dedicated server
    accessed through a UNC link. Electronic document management systems started to
    become mainstream after a few years and we needed to adapt our application so
    that it could use these systems to store documents. The natural choice for this
    was the Content Management Interoperability Services norm, as OASIS published
    a fully-featured 1.1 version supporting multiple metadata schemas, classification,
    versioning, and many more functions that we did not even need. It also happened
    that this was the only standard in use in this functional area, which makes for
    a very easy architectural decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'So we ended up using a few operations from the standard (in the first step,
    we only needed to create documents, add metadata and binary content to them, and
    then retrieve documents through a query on their metadata content), which took
    us a few weeks to add to our application. Customers were quite satisfied because
    a simple customization of the software would make documents appear in their Alfresco
    or Nuxeo EDM systems, since these applications are natively CMIS 1.1 compatible.
    But what really demonstrated the importance of such a normative approach was the
    first time we had to deal with a customer equipped with a proprietary EDM: the
    editor, a quite large company, with an important footprint in the information
    system of our common customer, wanted us to make changes to our application in
    order to support their proprietary web services in order to send documents and
    metadata. After an initial refusal from us, the situation got a bit tense but
    we were lucky that the information system owner was a clever person who understood
    perfectly the value of low coupling. She intelligently asked what the effort would
    be for one partner if she had to select another supplier for the services this
    one talked to. The EDM provider stated that they would not have to do anything
    if our company was replaced by another one. As far as our company was concerned,
    I explained that—in the reverse hypothesis—we would have to rewrite some parts
    of the code to adapt to another proprietary protocol. This was enough for the
    customer, even if she was not a technical expert, to realize that something was
    wrong with this way of operating and to demand that a standard-based, contractual
    communication channel was used. Disapproved by the customer, the EDM provider
    had no choice but to implement, at its own cost, support for the CMIS standard
    in its product.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This proved a very satisfying experience for many reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: First, I have to admit that replaying David against Goliath was one of the best
    ego boosts I had in my career.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, we went out of the meeting without having anything to add to our software,
    since it was already CMIS-ready.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third, the customer appreciated our expertise in helping them reach a better,
    more evolutive, system and not trying to push them into a vendor lock-in situation
    as the other *partner* did.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fourth, the interop project was technically very easy to lead because we would
    simply provide the partner with a Postman collection of the API calls we needed
    to work and they were able to validate them from the CMIS norm point of view.
    There were no “hidden parameters” in the interop calls, everything was explicit
    and strictly regulated through the OASIS standard. We only had one tweak to add
    in the case of authentication.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, even the initially reluctant partner admitted at the end of the project
    that this approach helped to avoid the ping-pong effect in the project, where
    both partners reject responsibility for a non-working call to the other, ending
    up in a global loss of time and the customer not being satisfied. And I am truly
    convinced that the CMIS support would open new opportunities for their product
    further down the line.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping complete compatibility
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All this sounds like a beautiful dream, with pink unicorns and rainbows everywhere,
    but having great APIs using international standards and norms does not prevent
    one last danger in interop. Actually, it is quite the reverse, and the cleaner
    and more usable an API is, the bigger this danger is. Sounds weird, doesn’t it?
    Welcome to Hyrum’s Law ([https://www.hyrumslaw.com/](https://www.hyrumslaw.com/)),
    which states the following:'
  prefs: []
  type: TYPE_NORMAL
- en: With a sufficient number of users of an API,
  prefs: []
  type: TYPE_NORMAL
- en: 'it does not matter what you promise in the contract:'
  prefs: []
  type: TYPE_NORMAL
- en: all observable behaviors of your system
  prefs: []
  type: TYPE_NORMAL
- en: will be depended on by somebody.
  prefs: []
  type: TYPE_NORMAL
- en: The more successful your API gets, the more important forward compatibility
    becomes as it is impossible to break the uses of many clients. But after all,
    this is just the flip side of success and not a bad price to pay if your API is
    the most used in your context, which ensures a large market share and notable
    income. Hyrum’s Law is harsher because even some parts of the API that you have
    no formal engagement with will become things that get you into trouble. A sudden
    change in performance, for example, might make it impossible for one of your biggest
    customers to continue working with your API. Even a smaller, non-contractual,
    modification may get you into this kind of trouble. You know what? Even removing
    a bug might make some of your API users unhappy because—in some twisted way—their
    system depended on this particular behavior to operate. That may sound silly but
    it occurs more widely than you may imagine. After all, it is very common that
    some API users consume response attributes by their order instead of their identifier.
  prefs: []
  type: TYPE_NORMAL
- en: 'To a certain extent, Hyrum’s Law can be considered as the API equivalent to
    the Liskhov substitution principle in object-oriented programming: even if a class
    can replace another one by implementing the same interface, if its behavior is
    not the same when the function calls have the same parameter values, then actual
    compatibility (and thus substitutability) is not achieved.'
  prefs: []
  type: TYPE_NORMAL
- en: Managing APIs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even if this is more of an operational concern, managing a number of APIs, with
    all the authorization access issues, logging, and possibly invoicing for API consumption,
    follow-up of versions, and so on can make for a tough challenge. Some dedicated
    software products exist for this under the common name of *API gateways*. They
    generally are implemented in the form of reverse proxies that act as a frontal
    server, hiding the actual API expositions.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on whether you need a very low-coupled system or a very integrated
    one, you could respectively use systems such as WSO² or Ocelot (in the case of
    an ASP.NET implementation of your API system).
  prefs: []
  type: TYPE_NORMAL
- en: Inversion of dependency for services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you remember the following schema from the previous chapter, you will recall
    that a port and adapter pattern is used in order for the satellite modules to
    depend on the main one that implements the business domain model, even if the
    calls come from the latter and go to the former:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Hexagonal architecture](img/B21293_08_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Hexagonal architecture
  prefs: []
  type: TYPE_NORMAL
- en: This is simply the principle of dependency inversion applied to architecture,
    with the description of a conventional interface being called by one module, without
    knowing what implementation is used behind this interface. In **Object-Oriented
    Programming (OOP)** code, this is generally done by object injection.
  prefs: []
  type: TYPE_NORMAL
- en: In service-oriented systems, and in particular, when using web APIs, the indirection
    level is done by the URL that the caller uses without knowing what is behind it.
    If having a dependency on this module is not a problem, then the call can be direct.
    But if the business domain module calls an API, a direct dependency is not a good
    idea for evolution and a way has got to be found in order to reverse the dependency.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is generally done by using some kind of callback mechanism, where the
    domain model module is instructed from the outside (the dependency, in our case)
    with the URL it should call, possibly in its customization but also in the runtime
    initialization steps. In the first explanation of the preceding webhooks, this
    is what happened when the town needed a change of filter on the events the regional
    council should take into account for informing the town: it would not be normal
    for the regional council to depend on the town, since the town is the functional
    requester of the information. This is why the best way for the town to provide
    the callback URL to the regional council is by registering for the events, possibly
    through a `/``subscribe` API.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This way, we reach a nice separation of responsibilities, as the regional council
    is responsible for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Exposing an API that allows clients to create, modify, and remove organizations
    from the data referential service’s persistence mechanism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exposing an API that allows clients (possibly other ones, possible the same
    ones) to register for events on organizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calling the URL provided by these clients upon registration whenever the event
    appears in the code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying the filter provided upon registration to only emit requested events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the other end, the town is responsible for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Registering on the organization referential for the events it needs to observe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing a URL for callbacks that is reachable, and points to the necessary
    implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When this kind of event-based mechanism is used for every interaction to provide
    a very low degree of coupling, the jargon term is **Event-Driven Architecture**
    (**EDA**). In its most advanced form, EDA adds lots of very precisely defined
    responsibilities to allow for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Different authentication and authorization methods for the registration and
    emission mechanisms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Management of robustness of delivery by reapplying the calls if necessary and,
    if needed, warning an administrator that, after a certain amount of tries, the
    event has been stored for later emission to certain registered clients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling high volumes of events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling large numbers of registered clients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service-level agreement management, among many other features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In its correct implementation, an EDA-based system is the most accomplished
    outcome of decoupling in software systems, allowing for a completely transparent
    evolution of the different modules and linear performance. But despite its long
    theoretical existence, there are very few actual implementations of this.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the notion of *service* has been presented and studied from various
    points of view, we are going to return to our sample information system and apply
    this new knowledge to it.
  prefs: []
  type: TYPE_NORMAL
- en: Application to our demonstration system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that the notion of *service* should hold any secrets for you, it is time
    to see some practical applications of what we have covered on our demonstration
    system to reinforce the takeaways from this chapter. Since we aim at something
    modern, the choice is quite obvious that the different modules of the example
    system will interact with each other through REST APIs. As much as possible, we
    will try to keep the middleware as transparent as we can. We may need some connectors
    for mediation in some cases, but other than that, applications will talk to centralized
    APIs that will then be implemented separately (this will be done using the concept
    of service in the container orchestrator that will be put in place).
  prefs: []
  type: TYPE_NORMAL
- en: Interfaces needing analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we will start with a hexagonal architecture diagram to list all the business
    domain models and their dependencies. The C4 approach used in the previous chapter
    showed that we will need at least three business domains, namely books, authors,
    and sales.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we concentrate on books, for example, the dependencies are the persistence
    mechanism, the authors cache module, the books’ GUI system, the books’ API controller,
    and some technical satellites such as logging, and identity and authorization
    management. This can be schematized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – An example of hexagonal architecture](img/B21293_08_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – An example of hexagonal architecture
  prefs: []
  type: TYPE_NORMAL
- en: In terms of the Agile approach, I am not saying that this contains all the interfaces
    that will be present at the end of our journey together. But in order to keep
    this exercise as realistic as possible, I am creating the sample information system
    at the same time as I write the book, in order not to leave anything hidden and
    so that you can follow the precise method of design that I recommend, and that
    I of course try to follow myself.
  prefs: []
  type: TYPE_NORMAL
- en: So, now that the first interfaces have been listed, we need to be a bit more
    precise than just a name. What are they going to do? How will they be designed
    to provide for clean, future-proof usage? Most importantly, how are these choices
    going to reflect the business/IT alignment principles that I have pushed forward
    since the first chapters?
  prefs: []
  type: TYPE_NORMAL
- en: Using norms and standards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since I have spoken so much about the crucial importance of norms and standards,
    it would have been a terrible signal not to start with them for the precise definition
    of the interfaces. And describing more precisely the interfaces we talked about
    in the previous section is as easy as can be when we use a standard because we
    simply need to name it (and possibly cite the version of it that will be used)
    and all the operations, formats, semantics, and other functions of the standard
    are immediately clearly defined through the documentation of the standard.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s start with the authentication and identification service.
    For this particular interface, we will use the OpenID Connect protocol, based
    on OAuth 2.0 (RFC 6749) and using JSON Web Tokens (RFC 7519), the JWT profile
    for OAuth 2.0 itself being standardized (RFC 7523). Again, the great thing about
    norms and standards is that they greatly simplify our work. If I had to describe
    with the same degree of precision the use of an interface without a standard,
    this chapter would be extra long. For this service, citing a few RFCs (and of
    course, in the next chapters, using good implementations of these norms) is enough
    to make everything explicit.
  prefs: []
  type: TYPE_NORMAL
- en: How about the database interface or, to be more precise, the persistence interface?
    The decision is to use a NoSQL document-based approach since it sounds the most
    adapted to the business entities we talked about and the volumetry we want to
    address. It may not be a very well-known fact about MongoDB, but most protocols
    used are open standards, and are, in fact, used by many other NoSQL database implementations.
    If you want to improve on your local MongoDB database, all you need to do to switch
    to an Atlas service or an Azure CosmosDB instance is to change the connection
    string, as everything works the same. The MongoDB Wire Protocol Specification
    is licensed under a Creative Commons *Attribution-NonCommercial-ShareAlike 3.0*
    license. The BSON format ([https://bsonspec.org/#/specification](https://bsonspec.org/#/specification))
    used is documented openly and can be implemented by any software. And the list
    goes on. In addition to the appropriate adaptation of the software to our needs
    and the fact it is easy to create a free database, the standardized aspect is
    the cherry on top that makes MongoDB a sound choice for our sample application.
  prefs: []
  type: TYPE_NORMAL
- en: OK, now on to authorizations! There happens to exist two main norms around software
    authorization management, namely `admin` role has all rights, the `operator` can
    read and write entities based on a portfolio, and the `reader` role can only read
    data, for example), then using OPA would not be the right choice, as it would
    add lots of overhead. Of course, the real question, again, is to take time into
    account. Of course, by the end of the book, our sample application will be so
    simple that using OPA would be over-dimensioning. However the goal of this exercise
    is to show how to work if we aim at a real, industrial, freely evolving information
    system. And since we operate under the hypothesis that rights management is going
    to be more complicated, then we will start right away with the adapted interface,
    which means OPA 1.0 in our case.
  prefs: []
  type: TYPE_NORMAL
- en: The logging feature is a bit of a different situation because this is not something
    directly functional, but rather a technical feature. However this does not mean
    that the same approach of standardization should not be used. The only difference
    is that this level of indirection will not be standardized at the international
    level as with other norms, but rather locally to the platform. Our sample application
    being implemented mostly uses .NET Core, so we will use whatever is standard for
    this technology, and there happens to be a standard global interface in `Microsoft.Extensions.Logging`
    called `ILogger`, which exists also as a generic class `ILogger<T>`. We will return
    in the technical chapters to see how to use it and maybe we will even spice it
    up by using a semantic logging system such as Serilog. But for now, suffice it
    to say that the logging mechanism will be standardized as well.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that some players in the field currently work towards a first
    level of standardization, such as Elastic with the ECS specification (see [https://www.elastic.co/guide/en/ecs/current/ecs-reference.html](https://www.elastic.co/guide/en/ecs/current/ecs-reference.html)
    for details). As Elastic is one of the major publishers of observation platforms
    and the specification is open source, we can place some hope in the spreading
    of this as a standard, although only time will tell.
  prefs: []
  type: TYPE_NORMAL
- en: Where do I find norms and standards?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When I teach or consult about business/IT alignment and in particular about
    this need to refer to norms and standards, the same question always comes up at
    some point: *How do we search for norms?* I should say that I am really astonished
    by this question, and for several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Finding them is as easy as any internet search and virtually all of them are
    public, with the need to be as visible as possible in order to achieve their goals,
    so there is absolutely no technical difficulty in finding them. It shows that
    most people working in the IT industry (and with the number of people I have trained
    or taught, I do have significant statistics) are ignorant of the standards of
    their industry, which is quite annoying. I can understand that not a lot of people
    know BPMN 2.0, for example, as processes are a specific use case, and not all
    applications need a workflow engine. But how can some architects not know about
    OAuth 2.0, since this is used almost everywhere on the internet and almost all
    software applications need some kind of authentication at some point?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even some people outside of the profession know some of the most identified
    providers of norms and standards, such as ISO or IETF. Even just the term **Request
    For Comments (RFC)** is understood by many people. Granted, some IT-specific organizations
    producing norms, such as OASIS, are lesser known. But then again, the **World
    Wide Web Consortium** (**W3C**) is a very active and recognized institution. So
    how come people asking this question do not have the reflex to start with these
    organizations and search them for what they need?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For some customers, I even created a whitepaper at some point with almost a
    hundred norms and standards used in the business context I was working in at the
    time (public and government organizations) because this question came back all
    the time and I wanted to have a quick answer, not only telling them where to find
    what they needed, but providing them with the answers already found for them.
    This is for a simple reason: because I found out that the real issue was not that
    these people did not know “where to find the norm,” but because it indicated doubts
    in their ability to use them. Norms and standards can be a bit intimidating with
    their hundreds of pages explaining all the possible cases. Even simple RFCs are
    indeed not easy to read.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But there are other answers to this as well:'
  prefs: []
  type: TYPE_NORMAL
- en: First, finding the right norm and starting to use it does not require you to
    read the norm specification. In fact, only if you need to implement large parts
    of it will you gain a benefit from reading it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In most cases, you will use components that implement the norm and all you have
    to do is check that they are recognized, well-established modules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, in order to use OpenID Connect in our sample information system,
    we will basically need to know nothing about the protocol itself since we will
    rely on Apache Keycloak, which implements it in a transparent way for us. All
    we have to deal with is the choice of identity provider and some customizations
    made easy by the Keycloak GUI.
  prefs: []
  type: TYPE_NORMAL
- en: Even if you have to dive into the details of the norms, most of the time, you
    will only need to understand a very small portion of them. For example, in our
    sample application, we will certainly need at some point to implement some kind
    of support for binary documents for authors’ contracts; which means we will of
    course use CMIS 1.1 since this is the recognized standard for this use case. But
    as we will only send documents, add binaries and metadata, and query documents
    in return, we may only use 10% of the whole norm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, a good norm is normally quite spread out and used internationally
    already. So, reading the full-blown specification is always an interesting read
    but let’s be honest: the way you will be exposed to the standards in the first
    steps is simply by mimicking some sample calls that you will find on reference
    websites and adapt to your needs. Only if you reach a certain level of complexity
    will it be easier at some point to find the exact nitty-gritty detail of implementation
    in the full text of the RFC.'
  prefs: []
  type: TYPE_NORMAL
- en: Pivotal format for the other interfaces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'And for the last part of this subject, the next question that arises is, logically:
    *What do we do when there is no norm or standard for* *our context?*'
  prefs: []
  type: TYPE_NORMAL
- en: My first reflexive reply to this question is always, “*Are you willing to bet
    that there is indeed no norm I can show you on this?”* Most of the time, this
    question goes back to the previous one and just shows that the person asking it
    is simply not comfortable with norms, or is afraid as they think it is going to
    be difficult (where in reality, on the contrary, norms free you from all the difficult
    design aspects). Because, let’s face it, we have norms for virtually everything
    today. All right, there may be fewer norms in IT than in the mechanical domain.
    But there are standards for every common feature. You have norms for all generic
    techniques, norms for every entity used in international data transfers, and for
    every common human activity including banking, insurance, travel, and so on. You
    even have an ISO-Gender norm (ISO/CEI 5218) for representing human genders in
    numeric format.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second part of the answer concerns what we should do when there is indeed
    no applicable norm for your context. And the answer to this has already been given
    a bit earlier in this chapter: you then create what is called a **pivotal format**,
    which has the same goal of standardization as a real norm, but limited to your
    own context. Of course, it is always better to aim at something universal. Not
    only because, you never know, but your format may become a norm if you put enough
    effort into it and other people have an interest in it (this is the way norms
    appear: it always starts with the effort of an individual who knows the business
    domain extremely well and makes the effort to transcribe their knowledge into
    something technical, which is then agreed upon by other participants as a sound
    basis for exchanges). But also because aiming at something universal will make
    your pivotal format as close to a norm as possible, with as many resulting advantages
    as possible.'
  prefs: []
  type: TYPE_NORMAL
- en: 'And the rule for this is to fall back on existing norms as quickly as possible.
    Sure, there does not seem to exist an international norm for the concept of authoring
    (though the Dublin Core `creator` attribute allows us to draw a link between a
    resource and the person or organization that authored this resource), but since
    it points to individual persons, lots of other related norms will quickly apply,
    such as Social Security Numbers for unique identification, ISO 8601 for the date
    of authoring, and so on. The same applies to books: of course, we may not find
    the perfect standard to precisely address what we need for our sample application,
    and in particular its persistence system, but there are nonetheless norms for
    languages (ISO 639), internationally-recognized standard codes for registered
    book identification such as **International Standard Book Numbers (ISBNs)**, and
    standards for virtually everything we will set out to record in the descriptions
    of the books in our system.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, the real question is what to put in the book and author’s pivotal format?
    And this is such a huge question that it will necessitate a chapter on its own.
    The good news is that the following chapter will explain how to answer this.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, I have used a short historical approach (a detailed one would
    be a book in itself) to explain what the stakes at play are in service orientation
    and how this seemingly simple yet hard-to-define word of *service* has been implemented
    in the past decades. We are definitely not at the end of the story yet, but nowadays,
    it seems the best approach is to use REST APIs with a middleware, reduced as much
    as possible through the use of norms and standards. This not only avoids the costly
    mediation connectors that translate one format to another, since everybody in
    the interaction talks the same language but also helps us know whether our design
    is the right one since consortiums and experts have thought a lot about this business
    domain.
  prefs: []
  type: TYPE_NORMAL
- en: Standardized APIs are what make it easy today to change some parts of important
    information systems without breaking them. They allow for international banking,
    much more efficient insurance systems, simplified travel abroad, and many other
    feats of the industrialized IT world.
  prefs: []
  type: TYPE_NORMAL
- en: 'We talked about norms, but also compatibility, the evolution of services, how
    services will be integrated through interfaces, and much more. By the end of this
    chapter, we came back to our sample application and showed which norms would be
    used to implement a few of the services it will expose. Now a difficult question
    remains: when there is no standard format for a business need and we need to create
    a pivotal format (of course, using norms as much as possible for its inner attributes),
    how do we determine the content of this format? The best answer I have is to use
    **Domain-Driven Design** (**DDD**). And this is the subject of the next chapter.'
  prefs: []
  type: TYPE_NORMAL
