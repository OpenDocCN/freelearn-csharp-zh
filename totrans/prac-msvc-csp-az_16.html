<html><head></head><body>
		<div id="_idContainer214">
			<h1 id="_idParaDest-374" class="chapter-number"><a id="_idTextAnchor373"/>16</h1>
			<h1 id="_idParaDest-375"><a id="_idTextAnchor374"/>Running Applications On-Premises and in the Cloud</h1>
			<p>Up to the last chapter, we added additional functionality to the Codebreaker application; in <a href="B21217_15.xhtml#_idTextAnchor349"><span class="No-Break"><em class="italic">Chapter 15</em></span></a>, we added services communicating with asynchronous communication. We used Azure Storage queues and Azure Event Hubs with the Azure Codebreaker variant; with the on-premises version, we added a <span class="No-Break">Kafka container.</span></p>
			<p>In this chapter, we look at what needs to be known when deploying the solution to Microsoft Azure and to on-premises environments. Using Azure, we deployed the solution to an Azure Container Apps environment from <a href="B21217_05.xhtml#_idTextAnchor110"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> onward. The Azure Container Apps environment uses Kubernetes behind the scenes. In this chapter, we directly deploy to a Kubernetes cluster, which can easily be used in on-premises environments and in <span class="No-Break">any cloud.</span></p>
			<p>In this chapter, you will learn about <span class="No-Break">the following:</span></p>
			<ul>
				<li>Customizing deployment with C# <span class="No-Break">and Aspire</span></li>
				<li>Creating a Kubernetes cluster <span class="No-Break">with Azure</span></li>
				<li>Deploying the application to Kubernetes <span class="No-Break">with Aspir8</span></li>
			</ul>
			<h1 id="_idParaDest-376"><a id="_idTextAnchor375"/>Technical requirements</h1>
			<p>With this chapter, like the previous chapters, you need an Azure subscription, .NET 8 with .NET Aspire, and Docker Desktop. In this chapter, we’ll use a new tool, Aspir8, to deploy the application to a <span class="No-Break">Kubernetes cluster.</span></p>
			<p>The code for this chapter can be found in this GitHub <span class="No-Break">repository: </span><a href="https://github.com/PacktPublishing/Pragmatic-Microservices-with-CSharp-and-Azure/"><span class="No-Break">https://github.com/PacktPublishing/Pragmatic-Microservices-with-CSharp-and-Azure/</span></a><span class="No-Break">.</span></p>
			<p>In the <strong class="source-inline">ch16</strong> folder, you’ll see the projects that can be deployed. The most important project for this chapter is <strong class="source-inline">Codebreaker.AppHost</strong>, which defines the app model using Azure native cloud services, as well as a configuration that can be used with an on-premises environment. This configuration is also used to deploy the solution to a <span class="No-Break">Kubernetes cluster.</span></p>
			<h1 id="_idParaDest-377"><a id="_idTextAnchor376"/>Thinking about deployment in production</h1>
			<p>The Codebreaker solution uses several different native Azure cloud services. In <a href="B21217_08.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, you saw how we can use <strong class="bold">GitHub Actions</strong> to<a id="_idIndexMarker1221"/> deploy to different environments, such as development, testing, staging, and production environments using approvals. As more and more services have been added in the last chapters, the deployments need to be updated <span class="No-Break">as well.</span></p>
			<p>With many organizations, deployments<a id="_idIndexMarker1222"/> to production environments are somewhat disconnected from the development environment. Often, a different team from the development organization manages these deployments using <span class="No-Break">different tools.</span></p>
			<p><strong class="bold">Continuous Integration</strong> (<strong class="bold">CI</strong>) and <strong class="bold">Continuous Development</strong> (<strong class="bold">CD</strong>) are often used in repositories<a id="_idIndexMarker1223"/> separated<a id="_idIndexMarker1224"/> from the source code. Different products such as GitHub Actions, Azure DevOps pipelines, and many third-party offerings <span class="No-Break">are used.</span></p>
			<p>From the pipelines, it’s possible to trigger the Azure Developer CLI (azd), use Bicep scripts, directly use the Azure CLI or PowerShell scripts, or use third-party offerings such as Terraform, Ansible, Chef, <span class="No-Break">and Puppet.</span></p>
			<p>When deciding between the different products, it’s also necessary to think about the requirements for the production environment, and what’s different from the development environment. With the production environment, different loads are expected. For a load test, it’s useful to run the same infrastructure as used with the production environment. With this, it’s important that the complete infrastructure for an environment needs to be <span class="No-Break">easily creatable.</span></p>
			<p>The infrastructure needs to map the needs of the business – what income is lost if things are not working as expected? We need to think about <span class="No-Break">these topics:</span></p>
			<ul>
				<li><strong class="bold">Scalability</strong>: Adapting to changing demands. Demand might increase slightly over time, or there might also be spikes <span class="No-Break">in demand.</span></li>
				<li><strong class="bold">Reliability</strong>: Making sure that the services work <span class="No-Break">as expected.</span></li>
				<li><strong class="bold">Availability</strong>: Making sure that the services are available from where the customers are. Availability metrics are <strong class="bold">Mean Time Between Failures</strong> (<strong class="bold">MTBF</strong>) – how<a id="_idIndexMarker1225"/> long until a failure happens – and <strong class="bold">Mean Time To Repair </strong>(<strong class="bold">MTTR</strong>) – how <a id="_idIndexMarker1226"/>long it takes until it’s <span class="No-Break">running again.</span></li>
				<li><strong class="bold">Recovery</strong>: If there’s an <a id="_idIndexMarker1227"/>outage, recovery metrics that can be used are <strong class="bold">Recovery Point Time</strong> (<strong class="bold">RTO</strong>) – the acceptable time for apps to <a id="_idIndexMarker1228"/>be unavailable – and <strong class="bold">Recovery Point Objective</strong> (<strong class="bold">RPO</strong>) – the maximum allowed time for a <span class="No-Break">data loss.</span></li>
			</ul>
			<p>These requirements need to be compared to the business needs. With <strong class="bold">redundancy</strong>, resources <a id="_idIndexMarker1229"/>are replicated, and multiple services are running. There’s not a single point of failure. Data can be replicated within one data center in an Azure region, between different data centers in an Azure region (Azure <strong class="bold">availability zones</strong>), and across different Azure regions (using a <span class="No-Break"><strong class="bold">multi-region</strong></span><span class="No-Break"> architecture).</span></p>
			<p>Another <a id="_idIndexMarker1230"/>requirement for the production environment is to enhance security. Data protection needs to make sure personal user data is safe. With <strong class="bold">encryption at rest</strong>, data is stored encrypted in the database. Instead of a service-managed key, customer-managed keys can be used. Using customer-managed keys is possible with many Azure services, but usually, different (more expensive) SKUs are required to enable customer-managed keys. Virtual networks are another option to enhance security. With subnets, it’s possible to restrict access to the database server. <strong class="bold">Private endpoints</strong> can be used to restrict<a id="_idIndexMarker1231"/> access only to a specific service and prevent data exfiltration. IP firewall rules can <span class="No-Break">be configured.</span></p>
			<p>We can’t discuss all the different requirements here, but an important takeaway is that with production environments, we might need some additional Azure resources (such as virtual networks), different configurations, and other SKUs. See <span class="No-Break"><em class="italic">Figure 16</em></span><em class="italic">.1</em> for the Codebreaker application making use of multiple <span class="No-Break">Azure regions.</span></p>
			<div>
				<div id="_idContainer209" class="IMG---Figure">
					<img src="image/B21217_16_01.jpg" alt="Figure 16.1 – Codebreaker with virtual networks"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.1 – Codebreaker with virtual networks</p>
			<p>This<a id="_idIndexMarker1232"/> figure shows Azure regions in the US, Europe, and Asia, and Azure Cosmos DB replicated across the regions. The database is accessed from Container Apps running in the same region of the database. The frontends (Blazor) and backends (Game APIs) in one region can run in one Azure Container Apps environment, with the Game APIs service only accessible internally. Azure Application Gateway with a firewall configured is used to access the Blazor web application. Azure Traffic Manager can route across <span class="No-Break">different regions.</span></p>
			<p>How does <a id="_idIndexMarker1233"/>the Codebreaker solution fulfill all the requirements? With scalability, reliability, and security, all the resources used by the application need to be verified. In <a href="B21217_12.xhtml#_idTextAnchor294"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>, we added a huge load on the Codebreaker services to test scaling up and scaling out. Due to the stateless nature of the developed services, the resources used also scale accordingly, and we anticipate no issues in meeting all the requirements. The Azure Cosmos DB database can replicate worldwide, even with multi-region writes to store games near the user for the best performance. We paid attention to the partition key, which doesn’t block other gamers’ writes to the database. Azure Event Hubs (added in <a href="B21217_15.xhtml#_idTextAnchor349"><span class="No-Break"><em class="italic">Chapter 15</em></span></a>) offers a lot more performance than needed. The Standard SKU supports 1,000 events per second with one throughput unit. Additional throughput units can be added, and a switch to the Premium tier, which offers even more, could be done. An important aspect is to see what’s going on to react early, which was covered in <a href="B21217_11.xhtml#_idTextAnchor263"><span class="No-Break"><em class="italic">Chapter 11</em></span></a><span class="No-Break">.</span></p>
			<p>While many organizations have separate teams for development and infrastructure, this has <span class="No-Break">some disadvantages.</span></p>
			<p>Using the .NET Aspire <a id="_idIndexMarker1234"/>manifest created from the app model, we covered creating Bicep scripts in <a href="B21217_06.xhtml#_idTextAnchor137"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>. These Bicep scripts can be customized to fulfill the requirements of the production environment. Using customized Bicep scripts has the disadvantage that changes on the app model don’t automatically reflect with the Bicep script. The Bicep script needs to be manually <span class="No-Break">updated again.</span></p>
			<p>It would be great to use C# code to completely define the Azure infrastructure configuration with all the different aspects needed. When the app model is updated with this, the infrastructure configuration is changed at the <span class="No-Break">same time.</span></p>
			<h2 id="_idParaDest-378"><a id="_idTextAnchor377"/>Customizing deployments with C# and .NET Aspire</h2>
			<p>At the time of <a id="_idIndexMarker1235"/>this writing, enhancements are in progress to make this happen. Currently, it’s just in experimental mode, and the APIs available are likely to change, thus we will only look briefly <span class="No-Break">into this.</span></p>
			<p>To define the .NET Aspire app model, APIs have an overload with a delegate parameter. For example, the <strong class="source-inline">AddAzureKeyVault</strong> method we used so far is an extension method for the <strong class="source-inline">IDistributedApplicationBuilder</strong> interface and uses a <strong class="source-inline">name</strong> parameter. A second overload specifies an additional <strong class="source-inline">Action</strong> delegate parameter. This overload has the <strong class="source-inline">Experimental</strong> attribute applied to mark that the API may change. The parameters used with this delegate are <strong class="source-inline">IResourceBuilder&lt;AzureKeyVaultResource&gt;</strong>, <strong class="source-inline">ResourceModuleConstruct</strong>, and <strong class="source-inline">KeyVault</strong>. This allows us to configure a secret retrieved from a parameter when creating Azure <span class="No-Break">Key Vault:</span></p>
			<pre class="source-code">
#pragma warning disable AZPROVISION001
var aSecret = builder.AddParameter("aSecret", secret: true);
var keyVault = <strong class="bold">builder.AddAzureKeyVault("keyvault",</strong>
<strong class="bold">  (_, construct, _)</strong> =&gt;
  {
    var secret = new KeyVaultSecret(construct,
      name: "secret1");
    secret.AssignProperty(p =&gt; p.Properties.Value,
      aSecret);
  });
#pragma warning restore AZPROVISION001</pre>
			<p>With<a id="_idIndexMarker1236"/> the method used here, the first and third parameters of the delegate are ignored. The second parameter of the <strong class="source-inline">ResourceModuleConstruct</strong> type specifies the scope of creating <strong class="source-inline">KeyVaultSecret</strong> – it’s created for this Azure <span class="No-Break">Key Vault.</span></p>
			<p>Another sample shows configuring properties and invoking method of a builder with an Azure <span class="No-Break">Storage Account:</span></p>
			<pre class="source-code">
var storage = <strong class="bold">builder.AddAzureStorage</strong>("storage",
<strong class="bold">  (builder, _, account) =&gt;</strong>
  {
<strong class="bold">    builder.AddQueues("botqueue");</strong>
<strong class="bold">    builder.AddBlobs("checkpoints");</strong>
<strong class="bold">    account.AssignProperty(p =&gt; p.AccessTier, "Hot");</strong>
<strong class="bold">    account.AssignProperty(p =&gt; p.Sku.Name,</strong>
<strong class="bold">      "Standard_LRS");</strong>
  });</pre>
			<p>When creating the Azure Storage account, the <strong class="source-inline">IResourceBuilder&lt;AzureStorageAccount&gt;</strong> and <strong class="source-inline">StorageAccount</strong> parameters are used with the <strong class="source-inline">Action</strong> delegate, and the second parameter is ignored. <strong class="source-inline">IResourceBuilder</strong> is used to create a queue and a blob container with the storage account. We used these <strong class="source-inline">AddQueues</strong> and <strong class="source-inline">AddBlobs</strong> methods already without the experimental API invoking these methods with the return of <strong class="source-inline">AddStorageAccount</strong>. The <strong class="source-inline">AddAzureStorage</strong> method returns a builder. This is just for convenience defining this within this code block. The <strong class="source-inline">StorageAccount</strong> parameter is used to specify properties, setting the SKU to local redundancy, and the access tier to hot, which is cheaper for operations but more expensive for <span class="No-Break">the storage.</span></p>
			<p>Many <a id="_idIndexMarker1237"/>organizations are in the process of changing the way to deploy and manage their infrastructure. Knowing about these developments can be useful to decide what direction should be taken, and what tools best fit the needs of <span class="No-Break">the organization.</span></p>
			<p>For now, it’s very likely that the API will change – so use it with care. With the fast development pace of .NET Aspire, new features can improve fast, and this feature might be released not too far away (at the time of this writing). Check the README file of this chapter <span class="No-Break">for updates.</span></p>
			<p>Next, we’ll look into easy deployment <span class="No-Break">to Kubernetes.</span></p>
			<h1 id="_idParaDest-379"><a id="_idTextAnchor378"/>Creating a Kubernetes cluster with Microsoft Azure</h1>
			<p>While the Azure Container<a id="_idIndexMarker1238"/> Apps environment is based on Kubernetes, the Kubernetes tool (<strong class="bold">kubectl</strong>) cannot be used; the Kubernetes functionality is abstracted for simplification. Kubernetes is an open source system to scale and manage containerized applications and is used by many companies in their on-premises environment. With this, for many companies, it’s important to have the possibility to run services on-premises and in any cloud environment. See the <em class="italic">Further reading</em> section for links to learn more <span class="No-Break">about Kubernetes.</span></p>
			<p>The Codebreaker application has been built with two launch profiles. We’ll publish the <strong class="source-inline">OnPremises</strong> launch profile to a Kubernetes cluster. With this launch profile, for example, Kafka is used instead of Azure <span class="No-Break">Event Hubs.</span></p>
			<p>By having Docker Desktop installed, you can enable Kubernetes. This single-node cluster is just for a small test scenario. Instead, we’ll use a managed version of Kubernetes: The <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>). Compared to a self-installed cluster, installation and management <a id="_idIndexMarker1239"/>are a <span class="No-Break">lot easier.</span></p>
			<p>Before creating the cluster, we need a new resource <a id="_idIndexMarker1240"/>group, and an <strong class="bold">Azure Container </strong><span class="No-Break"><strong class="bold">Registry</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ACR</strong></span><span class="No-Break">).</span></p>
			<p>Using the Azure CLI, create a new <span class="No-Break">resource group:</span></p>
			<pre class="console">
az group create -l westeurope -n rg-codebreaker-kubernetes</pre>
			<p>Specify<a id="_idIndexMarker1241"/> an Azure region of your choice and specify a resource group name. Then, create a new ACR using <strong class="source-inline">az </strong><span class="No-Break"><strong class="source-inline">acr create</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
az acr create -g rg-codebreaker-kubernetes --sku Basic -l &lt;yourregion&gt; -n &lt;youracr&gt;</pre>
			<p>Use the previously created resource group, specify an SKU (the cheapest version, <strong class="source-inline">Basic</strong>, fits the purpose), and use a unique name for <span class="No-Break">the registry.</span></p>
			<p> With this, create a new AKS in the <a id="_idIndexMarker1242"/>Azure portal (<a href="https://portal.azure.com">https://portal.azure.com</a>) – see <span class="No-Break"><em class="italic">Figure 16</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer210" class="IMG---Figure">
					<img src="image/B21217_16_02.jpg" alt="Figure 16.2 – Basic AKS configuration"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.2 – Basic AKS configuration</p>
			<p>Select the<a id="_idIndexMarker1243"/> resource group just created with the first dialog. With <strong class="bold">Cluster details</strong>, you can choose a preset configuration of either <strong class="bold">Production Standard</strong>, <strong class="bold">Dev/Test</strong>, <strong class="bold">Production Economy</strong>, and <strong class="bold">Production Enterprise</strong>. The virtual machine sizes are different based on the presets, and some features are differently configured. For example, <strong class="bold">Production Enterprise</strong> has a <strong class="bold">private cluster</strong> where <a id="_idIndexMarker1244"/>the API server is only accessible from an internal network. Select the <strong class="bold">Dev/Test</strong> preset for our test environment. Enter a cluster name and select the region of the cluster. All the other <strong class="bold">Basics</strong> settings can stay as their defaults – including the AKS pricing tier, <strong class="bold">Free</strong>. With the <strong class="bold">Free</strong> offering, a cost only applies for the nodes where our built Docker images are running and other services configured, such as managed Prometheus and Grafana. Be aware that every node instance you configure is a virtual machine that needs to be paid for. The <strong class="bold">Dev/Test</strong> preset setting is best for experimenting and testing with fewer than 10 nodes. With the <strong class="bold">Standard</strong> pricing tier, you can run up to 5,000 nodes in <span class="No-Break">a cluster.</span></p>
			<p>After the configuration of the <strong class="bold">Basics</strong> settings, click <strong class="bold">Next</strong> to configure the node pools (<span class="No-Break"><em class="italic">Figure 16</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">).</span></p>
			<div>
				<div id="_idContainer211" class="IMG---Figure">
					<img src="image/B21217_16_03.jpg" alt="Figure 16.3 – AKS node pools"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.3 – AKS node pools</p>
			<p>The <a id="_idIndexMarker1245"/>default configuration for the node pool is <strong class="bold">2 - 5</strong> nodes. In this chapter we don’t create load tests; therefore, to reduce the cost, you can reduce the minimum number of nodes to <strong class="source-inline">1</strong>. System node pools need Linux for the operating system. These node pools run system pods. To run the applications, user node pools are preferred. For a cheaper test, we just use one node pool – a system <span class="No-Break">node pool.</span></p>
			<p>When selecting the configuration of the pool, you can select the OS, the VM size, auto or manual scaling, the minimum and maximum node count, and the maximum pods per node. The allowed range is from 30–250 pods per node. One pod can run one or more containers. In most Kubernetes configurations, a pod runs one container. If the pod or the node where the pod runs fails, Kubernetes creates <span class="No-Break">a replica.</span></p>
			<p>With the <strong class="bold">Node pools</strong> configuration, you can also enable virtual nodes. Virtual nodes make use of Azure Container Instances, which allow the fast startup of containers if more load <span class="No-Break">is needed.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Creating user node pools allows you to select Windows for a node pool. This allows running legacy applications on Kubernetes. This is a difference AKS has to offer that’s not available with Azure <span class="No-Break">Container Apps.</span></p>
			<p>After <a id="_idIndexMarker1246"/>the <strong class="bold">Node pools</strong> configuration, clicking <strong class="bold">Next</strong> leads to the <strong class="bold">Networking</strong> configuration. Leave this with the default settings. Clicking <strong class="bold">Next</strong> again opens the <strong class="bold">Integrations</strong> settings (see <span class="No-Break"><em class="italic">Figure 16</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">).</span></p>
			<div>
				<div id="_idContainer212" class="IMG---Figure">
					<img src="image/B21217_16_04.jpg" alt="Figure 16.4 – AKS Integrations settings"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.4 – AKS Integrations settings</p>
			<p>With the <strong class="bold">Integrations</strong> settings, select the previously created ACR. With AKS, a direct integration with the registry <span class="No-Break">is offered.</span></p>
			<p>Clicking <strong class="bold">Next</strong> opens the <strong class="bold">Monitoring</strong> settings. Enabling Container Insights creates a Log Analytics namespace that you know from <a href="B21217_11.xhtml#_idTextAnchor263"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>. With the <strong class="source-inline">OnPremises</strong> launch profile, Docker containers for Grafana and Prometheus are configured. Alternatively, the Azure services Managed Prometheus and Managed Grafana could <span class="No-Break">be used.</span></p>
			<p>Leave the remaining settings as default. By clicking on <strong class="bold">Review + create</strong>, the final checks are done. If this succeeds, click the <strong class="bold">Create</strong> button. Creating an AKS takes several minutes – but it’s a lot faster than creating a Kubernetes <span class="No-Break">cluster manually.</span></p>
			<p>After deployment to the Kubernetes cluster succeeds, connect the Kubernetes command-line client, <strong class="source-inline">kubectl</strong>, to AKS. With Docker Desktop, this tool is installed with it. To connect <strong class="source-inline">kubectl</strong> to this AKS installation, use <span class="No-Break">the following:</span></p>
			<pre class="console">
az aks get-credentials --resource-group &lt;your resource group&gt; --name &lt;your aks name&gt;</pre>
			<p>This<a id="_idIndexMarker1247"/> adds the connection to AKS to the <strong class="source-inline">%HOMEPATH%/.kube/config</strong> configuration file. Now, you can use the <span class="No-Break"><strong class="source-inline">kubectl</strong></span><span class="No-Break"> tool:</span></p>
			<pre class="console">
kubectl get nodes</pre>
			<p>This returns the running nodes from the <span class="No-Break">AKS service.</span></p>
			<p>Next, let’s publish <span class="No-Break">our application.</span></p>
			<h1 id="_idParaDest-380"><a id="_idTextAnchor379"/>Using Aspir8 to deploy to Kubernetes</h1>
			<p>With .NET Aspire, we <a id="_idIndexMarker1248"/>created the app model to define all the dependencies between the different resources that are used. First, in <a href="B21217_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, you saw the Aspire manifest that’s created from an app model. This manifest file is independent of any technology where to deploy it. The Azure Developer CLI creates Bicep scripts for deploying the solution (see <a href="B21217_06.xhtml#_idTextAnchor137"><span class="No-Break"><em class="italic">Chapter 6</em></span></a> and <a href="B21217_08.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>). The open source tool <strong class="bold">Aspirate</strong> (<strong class="bold">Aspir8</strong>) (see <a href="https://github.com/prom3theu5/aspirational-manifests">https://github.com/prom3theu5/aspirational-manifests</a>) converts the Aspire manifest file to Docker Compose or <a id="_idIndexMarker1249"/>Kubernetes with <strong class="bold">Helm</strong> charts <a id="_idIndexMarker1250"/>or <span class="No-Break"><strong class="bold">kustomize</strong></span><span class="No-Break"> manifests.</span></p>
			<p>You can create an Aspire manifest for every launch profile, <span class="No-Break">like so:</span></p>
			<pre class="console">
cd Codebreaker.AppHost
dotnet run --launch-profile OnPremises -- --publisher manifest --output-path onpremises-manifest.json</pre>
			<p>Our app model is defined with two different versions. One version uses cloud-native Azure services, while the other option is independent of any cloud environment. The second one is configured by starting the application with the <strong class="source-inline">OnPremises</strong> <span class="No-Break">launch profile.</span></p>
			<p>With <strong class="source-inline">dotnet run</strong>, we pass the <strong class="source-inline">--launch-profile OnPremises</strong> option to start the application using the profile as specified with the <strong class="source-inline">launchprofiles.json</strong> file. The <strong class="source-inline">--</strong> option is a separator to specify arguments to the running application. The <strong class="source-inline">--publisher manifest</strong> option creates the Aspire <span class="No-Break">manifest file.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">We have a strict separation with the Codebreaker app model definition. It’s also possible in a somehow mixed mode. For example, you can use a solution running on-premises to use Azure Application Insights running within Azure to get the advantages of this cloud service offering. You can also use Azure Functions to run on an on-premises Kubernetes cluster. Many options are available to choose the service that best fits <span class="No-Break">your needs.</span></p>
			<p>Before using the <strong class="source-inline">aspirate</strong> tool, it needs to <span class="No-Break">be installed:</span></p>
			<pre class="console">
dotnet tool install -g aspirate --prerelease</pre>
			<p>At the<a id="_idIndexMarker1251"/> time of this writing, this tool is not released, thus it’s necessary to set the <strong class="source-inline">--prerelease</strong> option. The <strong class="source-inline">-g</strong> option installs this tool as a <span class="No-Break">global tool.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">At the time of this writing, the <strong class="source-inline">aspirate</strong> tool is in a prerelease state, and changes are expected. Check the README file of <a href="B21217_16.xhtml#_idTextAnchor373"><span class="No-Break"><em class="italic">Chapter 16</em></span></a> from the book’s repository for the latest updates deploying the Codebreaker application <span class="No-Break">to Kubernetes.</span></p>
			<p>Optionally, you can specify an initial configuration <span class="No-Break">with Aspir8:</span></p>
			<pre class="console">
cd Codebreaker.AppHost
aspirate init --launch-profile OnPremises</pre>
			<p>The <strong class="source-inline">aspirate</strong> tool allows specifying a launch profile similar to the .NET CLI to customize the configuration accordingly. By using <strong class="source-inline">aspirate init</strong>, you can specify a container builder and select between Docker Desktop and Podman. The default setting is Docker Desktop. With a fallback value for the container registry, enter the URL of the ACR you created. <strong class="source-inline">aspirate init</strong> creates the <strong class="source-inline">aspirate-state.json</strong> file with the configuration specified. You can rerun <strong class="source-inline">aspirate init</strong>, which overwrites this <span class="No-Break">configuration file.</span></p>
			<h2 id="_idParaDest-381"><a id="_idTextAnchor380"/>Creating Kubernetes manifests</h2>
			<p>Let’s now use<a id="_idIndexMarker1252"/> the app model with the launch profile to generate manifests for publishing <span class="No-Break">to Kubernetes:</span></p>
			<pre class="console">
aspirate generate --launch-profile OnPremises --output-path ./kustomize-output --skip-build --namespace codebreakerns</pre>
			<p><strong class="source-inline">aspirate generate</strong> can create Kubernetes manifests for deployment, as well as build and publish Docker images. Here, we don’t build Docker images by using the <strong class="source-inline">--skip-build</strong> option. With the <strong class="source-inline">--launch-profile</strong> option, the <strong class="source-inline">AppHost</strong> project with the app model is directly used. <strong class="source-inline">aspirate generate</strong> can also reference the previously generated .NET Aspire manifest with the <strong class="source-inline">--aspirate-manifest</strong> option instead. By setting <strong class="source-inline">--output-path</strong>, a different folder is specified to create the output result. The <strong class="source-inline">--namespace</strong> option is Kubernetes-related to define a namespace for the services deployed. This makes it easier to differentiate between the different services running on <span class="No-Break">the cluster.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout"><strong class="source-inline">aspirate</strong> supports generating manifests using Helm and <strong class="source-inline">kustomize</strong>. Helm is a package manager that uses a packaging format named <strong class="bold">charts</strong>. This is a collection of YAML files and templates. With Helm, installation, upgrades, and rollbacks can be done with simple commands. <strong class="source-inline">kustomize</strong> is a configuration manager natively built into <strong class="source-inline">kubectl</strong> with a template-free approach to patch and merge <span class="No-Break">YAML files.</span></p>
			<p>Check the result of the <strong class="source-inline">kustomize-output</strong> folder. For every project specified, a folder is created (e.g., <strong class="source-inline">gameapis</strong>, <strong class="source-inline">bot</strong>, and <strong class="source-inline">redis</strong>) that contains <strong class="source-inline">deployment.yaml</strong>, <strong class="source-inline">service.yaml</strong>, <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">kustomization.yaml</strong></span><span class="No-Break">.</span></p>
			<p>A deployment defines a declarative configuration for a pod and a replica set. The “desired state” of a pod is described by the deployment. In this file, you can read and change the number of replicas used, and the containers running in <span class="No-Break">a pod.</span></p>
			<p>A service defines a network application. This specifies the ports used with the application. A service runs in one or <span class="No-Break">more pods.</span></p>
			<p>The <strong class="source-inline">kustomization.yaml</strong> file references both <strong class="source-inline">deployment.yaml</strong> and <strong class="source-inline">service.yaml</strong>, and specifies configuration values such as the environment variables you’ve seen <a id="_idIndexMarker1253"/>with the .NET <span class="No-Break">Aspire dashboard.</span></p>
			<p>Having the manifest files ready, we can create Docker images and push them to <span class="No-Break">the ACR.</span></p>
			<h2 id="_idParaDest-382"><a id="_idTextAnchor381"/>Creating and pushing Docker images</h2>
			<p>Using <strong class="source-inline">aspirate build</strong>, we can build and publish Docker images to the registry. With<a id="_idIndexMarker1254"/> the <strong class="source-inline">aspirate</strong> tool, it’s possible to specify username and password values to push images to private registries. When using ACR, this is not necessary because Aspir8 makes use of <strong class="source-inline">dotnet publish</strong>. Just make sure to log in to the ACR using <span class="No-Break">the following:</span></p>
			<pre class="console">
az acr login –name &lt;yourregistry&gt;</pre>
			<p>Then, you can use <span class="No-Break"><strong class="source-inline">aspirate build</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
aspirate build --launch-profile OnPremises --container-image-tag 3.8 --container-image-tag latest --container-registry &lt;yourregistry&gt;.azurecr.io</pre>
			<p>Starting this command, specify the name of your registry. Specifying multiple tags will add them to the repository as shown in <span class="No-Break"><em class="italic">Figure 16</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer213" class="IMG---Figure">
					<img src="image/B21217_16_05.jpg" alt="Figure 16.5 – AKS repository"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 16.5 – AKS repository</p>
			<p>The <a id="_idIndexMarker1255"/>images are pushed to the ACR and show the <strong class="source-inline">latest</strong> and <strong class="source-inline">3.8</strong> tags, as specified with <strong class="source-inline">aspirate build</strong>. Next, deploy the images with the Kubernetes manifests to <span class="No-Break">the cluster.</span></p>
			<h2 id="_idParaDest-383"><a id="_idTextAnchor382"/>Deploying to Kubernetes</h2>
			<p>Now, we<a id="_idIndexMarker1256"/> can apply the manifests to the <span class="No-Break">Kubernetes cluster:</span></p>
			<pre class="console">
aspirate apply --input-path kustomize-output</pre>
			<p>The <strong class="source-inline">aspirate apply</strong> command uses the previously created manifest files to apply the services and deployments to the Kubernetes cluster by using the <strong class="source-inline">kubectl apply</strong> command. Just make sure to have AKS configured as the default Kubernetes environment (using the previously used command after creating AKS: <strong class="source-inline">az </strong><span class="No-Break"><strong class="source-inline">aks get-credentials</strong></span><span class="No-Break">).</span></p>
			<p>Now, you can use the <span class="No-Break">following command:</span></p>
			<pre class="console">
kubectl get deployments --namespace codebreakerns</pre>
			<p>This command shows the deployments from the <strong class="source-inline">codebreakerns</strong> namespace. You can see the deployments that are available <span class="No-Break">and ready.</span></p>
			<p>Similarly, use this command to see <span class="No-Break">the services:</span></p>
			<pre class="console">
kubectl get services --namespace codebreakerns</pre>
			<p>Here, you see the services with the IP addresses running, and the <span class="No-Break">ports registered.</span></p>
			<p>Now, you <a id="_idIndexMarker1257"/>can configure an <strong class="bold">ingress</strong> controller to access a service and test it running with Kubernetes. Configuring ingress controllers is planned with <strong class="source-inline">aspirate</strong>. For now, check the <em class="italic">Further reading</em> section to see how this can <span class="No-Break">be done.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Aspir8 also supports Docker Compose besides Kubernetes with <strong class="source-inline">kustomize</strong> and Helm. By using <strong class="source-inline">aspirate generate</strong>, you can supply <strong class="source-inline">compose</strong> with the <strong class="source-inline">--output-format</strong> option. This creates a simple Docker Compose file that you can start with the <span class="No-Break">Docker CLI.</span></p>
			<h1 id="_idParaDest-384"><a id="_idTextAnchor383"/>Summary</h1>
			<p>In this chapter, you learned about some final considerations for deploying applications using a microservices architecture in a production environment. You now have awareness of running the solution in multiple regions and using availability zones and can discuss the impact in <span class="No-Break">your organization.</span></p>
			<p>You learned about AKS as a managed option to host a Kubernetes cluster and deploy the solution by using the .NET Aspire manifest to create deployments <span class="No-Break">with Aspir8.</span></p>
			<p>By reaching <a href="B21217_16.xhtml#_idTextAnchor373"><span class="No-Break"><em class="italic">Chapter 16</em></span></a> of this book, you’ve done an impressive tour, starting with minimal APIs, and adding more services from chapter to chapter using <span class="No-Break">different technologies.</span></p>
			<p>With the book’s repository, the solution is planned to be updated to newer .NET and .NET Aspire versions. As newer versions become available, the book version will stay available in the <span class="No-Break"><strong class="source-inline">dotnet8</strong></span><span class="No-Break"> branch.</span></p>
			<p>To see more developments with Codebreaker, check the <a href="https://github.com/codebreakerapp">https://github.com/codebreakerapp</a> organization. There, you can see further developments of the solution, as well as a list of client applications. Also, check <a href="https://codebreaker.app">https://codebreaker.app</a> to play a few games – of course, now you can also use a version running in your (hosted) <span class="No-Break">Kubernetes cluster.</span></p>
			<h1 id="_idParaDest-385"><a id="_idTextAnchor384"/>Further reading</h1>
			<p>To learn more about the topics discussed in this chapter, you can refer to the <span class="No-Break">following links:</span></p>
			<ul>
				<li><em class="italic">Business continuity and disaster </em><span class="No-Break"><em class="italic">recovery</em></span><span class="No-Break">: </span><a href="https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/management-business-continuity-disaster-recovery"><span class="No-Break">https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/management-business-continuity-disaster-recovery</span></a></li>
				<li><em class="italic">Azure load-balancing </em><span class="No-Break"><em class="italic">options</em></span><span class="No-Break">: </span><a href="https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview"><span class="No-Break">https://learn.microsoft.com/en-us/azure/architecture/guide/technology-choices/load-balancing-overview</span></a></li>
				<li><span class="No-Break">Kubernetes: </span><a href="https://kubernetes.io/"><span class="No-Break">https://kubernetes.io/</span></a></li>
				<li>Learn Kubernetes <span class="No-Break">basics: </span><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/"><span class="No-Break">https://kubernetes.io/docs/tutorials/kubernetes-basics/</span></a></li>
				<li>Helm – the package manager for <span class="No-Break">Kubernetes: </span><a href="https://helm.sh"><span class="No-Break">https://helm.sh</span></a></li>
				<li>The <strong class="source-inline">kubectl</strong> command-line <span class="No-Break">tool: </span><a href="https://kubernetes.io/docs/reference/kubectl/"><span class="No-Break">https://kubernetes.io/docs/reference/kubectl/</span></a></li>
				<li>Aspirate GitHub <span class="No-Break">repository: </span><a href="https://github.com/prom3theu5/aspirational-manifests"><span class="No-Break">https://github.com/prom3theu5/aspirational-manifests</span></a></li>
				<li><em class="italic">aspir8 from </em><span class="No-Break"><em class="italic">scratch</em></span><span class="No-Break">: </span><a href="https://github.com/devkimchi/aspir8-from-scratch"><span class="No-Break">https://github.com/devkimchi/aspir8-from-scratch</span></a></li>
				<li><em class="italic">Configure ingress with Azure Kubernetes </em><span class="No-Break"><em class="italic">Services</em></span><span class="No-Break">: </span><a href="https://learn.microsoft.com/en-us/azure/aks/app-routing"><span class="No-Break">https://learn.microsoft.com/en-us/azure/aks/app-routing</span></a></li>
				<li><em class="italic">Deploy a .NET microservice to Kubernetes </em><span class="No-Break"><em class="italic">manually</em></span><span class="No-Break">: </span><a href="https://learn.microsoft.com/en-us/training/modules/dotnet-deploy-microservices-kubernetes/"><span class="No-Break">https://learn.microsoft.com/en-us/training/modules/dotnet-deploy-microservices-kubernetes/</span></a></li>
				<li><strong class="source-inline">kubectl</strong> – the definitive pronunciation <span class="No-Break">guide: </span><a href="https://www.youtube.com/watch?v=2wgAIvXpJqU"><span class="No-Break">https://www.youtube.com/watch?v=2wgAIvXpJqU</span></a></li>
			</ul>
		</div>
	</body></html>