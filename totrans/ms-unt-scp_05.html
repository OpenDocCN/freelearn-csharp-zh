<html><head></head><body><div class="chapter" title="Chapter&#xA0;5.&#xA0;Cameras, Rendering, and Scenes"><div class="titlepage"><div><div><h1 class="title"><a id="ch05"/>Chapter 5. Cameras, Rendering, and Scenes</h1></div></div></div><p>This chapter focuses on some of the many things you can do with cameras, rendering, and scenes, as well as interesting combinations of them. Generally speaking, the camera is an eye point from which a scene is rendered. It is a point in 3D space from which a view of the scene, from a given perspective and field of view, is captured and rasterized to a texture in the form of pixels. After this, it's rendered to the screen by being blended and composited on top of any previous renders from any other cameras. Thus, cameras, rendering, and scenes are intimately connected processes. In this chapter, we'll see how to animate cameras and build fly-through animations, move cameras along curved paths, and see how objects can know whether they are being seen and when they are being seen by any specific camera. In addition, we'll see how to manually edit and process camera renders to create a postprocess effect, and we'll also see how to configure orthographic cameras to render pixel perfect 2D textures for 2D games and graphic user interfaces. So let's get started.</p><div class="section" title="Camera gizmos"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec52"/>Camera gizmos</h1></div></div></div><p>When a camera is<a id="id376" class="indexterm"/> selected in the <span class="strong"><strong>Scene</strong></span> tab and the <span class="strong"><strong>Gizmo</strong></span> display is enabled, it displays a frustum gizmo that indicates clearly where the camera is positioned in the scene and what the camera can see from that view, given its other properties such as field of view, as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/0655OT_05_01.jpg" alt="Camera gizmos"/><div class="caption"><p>Camera displays the frustum when selected in the Scene view</p></div></div><p>This gizmo is especially helpful to position selected cameras to get the best possible view of the scene. However, there are times when you want to achieve almost the reverse, that is, to position objects in the view of unselected cameras. Specifically, you'll want to move particular objects in the frustum of a camera and make sure it's visible to that camera. This can be tedious<a id="id377" class="indexterm"/> to achieve under normal circumstances, because, by default, cameras don't display their frustum gizmo when deselected. This means that as you move objects around, you'll need to continually select and reselect your cameras to check whether the moved objects are really in the camera frustum, and adjust and tweak their positions if required. To solve this issue, it'd be great if Unity allowed you to view the frustum gizmo permanently, even when the camera was deselected, but it doesn't, at least, not at the time of writing this book. To work around this, however, you can write a script, as shown in the following code sample 5-1:</p><div class="informalexample"><pre class="programlisting">01 using UnityEngine;
02 using System.Collections;
03 //-------------------------------------------------------
04 [ExecuteInEditMode]
05 [RequireComponent(typeof(Camera))]
06 //-------------------------------------------------------
07 public class DrawFrustumRefined : MonoBehaviour 
08 {
09 //-------------------------------------------------------
10 private Camera Cam = null;
11 public bool ShowCamGizmo = true;
12 //-------------------------------------------------------
13 void Awake()
14 {
15       Cam = GetComponent&lt;Camera&gt;();
16 }
17 //-------------------------------------------------------
18 void OnDrawGizmos()
19 {
20       //Should we show gizmo?
21       if(!ShowCamGizmo) return;
22       //Get size (dimensions) of Game Tab
23       Vector2 v = DrawFrustumRefined.GetGameViewSize();
24       float GameAspect = v.x/v.y; //Calculate tab aspect ratio
25       float FinalAspect = GameAspect / Cam.aspect; 
26 
27       Matrix4x4 LocalToWorld = transform.localToWorldMatrix;
28       Matrix4x4 ScaleMatrix = Matrix4x4.Scale(new Vector3(Cam.aspect * (Cam.rect.width / Cam.rect.height), FinalAspect,1)); 

29       Gizmos.matrix = LocalToWorld * ScaleMatrix;
30       Gizmos.DrawFrustum(transform.position, Cam.fieldOfView, Cam.nearClipPlane, Cam.farClipPlane, FinalAspect); 

31       Gizmos.matrix = Matrix4x4.identity; //Reset gizmo matrix
32 }
33 //-------------------------------------------------------
34 //Function to get dimensions of game tab
35 public static Vector2 GetGameViewSize()
36 {
37       System.Type T = System.Type.GetType("UnityEditor.GameView,UnityEditor");
38        System.Reflection.MethodInfo GetSizeOfMainGameView = T.GetMethod("GetSizeOfMainGameView",System.Reflection.BindingFlags.NonPublic | System.Reflection.BindingFlags.Static);

39        return (Vector2)GetSizeOfMainGameView.Invoke(null,null);
40 }
41 //-------------------------------------------------------
42 }
43 //-------------------------------------------------------</pre></div><p>The following are the <a id="id378" class="indexterm"/>comments in code sample 5-1:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lines 27-31</strong></span>: The <code class="literal">Gizmos.DrawFrustum</code> function<a id="id379" class="indexterm"/> accepts arguments such as position and rotation in world space and not local space. This means all positional arguments must first be transformed using a matrix from local space to world space. This is achieved with the <code class="literal">localToWorldMatrix</code> member of the <code class="literal">Transform</code> class. Additionally, the aspect argument requires further calculation between the actual viewport height and width, and the size of the game window in width and height.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lines 35-40</strong></span>: The <a id="id380" class="indexterm"/><code class="literal">GetGameViewSize</code> function returns a 2D vector that express the actual pixel dimensions of the <span class="strong"><strong>Game</strong></span> tab view. It retrieves these values using <a id="id381" class="indexterm"/>undocumented editor features. The "undocumented" nature of the function call should be emphasized; this means that the code can easily be broken or invalidated by future and even minor releases.</li></ul></div><p>The following screenshot shows the frustum:</p><div class="mediaobject"><img src="graphics/0655OT_05_02.jpg" alt="Camera gizmos"/><div class="caption"><p>Frustum is shown even when the camera is deselected</p></div></div></div></div>
<div class="section" title="Being seen"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec53"/>Being seen</h1></div></div></div><p>There are many occasions during gameplay when questions of object visibility arise, some actual and some hypothetical. Concerning<a id="id382" class="indexterm"/> the actual occasion, there are several questions we could ask, including whether object X is visible to camera Y right now, whether object X is visible to any camera right now, or when does object X become visible or nonvisible to a specific camera or to any camera. With regard to hypotheticals, we would ask whether object X would be visible if camera Y were moved to position Z. In the actual occasion case, we're concerned with the real visibility of objects for the current frame, based on the positions of all cameras, and concerning hypotheticals, we're concerned with what would be the case if a camera were moved to a specific position. Both these cases are important for games. Knowing whether objects (such as enemy characters) are really visible to the camera is important to define behavior and AI. This is because when objects are not visible, there are many behaviors and calculations we could suspend to save the processing workload. Further, knowing whether an object would become visible if the camera were moved is helpful because it lets us anticipate which objects, if any, will enter visibility for the next frame so that we can prepare them ahead of time. Now, before moving on to consider how these questions can be answered in script, it's worth considering the visibility in its narrowest sense.</p><p>In terms of visibility, there are two main concepts: frustum and occlusion. Each perspective camera has a viewing frustum, as we saw earlier; this frustum is a trapezoidal volume extended outwards from the camera lens and contains a region defined by field of view and clipping plane distance properties. The frustum, in essence, mathematically defines the horizons of a<a id="id383" class="indexterm"/> camera—the region of a scene that the camera can potentially observe right now. The word, potentially, is significant, because even when an active and visible object is within the camera frustum, it doesn't necessarily mean that it's visible to the camera. This is because objects within the frustum can occlude others also inside the frustum; that is, nearer objects can obscure or conceal objects behind them either fully or partially. For this reason, true visibility tests involve at least two processes: first, determining whether an object is in the frustum, and second, determining whether it is occluded or not. Only if an object passes both tests can it be classified as visible to the camera, and even then, only on the assumption that an object is not concealed or rendered invisible by custom shaders or other postprocess effects. In short, there are many reasons why true visibility testing is an intricate process, but here, I'll take the two-stage test as good enough for most purposes.</p><div class="section" title="Detecting the object visibility"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec32"/>Detecting the object visibility</h2></div></div></div><p>Perhaps, the simplest and more<a id="id384" class="indexterm"/> direct visibility test for objects in Unity is determining when an object becomes visible and invisible to any camera. The two companion events, <code class="literal">OnBecameVisible</code> and <code class="literal">OnBecameInvisible</code>, are called automatically on any object with a renderer component, including <code class="literal">MeshRenderer</code> and <code class="literal">SkinnedMeshRenderer</code>. It's not, of course, called on empty game objects even if they fall within the view of the camera, as they (technically speaking) contain no visible parts, despite all parts being spatially located. You can handle these events, as shown in the following code sample 5-2:</p><div class="informalexample"><pre class="programlisting"> //----------------------------------------------
 using UnityEngine;
 using System.Collections;
 //----------------------------------------------
 public class ViewTester : MonoBehaviour 
 {
    //----------------------------------------------
   void OnBecameVisible()
    {
          Debug.Log ("Became Visible");
    }
    /----------------------------------------------
    void OnBecameInvisible()
    {
          Debug.Log ("Became Invisible");
    }
    //----------------------------------------------
 }
 //----------------------------------------------</pre></div><p>There are several important caveats worth noting with the events <code class="literal">OnBecameVisible</code> and <code class="literal">OnBecameInvisible</code>. First, visibility here only means that an object has come within the camera frustum; thus, it can still be <a id="id385" class="indexterm"/>occluded by other, nearer objects, and so, it might not be truly visible at all. Second, the events pertain to all cameras and not to specific cameras. <code class="literal">OnBecameVisible</code> is called once to tell you that the object, while previously not visible, has now entered the frustum of at least one camera. Likewise, <code class="literal">OnBecameInvisible</code> is called once and tells you that the object, while previously visible, has now left the frustum of all cameras. Finally, and rather unhelpfully, these functions also include the visibility of the scene camera. This means that if you're testing your game with the <span class="strong"><strong>Scene</strong></span> tab open and visible and the object is visible to you in the <span class="strong"><strong>Scene</strong></span> tab, this will count as being visible. In short, the methods <code class="literal">OnBecameVisible</code> and <code class="literal">OnBecameInvisible</code> would be useful only if your behavior depends on the total visibility or invisibility in the scene, where visibility just corresponds to the frustum's presence. In other words, these events are a great place to toggle behaviors such as AI behaviors that depend on visibility, for example, NPC panic behaviors and other kinds of NPC-to-NPC interactions.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip31"/>Tip</h3><p>More information on the functions <code class="literal">OnBecameVisible</code> and <code class="literal">OnBecameInvisible</code> can be <a id="id386" class="indexterm"/>found online in the Unity<a id="id387" class="indexterm"/> documentation at <a class="ulink" href="http://docs.unity3d.com/ ScriptReference/MonoBehaviour.OnBecameVisible.html">http://docs.unity3d.com/
ScriptReference/MonoBehaviour.OnBecameVisible.html</a> and <a class="ulink" href="http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameInvisible.html">http://docs.unity3d.com/ScriptReference/MonoBehaviour.OnBecameInvisible.html</a>.</p></div></div></div><div class="section" title="More on the object visibility"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec33"/>More on the object visibility</h2></div></div></div><p>Another check that's important, besides<a id="id388" class="indexterm"/> testing when an object enters and leaves camera visibility, is to test whether an object is visible right now to a specific camera. Unlike <code class="literal">OnBecameVisible</code> and <code class="literal">OnBecameInvisible</code>, which were called on a one-off basis when an object enters or leaves the frustum, this kind of test is about the current state of an object that assumes no prior knowledge of it. To achieve this, the <code class="literal">OnWillRenderObject</code> event can be used. This event is called continuously on an object, once per frame for each camera to which it is visible as long as the object is visible to that camera. "Visible" here is taken to mean "within the camera frustum". Again, no occlusion testing<a id="id389" class="indexterm"/> is applied. Refer to the following code sample 5-3, and notice that inside this event, the <code class="literal">Camera.current</code> member can be used to retrieve a reference to the camera to which the object is currently visible, including the scene view camera:</p><div class="informalexample"><pre class="programlisting">   void OnWillRenderObject()
   {
        Debug.Log (Camera.current.name);
   }</pre></div></div><div class="section" title="Frustum testing – renderers"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec34"/>Frustum testing – renderers</h2></div></div></div><p>There are many times when the Unity native camera events, as we saw earlier, are not sufficient for your visibility and <a id="id390" class="indexterm"/>frustum-testing requirements. Specifically, you might simply want to test whether just one specific camera can see a renderer, whether an invisible object would be seen if it were visible, whether a specified<a id="id391" class="indexterm"/> point in space is seen by the camera, or whether a camera would see a specific object if it were moved to a new location. All of these cases can be important visibility tests in different situations, and all of them require some degree of manual testing. To meet these camera visibility needs, we'll need to code more intensively. The functions in the following sections will be compiled together as static functions in a dedicated <code class="literal">CamUtility</code> class. Let's start by creating a function to test whether a specific renderer component is within the frustum of a specific <code class="literal">Camera</code> object, as shown in the following code sample 5-4:</p><div class="informalexample"><pre class="programlisting">01 using UnityEngine;
02 using System.Collections;
03 //---------------------------------------------------------
04 public class CamUtility
05 {
06 //---------------------------------------------------------
07 //Function to determine whether a renderer is within frustum of a specified camera
08 //Returns true if renderer is within frustum, else false
09 public static bool IsRendererInFrustum(Renderer Renderable, Camera Cam)

10 {
11        //Construct frustum planes from camera
12        //Each plane represents one wall of frustrum
13        Plane[] planes = GeometryUtility.CalculateFrustumPlanes(Cam);

14 
15       //Test whether renderable is within frustum planes
16       return GeometryUtility.TestPlanesAABB(planes, Renderable.bounds);

17 }
18 //---------------------------------------------------------
19 }</pre></div><p>From lines 10–17, the <code class="literal">GeometryUtility</code> class is used to generate an array of plane objects that describe the camera frustum. Planes are to 3D space what lines are to 2D space; they mark out a flat, imaginary <a id="id392" class="indexterm"/>surface in 3D. The frustum planes are a collection of six planes that are rotated and aligned in 3D space to represent the <a id="id393" class="indexterm"/>complete trapezoidal camera frustum. This array is then used by the <code class="literal">TestPlanesAABB</code> function, <span class="strong"><strong>Axially Aligned Bounding Box</strong></span> (<span class="strong"><strong>AABB</strong></span>), which<a id="id394" class="indexterm"/> determines whether the collision boundary of a mesh renderer exists inside the frustum as defined by the planes.</p></div><div class="section" title="Frustum testing – points"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec35"/>Frustum testing – points</h2></div></div></div><p>Of course, you don't always <a id="id395" class="indexterm"/>want to test renderers for visibility. Instead, you might simply want to test for a point. This might be for two main reasons. First, you might want to know whether an object, such as a particle or a gun target location, is actually visible. Second, you might not only want to know <a id="id396" class="indexterm"/>whether a point is visible but also where in the screen space; this will be rendered by the camera. The following code sample 5-5 will do this. It will test whether a point is within the camera frustum, and if so, it would further return where the point would be rendered on screen in a normalized viewport space (between 1-0).</p><div class="informalexample"><pre class="programlisting"> //---------------------------------------------------------
 //Determines if point is within frustum of camera
 //Returns true if point is within frustum, else false
 //The out param ViewPortLoc defines the location 
 
public static bool IsPointInFrustum(Vector3 Point, Camera Cam, out Vector3 ViewPortLoc)
    {
         //Create new bounds with no size
         Bounds B = new Bounds(Point, Vector3.zero);
 
        //Construct frustum planes from camera
        //Each plane represents one wall of frustrum

         Plane[] planes = GeometryUtility.CalculateFrustumPlanes(Cam);
 
        //Test whether point is within frustum planes
        bool IsVisible = GeometryUtility.TestPlanesAABB(planes, B);
        //Assign viewport location
        ViewPortLoc = Vector3.zero;
 
       //If visible then get viewport location of point
       if(IsVisible)
                ViewPortLoc = Cam.WorldToViewportPoint(Point);
 
         return IsVisible;
    }
    //---------------------------------------------------------</pre></div></div><div class="section" title="Frustum testing – occlusion"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec36"/>Frustum testing – occlusion</h2></div></div></div><p>As mentioned earlier, visibility in its strictest sense is primarily a two-stage and not a one-stage process. All visibility testing so far has consisted only of checking for an object's presence within the frustum <a id="id397" class="indexterm"/>of a camera. Typically, this is enough, and it should always be preferred. However, sometimes, it's really not enough, because even among objects within the frustum, it's possible for one object to occlude another, as nearer objects can conceal objects further away, either fully or partially. This, in itself, is not always a problem though, because more often than not, the main interest in determining object visibility is simply to know whether the camera is near enough for a set of performance-intensive behaviors (such as AI behaviors) to be enabled. The aim is not truly visibility<a id="id398" class="indexterm"/> testing, but to know whether the camera is close enough. In these cases, it doesn't matter whether the objects are occluded; it only matters whether they are in the frustum. Yet, occasionally, occlusion matters, such as when displaying GUI elements or pop-up notifications as the player looks at specific objects. In these cases, occlusion is important, because GUI elements should not pop up for objects on the other side of a wall, for example. Sometimes, you can even get around these situations with an inventive use of colliders, triggers, and careful object placement, and sometimes, there's really no choice but to further filter objects in the frustum with occlusion testing. Now, occlusion testing among objects within the frustum is a deep subject that can, via some implementations, have a significant performance overhead. For this reason, one of the best methods is to use a simple <code class="literal">Physics.LineCast</code> method call to determine whether an imaginary line drawn between the camera and destination object is intersected by other colliders. This method usually works well, but its limitations should be recognized. First, it assumes that all visible objects have colliders; any exceptions to this rule will not be detected by the<a id="id399" class="indexterm"/> <code class="literal">LineCast</code> method. Second, as colliders only approximate the bounds of a mesh and do not wrap around the mesh vertex for vertex, it's possible for the <code class="literal">LineCast</code> method to fail when meshes have internal holes, as the surrounding collider will <a id="id400" class="indexterm"/>prevent <code class="literal">LineCast</code> from penetrating them. Finally, meshes with transparent materials that reveal objects behind<a id="id401" class="indexterm"/> them will always fail the <code class="literal">LineCast</code> method. Consider the following code sample 5-6:</p><div class="informalexample"><pre class="programlisting">    //---------------------------------------------------------
    //Function to determine whether an object is visible
    public static bool IsVisible(Renderer Renderable, Camera Cam)
    {
         //If in frustrum then cast line
         if(CamUtility.IsRendererInFrustum(Renderable, Cam))
               return 

//Is direct line between camera and object?
!Physics.Linecast(Renderable.transform.position, Cam.transform.position);
         return false; //No line found or not in frustum
    }
    //---------------------------------------------------------</pre></div></div><div class="section" title="Camera vision – front and back"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec37"/>Camera vision – front and back</h2></div></div></div><p>In some games, such as <a id="id402" class="indexterm"/>RTS games or casual games, the camera horizon (or far clipping plane) does not have so great a significance, because the camera always sees everything that is in front of it. In these cases, when objects are outside the <a id="id403" class="indexterm"/>frustum, they are only outside in the <span class="emphasis"><em>x</em></span> and <span class="emphasis"><em>y</em></span> planes but not in the local <span class="emphasis"><em>z</em></span> axis; that is, the hidden objects are only hidden because the camera is not directly looking at them. However, when the camera is appropriately orientated, objects can never be too far away in the distance to be seen beyond the far clipping plane. In situations like these, visibility tests can often be reduced to faster and simpler orientation tests. Thus, the question changes from, "Is the object within the frustum and not occluded?" to "Is the object in front of the camera or is it behind?" Here, the answer we need is different; the question is not one of visibility but of orientation, whether the camera and its subject are so oriented that the subject is in front of the camera or behind it. To test for this, the vector dot product can be used. The dot product accepts two vectors as input and reduces them to a single dimensional, numerical value as output. This value describes the angular relationship between the two input vectors. In the following code sample 5-7, the <code class="literal">CamFieldView</code> class can be attached to a camera, and it detects whether the camera can see a target object, that is, whether the target object is within a limited field of view in front of the camera:</p><div class="informalexample"><pre class="programlisting"> using UnityEngine;
 using System.Collections;
 //-------------------------------------------------
 public class CamFieldView : MonoBehaviour 
 {
    //-------------------------------------------------
    //Field of view (degrees) in which can see in front of us
    //Measure in degrees from forward vector (left or right)
    public float AngleView = 30.0f;
 
    //Target object for seeing
    public Transform Target = null;
 
    //Local transform
    private Transform ThisTransform = null;
    //-------------------------------------------------
    // Use this for initialization
    void Awake () 
    {
         //Get local transform
         ThisTransform = transform;
    }
    //-------------------------------------------------
     // Update is called once per frame
     void Update ()
    {
         //Update view between camera and target
         Vector3 Forward = ThisTransform.forward.normalized;
         Vector3 ToObject = (Target.position - ThisTransform.position).normalized;
 
         //Get Dot Product
         float DotProduct = Vector3.Dot(Forward, ToObject);
         float Angle = DotProduct * 180f;
 
         //Check within field of view
        if(Angle &gt;= 180f-AngleView)
         {
                  Debug.Log ("Object can be seen");
         }
    }
    //-------------------------------------------------
 }
 //-------------------------------------------------</pre></div></div></div>
<div class="section" title="Orthographic cameras"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec54"/>Orthographic cameras</h1></div></div></div><p>Every newly created camera object in Unity is, by default, configured as a perspective camera, unless you change the default settings. This type of camera most closely corresponds to real-life cameras that have a position within the 3D space, a curved lens, and employ methods to convert<a id="id404" class="indexterm"/> captured images onto a flat, 2D surface, like a screen. The chief symptom of such a camera is foreshortening, the name given to the distortion applied to rendered objects. Specifically, rendered objects grow smaller as they recede into the distance, the shape and appearance of objects change as they move further from the center of vision, and all parallel lines converge at a vanishing point somewhere in the distance, whether on the horizon line itself or on a secondary line. In contrast to perspective cameras, however, there are orthographic cameras. These are useful for the creation of 2D and truly isometric games and not just for the semblance of isometric. With orthographic cameras, the lens is flattened out to a plane, and the result is a loss of foreshortening, that is, parallel lines remain parallel, objects don't shrink with distance, 2D remains 2D even when moved away from the center of the view, and so on. You can easily switch a camera from <span class="strong"><strong>Perspective</strong></span> to <span class="strong"><strong>Orthographic</strong></span> using the <span class="strong"><strong>Projection</strong></span> type setting from the Object Inspector, as shown in the following screenshot:</p><div class="mediaobject"><img src="graphics/0655OT_05_03.jpg" alt="Orthographic cameras"/><div class="caption"><p>Changing a Perspective camera to an Orthographic one</p></div></div><p>After changing the <span class="strong"><strong>Perspective</strong></span> type to <span class="strong"><strong>Orthographic</strong></span>, the camera frustum will also change from a trapezoidal volume to a box. Everything within the box will be visible, and nearer objects will continue to obscure more distant ones, but all other senses of depth will be lost, as shown in the following screenshot. Hence, this camera is considered suitable for 2D games.</p><div class="mediaobject"><img src="graphics/0655OT_05_04.jpg" alt="Orthographic cameras"/><div class="caption"><p>The frustum for an Orthographic camera is a box</p></div></div><p>The central problem when working with the <span class="strong"><strong>Orthographic</strong></span> cameras is how to create a 1:1 relationship between world units (in the scene) and pixels (on screen). This problem arises because in 2D games and GUIs, it's useful to show graphics on screen at their default and correct sizes, as defined in the texture files. In most 3D games, by contrast, texture mapping, foreshortening, and perspective means textures are seen distorted, that is, projected onto the<a id="id405" class="indexterm"/> surface of 3D objects where they are viewed not directly as though in a photo-editing program, but in perspective. With 2D games and sprites, the situation is different. These graphics are typically viewed head on. For this reason, it's desirable to display them in their default sizes, pixel for pixel. This kind of display is called pixel perfection, because each pixel in the texture will be shown onscreen and in the game, unchanged. Achieving this in practice, however, requires a specific approach. In short, to map 1 world unit to 1 pixel, the <span class="strong"><strong>Size</strong></span> field in the <span class="strong"><strong>Camera</strong></span> tab should be set to half the vertical resolution of the game. Thus, if your game runs at 1024 x 768, the <span class="strong"><strong>Size</strong></span> field should be <code class="literal">364</code>, because 768 / 2 = 364, as shown here:</p><div class="mediaobject"><img src="graphics/0655OT_05_05.jpg" alt="Orthographic cameras"/><div class="caption"><p>The Size field controls how world units map to pixels on screen</p></div></div><p>You can set the <span class="strong"><strong>Size</strong></span> field directly in the editor, but this would only work if your game resolution is constant<a id="id406" class="indexterm"/> and never changes. If the user can resize the game window or change the game resolution, then you would need to update the camera size in script, as shown in the following code sample 5-8:</p><div class="informalexample"><pre class="programlisting">01 //-------------------------------------------------------
02 using UnityEngine;
03 using System.Collections;
04 //-------------------------------------------------------
05 [RequireComponent(typeof(Camera))] 
06 //-------------------------------------------------------
07 public class OrthoCam : MonoBehaviour
08 {
09 //private reference to camera component
10 private Camera Cam = null;
11 
12 //Reference to Pixels to World Units Scale
13 public float PixelsToWorldUnits = 200f;
14 //-------------------------------------------------------
15 // Use this for initialization
16 void Awake () 
17 {
18        //Get camera reference
19        Cam = GetComponent&lt;Camera&gt;();
20 }
21 //-------------------------------------------------------
22 // Update is called once per frame
23 void LateUpdate () 
24 {
25        //Update orthographic size
26        Cam.orthographicSize = Screen.height / 2f / PixelsToWorldUnits;

27 }
28 //-------------------------------------------------------
29 }
30 //-------------------------------------------------------</pre></div><p>Notice that the member variable <code class="literal">PixelsToWorldUnits</code> has been added to line 13 to scale the orthographic <a id="id407" class="indexterm"/>size according to the <span class="strong"><strong>Pixels To Units</strong></span> field of imported sprite textures, as shown in the following screenshot. This helps ensure that sprites will appear in their correct pixel sizes when shown on screen. This is so because all sprites are necessarily scaled by this value to map pixels in the texture to units in the world.</p><div class="mediaobject"><img src="graphics/0655OT_05_06.jpg" alt="Orthographic cameras"/><div class="caption"><p>Setting the Pixels to Units scale for sprite textures</p></div></div></div>
<div class="section" title="Camera rendering and postprocessing"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec55"/>Camera rendering and postprocessing</h1></div></div></div><p>The official Unity documentation<a id="id408" class="indexterm"/> concerning camera rendering and postprocessing is comparatively sparse. However, this should not be taken as an indication that there's little to be said <a id="id409" class="indexterm"/>on the subject. On the contrary, Unity cameras and objects offer extensive flexibility over how the scene is rendered. These topics fall under the umbrella term of postprocessing. Specifically, this refers to all the additional edits and amendments made to a camera's rendered output that is not included as part of the normal render. This includes blur effects, color adjustments, fish-eye effects, and so on. It should be said here that access to these features is included only in the professional version of Unity and not in the free version. For this reason, free users will not be able to follow along and complete this section. However, for professional version users, there is a wide range of camera-rendering features available, as shown in the following screenshot. This section considers them by creating a camera change system in which one camera will cross-fade smoothly into another. By cross-fade, I don't simply mean that one<a id="id410" class="indexterm"/> camera will cut to another, which (incidentally) can be <a id="id411" class="indexterm"/>achieved by changing a camera's depth field, as higher-order cameras are rendered above lower-order cameras. I rather mean that the rendered output of the first camera will gradually dissolve in opacity to reveal the output of the second camera. So, let's get started.</p><div class="mediaobject"><img src="graphics/0655OT_05_07.jpg" alt="Camera rendering and postprocessing"/><div class="caption"><p>Creating a scene with multiple cameras</p></div></div><p>Start the project with a scene that contains two separate areas or regions, as shown in the preceding screenshot. The sample project is included in the book's companion files (code bundle) inside the <code class="literal">Cameras</code> folder of this chapter. Each region of the scene should be assigned a separate camera; this makes a total of two cameras in the scene, and each camera component should be disabled. This will prevent the cameras from rendering themselves automatically. Here, we'll be rendering the cameras manually; this will allow the render from each camera to be composited and faded on top of the other.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip32"/>Tip</h3><p>For each camera, the <code class="literal">AudioListener</code> component was removed, because a Unity scene can have only one <code class="literal">AudioListener</code> active at any one time.</p></div></div><p>Next, create a third camera tagged as <code class="literal">MainCamera</code> at the scene's origin and set with a culling mask of nothing, making<a id="id412" class="indexterm"/> sure that the camera is active but can render nothing. This<a id="id413" class="indexterm"/> will represent the central main scene camera that composites together renders from all other cameras, as shown here:</p><div class="mediaobject"><img src="graphics/0655OT_05_08.jpg" alt="Camera rendering and postprocessing"/><div class="caption"><p>Creating a third main camera for rendering</p></div></div><p>Now, the scene should have three cameras: two separate and disabled cameras at different locations (cameras <span class="strong"><strong>X</strong></span> and <span class="strong"><strong>Y</strong></span>), and one main camera at the scene's origin (camera <span class="strong"><strong>Z</strong></span>). On this basis, the following code sample 5-9 can be assigned to camera <span class="strong"><strong>Z</strong></span>, and this allows fading between cameras <span class="strong"><strong>X</strong></span> and <span class="strong"><strong>Y</strong></span> when Space bar is pressed:</p><div class="informalexample"><pre class="programlisting">001 //Class to fade from camera 0 to 1, and back from 1 to 0
002 //This class assumes there are only two scene cameras
003 //---------------------------------------
004 using UnityEngine;
005 using System.Collections;
006 //---------------------------------------
007 public class CameraFader : MonoBehaviour
008 {
009       //---------------------------------------
010       //All cameras in the scene to be composited
011       public Camera[] Cameras;
012 
013      //Color to multiply with render)
014      public Color[] CamCols = null;
015 
016      //Fade in/out time in seconds 
017       public float FadeTime = 2.0f;
018 
019       //Material used as shader to final render
020       public Material Mat = null;
021       //---------------------------------------
022       // Use this for initialization
023       void Start () 
024       {
025             //Assign render textures to each camera
026             foreach(Camera C in Cameras)
<span class="strong"><strong>027                    C.targetTexture = new RenderTexture(Screen.width, Screen.height, 24); //Create texture</strong></span>

028       }
029       //---------------------------------------
030       //Called once per frame after the camera has 
031       //finished rendering but before the render is shown
032       //Companion function: OnPreRender
<span class="strong"><strong>033        void OnPostRender()</strong></span>
034       {
035            //Define screen rect
036            Rect ScreenRct = new Rect(0,0,Screen.width,Screen.height);
037 
038            //Source Rect
039            Rect SourceRect = new Rect(0,1,1,-1);
040 
041            //Render each camera to their target texture
042            for(int i = 0; i&lt;Cameras.Length; i++)
043             {
044                   //Render camera
045                   Cameras[i].Render();
046 
047                   //Draw textures to screen using camera
048                   GL.PushMatrix();
049                   GL.LoadPixelMatrix();
050                   Graphics.DrawTexture(ScreenRct, Cameras[i].targetTexture, SourceRect, 0,0,0,0, CamCols[i]); 
051                   GL.PopMatrix(); //Reset matrix
052            }
053       }
054       //---------------------------------------
055       //This function is called after OnPostRender
056       //And when final pixels are to be shown on screen
057       //src = current render from camera
058       //dst = texture to be shown on screen
059       void OnRenderImage(RenderTexture src, RenderTexture dst)
060       {
061             //Now push final pixels to screen with Mat
062             Graphics.Blit(src, dst, Mat);
063       }
064       //---------------------------------------
065       //Lerp color over period TotalTime
066      //Fade alpha for topmost rendered camera CamCols[1]
067      public IEnumerator Fade(Color From, Color To, float TotalTime)

068      {
069           float ElapsedTime = 0f;
070 
071            //Loop while total time is not met
072            while(ElapsedTime &lt;= TotalTime)
073             {
074                   //Update color
075                   CamCols[1] = Color.Lerp(From, To, ElapsedTime/TotalTime);
076 
077                  //Wait until next frame
078                  yield return null;
079 
080                 //Update Time
081                 ElapsedTime += Time.deltaTime;
082             }
083 
084            //Apply final color
085             CamCols[1] = Color.Lerp(From, To, 1f);
086     }
087       //---------------------------------------
088       //Sample for testing camera functionality
089       //Press space bar to fade in and out between cameras
090       void Update()
091       {
092             //Fade camera in or out when space is pressed
093             if(Input.GetKeyDown(KeyCode.Space))
094             {
095                   StopAllCoroutines();
096 
097                   //Should we fade out or in
098                   if(CamCols[1].a &lt;= 0f)
099                          StartCoroutine(Fade(CamCols[1], new Color(0.5f,0.5f,0.5f,1f), FadeTime)); //Fade in

100                    else
101                           StartCoroutine(Fade(CamCols[1], new Color(0.5f,0.5f,0.5f,0f), FadeTime)); //Fade out

102            }
103       }
104       //---------------------------------------
105 }</pre></div><p>The following are comments in code sample 5-9:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lines 011-020</strong></span>: The <code class="literal">CamerFader</code> class is responsible for cross fading between <code class="literal">Camera[0]</code> and <code class="literal">Camera[1]</code>. To achieve this, several variables are created. The <code class="literal">Cameras</code> array maintains a list of cameras: two cameras in this case. The <code class="literal">CamCols</code> array is linked to <code class="literal">Cameras</code>. It describes the color by which the render from<a id="id414" class="indexterm"/> the camera will be multiplied; this allows the alpha value to make the render transparent. The <code class="literal">FadeTime</code> variable defines the total time in seconds for a camera fade in one direction, either fade-out<a id="id415" class="indexterm"/> or fade-in. Finally, the <code class="literal">Mat</code> variable references any valid material that will be applied to the final render from the main camera, that is, the pixels of the completed render, including everything composited from all the other cameras.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lines 023-038</strong></span>: The <code class="literal">Start</code> method creates <code class="literal">RenderTexture</code> for each camera that assigns the texture to its <code class="literal">TargetTexture</code> member. In essence, this means each camera is assigned an internal texture to which its render is locally composited.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lines 033-052</strong></span>: The <code class="literal">OnPostRender</code> event is called automatically by Unity for any active camera objects in the scene, once for each frame and after the camera has completed its render as normal. It gives the object an opportunity to render additional cameras or elements on top of the normal rendered data. Here, the <code class="literal">Render</code> method of each camera in the <code class="literal">Cameras</code> array is called; this method manually renders the camera, not directly on screen but to its render texture. Once rendered to the texture, the <code class="literal">Graphics.DrawTexture</code> function draws <code class="literal">RenderTexture</code> for each camera onto the screen in the order of the array, one atop the other. Notice that each <code class="literal">DrawTexture</code> call multiplies the <code class="literal">CamCols</code> color to the texture; this also factors in the alpha component for transparency.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lines 059-063</strong></span>: Like <code class="literal">OnPostRender</code>, the <code class="literal">OnRenderImage</code> event is called automatically on active camera objects by Unity, once per frame. It's called after <code class="literal">OnPostRender</code> and just before the camera render is presented on screen. This event provides two arguments, namely, <code class="literal">src</code> and <code class="literal">dst</code>. The <code class="literal">src</code> argument is a<a id="id416" class="indexterm"/> reference to a render texture that contains the completed<a id="id417" class="indexterm"/> render from the camera, which was output from <code class="literal">OnPostRender</code>, and the <code class="literal">dst</code> argument reference defines the render texture that will be shown on screen when the <code class="literal">OnRenderImage</code> event completes. In short, this function gives us an opportunity to edit the pixels of the render either manually in code or via shader. Here, the <code class="literal">Graphics.Blit</code> function is called to copy the source to the destination render texture using the shader associated with the material reference <code class="literal">Mat</code>.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Lines 067-085</strong></span>: <code class="literal">Fade</code> is a <code class="literal">CoRoutine</code> that transitions a <code class="literal">From</code> color to a <code class="literal">To</code> color over the time (<code class="literal">TotalTime</code>). This <code class="literal">CoRoutine</code> method is used to transition the alpha of a camera color between <code class="literal">0</code> and <code class="literal">1</code>, which refer to transparent and opaque, respectively.</li></ul></div><p>The following screenshot shows the cross-fading camera effect:</p><div class="mediaobject"><img src="graphics/0655OT_05_09.jpg" alt="Camera rendering and postprocessing"/><div class="caption"><p>Cross-fading cameras</p></div></div></div>
<div class="section" title="Camera shake"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec56"/>Camera shake</h1></div></div></div><p>Now, here's an effect we can achieve with the Unity free version: camera shake! For fighting, shooting, and action games generally, a camera shake effect can be important. It conveys impact, danger, action, dynamism, and excitement—a form of kinetic feedback. It can, in fact, be used to stand in for<a id="id418" class="indexterm"/> lots of other animations too that simulate a pervasive motion and emotion where there really isn't any to be found elsewhere in the scene. To this extent, camera shakes can save us lots of work by creating an overarching animation, as shown here:</p><div class="mediaobject"><img src="graphics/0655OT_05_10.jpg" alt="Camera shake"/><div class="caption"><p>Camera shake effects</p></div></div><p>There are many ways to create camera shakes, but all of them involve fluctuation of the camera position between<a id="id419" class="indexterm"/> a minimum and maximum range using some kind of "randomness" function. Sometimes, the "randomness" is left raw, and sometimes, it's smoothened using the damping functionality to create a slower or more "flowing" shake. Refer to the following code sample 5-10 that can be attached to any camera to create a shake effect:</p><div class="informalexample"><pre class="programlisting"> using UnityEngine;
 using System.Collections;
 //---------------------
 public class CameraShake : MonoBehaviour 
 {
    private Transform ThisTransform = null;
 
     //Total time for shaking in seconds
     public float ShakeTime = 2.0f;
     //Shake amount - distance to offset in any direction
     public float ShakeAmount = 3.0f;
 
     //Speed of camera moving to shake points
     public float ShakeSpeed = 2.0f;
 
    //---------------------
    // Use this for initialization
    void Start () 
    {
         //Get transform component
         ThisTransform = GetComponent&lt;Transform&gt;();
 
         //Start shaking
        StartCoroutine(Shake());
    }
    //---------------------
    //Shake camera
    public IEnumerator Shake()
    {
         //Store original camera position
         Vector3 OrigPosition = ThisTransform.localPosition;
 
          //Count elapsed time (in seconds)
          float ElapsedTime = 0.0f;
  
         //Repeat for total shake time
         while(ElapsedTime &lt; ShakeTime)
         {
               //Pick random point on unit sphere
                Vector3 RandomPoint = OrigPosition + Random.insideUnitSphere * ShakeAmount;
 
                //Update Position
                ThisTransform.localPosition = Vector3.Lerp(ThisTransform.localPosition, RandomPoint, Time.deltaTime * ShakeSpeed);
 
                //Break for next frame
                yield return null;
 
                //Update time
                 ElapsedTime += Time.deltaTime;
         }
         //Restore camera position
         ThisTransform.localPosition = OrigPosition;
    }
    //---------------------
 }
 //---------------------</pre></div></div>
<div class="section" title="Cameras and animation"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec57"/>Cameras and animation</h1></div></div></div><p>Camera fly-throughs are <a id="id420" class="indexterm"/>animations in which the camera is moved and rotated over time across specific positions to create a cinematic. Their importance is primarily to create cut-scenes, though not exclusively. It can be useful for the creation of stylized third-person cameras and other top-down <a id="id421" class="indexterm"/>views in which the camera motion must be mapped in a specific and deliberated way. One of the most <a id="id422" class="indexterm"/>common methods to create a camera motion like this is to predefine them either using Unity's animation editor or third-party tools such as Maya, Blender, and 3DS Max. However, there are times when more programmatic control is required over the camera to adjust its position manually, away from an average center, using smooth, curved motions, passing through a series of points or following a specific and predefined route. This section considers three approaches.</p><div class="section" title="Follow cameras"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec38"/>Follow cameras</h2></div></div></div><p>Perhaps, one of the most common camera <a id="id423" class="indexterm"/>needs is a follow camera, that is, a camera that tracks a specified object in the scene and follows it. This camera maintains some<a id="id424" class="indexterm"/> distance between the object and the camera, as shown in the following screenshot. This is useful for third-person cameras, such as over-the-shoulder views and top-down views for RTS games.</p><div class="mediaobject"><img src="graphics/0655OT_05_11.jpg" alt="Follow cameras"/><div class="caption"><p>Making a camera smoothly follow an object</p></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip33"/>Tip</h3><p>This project can be found in the book's companion files (code bundle) inside the <code class="literal">Camera_Smooth_Damp</code> folder of this chapter.</p></div></div><p>For such cameras, a simple follow behavior is usually not enough for your purposes. If it were, you could simply parent the camera to the object and leave it at that. However, typically, you'll want some degree of smoothing or damping to the camera motion, that is, a falling-off of speed that allows<a id="id425" class="indexterm"/> the camera to gradually slow down to a stop on reaching the target, as opposed to a sudden and immediate stop in which the camera is either travelling at full speed or not at all. To achieve this, the <code class="literal">Quaternion.Slerp</code> and <code class="literal">Vector3.SmoothDamp</code> functions can be used. Consider the following code sample 5-11 for a class that can be attached to any camera to smoothly follow an object:</p><div class="informalexample"><pre class="programlisting"> using UnityEngine;
 using System.Collections;
 //---------------------------------------------------------------
 public class CamFollow : MonoBehaviour 
 {
 //---------------------------------------------------------------
    //Follow target
     public Transform Target = null;
 
    //Reference to local transform
    private Transform ThisTransform = null;
 
    //Linear distance to maintain from target (in world units)
    public float DistanceFromTarget = 10.0f;
 
    //Height of camera above target
    public float CamHeight = 1f;
 
    //Damping for rotation
    public float RotationDamp = 4f;
 
    //Damping for position
    public float PosDamp = 4f;
 //---------------------------------------------------------------
    void Awake()
    {
         //Get transform for camera
         ThisTransform = GetComponent&lt;Transform&gt;();
    }
 //---------------------------------------------------------------
    // Update is called once per frame
    void LateUpdate () 
    {
         //Get output velocity
         Vector3 Velocity = Vector3.zero;
 
         //Calculate rotation interpolate
         ThisTransform.rotation = Quaternion.Slerp(ThisTransform.rotation, Target.rotation, RotationDamp * Time.deltaTime);
 
         //Get new position
         Vector3 Dest = ThisTransform.position = Vector3.SmoothDamp(ThisTransform.position, Target.position, ref Velocity, PosDamp * Time.deltaTime);
 
         //Move away from target
         ThisTransform.position = Dest - ThisTransform.forward * 
DistanceFromTarget;
 
          //Set height
          ThisTransform.position = new Vector3(ThisTransform.position.x, CamHeight, ThisTransform.position.z);
 
         //Look at dest
         ThisTransform.LookAt(Dest);
    }
 //---------------------------------------------------------------
 }</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip34"/>Tip</h3><p>More information on <code class="literal">Quaternion.Slerp</code> can be <a id="id426" class="indexterm"/>found online at <a class="ulink" href="http://docs.unity3d.com/ScriptReference/Quaternion.Slerp.html">http://docs.unity3d.com/ScriptReference/Quaternion.Slerp.html</a>, and more information <a id="id427" class="indexterm"/>on <code class="literal">Vector3.SmoothDamp</code> can be found online at <a class="ulink" href="http://docs.unity3d.com/ScriptReference/Vector3.SmoothDamp.html">http://docs.unity3d.com/ScriptReference/Vector3.SmoothDamp.html</a>.</p></div></div></div></div>
<div class="section" title="Cameras and curves"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec58"/>Cameras and curves</h1></div></div></div><p>For cut-scenes, menu backgrounds, or simpler camera fly-throughs, you might just need the camera to travel<a id="id428" class="indexterm"/> roughly in a straight line that allows some curvature and fluctuation in speed as the camera moves using a smooth-in and smooth-out motion. This<a id="id429" class="indexterm"/> means that the camera picks up speed at the beginning and slowly drops in speed towards the end of the path. To achieve this, you can use a prescripted animation via Unity's animation editor, or you can use animation curves, which offer a high degree of flexibility and control over object transformations across time, as shown here:</p><div class="mediaobject"><img src="graphics/0655OT_05_12.jpg" alt="Cameras and curves"/><div class="caption"><p>Moving cameras with animation curves</p></div></div><p>To create a camera control script that allows you to control object speed and motion over time, including <a id="id430" class="indexterm"/>curved motion and smoothing or damping of speed, the<a id="id431" class="indexterm"/> following code sample 5-12 can be used:</p><div class="informalexample"><pre class="programlisting">//-----------------------------
 using UnityEngine;
 using System.Collections;
 //-----------------------------
 public class CameraMover : MonoBehaviour 
 {
    //-----------------------------
    //Total time for animation
    public float TotalTime = 5.0f;
 
    //Total Distance to move on each axis
    public float TotalDistance = 30.0f;
    //Curves for motion
    public AnimationCurve XCurve;
    public AnimationCurve YCurve;
    public AnimationCurve ZCurve;
 
    //Transform for this object
    private Transform ThisTransform = null;
    //-----------------------------
    void Start()
   {
         //Get transform component
         ThisTransform = GetComponent&lt;Transform&gt;();
 
        //Start animation
        StartCoroutine(PlayAnim());
    }
    //-----------------------------
    public IEnumerator PlayAnim()
    {
         //Time that has passed since anim start
         float TimeElapsed = 0.0f;
 
          while(TimeElapsed &lt; TotalTime)
          {
                //Get normalized time
                float NormalTime = TimeElapsed / TotalTime;
 
               //Sample graph for X Y and Z
               Vector3 NewPos = ThisTransform.right.normalized * XCurve.Evaluate(NormalTime) * TotalDistance;

                NewPos += ThisTransform.up.normalized * YCurve.Evaluate(NormalTime) * TotalDistance;

                NewPos += ThisTransform.forward.normalized * ZCurve.Evaluate(NormalTime) * TotalDistance;
 
               //Update position
               ThisTransform.position = NewPos;
 
               //Wait until next frame
               yield return null;
 
               //Update time
               TimeElapsed += Time.deltaTime;
          }
    }
    //-----------------------------
 
 }
 //-----------------------------</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip35"/>Tip</h3><p>A sample project using animation curves for camera movement can be found in the book's companion files (code bundle) inside the <code class="literal">Camera_Anim_Curves</code> folder of this chapter.</p></div></div><p>To use the <code class="literal">CameraMover</code> class, attach the script to a camera, and from the Object Inspector, click on each of the <span class="strong"><strong>X</strong></span>, <span class="strong"><strong>Y</strong></span>, and <span class="strong"><strong>Z</strong></span> curve fields to plot the distance and speed of the camera over time. By clicking on a <span class="strong"><strong>Graph</strong></span> swatch, you can edit the graph, thus adding points and defining<a id="id432" class="indexterm"/> a motion curve to apply for that axis. Notice that the <span class="strong"><strong>X</strong></span>, <span class="strong"><strong>Y</strong></span>, and <span class="strong"><strong>Z</strong></span> motion is plotted to the object's local axes (forward, up, and right) and not to the <a id="id433" class="indexterm"/>world axes (<span class="emphasis"><em>x</em></span>, <span class="emphasis"><em>y</em></span>, and <span class="emphasis"><em>z</em></span>). This allows the object motion to apply relatively that offers you root-level control of object motion while honoring the relevance of animation data, as shown here:</p><div class="mediaobject"><img src="graphics/0655OT_05_13.jpg" alt="Cameras and curves"/><div class="caption"><p>Plotting motion curves using animation curves</p></div></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip36"/>Tip</h3><p>More information on<a id="id434" class="indexterm"/> animation curves can be found online in the Unity documentation at <a class="ulink" href="http://docs.unity3d.com/Manual/AnimatorCurves.html">http://docs.unity3d.com/Manual/AnimatorCurves.html</a>.</p></div></div><div class="section" title="Camera paths – iTween"><div class="titlepage"><div><div><h2 class="title"><a id="ch05lvl2sec39"/>Camera paths – iTween</h2></div></div></div><p>One very common feature request that, strangely, has not yet been implemented as a native Unity feature is programmable<a id="id435" class="indexterm"/> motion paths. This refers to the ability to have a <code class="literal">GameObject</code>, such as a camera, smoothly follow a path or spline using spherical interpolation, where the path is defined by a series of connected game objects. This feature already exists in the sense that camera motion can be defined through prescripted animations that are created using Unity's animation editor. However, there is a desire for more<a id="id436" class="indexterm"/> flexible and programmatic control over a motion path in which the path is defined by a set of waypoints that can be adjusted in code over time. This functionality is especially useful, for example, for space-shooter games where the trajectory of enemy ships clearly follows smooth, curved flight paths that sometimes change according to the position of the player's space ship, as shown in the following screenshot. There are many ways to achieve this in Unity, but a quick and easy solution is to use the freely available add-on, iTween by Bob Berkebile; this can be downloaded and imported directly<a id="id437" class="indexterm"/> from Unity's Asset Store. More information on iTween can be found at <a class="ulink" href="http://itween.pixelplacement.com/index.php">http://itween.pixelplacement.com/index.php</a>.</p><div class="mediaobject"><img src="graphics/0655OT_05_14.jpg" alt="Camera paths – iTween"/><div class="caption"><p>Creating camera motion paths with iTween</p></div></div><p>In addition to the default iTween package, you can also download the freely available extension for iTween, namely, the <a id="id438" class="indexterm"/>Visual iTween Path Editor, which is accessible from <a class="ulink" href="http://pixelplacement.com/2010/12/03/visual-editor-for-itween-motion-paths/">http://pixelplacement.com/2010/12/03/visual-editor-for-itween-motion-paths/</a>.</p><p>After importing both iTween packages, the next step is to start using it to create an object animated along a path. To take the<a id="id439" class="indexterm"/> example of a camera fly-through, drag-and-drop the script <code class="literal">iTweenPath</code> onto a camera object. This script allows you to create an independent and named path that consists of multiple waypoints, as shown here:</p><div class="mediaobject"><img src="graphics/0655OT_05_15.jpg" alt="Camera paths – iTween"/><div class="caption"><p>The iTweenPath script allows you to define a path of waypoints</p></div></div><p>To define multiple waypoints for a path, enter the total number of waypoints to create inside the <span class="strong"><strong>Node Count</strong></span> field and then select each node gizmo in the <span class="strong"><strong>Scene</strong></span> viewport that transforms each into place. Notice the curved path drawn between the points that outline the path for the camera to take:</p><div class="mediaobject"><img src="graphics/0655OT_05_16.jpg" alt="Camera paths – iTween"/><div class="caption"><p>Defining the waypoints for a path</p></div></div><p>Then, to make the camera<a id="id440" class="indexterm"/> follow the path at runtime, add the following code sample 5-13 script to the camera :</p><div class="informalexample"><pre class="programlisting"> using UnityEngine;
 using System.Collections;
 
 public class cam_itween_mover : MonoBehaviour 
 {
    // Use this for initialization
    void Start () 
    {
<span class="strong"><strong>         iTween.MoveTo(gameObject, iTween.Hash("path", iTweenPath.GetPath("Camera Fly") , "time", 4f, "easetype", iTween.EaseType.easeInOutSine));</strong></span>
    }
 }</pre></div><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="tip37"/>Tip</h3><p>More information on iTween and its usage<a id="id441" class="indexterm"/> can be found online at <a class="ulink" href="http://itween.pixelplacement.com/gettingstarted.php">http://itween.pixelplacement.com/gettingstarted.php</a>.</p></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch05lvl1sec59"/>Summary</h1></div></div></div><p>This chapter concentrated on many common tasks expected or needed of cameras. Cameras are essential in Unity and in any game engine, because they represent the perspective from which the scene is rendered to the screen. Most of the camera functionality is commonly taken for granted in Unity, and as a result, much of the flexibility and control that cameras offer us is lost and not discussed. Specifically, here, we first considered gizmo rendering, that is, how to permanently render the camera gizmo in the scene viewport even when the camera is deselected. Second, we saw how to determine which objects are visible to the camera and which are not. This included several kinds of important tests such as frustum presence and occlusion testing. Third, we saw how to create and configure orthographic cameras that render 2D elements without perspective distortion. Fourth, we saw how to edit and enhance a camera render through render textures. This involved overriding a series of camera-critical events and blending renders from other cameras to create a camera cross-fade effect. Fifth, we saw how to create more advanced camera motions, such as camera shake. Finally, you learned about camera paths, that is, the ability for a camera to follow a specified path, whether this path was defined by a series of game object waypoints or was simply an object to follow. Next up, we'll explore the Mono Framework further.</p></div></body></html>