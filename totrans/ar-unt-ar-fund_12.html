<html><head></head><body><div><div><h1 id="_idParaDest-214"><em class="italic"><a id="_idTextAnchor224"/>Chapter 9</em>: Selfies: Making Funny Faces</h1>
			<p>In this chapter, you will learn how to use Unity AR Foundation for face tracking in order to make fun and entertaining face filters. I apologize in advance for showing my handsome face throughout this chapter – it's a necessary evil when working with selfies!</p>
			<p>We'll start with a brief explanation of how face tracking works, and then we will create a new AR scene with face tracking enabled. We will use a couple of 3D head models that track your head pose and to which you can add extra accessories, such as a hat and sunglasses. We are going to build a main menu so that the user can select and change models at runtime. We'll then work with dynamic face meshes and create several materials to easily switch between them. In the last part, we'll look at more advanced features such as eye tracking, face regions (ARCore), and blend shapes (ARKit).</p>
			<p>We will cover the following topics:</p>
			<ul>
				<li>Understanding face tracking</li>
				<li><a id="_idTextAnchor225"/>Configuring a new AR scene for face tracking</li>
				<li>Tracking the face pose with 3D models and accessories</li>
				<li><a id="_idTextAnchor226"/>Controlling the app's main mode and building a main menu</li>
				<li>Making dynamic face meshes with a variety of materials</li>
				<li>Using eye-tracking (ARKit)</li>
				<li>Attaching stickers to face regions (ARCore)</li>
				<li>Tracking expressive face blend shapes (ARKit)</li>
			</ul>
			<p>By the end of this chapter, you'll be familiar with many of the face tracking features in AR Foundation, ARCore, and ARKit. You will also have a working <em class="italic">Face Maker</em> project you can show off to your friends!</p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor227"/>Technical requirements</h1>
			<p>To implement the project in this chapter, you need Unity installed on your development computer and connected with a mobile device that supports augmented reality applications (see <a href="B15145_01_Final_SB_epub.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a>, <em class="italic">Setting Up for AR Development</em>, for instructions). We also assume that you have the <code>ARFramework</code> template and its prerequisites installed (see <a href="B15145_05_Final_SB_epub.xhtml#_idTextAnchor119"><em class="italic">Chapter 5</em></a>, <em class="italic">Using the AR User Framework</em>). The completed project can be found in this book's GitHub repository, available at the following URL: <a href="https://github.com/PacktPublishing/Augmented-Reality-with-Unity-AR-Foundation">https://github.com/PacktPublishing/Augmented-Reality-with-Unity-AR-Foundation</a>.</p>
			<h1 id="_idParaDest-216"><a id="_idTextAnchor228"/>Understanding face tracking</h1>
			<p>Let's <a id="_idIndexMarker726"/>start with some background on face tracking and the technology that makes it work. Face tracking is a kind of Augmented Reality that (usually) uses the front-facing camera on your mobile device. Apps such as Snapchat, Instagram, and Animoji have popularized face filter technology, and it has now become mainstream on mobile devices. It makes for highly entertaining and creative experiences. The technology detects facial features and expressions, and Unity AR Foundation enables you to write applications for attaching 3D objects to specific facial features that are tracked.</p>
			<p>Face tracking begins with a frame of the video from your device's camera. It analyzes the pixels, looking for patterns that represent a face – for example, the bridge of the nose is lighter than the pixels surrounding it, and the eyes are darker than the forehead. Key points and regions are recognized and used to construct a 3D mesh, like a mask, representing the face. Nodes of the mesh are "locked onto" key points in the image, allowing the mesh to follow not just the pose of the face, but detailed changes that correspond to human facial expressions, like a smile or a wink of the eye.</p>
			<p>To learn more about how face tracking works, I encourage you to watch the seminal Vox video (over 3 million views) <em class="italic">How Snapchat's filters work</em>, available at the following URL: <a href="https://www.youtube.com/watch?v=Pc2aJxnmzh0">https://www.youtube.com/watch?v=Pc2aJxnmzh0</a>.</p>
			<p>It's helpful to understand the distinction between face tracking and face identification, and how to track a face with AR Foundation.</p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor229"/>Face tracking versus face identification</h2>
			<p>A <a id="_idIndexMarker727"/>distinction should be made between <em class="italic">face tracking</em> and <em class="italic">face identification</em>. Face tracking, in general, is limited to detecting a human face and tracking its pose (position and rotation), facial features such as the forehead and nose, and changes representing expressions, such as opening your mouth or blinking your eyes. Face identification, on<a id="_idIndexMarker728"/> the other hand, adds recognition of the features that make your face unique and different from other faces. Face recognition<a id="_idIndexMarker729"/> is used as a fingerprint. One example of face recognition technology is for unlocking devices. More advanced (and creepy) face identification is increasingly being used by authoritarian governments and law enforcement to identify strangers in a crowd, using a large database of faces.</p>
			<p>Using Unity AR Foundation, you can access the AR face-tracking capabilities of your device. We are going to examine this next.</p>
			<h2 id="_idParaDest-218"><a id="_idTextAnchor230"/>Tracking a face with AR Foundation</h2>
			<p>As you <a id="_idIndexMarker730"/>now know, a Unity project using AR Foundation and XR Plugins will<a id="_idIndexMarker731"/> have a scene that includes an <strong class="bold">ARSession</strong> and an <strong class="bold">ARSessionOrigin</strong> object. The AR Face Manager component is added to the AR Session Origin to enable face tracking. Like most AR Foundation features, this component wraps the Unity AR subsystems, namely <a id="_idIndexMarker732"/>the XR face subsystem (see <a href="mailto:https://docs.unity3d.com/Packages/com.unity.xr.arsubsystems@4.2/api/UnityEngine.XR.ARSubsystems.XRFaceSubsystem.html">https://docs.unity3d.com/Packages/com.unity.xr.arsubsystems@4.2/api/UnityEngine.XR.ARSubsystems.XRFaceSubsystem.html</a>). This in turn interfaces with the underlying XR plugin, such as ARCore or ARKit.</p>
			<p>The <strong class="bold">AR Face Manager</strong> component references a face prefab provided by you. This prefab will be instantiated and tracked with the detected face. The component also provides a <strong class="bold">Maximum Face Count</strong> parameter, should you want the app to support multiple people in the same camera view (depending on the capabilities of the underlying device). The component is shown in the following screenshot:</p>
			<div><div><img src="img/Figure_9.01_B15145.jpg" alt="Figure 9.1 – The AR Face Manager component on an AR Session Origin object&#13;&#10;" width="450" height="105"/>
				</div>
			</div>
			<p class="figure-caption">Figur<a id="_idTextAnchor231"/>e 9.1 – The AR Face Manager component on an AR Session Origin object</p>
			<p>The face prefab should have an <strong class="bold">AR Face</strong> component on it that represents a face detected by an AR device. It has properties including the face mesh vertices, facet normals, and transforms for the left and right eyes. Like other AR trackables, your scripts can subscribe to changes to know when faces have been added, updated, and removed. The specific <a id="_idIndexMarker733"/>properties available will depend on the capabilities of the <a id="_idIndexMarker734"/>underlying device. See the documentation available at the following URL: <a href="mailto:https://docs.unity3d.com/Packages/com.unity.xr.arfoundation@4.2/api/UnityEngine.XR.ARFoundation.ARFace.html">https://docs.unity3d.com/Packages/com.unity.xr.arfoundation@4.2/api/UnityEngine.XR.ARFoundation.ARFace.html</a>. Also, see the following URL: <a href="mailto:https://docs.unity3d.com/Packages/com.unity.xr.arsubsystems@4.2/api/UnityEngine.XR.ARSubsystems.XRFace.html">https://docs.unity3d.com/Packages/com.unity.xr.arsubsystems@4.2/api/UnityEngine.XR.ARSubsystems.XRFace.html</a>.</p>
			<p>AR Foundation provides an interface for AR face tracking (not identification), using the AR Face Manager component added to your AR Session Origin object. We can now get started building a selfie face filter project.</p>
			<h1 id="_idParaDest-219"><a id="_idTextAnchor232"/>Getting started</h1>
			<p>To begin, we'll create a new scene named <code>FaceMaker</code> using the <code>ARFramework</code> scene template. If you're targeting iOS ARKit, there may be additional setup required, including installing the separate ARKit Face Tracking package. Then we'll add a project title to the UI before moving on to adding face tracking to the scene. </p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor233"/>Creating a new scene using the ARFramework template</h2>
			<p>Create a new scene in your <a id="_idIndexMarker735"/>Unity AR-ready project using the<a id="_idIndexMarker736"/> following steps:</p>
			<ol>
				<li value="1">Select <strong class="bold">File</strong> | <strong class="bold">New Scene</strong>.</li>
				<li>In the <strong class="bold">New Scene</strong> dialog box, select the <strong class="bold">ARFramework</strong> template.</li>
				<li>Click <strong class="bold">Create</strong>.</li>
				<li>Select <code>Scenes/</code> folder in your project <code>Assets</code> folder, give it the name <code>FaceMaker</code>, and click <strong class="bold">Save</strong>. </li>
			</ol>
			<p>The new AR scene already has the following setup from the template:</p>
			<ul>
				<li><strong class="bold">AR Session</strong> game object with an AR Session component.</li>
				<li><strong class="bold">An AR Session Origin</strong> rig with an AR Session Origin component, among others, and a child main camera. We will replace its AR Plane Manager component with an AR Face Manager one.</li>
				<li><strong class="bold">UI Canvas</strong> is a screen space canvas with the child panels <strong class="bold">Startup UI</strong>, <strong class="bold">Scan UI</strong>, <strong class="bold">Main UI</strong>, and <strong class="bold">NonAR UI</strong> that we built for the <strong class="bold">ARFramework</strong>. It has the UI Controller component script that we wrote. We'll update this with the project-specific UI.</li>
				<li><strong class="bold">Interaction Controller</strong> is a game object we built for the ARFramework, with an interaction<a id="_idIndexMarker737"/> controller component script <a id="_idIndexMarker738"/>we wrote that helps the app switch between interaction modes, including Startup, Scan, Main, and NonAR modes. It also has a <strong class="bold">Player Input</strong> component configured with the <strong class="bold">AR Input Actions</strong> asset we previously created. We are going to customize the main mode for our face tracking app.</li>
				<li><strong class="bold">OnboardingUX</strong> is a prefab from the AR Foundation Demos project that provides AR session status messages and animated onboarding graphics prompts.</li>
			</ul>
			<p>Let's start by setting the app title now as follows:</p>
			<ol>
				<li value="1">In the <strong class="bold">Hierarchy</strong>, unfold the <strong class="bold">UI Canvas</strong> object, and unfold its child <strong class="bold">App Title Panel</strong>.</li>
				<li>Select the <strong class="bold">Title Text</strong> object.</li>
				<li>In its <code>Face Maker</code>.</li>
			</ol>
			<p>If you are targeting ARKit on iOS, there may be additional project setup required.</p>
			<h2 id="_idParaDest-221"><a id="_idTextAnchor234"/>Setting up iOS ARKit for face tracking</h2>
			<p>To develop <a id="_idIndexMarker739"/>and build a project using face tracking with ARKit<a id="_idIndexMarker740"/> for an iOS device, you also need to install the ARKit Face Tracking package via the package manager. Perform the following steps:</p>
			<ol>
				<li value="1">Open the package manager using <strong class="bold">Window</strong> | <strong class="bold">Package Manager</strong>.</li>
				<li>In the <strong class="bold">Packages</strong> filter selection at the top left, choose <strong class="bold">Unity Registry</strong>.</li>
				<li>Use the search field at the top right to search for <code>ar</code>, and select the <strong class="bold">ARKit Face Tracking</strong> package from the packages list.</li>
				<li>Click <strong class="bold">Install</strong> at the bottom right of the window.</li>
			</ol>
			<p>Then, configure ARKit XR Plugin for face tracking, as follows:</p>
			<ol>
				<li value="1">Open the <strong class="bold">Project Settings</strong> window, using <strong class="bold">Edit</strong> | <strong class="bold">Project Settings</strong>.</li>
				<li>On the left-side tabs menu, select <strong class="bold">XR Plug-in Management</strong> | <strong class="bold">ARKit</strong>.</li>
				<li>Check the <strong class="bold">Face Tracking</strong> checkbox.</li>
			</ol>
			<p>Next, we will gather some assets that we'll be using in this chapter. Some of these are also provided in this book's GitHub repository. Others are third-party assets that you must download and import separately.</p>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor235"/>Importing assets used in this project</h2>
			<p>First, you should<a id="_idIndexMarker741"/> already have the <em class="italic">AR Foundation Samples</em> assets in your project (the ones that we imported back in <a href="B15145_01_Final_SB_epub.xhtml#_idTextAnchor013"><em class="italic">Chapter 1</em></a>, <em class="italic">Setting Up for AR Development</em>). If you followed along, these are in the <code>Assets/ARF-samples/</code> folder. It contains some useful example assets that we'll use and reference in this chapter that can give you additional insight into the capabilities of AR Foundation face tracking, as well as how to use those capabilities.</p>
			<p>We are also going to use the assets from the <em class="italic">AR Face Assets</em> package from Unity (available in the Asset Store). These assets are also used in the Unity Learn tutorial, <em class="italic">AR Face Tracking with AR Foundation</em> (<a href="https://learn.unity.com/project/ar-face-tracking-with-ar-foundations">https://learn.unity.com/project/ar-face-tracking-with-ar-foundations</a>). To import the package, follow these steps:</p>
			<ol>
				<li value="1">Using your internet browser, go to the following URL: <a href="https://assetstore.unity.com/packages/essentials/asset-packs/ar-face-assets-184187">https://assetstore.unity.com/packages/essentials/asset-packs/ar-face-assets-184187</a>.</li>
				<li>Click <strong class="bold">Add to My Assets</strong> (if necessary), then click <strong class="bold">Open In Unity</strong>.</li>
				<li>In Unity, this<a id="_idIndexMarker742"/> should open the <strong class="bold">Package Manager</strong> window (or select <strong class="bold">Window</strong> | <strong class="bold">Package Manager</strong>). </li>
				<li>Select <strong class="bold">My Assets</strong> from the <strong class="bold">Packages</strong> filter at the top left. </li>
				<li>Find the <strong class="bold">AR Face Assets</strong> package and click <strong class="bold">Download</strong> and/or <strong class="bold">Import</strong> (bottom right). In the <strong class="bold">Import Unity Package</strong> window, click the <strong class="bold">Import</strong> button.</li>
				<li>Convert the imported materials to the Universal Render Pipeline by selecting <strong class="bold">Edit</strong> | <strong class="bold">Render Pipeline</strong> | <strong class="bold">Universal Render Pipeline</strong> | <strong class="bold">Upgrade Project Materials to URP Materials</strong>.</li>
			</ol>
			<p><em class="italic">Face accessories 3D models</em>: I have found some free 3D models to use in this project. You can also use them or substitute your own. If you wish to use them, they are included in the following GitHub repositories:</p>
			<ul>
				<li>Sunglasses: <a href="https://free3d.com/3d-model/sunglasses-v1--803862.html">https://free3d.com/3d-model/sunglasses-v1--803862.html</a>. OBJ format (submitted by <em class="italic">printable_models</em>, <a href="https://free3d.com/user/printable_models">https://free3d.com/user/printable_models</a>)</li>
				<li>Top hat: <a href="https://free3d.com/3d-model/cartola-278168.html.">https://free3d.com/3d-model/cartola-278168.html.</a> FBX format (submitted by <em class="italic">zotgames</em>, <a href="https://free3d.com/user/zotgames">https://free3d.com/user/zotgames</a>)</li>
			</ul>
			<p>If you're downloading these yourself, unzip and drag the files into your project's <code>Assets/</code> folder. We'll address the import settings and steps later in the chapter.</p>
			<p><em class="italic">Face stickers 2D sprite images</em>: For the ARCore-based face region stickers, I found some free clipart at Creative Commons. You can use them or substitute your own. If you wish to use them, they are included in the following GitHub repositories:</p>
			<ul>
				<li>Eyebrows: <a href="https://clipground.com/images/angry-eyebrows-clipart-11.png">https://clipground.com/images/angry-eyebrows-clipart-11.png</a> </li>
				<li>Mustache: <a href="https://clipground.com/images/monocle-clipart-12.jpg">https://clipground.com/images/monocle-clipart-12.jpg</a></li>
				<li>Licking lips: <a href="https://clipground.com/images/licking-lips-clipart-12.jpg">https://clipground.com/images/licking-lips-clipart-12.jpg</a></li>
			</ul>
			<p>I used Photoshop to <a id="_idIndexMarker743"/>adapt each of these images with a transparent background, square-shaped canvas, and scaled to 512x512 pixels. These are imported as <strong class="bold">Texture Type: Sprite (2D and UI)</strong>.</p>
			<p>For all the aforementioned assets, I also created button icons that we'll use in the UI. These are also available on the GitHub repository in the <code>icons/</code> folder and are imported as <strong class="bold">Texture Type: Sprite (2D and UI)</strong>.</p>
			<p>We now have our basic scene created, as well as prerequisite assets imported into the project. We used the <code>ARFramework</code> scene template created for this book when creating the new scene, and updated the UI title text for this project. If you're working on iOS, we also installed extra required packages into the project. Then, we imported other graphic assets we're going to use, including the demo AR Face Assets pack provided by Unity. Let's now configure the scene for face tracking.</p>
			<h1 id="_idParaDest-223"><a id="_idTextAnchor236"/>Configuring a new AR scene for face tracking</h1>
			<p>There are a few<a id="_idIndexMarker744"/> simple steps required to configure an AR <a id="_idIndexMarker745"/>Foundation-based scene for face tracking. Since we're going to do selfies, we'll set up the AR camera to use input from the front-facing camera. Then we'll add an AR Face Manager component to the AR Session Origin. If you want to use the Unity Onboarding UX animated graphic to prompt the user, you can adapt the <code>ScanMode</code> script for that.</p>
			<p>Let's get started!</p>
			<h2 id="_idParaDest-224"><a id="_idTextAnchor237"/>Setting the AR camera for selfies</h2>
			<p>Use the<a id="_idIndexMarker746"/> following steps <a id="_idIndexMarker747"/>to set up the AR camera for selfies:</p>
			<ol>
				<li value="1">In the <strong class="bold">Hierarchy</strong>, unfold the <strong class="bold">AR Session Origin</strong> game object and select its child <strong class="bold">Main Camera</strong>.</li>
				<li>In the <strong class="bold">Inspector</strong>, set <strong class="bold">AR Camera Manager</strong> | <strong class="bold">Facing Direction</strong> to <strong class="bold">User</strong>.</li>
				<li>We also need to set the AR Session tracking mode for rotation only. Select the <strong class="bold">AR Session</strong> game <a id="_idIndexMarker748"/>object<a id="_idIndexMarker749"/> in the <strong class="bold">Hierarchy</strong>.</li>
				<li>In the <strong class="bold">Inspector</strong>, set the <strong class="bold">AR Session</strong> | <strong class="bold">Tracking Mode</strong> to <strong class="bold">Rotation Only</strong>.</li>
			</ol>
			<p>Next, we'll add the AR Face Manager component to the AR Session Origin.</p>
			<h2 id="_idParaDest-225"><a id="_idTextAnchor238"/>Adding an AR Face Manager component</h2>
			<p>Using the<a id="_idIndexMarker750"/> scene provided by the <code>ARFramework</code> template, we will replace the given AR trackable components with an <strong class="bold">AR Face Manager</strong> one. For the <strong class="bold">Face Prefab</strong>, we'll start with the <strong class="bold">TriAxes</strong> prefab from the AR Samples project. If you examine this prefab, you'll discover it has an <strong class="bold">AR Face</strong> component, so it can be used as a trackable.</p>
			<p>To configure the <strong class="bold">AR Session</strong> to track faces, follow these steps:</p>
			<ol>
				<li value="1">In the <strong class="bold">Hierarchy</strong> window, select the <strong class="bold">AR Session Origin</strong> game object.</li>
				<li>In the <strong class="bold">Inspector</strong> window, use the <em class="italic">three-dot context menu</em> (or <em class="italic">right-click</em>) on the <strong class="bold">AR Plane Manager</strong> component, and select <strong class="bold">Remove Component</strong>.</li>
				<li>Use the <code>AR</code>, and add an <strong class="bold">AR Face Manager</strong> component.</li>
				<li>In your <code>Assets/ARF-samples/Prefabs/</code> folder), and drag it into the <strong class="bold">Inspector</strong>, dropping it onto the <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong> slot.</li>
				<li>Save the scene using <strong class="bold">File</strong> | <strong class="bold">Save</strong>.</li>
			</ol>
			<p>The scene is now basically set up for face tracking. <code>ARFamework</code> includes a scan mode that prompts the user to find a trackable object with their camera. We can now configure that for face tracking.</p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor239"/>Prompting the user to find a face, or not</h2>
			<p>Optionally, you can<a id="_idIndexMarker751"/> have your app prompt the user to scan for their face. This is less necessary when using the selfie camera (with <strong class="bold">Facing Direction</strong> set to <strong class="bold">User</strong>) because when you're holding your phone and looking at the screen, the camera is looking right back at you! But if your app were using the world-facing camera instead, it might be necessary to use an instructional prompt to tell the user to find a face.</p>
			<p>To skip the scan mode and its instructional prompt, tell the startup mode to proceed directly to the main mode, using the following steps:</p>
			<ol>
				<li value="1">In the <strong class="bold">Hierarchy</strong>, under the <strong class="bold">Interaction Controller</strong> game object, select the <strong class="bold">Startup Mode</strong> object.</li>
				<li>In the <code>Main</code> into the <strong class="bold">Next Mode</strong> property.</li>
			</ol>
			<p>Otherwise, if you want to use scan mode, you'll need to write a <code>FaceScanMode</code> script as follows:</p>
			<ol>
				<li value="1">In your <code>Scripts/</code> folder, <em class="italic">right-click</em> and select <code>FaceScanMode</code>.</li>
				<li>Open the script for editing and replace its contents as follows:<pre>using UnityEngine;
using UnityEngine.XR.ARFoundation;
public class FaceScanMode : MonoBehaviour
{
    [SerializeField] ARFaceManager faceManager;
    private void OnEnable()
    {
        UIController.ShowUI("Scan");
    }
    void Update()
    {
        if (faceManager.trackables.count &gt; 0)
        {
            InteractionController.EnableMode("Main");
        }
    }
}</pre><p>The script shows the <code>Update</code>, waits until a face is being tracked before transitioning the app to the main mode.</p></li>
				<li>In Unity, in <a id="_idIndexMarker752"/>the <strong class="bold">Hierarchy</strong> window, select the <strong class="bold">Scan Mode</strong> object (under <strong class="bold">Interaction Controller</strong>).</li>
				<li>Remove the old <strong class="bold">Scan Mode</strong> component using the three-dot context menu and then choose <strong class="bold">Remove Component</strong>. </li>
				<li>Drag the new <code>FaceScanMode</code> script onto the <strong class="bold">Scan Mode</strong> game object, adding it as a component. </li>
				<li>Drag the <strong class="bold">AR Session Origin</strong> game object from the <strong class="bold">Hierarchy</strong> onto the <strong class="bold">Face Scan Mode</strong> | <strong class="bold">Face Manager</strong> slot.</li>
				<li>In the <strong class="bold">Hierarchy</strong>, navigate and select <strong class="bold">UI Canvas</strong> | <strong class="bold">Scan UI</strong> | <strong class="bold">Animated Prompt</strong>.</li>
				<li>In the <strong class="bold">Inspector</strong>, set <a id="_idIndexMarker753"/>the <strong class="bold">Instruction</strong> property to <strong class="bold">Find A Face</strong>.</li>
			</ol>
			<p>With this latter setup, the app starts in startup mode. After the AR Session is running, it goes to scan mode, prompting the user to find a face. Once a face is detected, the app proceeds to main mode (as yet, this does nothing). You also have the option to skip the scan mode prompt altogether by telling the startup mode to go straight to the main mode.</p>
			<p>Let's make sure everything works so far. You're now ready to try to run the scene.</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor240"/>Build and run</h2>
			<p>Let's do a <strong class="bold">Build And Run</strong> on<a id="_idIndexMarker754"/> your device to ensure the project is set up correctly. Use the following steps:</p>
			<ol>
				<li value="1">Save your work using <strong class="bold">File</strong> | <strong class="bold">Save</strong>.</li>
				<li>Select <strong class="bold">File</strong> | <strong class="bold">Build Settings</strong> to open the <strong class="bold">Build Settings</strong> window.</li>
				<li>Click <code>FaceMaker</code> scene to <strong class="bold">Scenes In Build</strong>, and ensure it is the only scene in the list with a checkmark.</li>
				<li>Ensure your target device is plugged into a USB port and is ready.</li>
				<li>Click <strong class="bold">Build And Run</strong> to build the project.</li>
			</ol>
			<p>In the following screen capture, you can see the face pose is visualized using the <strong class="bold">TriAxes</strong> prefab. I have tilted my head to the side and back a little to make the three axes more evident.</p>
			<div><div><img src="img/Figure_9.02_B15145.jpg" alt="Figure 9.2 – Tracking the face pose, visualized with the TriAxes prefab&#13;&#10;" width="505" height="1013"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.2 – Tracking the face pose, visualized with the TriAxes prefab</p>
			<p>Note the direction of<a id="_idIndexMarker755"/> each of the axes. The axes are colored red, green, and blue, corresponding to X, Y, and Z respectively. The positive Z direction is in the direction that the device camera is facing, and thus, pointing towards my back.</p>
			<p>Now that we have face tracking running, let's substitute this <strong class="bold">TriAxes</strong> prefab with something more interesting – a whole 3D head model.</p>
			<h1 id="_idParaDest-228"><a id="_idTextAnchor241"/>Tracking the face pose with 3D heads</h1>
			<p>The AR Face Assets<a id="_idIndexMarker756"/> package from Unity that we imported at the <a id="_idIndexMarker757"/>top of this chapter contains a couple of 3D head models we can use in our project. We'll create prefabs of each model and try them separately in the AR Face Manager <strong class="bold">Face Prefab</strong> property. In the next section, we'll create a menu so that the user can pick which head to view at runtime.</p>
			<h2 id="_idParaDest-229"><a id="_idTextAnchor242"/>Making a Mr. Plastic Head prefab</h2>
			<p>The first head prefab<a id="_idIndexMarker758"/> will use the Plasticscene Head assets given in the Unity AR Face Assets package, and found in the <code>Assets/AR face Assets/3D Head/Plasticene Head/</code> folder. This folder contains an FBX model named <code>Plasto_Head</code> and a material named <code>PlasiceneHead</code> (the typo is theirs). The model will require some transform adjustments before it can be used as a face prefab. To create a prefab for this model, use the following steps:</p>
			<ol>
				<li value="1">In the <code>Prefabs/</code> folder (create one first if necessary) and choose <code>MrPlasticHead</code>.</li>
				<li>Click <strong class="bold">Open Prefab</strong> to begin editing.</li>
				<li>With the root object selected, in the <strong class="bold">Inspector</strong>, click <strong class="bold">Add Component</strong>. Then, search and choose <strong class="bold">AR Face</strong> to add an <strong class="bold">AR Face</strong> component.</li>
				<li>From the <code>Plastic_Head</code> model to the <strong class="bold">Hierarchy</strong> and drop it as a child of <strong class="bold">MrPlasticHead</strong>.</li>
				<li>Select the <code>180</code>, so it's facing the camera.</li>
				<li>Set <code>0.6, 0.6, 0.6</code>). Then set <code>-0.2</code>. I selected these transform settings by trial and error and using a measuring cube (see the inset <em class="italic">Tip</em>). </li>
				<li>If the default material (converted to URP) appears too dark, select the child <strong class="bold">Plaso_Head/Plasto_Head</strong> object, and in the <strong class="bold">Inspector</strong>, under the <strong class="bold">Plasicene Head</strong> material, set the <strong class="bold">Base Map</strong> color to white (from middle gray).</li>
				<li>Save the prefab and exit back to the scene <code>0, 0, 0</code>), <code>0, 0, 0</code>), and <code>0.125, 0.125, 0.125</code>). This can help you decide the transform parameters of other imported models you are using.</p></li>
			</ol>
			<p>Let's see how this looks. Add<a id="_idIndexMarker759"/> the prefab to the <strong class="bold">AR Face Manager</strong> and build the project as follows:</p>
			<ol>
				<li value="1">In the <strong class="bold">Hierarchy</strong> window, select the <strong class="bold">AR Session Origin</strong> game object.</li>
				<li>From the <strong class="bold">Project</strong> window, drag the <strong class="bold">MrPlasticHead</strong> prefab into the <strong class="bold">Inspector</strong>, dropping it onto <strong class="bold">AR Face Manager</strong> | the <strong class="bold">Face Prefab</strong> slot.</li>
				<li>Save the scene using <strong class="bold">File</strong> | <strong class="bold">Save</strong>.</li>
				<li>Build the project using <code>PlasticeneHead</code> material uses three textures for the <strong class="bold">Base</strong> (albedo), <strong class="bold">Normal</strong>, and <strong class="bold">Occlusion</strong> maps. The <strong class="bold">Base</strong> texture provides the albedo coloring as if the surface of the mesh were painted with these pixels. The Normal map (also known as the Bump map or Height map) lets the shader alter the mathematical surface normal vector in more detail than given by the mesh geometry itself, simulating surface textures that are especially noticeable with lighting. Finally, the <strong class="bold">Occlusion</strong> map provides additional realism by darkening deeper crevasses in the surface texture, creating higher contrast as occurs in real-life materials. For a more detailed explanation, starting with <strong class="bold">Normal</strong> maps, see the following URL: <a href="https://docs.unity3d.com/Manual/StandardShaderMaterialParameterNormalMap.html">https://docs.unity3d.com/Manual/StandardShaderMaterialParameterNormalMap.html</a>.</p></li>
			</ol>
			<p>A screen capture of me with a Mr. Plastic Head head is shown below, together with the Mr. Facet Head<a id="_idIndexMarker760"/> model that we'll use next:</p>
			<div><div><img src="img/Figure_9.03_B15145.jpg" alt="Figure 9.3 – Screen capture of myself with MrPlasticHead (right) and MrFacetHead (left)&#13;&#10;" width="899" height="779"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – Screen capture of myself with MrPlasticHead (right) and MrFacetHead (left)</p>
			<p>Let's make the <strong class="bold">MrFacetHead</strong> prefab next.</p>
			<h2 id="_idParaDest-230"><a id="_idTextAnchor243"/>Making a Mr. Facet Head prefab</h2>
			<p>There is a second model <a id="_idIndexMarker761"/>provided in the AR Face Assets package, Faceted Head, found in the <code>Assets/AR face Assets/3D Head/Faceted Head/</code> folder. This folder contains an FBX model named <code>FacetedHead</code>, and a material also named <code>FacetedHead</code>. As before, the model will require some transform adjustments to be used as a face prefab. To create a prefab for this model, use the following steps:</p>
			<ol>
				<li value="1">In the <code>Prefabs/</code> folder and choose <code>MrFacetHead</code>.</li>
				<li>Click <strong class="bold">Open Prefab</strong> to begin editing.</li>
				<li>With the root object selected, in the <strong class="bold">Inspector</strong>, click <strong class="bold">Add Component</strong>. Then, search and choose <strong class="bold">AR Face</strong> to add an <strong class="bold">AR Face</strong> component.</li>
				<li>From the <code>FacetedHead</code> model to the <strong class="bold">Hierarchy</strong> and drop it as a child of <strong class="bold">MrFacetHead</strong>.</li>
				<li>With the <code>-90</code> so that it's facing the camera. Set <code>1.1, 1.1, 1.1</code>).</li>
				<li>If the default material (converted to URP) appears too dark, select the <strong class="bold">FacetedHead</strong> object, and in its <strong class="bold">Inspector</strong> under the <strong class="bold">FacetedHead</strong> material, set the <strong class="bold">Base Map</strong> color to white.</li>
				<li>Save the prefab, and exit back to the scene <strong class="bold">Hierarchy</strong> window, using the <strong class="bold">&lt;</strong> button at the top left of the window.</li>
				<li>In the <strong class="bold">Hierarchy</strong> window, select<a id="_idIndexMarker762"/> the <strong class="bold">AR Session Origin</strong> game object.</li>
				<li>From the <strong class="bold">Project</strong> window, drag the <strong class="bold">MrFacetHead</strong> prefab into the <strong class="bold">Inspector</strong>, dropping it onto the <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong> slot.</li>
				<li>Save the scene using <strong class="bold">File</strong> | <strong class="bold">Save</strong>.</li>
				<li>Build the project using <strong class="bold">File</strong> | <strong class="bold">Build And Run</strong>.</li>
			</ol>
			<p>When it runs, you now have a Mr. Faceted Head head, as shown in the preceding figure (yes, those are my real eyes peering through the mask).</p>
			<p>In this section, we created two prefabs, <strong class="bold">MrPlasticHead</strong> and <strong class="bold">MrFacetHead</strong>, using assets from the Unity <em class="italic">AR Face Assets</em> package that we imported earlier. Each of these has an AR Foundation <strong class="bold">AR Face</strong> component on its root GameObject and different imported models for the two heads. We tried using one of these in our app by adding it to the <strong class="bold">AR Face Manager</strong> component and running the scene.</p>
			<p>Wouldn't it be nice to let the user choose a head at runtime, rather than manually setting the AR Face Manager and rebuilding the project? Next, let's create a main menu, and a changeable face prefab we can control from the menu buttons.</p>
			<h1 id="_idParaDest-231"><a id="_idTextAnchor244"/>Building the Main mode and menu </h1>
			<p>In this section, we will set up the <a id="_idIndexMarker763"/>main mode app to handle user interactions, including face filter selections from a main menu. To do this, we first need to create a changeable face prefab that can be told which facial features to display. We'll write a <code>FaceMainMode</code> script that displays the main UI panel and passes change requests from the user to the face object. Then, we'll make a main menu with a set of horizontally scrolling buttons that the user can tap to change face filters. </p>
			<h2 id="_idParaDest-232"><a id="_idTextAnchor245"/>Creating a changeable face prefab</h2>
			<p>To create a face prefab<a id="_idIndexMarker764"/> that we can use for dynamically changing filters during runtime, we'll start with an empty game object with an AR Face component, and add a script for setting the contained prefab object. Use the following steps:</p>
			<ol>
				<li value="1">In the <code>Prefabs/</code> folder and choose <code>Changeable Face Prefab</code>.</li>
				<li>Click <strong class="bold">Open Prefab</strong> to begin editing.</li>
				<li>With the root object selected, in the <strong class="bold">Inspector</strong>, click <strong class="bold">Add Component</strong>. Search for and choose <strong class="bold">AR Face</strong> to add an <strong class="bold">AR Face</strong> component.</li>
				<li>In your <code>Scripts/</code> folder, <em class="italic">right-click</em> and select <code>ChangeableFace</code>. </li>
				<li>Open the script for editing and replace its contents as follows:<pre>using System.Collections.Generic;
using UnityEngine;
using UnityEngine.XR.ARFoundation;
public class ChangeableFace : MonoBehaviour
{
    GameObject currentPosePrefab;
    GameObject poseObj;
    public void SetPosePrefab(GameObject prefab)
    {
        if (prefab == currentPosePrefab)
            return;
        if (poseObj != null) 
            Destroy(poseObj);
       currentPosePrefab = prefab;
       if (prefab != null)
            poseObj = Instantiate(prefab, transform,                false);
    }
}</pre><p>The script exposes a <a id="_idIndexMarker765"/>public <code>SetPosePrefab</code> function that instantiates the <code>prefab</code> argument as a child of the current object. If the requested prefab is already instantiated, the request is ignored. If there was a previously instantiated object, it is first destroyed. The function can be called with a null value for the <code>prefab</code> argument that will only clear the existing instantiated object.</p></li>
				<li>Save the script and, back in Unity, drag the <code>ChangeableFace</code> script onto the <strong class="bold">Changeable Face Prefab</strong> root object.</li>
				<li>Save the prefab and <a id="_idIndexMarker766"/>exit back to the scene hierarchy using the <strong class="bold">&lt;</strong> button at the top left of the window.</li>
				<li>In the <strong class="bold">Hierarchy</strong>, select the <strong class="bold">AR Session Origin</strong> object. From the <strong class="bold">Project</strong> window, drag the <strong class="bold">Changeable Face Prefab</strong> into the <strong class="bold">Inspector</strong>, dropping it onto the <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong> slot.</li>
			</ol>
			<p>We now have a <code>ChangeableFace</code> script. We are planning to call its <code>SetPosePrefab</code> function from the main mode in response to a user button click. We should set up the main mode now.</p>
			<h2 id="_idParaDest-233"><a id="_idTextAnchor246"/>Writing a main mode controller script</h2>
			<p>In our <a id="_idIndexMarker767"/>ARFramework template, interaction modes are represented with game objects under the interaction controller and are activated when a specific mode is enabled. The default <code>MainMode</code> script from the template is simply a placeholder. We should replace it now with a custom script for this project. To do so, follow these steps:</p>
			<ol>
				<li value="1">In the <code>FaceMainMode</code>.</li>
				<li>In the <strong class="bold">Hierarchy</strong>, select the <strong class="bold">Main Mode</strong> game object (under <strong class="bold">Interaction Controller</strong>).</li>
				<li>In the <strong class="bold">Inspector</strong>, remove the default <strong class="bold">Main Mode</strong> component using the three-dot menu, then click <strong class="bold">Remove Component</strong>.</li>
				<li>Drag the new <code>FaceMainMode</code> script onto the <strong class="bold">Main Mode</strong> object, adding it as a component.</li>
				<li>Open the <code>FaceMainMode</code> script for editing, and start it as follows:<pre>using UnityEngine;
using UnityEngine.XR.ARFoundation;
public class FaceMainMode : MonoBehaviour
{
    [SerializeField] ARFaceManager faceManager;
    void OnEnable()
    {
        UIController.ShowUI("Main");
    }
    public void ChangePosePrefab(GameObject prefab)
    {
        foreach (ARFace face in faceManager.trackables)
        {
            ChangeableFace changeable =                 face.GetComponent&lt;ChangeableFace&gt;();
            if (changeable != null)
            {
                changeable.SetPosePrefab(prefab);
            }
        }
    }
}</pre></li>
			</ol>
			<p>When the <a id="_idIndexMarker768"/>main mode is enabled, it shows the main UI panel. This will contain the main menu buttons. When a menu button is clicked and it calls <code>ChangePosePrefab</code>, that in turn will call <code>SetPosePrefab</code> for any trackable faces in the scene.</p>
			<p>Let's create the menu UI next.</p>
			<h2 id="_idParaDest-234"><a id="_idTextAnchor247"/>Creating scrollable main menu buttons</h2>
			<p>In our user framework, a <a id="_idIndexMarker769"/>mode's UI panel will be enabled by the corresponding interaction mode. We'll now add a horizontally-scrolling main menu to the main UI panel with buttons that can change the tracked face. Use the following steps:</p>
			<ol>
				<li value="1">In the <code>MainMenu Panel</code>.</li>
				<li>In the <strong class="bold">Inspector</strong>, use the <strong class="bold">Anchor Presets</strong> option (at the upper left of <strong class="bold">Rect Transform</strong>) to set <strong class="bold">Bottom-Stretch</strong>, then use <em class="italic">Shift + Alt + left-click Bottom-Stretch</em>.</li>
				<li>Set <code>150</code>.</li>
				<li>Remove its <strong class="bold">Image</strong> component with the three-dot menu, then <strong class="bold">Remove Component</strong> (we won't have a background on this menu).</li>
				<li>In the <strong class="bold">Hierarchy</strong>, <em class="italic">right-click</em> the <strong class="bold">MainMenu Panel</strong>, and select <strong class="bold">UI</strong> | <strong class="bold">Scroll View</strong>.</li>
				<li>Use <strong class="bold">Anchor Presets</strong> to click the <strong class="bold">Stretch-Stretch</strong> option, and then use <em class="italic">Shift + Alt + left-click Stretch-Stretch</em>.</li>
				<li>Remove the <strong class="bold">Image</strong> component.</li>
				<li>In the <strong class="bold">Scroll Rect</strong> component, uncheck <strong class="bold">Vertical</strong>.</li>
				<li>Delete the content of the <strong class="bold">Horizontal Scrollbar</strong> and <strong class="bold">Vertical Scrollbar</strong> fields, and disable (or delete) the <strong class="bold">Scrollbar Horizontal</strong> and <strong class="bold">Scrollbar Vertical</strong> game objects in the hierarchy.</li>
				<li>In the <strong class="bold">Hierarchy</strong>, unfold the child <strong class="bold">Viewport</strong> game object, and select the child <strong class="bold">Content</strong> game object.</li>
				<li>Click <strong class="bold">Add Component</strong>, then search for and select <strong class="bold">Horizontal Layout Group</strong>. </li>
				<li>Uncheck all of its checkboxes, including <strong class="bold">Child Force Expand</strong> | <strong class="bold">Width</strong> and <strong class="bold">Height</strong>. </li>
				<li>Set <code>5</code>.</li>
				<li>Click <strong class="bold">Add Component</strong>, then search for and select <strong class="bold">Content Size Fitter</strong>. </li>
				<li>Set <strong class="bold">Horizontal Fit</strong> to <strong class="bold">Preferred Size</strong>.</li>
			</ol>
			<p>We now have a <strong class="bold">MainMenu Panel</strong> under <strong class="bold">Main UI</strong>. It contains a horizontally-scrolling content area, as shown in the following<a id="_idIndexMarker770"/> screenshot of the UI hierarchy with the <strong class="bold">Content</strong> object selected:</p>
			<div><div><img src="img/Figure_9.04_B15145.jpg" alt="Figure 9.4 – Main UI hierarchy with content inspector shown&#13;&#10;" width="904" height="648"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – Main UI hierarchy with content inspector shown</p>
			<p>We can now add buttons to the <strong class="bold">Content</strong> container. For now, we'll create just two buttons, for the<a id="_idIndexMarker771"/> two heads. Later, we'll expand it with more options. Each button will display an image icon (if you don't have an icon for your own content, you can use text labels):</p>
			<ol>
				<li value="1">In the <code>PlasticHead Button</code>.</li>
				<li>Set its <code>150, 150</code>).</li>
				<li>Remove its child <strong class="bold">Text</strong> object (unless you don't have an icon image for this button).</li>
				<li>From the <code>plastichead icon</code> image asset (perhaps found in your <code>/icons</code> folder) onto the <strong class="bold">Image</strong> | <strong class="bold">Source Image</strong> slot.</li>
				<li>In the <strong class="bold">Inspector</strong>, click the <strong class="bold">+</strong> button at the bottom right of the <strong class="bold">On Click</strong> area of the <strong class="bold">Button</strong> component.</li>
				<li>From the <strong class="bold">Hierarchy</strong>, drag the <strong class="bold">Main Mode</strong> object (under <strong class="bold">Interaction Controller</strong>), into the <strong class="bold">Inspector</strong>, and drop it onto the <strong class="bold">On Click Object</strong> slot.</li>
				<li>In the <strong class="bold">Function</strong> selection list, choose <strong class="bold">FaceMainMode</strong> | <strong class="bold">ChangePosePrefab</strong>.</li>
				<li>From the <code>Prefabs/</code> folder) onto the empty parameter slot, as shown in the following screenshot:</li>
			</ol>
			<div><div><img src="img/Figure_9.05_B15145.jpg" alt="Figure 9.5 – The PlasticHead button's On Click action will pass the MrPlasticHead prefab to the FaceMainMode.ChangePosePrefab function&#13;&#10;" width="534" height="306"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – The PlasticHead button's On Click action will pass the MrPlasticHead prefab to the FaceMainMode.ChangePosePrefab function</p>
			<p class="callout-heading">Tip: Creating button icons</p>
			<p class="callout">To create many of the button icons used in this chapter, I sometimes start by making a screen capture of the actual game object. Then, in Photoshop, I isolate the shape by selecting its edges (using the Magic Wand tool) and make a cutout with a transparent background. I then crop the image on a square-shaped canvas and resize it to 256x256, before exporting it as a PNG file. Then, in Unity, I import the image and, in <strong class="bold">Import Settings</strong>, set <strong class="bold">Texture Type</strong> to <strong class="bold">Sprite (2D or UI)</strong>, and click <strong class="bold">Apply</strong>. The asset can now be used as a UI sprite in an image component like those on button objects. </p>
			<p>We now have one<a id="_idIndexMarker772"/> button in the <strong class="bold">Main Menu</strong>. This is for selecting the MrPlasticHead model. Let's make a second button, for the MrFacetHead prefab. To do that, we can duplicate and modify the first button, as follows:</p>
			<ol>
				<li value="1">In the <strong class="bold">Hierarchy</strong>, select the <strong class="bold">PlasticHead Button</strong> game object.</li>
				<li>From the main menu, select <code>FacetHead Button</code>.</li>
				<li>From the <code>facethead icon</code> asset onto the <strong class="bold">Image</strong> | <strong class="bold">Source Image</strong> slot.</li>
				<li>From the <code>Prefabs/</code> folder) onto the <a id="_idIndexMarker773"/>parameter slot (replacing the <strong class="bold">MrPlasticHead</strong> prefab already there).</li>
			</ol>
			<p>The <strong class="bold">Main Menu</strong> now has two buttons. When the app runs, clicking one will show <strong class="bold">MrPlasticHead</strong> on my face. Clicking the other will show <strong class="bold">MrFacetHead</strong>. It would also be nice to offer a reset button that clears all the face filters.</p>
			<h2 id="_idParaDest-235"><a id="_idTextAnchor248"/>Adding a reset face button</h2>
			<p>We can also add a reset button<a id="_idIndexMarker774"/> that sets the current pose object to null. Let's do this as a separate function in the <code>FaceMainMode</code> script. Use the following steps:</p>
			<ol>
				<li value="1">Open the <code>FaceMainMode</code> script for editing, and add a <code>ResetFace</code> function:<pre>    public void ResetFace()
    {
        foreach (ARFace face in faceManager.trackables)
        {
            ChangeableFace changeable =                 face.GetComponent&lt;ChangeableFace&gt;();
            if (changeable != null)
            {
                changeable.SetPosePrefab(null);
            }
        }
    }</pre></li>
				<li>In Unity, under <code>Reset Button</code>.</li>
				<li>Set its <code>150, 150</code>). Remove its <strong class="bold">Image</strong> component.</li>
				<li>On its child <code>Reset</code>, check the <strong class="bold">Auto Size</strong> checkbox, and change the text <strong class="bold">Vertex Color</strong>, if you want.</li>
				<li>Click the <strong class="bold">+</strong> button on the <strong class="bold">On Click</strong> list, drag the <strong class="bold">Main Mode</strong> object onto the <strong class="bold">Object</strong> slot, and select <strong class="bold">FaceMainMode</strong> | <strong class="bold">ResetFace</strong> from the <strong class="bold">Function</strong> list.</li>
			</ol>
			<p>My main menu, at the bottom<a id="_idIndexMarker775"/> of the screen, now looks like this with its three buttons:</p>
			<div><div><img src="img/Figure_9.06_B15145.jpg" alt="Figure 9.6 – The Main Menu with three buttons&#13;&#10;" width="290" height="95"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.6 – The Main Menu with three buttons</p>
			<p>You're now ready to build and run the project. Save your work (<strong class="bold">File</strong> | <strong class="bold">Save</strong>) and build it (<strong class="bold">File</strong> | <strong class="bold">Build and Run</strong>). You now have a little Face Maker app that lets you choose between 3D heads or <strong class="bold">resetting the scene</strong>!</p>
			<p>In this section, we created a <strong class="bold">Changeable Face Prefab</strong> that you can set the child prefab of at runtime so the user can select different head models for their selfie. We then created a <strong class="bold">Main Menu</strong> panel with horizontally scrollable buttons, and added buttons that allow the user to choose <strong class="bold">MrPlasticHead</strong>, <strong class="bold">MrFacetHead</strong>, or to reset the current model.</p>
			<p>Next, let's add some 3D accessories to your face – sunglasses and a hat.</p>
			<h1 id="_idParaDest-236"><a id="_idTextAnchor249"/>Attaching 3D Accessories</h1>
			<p>Suppose you now want to <a id="_idIndexMarker776"/>accessorize your face and head. The setup is very similar to the pose prefabs we just used. For this, we will introduce a couple of third-party models downloaded from the web (and imported into your project at the top of this chapter). We'll also add an <code>AddAccessory</code> function to the <strong class="bold">Changeable Face Prefab</strong> that allows the user to view more than one accessory at a time.</p>
			<h2 id="_idParaDest-237"><a id="_idTextAnchor250"/>Wearing a hat</h2>
			<p>I found a 3D hat on the internet (<a href="https://free3d.com/3d-model/cartola-278168.html">https://free3d.com/3d-model/cartola-278168.html</a>), and we downloaded and<a id="_idIndexMarker777"/> installed it earlier in this chapter. Feel free to use this model and/or find your own model to add to the project. I installed it in my <code>Assets/Models/TopHat/</code> folder. The model is an FBX file named <code>CapCartola</code>. We'll also need to configure its materials.</p>
			<p>If you select the <code>CapCartola</code> model in the <strong class="bold">Project</strong> window and unfold it, you'll notice it has child <strong class="bold">Camera</strong> and <strong class="bold">Light</strong> objects. This is not unusual for models exported from some 3D modeling programs such as Blender, for example. We obviously do not need these in our scene, so we'll also remove them from the imported model. Then we'll extract and set up the materials, and then put them together as a prefab. Follow these steps:</p>
			<ol>
				<li value="1">In the <code>CapCartola</code> model (in the <code>Assets/Models/TopHat/</code> folder).</li>
				<li>In the <strong class="bold">Inspector</strong>, you'll see <strong class="bold">Import Settings</strong>. Make sure the <strong class="bold">Model</strong> tab is selected at the top of the window.</li>
				<li>Uncheck the <strong class="bold">Import Cameras</strong> and <strong class="bold">Import Lights</strong> checkboxes. Then click <strong class="bold">Apply</strong>.</li>
				<li>Select the <strong class="bold">Materials</strong> tab at the top of the <strong class="bold">Inspector</strong> window.</li>
				<li>Click the <code>Material.001</code> (for the hat itself) and <code>Material.002</code> (for its ribbon band). These are already associated with the model.</li>
				<li>In the <code>Prefabs/</code> folder and select <code>TopHat</code>. Then open the prefab for editing.</li>
				<li>From the <strong class="bold">Project</strong> window, drag the <strong class="bold">CapCartola</strong> model into the <strong class="bold">Hierarchy</strong>, creating a child instance under the root <strong class="bold">TopHat</strong> object.</li>
				<li>With <code>0, 0.18, -0.02</code>), <code>(-20, 0, 0</code>), and <code>0.077, 0.077, 0.077</code>).</li>
				<li>Unfold <strong class="bold">CapCartola</strong> in the <strong class="bold">Hierarchy</strong> and select its child <strong class="bold">Cylinder</strong> object. </li>
				<li>In the <code>#331D1D</code>).</li>
				<li>Likewise, under <code>#FF1919</code>).</li>
				<li>If you add an <strong class="bold">AR Face</strong> component to the root object, you can test it out right away by using it as the <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong>.</li>
				<li><strong class="bold">Save</strong> the prefab and exit back to the scene hierarchy.  </li>
			</ol>
			<p>You now have a <strong class="bold">TopHat</strong> prefab that you can use to accessorize your face. Let's also add sunglasses.</p>
			<h2 id="_idParaDest-238"><a id="_idTextAnchor251"/>Sporting cool sunglasses</h2>
			<p>I found a 3D sunglasses model on the internet (<a href="https://free3d.com/3d-model/sunglasses-v1--803862.html">https://free3d.com/3d-model/sunglasses-v1--803862.html</a>), which we downloaded and installed earlier in this chapter. I installed it in my <code>Assets/Models/Sunglasses/</code> folder. The original model is an OBJ file<a id="_idIndexMarker779"/> named <code>12983_Sunglasses_v2_l3</code>. We'll also need to configure its materials.</p>
			<p>Extract and set up the materials, and then put the model together as a prefab using the following steps:</p>
			<ol>
				<li value="1">In the <code>12983_Sunglasses_v2_l3</code> model and select it.</li>
				<li>In the <code>sunglasses_body</code> and <code>sunglasses_lens</code>.</li>
				<li>Select the <strong class="bold">sunglasses_body</strong> material and adjust it as you desire. I made mine black. The lens material may be fine as is (dark with transparency).</li>
				<li>In the <code>Prefabs/</code> folder and select <code>Sunglasses</code>.</li>
				<li>Open the <strong class="bold">Sunglasses</strong> prefab for editing.</li>
				<li>From the <strong class="bold">Project</strong> window, drag the <strong class="bold">12983_Sunglasses_v2_l3</strong> model into the <strong class="bold">Hierarchy</strong>, creating a child instance under the root <strong class="bold">Sunglasses</strong>.</li>
				<li>With <code>-0.08, -0.025, -0.058</code>), <code>(-90, 90, 09</code>), and <code>0.0235, 0.0235, 0.0235</code>).</li>
				<li>If you also add an <strong class="bold">AR Face</strong> component to the root object, you can test it out right<a id="_idIndexMarker780"/> away by using it as the <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong>.</li>
				<li>Save the prefab and exit back to the scene hierarchy.</li>
			</ol>
			<p>We now have two models we can use as face accessories. You can test them out by manually adding one to the <strong class="bold">AR Session Origin</strong> | <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong> slot and building and running the project. When you're done, don't forget to put the <strong class="bold">Changeable Face Prefab</strong> back into the slot.</p>
			<p>Next, we'll add support for these accessories in the scripts.</p>
			<h2 id="_idParaDest-239"><a id="_idTextAnchor252"/>Updating the scripts for accessories</h2>
			<p>We need to update the <code>ChangeableFace</code> script<a id="_idIndexMarker781"/> to manage the<a id="_idIndexMarker782"/> accessory objects. It will maintain a list of the current accessory objects, ensuring we create only one instance of any prefab.</p>
			<p>Instead of destroying an accessory object when it's removed from the scene, we'll disable it, and then re-enable it if the user adds the same object again.</p>
			<p>We also need to <a id="_idIndexMarker783"/>update the <code>FaceMainMode</code> script with a function that the menu buttons can call. This in turn passes the requested prefab to <code>ChangeableFace</code>.</p>
			<p>Use the following steps to update your scripts:</p>
			<ol>
				<li value="1">Begin by opening the <code>ChangeableFace</code> script for editing and add the following <a id="_idIndexMarker784"/>declaration at the top of the class: <pre>    Dictionary&lt;GameObject, GameObject&gt; accessories =         new Dictionary&lt;GameObject, GameObject&gt;();</pre><p>We're using a dictionary to maintain the list of instantiated accessory objects, keyed by the prefab.</p></li>
				<li>Then, add an <code>AddAccessory</code> function as follows:<pre>    public void AddAccessory(GameObject prefab)
    {
        GameObject obj;
        if (accessories.TryGetValue(prefab, out obj) &amp;&amp;            obj.activeInHierarchy)
        {
            obj.SetActive(false);
            return;
        }
        else if (obj != null)
        {
            obj.SetActive(true);
        }
        else
        {
            obj = Instantiate(prefab, transform, false);
            accessories.Add(prefab, obj);
        }
    }</pre><p><code>AddAccessory</code> instantiates the prefab as a child of the face and adds it to the <code>accessories</code> list. However, if the prefab has already been instantiated, we remove it from the scene by setting it as inactive. Likewise, if you try to add it again, it is reactivated. </p></li>
				<li>Next, we'll<a id="_idIndexMarker785"/> add a <code>ResetAccessories</code> function <a id="_idIndexMarker786"/>that removes all accessories, as follows:<pre>    public void ResetAccessories()
    {
        foreach (GameObject prefab in accessories.Keys)
        {
            accessories[prefab].SetActive(false);
        }
    }</pre><p class="callout-heading">Tip: Avoid garbage collection by using object caching </p><p class="callout">In this <code>AddAccessory</code> function, I could have called <code>Destroy</code> to remove an existing instance, and then called <code>Instantiate</code> again if and when the object was added a second time. Instead, I'm managing memory by simply disabling existing objects when not wanted and reusing the same instances when requested. Repeatedly instantiating and destroying objects at runtime can cause memory fragmentation and require Unity to perform memory <code>Destroy</code>.</p></li>
				<li>Next, we can open the <code>FaceMainMenu</code> script for editing, and add an <code>AddAccessory</code> function that will be called by the menu buttons, as follows:<pre>    public void AddAccessory(GameObject prefab)
    {
        foreach (ARFace face in faceManager.trackables)
        {
            ChangeableFace changeable =                 face.GetComponent&lt;ChangeableFace&gt;();
            if (changeable != null)
            {
                changeable.AddAccessory(prefab);
            }
        }
    }</pre></li>
				<li>Next, add the <a id="_idIndexMarker787"/>following highlighted <a id="_idIndexMarker788"/>code to <code>ResetFace</code>:<pre>    public void ResetFace()
    {
        foreach (ARFace face in faceManager.trackables)
        {
            ChangeableFace changeable =                 face.GetComponent&lt;ChangeableFace&gt;();
            if (changeable != null)
            {
                changeable.SetPosePrefab(null);
<strong class="bold">                changeable.ResetAccessories();</strong>
            }
        }
    }</pre></li>
			</ol>
			<p>We're now ready to add menu buttons for the TopHat and Sunglasses accessories.</p>
			<h2 id="_idParaDest-240"><a id="_idTextAnchor253"/>Adding accessories to the main menu</h2>
			<p>To add new buttons to <a id="_idIndexMarker789"/>the main menu, we can duplicate an existing<a id="_idIndexMarker790"/> button and modify it by following these steps:</p>
			<ol>
				<li value="1">In the <code>HatAccessory Button</code>.</li>
				<li>From the <code>tophat icon</code> asset onto the <strong class="bold">Image</strong> | <strong class="bold">Source Image</strong> slot.</li>
				<li>On the <code>FaceMainMode.AddAccessory</code>.</li>
				<li>From the <code>Prefabs/</code> folder) onto the parameter slot.</li>
				<li>Likewise, repeat <em class="italic">steps 1-4</em> for a <code>SunglassesAcessory Button</code>, using the <code>sunglasses icon</code> image and the <strong class="bold">Sunglasses</strong> prefab asset.</li>
			</ol>
			<p>Save the scene and <a id="_idIndexMarker791"/>build the project. When you tap the hat button, you're <a id="_idIndexMarker792"/>wearing a top hat. Tap it again to remove it. In the following screen capture, I'm wearing the facet face, top hat, and sunglasses. I've never looked so cool!</p>
			<div><div><img src="img/Figure_9.07_B15145.jpg" alt="Figure 9.7 – Selfie with me wearing a top hat, sunglasses, and faceted face at the same time&#13;&#10;" width="461" height="923"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – Selfie with me wearing a top hat, sunglasses, and faceted face at the same time</p>
			<p>In this section, we built upon the basic face pose tracking features by adding other models to be tracked at the same time. We created prefabs for the TopHat and Sunglasses using models download from the web. Then, we updated the <code>ChangeableFace</code> script to handle multiple accessory objects. This implements good memory management practices by avoiding duplicate instances of the same prefab and caching the spawned instances in a dictionary list. After updating the <code>FaceMainMode</code> script with a public <code>AddAccessory</code> function, we added new buttons to the main menu so that the<a id="_idIndexMarker793"/> user can accessorize their head with a hat and/or<a id="_idIndexMarker794"/> sunglasses.</p>
			<p>So far, all our faces are fixed-expression static models. AR Foundation also supports the dynamic visualization of faces. Let's try that next.</p>
			<h1 id="_idParaDest-241"><a id="_idTextAnchor254"/>Making dynamic face meshes with a variety of materials</h1>
			<p>To show an augmented <a id="_idIndexMarker795"/>face that matches your real-life expressions, Unity AR Foundation lets you generate a face mesh dynamically at runtime. On this mesh, you can apply different materials, giving the effect of you wearing arbitrary face masks. To add this to our project, we'll first look at the default face game object given by AR Foundation. Then we'll create several different materials to use. To integrate this feature into our project, we'll extend the <code>ChangeableFace</code> script to switch materials, add a similar function to the <code>FaceMainMode</code> script to update the face trackables, and then add menu buttons to switch materials.</p>
			<h2 id="_idParaDest-242"><a id="_idTextAnchor255"/>Exploring AR Default Face</h2>
			<p>You can create a dynamic face<a id="_idIndexMarker796"/> game object for AR Foundation from the Unity menu at <strong class="bold">GameObject</strong> | <strong class="bold">XR</strong> | <strong class="bold">AR Default Face</strong>. The object includes an <strong class="bold">AR Face Mesh Visualizer</strong> component that generates a face mesh at runtime that matches your facial expressions, including moving your mouth and raising your eyebrows. Let's quickly try it out before we add this feature to our <strong class="bold">Changeable Face Prefab</strong>. Use the following steps:</p>
			<ol>
				<li value="1">From the Editor menu bar, select <strong class="bold">GameObject</strong> | <strong class="bold">XR</strong> | <strong class="bold">AR Default Face</strong>. This creates an object named <strong class="bold">AR Default Face</strong> in the scene hierarchy.<p>Note that you won't see this object in your Scene window because the mesh is dynamically generated at runtime, so there's nothing to render yet.</p></li>
				<li>Replace the default material (the one included is not for URP): In the <code>Materials/</code> folder (create one first if necessary), and name it <code>DefaultFace Material</code>. Set the <strong class="bold">Base Map</strong> color to your favorite color. Drag the material onto the <strong class="bold">AR Default Face</strong> object.</li>
				<li>Make it a prefab. Drag the <code>Prefabs/</code> folder.</li>
				<li>Then delete it from the <strong class="bold">Hierarchy</strong>.</li>
				<li>Now, drag the prefab <a id="_idIndexMarker797"/>onto your <strong class="bold">AR Session Origin</strong> | <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong> slot.</li>
			</ol>
			<p>Here's a screen capture of me wearing the default mask, and smiling brightly, on the left. On the right is a scene view of my face mesh generated at runtime:</p>
			<div><div><img src="img/Figure_9.08_B15145.jpg" alt="Figure 9.8 – Me wearing an AR default mask (left) and a wireframe of my face mesh (right)&#13;&#10;" width="813" height="775"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – Me wearing an AR default mask (left) and a wireframe of my face mesh (right)</p>
			<p>It's easy to replace this default material with other materials to make your own masks.</p>
			<h2 id="_idParaDest-243"><a id="_idTextAnchor256"/>Creating face materials</h2>
			<p>For fun (and for the purposes of instruction), let's try using an arbitrary photo as a face texture. I'll use a<a id="_idIndexMarker798"/> picture named <code>WinterBarn.jpg</code> (this was also used in <a href="B15145_06_Final_SB_epub.xhtml#_idTextAnchor136"><em class="italic">Chapter 6</em></a>, <em class="italic">Gallery: Building an AR App</em>). Create a new material using the photo, with the following steps:</p>
			<ol>
				<li value="1"><em class="italic">Right-click</em> in your <code>Materials/</code> folder and select <code>PhotoFace Material</code>.</li>
				<li>Drag a photo from the <code>WinterBar.jpg</code>) onto the <strong class="bold">Base Map</strong> texture chip. Ensure the <strong class="bold">Base Map</strong> color is white.</li>
				<li>Duplicate the <code>PhotoFace Prefab</code>.</li>
				<li>Open the new prefab for editing and drag the <strong class="bold">PhotoFace Material</strong> onto it. <strong class="bold">Save</strong> the prefab and return to the scene hierarchy.</li>
				<li>To try it out, drag the <strong class="bold">PhotoFace Prefab</strong> onto <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong> and run the scene.</li>
			</ol>
			<p>This ought to give you a feeling of how a 2D texture image is mapped onto the face mesh. This is called <code>PopFace_Albedo</code>) for the face mesh:</p>
			<div><div><img src="img/Figure_9.09_B15145.jpg" alt="Figure 9.9 – Ordinary 2D image as face texture (left), and a UV mapped face texture (right)&#13;&#10;" width="970" height="463"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.9 – Ordinary 2D image as face texture (left), and a UV mapped face texture (right)</p>
			<p>In this way, you can use <a id="_idIndexMarker799"/>any 2D photograph or image that you want. Try others for yourself, such as your national flag, the logo of your favorite sports team, and so on.</p>
			<p>The <code>PopFace_Albedo</code> texture shown in the preceding figure is included in the AR Face Assets package from Unity that we imported into our project at the beginning of this chapter. Make a material for that now by repeating <em class="italic">steps 1-5</em>, naming the material <code>PopFace Material</code>, and using <code>PopFace_Albedo</code> for the <strong class="bold">Base Map</strong> texture.</p>
			<p>Likewise, the AR Face Assets package includes textures for a robot face. Again, repeat <em class="italic">steps 1-5</em> for a new <code>RobotFace Material</code>, using <code>Robot_Albedo</code> for the <code>Robot_Normal</code> and <code>Robot_Occlusion</code> for <strong class="bold">Normal Map</strong> and <strong class="bold">Occlusion Map</strong>, respectively.</p>
			<p>When adding the <strong class="bold">Normal Map</strong> texture, you may be prompted with <strong class="bold">This texture is not marked as a normal map</strong>. Click the <strong class="bold">Fix Now</strong> button to apply the required <strong class="bold">Import Settings</strong>.</p>
			<p>The following figure shows me wearing the <strong class="bold">RobotFace</strong> and <strong class="bold">PopFace</strong> masks. Not obvious in these screen captures is the fact that the face mesh follows my facial expressions in real time:</p>
			<div><div><img src="img/Figure_9.10_B15145.jpg" alt="Figure 9.10 – Selfies using the Robot PBR material (left), and the Pop albedo texture (right)&#13;&#10;" width="874" height="416"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.10 – Selfies using the Robot PBR material (left), and the Pop albedo texture (right)</p>
			<p class="callout-heading">Info: Using Procreate to paint your own textures</p>
			<p class="callout">If you're interested in painting your own UV mapped face textures (and have an iPad), the Procreate app (<a href="https://procreate.art/">https://procreate.art/</a>) has a feature for doing this (check out <em class="italic">Dilmer Valecillos's</em> video on this at <a href="https://youtu.be/FOxhcRzDLx8">https://youtu.be/FOxhcRzDLx8</a>). </p>
			<p>With the <a id="_idIndexMarker800"/>materials made, we can add the face mesh visualizer to the changeable face prefab, so it will generate the face mesh at runtime.</p>
			<h2 id="_idParaDest-244"><a id="_idTextAnchor258"/>Adding a face mesh visualizer to the changeable face prefab</h2>
			<p>To integrate a dynamic face mesh <a id="_idIndexMarker801"/>into our app, we should add it to our versatile <strong class="bold">Changeable Face Prefab</strong>. We will need the same components as the <strong class="bold">AR Default Face</strong> game object we generated earlier, and they need to be on the prefab's root object. Use the following steps to add them manually:</p>
			<ol>
				<li value="1">Open <strong class="bold">Changeable Face Prefab</strong> for editing.</li>
				<li>With the prefab root object selected, click <strong class="bold">Add Component</strong> in the <strong class="bold">Inspector</strong>.</li>
				<li>Search for and select the <strong class="bold">AR Face Mesh Visualizer</strong> component.</li>
				<li>Search for and select a <strong class="bold">Mesh Filter</strong> component.</li>
				<li>Search for and select a <strong class="bold">Mesh Renderer</strong> component.</li>
				<li>Drag the <strong class="bold">DefaultFace Material</strong> from the <strong class="bold">Project</strong> window onto the <strong class="bold">Changeable Face Prefab</strong> root object.</li>
				<li>Save the prefab.</li>
				<li>Back in the scene hierarchy, drag the <strong class="bold">Changeable Face Prefab</strong> asset onto the <strong class="bold">AR Session Origin</strong> | <strong class="bold">AR Face Manager</strong> | <strong class="bold">Face Prefab</strong> slot.</li>
			</ol>
			<p>If you build and run<a id="_idIndexMarker802"/> now, you'll see the default face mesh. All the menu buttons still work, letting you add 3D head models and accessories.</p>
			<p>We want to have buttons that let the user choose between face materials. For that, we need to update our scripts.</p>
			<h2 id="_idParaDest-245"><a id="_idTextAnchor259"/>Controlling the face material</h2>
			<p>We can hide or show<a id="_idIndexMarker803"/> the face mesh by toggling the <strong class="bold">AR Face Mesh Visualizer</strong> and <strong class="bold">Mesh Render</strong> components. Use the following steps:</p>
			<ol>
				<li value="1">Open the <code>ChangeableFace</code> script for editing and add the following at the top of the script:<pre>using UnityEngine.XR.ARFoundation;</pre></li>
				<li>Add the following code to declare and initialize references to the <code>ARFaceMeshVisualizer</code> and <code>MeshRenderer</code> components:<pre>    ARFaceMeshVisualizer meshVisualizer;
    MeshRenderer renderer;
    private void Start()
    {
        meshVisualizer =            GetComponent&lt;ARFaceMeshVisualizer&gt;();
        meshVisualizer.enabled = false;
        renderer = GetComponent&lt;MeshRenderer&gt;();
        renderer.enabled = false;
    }</pre><p>We'll start the app<a id="_idIndexMarker804"/> with the face mesh not visible, so both components are disabled.</p></li>
				<li>Then, add a <code>SetMeshMaterial</code> function as follows:<pre>    public void SetMeshMaterial(Material mat)
    {
        if (mat == null)
        {
            meshVisualizer.enabled = false;
            renderer.enabled = false;
            return;
        }
        renderer.material = mat;
        meshVisualizer.enabled = true;
        renderer.enabled = true;
    }</pre><p>When given a material, <code>mat</code>, the function sets it in the renderer and makes sure the visualizer and renderer components are enabled. If you pass a <code>null</code> value for the <code>mat</code>, then the components will be disabled. </p></li>
				<li>Next, open the <code>FaceMainMode</code> script and add a <code>ChangeMaterial</code> function, as follows:<pre>    public void ChangeMaterial(Material mat)
    {
        foreach (ARFace face in faceManager.trackables)
        {
            ChangeableFace changeable =                 face.GetComponent&lt;ChangeableFace&gt;();
            if (changeable != null)
            {
                changeable.SetMeshMaterial(mat);
            }
        }
    }</pre><p>Like the <a id="_idIndexMarker805"/>other functions in the script, it loops through any trackables and calls into the changeable component.</p></li>
				<li>Next, update the <code>ResetFace</code> function with the following highlighted line:<pre>                changeable.SetPosePrefab(null);
                changeable.ResetAccessories();
<strong class="bold">                changeable.SetMeshMaterial(null);</strong></pre></li>
			</ol>
			<p>The code is now written. We added a <code>SetMaterial</code> function to the <code>ChangeableFace</code> script that enables the mesh visualizer and sets the material to render. To the <code>FaceMainMode</code> script, we added a <code>ChangeMaterial</code> function that calls <code>SetMaterial</code> on each trackable AR face. </p>
			<p>We're now ready to add menu buttons for the various mesh materials.</p>
			<h2 id="_idParaDest-246"><a id="_idTextAnchor260"/>Adding face materials to the main menu</h2>
			<p>To add new buttons <a id="_idIndexMarker806"/>to the main menu, we can duplicate an existing button and modify it, as we did earlier. Use the following steps:</p>
			<ol>
				<li value="1">In the <code>DefaultFace Button</code>.</li>
				<li>From the <code>default face icon</code> asset onto the <strong class="bold">Image</strong> | <strong class="bold">Source Image</strong> slot.</li>
				<li>On the button <strong class="bold">On Click</strong> action, change <strong class="bold">Function</strong> to <strong class="bold">FaceMainMode.ChangeMaterial</strong>.</li>
				<li>From the <code>Materials/</code> folder) onto the parameter slot.</li>
				<li>Likewise, repeat <em class="italic">steps 1-4</em> three times, for <code>PhotoFace Button</code> (using the <code>photo face icon</code> image, and the <code>PopFace Button</code>, and for <code>RobotFace Button</code>.</li>
			</ol>
			<p>Save the scene and build the project. When you tap one of the face material buttons, it renders the face mesh. The following cropped screen capture shows the horizontally-scrolled menu with the new buttons:</p>
			<div><div><img src="img/Figure_9.11_B15145.jpg" alt="Figure 9.11 – Face mesh texture buttons on the main menu&#13;&#10;" width="441" height="103"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.11 – Face mesh texture buttons on the main menu</p>
			<p>In this section, we added an <code>FaceMainMode</code>. This then forwards it to the trackable face(s). </p>
			<p>While the face visualizer can follow some of your expressions, including raised eyebrows and opening your mouth, it does nothing for your eyes. Let's consider eye tracking next.</p>
			<h1 id="_idParaDest-247"><a id="_idTextAnchor261"/>Using eye tracking (ARKit)</h1>
			<p>For eye tracking, as you <a id="_idIndexMarker807"/>might expect, you are given the pose transforms for each eye, which you can use to update your own "eyeball" game objects. For this feature, I'll show you how to do it, but leave the details of integrating it into the project up to you. Presently, this feature requires an iOS device with a <strong class="bold">TrueDepth</strong> camera.</p>
			<p>To learn more about eye tracking with AR Foundation, take a look at the <code>EyeLasers</code> scene given in the AR Foundation sample assets (we installed these in the <code>Assets/ARF-samples/</code> folder).</p>
			<p>The <strong class="bold">Face Prefab</strong> in the scene's <strong class="bold">AR Face Manager</strong> is the <strong class="bold">AR Eye Laser Visualizer</strong> prefab. This has an <strong class="bold">AR Face</strong> component (as you would expect), plus an <strong class="bold">Eye Pose Visualizer</strong>. This visualizer script, in turn, is given an eyeball prefab. In this specific scene, it is given the <strong class="bold">Eye Laser Prefab</strong>. This simply contains a long thin cylinder that'll be rendered to look like a laser beam. In summary, these dependencies could be depicted as the following:</p>
			<p class="author-quote">EyeLasers scene -&gt; AR Eye Laser Visualizer face prefab -&gt; Eye Pose Visualizer script -&gt; Eye Laser Prefab</p>
			<p>The <code>EyePoseVisualizer</code> script is an example script (not part of the AR Foundation package itself). Briefly, you give it an eyeball prefab, which is instantiated twice and parented by the <code>ARFace</code>, <code>leftEye</code>, and <code>rightEye</code> pose transforms. For example, you'll find this line of code in the script's <code>CreateEyeGameObjectsIfNecessary</code> function (line 45):</p>
			<pre>m_LeftEyeGameObject = Instantiate(m_EyePrefab, m_Face.leftEye);</pre>
			<p>As a child of the tracked eye transforms, the spawned objects appear to automatically track with your detected eye movements.</p>
			<p>The script also subscribes to the <code>ARFace</code> and <code>update</code> events, where it toggles the eyes' visibility based on the trackable's tracking state, as shown in the following code:</p>
			<pre>        void OnUpdated(ARFaceUpdatedEventArgs eventArgs)
        {
            CreateEyeGameObjectsIfNecessary();
            SetVisible((m_Face.trackingState ==                 TrackingState.Tracking) &amp;&amp;                     (ARSession.state &gt; ARSessionState.Ready));
        }</pre>
			<p class="callout-heading">Tip: Using updated events with face tracking</p>
			<p class="callout">This script illustrates another best practice for face tracking with AR Foundation. By subscribing to the trackables' <code>updated</code> events, it toggles the visibility of instantiated prefabs based on the trackable's <code>trackingState</code>, as well as the overall <code>ARSession.state</code>. You might consider refactoring the functions in our <code>FaceMainMode</code> class to handle <code>updated</code> events in this way too.</p>
			<p>Eye tracking is<a id="_idIndexMarker808"/> not available on all platforms. When the script is enabled, it first checks the Unity eye tracking subsystem. If the feature is not supported, the component disables itself, as highlighted in the following <code>OnEnable</code> function (lines 65-78):</p>
			<pre>        void OnEnable()
        {
            var faceManager =                FindObjectOfType&lt;ARFaceManager&gt;();
            if (faceManager != null &amp;&amp; <strong class="bold">faceManager.subsystem !=            null &amp;&amp; faceManager.descriptor.supportsEyeTracking</strong>)
            {
                m_FaceSubsystem =                     (XRFaceSubsystem)faceManager.subsystem;
                SetVisible((m_Face.trackingState ==                    TrackingState.Tracking) &amp;&amp;                     (ARSession.state &gt; ARSessionState.Ready));
                m_Face.updated += OnUpdated;
            }
            else
            {
                <strong class="bold">enabled = false;</strong>
            }
        }</pre>
			<p>If you want to try<a id="_idIndexMarker809"/> this yourself with an eyeball instead of a laser beam, the following URL contains a free eyeball 3D model you could use: <a href="https://free3d.com/3d-model/eyeball--33237.html.">https://free3d.com/3d-model/eyeball--33237.html.</a> Make it into a prefab and substitute it for the eye laser prefab on the AR eye laser visualizer prefab's <strong class="bold">Eye Pose Visualizer</strong> | <strong class="bold">Eye Prefab</strong> slot.</p>
			<p>This is fantastic! However, you can do so much more. For example, with ARCore, you can attach graphics to specific regions of the face. Let's look into that now.</p>
			<h1 id="_idParaDest-248"><a id="_idTextAnchor262"/>Attaching stickers to face regions (ARCore)</h1>
			<p>If your project is using <a id="_idIndexMarker810"/>ARCore XR Plugin and Android, you<a id="_idIndexMarker811"/> have access to ARCore-specific features, including transforms for three important face regions: the nose tip, left forehead, and right forehead. If you raise your left eyebrow, for example, that transform will move independently of the rest of the face, providing some more detail to the facial expressions in your app.</p>
			<p>In addition to what we do here, you may also want to look at the <code>ARF-samples/</code> folder in your project), and the <code>ARCoreFaceRegionManager</code> script it uses. The code we develop in this section is considerably simpler and easier to follow.</p>
			<p>To demonstrate ARCore face regions, we'll implement several 2D stickers and attach them to the <a id="_idIndexMarker812"/>3D face regions. We'll let you add eyebrows, a <a id="_idIndexMarker813"/>mustache, and licking lips using clipart that we identified at the top of this chapter (and I edited in Photoshop). They've been imported as <strong class="bold">Sprite (2D and UI)</strong>. These are available in this book's GitHub repository.</p>
			<p>We can start by creating the sticker prefabs.</p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor263"/>Creating the sticker prefabs</h2>
			<p>To make prefabs of these clipart<a id="_idIndexMarker814"/> images, use the following steps:</p>
			<ol>
				<li value="1"><em class="italic">Right-click</em> in the <code>Mustache Prefab</code>. Then open it for editing.</li>
				<li>From the <code>mustache</code> image onto the root <strong class="bold">Mustache Prefab</strong>. This creates a child object named <strong class="bold">mustache</strong> with a <strong class="bold">Sprite Renderer</strong> component.</li>
				<li>Set the <code>0, -0.02, 0</code>) and <code>0,019, 0,019, 0,019</code>).</li>
				<li>Save the prefab.</li>
				<li>Repeat <em class="italic">steps 1-4</em>, making <code>Lips Prefab</code> using the <code>licking-lips</code> sprite image. Use <code>0, -0.05, 0</code>) and <code>0,019, 0,019, 0,019</code>).</li>
				<li>Again, repeat <em class="italic">steps 1-4</em>, making <code>Eyebrow Left Prefab</code> using the <code>eyebrow-left</code> sprite image. Use <code>0, -0.01, 0</code>) and <code>0,019, 0,019, 0,019</code>).</li>
				<li>And likewise, one more time, make <code>Eyebrow Right Prefab</code> using the <code>eyebrow-right</code> sprite <a id="_idIndexMarker815"/>image. Use <code>0, -0.01, 0</code>) and <code>0,019, 0,019, 0,019</code>).</li>
			</ol>
			<p>We now have prefabs for a mustache, lips, and eyebrows. Let's write the scripts to attach them using the ARCore face regions support.</p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor264"/>Managing attachments' positions</h2>
			<p>We'll create a separate script, <code>FaceRegionAttachments</code> on <code>ChangeableFace</code> script because the code is ARCore-specific and is relatively long.</p>
			<p>The lines of code that depend on ARCore are enclosed in <code>#if UNITY_ANDROID &amp;&amp;!UNITY_EDITOR</code> compiler symbols, so they will not run in a non-Android environment (including the desktop play mode). Use the following steps:</p>
			<ol>
				<li value="1">Create a new C# script named <code>FaceRegionAttachments</code> and open it for editing.</li>
				<li>Start writing the script by replacing the content with the following code:<pre>using System.Collections.Generic;
using UnityEngine;
using Unity.Collections;
using UnityEngine.XR.ARFoundation;
#if UNITY_ANDROID
using UnityEngine.XR.ARCore;
#endif
public class FaceRegionAttachments : MonoBehaviour
{
    ARFaceManager faceManager;
    ARFace face;
    Dictionary&lt;ARCoreFaceRegion, GameObject&gt; prefabs =      new Dictionary&lt;ARCoreFaceRegion, GameObject&gt;();
    Dictionary&lt;ARCoreFaceRegion, GameObject&gt; objs =       new Dictionary&lt;ARCoreFaceRegion, GameObject&gt;();
#if UNITY_ANDROID &amp;&amp; !UNITY_EDITOR
    NativeArray&lt;ARCoreFaceRegionData&gt; faceRegions;
#endif
    private void Start()
    {
        faceManager = FindObjectOfType&lt;ARFaceManager&gt;();
        face = GetComponent&lt;ARFace&gt;();
    }</pre><p>The script first<a id="_idIndexMarker817"/> declares that we're using the ARFoundation API as well as ARCore. Then, at the top of the class, we declare variables for <code>ARFaceManager</code> and the object's <code>ARFace</code>, and initialize these in <code>Start</code>. We also declare two dictionaries, <code>prefabs</code> and <code>objs</code>, that will be indexed by the ARCore <code>region</code> identifier (enum). We then declare a <code>NativeArray</code> of <code>ARCoreFaceRegionData</code> named <code>faceRegions</code> that we'll be using in <code>Update</code>.</p></li>
				<li>Add a <code>SetRegionAttachment</code> function (that will be called from <code>FaceMainMode</code>) as follows:<pre>    public void SetRegionAttachment(ARCoreFaceRegion         region, GameObject prefab)
    {
        GameObject obj;
        if (objs.TryGetValue(region, out obj))
        {
            GameObject currentPrefab = prefabs[region];
            Destroy(obj);
            prefabs.Remove(region);
            objs.Remove(region);
            if (prefab == currentPrefab)
                return;
        }
        obj = Instantiate(prefab);
        prefabs.Add(region, prefab);
        objs.Add(region, obj);
    }</pre><p>The function gets a <code>region</code> ID and a <code>prefab</code>, instantiates the <code>prefab</code>, and records both the <code>prefab</code> and spawned object in the dictionaries. If there is already a spawned object, it is first destroyed and removed from the lists. We check if the <a id="_idIndexMarker818"/>new prefab was the same as the current one, so it won't be respawned again, effectively allowing the menu button to toggle on and off as an attachment by clicking twice.</p></li>
				<li>On each <code>Update</code>, we need to ask ARCore for the current list of face regions, and update the spawned object transforms accordingly, as follows:<pre>    private void Update()
    {
#if UNITY_ANDROID &amp;&amp; !UNITY_EDITOR
        var subsystem =             (ARCoreFaceSubsystem)faceManager.subsystem;
        if (subsystem == null)
            return;
        subsystem.GetRegionPoses(face.trackableId,            Allocator.Persistent, ref faceRegions);
        for (int i = 0; i &lt; faceRegions.Length; ++i)
        {
            GameObject obj;
            if (objs.TryGetValue(faceRegions[i].region,                out obj))
            {
                obj.transform.localPosition =                    faceRegions[i].pose.position;
            }
        }
#endif
    } </pre></li>
				<li>We can <a id="_idIndexMarker819"/>also provide a public <code>Reset</code> function that destroys all the instantiated objects and clears the dictionaries:<pre>    public void Reset()
    {
        foreach (ARCoreFaceRegion region in objs.Keys)
        {
            Destroy(objs[region]);
        }
        objs.Clear();
        prefabs.Clear();
    }</pre></li>
				<li>Finally, it's<a id="_idIndexMarker820"/> good practice to dispose of the <code>faceRegions</code> native array when this game object is destroyed, as follows:<pre>    void OnDestroy()
    {
#if UNITY_ANDROID &amp;&amp; !UNITY_EDITOR
        if (faceRegions.IsCreated)
            faceRegions.Dispose();
#endif
    }
}</pre></li>
				<li>Save the script, then, back in Unity, open the <strong class="bold">Changeable Face Prefab</strong> asset for editing.</li>
				<li>Drag the <code>FaceRegionAttachments</code> script onto the root <code>Destroy</code> and <code>Instantiate</code> for the same prefabs.</p></li>
			</ol>
			<p>Now we'll update the <code>FaceMainMode</code> script to use it and provide public functions that the menu buttons can call, as follows:</p>
			<ol>
				<li value="1">Open the <code>FaceMainMode</code> script for editing, and start by adding the following lines at the top of the file (needed for the <code>enum</code> <code>ARCoreFaceRegion</code> definition):<pre>#if UNITY_ANDROID 
using UnityEngine.XR.ARCore;
#endif</pre></li>
				<li>Add a<a id="_idIndexMarker821"/> private <code>SetRegionAttachment</code> function that loops through the trackables and calls <code>SetRegionAttachment</code> on them:<pre>    private void SetRegionAttachment(ARCoreFaceRegion         region, GameObject prefab)
    {
        foreach (ARFace face in faceManager.trackables)
        {
            FaceRegionAttachments regionAttachments =              face.GetComponent&lt;FaceRegionAttachments&gt;();
            if (regionAttachments != null)
            {
                regionAttachments.                    SetRegionAttachment(region, prefab);
            }
        }
    }</pre></li>
				<li>Next, expose this capability via separate public functions we can call from the menu button Unity actions, as follows:<pre>    public void SetNoseAttachment(GameObject prefab)
    {
        SetRegionAttachment(ARCoreFaceRegion.NoseTip,            prefab);
    }
    public void SetForeheadLeftAttachment(GameObject         prefab)
    {
        SetRegionAttachment(            ARCoreFaceRegion.ForeheadLeft, prefab);
    }
    public void SetForeheadRightAttachment(GameObject         prefab)
    {
        SetRegionAttachment(            ARCoreFaceRegion.ForeheadRight, prefab);
    }</pre></li>
				<li>Save the script. </li>
			</ol>
			<p>Here, we <a id="_idIndexMarker822"/>created a new <code>FaceRegionAttachments</code> script that maintains dictionary lists of <code>prefabs</code> and spawned <code>objs</code> for game objects attached to specific face regions. On each frame <code>Update</code>, the <code>objs</code> transforms are updated based on the face region's pose transform, so it tracks with its region. This implementation allows multiple attachments on a face, but only one per region. Then, we updated the <code>FaceMainMode</code> script with public functions that can be called by menu buttons to add attachments.</p>
			<p>We can now make the menu buttons.</p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor265"/>Adding region attachments to the main menu</h2>
			<p>As we did earlier, to add<a id="_idIndexMarker823"/> new buttons to the main menu, we can<a id="_idIndexMarker824"/> duplicate an existing button and modify it. Use the following steps:</p>
			<ol>
				<li value="1">In the <code>Mustache Button</code>.</li>
				<li>From the <code>mustache icon</code> asset onto the <strong class="bold">Image</strong> | <strong class="bold">Source Image</strong> slot.</li>
				<li>On the button <strong class="bold">On Click</strong> action, change <strong class="bold">Function</strong> to <strong class="bold">FaceMainMode.SetNoseAttachment</strong>.</li>
				<li>From the <strong class="bold">Project</strong> window, drag the <strong class="bold">Mustache Prefab</strong> asset onto the parameter slot.</li>
				<li>Repeat <em class="italic">steps 1-4</em> for <code>Lips Button</code>, using the <code>licking-lips icon</code> image, and the <strong class="bold">Lips Prefab</strong> asset. Use the same function as the mustache, <strong class="bold">FaceMainMode.SetNoseAttachment</strong>.</li>
				<li>Repeat <em class="italic">steps 1-4</em> again for <code>Eyebrows Button</code>, using the <code>eyebrows icon</code> image. This time, we'll have two <strong class="bold">On Click</strong> actions, one for each eye. The first calls <strong class="bold">FaceMainMode.SetForeheadLeftAttachment</strong> with the <strong class="bold">EyebrowLeft Prefab</strong>. The second calls <strong class="bold">FaceMainMode.SetForeheadRightAttachment</strong> with the <strong class="bold">EyebrowRight Prefab</strong>, as shown in the following:</li>
			</ol>
			<div><div><img src="img/Figure_9.12_B15145.jpg" alt="Figure 9.12 – The eyebrows button has two On Click actions, for both the left and &#13;&#10;right regions and prefabs" width="535" height="166"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.12 – The eyebrows button has two On Click actions, for both the left and right regions and prefabs</p>
			<p>Save the scene and build the project. When you tap one of the region attachment buttons, it adds <a id="_idIndexMarker825"/>its sticker prefabs to the scene. The <a id="_idIndexMarker826"/>mustache and lips both set the nose attachment so you can only view one at a time. The following screen captures show me all decked out, including combining it with other face augmentations we created earlier (right):</p>
			<div><div><img src="img/Figure_9.13_B15145.jpg" alt="Figure 9.13 – Selfie screenshots with multiple stickers, and (on the right) combined &#13;&#10;with other augmentations" width="822" height="783"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.13 – Selfie screenshots with multiple stickers, and (on the right) combined with other augmentations</p>
			<p>Because this<a id="_idIndexMarker827"/> feature is specific to ARCore, you will <a id="_idIndexMarker828"/>probably want to hide the sticker buttons if you try building the project for iOS. We can add those next.</p>
			<h2 id="_idParaDest-252"><a id="_idTextAnchor266"/>ARCore-only UI buttons</h2>
			<p>This face region stickers <a id="_idIndexMarker829"/>feature only runs on ARCore and Android. If you plan to build the same project on iOS (as well as Android), we already account for code compilation issues using conditional compile symbols. However, the menu buttons will still be visible. You could disable them by hand in the editor before doing a build, or you could let a script handle it.</p>
			<p>Use the following <code>ARCoreOnly</code> script to hide buttons from the UI (unless you're targeting Android). If you're targeting Android but using play mode in the editor (using the AR Foundation remote tool), this script will disable the button so that it is visible but not interactable:</p>
			<pre>using UnityEngine;
using UnityEngine.UI;
public class ARCoreOnly : MonoBehaviour
{
    private void Awake()
    {
#if !UNITY_ANDROID
        gameObject.SetActive(false);
#endif
#if UNITY_EDITOR
        Button button = GetComponent&lt;Button&gt;();
        button.interactable = false;
#endif
    }
}</pre>
			<p>Drag a copy of this script onto the mustache button, lips button, and eyebrows button game objects so that they can only be used with ARCore.</p>
			<p>To summarize, in this section, we created several sticker prefabs containing <code>FaceRegionAttachments</code>, that uses the native <code>ARCoreFaceRegionData</code> (via <code>ARCoreFaceSubsystem</code>) to find the pose transform of each face region (nose tip, left forehead, and right forehead), and track each spawned game object with the given face region. We added menu buttons for each of the stickers that call public functions in <code>FaceMainMenu</code> by passing the sticker prefab to add. This in turn forwards the prefab to the trackable faces. Feel free to add more sticker prefabs <a id="_idIndexMarker830"/>and buttons, using similar steps to the ones found in this section.</p>
			<p>This is cool, but having just three face regions is kind of limited. Using ARKit, you have access to much more refined detail about face geometry. This is achieved with the use of blend shapes.</p>
			<h1 id="_idParaDest-253"><a id="_idTextAnchor267"/>Tracking expressive face blend shapes (ARKit)</h1>
			<p>ARKit introduces<a id="_idIndexMarker831"/> additional advanced face tracking features available only on iOS devices, including blend shapes. <strong class="bold">Blend shapes</strong> refer <a id="_idIndexMarker832"/>to morphing mesh geometries that are commonly used for animating the faces of NPCs (non-player characters) in video games and VR applications. Presently, they are an ARKit-specific feature. ARKit blend shapes provide intricate details of facial expressions as separate features, such as a left or right eye blink, looking down, eyes wide open, cheek puff, cheek squint, jaw left, mouth dimple, and many more. Each feature is given a coefficient on a scale of 0.0 to 1.0. This shape data can be forwarded to the Unity <strong class="bold">Skinned Mesh Renderer</strong> (<a href="https://docs.unity3d.com/Manual/class-SkinnedMeshRenderer.html">https://docs.unity3d.com/Manual/class-SkinnedMeshRenderer.html</a>) that is used in character animation. A good explanation and conversation can be found at the following URL: <a href="https://www.quora.com/What-is-blendshape-exactly">https://www.quora.com/What-is-blendshape-exactly</a>. </p>
			<p>Building an animated rig (with bones and a skinned mesh) is beyond the scope of this book. Instead, by way of explanation, I'll walk through the example assets given in the AR Foundation samples project's <code>ARKitFaceBlendShapes</code> scene, found in the <code>Assets/ARF-samples/scenes/FaceTracking/</code> folder. To begin, you can try it yourself (if you're set up for iOS development) by building the <code>ARKitFaceBlendShapes</code> scene. Now, let's take a closer look.</p>
			<p>Opening the scene in the Unity Editor, you will find <code>SlothHead</code> prefab for the <strong class="bold">Face Prefab</strong>.</p>
			<p>Opening the <code>ARKitBlenShapeVisualizer</code>. This is an example script provided with AR Foundation samples (it is not part of the AR Foundation package itself). This component has a parameter for <strong class="bold">Skinned Mesh Renderer</strong>. This is on the <strong class="bold">Sloth_Head2</strong> child object, as shown in the following screenshot:</p>
			<div><div><img src="img/Figure_9.14_B15145.jpg" alt="Figure 9.14 – The SlothHead prefab has the sample ARKitBlendShapeVisualizer script that references the skinned mesh render on the child Sloth_Head2" width="1170" height="585"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 9.14 – The SlothHead prefab has the sample ARKitBlendShapeVisualizer script that references the skinned mesh render on the child Sloth_Head2</p>
			<p>Open the <code>ARKitBlendShapeVisualizer</code> script in your code editor. You'll find a function, <code>CreateFeatureBlendMapping</code>, that is called <code>Awake</code>. This maps ARKit blend shape names (type <code>ARKitBlendShapeLocation</code>) with corresponding indexes on the <code>skinnedMeshRenderer</code>. For the list of locations and descriptions, see the following URL: <a href="mailto:https://docs.unity3d.com/Packages/com.unity.xr.arkit-face-tracking@4.2/api/UnityEngine.XR.ARKit.ARKitBlendShapeLocation.html">https://docs.unity3d.com/Packages/com.unity.xr.arkit-face-tracking@4.2/api/UnityEngine.XR.ARKit.ARKitBlendShapeLocation.html</a>.</p>
			<p>The following screenshot shows the <strong class="bold">Sloth_Head2</strong> object's <strong class="bold">Skinned Mesh Renderer</strong>, with <a id="_idIndexMarker834"/>some of its <strong class="bold">BlendShapes</strong> visible in the Unity <strong class="bold">Inspector</strong>:</p>
			<div><div><img src="img/Figure_9.15_B15145.jpg" alt="Figure 9.15 – Skinned Mesh renderer component with some of the blend shapes listed&#13;&#10;" width="947" height="595"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.15 – Skinned Mesh renderer component with some of the blend shapes listed</p>
			<p>The ARKit blend shape locations are mapped to the <strong class="bold">Skinned Mesh Renderer</strong> ones.</p>
			<p>Then the <code>ARKitBlendShapeVisualizer</code> script, which subscribes to the <code>ARFace</code> <code>updated</code> events with the <code>OnUpdated</code> function, in turn, calls its <code>UpdateFaceFeatures</code> function. <code>UpdateFaceFeatures</code> gets the current blend shape coefficients from ARKit (<code>m_ARKitFaceSubsystem.GetBlendShapeCoefficients</code>), and for each coefficient, sets that coefficient value (scaled by a global scalar) to the <code>skinnedMeshRender</code>. From there, Unity does its magic, deforming and animating the mesh geometry to <a id="_idIndexMarker835"/>be rendered on the screen. This is not simple but does make sense if you can follow it correctly.</p>
			<p>That's basically how blend shapes work. Developing your own models and code may require a good familiarity with the parts of Unity in question, but all the information you need is accessible. You will be successful if you know how to use it.</p>
			<h1 id="_idParaDest-254"><a id="_idTextAnchor268"/>Summary</h1>
			<p>In this chapter, you built a face maker app that handles face tracking with the forward-facing (user-facing) camera on a mobile device. You learned that the <code>ChangeableFace</code> script that we could update from the <code>FaceMainMode</code> script.</p>
			<p>You used this architecture to explore several ways of rendering tracked faces. First, you used the face pose to render an instantiated 3D head model (<strong class="bold">MrPlasticHead</strong> and <strong class="bold">MrFacetHead</strong>). Next, you used this technique to add accessories to the face, including a <strong class="bold">TopHat</strong> and <strong class="bold">Sunglasses</strong>. Then, you added an <strong class="bold">AR Face Mesh Visualizer</strong> to generate a face mesh dynamically at runtime, and then made several materials that can be applied to the mesh to make a wide variety of face masks. If you're on ARCore, you also implemented face region stickers using sprite images attached to ARCore face regions. Finally, you learned about ARKit-specific face tracking features, including eye tracking and blend shapes. In the process, you implemented a horizontally-scrolling main menu button that lets users choose various combinations of face filters. All this was great fun!</p>
			<p>You now have a working knowledge of how to build AR applications in Unity using AR Foundation. If you followed along with each of the chapters of this book, you will have learned how to set up your system for AR development with Unity configured to build on your target platform and mobile device. You created a simple AR scene, learning the main game objects required for AR, including the AR Session and AR Session Origin. You also explored the sample AR projects provided by Unity. Next, you learned about improving the developer workflow and troubleshooting your apps, considering situations unique to AR development.</p>
			<p>You created a user framework for developing an AR application that included onboarding graphics, interaction modes, and UI panels. This was saved as a scene template for reuse. You learned how to use the framework, first building a simple place-object scene with a simple main menu.</p>
			<p>In the third part of the book, you built several AR applications, including a picture gallery that lets you place framed photos on your walls, with menus and user interactivity. You improved the app, adding editing tools to move, resize, delete, and change the images displayed in virtual pictures in the scene. In the next project, you used image tracking to present 3D graphics and information about the planets using real-life printed flashcards. Finally, in this chapter, you built a face tracking app with a scrolling menu containing a variety of face heads, masks, and attachable accessories to make fun selfies.</p>
			<p>This is just the start. AR Foundation and Unity provide even more support for augmented reality applications, including object tracking and geotagging with GPS, as well as the full richness of the Unity platform for the development of interactive 3D games and applications. Go out and augment the world! </p>
		</div>
	</div></body></html>