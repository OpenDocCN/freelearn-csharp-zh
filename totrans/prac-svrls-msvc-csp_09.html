<html><head></head><body>
<div><h1 class="chapterNumber"><a id="_idTextAnchor261"/>9</h1>
<h1 class="chapterTitle" id="_idParaDest-180"><a id="_idTextAnchor262"/>Simplifying Containers and Kubernetes: Azure Container Apps, and Othert Tools</h1>
<p class="normal">While Kubernetes is probably the most complete orchestrator, any transition from monolithic development to microservices on Kubernetes faces two hard difficulties.</p>
<p class="normal">The first difficulty is that the cost of a Kubernetes cluster often is not justified by the initial low traffic of the application. In fact, a production-grade Kubernetes cluster typically requires multiple nodes for redundancy and reliability. While self-managed clusters may need at least two master <a id="_idIndexMarker725"/>nodes and three worker nodes, managed <a id="_idIndexMarker726"/>Kubernetes services such as <strong class="keyWord">Amazon Elastic Kubernetes Service</strong> (<strong class="keyWord">Amazon EKS</strong>), <strong class="keyWord">Azure Kubernetes Service</strong> (<strong class="keyWord">AKS</strong>), or <strong class="keyWord">Google Kubernetes Engine</strong> (<strong class="keyWord">GKE</strong>) often handle control plane redundancy at a lower cost (Amazon EKS control <a id="_idIndexMarker727"/>plane costs ~$72/month). Teams can start with smaller instance <a id="_idIndexMarker728"/>types and scale as needed, reducing the initial burden.</p>
<p class="normal">Another difficulty is the learning curve of Kubernetes itself. Moving the whole team to discrete Kubernetes knowledge/expertise might require time that we simply don’t have. Moreover, if we are transitioning an existing monolithic application, at the beginning of the transition—when the number of microservices is still low and their organization still resembles the same organization of the monolithic application—we simply don’t need all the opportunities and options offered by Kubernetes.</p>
<p class="normal">The preceding considerations led to the conception of <strong class="keyWord">Azure Container Apps</strong>, which is a serverless <a id="_idIndexMarker729"/>alternative to Kubernetes. Being a serverless option, you pay just for what you use and overcome the problem of the initial cluster size threshold. <strong class="keyWord">Azure Container Apps</strong> also lowers the learning curve thanks to the following features:</p>
<ol>
<li class="numberedList" value="1">While Kubernetes offers all the building blocks for coding both tools and microservices, <strong class="keyWord">Azure Container Apps</strong> building blocks are the microservices themselves, so the developer can remain focused on the business logic without spending too much time on technical details. Tools such as storage solutions, message brokers, and other performance and security tools are taken from the hosting platform—that is, Azure.</li>
<li class="numberedList">There are acceptable defaults for everything, so deploying an application may become as simple as deciding on the Docker images to deploy. Customizations can also be specified at a later time.</li>
</ol>
<p class="normal">After a short description of the various tools used to simplify the usage and administration of Kubernetes clusters, this chapter describes <strong class="keyWord">Azure Container Apps</strong> in detail and how to use it in practice. This chapter relies on preexisting knowledge of Kubernetes, so please read it after having studied <a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>.</p>
<p class="normal">More specifically, this chapter covers the follow<a id="_idTextAnchor263"/>ing:</p>
<ul>
<li class="bulletList">Tools for simplifying Kubernetes cluster usage and administration</li>
<li class="bulletList"><strong class="keyWord">Azure Container Apps</strong> basics and p<a id="_idTextAnchor264"/>lans</li>
<li class="bulletList">Deploying your microservice application with <strong class="keyWord">Azure Container Apps</strong></li>
</ul>
<h1 class="heading-1" id="_idParaDest-181"><a id="_idTextAnchor265"/>Technical requirements</h1>
<p class="normal">This chapter requires the following:</p>
<ol>
<li class="numberedList" value="1">Visual Studio 2022 free <em class="italic">Community Edition</em>, at least.</li>
<li class="numberedList">Azure CLI. Links for both the 32-bit and 64-bit Windows installers can be found at<strong class="keyWord"> </strong><a href="https://learn.microsoft.com/bs-latn-ba/cli/azure/install-azure-cli-windows?tabs=azure-cli">https://learn.microsoft.com/bs-latn-ba/cli/azure/install-azure-cli-windows?tabs=azure-cli</a><strong class="keyWord">.</strong></li>
<li class="numberedList">An Azure subscription.</li>
<li class="numberedList">minikube and kubectl. Please refer to the <em class="italic">Technical requirements</em> section of <a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>.</li>
</ol>
<h1 class="heading-1" id="_idParaDest-182"><a id="_idTextAnchor266"/>Tools for simplifying Kubernetes clusters usage and administration</h1>
<p class="normal">After <a id="_idIndexMarker730"/>the success of Kubernetes, a lot of products, services and open sources connected with it appeared. In this section, we classify them and provide some relevant examples. The whole offering related to Kubernetes can be classified as follows:</p>
<ol>
<li class="numberedList" value="1">Tools for packaging libraries and applications.</li>
<li class="numberedList">Kubernetes graphic UIs.</li>
<li class="numberedList">Administrative tools for taking and presenting various cluster metrics, handling alarms, and performing administrative actions.</li>
<li class="numberedList">Tools for handling the whole development and deployment of microservices-based applications that include Kubernetes as their target deployment platform.</li>
<li class="numberedList">Programming environments built on top of Kubernetes. These include both vertical applications, such as machine learning and big data tools, and general-purpose programming environments, such as Azure Container Apps.</li>
</ol>
<p class="normal">When it comes to packaging tools, the most relevant is <strong class="keyWord">Helm</strong>, which became a de facto standard for packaging Kubernetes applications and libraries. We will analyze it in a dedicated subsection next.</p>
<h2 class="heading-2" id="_idParaDest-183"><a id="_idTextAnchor267"/>Helm and Helm charts</h2>
<p class="normal"><strong class="keyWord">Helm</strong> is a package <a id="_idIndexMarker731"/>manager, and the packages <a id="_idIndexMarker732"/>it manages are called <strong class="keyWord">Helm charts</strong>. Helm charts are a way to organize the installation of complex Kubernetes applications <a id="_idIndexMarker733"/>that contain several <code class="inlineCode">.yaml</code> files. A <a id="_idIndexMarker734"/>Helm chart is a set of <code class="inlineCode">.yaml</code> files organized into folders and subfolders. Here is a typical folder structure of a Helm chart taken from the official documentation:</p>
<figure class="mediaobject"><img alt="Figure 9.1: Folder structure of a Helm chart" src="img/B31916_09_1.png"/></figure>
<p class="packt_figref">Figure 9.1: Folder structure of a Helm chart</p>
<p class="normal">The <code class="inlineCode">.yaml</code> files <a id="_idIndexMarker735"/>specific to the application are placed in the top <code class="inlineCode">templates</code> directory, while the <code class="inlineCode">charts</code> directory <a id="_idIndexMarker736"/>may contain other Helm charts used as helper libraries. The top-level <code class="inlineCode">Chart.yaml</code> file contains general information about the package (name and description), together with both the application version and the Helm chart version. The following is a typical example:</p>
<pre class="programlisting code"><code class="hljs-code">apiVersion: v2
name: myhelmdemo
description: My Helm chart
type: application
version: 1.3.0
appVersion: 1.2.0
</code></pre>
<p class="normal">Here, <code class="inlineCode">type</code> can be either <code class="inlineCode">application</code> or <code class="inlineCode">library</code>. Only <code class="inlineCode">application</code> charts can be deployed, while <code class="inlineCode">library</code> charts are utilities for developing other charts. <code class="inlineCode">library</code> charts are placed in the <code class="inlineCode">charts</code> folder of other Helm charts.</p>
<p class="normal">In order to configure each specific application installation, Helm chart <code class="inlineCode">.yaml</code> files contain variables that are specified when Helm charts are installed. Moreover, Helm charts also provide a simple templating language that allows some declarations to be included only if some conditions depending on the input variables are satisfied. The top-level <code class="inlineCode">values.yaml</code> file declares default values for the input variables, meaning that the developer needs to specify just a few variables for which they require different values from the defaults. We will not describe the Helm chart templates language because it would be too extensive, but you can find it in the official Helm documentation referred<a id="_idTextAnchor268"/> to in the <em class="italic">Further reading</em> section.</p>
<p class="normal">Helm charts are usually organized in public or private repositories in a way that is similar to Docker images. There is a Helm client, which you can use to download packages from a remote repository and install charts in Kubernetes clusters. The Helm client can be installed on any machine with a kubectl installation through the Chocolatey package manager, as follows:</p>
<pre class="programlisting con"><code class="hljs-con">choco install kubernetes-helm
</code></pre>
<p class="normal">In turn, you may find the Chocolatey installation procedure in the <em class="italic">Technical requirements</em> section of<em class="italic"> </em><a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>. Helm operates with the <a id="_idIndexMarker737"/>current kubectl Kubernetes cluster and user.</p>
<p class="normal">A remote <a id="_idIndexMarker738"/>repository must be added before using its packages, as shown in the following example:</p>
<pre class="programlisting con"><code class="hljs-con">helm repo add &lt;my-repo-local-name&gt; https://mycharts.helm.sh/stable
</code></pre>
<p class="normal">The previous <a id="_idIndexMarker739"/>command makes the package information of a remote repository <a id="_idIndexMarker740"/>available locally and gives a local name to that remote repository. The information about all charts available in one or more repositories can be refreshed with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">helm repo update &lt;my-repo-local-name 1&gt; &lt;my-repo-local-name 2&gt;…
</code></pre>
<p class="normal">If no repository name is specified, all local repositories are updated.</p>
<p class="normal">After that, any package from the remote repository can be installed with a command such as the following:</p>
<pre class="programlisting con"><code class="hljs-con">helm install &lt;instance name&gt; &lt;my-repo-local-name&gt;/&lt;package name&gt; -n &lt;namespace&gt;
</code></pre>
<p class="normal">Here, <code class="inlineCode">&lt;namespace&gt;</code> is the Kubernetes namespace where to install the application. As usual, if it’s not provided, the <code class="inlineCode">default</code> namespace is assumed. <code class="inlineCode">&lt;package name&gt;</code> is the name of the package you would like to install, and finally, <code class="inlineCode">&lt;instance name&gt;</code> is the name that you give to the installed application. You need this name to get information about the installed application with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">helm status &lt;instance name&gt;
</code></pre>
<p class="normal">You can get also information about all applications installed with Helm with the help of the following command:</p>
<pre class="programlisting con"><code class="hljs-con">helm ls
</code></pre>
<p class="normal">The application name is also needed to delete the application from the cluster using the following command:</p>
<pre class="programlisting con"><code class="hljs-con">helm delete &lt;instance name&gt;
</code></pre>
<p class="normal">When we install an application, we may also provide a <code class="inlineCode">.yaml</code> file with all the default variable values we <a id="_idIndexMarker741"/>want to override. We can also specify a specific version of the Helm chart; otherwise, the most <a id="_idIndexMarker742"/>recent version is used. Here is an example with both the version and values overridden:</p>
<pre class="programlisting con"><code class="hljs-con">helm install &lt;instance name&gt; &lt;my-repo-local-name&gt;/&lt;package name&gt; -f values.yaml --version &lt;version&gt;
</code></pre>
<p class="normal">Finally, default <a id="_idIndexMarker743"/>value overrides <a id="_idIndexMarker744"/>can also be provided in line with the <code class="inlineCode">--set</code> option, as shown here:</p>
<pre class="programlisting con"><code class="hljs-con">...--set &lt;variable1&gt;=&lt;value1&gt;,&lt;variable2&gt;=&lt;value2&gt;...
</code></pre>
<p class="normal">We can also upgrade an existing installation with the <code class="inlineCode">upgrade</code> command, as shown here:</p>
<pre class="programlisting con"><code class="hljs-con">helm upgrade &lt;instance name&gt; &lt;my-repo-local-name&gt;/&lt;package name&gt;...
</code></pre>
<p class="normal">The <code class="inlineCode">upgrade</code> command may specify new value overrides with the <code class="inlineCode">–f</code> option or with the <code class="inlineCode">--set</code> option, and it can also specify the new version to install with <code class="inlineCode">--version</code>. If no version is specified, the more recent version is installed.</p>
<p class="normal">More details on Helm can be found in the official documentation at <a href="https://helm.sh/">https://helm.sh/</a>. We will show how to use Helm in practice in the later subsection about Kubernetes administrative tools.</p>
<h2 class="heading-2" id="_idParaDest-184"><a id="_idTextAnchor269"/>Kubernetes graphic UIs</h2>
<p class="normal">There are also tools that help the definition and deployment of Kubernetes resources through user-friendly <a id="_idIndexMarker745"/>graphic interfaces. Among <a id="_idIndexMarker746"/>them, it is worth mentioning ArgoCD and Rancher UI.</p>
<p class="normal"><strong class="keyWord">ArgoCD</strong> handles a <a id="_idIndexMarker747"/>database of Kubernetes resources and automatically updates a Kubernetes cluster whenever the code that defines a resource changes. ArgoCD simplifies a lot of Kubernetes cluster handling but automatic re-deployment of resources may cause issues in production environments that require zero downtime. We will not describe ArgoCD here, but interested readers can find more details in the <em class="italic">Further reading</em> section.</p>
<p class="normal"><strong class="keyWord">Rancher UI</strong> enables users <a id="_idIndexMarker748"/>to interact with several Kubernetes clusters through a web-based UI. It has also tools for handling the whole development process, such as the definition of projects.</p>
<p class="normal">The <a id="_idIndexMarker749"/>Rancher UI web application must be accessible from within each Kubernetes cluster it must handle, and <a id="_idIndexMarker750"/>requires the installation software inside each of the Kubernetes clusters that it must handle.</p>
<p class="normal">Rancher UI can also be installed on a developer’s local machine, where it can be used to interact with minikube. The simplest way to perform a local installation is through Docker. Open a Linux shell and enter the following code:</p>
<pre class="programlisting con"><code class="hljs-con">docker run -d \
  --restart unless-stopped \
  -p 80:80 \
  -p 443:443 \
  --privileged \
  --name rancher \
  rancher/rancher:stable
</code></pre>
<p class="normal">A few minutes after the installation is completed, Rancher UI is available at <code class="inlineCode">https://localhost</code>. If you can’t access it, wait a minute and retry.</p>
<p class="normal">Once the web interface appears for the first time, you need a temporary password. You can get this password with the following Linux command:</p>
<pre class="programlisting con"><code class="hljs-con">docker logs rancher 2&gt;&amp;1 | grep "Bootstrap Password:"
</code></pre>
<p class="normal">Copy the temporary password in the Rancher UI initial page, and press <strong class="keyWord">Continue</strong>. The new page that appears should propose a new definitive password for the admin user, and the URL to be used by minikube to access Rancher UI. Fill this page as shown here:</p>
<figure class="mediaobject"><img alt="Figure 9.2: Rancher initial settings" src="img/B31916_09_2.png"/></figure>
<p class="packt_figref">Figure 9.2: Rancher initial settings</p>
<p class="normal">Accept <a id="_idIndexMarker751"/>the proposed <a id="_idIndexMarker752"/>password, copy it, and store it in a safe place. The <code class="inlineCode">host.docker.internal</code> hostname enables minikube to connect with our machine localhost.</p>
<p class="normal">On the dashboard, click the <strong class="screenText">Import Existing</strong> button to start the process of connecting an existing cluster with Rancher UI:</p>
<figure class="mediaobject"><img alt="Figure 9.3: Importing an existing cluster" src="img/B31916_09_3.png"/></figure>
<p class="packt_figref">Figure 9.3: Importing an existing cluster</p>
<p class="normal">On the new page that appears, select the <a href="https://www.Generic.com">Generic</a> cluster option:</p>
<figure class="mediaobject"><img alt="Figure 9.4: Generic cluster option" src="img/B31916_09_4.png"/></figure>
<p class="packt_figref">Figure 9.4: Generic cluster option</p>
<p class="normal">Fill in <a id="_idIndexMarker753"/>just the <a id="_idIndexMarker754"/>cluster name and description on the page that a<a id="_idTextAnchor270"/>ppears, as shown here:</p>
<p class="normal"><img alt="" role="presentation" src="img/B31916_09_5.png"/></p>
<p class="packt_figref">Figure 9.5: Filling in the cluster information</p>
<p class="normal">Then, click the <strong class="screenText">Create</strong> button. A page with the code to run in your cluster should appear. You should select the second code option since the local Rancher installation uses a self-signed certificate, which should be something like this:</p>
<pre class="programlisting con"><code class="hljs-con">curl --insecure -sfL https://host.docker.internal/v3/import/6rd2jg4nntmkkw9z9mjhttrjfjj64cz9vl8zr6pr6tskbt6cc98zfz_c-2p47w.yaml | kubectl apply -f -
</code></pre>
<p class="normal">However, this code must be executed in a Linux shell, and <code class="inlineCode">kubectl</code> is installed only on Windows. Therefore, replace the preceding instruction with the following:</p>
<pre class="programlisting con"><code class="hljs-con">curl --insecure -sfL https://host.docker.internal/v3/import/6rd2jg4nntmkkw9z9mjhttrjfjj64cz9vl8zr6pr6tskbt6cc98zfz_c-2p47w.yaml &gt; install.yaml
</code></pre>
<p class="normal">Then, execute it in a Linux shell. It will create the <code class="inlineCode">install.yaml</code> file that contains our Kubernetes code.</p>
<p class="normal">Now, we <a id="_idIndexMarker755"/>can install <a id="_idIndexMarker756"/>Rancher on minikube. Ensure that minikube is running, open a Windows console, and execute the following command:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl apply -f install.yaml
</code></pre>
<p class="normal">When the installation is complete, return to the dashboard; you should see the newly imported minikube cluster:</p>
<figure class="mediaobject"><img alt="Figure 9.6: Minikube cluster connected" src="img/B31916_09_6.png"/></figure>
<p class="packt_figref">Figure 9.6: Minikube cluster connected</p>
<p class="normal">Click on the <code class="inlineCode">minikube</code> link and enjoy the power of interacting with Minikube through a graphic UI! Here, you can see nodes, Pods, namespaces, and all types of Kubernetes resources, and can also define new resources.</p>
<p class="normal">When you have finished experimenting, stop minikube and the Rancher container in the Docker UI. If you don’t need to interact with minikube through Rancher anymore, just execute the following:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl delete -f install.yaml
</code></pre>
<h2 class="heading-2" id="_idParaDest-185"><a id="_idTextAnchor271"/>Kubernetes administrative tools</h2>
<p class="normal">Each cloud provider offers administrative UIs together with the Kubernetes offering. These UIs include <a id="_idIndexMarker757"/>the possibility to perform actions on the cluster, such as inspecting Kubernetes resources, collecting various metrics, and both querying <a id="_idIndexMarker758"/>and plotting these metrics. We will analyze the administrative tools offered by Azure in more detail in <a href="Chapter_10.xhtml#_idTextAnchor297"><em class="italic">Chapter 10</em></a>, <em class="italic">Security and Observability for Serverless and Microservices Applications</em>.</p>
<p class="normal">However, there are also several tools offered by third parties and also several open source projects. Among the <a id="_idIndexMarker759"/>open source projects, it is worth mentioning the metrics collector called <strong class="keyWord">Prometheus</strong>, and the UI-based <a id="_idIndexMarker760"/>administrative console called <strong class="keyWord">Grafana</strong>. Usually, they are installed together and Prometheus works as a metrics source for Grafana. They can be installed on any Kubernetes cluster, including minikube.</p>
<p class="normal">A detailed description of these tools is beyond the purpose of the book, but since they are very common and are also a prerequisite for other tools, we will describe how to install them.</p>
<p class="normal">If you would like to test these tools on minikube, you need a configuration with more memory, and some other custom settings, so the the best option is to define a new profile while starting minikube with the following:</p>
<pre class="programlisting con"><code class="hljs-con">minikube start --memory=6g --extra-config=kubelet.authentication-token-webhook=true --extra-config=kubelet.authorization-mode=Webhook --extra-config=scheduler.bind-address=0.0.0.0 --extra-config=controller-manager.bind-address=0.0.0.0 -p &lt;your profile name&gt;
</code></pre>
<p class="normal">Here, the <code class="inlineCode">--extra-config</code> option allows the configuration of various Kubernetes installation options. If you don’t use minikube, you must be sure that the Kubernetes cluster is configured with the options passed with <code class="inlineCode">--extra-config</code> in the preceding instruction. These settings enable Webhooks on the controller manager that Prometheus uses to collect its metrics and change the IP addresses exposed by both the controller and scheduler on the master nodes to enforce compatibility with Prometheus.</p>
<p class="normal">Once all these settings are fixed, we can install both Prometheus and Grafana with Helm:</p>
<pre class="programlisting con"><code class="hljs-con">helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/prometheus --namespace monitoring --create-namespace
helm install grafana grafana/grafana --namespace monitoring
</code></pre>
<p class="normal">The first two instructions add the repositories containing Prometheus and Grafana, respectively, and the third instruction updates all repository local directories. The third instruction installs Prometheus in the <code class="inlineCode">monitoring</code> namespace, after having created this namespace, and finally, the last instruction installs Grafana in the same namespace.</p>
<p class="normal">After the installation, we can inspect the <code class="inlineCode">monitoring</code> namespace to verify that all resources are ready:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl get all -n monitoring
</code></pre>
<p class="normal">Finally, both the <a id="_idIndexMarker761"/>Prometheus and Grafana UIs can be accessed by port-forwarding adequate <a id="_idIndexMarker762"/>services. Remember to use a different console window for each port-forward service, since the console freezes while port-forwarding:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl --namespace monitoring port-forward service/prometheus-server 9090:80
kubectl --namespace monitoring port-forward service/grafana 3000:80
</code></pre>
<p class="normal">After that, Prometheus will be available at <a href="http://localhost:9090">http://localhost:9090</a> and Grafana at http://localhost:3000. While Prometheus doesn’t require a login, the default user for Grafana is <code class="inlineCode">admin</code> and the password must be extracted from a Kubernetes secret, as shown here:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl get secret --namespace monitoring grafana -o jsonpath="{.data.admin-password}"
</code></pre>
<p class="normal">Copy the string returned by the preceding command; we need to Base64-decode it to get the actual password. As usual, Base64-decoding can be performed by opening a Linux console and using the <code class="inlineCode">base64 </code>command:</p>
<pre class="programlisting con"><code class="hljs-con">echo -n &lt;string to decode&gt; | base64 -d
</code></pre>
<p class="normal">Once logged in to Grafana, we must declare Prometheus as its metrics data source. In the Grafana left menu, go to <strong class="screenText">Connections -&gt; Data sources</strong>, and then select <strong class="screenText">Add new data source</strong>. In the page that appears, select <strong class="keyWord">Prometheus</strong>, as shown in the following figure:</p>
<figure class="mediaobject"><img alt="Figure 9.7: Selecting Prometheus as the data source" src="img/B31916_09_7.png"/></figure>
<p class="packt_figref">Figure 9.7: Selecting Prometheus as the data source</p>
<p class="normal">We need <a id="_idIndexMarker763"/>to configure Prometheus as the default data source <a id="_idIndexMarker764"/>and set the URL at which to retrieve all metrics to <a href="http://prometheus-server:80">http://prometheus-server:80</a>, which corresponds to the address and port of the same Prometheus service we have port-forwarded, as shown here:</p>
<figure class="mediaobject"><img alt="Figure 9.8: Prometheus settings" src="img/B31916_09_8.png"/></figure>
<p class="packt_figref">Figure 9.8: Prometheus settings</p>
<p class="normal">You can <a id="_idIndexMarker765"/>keep all the other default settings; just click the <strong class="screenText">Save and test</strong> button. After <a id="_idIndexMarker766"/>that, click the <strong class="screenText">Dashboards</strong> tab and import all proposed dashboards.</p>
<p class="normal">Then, go to <strong class="screenText">Dashboards</strong> in the Grafana left menu and inspect all the imported dashboards by clicking their links:</p>
<figure class="mediaobject"><img alt="Figure 9.9: Available dashboards" src="img/B31916_09_9.png"/></figure>
<p class="packt_figref">Figure 9.9: Available dashboards</p>
<p class="normal">If you <a id="_idIndexMarker767"/>click <strong class="screenText">new</strong> and then <strong class="screenText">import</strong>, you can import a dashboard from grafana.com. Just follow the <code class="inlineCode">grafana.com/dashboards</code> link, select a dashboard, take its ID, and copy it, as shown here:</p>
<figure class="mediaobject"><img alt="Figure 9.10: Importing a dashboard from grafana.com" src="img/B31916_09_10.png"/></figure>
<p class="packt_figref">Figure 9.10: Importing a dashboard from grafana.com</p>
<p class="normal">You <a id="_idIndexMarker768"/>might be required to subscribe to get a dashboard ID. Subscription is free. The dashboard selection pages contain links to the documentation you might be interested in exploring.</p>
<p class="normal">If you stop minikube with <code class="inlineCode">minikube stop -p &lt;profle name&gt;</code>, minikube will be stopped but all your data will be saved, so you can continue experimenting with Grafana. If you want to uninstall Grafana and Prometheus, you can do it with Helm, as shown here:</p>
<pre class="programlisting con"><code class="hljs-con">helm delete grafana
helm delete prometheus
</code></pre>
<p class="normal">Let’s close this section with the remaining tools.</p>
<h2 class="heading-2" id="_idParaDest-186"><a id="_idTextAnchor272"/>Development environments based on Kubernetes</h2>
<p class="normal">Among the complete development platforms based on Kubernetes, it is worth mentioning <strong class="keyWord">OpenShift</strong> (<a href="https://www.redhat.com/en/technologies/cloud-computing/openshift">https://www.redhat.com/en/technologies/cloud-computing/openshift</a>), which includes <a id="_idIndexMarker769"/>tools for the whole development process, including <a id="_idIndexMarker770"/>DevOps automation and cloud services.</p>
<p class="normal">OpenShift can be installed on-premises or it can be used as a PaaS service available in the main cloud services, Azure included (<a href="https://azure.microsoft.com/it-it/products/openshift">https://azure.microsoft.com/it-it/products/openshift</a>).</p>
<p class="normal">Big data and <a id="_idIndexMarker771"/>machine learning frameworks use Kubernetes, but we will not discuss them since they are completely beyond the purpose of this book.</p>
<p class="normal">It is also worth mentioning simple code generators offered by some start-ups that create Kubernetes applications by combining containers with the help of graphic interfaces. Needless to say, similar tools are just aimed at creating low-cost applications. We will not describe them because the focus of the book is enterprise high-quality applications and, at the moment, there is neither an emerging general pattern nor an emerging specific framework.</p>
<p class="normal">Instead, when it comes to higher-level abstraction alternatives to Kubernetes that are built on top of Kubernetes, at the time this book was written, the most relevant option is <strong class="keyWord">Azure Container Apps,</strong> which will be described in the remainder of the chapter.</p>
<h1 class="heading-1" id="_idParaDest-187"><a id="_idTextAnchor273"/>Azure Container Apps basics and plans</h1>
<p class="normal">Azure Container <a id="_idIndexMarker772"/>Apps is available as a serverless offering with <strong class="keyWord">consumption</strong> plans but has also <strong class="keyWord">dedicated</strong> plans based on the horizontal scaling of virtual machines, called <strong class="keyWord">workload profiles</strong>. Some <a id="_idIndexMarker773"/>advanced features are available only with <strong class="keyWord">workload profiles</strong>. We will talk more about plans later on in this section.</p>
<p class="normal">While Kubernetes offers several kinds of independent building blocks, Azure Container Apps is based on just two kinds of building blocks: <strong class="keyWord">applications/jobs</strong> and <strong class="keyWord">environments</strong>.</p>
<p class="normal">Applications map one-to-one with microservices, while jobs are useful for long-running tasks and will not be discussed in this chapter.</p>
<p class="normal">Applications automatically handle replicas—that is, each application may have several identical replicas exactly like a Kubernetes Deployment. Applications support the same configuration options as Kubernetes Deployments, as follows:</p>
<ul>
<li class="bulletList">Environment variables</li>
<li class="bulletList">Volume mounts</li>
<li class="bulletList">Health probes</li>
<li class="bulletList">CPU and memory resources configuration</li>
<li class="bulletList">Automatic log collection</li>
</ul>
<p class="normal">They also support communication configuration, secrets, and automatic scaling, but they are not defined as <a id="_idIndexMarker774"/>separate objects as in Kubernetes but inside the application configuration itself. Moreover, there is no equivalent of StatefulSets—that is, there is no way to implement sharding algorithms.</p>
<p class="normal">The rationale behind these choices is that the developer must map each microservice into a single resource instead of several coordinated resources, so they can concentrate mainly on business business logic without being overwhelmed by orchestrator-specific configuration.</p>
<p class="normal">Coordination tools <a id="_idIndexMarker775"/>such as StatefulSets are simply omitted since they don’t include business logic but are just used for solving coordination and parallel update issues. In fact, StatefulSets are used mainly to implement tools such as storage engines and message brokers, so the basic idea is that the developer should use resources already available in the cloud instead of implementing customized solutions so they can concentrate all their efforts on the business logic.</p>
<p class="normal">Other resources, such as permissions, users, and roles, are taken from Azure, too. This way, your microservice application is smoothly integrated into the hosting cloud instead of being a self-contained deployment environment loosely coupled with the hosting cloud, such as Kubernetes.</p>
<p class="normal">Summing up, we can say that Azure Container Apps simplifies the implementation of a microservice application at the price of decreasing its portability. Once you implement your application to run in Azure Container Apps and to use Azure cloud resources, the only option to migrate to another cloud is to rewrite the whole orchestrator-related code.</p>
<div><p class="normal">Needless to say, if containers are carefully designed, they are not lost in the case of migrations, but the whole logic around them is lost.</p>
</div>
<p class="normal">This is not a big issue if your application is small and consists of a few microservices, but for big applications made of hundreds or thousands of microservices, a migration might imply an unacceptable cost both in terms of time and money.</p>
<p class="normal">Therefore, Azure Container Apps is a good option for small applications or when you plan to deploy your application on a single cloud (Azure) and when you don’t need too many customizations (custom tools, highly customized tools, complex custom distributed algorithms, and so on). This makes it a good entry point in the world of distributed computing when you start the conversion of a monolithic application.</p>
<p class="normal">The boundaries of a microservice application are defined by an <strong class="keyWord">environment</strong>. Inside each environment, all applications can freely interact, but you can also decide to expose some endpoints to the <strong class="keyWord">outside world</strong>. If you use a consumption plan, the outside world is necessarily the internet, but with workload profiles, you can bypass this limitation by associating a subnet of an existing Azure virtual network to your environment. In fact, in this case, the outside world would be the remainder of the virtual network.</p>
<p class="normal">There is no equivalent of Kubernetes ingresses for routing communications from a single environment <a id="_idIndexMarker776"/>entry point to all frontend microservices inside the environment, but you can implement a similar functionality by using an application as an API gateway (see the <em class="italic">Interfacing the external world</em> subsection of <a href="Chapter_2.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Demystifying Microservices Applications</em>). For HTTP and HTTPS termination, you can configure any application for using HTTPS without the burden of creating and handling HTTPS certificates, since Azure will take care of this for you.</p>
<p class="normal">The following figure illustrates what we said about applications and environments:</p>
<figure class="mediaobject"><img alt="Figure 9.11: Azure Container Apps organization" src="img/B31916_09_11.png"/></figure>
<p class="packt_figref">Figure 9.11: Azure Container Apps organization</p>
<p class="normal">Take note of the following:</p>
<ul>
<li class="bulletList">Each environment can be defined as either consumption only or a workload profile.</li>
<li class="bulletList">Each environment can have profiles added to it. Consumption-only environments can only have the default consumption profile. Workload profile environments have the default consumption profile but can also have customizable workload profiles added. Profiles will be discussed more later on in this section.</li>
<li class="bulletList">Each application associated with the environment can specify which of the profiles associated with the environment to run on.</li>
<li class="bulletList">Each application is accessible with an <code class="inlineCode">http://&lt;application name&gt;</code> URL from inside the environment. We can also decide that an application is not accessible with a direct link when we use a message broker.</li>
<li class="bulletList">Some applications <a id="_idIndexMarker777"/>can be configured for access from outside of the environment, in which case, they receive the <code class="inlineCode">https://&lt;application name&gt;.&lt;environment name&gt;.&lt;zone&gt;.azurecontainerapps.io</code> URL. Here, <code class="inlineCode">&lt;zone&gt;</code> is the Azure geographic zone where you defined your environment. <em class="italic">HTTP traffic must be passed on the usual 80 and 443 ports</em>. For pure TCP traffic, the developer can specify different ports.</li>
<li class="bulletList">Each environment has an associated virtual network. Only if the environment has a workload profile can you assign it a custom subnet of a virtual network.</li>
<li class="bulletList">Environments and applications can access any Azure resources if they are granted the necessary permissions or credentials.</li>
</ul>
<p class="normal">The remainder of this section is organized into subsections that describe the following subjects:</p>
<ol>
<li class="numberedList" value="1">Consumption-only and<a id="_idTextAnchor274"/> workload profiles</li>
<li class="numberedList">Application versioning</li>
<li class="numberedList">Interacting with Azure Container Apps</li>
</ol>
<h2 class="heading-2" id="_idParaDest-188"><a id="_idTextAnchor275"/>Consumption-only and workload profiles</h2>
<p class="normal">Applications <a id="_idIndexMarker778"/>running in a consumption profile are billed as follows:</p>
<pre class="programlisting code"><code class="hljs-code">Kcpu*&lt;virtual CPU seconds&gt; + Kmem*&lt;Gigabytes seconds&gt; + Kreq*&lt;requests per seconds&gt;
</code></pre>
<p class="normal">In a few words, the application is billed proportionally to its memory, CPU, and request consumption. The actual constants for the various countries are available here: <a href="https://azure.microsoft.com/en-us/pricing/details/container-apps/. ">https://azure.microsoft.com/en-us/pricing/details/container-apps/.</a></p>
<p class="normal">With workload profiles, you are billed according to the CPUs and gigabytes of each virtual machine in use and not for the CPU and memory allocated to the applications. Thus, for instance, notwithstanding you use just 10% of a profile virtual machine, you are billed for the overall virtual machine CPU and memory. However, for workload profiles, there is no billing quota corresponding to the application requests. There is also an hourly profile-handling cost to add to the overall cost of each profile. The actual constants for the various countries are available here: <a href="https://azure.microsoft.com/en-us/pricing/details/container-apps/. ">https://azure.microsoft.com/en-us/pricing/details/container-apps/.</a></p>
<p class="normal">Each profile can be used by several applications, and the number of virtual machines allocated to a profile is computed according to the CPU and memory requested by all applications that run in that profile. That is, a new virtual machine is allocated whenever the total CPU or memory requested by all applications exceeds the total CPUs and memory of the already allocated machines.</p>
<p class="normal">Needless to say, one can specify both a maximum number and a minimum number of machines <a id="_idIndexMarker779"/>allocated to each profile. Since allocating a new virtual machine requires time, it is advised to set the minimum number of instances to at least 1; otherwise, the first requests after a period of inactivity would experience unacceptable response times.</p>
<p class="normal">The hourly CPU and memory costs of workload profiles are lower than the ones of consumption-only profiles but workload profiles have an hourly management cost. Workload profiles become convenient when the average workload exceeds 3–4 CPUs with 16 GB of memory. However, certain features are only available with workload profiles. For instance, you need a workload profile if you want to customize the virtual network underlying your environment by adding firewalls, or by using a subnet of another virtual network.</p>
<p class="normal">All available workload profile types are listed on this page: <a href="https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview">https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview</a>.</p>
<p class="normal">Let’s move on to a useful feature of Azure Container Apps: automatic versioning support.</p>
<h2 class="heading-2" id="_idParaDest-189"><a id="_idTextAnchor276"/>Application versioning</h2>
<p class="normal">Azure <a id="_idIndexMarker780"/>Container Apps automatically versions your applications. Each time you modify the containers or scale configuration of your application, a new version is automatically created.</p>
<p class="normal">Each version is given a name and is called a <strong class="keyWord">revision</strong> of the application. As a default, only the last revision is active and accessible through the application link.</p>
<p class="normal">However, any application <a id="_idIndexMarker781"/>may be put in <strong class="keyWord">multiple-revision</strong> mode, in which case, you may decide manually which revisions are <strong class="keyWord">active</strong> and which revisions are connected to the application link.</p>
<p class="normal">If more than one revision is connected to the application link, you must specify how to split the traffic between them. If just one revision is attached to the application link but there are multiple active revisions, you may reach each active revision that is not attached to the application URL through its revision name, as follows:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;application name&gt;-&lt;revision name&gt;.&lt;environment&gt;.&lt;zone&gt;.azurecontainerapps.io
</code></pre>
<p class="normal">Since revision <a id="_idIndexMarker782"/>names are automatically generated and are not user-friendly, each revision may be attached with friendly labels that can be used to reach the revision with links such as the following:</p>
<pre class="programlisting code"><code class="hljs-code">&lt;application name&gt;--&lt;revision label&gt;.&lt;environment&gt;.&lt;zone&gt;.azurecontainerapps.io
</code></pre>
<p class="normal">Azure Container Apps revisions logic enables several deployment models, as follows:</p>
<ul>
<li class="bulletList"><em class="italic">Staging/production</em>: The newer revision is not attached to the application link but can be reached just through its revision link, so it can be tested in staging. As soon as the new revision is approved, it is attached to the application link and the previous revision is deactivated.</li>
<li class="bulletList"><em class="italic">New features preview</em>: The traffic is split among the last two revisions. Initially, the new revision is passed a low percentage of the overall traffic, so that users can experiment with new features. Then, gradually, the new version receives more traffic till it reaches 100%, and the previous version is deactivated.</li>
<li class="bulletList">During traffic splitting, <strong class="keyWord">session affinity</strong> is enabled, so that if a user request is served by a revision, <code class="inlineCode">r</code>, then all subsequent requests will continue being served by the same <code class="inlineCode">r</code> revision. This way, we avoid users walking randomly between the two revisions.</li>
</ul>
<p class="normal">Revisions are useful mainly for frontend services, especially if internal communication relies on message brokers. Testing a new version of a worker microservice requires a completely separate staging environment.</p>
<p class="normal">We will provide more details on the <a id="_idTextAnchor277"/>practical usage of revisions at the end of the <em class="italic">Deploying your microservice application with Azure Container Apps</em> section. The next subsection explains how to interact with your microservice application in Azure Container Apps.</p>
<h2 class="heading-2" id="_idParaDest-190"><a id="_idTextAnchor278"/>Interacting with Azure Container Apps</h2>
<p class="normal">There is no equivalent of kubectl to interact with Azure Container Apps environments and applications. You may <a id="_idIndexMarker783"/>interact with them either through the Azure portal or with <strong class="keyWord">Azure CLI</strong>.</p>
<p class="normal">Application and <a id="_idIndexMarker784"/>environment settings can be specified either with command options or through <code class="inlineCode">.yaml</code> or JSON files. We will focus just on command options and <code class="inlineCode">.yaml</code> files, describing just the most practical alternatives.</p>
<p class="normal">The interaction <a id="_idIndexMarker785"/>with Azure Containers Apps requires the installation of the <strong class="keyWord">containerapp Azure CLI</strong> extension. You can install it with the following command after you have logged in with <code class="inlineCode">az login</code>:</p>
<pre class="programlisting con"><code class="hljs-con">az upgrade
az extension add --name containerapp --upgrade
</code></pre>
<p class="normal">The first <code class="inlineCode">upgrade</code> command ensures you have the latest Azure CLI version, while the <code class="inlineCode">upgrade</code> option in the second command updates the extension to the latest version. The preceding commands are needed only once, or each time you would like to update to a new version.</p>
<p class="normal">Before starting any new session, you must register a couple of namespaces. Namespaces registration has the same semantics as C# <code class="inlineCode">using</code> statements. Here are the required registration commands:</p>
<pre class="programlisting con"><code class="hljs-con">az provider register --namespace Microsoft.App
az provider register --namespace Microsoft.OperationalInsights
</code></pre>
<p class="normal">Now, we are ready to interact with Azure Container Apps. The next section explains in detail how to deploy and configure your microservice application on Azure Container Apps.</p>
<h1 class="heading-1" id="_idParaDest-191"><a id="_idTextAnchor279"/>Deploying your microservice application with Azure Container Apps</h1>
<p class="normal">In this section, we will see how to define and configure your applications in Azure Container Apps. In <a id="_idIndexMarker786"/>the first subsection, we <a id="_idIndexMarker787"/>will describe the basic commands and operativity, while all configuration options and the <code class="inlineCode">.yaml</code> file configuration formats will be described in a later subsection.</p>
<h2 class="heading-2" id="_idParaDest-192"><a id="_idTextAnchor280"/>Basic commands and operativity</h2>
<p class="normal">All Azure <a id="_idIndexMarker788"/>Container Apps commands start with <code class="inlineCode">az containerapp</code>. Then, there is the main command and various configuration options. Configuration options may be passed each with a different command option or organized in a <code class="inlineCode">.yaml</code> or JSON file.</p>
<div><p class="normal">In a PowerShell console, you can split a command into several lines with the help of the ` (backquote) character, as shown in all the commands in this subsection.</p>
</div>
<p class="normal">The <code class="inlineCode">up</code> command is the simplest way to define an application together with a new environment. It is useful to perform a quick test of a container. The only obligatory parameters are the application name and the container image URL. For all other options, reasonable defaults are assumed. If you don’t specify a resource group and an environment, the command creates new ones:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp up '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --image &lt;REGISTRY_SERVER&gt;/&lt;IMAGE_NAME&gt;:&lt;IMAGE TAG&gt; '
  --ingress external '
  --target-port &lt;PORT NUMBER&gt; '
  --registry-server &lt;REGISTRY SERVER URL&gt; '
  --registry-username &lt;REGISTRY USERNAME&gt; '
  --registry-password &lt;REGISTRY PASSWORD&gt;
</code></pre>
<p class="normal">Let’s <a id="_idIndexMarker789"/>break this down:</p>
<ul>
<li class="bulletList"><code class="inlineCode">name</code> is the application name. It is obligatory.</li>
<li class="bulletList"><code class="inlineCode">image</code> is the container image URL. It is obligatory. As usual, the <code class="inlineCode">image</code> tag is used for image versioning, and if omitted, <code class="inlineCode">latest</code> is assumed.</li>
<li class="bulletList"><code class="inlineCode">ingress</code> may be <code class="inlineCode">internal</code> or <code class="inlineCode">external</code>. In the first case, the application will be accessible only from inside its environment, while in the second case, the application will be exposed to the external world. If this parameter is omitted, the application will not be accessible with a direct link (useful when internal communication relies on a message broker).</li>
<li class="bulletList"><code class="inlineCode">target-port</code> specifies the target port exposed by the container, if any. The application traffic will be redirected to this container port. If there are several containers, there should be just one that receives the application traffic, and you must specify its port. Application HTTP/S traffic must be sent to the usual <code class="inlineCode">80</code> and <code class="inlineCode">443</code> ports.</li>
<li class="bulletList"><code class="inlineCode">registry-server</code>, <code class="inlineCode">registry-username</code>, and <code class="inlineCode">registry-password</code> are parameters that specify the credentials associated with a specific image registry server, which should be the same as used in the <code class="inlineCode">image</code> parameter. If specified, these parameters are added to the application configuration and will be used also in subsequent application updates. Later on, we will see how assigning an Azure identity to an application allows it to access Azure resources by simply granting adequate privileges to this identity with no need to provide passwords.</li>
</ul>
<p class="normal">The preexisting environment and resource group can be specified with the <code class="inlineCode">--environment</code> and <code class="inlineCode">--resource-group</code> options.</p>
<p class="normal">The <code class="inlineCode">up</code> commands can be used to update the application configuration or the application container image, but in this case, you must always pass the <code class="inlineCode">--name</code>, <code class="inlineCode">--environment</code>, and <code class="inlineCode">--resource-group</code> parameters with the values of the preexisting application.</p>
<p class="normal">You can <a id="_idIndexMarker790"/>test the <code class="inlineCode">up</code> command with the simple <code class="inlineCode">gcr.io/google-samples/hello-app:1.0</code> image we used in the <em class="italic">Testing ingresses with minikube </em>subsection of<em class="italic"> </em><a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>. You don’t need to specify registry credentials since the registry is public. The container port is <code class="inlineCode">8080</code>:</p>
<pre class="programlisting con"><code class="hljs-con">az group create '
  --name &lt;resource group name&gt; '
  --location centralus
az containerapp up --name &lt;CONTAINER_APP_NAME&gt; --image gcr.io/google-samples/hello-app:1.0 '
  --resource-group &lt;resource group name&gt; '
  --location centralus '
  --environment &lt;environment name&gt; '
  --ingress external --target-port 8080 '
  --query properties.configuration.ingress.fqdn
</code></pre>
<p class="normal">We previously created a resource group in order to decide its name. We also specified the name of the environment to create. The <code class="inlineCode">--query properties.configuration.ingress.fqdn</code> option lets the command return the application URL, which you might also compute manually with the URL format we gave in the previous section. Once you have tested this simple single HTML page application by going to the application URL with your favorite browser, you can also check all Azure resources created on your Azure portal home page.</p>
<p class="normal">You can get the whole <code class="inlineCode">.yaml</code> config<a id="_idTextAnchor281"/>uration of the application created with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp show '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  -o yaml
</code></pre>
<p class="normal">A good way to arrive at a properly configured application is by starting with default configurations, then getting the <code class="inlineCode">.yaml</code> application configuration with the preceding command, modifying this <code class="inlineCode">.yaml</code> file, and finally, submitting the modified <code class="inlineCode">.yaml</code> file with the <code class="inlineCode">update</code> command, as shown here:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp update '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  --yaml mymodified.yaml
</code></pre>
<div><p class="normal">Each application is univocally identified by both its name and its resource group, so each <code class="inlineCode">update</code> or <code class="inlineCode">delete</code> command must specify both of them.</p>
</div>
<p class="normal">The simplest <a id="_idIndexMarker791"/>way to clean up all resources after the experiment is by deleting the whole resource group, as shown here:</p>
<pre class="programlisting con"><code class="hljs-con">az group delete --name &lt;resource group name&gt;
</code></pre>
<p class="normal">When you need to deploy several applications in the same environment, the best way to proceed is to create the environment first with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp env create '
  --name &lt;CONTAINERAPPS_ENVIRONMENT&gt; '
  --resource-group &lt;RESOURCE_GROUP&gt; '
  --location "&lt;AZURE LOCATION NAME&gt;"
</code></pre>
<p class="normal">If you would like to enable workload profiles on the environment, you must also add the <code class="inlineCode">--enable-workload-profiles</code> option.</p>
<p class="normal">If you want to place all resources involved in your overall microservice application in a new resource group. you need to create it before creating the environment, as follows:</p>
<pre class="programlisting con"><code class="hljs-con">az group create '
  --name &lt;RESOURCE_GROUP&gt; '
  --location "&lt;AZURE LOCATION NAME&gt;"
</code></pre>
<p class="normal">Workload profiles can be added to an environment with the following instruction:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp env workload-profile add '
  --resource-group &lt;RESOURCE_GROUP&gt; '
  --name &lt;ENVIRONMENT_NAME&gt; '
  --workload-profile-type &lt;WORKLOAD_PROFILE_TYPE&gt; <a id="_idTextAnchor282"/>'
  --workload-profile-name &lt;WORKLOAD_PROFILE_NAME&gt; '
  --min-nodes &lt;MIN_INSTANCES&gt; '
  --max-nodes &lt;MAX_INSTANCES&gt;
</code></pre>
<p class="normal">Here, <code class="inlineCode">--workload-profile-name</code> is the name you give to the workload profile, while <code class="inlineCode">--workload-profile-type</code> is a profile type—that is, a type of virtual machine that you can select from the ones listed here: <a href="https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview">https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview</a>. <code class="inlineCode">--min-nodes</code> and <code class="inlineCode">--max-nodes</code> are, respectively, the minimum and maximum instances of the virtual machine that can be created.</p>
<p class="normal">Workload <a id="_idIndexMarker792"/>profiles can also be removed at a later time with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp env workload-profile delete '
  --resource-group "&lt;RESOURCE_GROUP&gt;" '
  --name &lt;ENVIRONMENT_NAME&gt; '
  --workload-profile-name &lt;WORKLOAD_PROFILE_NAME&gt;
</code></pre>
<p class="normal">When the environment is set up, you can deploy all container images in a common registry, and then you can start creating each application with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp create '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --image &lt;REGISTRY_SERVER&gt;/&lt;IMAGE_NAME&gt;:&lt;TAG&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  --environment &lt;ENVIRONMENT_NAME&gt; '
  --ingress &lt;external or internal or omit this option&gt; '
  --target-port &lt;PORT_NUMBER&gt; '
  --registry-server &lt;REGISTRY SERVER URL&gt; '
  --registry-username &lt;REGISTRY USERNAME&gt; '
  --registry-password &lt;REGISTRY PASSWORD&gt;
</code></pre>
<p class="normal">The preceding command creates an application with a default configuration. If you want the application to run in a workload profile instead of the default consumption profile, you must add the <code class="inlineCode">--workload-profile-name &lt;WORKLOAD_PROFILE_NAME&gt;</code> option.</p>
<p class="normal">Then, you can extract its <code class="inlineCode">.yaml</code> and modify it with the following:</p>
<pre class="programlisting con"><code class="hljs-con"> az containerapp show '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  -o yaml
</code></pre>
<p class="normal">You will need to use the preceding code with this code, too:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp update '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  --yaml mymodified.yaml
</code></pre>
<p class="normal">You can <a id="_idIndexMarker793"/>also opt in for immediately specifying a <code class="inlineCode">.yaml</code> file during the application creation, as shown here:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp create '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --environment &lt;ENVIRONMENT_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  --yaml myapp.yaml
</code></pre>
<p class="normal">You can get the list of all application revisions with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp revision list '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP&gt;
</code></pre>
<p class="normal">You can get also all replicas of each revision with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp replica list '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP&gt; '
  --revision &lt;REVISIONNAME&gt;
</code></pre>
<div><p class="normal">You can also get an interactive console in a container of a specific replica of a specific revision, similar to how Kubernetes <code class="inlineCode">exec</code> works:</p>
</div>
<pre class="programlisting con"><code class="hljs-con">az containerapp exec `
  --name &lt;CONTAINER_APP_NAME&gt; `
  --resource-group &lt;RESOURCE_GROUP&gt; `
  --revision &lt;REVISION_NAME&gt; `
  --replica &lt;REPLICA_NAME&gt;
</code></pre>
<div><p class="normal">If there are several containers, you can specify the container name with the <code class="inlineCode">--container</code> option.</p>
</div>
<p class="normal">You can delete an application with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp delete '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt;
</code></pre>
<p class="normal">You can delete a whole environment and all the applications it contains with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp env delete '
  --name &lt;ENVIRONMENT_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt;
</code></pre>
<p class="normal">These commands <a id="_idIndexMarker794"/>cover most of the practical use cases. Other options and commands can be found in the official command reference at <a href="https://learn.microsoft.com/it-it/cli/azure/containerapp?view=azure-cli-latest">https://learn.microsoft.com/it-it/cli/azure/containerapp?view=azure-cli-latest</a>. In the next subsection, we will describe how to configure your application with a <code class="inlineCode">.yaml</code> file.</p>
<h2 class="heading-2" id="_idParaDest-193"><a id="_idTextAnchor283"/>Application configuration options and the .yaml format</h2>
<p class="normal">The simplest <a id="_idIndexMarker795"/>way to customize the <a id="_idIndexMarker796"/>application configuration is with a <code class="inlineCode">.yaml</code> file passed to the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp update '
  --name &lt;CONTAINER_APP_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  --yaml myappconfiguration.yaml
</code></pre>
<p class="normal">The organization of an application <code class="inlineCode">.yaml</code> file is shown here:</p>
<pre class="programlisting code"><code class="hljs-code">identity:
...
properties:
environmentId: "/subscriptions/&lt;subscription_id&gt;/resourceGroups/….."
workloadProfileName: My-GP-01
configuration:
ingress:
…
maxInactiveRevisions: 10
secrets:
- name: &lt;nome&gt;
value: &lt;valore&gt;
registries:
- server: &lt;server URL&gt;
username: &lt;user name&gt;
passwordSecretRef: &lt;name of the secret that contains the password&gt;
- server: &lt;server URL&gt;
identity: &lt;application identity resource id&gt;
template:
containers:
- …
initContainers:
- ...
scale:
minReplicas: 1
maxReplicas: 5
rules:
- ...
volumes:
- ...
</code></pre>
<p class="normal">Let’s <a id="_idIndexMarker797"/>break this down:</p>
<ul>
<li class="bulletList">The <code class="inlineCode">identity</code> section is present only if the application has been attached to an Azure <a id="_idIndexMarker798"/>identity for handling its access to other resources without passwords.</li>
<li class="bulletList"><code class="inlineCode">environmentId</code> is the Azure unique ID of the environment the application is in (don’t confuse it with the environment name). The simplest way to get this and other values is by creating an application with default values and then showing its <code class="inlineCode">.yaml</code> file.</li>
<li class="bulletList"><code class="inlineCode">workloadProfileName</code> is present only if the application is associated with a workload profile and contains the workload profile name.</li>
<li class="bulletList">The <code class="inlineCode">ingress</code> section is present only if the application must be accessible with a direct link from inside or outside its environment. It contains all its direct communication-related properties, CORS settings, and traffic splitting between versions.</li>
<li class="bulletList"><code class="inlineCode">maxInactiveRevisions</code> is the number of previous revisions that are saved and can be activated. The default is 100.</li>
<li class="bulletList">The <code class="inlineCode">registries</code> section contains information about registries that must be accessed with credentials. Registries that are not private and don’t need credentials should not be listed here. Each entry specifies either the registry username and password or an Azure identity with permission to access the registry. The identity must be listed in the i<code class="inlineCode">dentity</code> section. For more details, see the <em class="italic">Associating an Azure identity to your application</em> section.</li>
<li class="bulletList"><code class="inlineCode">secrets</code> are name-value pairs that are stored safely. They are equivalent to Kubernetes generic secrets.</li>
<li class="bulletList">As in Kubernetes, we have <code class="inlineCode">containers</code> and <code class="inlineCode">initContainers</code>. <code class="inlineCode">initContainers</code> work the same as in Kubernetes, but there is no way to declare <code class="inlineCode">sidecar</code> containers, so <code class="inlineCode">sidecar</code> containers must be included among the standard containers.</li>
<li class="bulletList">The <code class="inlineCode">scale</code> section contains the minimum and maximum number of application replicas <a id="_idIndexMarker799"/>and rules for deciding the exact number <a id="_idIndexMarker800"/>of replicas. The most common rules decide the number of replicas trying to maintain a target number of HTTP requests or TCP/IP connections per replica:
        <pre class="programlisting con-one"><code class="hljs-con">- name: my-http-rule,
  http:
      metadata:
            concurrentRequests: 100
- name: my-tcp-rule,
  tcp:
      metadata:
            concurrentConnections: 100
</code></pre>
</li>
<li class="bulletList">Finally, we have a <code class="inlineCode">volumes</code> section that declares all volumes mounted by containers. As in Kubernetes, they are referred to by a <code class="inlineCode">volumeMounts</code> section inside the container definitions.</li>
</ul>
<p class="normal">All properties that were not fully specified in the previous <code class="inlineCode">.yaml</code> file will be described in a separate subsection. Let’s start with containers.</p>
<h3 class="heading-3" id="_idParaDest-194"><a id="_idTextAnchor284"/>Container configuration</h3>
<p class="normal">The <a id="_idIndexMarker801"/>configuration of each container is <a id="_idIndexMarker802"/>similar to the one in Kubernetes but there are some simplifications. The schema is shown here:</p>
<pre class="programlisting code"><code class="hljs-code"> - image: &lt;IMAGE URL&gt;:&lt;TAG&gt;
name: &lt;CONTAINER NAME&gt;
env:
- name: &lt;variable name&gt;
value: &lt;variable name&gt;
- name: &lt;variable name&gt;
secretRef: &lt;secret name&gt;
resources:
cpu: 0.2
memory: 100Mi
probes:
- type: liveness
…
- type: readiness
…
- type: startup
…
volumeMounts:
- mountPath: /mypath
volumeName: myvolume
</code></pre>
<p class="normal"><code class="inlineCode">image</code> and <code class="inlineCode">name</code> are identical to the Kubernetes configuration.</p>
<p class="normal">Environment <a id="_idIndexMarker803"/>variables can be defined either as name-value pairs or as <code class="inlineCode">name</code>-<code class="inlineCode">secretRef</code> pairs, where <code class="inlineCode">secretRef</code> contains the name of a secret defined in the <code class="inlineCode">secrets</code> section. In the second case, the variable value is the value of the secret.</p>
<p class="normal"><code class="inlineCode">volumeMounts</code> is similar to Kubernetes, too. The only difference is that the volume name is called <code class="inlineCode">name</code> in Kubernetes while, here, it is called <code class="inlineCode">volumeName</code>.</p>
<p class="normal">The Kubernetes <code class="inlineCode">resources</code> property has two properties, <code class="inlineCode">requests</code> and <code class="inlineCode">limits</code>, while here we have <a id="_idIndexMarker804"/>just a couple of values that correspond to the Kubernetes <code class="inlineCode">requests</code> property. This means that we cannot specify <code class="inlineCode">resources</code> limits as in Kubernetes. The reason behind this choice is probably connected to the serverless nature of Azure Container Apps. The meanings and units of measure of both <code class="inlineCode">cpu</code> and <code class="inlineCode">memory</code> are the same as in Kubernetes.</p>
<p class="normal">As you can see, liveness, readiness, and startup probes are defined in slightly different ways but their meaning is the same as in Kubernetes. The syntax and meaning of the properties after <code class="inlineCode">type: liveness/readiness/startup</code> is identical to the corresponding Kubernetes configuration.</p>
<p class="normal">Let’s move on to the <code class="inlineCode">ingress</code> configuration.</p>
<h3 class="heading-3" id="_idParaDest-195"><a id="_idTextAnchor285"/>The ingress configuration</h3>
<p class="normal">The <code class="inlineCode">ingress</code> configuration <a id="_idIndexMarker805"/>mixes some <a id="_idIndexMarker806"/>Kubernetes <code class="inlineCode">Service</code> and <code class="inlineCode">Ingress</code> settings with the traffic splitting between various revisions, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code"> ingress:
external: true
targetPort: 3000
# only for TCP communication. HTTP/S always use 80 and 443 ports
exposedPort: 5000
allowInsecure: false # false or true
clientCertificateMode: accept # accept required or ignore
corsPolicy:
allowCredentials: true
maxAge: 5000 (pre-flight caching time in seconds)
allowedOrigins:
- "https://example.com"
allowedMethods:
- "GET"
- "POST"
…
allowedHeaders: []
        exposeHeaders: []
      traffic:
- weight: 100
revisionName: testcontainerApp0-ab1234
label: production
stickySessions:
affinity: sticky
</code></pre>
<p class="normal">Let’s <a id="_idIndexMarker807"/>break this down:</p>
<ul>
<li class="bulletList"><code class="inlineCode">external</code> must be set to <code class="inlineCode">true</code> to expose the application to the outside world, otherwise, to <code class="inlineCode">false</code>.</li>
<li class="bulletList"><code class="inlineCode">targetPort</code> is the <a id="_idIndexMarker808"/>container port to which to rou<a id="_idTextAnchor286"/>te the application traffic.</li>
<li class="bulletList"><code class="inlineCode">exposedPort</code> must be used only in case of non-HTTP/S traffic. It sets the application listening port. All traffic received on this port is routed to <code class="inlineCode">targetPort</code>. The <code class="inlineCode">exposedPort</code> ports of applications exposed to the outside world must be unique inside the environment.</li>
<li class="bulletList">HTTP/S traffic, instead, always uses the usual <code class="inlineCode">80</code> and <code class="inlineCode">443</code> ports with no customization possibilities.</li>
<li class="bulletList">If <code class="inlineCode">allowInsecure</code> is <code class="inlineCode">false</code>, HTTP traffic is automatically redirected to HTTPS. The default is <code class="inlineCode">true</code>.</li>
<li class="bulletList"><code class="inlineCode">clientCertificateMode</code> specifies whether TCP/IP client certificates are accepted for authentication. This setting is completely analogous to a similar setting exposed by Kestrel. If set to <code class="inlineCode">accept</code>, client certificates are accepted and processed. If set to <code class="inlineCode">required</code>, client certificates are obligatory, and if not provided, the connection is refused. If set to <code class="inlineCode">ignore</code>, client certificates are completely ignored.</li>
<li class="bulletList"><code class="inlineCode">corsPolicy</code> contains standard web server CORS settings, which are the same as those supported by ASP.NET Core. For completeness, we describe all the CORS settings here:<ul>
<li class="bulletList level-2">If <code class="inlineCode">allowCredentials</code> is set to <code class="inlineCode">false</code>, CORS requests containing credentials are refused. The default is <code class="inlineCode">false</code>.</li>
<li class="bulletList level-2"><code class="inlineCode">maxAge</code> specifies the caching time of the pre-flight request. The pre-flight request has the only purpose of verifying whether a CORS request will be accepted before sending actual data.</li>
<li class="bulletList level-2"><code class="inlineCode">allowedOrigins</code> and <code class="inlineCode">allowedMethods</code> specify, respectively, the origin domains from which to accept CORS requests and the accepted HTTP verbs.</li>
<li class="bulletList level-2">Regarding <code class="inlineCode">allowedHeaders</code>, as a default, only some safe <code class="inlineCode">requests</code> headers are allowed. This setting adds further <code class="inlineCode">requests</code> headers to the ones accepted.</li>
<li class="bulletList level-2">Regarding <code class="inlineCode">exposeHeaders</code>, as a default, only some safe <code class="inlineCode">response</code> headers are exposed in the responses to CORS requests. This setting adds further headers to the ones allowed.</li>
</ul>
</li>
<li class="bulletList"><code class="inlineCode">traffic</code> specifies the traffic splitting among various revisions. If a revision is listed with a <code class="inlineCode">0</code> split, it will receive no application traffic but it will be set to active—that is, it can be reached with its revision-specific links. All labels added to an active revision must be specified here.</li>
</ul>
<p class="normal">While <a id="_idIndexMarker809"/>revision handling can be done by <a id="_idIndexMarker810"/>modifying the <code class="inlineCode">traffic</code> section, it is more practical to handle it with ad hoc commands.</p>
<p class="normal">The list of all revisions in table format for a given application can be obtained with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp revision list '
  --name &lt;APPLICATION_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  -o table
</code></pre>
<p class="normal">Details about a specific revision can be obtained with the following:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp revision show '
  --name &lt;APPLICATION_NAME&gt; '
  --revision &lt;REVISION_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt;
</code></pre>
<p class="normal">Labels can be attached or detached from a specific revision with the following commands:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp revision label &lt;add or remove&gt; '
  --revision &lt;REVISION_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  --label &lt;LABEL_NAME&gt;
</code></pre>
<p class="normal">An application <a id="_idIndexMarker811"/>can be switched from single revision mode to multiple <a id="_idIndexMarker812"/>revision mode, and vice versa, with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp revision set-mode '
  --name &lt;APPLICATION_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt; '
  --mode &lt;single or multiple&gt;
</code></pre>
<p class="normal">A given revision can be activated, deactivated, or restarted with the following commands:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp revision &lt;activate or deactivate or restart&gt; '
  --revision &lt;REVISION_NAME&gt; '
  --resource-group &lt;RESOURCE_GROUP_NAME&gt;
</code></pre>
<p class="normal">Finally, traffic splitting between revisions can be changed with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp ingress traffic set \
    --name &lt;APP_NAME&gt; \
    --resource-group &lt;RESOURCE_GROUP&gt; \
    --label-weight &lt;LABEL_1&gt;=80 &lt;LABEL_2&gt;=20 …
</code></pre>
<p class="normal">The next section focuses on how to define volumes in the <code class="inlineCode">volumes</code> section.</p>
<h3 class="heading-3" id="_idParaDest-196"><a id="_idTextAnchor287"/>Volume definition and allocation</h3>
<p class="normal">Volumes <a id="_idIndexMarker813"/>can be either <code class="inlineCode">EmptyDir</code> (which works <a id="_idIndexMarker814"/>in the same way as Kubernetes <code class="inlineCode">EmptyDir</code>) or file <a id="_idIndexMarker815"/>shares taken from Azure Files, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code"> volumes:
- name: myempty
storageType: EmptyDir
- name: my-azure-files-volume
storageType: AzureFile
storageName: mystorage
</code></pre>
<p class="normal">Here, <code class="inlineCode">mystorage</code> is the name of a file share you created and attached to the environment. Therefore, you must execute the following steps to get <code class="inlineCode">mystorage</code>:</p>
<ol>
<li class="numberedList" value="1">Define <a id="_idIndexMarker816"/>a storage account if you don’t have it:
        <pre class="programlisting con-one"><code class="hljs-con">az storage account create '
  --resource-group &lt;RESOURCE GROUP &gt; '
  --nam<a id="_idTextAnchor288"/>e &lt;STORAGE ACCOUNT NAME&gt; '
  --location &lt;AZURE LOCATION &gt; '
  --kind StorageV2 ' 🡨 type (generic usage type)
  --sku Standard_LRS ' 🡨 performance level (this is a standard level)
  --enable-large-file-share '
  --query provisioningState 🡨 returns the provisioning state
</code></pre>
</li>
<li class="numberedList">Define a file share:
        <pre class="programlisting con-one"><code class="hljs-con">az storage share-rm create '
  --resource-group &lt;RESOURCE GROUP&gt; '
  --storage-account &lt;STORAGE ACCOUNT NAME&gt;'
  --name &lt;STORAGE SHARE NAME&gt; '
  --quota 1024 ' 🡨 megabyte to share
  --enabled-protocols SMB ' 🡨 SMB or NFS, SMB is usually better
  --output table 🡨 return information on the created share in table format
</code></pre>
</li>
<li class="numberedList">Get the credentials to access the storage account:
        <pre class="programlisting con-one"><code class="hljs-con">STORAGE_ACCOUNT_KEY='az storage account keys list -n &lt;STORAGE ACCOUNT NAME&gt; --query "[0].value" -o tsv'
</code></pre>
</li>
<li class="numberedList">Add a file share name to the environment:
        <pre class="programlisting con-one"><code class="hljs-con">az containerapp env storage set '
  --access-mode ReadWrite '
  --azure-file-account-name &lt;STORAGE ACCOUNT NAME&gt; '
  --azure-file-account-key $STORAGE_ACCOU<a id="_idTextAnchor289"/>NT_KEY '
  --azure-file-share-name &lt;STORAGE SHARE NAME&gt; '
  --storage-name &lt;STORAGE_MOUNT_NAME&gt; '
  --name &lt;ENVIRONMENT NAME&gt; '
  --resource-group &lt;RESOURCE GROUP&gt; '
  --output table 🡨 return details in table format
</code></pre>
</li>
</ol>
<p class="normal">Now, you <a id="_idIndexMarker817"/>can define the volume in your application using the <code class="inlineCode">--storage-name</code> value passed to the last command, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code"> - name: my-azure-files-volume
storageType: AzureFile
storageName: &lt;STORAGE MOUNT NAME&gt;
</code></pre>
<p class="normal">The next subsection explains how to associate an Azure identity to an application, thus enabling it to access Azure resources.</p>
<h2 class="heading-2" id="_idParaDest-197"><a id="_idTextAnchor290"/>Associating an Azure identity to your application</h2>
<p class="normal">The Azure identity to associate with an application can be automatically generated and handled <a id="_idIndexMarker818"/>by Azure or can be defined manually. The main advantage of using a user-defined identity is that you can add the same identity to several applications.</p>
<p class="normal">Adding a system-assigned identity to an application is very easy:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp identity assign '
--name my-container-app '
--resource-group my-container-app-rg '
--system-assigned
</code></pre>
<p class="normal">The preceding command returns the Azure resource ID of the created identity. A system-assigned identity can be associated with the application also by adding <code class="inlineCode">type: SystemAssigned</code> to the <code class="inlineCode">identity</code> section of the application’s <code class="inlineCode">.yaml</code> file, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">identity:
type: SystemAssigned
</code></pre>
<p class="normal">A user-defined identity must be created first and then assigned to the application, so adding a user-defined identity requires two steps.</p>
<p class="normal">The identity can be created with the simple command shown here:</p>
<pre class="programlisting con"><code class="hljs-con">az identity create --resource-group &lt;GROUP_NAME&gt; --name &lt;IDENTITY_NAME&gt; --output json
</code></pre>
<p class="normal">The <code class="inlineCode">--output json</code> option forces the command to return information about the created identity in JSON format. The returned JSON object contains the Azure resource ID of the created identity. You need it to associate the identity with your applications using the following command:</p>
<pre class="programlisting con"><code class="hljs-con">Az containerapp identi<a id="_idTextAnchor291"/>ty assign --resource-group &lt;GROUP_NAME&gt; --name &lt;APP_NAME&gt; '
--user-assigned &lt;IDENTITY RESOURCE ID&gt;
</code></pre>
<p class="normal">The last step can be performed b<a id="_idTextAnchor292"/>y adding the resource ID of one or more identities directly to the <code class="inlineCode">identity</code> section of the application’s <code class="inlineCode">.yaml</code> files, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">identity:
type: UserAssigned
userAssignedIdentities:
&lt;IDENTITY1_RESOURCE_ID&gt;: {}
        &lt;IDENTITY2_RESOURCE_ID&gt;: {}
</code></pre>
<p class="normal">As an example, let’s see how to enable a created identity to access an Azure container registry. This way, we can <a id="_idIndexMarker819"/>avoid storing registry credentials in the application’s <code class="inlineCode">.yaml</code> file.</p>
<p class="normal">First of all, we need the container registry resource ID. We can get it with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az acr show --name &lt;REGISTRY NAME&gt; --query id --output tsv
</code></pre>
<p class="normal">Then, we can assign the <code class="inlineCode">AcrPull</code> role on our container registry to our identity with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">az role assignment create '
--assignee &lt;IDENTITY RESOURCE ID&gt; '
--role AcrPull '
--scope &lt;ACR_RESOURCE_ID&gt;
</code></pre>
<p class="normal">Finally, we must inform the application that it can use its system-assigned or user-assigned identity to access the registry:</p>
<pre class="programlisting con"><code class="hljs-con">az containerapp registry set '
--name my-container-app '
--resource-group my-container-app-rg '
--server &lt;ACR_NAME&gt;.azurecr.io '
--identity system 🡨 system if system assigned or the id of the user defined identity
</code></pre>
<p class="normal">The last step can also be performed by adding an entry to the <code class="inlineCode">registries</code> section of the application’s <code class="inlineCode">.yaml</code> files, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">- server: &lt;server URL&gt;
identity: &lt;application identity resource id&gt;
</code></pre>
<p class="normal">We have finished our Azure Container Apps trip. We will return to Azure Container Apps in <a href="Chapter_12.xhtml#_idTextAnchor345"><em class="italic">Chapter 12</em></a>, <em class="italic">Simplifying Microservices with .NET Aspire</em>, where we will see how to automatically <a id="_idIndexMarker820"/>create all instructions to deploy a whole microservice application to Azure Container Apps, and we will use the book case study application as an example.</p>
<p class="normal">Our description of Azure Container Apps is fundamentally complete and covers 95% of practical Azure <a id="_idIndexMarker821"/>Container Apps operativity. More details can be found in the official documentation at <a href="https://learn.microsoft.com/en-us/azure/container-apps/">https://learn.microsoft.com/en-us/azure/container-apps/</a>.</p>
<p class="normal">The next chapter focuses on the security and observability of the microservice application.</p>
<h1 class="heading-1" id="_idParaDest-198"><a id="_idTextAnchor293"/>Summary</h1>
<p class="normal">This chapter described Kubernetes-related tools that facilitate the administration and coding of distributed applications and then focused on Azure Container Apps.</p>
<p class="normal">We described the basic ideas behind the Azure Container Apps offering, including its fundamental concepts and principles. Then, we described the available plans and how to interact with Azure Container Apps through the Azure portal.</p>
<p class="normal">In particular, we described the main commands and the<code class="inlineCode">.yaml</code> format that defines a whole application. We showed how all resources in Kubernetes are implemented in Azure Container Apps and compared the two approaches.</p>
<h1 class="heading-1" id="_idParaDest-199"><a id="_idTextAnchor294"/>Questions</h1>
<ol>
<li class="numberedList" value="1">Is it true that environments are equivalent to Kubernetes namespaces?</li>
</ol>
<p class="normal-one">They are similar but not equivalent.</p>
<ol>
<li class="numberedList" value="2">How does Helm simplify the deployment of Kubernetes applications and tools?</li>
</ol>
<p class="normal-one">Because it allows the simultaneous deployment of several yaml files which can be configured according to selected options and parameters.</p>
<ol>
<li class="numberedList" value="3">What are Prometheus and Grafana?</li>
</ol>
<p class="normal-one">They’re administrative tools that collect metrics, and other information and present them to the user.</p>
<ol>
<li class="numberedList" value="4">Can you describe the URL composition of an Azure Container Apps application exposed to the external world?</li>
</ol>
<p class="normal-one"><code class="inlineCode">&lt;application name&gt;.&lt;Environment name&gt;.&lt;zone&gt;.azurecontainerapps.io</code></p>
<ol>
<li class="numberedList" value="5">Do environments provide access to all properties of their underlying networks?</li>
</ol>
<p class="normal-one">No.</p>
<ol>
<li class="numberedList" value="6">Which kinds of Azure identities can be associated with Azure Container Apps?</li>
</ol>
<p class="normal-one">User defined and System Assigned.</p>
<ol>
<li class="numberedList" value="7">Is it true that, in Azure Container Apps, Azure file storage allocation is automatic (as in Kubernetes) and requires just the declaration of volumes in the <code class="inlineCode">volumes</code> section of the application’s <code class="inlineCode">.yaml</code> file?</li>
</ol>
<p class="normal-one">No.</p>
<ol>
<li class="numberedList" value="8">Is it possible to deploy an Azure Container Apps application with a single Azure console command without filling in any configuration file?</li>
</ol>
<p class="normal-one">Yes, in several ways.</p>
<ol>
<li class="numberedList" value="9">In which section of an Azure Container Apps <code class="inlineCode">.yaml</code> file can you define traffic splitting between revisions?</li>
</ol>
<p class="normal-one"><code class="inlineCode">ingress-&gt;traffic</code></p>
<ol>
<li class="numberedList" value="10">Can the port where an Azure Container Apps application listens to HTTP/S requests be customized?</li>
</ol>
<p class="normal-one">No.</p>
<h1 class="heading-1" id="_idParaDest-200"><a id="_idTextAnchor295"/>Further reading</h1>
<ul>
<li class="bulletList">More information on Helm and Helm charts can be found in the official documentation. This is extremely well written and contains some good tutorials: <a href="https://helm.sh/">https://helm.sh/</a>.</li>
<li class="bulletList">Grafana dashboards: <a href="https://grafana.com/grafana/dashboards/">https://grafana.com/grafana/dashboards/</a>.</li>
<li class="bulletList">ArgoCD: <a href="https://argo-cd.readthedocs.io/en/stable/">https://argo-cd.readthedocs.io/en/stable/</a></li>
<li class="bulletList">Rancher UI: <a href="https://ranchermanager.docs.rancher.com/ ">https://ranchermanager.docs.rancher.com/</a></li>
<li class="bulletList">OpenShift: <a href="https://www.redhat.com/en/technologies/cloud-computing/openshift">https://www.redhat.com/en/technologies/cloud-computing/openshift</a>.</li>
<li class="bulletList">Azure OpenShift: <a href="https://azure.microsoft.com/it-it/products/openshift">https://azure.microsoft.com/it-it/products/openshift</a>.</li>
<li class="bulletList">Azure Container Apps pricing: <a href="https://azure.microsoft.com/en-us/pricing/details/container-apps/">https://azure.microsoft.com/en-us/pricing/details/container-apps/</a>.</li>
<li class="bulletList">Azure Container Apps custom profiles: <a href="https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview">https://learn.microsoft.com/en-us/azure/container-apps/workload-profiles-overview</a></li>
<li class="bulletList">Azure Container Apps official documentation: <a href="https://learn.microsoft.com/en-us/azure/container-apps/">https://learn.microsoft.com/en-us/azure/container-apps/</a>.</li>
<li class="bulletList">Azure Container Apps commands reference: <a href="https://learn.microsoft.com/it-it/cli/azure/containerapp?view=azure-cli-latest">https://learn.microsoft.com/it-it/cli/azure/containerapp?view=azure-cli-latest</a>.</li>
</ul>
<h1 class="heading-1" id="_idParaDest-201"><a id="_idTextAnchor296"/>Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
<p class="normal"><a href="https://packt.link/PSMCSharp">https://packt.link/PSMCSharp</a></p>
<p class="normal"><img alt="A qr code with black squares  AI-generated content may be incorrect." src="img/B31916_Discord-QR-Code.png"/></p>
</div>
</body></html>