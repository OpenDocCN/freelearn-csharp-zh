- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Profiling and Identifying Bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As your minimal API project evolves, the potential for performance bottlenecks
    increases. Working with data, making connections over networks, and running business
    logic and calculations – all these activities have a performance cost. If configured
    the wrong way, these activities could incur a higher than necessary cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to explore strategies for analyzing resource
    utilization, identifying common bottlenecks, and implementing them. We will cover
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to profiling and performance monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling tools and techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common performance bottlenecks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need Visual Studio 2022 or Visual Studio code running, at minimum,
    a new ASP.NET core minimal API project. It is recommended to use the code from
    the previous chapter, as we will be working with performance examples within the
    context of the **MyCompany** API project. Because the examples in this chapter
    are run against the code examples in [*Chapter 10*](B20968_10.xhtml#_idTextAnchor154)
    , you will need to have Entity Framework installed as per the instructions in
    the previous chapter. (See the *Configuring Entity Framework in minimal API projects*
    section in [*Chapter 9*](B20968_09.xhtml#_idTextAnchor143) .)
  prefs: []
  type: TYPE_NORMAL
- en: An introduction to profiling and performance monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the beginning of this chapter, we established that the code we run in a minimal
    API application will incur performance costs, some of which could be presented
    as bottlenecks, hampering the efficiency of the overall system. To remedy this,
    we can leverage a profiling tool, also known as a profiler.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the profiler
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A **profiler** is a piece of software that measures the cost of running code.
    While your API application runs, the profiler will provide telemetry that outlines
    how expensive certain areas of the code base are in terms of resource usage. This
    allows us to identify areas of inefficiency, which is critical to optimizing the
    performance of your minimal API applications. This is an important practice for
    many reasons, not limited to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalability** : The ability to ensure that your code will be able to perform
    at an increasing rate of demand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Availability** : Access to the API to outside clients is paramount. If clients
    cannot access the API because of a lack of available hardware resources, the application
    has lost availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security** : The connection between the client and API should not be open
    for any longer than necessary. If your API takes a long time to complete a request,
    the connection is open for longer, leaving more opportunities for malicious activity
    to occur.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost** : The financial cost of not optimizing a system can be severe. If
    production servers frequently require upgrades because of software bottlenecks,
    each scale-up of the hardware incurs financial costs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User experience** : Ensuring that your API runs as quickly as possible ensures
    that people will have a positive experience, securing repeat usage of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Error detection** : While profiling allows for the detection of bottlenecks,
    it can also indirectly reveal other bugs in the code base that may not have been
    detected by unit or integration testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Along the same vein, the advantages of profiling minimal APIs are considerable:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Latency reduction** : With profiling, response times can be increased, resulting
    in a much more responsive API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Optimal hardware usage** : Profiling can help you see where you are overconsuming
    resources such as CPU, memory, and I/O.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Preventative measures** : Running a profiler to identify potential optimizations
    allows developers to get ahead of potential future issues, letting them make planned
    changes rather than reactionary ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maintenance** : Overall, a more performant code base is usually easier to
    maintain. If the minimal API application is easy to maintain, it will likely see
    a more frequent release cadence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let’s look at some performance metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Performance metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before releasing an application for general use, it is difficult to predict
    how an API will cope under heavy load in an accurate way without performing stress
    testing and gathering the resulting data. **Performance monitoring** can help
    by providing insights into how your code is performing in specific scenarios.
    This data in the form of metrics can inform how you optimize your code as you
    approach release. One of the key things you need to understand from performance
    metrics is how the resources on the machine hosting the API handle a high volume
    of requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Profiling can monitor various resources within a minimal API and its dependencies,
    including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Response times** : The amount of time it takes for a request to be handled
    by the API, with a response being returning the client.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Throughput** : The volume of data flowing through a connection at any given
    time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CPU processing** : The amount of processing being completed by the API host’s
    CPU during requests, or even on other background tasks not related to a client
    request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory** : The amount of RAM being consumed by the application at any given
    time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having access to metrics allows us to start identifying potential bottlenecks
    so that we can then take steps to address them in the minimal API code.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the profiler might show a sudden increase in CPU usage during a
    particular operation. This may indicate that the operation is written in a sub-optimal
    way (e.g., an unnecessary loop or iteration over a collection).
  prefs: []
  type: TYPE_NORMAL
- en: With some understanding of profiling and performance monitoring, let’s take
    a look at some tools and techniques for the former.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling tools and techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are many different profiling tools available, but for the purposes of
    developing minimal APIs in ASP.NET, we will be looking at two examples: the Visual
    Studio profiler and BenchmarkDotNet. The former is a GUI-based tool, whereas the
    latter is a library that we can add as a dependency to our project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each of these tools has its strengths in particular use cases, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Visual Studio profiler** : It is integrated into the IDE and provides
    live performance data and CPU and memory metrics. It is ideal for capturing a
    quick profile, performing basic performance analysis, and identifying areas of
    high CPU and memory usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BenchmarkDotNet** : It can be installed as a package within a .NET project
    and is adept at micro-benchmarking. It is used for establishing baseline performance
    and the fine-tuning of code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are several other potential choices that are not free, such as dotTrace
    by JetBrains, which is a very competent profiler that can provide the usual resource
    consumption metrics along with some very in-depth views of the call tree and events
    over a timeline. I can certainly recommend dotTrace, but as it is not free, we
    will keep things simple by exploring profiling examples in the Visual Studio profiler
    and BenchmarkDotNet.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling in Visual Studio
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let us start by setting up profiling in Visual Studio:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the **MyCompany** API example in Visual Studio. Then, click **Debug** ,
    and select **Performance Profiler** . You will see several different options on
    the screen for various kinds of profiling. For this example, we are going to profile
    CPU usage to demonstrate profiling.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Tick **CPU Usage** and click **Start** .
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.1: The profiling configuration screen](img/B20968_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.1: The profiling configuration screen'
  prefs: []
  type: TYPE_NORMAL
- en: The aim will be to start profiling so that it is capturing CPU usage data in
    the background while we are interacting with the API. Once the application stops,
    a report will be generated that will give us a breakdown of CPU usage over time,
    which we can then track back to specific lines of code.
  prefs: []
  type: TYPE_NORMAL
- en: After starting the profiler (ensure that it is recording) your API project will
    also start running. Interact with the API by calling the **GetEmployeeById** endpoint,
    passing an ID value for an existing employee record. You will notice when you
    make the request that the profiler updates in real time. You should see an increase
    in CPU usage as soon as the request starts, which settles down again once the
    request has completed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once you have made some requests to the API, click the **Stop Collection** button
    in the top-left corner of the screen, and then click the **CPU Usage** tab (around
    a quarter of the way down the screen toward the left). The result should be a
    diagnostic report showing the peaks and dips in CPU usage across the time being
    profiled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.2: The profiler report for CPU usage](img/B20968_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.2: The profiler report for CPU usage'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in *Figure 10* *.2* , there was a spike in CPU usage at the beginning
    of the profiling session. This was at the point that a **GET** request was made
    to the **employees** endpoint, with the API handling the request by returning
    an **Employee** object with the given ID.
  prefs: []
  type: TYPE_NORMAL
- en: There is a wealth of information that can be filtered in this view. Suffice
    it to say, a whole book could be written on profiling in .NET alone. However,
    by way of example, click the **Open Details** button toward the top-right corner
    of the **CPU** **Usage** pane.
  prefs: []
  type: TYPE_NORMAL
- en: The details shown on the screen following this will provide more detailed information
    about the code that consumes various percentage levels of CPU for the given time.
    There are several key views, such as the **Call Tree** view, which shows the nested
    relationships between function and method calls (i.e., *what* *called what* ).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3: The Call Tree view, showing the CPU consumed by functions at
    each level of the tree](img/B20968_10_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.3: The Call Tree view, showing the CPU consumed by functions at each
    level of the tree'
  prefs: []
  type: TYPE_NORMAL
- en: The **Functions** view is quite useful in the sense that it can be used to identify
    which specific lines of code are consuming higher amounts of CPU. By sorting this
    view by **Total CPU% descending** , you can quickly identify the top consumer
    of CPU. This can be beneficial when performing optimization on a minimal API,
    as you can gain insights into the underlying functions’ impact on an endpoint’s
    response time for example.
  prefs: []
  type: TYPE_NORMAL
- en: What is more, any of the entries in this view can be double-clicked to reveal
    the original source code, with the CPU usage annotated next to the function signature.
  prefs: []
  type: TYPE_NORMAL
- en: The **Caller/Callee** view, which demonstrated what functions are called by
    and what they themselves call, is particularly insightful in this request.
  prefs: []
  type: TYPE_NORMAL
- en: Take the example in *Figure 10* *.4* . We can see that for the current function
    in **EmployeeService** , **GetEmployeeById()** , the CPU resource was consumed
    at **51.42%** . Going deeper, we can see that the function is called into a method
    within Entity Framework Core. In this case, the function was **FirstOrDefault()**
    .
  prefs: []
  type: TYPE_NORMAL
- en: '**FirstOrDefault()** is a **Language Integrated Query** ( **LINQ** ) feature
    that will get the first item in a collection that meets the given condition, or
    it will return a default value, in this case, **null** .'
  prefs: []
  type: TYPE_NORMAL
- en: What we can see in *Figure 10* *.4* is that of the **51.42%** of CPU usage consumed
    by **GetEmployeeById()** , **50.34%** of that usage was taken up by **FirstOrDefault()**
    ; don’t be surprised if the value you get for the same profiling differs. This
    value should and would vary between machines. The important thing is that you
    are able to see a spike in usage.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4: The Caller/Callee view, demonstrating the breakdown of CPU usage
    for the GetEmployeeById() function](img/B20968_10_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.4: The Caller/Callee view, demonstrating the breakdown of CPU usage
    for the GetEmployeeById() function'
  prefs: []
  type: TYPE_NORMAL
- en: This result demonstrates the percentage of CPU usage spread across each function.
    On its own, this does not necessarily indicate a bottleneck, but it is useful
    information when troubleshooting performance or for general optimization.
  prefs: []
  type: TYPE_NORMAL
- en: We could dig into this further by replacing **FirstOrDefault()** with our own
    custom implementation of a loop for finding the first employee with the matching
    ID.
  prefs: []
  type: TYPE_NORMAL
- en: 'The loop would look like the example here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: If we run this loop in place of **FirstOrDefault()** , we can check the same
    profiling capture and compare the CPU usage.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, when running the updated code using a loop, we saw a minor increase
    in CPU usage compared to **FirstOrDefault()** . So, while **FirstOrDefault()**
    is not confirmed to be the most performant method of retrieving **Employee** for
    the calling API endpoint, it is confirmed that our alternative is not as performant.
    This is a process of elimination technique, which is an exercise worth practicing
    across your whole code base.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5: CPU usage for GetEmployeeById() using a foreach loop instead
    of FirstOrDefault()](img/B20968_10_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10.5: CPU usage for GetEmployeeById() using a foreach loop instead of
    FirstOrDefault()'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, we could go much further into the Visual Studio profiler,
    but that is beyond the scope of this book. With this foundation, you should now
    have at least one item in your toolset for optimizing minimal APIs. Let us look
    at another useful tool for analyzing API performance – BenchmarkDotNet.
  prefs: []
  type: TYPE_NORMAL
- en: Benchmarking with BenchmarkDotNet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**BenchmarkDotNet** is an open source .NET library designed to facilitate micro-benchmarking
    in .NET applications. It was created by software engineer, Andrey Akinshin, a
    prominent member of the .NET community specializing in software performance.'
  prefs: []
  type: TYPE_NORMAL
- en: The project started around 2014 to provide developers with an easy-to-use tool
    for measuring and comparing the performance of different pieces of code.
  prefs: []
  type: TYPE_NORMAL
- en: The library is available as a NuGet package and will need to be installed in
    order for us to run performance benchmarking against the **MyCompany** API project.
  prefs: []
  type: TYPE_NORMAL
- en: To keep things clean, we will perform the benchmarking in another project. However,
    we can stay within the current Visual Studio setup by adding the new benchmarking
    project to the current solution.
  prefs: []
  type: TYPE_NORMAL
- en: In Visual Studio’s Solution Explorer, right-click the current solution and select
    **Add** | **New Project** .
  prefs: []
  type: TYPE_NORMAL
- en: In the **New Project** screen there is a search box at the top of the window
    that allows you to search for a project template. Use this to search for **"C#
    Console App"** . Once you see it, select it and click **"Next"** . You will be
    asked to choose a .NET version. We are using version 9, so leave this selected
    and click **"Create"** .
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will need to add the **BenchmarkDotNet** library package to the new
    project via the Package Manager Console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The new project is in our solution and has the required libraries installed,
    but how is it supposed to be able to reference the dependencies from the minimal
    API project?
  prefs: []
  type: TYPE_NORMAL
- en: The way to address this is to create a project reference. This allows us to
    reference object types across multiple .NET projects. This is especially easy
    when the projects are in the same solution as they are in this example.
  prefs: []
  type: TYPE_NORMAL
- en: To add the project reference, right-click your new benchmarking project and
    click **Add** | **Project Reference** .
  prefs: []
  type: TYPE_NORMAL
- en: You will be presented with a dialog box in which you can browse to the project
    location. Your ASP.NET project should have been compiled as a **Dynamic Link Library**
    ( **DLL** ) so you should be able to select that from the bin folder within your
    ASP.NET project directory.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a project reference, you can add using statements to reference
    types in that project as if they had been created within the benchmarking project.
  prefs: []
  type: TYPE_NORMAL
- en: We can now move on to setting up our benchmarks and utilizing the dependencies
    that we would have normally injected, but first, the benchmarks need their own
    class; so, create one called **EmployeeBenchmarks** .
  prefs: []
  type: TYPE_NORMAL
- en: 'In this new class, create a private field to hold **EmployeeService** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Next, we can create a method that accesses the required dependencies. We will
    call this method **Setup()** . We need to annotate this method with an attribute
    – **[** **GlobalSetup]**
  prefs: []
  type: TYPE_NORMAL
- en: 'Having this attribute means that BenchmarkDotNet will run the logic inside
    **Setup()** before benchmarks run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This code uses **ServiceCollection** , which will require the **Microsoft.Extensions.DependencyInjection**
    package to be installed.
  prefs: []
  type: TYPE_NORMAL
- en: Inside **Setup()** , we have created the required dependencies and added them
    to **ServiceContainer** so that they are ready to be used at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: We have also retrieved **EmployeeService** and stored it in the private field
    so that our benchmark can call the **GetEmployeeId()** function within it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, for this class, we add the benchmark itself, which is the important
    part. We want to create a benchmark for the activity running in Entity Framework
    so we will call the **GetEmployeeId()** function so that it interacts with the
    database via **MyCompanyContext** , and this activity will be recorded by BenchmarkDotNet.
    We are passing a hardcoded ID to **GetEmployeeById()** , because we know that
    the **Employee** record with ID **6** exists and that this is not going to change
    (obviously, you must ensure a record with this ID exists, or change the value
    from **6** to one you know to exist in the database):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Notice the presence of the **[Benchmark]** attribute decorating the **GetEmployeeByIdBenchmark()**
    method. This labels the method as being a relevant benchmark that should be run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, this is where having a separate console application really helps. In the
    **Main()** method of the benchmark console application’s **Program.cs** class,
    we can simply call the static **BenchmarkRunner** and tell it to run any of the
    benchmarks in the benchmark class, which it will detect based on the presence
    of the **[** **Benchmark]** attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The benchmarking console application can now be run to provide results for any
    methods or functions in **EmployeeBenchmarks** that are annotated with the **[**
    **Benchmark]** attribute.
  prefs: []
  type: TYPE_NORMAL
- en: Before running the console application, right-click the console application
    project in Solution Explorer and select **Set as** **Startup Project** .
  prefs: []
  type: TYPE_NORMAL
- en: Once the console app has finished running, you will see the benchmark output
    in the console window, as well as a series of files published to the **bin** directory
    of the application in a folder called **BenchmarkDotNet.Artifacts** . Here, you
    will find the output to the console, as well as the results organized in HTML,
    Markdown, and Excel formats.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the most important section of the output. In the result shown
    in the console, you’ll notice a table. This table contains the benchmarking information
    for **GetEmployeeById()** :'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This table shows the average time in microseconds that it took to run **GetEmployeeById()**
    out of several iterations.
  prefs: []
  type: TYPE_NORMAL
- en: The average time taken is displayed as a mean value, giving us a measurement
    we can use as a basis for performance analysis. It would be advisable to note
    this mean average, and then run benchmarking several more times with different
    inputs, to provide further re-enforcement of this average value.
  prefs: []
  type: TYPE_NORMAL
- en: The **Error** and **StdDev** columns provide some further supporting information.
    **StdDev** represents the **standard deviation** , which is the amount of variation
    from the average. A smaller standard deviation means that benchmark times were
    consistent. If you see a higher standard deviation, it implies more variability
    in average results.
  prefs: []
  type: TYPE_NORMAL
- en: The **Error** column represents the estimated standard deviation of the mean
    average result, which is an indication of how reliable the result is. The smaller
    the number, the more reliable the result.
  prefs: []
  type: TYPE_NORMAL
- en: Again, it makes sense to run several benchmarks with varying inputs. If you
    are seeing similar standard deviations and errors, you can be confident in the
    accuracy of the results.
  prefs: []
  type: TYPE_NORMAL
- en: Release mode
  prefs: []
  type: TYPE_NORMAL
- en: Your project will need to be built in Release mode for the preceding profiling
    to work. If you see the word **Debug** in a dropdown in the top ribbon of Visual
    Studio, change it to **Release** and then rebuild your project.
  prefs: []
  type: TYPE_NORMAL
- en: Common performance bottlenecks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s look at some common reasons that performance could be degraded and how
    you might address them. These are by no means applicable to every situation, but
    they are well-known bottlenecks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Database access** : The bottleneck is caused by slow database queries or
    inefficient use of database connections. To mitigate this, do the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use asynchronous database operations ( **async/await** ).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimize SQL queries and use proper indexing. Look at any **WHERE** clauses
    or **JOIN** operations that might be taxing the system.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement connection pooling to reduce the number of times new connections need
    to be opened.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a caching system such as ASP.NET’s **IMemoryCache** for frequently accessed
    data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I/O operations** : The bottleneck is due to blocking I/O operations, such
    as file or network access. To mitigate this, do the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use asynchronous I/O operations.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize disk and network I/O. Where possible, retrieve commonly required data
    from memory rather than from persistent storage or over a network.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use efficient data formats (e.g., JSON instead of XML).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Serialization/deserialization** : The bottleneck arises from slow or inefficient
    serialization and deserialization of data. To mitigate this, do the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use optimized serializers such as **System.Text.Json** instead of **Newtonsoft.Json.**
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize the size of the data being serialized.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Middleware pipeline** :The bottleneck is caused by excessive or inefficient
    middleware in the request pipeline. To mitigate this, do the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Review and optimize middleware components.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Remove unnecessary middleware.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use lightweight middleware.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logging** : The bottleneck results from extensive or synchronous logging.
    To mitigate this, do the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use asynchronous logging.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduce the log verbosity level in production.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use efficient logging frameworks such as Serilog.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependency injection (DI)** :The bottleneck is due to the inefficient use
    of dependency injection. To mitigate this, do the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use scoped or singleton lifetimes where appropriate.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid unnecessary injections of services. If there is a simpler alternative
    that avoids dependency injection, use it.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Garbage collection (GC) pressure** : The bottleneck results from excessive
    memory allocation, leading to frequent garbage collection. To mitigate this, do
    the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reduce allocations by reusing objects.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use value types instead of reference types where possible.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimize data structures and avoid large allocations of objects onto the heap
    (relates back to using value types over reference types where possible).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network latency** : The bottleneck is caused by high latency in network calls.
    To mitigate this, do the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimize the number of network calls.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement retry policies with exponential backoff.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Investigate alternative network protocols, using benchmarking to see whether
    they are less resource-intensive.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By having a general understanding of the most common bottlenecks and how they
    can be mitigated, you will become more vigilant when debugging and reviewing code
    in minimal APIs.
  prefs: []
  type: TYPE_NORMAL
- en: We will now recap the various topics we have covered in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored at a high level the various pitfalls and mitigation
    options for performance issues in minimal APIs.
  prefs: []
  type: TYPE_NORMAL
- en: We started by outlining the basics of performance analysis and why it is important
    within not just minimal APIs, but in general software engineering.
  prefs: []
  type: TYPE_NORMAL
- en: We then reviewed some of the different tools on offer, before narrowing the
    scope of the tools we would use to the Visual Studio profiler and BenchmarkDotNet.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we started profiling the **MyCompany** API using the Visual Studio profiler,
    with a breakdown of the various metrics that are outputted into the diagnostic
    report produced by the profiler. This allowed us to find the overall CPU usage
    of a section of a code, but then also to break that down further by its called
    functions lower down in the call tree.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on to BenchMarkDotNet, we implemented the same analysis example undertaken
    by the Visual Studio profiler, this time running a performance benchmark against
    the target method. We then reviewed the output to understand how best to secure
    an accurate benchmark based on the consistency of the error rate and the standard
    deviation.
  prefs: []
  type: TYPE_NORMAL
- en: Like many topics in this book, this is just a scratch of the surface, but it
    will provide a solid foundation for further optimization of minimal APIs and give
    you a good grounding in analyzing their efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on to the next chapter, in which we will be exploring ways to use
    asynchronous programming to scale minimal APIs.
  prefs: []
  type: TYPE_NORMAL
