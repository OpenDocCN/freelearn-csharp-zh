- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Microservices in Practice
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践中的微服务
- en: This chapter is dedicated to the practical implementation of each microservice
    that exists after the design of the general application architecture and after
    that all interfaces of all Microservices have been defined. The interaction between,
    and orchestration of, microservices will be detailed in the remaining chapters
    of this book.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章致力于在通用应用架构设计之后以及所有微服务的所有接口都已定义之后，每个微服务的实际实现。本书剩余章节将详细阐述微服务之间的交互和编排。
- en: All concepts will be illustrated with the example of a worker microservice taken
    from the book’s case study application that we introduced in the *Car-sharing
    example* subsection of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying
    Microservices Applications*.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 所有概念将通过从本书案例研究应用中提取的工人微服务示例进行说明，该示例我们在[*第2章*](Chapter_2.xhtml#_idTextAnchor038)的*“汽车共享示例”子节中介绍，即*“揭秘微服务应用”*。
- en: After a short description of the example worker microservice specifications,
    we will describe how to design microservices’ input and output communication subsystems,
    and how to organize the microservice request-serving logic.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在简要描述示例工人微服务规范后，我们将描述如何设计微服务的输入和输出通信子系统，以及如何组织微服务请求服务逻辑。
- en: 'Finally, we will discuss the details of how to implement a microservice with
    the Onion Architecture project templates introduced in the *A solution template
    based on the Onion Architecture* section of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论如何使用在[*第3章*](Chapter_3.xhtml#_idTextAnchor067)的*“基于洋葱架构的解决方案模板”*部分中介绍的洋葱架构项目模板来实现微服务的细节。
- en: 'More specifically, this chapter covers the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，本章涵盖了以下内容：
- en: The route-planning microservice of the car-sharing application
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汽车共享应用的路线规划微服务
- en: Microservice basic design
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务基本设计
- en: Ensuring resilient communication with Polly
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保与Polly的通信具有弹性
- en: From abstraction to implementation details
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从抽象到实现细节
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要以下条件：
- en: Visual Studio 2022, at least the free *Community* edition.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 至少需要Visual Studio 2022，尤其是免费的*社区*版。
- en: 'A SQL instance that accepts TCP/IP requests and user/password authentication
    since it must communicate with clients running inside Docker containers. Please
    note that the SQL instance that comes with the Visual Studio installation doesn’t
    support TCP/IP, so you need to either install SQL Express or use a cloud instance.
    For local installation, both the installer and instructions are available here:
    [https://www.microsoft.com/en-US/download/details.aspx?id=104781](https://www.microsoft.com/en-US/download/details.aspx?id=104781).
    You may also run the SQL Server Developer edition as a Docker image with the following
    code:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个接受TCP/IP请求和用户/密码身份验证的SQL实例，因为它必须与运行在Docker容器内的客户端通信。请注意，Visual Studio安装附带的支持TCP/IP的SQL实例，因此您需要安装SQL
    Express或使用云实例。对于本地安装，安装程序和说明都可在以下链接找到：[https://www.microsoft.com/en-US/download/details.aspx?id=104781](https://www.microsoft.com/en-US/download/details.aspx?id=104781)。您还可以使用以下代码将SQL
    Server Developer版作为Docker镜像运行：
- en: '[PRE0]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The username corresponding to the chosen password will be `sa`.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对应于所选密码的用户名将是`sa`。
- en: Docker Desktop for Windows ([https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Desktop for Windows ([https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)).
- en: 'Docker Desktop, in turn, requires **Windows Subsystem for Linux (WSL)**, which
    can be installed by following these steps:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Desktop，反过来，需要**Windows Subsystem for Linux (WSL)**，可以通过以下步骤安装：
- en: Type `powershell` in the Windows 10/11 search bar.
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Windows 10/11的搜索栏中输入`powershell`。
- en: When **Windows PowerShell** is proposed as a search result, click on **Run as
    an administrator**.
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当**Windows PowerShell**作为搜索结果出现时，请单击**以管理员身份运行**。
- en: In the Windows PowerShell administrative console that appears, run the `wsl
    --install` command.
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在出现的Windows PowerShell管理控制台中，运行`wsl --install`命令。
- en: You can find the sample code for this chapter at [https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在此处找到本章的示例代码：[https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp)。
- en: The route-planning microservice of the car-sharing application
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 汽车共享应用的路线规划微服务
- en: In this section, we describe our example microservice, how to handle security,
    and how to prepare the solution for its implementation into three separate subsections.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了我们的示例微服务、如何处理安全以及如何为其实施准备解决方案，并将它们分为三个独立的子节。
- en: Microservice specifications
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务规范
- en: The route-planning microservice stores and matches pending requests to move
    from one town to another with existing routes that are still open to other participants.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 路由规划微服务存储和匹配待处理的请求，这些请求需要从一个城镇移动到另一个城镇，并且使用的是仍然对其他参与者开放的路由。
- en: When an opened route of a car owner is created, it is matched with requests
    whose start and end towns are close to the car owner’s route and whose date constraints
    are compatible. If matches are found, a proposal to modify the route to include
    them is created and sent to other interested microservices. A symmetric operation
    is also done when a new request is inserted.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当车主开启的路由被创建时，它会与那些起点和终点城镇靠近车主路线且日期限制相兼容的请求进行匹配。如果找到匹配项，则会创建一个修改路由以包含它们的提案，并将其发送给其他感兴趣的微服务。当插入新的请求时，也会执行对称操作。
- en: When a proposal to extend the route is accepted, the original route is extended.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当接受扩展路由的提案时，原始路由被扩展。
- en: 'After the initial match attempt, both requests and routes are stored for possible
    future matches. Requests and routes are removed or modified under the following
    circumstances:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始匹配尝试之后，请求和路由都会被存储起来，以备将来可能的匹配。在以下情况下，请求和路由会被移除或修改：
- en: A route is removed from possible matches when it is closed to new participants
    or aborted.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当路由对新参与者关闭或被取消时，它将从可能的匹配中移除。
- en: A route is extended when it is merged with some requests. No new matches are
    attempted as a consequence of this operation.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当路由与某些请求合并时，它会扩展。此操作不会尝试进行新的匹配。
- en: A request is removed from possible matches when it is merged with a route.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当请求与路由合并时，请求将从可能的匹配中移除。
- en: A request becomes available again when the route it was merged with is aborted.
    After this operation, new matches are attempted.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当请求合并的路由被取消时，请求再次可用。在此操作之后，将尝试进行新的匹配。
- en: Both requests and routes are deleted *N* days after their maximum travel day
    expires, where *N* is a parameter to be provided.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求和路由在它们的最大旅行日过期后*N*天后被删除，其中*N*是一个需要提供的参数。
- en: 'Matches between routes and requests are done when the following circumstances
    are met:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当满足以下条件时，进行路由和请求之间的匹配：
- en: The route date falls between the minimum and maximum dates associated with the
    request.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 路由日期在请求关联的最小和最大日期之间。
- en: Both the request start and end towns are close enough to the route.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求的起点和终点城镇与路线足够接近。
- en: We will implement most microservice-to-microservice communication with the publisher/subscriber
    pattern in order to maximize microservice decoupling. This choice will also minimize
    the overall communication-related code, since message handlers and their client
    libraries take care of most of the asynchronous communication problems. Please
    refer to the *Event-based communications* subsection of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038),
    *Demystifying Microservices Applications*, for more details on event-based communication.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用发布者/订阅者模式来实现大多数微服务之间的通信，以最大化微服务的解耦。这个选择也将最小化整体通信相关的代码，因为消息处理程序及其客户端库负责处理大多数异步通信问题。请参阅[*第2章*](Chapter_2.xhtml#_idTextAnchor038)的*基于事件的通信*子节，*揭秘微服务应用程序*，以获取有关基于事件通信的更多详细信息。
- en: Moreover, in order to maximize application portability, we will use the **RabbitMQ**
    message broker, which is not tied to a specific platform or cloud but can be installed
    in any Kubernetes-based network with an adjustable number of replicas. **RabbitMQ**
    will be described in a dedicated subsection of the next section.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了最大化应用程序的可移植性，我们将使用**RabbitMQ**消息代理，它不受特定平台或云的限制，但可以在任何基于Kubernetes的网络中安装，并具有可调整的副本数量。**RabbitMQ**将在下一节的专用子节中描述。
- en: Since the car-sharing application doesn’t exchange heavy messages, we may avoid
    non-standard binary serializations such as **gRPC Protobuf** and opt for a simple
    **JSON** message serialization.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 由于共享汽车应用程序不交换大量消息，我们可能避免使用非标准的二进制序列化，如**gRPC Protobuf**，而选择简单的**JSON**消息序列化。
- en: Most web servers and communication libraries can be configured to automatically
    compress JSON data. Web servers negotiate compression with the client.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数Web服务器和通信库都可以配置为自动压缩JSON数据。Web服务器与客户端协商压缩。
- en: Finally, since our worker microservice in-out communication is based on message
    brokers and not on the usual **HTTP** and **gRPC** ASP.NET Core protocols, we
    might consider the ad hoc **Worker service** project template based on the so-called
    **hosted services** (**hosted services** will be discussed in the next section).
    However, microservices best practices prescribe that each microservice should
    expose an HTTP endpoint to verify its health status, so we will adopt a minimal
    API-based ASP.NET Core Web APIproject since it also supports the hosted services
    that we need for receiving message-broker-based communication.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于我们的工作微服务入出通信基于消息代理而不是常规的**HTTP**和**gRPC** ASP.NET Core协议，我们可能会考虑基于所谓的**托管服务**（**托管服务**将在下一节讨论）的**Worker服务**项目模板。然而，微服务最佳实践规定每个微服务都应该公开一个HTTP端点以验证其健康状态，因此我们将采用基于最小API的ASP.NET
    Core Web API项目，因为它也支持我们需要的基于消息代理的通信所需的托管服务。
- en: Having clarified the microservice responsibilities, we can move on to security
    considerations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在明确了微服务职责后，我们可以继续考虑安全因素。
- en: Handling security and authorization
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理安全和授权
- en: The authorization of requests coming from actual users is handled with the usual
    ASP.NET Web API techniques, that is, with web tokens (typically a **JSON bearer
    token**) and `Authorize` attributes. Web tokens are provided by the login and
    token-renew endpoints of a specialized microservice that acts as the authorization
    server.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 来自实际用户的请求授权通常使用ASP.NET Web API的常规技术处理，即使用Web令牌（通常是**JSON承载令牌**）和`Authorize`属性。Web令牌由一个充当授权服务器的专用微服务的登录和令牌续订端点提供。
- en: Requests coming from other services instead are usually secured with mTLS, that
    is, with certificate-based client authentication. Client certificates are handled
    by the lower-level TCP/IP protocol together with the server certificate used for
    encrypting the HTTPS communication. Then, the information extracted by the client
    certificate is passed to the ASP.NET Core authentication middleware to create
    a `ClaimsPrincipal` (the usual ASP.NET Core **User** object). When the application
    runs within an orchestrator, it is also possible to use orchestrator-specific
    authorization, and when the application runs in the cloud, it is possible to use
    cloud-specific authorization.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 来自其他服务的请求通常使用mTLS（即基于证书的客户端身份验证）进行安全保护。客户端证书由底层TCP/IP协议与用于加密HTTPS通信的服务器证书一起处理。然后，客户端证书提取的信息传递给ASP.NET
    Core身份验证中间件以创建一个`ClaimsPrincipal`（通常的ASP.NET Core **User**对象）。当应用程序在编排器中运行时，也可以使用编排器特定的授权，而当应用程序在云中运行时，可以使用云特定的授权。
- en: Luckily, if both communicating microservices are exposed in a private network,
    or better, in a private network handled by a microservices orchestrator, we may
    replace user authentication with firewall rules and/or with other communication-securing
    facilities offered by the orchestrator.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，如果两个通信微服务都暴露在私有网络中，或者更好，由微服务编排器管理的私有网络中，我们可以用防火墙规则和/或编排器提供的其他通信安全设施来替换用户身份验证。
- en: We will analyze the Kubernetes orchestrator in [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205),
    *Practical Microservices Organization with Kubernetes*, and its communication-securing
    facilities in [*Chapter 10*](Chapter_10.xhtml#_idTextAnchor297), *Security and
    Observability for Serverless and Microservices Applications*. Even in a private
    network, it is recommended to encrypt internal communication using mTLS or other
    encryption methods to mitigate insider threats and network attacks, but for the
    sake of simplicity in this book, we will only secure communication with the outside
    world.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第8章*](Chapter_8.xhtml#_idTextAnchor205)“使用Kubernetes的实用微服务组织”和[*第10章*](Chapter_10.xhtml#_idTextAnchor297)“无服务器和微服务应用程序的安全性和可观察性”中分析Kubernetes编排器，以及其通信安全设施。即使在私有网络中，也建议使用mTLS或其他加密方法加密内部通信以减轻内部威胁和网络攻击，但为了本书的简洁性，我们只将保护与外部世界的通信。
- en: Therefore, if we adequately organize our private network, we need to secure
    just communication with the outside world, that is, communication with frontend
    microservices. However, as discussed in the *Interfacing the external world* subsection
    of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying Microservices
    Applications*, microservices-based applications use API gateways to communicate
    with the external world. In the simplest case, the interface with the external
    world is just a load-balanced web server that performs HTTPS termination, that
    is, that receives HTTPS communications from the external world. While some architectures
    terminate HTTPS at the API gateway and use HTTP internally, it is recommended
    to maintain encryption within the private network using mTLS or re-encryption
    to ensure security within the microservices ecosystem. This way, we may use just
    a single HTTPS certificate for the whole application, thus avoiding the whole
    certificate issuing and renewal procedure for all microservices that compose the
    application.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们充分组织我们的私有网络，我们只需要确保与外部世界的通信安全，即与前端微服务的通信。然而，如[*第2章*](Chapter_2.xhtml#_idTextAnchor038)中“揭秘微服务应用”部分的*接口外部世界*小节所述，基于微服务的应用使用API网关与外部世界通信。在最简单的情况下，与外部世界的接口只是一个负载均衡的Web服务器，执行HTTPS终止，即从外部世界接收HTTPS通信。虽然一些架构在API网关终止HTTPS并在内部使用HTTP，但建议在私有网络中使用mTLS或重新加密来确保微服务生态系统内的安全性。这样，我们可能只需要为整个应用程序使用一个HTTPS证书，从而避免所有组成应用程序的微服务的整个证书颁发和更新流程。
- en: Summing up, if we use any kind of HTTPS-termination interface to access the
    microservice application, we may avoid using HTTPS communication in all microservices.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，如果我们使用任何类型的HTTPS终止接口来访问微服务应用，我们可能避免在所有微服务中使用HTTPS通信。
- en: Now we are ready to prepare the Visual Studio solution that will host the route-planning
    microservice!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好准备将托管路由规划微服务的Visual Studio解决方案了！
- en: Creating the Visual Studio solution
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建Visual Studio解决方案
- en: 'Since we decided to implement the outermost layer of our worker microservice
    with an ASP.NET Core Web API project, let’s create a `CarSharing` Visual Studio
    solution containing an ASP.NET Core Web APIproject called `RoutesPlanning`. The
    **ASP.NET Core Web API** project can be easily found by selecting **C#**, **All
    platforms**, and **Web API** from the dropdowns of the Visual Studio project selection
    window, as shown here:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们决定使用ASP.NET Core Web API项目来实现工作微服务的最外层，让我们创建一个包含名为`RoutesPlanning`的ASP.NET
    Core Web API项目的`CarSharing` Visual Studio解决方案。**ASP.NET Core Web API**项目可以通过从Visual
    Studio项目选择窗口的下拉菜单中选择**C#**、**所有平台**和**Web API**来轻松找到，如图所示：
- en: '![](img/B31916_07_1.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图7.1：项目选择](img/B31916_07_1.png)'
- en: 'Figure 7.1: Project selection'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：项目选择
- en: As discussed previously, we may avoid HTTPS communication, and worker microservices
    do not need authentication. However, we need Docker support since microservices
    are usually containerized.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们可能避免HTTPS通信，并且工作微服务不需要认证。然而，由于微服务通常容器化，我们需要Docker支持。
- en: 'Finally, we don’t need controllers but just a minimal API since we need to
    expose just a couple of trivial endpoints for health checks:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们不需要控制器，只需要一个最小的API，因为我们只需要暴露几个简单的端点进行健康检查：
- en: '![Figure 7.2: Project settings](img/B31916_07_2.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图7.2：项目设置](img/B31916_07_2.png)'
- en: 'Figure 7.2: Project settings'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：项目设置
- en: 'We will use the Onion Architecture, so we need to also add a project for the
    application services and domain layer. Therefore, let’s add two more **Class Library**
    projects, called `RoutesPlanningApplicationServices` and `RoutesPlanningDomainLayer`.
    We will adapt the Onion Architecture template introduced in the *A solution template
    based on the Onion Architecture* section of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用洋葱架构，因此我们还需要为应用服务和领域层添加一个项目。因此，让我们添加两个额外的**类库**项目，分别命名为`RoutesPlanningApplicationServices`和`RoutesPlanningDomainLayer`。我们将根据[*第3章*](Chapter_3.xhtml#_idTextAnchor067)中“基于洋葱架构的解决方案模板”部分介绍的洋葱架构模板进行适配。
- en: Let’s open the `OnionArchitectureComplete` project template, which you can find
    in the `ch03` folder of the book’s GitHub repository. In the `RoutesPlanningDomainLayer`
    project, delete the **Class1.cs** file, select the three folders in the `DomainLayer`
    project of the `ch03` project template, copy them, and paste them into the `RoutesPlanningDomainLayer`
    project. If you have the latest Visual Studio 2022 version installed, you should
    be able to perform the copy operation from within Visual Studio Solution Explorer.
    Also, add a reference to the `Microsoft.Extensions.DependencyInjection.Abstractions`
    NuGet package to the `RoutesPlanningDomainLayer` project.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打开`OnionArchitectureComplete`项目模板，你可以在书的GitHub仓库的`ch03`文件夹中找到它。在`RoutesPlanningDomainLayer`项目中，删除**Class1.cs**文件，选择`ch03`项目模板中`DomainLayer`项目的三个文件夹，复制它们，并将它们粘贴到`RoutesPlanningDomainLayer`项目中。如果你安装了最新的Visual
    Studio 2022版本，你应该能够从Visual Studio解决方案资源管理器中执行复制操作。此外，将`Microsoft.Extensions.DependencyInjection.Abstractions`
    Nuget包的引用添加到`RoutesPlanningDomainLayer`项目中。
- en: Then, perform the analogous operations on the `RoutesPlanningApplicationServices`
    and `ApplicationServices` projects.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在`RoutesPlanningApplicationServices`和`ApplicationServices`项目上执行类似的操作。
- en: Now that you have all the Onion Architecture files in place, you need to add
    just a reference to `RoutesPlanningDomainLayer` in `RoutesPlanningApplicationServices`
    and a reference to `RoutesPlanningApplicationServices` in `RoutesPlanning`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经放置了所有的洋葱架构文件，你只需要在`RoutesPlanningApplicationServices`中添加对`RoutesPlanningDomainLayer`的引用，并在`RoutesPlanning`中添加对`RoutesPlanningApplicationServices`的引用。
- en: After the last operation, your solution should compile, but we have not finished
    preparing our solution yet. We need to also add an **Entity Framework Core**-based
    library in order to provide an implementation driver for our domain layer.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步操作之后，你的解决方案应该可以编译，但我们还没有完成解决方案的准备工作。我们还需要添加一个基于**Entity Framework Core**的库，以便为我们的领域层提供一个实现驱动程序。
- en: Let’s add a new class library project and call it `RoutesPlanningDBDriver`.
    Add references to the `Microsoft.EntityFrameworkCore.SqlServer` and `Microsoft.EntityFrameworkCore.Tools`
    Nuget packages, and to the `RoutesPlanningDomainLayer` project.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们添加一个新的类库项目，并将其命名为`RoutesPlanningDBDriver`。添加对`Microsoft.EntityFrameworkCore.SqlServer`和`Microsoft.EntityFrameworkCore.Tools`
    Nuget包的引用，以及对`RoutesPlanningDomainLayer`项目的引用。
- en: After that, delete the **Class1.cs** file and replace it with all code files
    and folders from the `DBDriver` project of the `ch03` project template.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，删除**Class1.cs**文件，并用`ch03`项目模板中`DBDriver`项目的所有代码文件和文件夹替换它。
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`RoutesPlanning` needs a reference to `RoutesPlanningDBDriver` because the
    outermost layer of an Onion Architecture must reference all implementation-specific
    drivers. `AddApplicationServices` adds all queries, commands, and event handlers
    to the dependency injection engine, while `AddDbDtiver` adds all repository implementations
    and the `IUnitOfWork` implementation to the dependency injection.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`RoutesPlanning`需要引用`RoutesPlanningDBDriver`，因为洋葱架构的最外层必须引用所有特定实现的驱动程序。`AddApplicationServices`将所有查询、命令和事件处理程序添加到依赖注入引擎中，而`AddDbDtiver`将所有存储库实现和`IUnitOfWork`实现添加到依赖注入中。'
- en: 'For more information on the Onion Architecture project template that we used
    to prepare our solution, please refer to the *A solution template based on the
    Onion Architecture* section of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们用来准备解决方案的洋葱架构项目模板的更多信息，请参阅[*第3章*](Chapter_3.xhtml#_idTextAnchor067)的*基于洋葱架构的解决方案模板*部分，*设置和理论：Docker和洋葱架构*。
- en: Now, our solution is finally ready! We can start designing our worker microservice!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的解决方案终于准备好了！我们可以开始设计我们的工作微服务了！
- en: Microservice basic design
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务基本设计
- en: 'In this section, we will define all the main microservice abstractions, that
    is, the overall communication strategy, all Onion Architecture commands and events,
    and the top-level loops of the required hosted services. We will start with a
    description of the chosen message broker: **RabbitMQ**.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将定义所有主要微服务抽象，即整体通信策略、所有洋葱架构命令和事件，以及所需托管服务的顶级循环。我们将从对所选消息代理的描述开始：**RabbitMQ**。
- en: 'The message broker: RabbitMQ'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消息代理：RabbitMQ
- en: Natively, RabbitMQ supports the **AMQP** asynchronous message protocol, which
    is one of the most used asynchronous protocols, the other being **MQTT**, which
    has a specific syntax for the publisher/subscriber pattern. Support for **MQTT**
    can be added with a plugin, but RabbitMQ has facilities for easily implementing
    a publisher/subscriber pattern on top of **AMQP**. Moreover, RabbitMQ offers several
    tools to support scalability, disaster recovery, and redundancy, so it fulfills
    all requirements to be a first-class actor in cloud and microservices environments.
    More specifically, by defining a RabbitMQ cluster, we may achieve both load balancing
    and data replication which is required in most SQL and NoSQL databases.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ 本地支持 **AMQP** 异步消息协议，这是最常用的异步协议之一，另一个是 **MQTT**，它具有特定的发布/订阅模式语法。可以通过插件添加对
    **MQTT** 的支持，但 RabbitMQ 提供了在 **AMQP** 上轻松实现发布/订阅模式的工具。此外，RabbitMQ 提供了支持可伸缩性、灾难恢复和冗余的几个工具，因此它满足了成为云和微服务环境中一流演员的所有要求。更具体地说，通过定义
    RabbitMQ 集群，我们可以实现负载均衡和数据复制，这在大多数 SQL 和 NoSQL 数据库中都是必需的。
- en: 'In this section, we will just describe RabbitMQ’s basic operation, while the
    installation and usage of RabbitMQ clusters in Kubernetes will be discussed in
    [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205), *Practical Microservices Organization
    with Kubernetes*. You can find more details in the tutorials and documentation
    on the RabbitMQ official website: [https://www.rabbitmq.com/](https://www.rabbitmq.com/).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将仅描述 RabbitMQ 的基本操作，而 RabbitMQ 集群在 Kubernetes 中的安装和使用将在 [*第 8 章*](Chapter_8.xhtml#_idTextAnchor205)，*使用
    Kubernetes 的实用微服务组织* 中讨论。您可以在 RabbitMQ 官方网站上的教程和文档中找到更多详细信息：[https://www.rabbitmq.com/](https://www.rabbitmq.com/)。
- en: RabbitMQ messages must be prepared in binary format, since RabbitMQ messages
    must be just an array of bytes. However, we will use the **EasyNetQ** client,
    which takes care of object serialization and of most of the client-server wiring
    and error recovery. **EasyNetQ** is a NuGet package built on top of RabbitMQ’s
    low-level **RabbitMQ.Client** NuGet client, which makes the usage of RabbitMQ
    easy while reducing the communication-code overhead and enhancing its modularity
    and modifiability.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ 消息必须以二进制格式准备，因为 RabbitMQ 消息必须只是一个字节数组。然而，我们将使用 **EasyNetQ** 客户端，它负责对象序列化和大多数客户端/服务器连接以及错误恢复。**EasyNetQ**
    是一个基于 RabbitMQ 的低级 **RabbitMQ.Client** NuGet 客户端的 NuGet 包，它使得 RabbitMQ 的使用变得简单，同时减少了通信代码的开销，并增强了其模块化和可修改性。
- en: 'Once sent to RabbitMQ, messages are placed in **queues**. More specifically,
    they are placed in one or more **queues** by passing through other entities, called
    **exchanges**. The exchanges route the messages to **queues** using a routing
    strategy that depends on the **exchange** type. Exchanges are an **AMQP**-specific
    concept, and they are the RabbitMQ way to configure complex communication protocols
    like the publishing/subscriber protocol, as shown in the following figure:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦消息被发送到 RabbitMQ，它们会被放置在 **队列** 中。更具体地说，它们通过其他实体（称为 **交换**）传递时，会被放置在一个或多个 **队列**
    中。交换使用依赖于 **交换** 类型的路由策略将消息路由到 **队列**。交换是 **AMQP** 特有的概念，它们是 RabbitMQ 配置复杂通信协议（如发布/订阅协议）的方式，如下面的图所示：
- en: '![Figure 7.3: RabbitMQ exchanges](img/B31916_07_3.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3：RabbitMQ 交换](img/B31916_07_3.png)'
- en: 'Figure 7.3: RabbitMQ exchanges'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：RabbitMQ 交换
- en: 'By adequately defining the exchange routing strategy, we can implement several
    patterns. More specifically, the following apply:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通过适当地定义交换路由策略，我们可以实现几种模式。更具体地说，以下适用：
- en: When we use a **default exchange**, the message is sent to a single queue and
    we can implement asynchronous direct calls.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用 **默认交换** 时，消息会被发送到单个队列，并且我们可以实现异步直接调用。
- en: When we use a **fanout exchange**, the exchange will send the messages to all
    queues that subscribe to that exchange. This way, we can implement the publisher/subscriber
    pattern.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用 **fanout 交换** 时，交换会将消息发送到所有订阅该交换的队列。这样，我们可以实现发布/订阅模式。
- en: There is also a **topic exchange**, which enhances the publisher/subscriber
    pattern by enabling the matching of named event subclasses called topics. Matching
    between receivers and topics also supports wildcard chars. We will describe its
    practical usage with enterprise microservices in the *Ensuring that messages are
    processed in the proper order* subsection.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个 **topic 交换**，它通过允许匹配名为事件子类的主题来增强发布/订阅模式。接收者和主题之间的匹配也支持通配符字符。我们将在 *确保消息按正确顺序处理*
    子节中描述其在企业微服务中的实际用法。
- en: Whenever several receivers are attached to the same queue, messages are equally
    distributed among them according to a round-robin pattern. This is the case of
    *N* identical replicas of the same microservice. Therefore, replicas are automatically
    load-balanced by RabbitMQ.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当多个接收器连接到同一个队列时，消息将根据轮询模式在它们之间平均分配。这是相同微服务的 *N* 个相同副本的情况。因此，副本由 RabbitMQ 自动负载均衡。
- en: Luckily, **EasyNetQ** directly exposes the publish/subscribe protocol (possibly
    enriched with topics) and the direct call protocol, together with a request/response
    asynchronous RPC protocol, taking care of creating and connecting all needed queues
    and exchanges. Details on how to use **EasyNetQ** will be provided when describing
    the code of our route-planning microservice.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，**EasyNetQ** 直接暴露了发布/订阅协议（可能包含主题），直接调用协议，以及请求/响应异步 RPC 协议，负责创建和连接所有需要的队列和交换。在描述我们的路线规划微服务代码时，将提供如何使用
    **EasyNetQ** 的详细信息。
- en: The easiest way to install RabbitMQ is by using its Docker image. We will adopt
    this option since all our microservices will also be containerized, and since
    in the final Kubernetes version of the overall application, we will use containerized
    RabbitMQ clusters.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 RabbitMQ 最简单的方法是使用其 Docker 镜像。我们将采用此选项，因为我们的所有微服务也将被容器化，并且在整体应用程序的最终 Kubernetes
    版本中，我们将使用容器化的 RabbitMQ 集群。
- en: 'We can just run the following command in a Linux shell:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Linux shell 中运行以下命令：
- en: '[PRE3]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Since we provided the `-it` flags, after the image is downloaded and the container
    is created and started, the Linux shell remains blocked in the container filesystem.
    Moreover, since we also added the `–-rm` option, the container is destroyed as
    soon as it is stopped with the following line:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们提供了 `-it` 标志，在镜像下载并容器创建并启动后，Linux shell 仍然被阻塞在容器文件系统中。此外，由于我们也添加了 `–-rm`
    选项，容器在停止后立即被销毁，如下所示：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In order to verify that RabbitMQ is working properly, please navigate to [http://localhost:15672](http://localhost:15672).
    The RabbitMQ management console should appear. You can log in with the startup
    credentials, which are `guest`for both the username and password.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证 RabbitMQ 是否正常工作，请导航到 [http://localhost:15672](http://localhost:15672)。RabbitMQ
    管理控制台应该出现。您可以使用启动凭证登录，用户名和密码都是 `guest`。
- en: You don’t need to leave the container running; you can stop it and re-execute
    the `run` command when you need RabbitMQ to test the microservice code.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您不需要让容器持续运行；当您需要测试微服务代码时，可以停止它并重新执行 `run` 命令。
- en: 'The disk space needed by RabbitMQ is mounted as a Docker volume with the following
    volume statement directly inserted in the `Dockerfile` image:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ 需要的磁盘空间作为 Docker 卷挂载，以下卷声明直接插入到 `Dockerfile` 镜像中：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This means that the disk content is reset when the container is destroyed and
    run again. Therefore, if you want to keep the disk content, avoid running the
    container with the `–-rm` option, so it will not be destroyed when it is stopped.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着当容器被销毁并重新运行时，磁盘内容会被重置。因此，如果您想保留磁盘内容，请避免使用带有 `–-rm` 选项的容器运行，这样它在停止时不会被销毁。
- en: 'If you need customized credentials, please add the following environment variables
    to the `run` command:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要自定义凭证，请将以下环境变量添加到 `run` 命令中：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is necessary when RabbitMQ is accessed outside of `localhost`, because
    in this case, the default username and password are not accepted for security
    reasons.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这在访问 RabbitMQ 时需要从 `localhost` 外部进行时是必要的，因为在这种情况下，出于安全原因，默认的用户名和密码不被接受。
- en: Now, we can move on to designing the input and output messages of our worker
    microservices.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以继续设计我们的工作微服务的输入和输出消息。
- en: Input communication
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入通信
- en: Since classes that represent intra-microservices messages must be known to both
    clients and servers, the best option is defining them during the initial microservices
    external interfaces design and placing them in one or more shared libraries. Since
    our project contains a reasonably small number of microservices, we may assume
    that all messages are visible to all microservices, so we can use a single shared
    library.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于表示微服务内部消息的类必须为客户端和服务器所知，最佳选项是在初始微服务外部接口设计期间定义它们，并将它们放在一个或多个共享库中。由于我们的项目包含相对较少的微服务，我们可以假设所有消息对所有微服务都是可见的，因此我们可以使用单个共享库。
- en: However, in more complex scenarios containing hundreds or thousands of microservices,
    their organization must be hierarchical, so we will have level 0 messages, known
    to all microservices; level 1 messages, known just within level 1 groups of microservices,
    and so on.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在包含数百或数千个微服务的更复杂场景中，它们的组织必须是分层的，因此我们将有0级消息，所有微服务都知道；1级消息，仅在1级微服务组内知道，依此类推。
- en: Let’s add a new **Class Library** project called `SharedMessages` to our solution,
    and we’ll select **standard 2.1** for its version. Then, let’s add a reference
    to this new project to the `RoutesPlanningApplicationServices` project. We will
    place all application messages here.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在解决方案中添加一个新的**类库**项目，命名为`SharedMessages`，并为其选择**标准2.1**版本。然后，让我们将此新项目添加到`RoutesPlanningApplicationServices`项目中。我们将在这里放置所有应用程序消息。
- en: 'From the specifications of the route-planning microservice, we have just four
    messages:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从路线规划微服务的规范来看，我们只有四条消息：
- en: '**New request**: It will contain a unique request identifier, an interval of
    acceptable travel dates, and two unique identifiers for the start and arrival
    towns, their display names, and their latitude and longitude. Moreover, it will
    contain a unique identifier representing the user that issued the request and
    their display name.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**新请求**：它将包含一个唯一的请求标识符、可接受的旅行日期间隔以及代表出发地和到达地的两个唯一标识符，它们的显示名称以及它们的纬度和经度。此外，它还将包含一个唯一标识符，代表提出请求的用户及其显示名称。'
- en: '**New route**: It will contain a unique route identifier, a travel date, and
    two unique identifiers representing the start and arrival towns, their display
    names, and their latitude and longitude. Moreover, it will contain a unique identifier
    representing the car owner that issued the route proposal and their display name.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**新路线**：它将包含一个唯一的路线标识符、旅行日期以及代表出发地和到达地的两个唯一标识符，它们的显示名称以及它们的纬度和经度。此外，它还将包含一个唯一标识符，代表提出路线提案的汽车所有者及其显示名称。'
- en: '**Route closed/aborted**: It will contain just the unique route identifier
    and a flag specifying whether the route was successfully closed or aborted.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**路线关闭/取消**：它将仅包含唯一的路线标识符和一个标志，指定路线是否成功关闭或取消。'
- en: '**Route extension**: It informs that the car owner accepted extending the route
    with the start and ending towns of other requests. It contains the same information
    contained in the new route message as well as new request messages.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**路线扩展**：它通知汽车所有者已接受扩展路线，包括其他请求的出发地和结束地。它包含与新的路线消息相同的信息，以及新的请求消息。'
- en: It also contains a flag that specifies whether, after the extension, the route
    has been closed to other participants.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 它还包含一个标志，指定在扩展后，路线是否已对其他参与者关闭。
- en: The message content might appear redundant for the route-planning microservice.
    For instance, most of the information contained in the route extension message
    is already known to the route-planning microservice. As a matter of fact, the
    route-planning microservice needs just the unique identifiers of the request and
    route to join.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于路线规划微服务，消息内容可能显得冗余。例如，路线扩展消息中包含的大部分信息，路线规划微服务已经知道。实际上，路线规划微服务只需要请求和路线的唯一标识符来连接。
- en: However, messages sent with the publisher/subscriber pattern are used by several
    potentially unknown subscribers, so they can’t assume specific a priori knowledge
    of the subscribers. For instance, the route extension message will also be subscribed
    by the microservice that handles all requests that don’t contain information about
    all existing route proposals, so all information needed on the merged route must
    be received through this message.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用发布者/订阅者模式发送的消息被几个可能未知订阅者使用，因此它们不能假设订阅者具有特定的先验知识。例如，路线扩展消息也将被处理所有不包含有关所有现有路线提案信息的请求的微服务订阅，因此所有关于合并路线所需的信息都必须通过此消息接收。
- en: On the contrary, the route closed/aborted message doesn’t need to convey the
    whole route information, since any service interested in the event must already
    know of this route and must already have all the data it needs about it. It might
    lack this data if it has never interacted with this route, but in this case, the
    event represented by the message can’t modify its state and must simply be ignored.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，路线关闭/取消消息不需要传达整个路线信息，因为任何对事件感兴趣的服务必须已经知道此路线，并且必须已经拥有关于它的所有所需数据。如果它从未与此路线交互，它可能缺少这些数据，但在此情况下，由消息表示的事件不能修改其状态，而必须简单地忽略。
- en: 'An important question we must always ask about all microservices input is:
    what happens if the messages arrive in the wrong order, that is, in a different
    order than they were sent? If the message order matters, we either ensure that
    all messages arrive and are processed in the right order or we reorder messages
    with the technique explained in the *Efficacious handling of asynchronous communication*
    subsection of [*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying Microservices
    Applications*. Unfortunately, reordering input messages is not enough; we must
    also process them in the right order.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须始终对所有微服务输入提出的一个重要问题是：如果消息到达的顺序错误，即与发送的顺序不同，会发生什么？如果消息顺序很重要，我们要么确保所有消息都按正确顺序到达并被处理，要么使用在[*第二章*](Chapter_2.xhtml#_idTextAnchor038)中“揭秘微服务应用”的*有效处理异步通信*小节中解释的技术重新排序消息。不幸的是，重新排序输入消息是不够的；我们还必须按正确的顺序处理它们。
- en: This is not a trivial task if several replicas of the same microservice process
    these input messages concurrently. Luckily, no application needs a fixed ordering
    for all input messages. But some *related messages*, for instance, all messages
    that contain the same route, must be processed in the right order. Therefore,
    we can avoid *just* concurrent processing of *related messages* by passing all
    related messages to the same replica. We will analyze techniques for achieving
    a similar load-balancing strategy of all replicas in the *Ensuring that messages
    are processed in the proper order* section.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果多个相同微服务的副本并发处理这些输入消息，这并不是一个简单任务。幸运的是，没有应用程序需要为所有输入消息固定排序。但是，一些*相关消息*，例如，所有包含相同路由的消息，必须按正确顺序处理。因此，我们可以通过将所有相关消息传递给同一个副本来避免*仅仅*并发处理*相关消息*。我们将在*确保消息按正确顺序处理*部分分析实现类似负载均衡策略的技术。
- en: In our case, the order in which new route offers and route requests arrive is
    not an issue, since we can correctly process out-of-order messages with simple
    tricks. We just need to add an update version number to detect past updates. Update
    version numbers must be unique and must correspond to the real order in which
    updates were applied to a given entity. When the entity is created, it starts
    with version 0, and then this number is incremented at each new update.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这个案例中，新路由提供和路由请求到达的顺序并不是问题，因为我们可以通过简单的技巧正确处理乱序消息。我们只需要添加一个更新版本号来检测过去的更新。更新版本号必须是唯一的，并且必须与对给定实体应用更新的实际顺序相对应。当实体被创建时，它从版本
    0 开始，然后每次新更新都会增加这个数字。
- en: As a general rule, if all modification and creation messages contain the entire
    entity data, and if all deletes are logical, that is, entities are just marked
    as deleted, then messages don’t need to be ordered.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一般规则，如果所有修改和创建消息都包含整个实体数据，并且如果所有删除都是逻辑的，即实体只是被标记为已删除，那么消息不需要排序。
- en: In fact, we can recognize and apply an incoming modification only if it is more
    recent than the one already applied. Moreover, we can always verify whether the
    entity mentioned in a modification message has already been deleted and discard
    the modification. Finally, if an entity mentioned in a modification has not already
    been created, we can always create it with the data contained in the modification
    message, since each modification contains the entire entity data.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们只能识别并应用比已应用的更新更近的修改。此外，我们总是可以验证修改消息中提到的实体是否已经被删除，并丢弃该修改。最后，如果修改中提到的实体尚未创建，我们可以始终使用修改消息中包含的数据创建它，因为每个修改都包含整个实体数据。
- en: In our case, the order of the route extension messages doesn’t matter, because
    request merged to a route simply sum up and it is enough to select the more recent
    list of towns of the one stored in the route and the one contained in the message.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这个案例中，路由扩展消息的顺序并不重要，因为合并到路由中的请求只是简单相加，并且只需要选择存储在路由中的城镇列表和消息中包含的较新列表。
- en: Inversions of route extensions and route closed/aborted messages do not cause
    problems, too, since it is enough to ignore extensions of aborted routes, and
    to merge previous requests that arrived after the closure.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 路由扩展和路由关闭/中止消息的倒置也不会引起问题，因为忽略中止路由的扩展，并合并关闭后到达的先前请求就足够了。
- en: Inversions of route creations and extensions can never take place, since only
    successfully created routes can cause request-route matches that can subsequently
    cause route extensions.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 路由创建和扩展的逆操作永远不会发生，因为只有成功创建的路由才能引起请求-路由匹配，进而导致路由扩展。
- en: Deleted routes do not cause problems since both route aborted and closed messages
    are de facto logical deletes. We can delete them after the travel day has expired
    by *N* days, since at that point, previous delayed messages can’t arrive (messages
    can be delayed by some hours or even a day in the case of severe failures). This
    can be done with cron jobs.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 已删除的路由不会引起问题，因为路线中止和关闭消息实际上是逻辑删除。我们可以在旅行日过去后 *N* 天内删除它们，因为到那时，之前的延迟消息无法到达（在严重故障的情况下，消息可能会延迟数小时甚至一天）。这可以通过
    cron 作业完成。
- en: Possible duplication of messages due to timeouts and resends also do not cause
    problems since they can always be recognized and ignored. As an exercise, you
    can analyze all possibilities in detail.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 由于超时和重发导致的消息重复也不会引起问题，因为它们总是可以被识别并忽略。作为一个练习，你可以详细分析所有可能性。
- en: 'All required messages can be easily defined in terms of some basic types that
    we will place in a `BasicTypes` folder of the `SharedMessages` project. They are
    as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所有必需的消息都可以通过一些基本类型轻松定义，我们将它们放置在 `SharedMessages` 项目的 `BasicTypes` 文件夹中。具体如下：
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Moreover, since all messages must contain an update time, we may let all of
    them inherit from the following class:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于所有消息都必须包含一个更新时间，我们可以让它们都继承以下类：
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let’s place this class in the `BasicTypes` folder, too.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个类也放置在 `BasicTypes` 文件夹中。
- en: 'Now, all messages can be defined as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，所有消息都可以定义为以下内容：
- en: '**New request**:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**新请求**：'
- en: '[PRE9]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**New route**:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**新路由**：'
- en: '[PRE10]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Route closed/aborted**:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**路由关闭/中止**：'
- en: '[PRE11]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Route extension**:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**路由扩展**：'
- en: '[PRE12]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Place them in a `SharedMessages` project folder called `RouteNegotiation`.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 将它们放置在名为 `RouteNegotiation` 的 `SharedMessages` 项目文件夹中。
- en: We have just finished with the microservice input design! Let’s move on to the
    output.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚完成了微服务输入设计！让我们继续进行输出设计。
- en: Output communication
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出通信
- en: 'The output of the route-planning microservice consists of proposals to augment
    routes with matching requests. These proposals must be accepted by the users that
    own the routes. A single route extension message contains the unique identifier
    of the route and all its newly discovered matching requests:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 路线规划微服务的输出包括增加匹配请求以增强路线的建议。这些建议必须由拥有这些路线的用户接受。一个单独的路由扩展消息包含路线的唯一标识符以及所有新发现的匹配请求：
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Let’s place this class in the `RouteNegotiation` folder of the `SharedMessages`
    project.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个类放置在 `SharedMessages` 项目的 `RouteNegotiation` 文件夹中。
- en: Please notice that the timestamp associated with this message is the more recent
    timestamp associated with the route that this worker microservice received. In
    fact, this microservice doesn’t perform actual route updates, but just computes
    update proposals, which might be turned intoactual updates by another microservice.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，与此消息相关的时间戳是此工作微服务接收的路由的最新时间戳。实际上，这个微服务并不执行实际的路线更新，而只是计算更新建议，这些建议可能由另一个微服务转换为实际更新。
- en: As a rule of thumb, all updates to an entity must be performed on a single database
    replica. This way, computing entity versions becomes a feasible task that requires
    just a simple database transaction. Otherwise, each update should be coordinated
    among *N* different microservices with a complex distributed transaction. Therefore,
    if several microservices have different views of the same conceptual entity in
    their databases, each of them can change the entity private data it uses without
    needing to version them. But there should be a single microservice that is in
    charge of updating all shared properties of the entity, versioning them, and sending
    them to all interested microservices.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一条经验法则，对实体的所有更新都必须在一个数据库副本上执行。这样，计算实体版本就变成了一项可行的任务，只需要简单的数据库事务即可完成。否则，每个更新都应该在
    *N* 个不同的微服务之间进行协调，这需要复杂的分布式事务。因此，如果几个微服务在其数据库中具有相同概念实体的不同视图，它们中的每一个都可以更改其使用的实体私有数据，而无需对其进行版本控制。但应该有一个微服务负责更新实体的所有共享属性，对其进行版本控制，并将它们发送给所有感兴趣的微服务。
- en: Unfortunately, sometimes distributed transactions are unavoidable, but still,
    in these cases, a single microservice replica proposes a new version number that
    is accepted by all microservices involved in the transaction if the transaction
    succeeds.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，有时分布式事务是不可避免的，但即使在这些情况下，单个微服务副本也会提出一个新版本号，如果事务成功，所有参与事务的微服务都将接受这个版本号。
- en: Output messages can be placed in an internal queue implemented with permanent
    storage immediately after their creation, as explained in the *Efficacious handling
    of asynchronous communication* section of [*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038),
    *Demystifying Microservices Applications*. However, if we use a broker, that strategy
    needs to be modified a little bit. There, we applied an exponential retry strategy,
    by retrying the failed messages after an exponentially increasing time, while
    continuing to send other messages from the internal queue. When messages are not
    mediated by a message broker, this strategy makes sense, since the failure is
    connected either to the destination or to some component in the path between the
    source and destination. So, if the next message has a different destination, it
    would probably succeed.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 输出消息可以在其创建后立即放置在由永久存储实现的内部队列中，如[*第二章*](Chapter_2.xhtml#_idTextAnchor038)“揭秘微服务应用”中“有效处理异步通信”部分所述。然而，如果我们使用代理，该策略需要稍作修改。在那里，我们应用了指数重试策略，在指数增长的时间后重试失败的消息，同时继续从内部队列发送其他消息。当消息不由消息代理中介时，这种策略是有意义的，因为失败与目的地或源和目的地之间路径上的某些组件有关。因此，如果下一个消息有不同的目的地，它可能会成功。
- en: If we use a message broker, the failure depends on the message broker itself
    since the confirmation simply states that the message broker successfully received
    the message, not that the message was received and confirmed by the destination.
    Therefore, immediately attempting a new message transmission would probably result
    in another failure.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用消息代理，失败取决于消息代理本身，因为确认只是表明消息代理成功接收了消息，而不是消息被接收和确认。因此，立即尝试新的消息传输可能会再次导致失败。
- en: We may conclude that when communication is mediated by a message broker, we
    don’t need to delay the single faulty message; instead, we must stop sending messages
    to the message broker applying both exponential retry and circuit break strategies.
    Moreover, since keeping too many threads waiting for confirmations might congest
    the system, we must also apply a Bulkhead Isolation strategy to limit the number
    of pending tasks.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出结论，当通信由消息代理中介时，我们不需要延迟单个错误消息；相反，我们必须停止向消息代理发送消息，并应用指数重试和断路器策略。此外，由于保持太多线程等待确认可能会使系统拥塞，我们还必须应用舱壁隔离策略来限制挂起任务的数量。
- en: 'At this point, you might ask: why do we need an internal queue if we already
    have the message broker external queue? There are two reasons; the first one,
    in particular, is quite compelling:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你可能会问：如果我们已经有了外部队列的消息代理，为什么还需要内部队列？有两个原因；尤其是第一个原因相当有说服力：
- en: The internal queue is implemented with a database table, so it is populated
    in the same database transaction as the database update that triggered the output
    event. Therefore, if something goes wrong, the whole transaction is aborted, thus
    giving the possibility to retry it at a later time.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内部队列是通过数据库表实现的，因此它在触发输出事件的数据库更新同一事务中被填充。因此，如果出现问题，整个事务将被中止，从而为稍后重试提供了可能性。
- en: 'The performance cost for achieving the same result directly with the message
    broker queue is higher: we should keep the database transaction open until we
    receive a confirmation, an error, or a timeout from the message transmission to
    the message broker. This time becomes several orders of magnitude higher if we
    use exponential retry.'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接使用消息代理队列实现相同结果的性能成本更高：我们应该保持数据库事务打开，直到我们从消息传输到消息代理那里收到确认、错误或超时。如果我们使用指数重试，这个时间会高几个数量级。
- en: Once the message is in the internal queue, in case of failures, we don’t need
    to undo the database update but we need simply to retry the message transmission
    at a later time.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦消息进入内部队列，在出现故障的情况下，我们不需要撤销数据库更新，但需要简单地稍后重试消息传输。
- en: Due to the different ways databases and message brokers are implemented, and
    due to the fact that the database is shared just by the microservice replicas,
    the confirmation of the successful execution of the whole database transaction
    (required update plus registration of the output message in the internal queue)
    is faster than the message broker confirmation.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于数据库和消息代理的不同实现方式，以及数据库仅由微服务副本共享的事实，整个数据库事务（所需更新加在内部队列中注册输出消息）的成功执行确认比消息代理确认要快。
- en: Now that we have clarified how to handle both input and output messages, in
    general and for our route-planning microservice, we can discuss how to recover
    and maintain the proper message-processing order.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经明确了如何处理输入和输出消息，无论是总体上还是针对我们的路由规划微服务，我们可以讨论如何恢复和维护正确的消息处理顺序。
- en: Ensuring that messages are processed in the proper order
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确保消息按正确顺序处理
- en: As discussed in the previous subsections, our route-planning microservice doesn’t
    need to enforce the correct message-processing order. However, there are cases
    where processing all messages in the right order is unavoidable, so in this subsection,
    we will discuss how they are usually handled.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一小节所述，我们的路由规划微服务不需要强制执行正确的消息处理顺序。然而，在某些情况下，不可避免地需要按正确顺序处理所有消息，因此在本小节中，我们将讨论它们通常是如何处理的。
- en: It is worth pointing out that strategies for enforcing the right message-processing
    order have a non-negligible impact on performance and scalability, so any trick
    to avoid their usage is welcome.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，强制执行正确消息处理顺序的策略对性能和可扩展性有不可忽视的影响，因此任何避免使用它们的技巧都受欢迎。
- en: 'Usually, order constraints must be enforced just within the same group of related
    messages, so it is enough to ensure the following:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，顺序约束必须在同一相关消息组内强制执行，因此只需确保以下内容：
- en: All messages belonging to the same group of related messages are processed by
    the same microservice replica, so concurrence between replicas can’t shuffle the
    message-processing order.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有属于同一相关消息组的消息都由同一微服务副本处理，因此副本之间的并发不会打乱消息处理顺序。
- en: Each replica processes a message only after all previous messages have been
    successfully processed.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个副本仅在所有之前的消息都成功处理后才会处理消息。
- en: Proper operation of the preceding technique requires that each message contains
    its sequence number in its group.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 正确操作上述技术需要每个消息在其组中包含其序列号。
- en: Often, groups coincide with database entities, or better, with database aggregates.
    That is, two messages belong to the same group if they represent different operations
    performed on the same entity. Thus, in the case of our route-planning service,
    we might have a group for each request and for each route.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，组与数据库实体相对应，或者更好，与数据库聚合相对应。也就是说，如果两个消息代表对同一实体的不同操作，则它们属于同一个组。因此，在我们的路由规划服务中，我们可能为每个请求和每条路由都有一个组。
- en: 'Now suppose that that there are *N* microservice replicas, indexed by the integers
    from 1 to *N*. We can define a hash function that, given a group identifier, returns
    a number between 1 and *N*. This way, if we route each message to the replica
    indexed by the result of the hash function applied to the group of the message,
    all messages in the same group will be processed by the same replica. The following
    figure exemplifies the message-routing strategy:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设有 *N* 个微服务副本，由整数 1 到 *N* 索引。我们可以定义一个哈希函数，它给定一个组标识符，返回一个介于 1 和 *N* 之间的数字。这样，如果我们将每个消息路由到由哈希函数应用于消息组的索引的副本，则同一组中的所有消息都将由同一副本处理。以下图例说明了消息路由策略：
- en: '![Figure 7.4: Message sharding](img/B31916_07_4.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4：消息分片](img/B31916_07_4.png)'
- en: 'Figure 7.4: Message sharding'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：消息分片
- en: This technique is called **sharding**, and if the hash function is fair, each
    replica will receive the same *average* load.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术称为**分片**，如果哈希函数是公平的，每个副本将接收相同的*平均*负载。
- en: Thus, if we have no order constraints, we achieve exact load-balancing with
    a round-robin strategy, while with order constraints, we can just achieve *average*
    load-balancing with sharding. This means that probabilistic balancing fluctuations
    will for sure cause temporary congestion.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果没有顺序约束，我们可以通过轮询策略实现精确的负载均衡，而在顺序约束的情况下，我们只能通过分片实现*平均*负载均衡。这意味着概率平衡波动肯定会引起暂时性拥塞。
- en: Sharding will also cause a loss of flexibility in scaling the number of replicas.
    In fact, changing the number of replicas changes both the hash function and the
    group of messages received by each replica. For these reasons, scaling operations
    will have a higher cost and consequently can be performed less frequently. In
    practice, most orchestrators automatically scale non-indexed replicas according
    to customizable criteria, but don’t offer the same service for replicas that need
    to be indexed. We will analyze in more detail the difference between these different
    sets of replicas and automating scaling in [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205),
    *Practical Microservices Organization with Kubernetes*.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 分片还会导致在扩展副本数量时失去灵活性。实际上，更改副本数量会同时改变哈希函数和每个副本接收的消息组。因此，扩展操作的成本会更高，因此可以更频繁地执行。在实践中，大多数编排器会根据可定制的标准自动扩展非索引副本，但不会为需要索引的副本提供相同的服务。我们将在[*第8章*](Chapter_8.xhtml#_idTextAnchor205)“使用
    Kubernetes 的实用微服务组织”中更详细地分析这些不同副本集之间的差异以及自动扩展。
- en: Sharding can be implemented with a single-replica microservice that receives
    all messages from the message broker and routes them to the appropriate replicas
    by sending them to a replica-specific message broker queue. This technique is
    more complex and requires more coding, but it is more flexible. In fact, for instance,
    if it is informed by changes in the number of replicas, it can dynamically adapt
    its behavior to the number of replicas.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用单副本微服务来实现分片，该微服务接收来自消息代理的所有消息，并通过将它们发送到特定副本的消息代理队列将它们路由到适当的副本。这种技术更复杂，需要更多的编码，但更灵活。实际上，例如，如果它根据副本数量的变化而得知，它可以动态地根据副本数量调整其行为。
- en: Sharding can also be achieved with RabbitMQ topics. Basically, a topic is a
    string attached to a message, and event subscribers can be enabled just for some
    topics. Therefore, if we attach the result of the hash function to each message
    as a topic, then each replica can subscribe just to the topic equal to its index,
    thus implementing sharding with no need for an extra component.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 RabbitMQ 主题也可以实现分片。基本上，主题是附加到消息上的一个字符串，并且可以为某些主题启用事件订阅者。因此，如果我们将哈希函数的结果作为主题附加到每条消息上，那么每个副本只需订阅与其索引相等的主题，从而无需额外组件即可实现分片。
- en: The disadvantage of the topic-based sharding technique is that the number of
    replicas must be known to all senders and can be changed just by restarting the
    whole application. Moreover, since the topic to assign to each message depends
    on both how the destination microservice defines message groups and the destination
    microservice, the number of replicas technique can’t be used with the publisher/subscriber
    pattern where messages are received by several heterogeneous microservices.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 基于主题的分片技术的缺点是副本的数量必须为所有发送者所知，并且只能通过重启整个应用程序来更改。此外，由于分配给每条消息的主题既取决于目标微服务如何定义消息组，也取决于目标微服务，因此副本数量技术不能用于消息由多个异构微服务接收的发布/订阅模式。
- en: RabbitMQ also has a sharding plugin ([https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding))
    that computes a modulo *N* hash. This plugin defines a new type of exchange with
    a sharding-based routing strategy that we can attach immediately before each separate
    subscriber queue. Moreover, the plugin takes care of splitting the unique subscriber
    queue into *N* different sharded queues and distributing all subscribers among
    the *N* sharded queue. This technique is completely analogous to the single-replica
    routing microservice technique, but being integrated inside the message broker
    requires trading reduced flexibility for better performance. This technique solves
    all the problems of the topics-based technique but is not supported by the high-level
    **EasyNetQ** interface, so it increases the code complexity and maintainability.
    Moreover, it requires a broker configuration that depends on the exact topology
    of all subscribers, thus undermining the application’s extensibility.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ还有一个分片插件([https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding))，它计算一个模*N*散列。此插件定义了一种基于分片的路由策略的新类型交换，我们可以在每个单独的订阅者队列之前立即附加。此外，该插件负责将唯一的订阅者队列分割成*N*个不同的分片队列，并将所有订阅者分配到*N*个分片队列中。这种技术与单副本路由微服务技术完全类似，但集成在消息代理中需要以降低灵活性换取更好的性能。这种技术解决了基于主题技术的所有问题，但不支持高级**EasyNetQ**接口，因此增加了代码复杂性和可维护性。此外，它需要一个依赖于所有订阅者确切拓扑结构的代理配置，从而损害了应用程序的可扩展性。
- en: Summing up, when using publisher/subscriber communication, the best option is
    almost always the single-replica routing microservice technique.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，当使用发布者/订阅者通信时，最佳选择几乎总是单副本路由微服务技术。
- en: Having discussed microservices input and output, we can now move on to the design
    of the microservice container input parameters.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了微服务的输入和输出之后，我们现在可以继续讨论微服务容器输入参数的设计。
- en: Designing Docker image environment parameters
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计Docker镜像环境参数
- en: 'As already hinted at in the *A few more Docker commands and options* subsection
    of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067), *Setup and Theory: Docker and
    Onion Architecture*, containers usually adapt to their deployment environment
    by being passed as environment variables of the container’s virtual filesystem.
    In a .NET environment, parameters are available through the `IConfiguration` interface
    together with all parameters defined in the .NET configuration files, such as
    `appsettings.json`. Nested JSON paths are represented in the `IConfiguration`
    dictionary arguments by separating all segments with colons, as is the case for
    `IConfiguration[“ConnectionStrings:DefaultConnection”]`, which represents the
    usual default database connection string. When nested paths are represented by
    environment variables, colons are replaced with double underscores, in order to
    get valid environment variables names. Therefore, `ConnectionStrings:DefaultConnection`
    must be defined with an environment variable named `ConnectionStrings__DefaultConnection`.
    If environment variable names are prefixed with `ASPNETCORE_` or `DOTNET_`, these
    prefixes are removed; therefore, `ASPNETCORE_ENVIRONMENT` can be accessed with
    `IConfiguration[“ENVIRONMENT”]`. These prefixes are used to pass ASP.NET Core-
    and .NET-specific settings, such as staging, production, or development environment,
    and `ASPNETCORE_HTTP_PORTS` is also used, which contains a semicolon-separated
    list of all ports that Kestrel must listen on.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如同在[*第3章*](Chapter_3.xhtml#_idTextAnchor067)的*更多Docker命令和选项*子节中已经暗示的那样，*设置和理论：Docker和洋葱架构*，容器通常通过作为容器虚拟文件系统的环境变量来适应其部署环境。在.NET环境中，参数可以通过`IConfiguration`接口获得，以及所有在.NET配置文件中定义的参数，例如`appsettings.json`。嵌套的JSON路径通过在所有段之间用冒号分隔来表示`IConfiguration`字典参数，例如`IConfiguration[“ConnectionStrings:DefaultConnection”]`，它表示通常的默认数据库连接字符串。当嵌套路径由环境变量表示时，冒号被替换为双下划线，以便得到有效的环境变量名称。因此，`ConnectionStrings:DefaultConnection`必须使用名为`ConnectionStrings__DefaultConnection`的环境变量来定义。如果环境变量名称以`ASPNETCORE_`或`DOTNET_`为前缀，则这些前缀将被移除；因此，可以使用`IConfiguration[“ENVIRONMENT”]`来访问`ASPNETCORE_ENVIRONMENT`。这些前缀用于传递ASP.NET
    Core和.NET特定的设置，例如预发布、生产或开发环境，并且`ASPNETCORE_HTTP_PORTS`也被使用，它包含Kestrel必须监听的所有端口的分号分隔列表。
- en: 'You can also define your own custom prefix to apply to all your environment
    variables to avoid name collisions. However, since each microservice has a private
    container, collisions between environment variables used by different applications
    are impossible. Anyway, a new environment variable’s custom prefix can be defined
    inside the application services definition section with code analogous to the
    following:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以定义自己的自定义前缀，并将其应用于所有环境变量以避免名称冲突。然而，由于每个微服务都有一个私有容器，因此不同应用程序使用的环境变量之间的冲突是不可能的。无论如何，可以在应用程序服务定义部分中使用类似于以下代码的代码定义新环境变量的自定义前缀：
- en: '[PRE14]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As we will see in [*Chapter 8*](Chapter_8.xhtml#_idTextAnchor205), *Practical
    Microservices Organization with Kubernetes*, defining configuration settings with
    environment variables allows the easy specification of their values in the code
    files for the chosen orchestrator.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在[*第8章*](Chapter_8.xhtml#_idTextAnchor205)“使用Kubernetes的实用微服务组织”中看到的那样，使用环境变量定义配置设置允许轻松地在所选协调器的代码文件中指定它们的值。
- en: 'During development, environment variable values can be specified in the `Properties
    -> launchSettings.json` file of the top-level project of the Onion Architecture,
    which, in our case, is the `RoutesPlanning` project. The following snippet shows
    where to place your environment variable values:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中，可以在Onion架构顶层项目的`Properties -> launchSettings.json`文件中指定环境变量值，在我们的案例中，是`RoutesPlanning`项目。以下代码片段显示了放置您的环境变量值的位置：
- en: '[PRE15]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In our case, we need the following:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们需要以下内容：
- en: The database connection string
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库连接字符串
- en: The RabbitMQ connection string.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RabbitMQ的连接字符串。
- en: The maximum distance for proposing a match between a request and a route, and
    the maximum number of best matches to retrieve from the database.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提出请求与路由之间匹配的最大距离，以及从数据库中检索的最佳匹配数量的最大值。
- en: The subscription ID prefix for all our microservice replicas. This string is
    used as a prefix for all subscription queue names in our microservice replicas.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们所有微服务副本的订阅ID前缀。此字符串用作我们微服务副本中所有订阅队列名称的前缀。
- en: You don’t need to discover all the settings you need at this stage, just the
    ones that play a fundamental role in your microservice. Further settings can be
    easily added at a later time.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您在这个阶段不需要发现所有需要的设置，只需那些在您的微服务中起基本作用的设置即可。进一步的设置可以在稍后轻松添加。
- en: 'Therefore, let’s define all settings in the `launchSettings.json` file as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们将所有设置定义在`launchSettings.json`文件中，如下所示：
- en: '[PRE16]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We left the database connection string empty. We will fill it once we have defined
    the SQL Server development database.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据库连接字符串留空。一旦我们定义了SQL Server开发数据库，我们就会填充它。
- en: The RabbitMQ connection string contains the server URL and the default credential.
    Note that the default credentials are accepted just when RabbitMQ is accessed
    from `localhost`, so you are encouraged to change them once you have installed
    the server. `publisherConfirms=true` informs RabbitMQ that it must confirm that
    the message was safely received, and `timeout=10` specifies the connection timeout
    in seconds.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ的连接字符串包含服务器URL和默认凭证。请注意，默认凭证仅在从`localhost`访问RabbitMQ时被接受，因此一旦您安装了服务器，就鼓励您更改它们。`publisherConfirms=true`通知RabbitMQ它必须确认消息已被安全接收，而`timeout=10`指定了连接超时时间（秒）。
- en: The microservice main service
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务主服务
- en: 'All modern .NET applications based on a host allow the definition of the so-called
    **hosted services**, which are services similar to Windows services running for
    the entire application lifetime. They can be defined by implementing the `IHostedService`
    interface and adding them to the services definition section of the application
    with the following code:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 所有基于主机的现代.NET应用程序都允许定义所谓的**托管服务**，这些服务类似于在整个应用程序生命周期中运行的Windows服务。它们可以通过实现`IHostedService`接口并将它们添加到应用程序的服务定义部分来定义，如下面的代码所示：
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In practice, hosted services are defined by inheriting from `BackgroundService`,
    which contains a partial implementation of the service and exposes a single `ExecuteAsync`
    method that we must override.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，托管服务是通过从`BackgroundService`继承来定义的，它包含服务的一部分实现并公开了一个必须重写的`ExecuteAsync`方法。
- en: Our microservice needs three hosted services. The main one listens to all input
    messages arriving from the message broker and processes them. Another hosted service
    extracts messages from the output internal queue and sends them to the message
    broker. Finally, the third hosted service performs housekeeping jobs, such as
    deleting expired requests and routes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的微服务需要三个托管服务。主要的一个监听来自消息代理的所有输入消息并处理它们。另一个托管服务从输出内部队列中提取消息并发送到消息代理。最后，第三个托管服务执行一些维护工作，例如删除过期的请求和路由。
- en: 'This subsection describes the main hosted service. The job of this hosted service
    is quite simple it listens for all four input messages we defined, and once it
    has received a message, it will create a command specific to that message and
    invoke the command handler associated with that command. Commands and command
    handlers are Onion Architecture building blocks that were discussed in the *Commands*
    subsection of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067), *Setup and Theory:
    Docker and Onion Architecture*.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节描述了主要托管服务。这个托管服务的任务相当简单，它监听我们定义的所有四个输入消息，一旦收到消息，它将为该消息创建一个特定的命令并调用与该命令关联的命令处理器。命令和命令处理器是
    Onion 架构的构建块，这在[*第 3 章*](Chapter_3.xhtml#_idTextAnchor067)的*命令*小节中讨论过，*设置和理论：Docker
    和 Onion 架构*。
- en: 'Let’s create a `HostedServices` folder in the `RoutesPlanning` project. Then,
    add a class named `MainService` that inherits from `BackgroundService` to it:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 `RoutesPlanning` 项目中创建一个 `HostedServices` 文件夹。然后，向其中添加一个名为 `MainService`
    的类，该类继承自 `BackgroundService`：
- en: '[PRE18]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The class name is followed by a couple of parentheses since it is the principal
    constructor where we will add parameters. In fact, all parameters of a hosted
    service constructor are automatically taken from the dependency engine container,
    so we can put all services it needs to perform its job there: an `IConfiguration`
    parameter, and an `IServiceProvider` interface that we will use to get scoped
    services. In fact, command handlers are scoped services, so we need to create
    a request scope before requiring them for the dependency injection container.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 类名后面跟着一对括号，因为它是我们将添加参数的主要构造函数。实际上，托管服务构造函数的所有参数都自动从依赖引擎容器中获取，因此我们可以将其所有需要执行其工作的服务放在那里：一个
    `IConfiguration` 参数，以及一个我们将用于获取作用域服务的 `IServiceProvider` 接口。实际上，命令处理器是作用域服务，因此我们需要在要求它们之前创建一个请求作用域。
- en: 'Summing up our principal constructor, it looks as follows:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 总结我们的主要构造函数，它看起来如下：
- en: '[PRE19]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Before proceeding, let’s add this hosted service to the dependency injection
    container, so it will be immediately executed at the start of the program. We
    just need to add the following instruction to `Program.cs`:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们将此托管服务添加到依赖注入容器中，以便它在程序开始时立即执行。我们只需要将以下指令添加到 `Program.cs`：
- en: '[PRE20]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In the case of the worker microservice, there is a one-to-one mapping between
    messages and commands, and all input needed by the command is contained in the
    message, so a unique generic command called `MessageCommand<T>` suffices. Let’s
    define it in the `Commands` folder of the `RoutesPlanningApplicationServices`
    project:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作微服务的情况下，消息和命令之间存在一对一的映射，命令所需的所有输入都包含在消息中，因此一个名为 `MessageCommand<T>` 的唯一泛型命令就足够了。让我们在
    `RoutesPlanningApplicationServices` 项目的 `Commands` 文件夹中定义它：
- en: '[PRE21]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, let’s define a method that given a message of type `T` creates a scope,
    requires the appropriate command handler, and executes it:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义一种方法，该方法给定一个类型为 `T` 的消息，创建一个作用域，要求适当的命令处理器，并执行它：
- en: '[PRE22]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Errors, that is, exceptions thrown during a `ProcessMessage<T>` execution, are
    handled by counting the number of consecutive errors and then rethrowing the exception.
    As we will see, rethrowing the exception basically undoes the extraction of the
    messages from the message broker queue so it can be processed again.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 错误，即在 `ProcessMessage<T>` 执行期间抛出的异常，通过计算连续错误的数量然后重新抛出异常来处理。正如我们将看到的，重新抛出异常基本上是撤销从消息代理队列中提取消息的操作，以便它可以再次被处理。
- en: 'Error counting can be performed with a thread-safe critical region, as shown
    here:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 错误计数可以使用线程安全的临界区来执行，如下所示：
- en: '[PRE23]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Consecutive error counts can be used to define the microservice health state.
    Now, we can define an error-protected wrapper of `ProcessMessage<T>`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 连续错误计数可以用来定义微服务的健康状态。现在，我们可以定义 `ProcessMessage<T>` 的错误保护包装器：
- en: '[PRE24]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s also define a small method that computes the subscription ID to use for
    each message:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再定义一个小方法，用于计算每个消息要使用的订阅 ID：
- en: '[PRE25]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we are ready to define our main `ExecuteAsync` method; but before doing
    that, we must add a reference to the EasyNetQ NuGet package. Please select a version
    greater than or equal to 8, also if it is a prerelease. Once we have installed
    this package, we need to add its services to dependency injection in `Program.cs`
    by calling the `AddEasyNetQ` extension method and passing it the RabbitMQ connection
    string:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备定义我们的主要 `ExecuteAsync` 方法；但在做之前，我们必须添加对 EasyNetQ NuGet 包的引用。请选择一个大于或等于
    8 的版本，如果是预发布版本也行。一旦我们安装了这个包，我们需要通过调用 `AddEasyNetQ` 扩展方法并将其 RabbitMQ 连接字符串传递给它，将其服务添加到
    `Program.cs` 中的依赖注入：
- en: '[PRE26]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The chained call defines how to handle errors in the received message handlers.
    We decided to requeue faulty messages so that they can be retried. If a microservice
    replica is faulty and generates an error on all messages, the message will eventually
    be processed by a healthy replica, while the unhealthy replica will eventually
    be discovered thanks to the consecutive error count that we will expose on a health
    endpoint. Unhealthy replicas are killed and recreated by all microservice orchestrators.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 连接调用定义了如何在接收消息处理程序中处理错误。我们决定重新排队有问题的消息，以便它们可以重试。如果一个微服务副本有问题并且对所有消息都产生错误，那么消息最终将由一个健康的副本处理，而不健康的副本最终将由于我们将暴露在健康端点上的连续错误计数而被发现。所有微服务编排器都会杀死并重新创建不健康的副本。
- en: The requeue strategy is usually the best error-handling strategy for enterprise
    microservices. Anyway, there are other strategies available. If no strategy is
    specified, faulty messages, that is, messages whose handlers throw exceptions,
    are enqueued in a special error queue where they can be handled manually with
    administrative tools (see [https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe](https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe)).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 重排队策略通常是企业微服务最好的错误处理策略。无论如何，还有其他策略可用。如果没有指定策略，有问题的消息，即处理程序抛出异常的消息，将被排队在一个特殊的错误队列中，在那里可以使用管理工具手动处理（见[https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe](https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe))）。
- en: 'Access to all EasyNetQ communication facilities is done through an `IBus` interface.
    Let’s add it to our hosted service main constructor:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `IBus` 接口访问所有 EasyNetQ 通信设施。让我们将其添加到我们的托管服务主构造函数中：
- en: '[PRE27]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `IBus` interface handles all communication with three properties:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`IBus` 接口处理与三个属性的所有通信：'
- en: '`PubSub`: This contains all methods for sending and receiving messages with
    the publisher/subscriber pattern'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PubSub`：这包含使用发布/订阅模式发送和接收消息的所有方法'
- en: '`SendReceive`: This contains all methods for sending and receiving messages
    with direct communication'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SendReceive`：这包含使用直接通信发送和接收消息的所有方法'
- en: '`Rpc`: This contains all methods for issuing asynchronous remote procedure
    calls and returning their responses'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Rpc`：这包含发出异步远程过程调用并返回其响应的所有方法'
- en: Here, we will describe `PubSub`, but `SendReceive` is completely analogous.
    The only difference is that the `Send` method explicitly specifies the name of
    the destination queue, while `Publish` does not. The `Publish` RabbitMQ exchange
    name is implicitly defined through the type of the message.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将描述 `PubSub`，但 `SendReceive` 完全类似。唯一的区别是 `Send` 方法明确指定了目标队列的名称，而 `Publish`
    则没有。`Publish` RabbitMQ 交换机的名称通过消息的类型隐式定义。
- en: 'The following are the publish methods:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些发布方法：
- en: '[PRE28]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The second overload lets you specify a message topic, while the third lets you
    specify various configuration settings that may also include the message topic.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个重载允许您指定消息主题，而第三个允许您指定可能包括消息主题的各种配置设置。
- en: 'The following are the subscribe methods:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些订阅方法：
- en: '[PRE29]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The returned value must be disposed of to unsubscribe. The second overload
    accepts a `CancelationToken` in the message handler, and also accepts a configuration
    action. The configuration of the receiver contains more useful settings, among
    them the following:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的值必须被销毁以取消订阅。第二个重载接受消息处理程序中的 `CancelationToken`，并且也接受配置操作。接收器的配置包含更多有用的设置，其中以下是一些：
- en: '`conf => conf.WithTopic(“mytopic”).WithTopic(“anothertopic”)`: The consumer
    will receive just the messages tagged with one of the selected topics.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conf => conf.WithTopic(“mytopic”).WithTopic(“anothertopic”)`：消费者将只接收标记为所选主题之一的消息。'
- en: '`conf => conf.WithPrefetchCount(N)`: `N` is the maximum number of messages
    extracted from the queue by the consumer and waiting to be processed. *N* defaults
    to 20.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conf => conf.WithPrefetchCount(N)`：`N`是消费者从队列中提取的最大消息数，并等待处理。*N*默认为20。'
- en: '`Conf => conf.WithDurable(durable)`: If `durable` is `true`, all consumer queue
    messages are recorded on disk by RabbitMQ. The default is `true`.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Conf => conf.WithDurable(durable)`：如果`durable`为`true`，所有消费者队列消息都将由RabbitMQ记录在磁盘上。默认为`true`。'
- en: If messages must be processed in the same order that they were inserted in the
    queue, the prefetch count must be set to `1` and we must also apply one of the
    strategies described in the *Ensuring that messages are processed in the proper
    order* subsection.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如果必须按照它们在队列中插入的顺序处理消息，则必须将预取计数设置为`1`，并且我们还必须应用在*确保消息按正确顺序处理*子节中描述的一种策略。
- en: If we use `Subscribe`, all prefetched messages are put in an internal in-memory
    queue and processed in a unique thread. However, there is also a completely analogous
    `SubscribeAsync` that creates several parallel threads. Moreover, `SubscribeAsync`,
    as usual, returns `Task<SubscriptionResult>`.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用`Subscribe`，所有预取的消息都会放入一个内部内存队列，并在一个独特的线程中处理。然而，也存在一个完全类似的`SubscribeAsync`，它创建几个并行线程。此外，`SubscribeAsync`，像往常一样，返回`Task<SubscriptionResult>`。
- en: We will use `SubscribeAsync` to better exploit processor cores, and parallelism
    between disk/database operations and processor operations, but the simple fact
    of using several microservice replicas already exploits parallelism. The advantage
    of using several threads is that creating a thread costs less than creating another
    replica, so each replica should use several threads to optimize performance.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`SubscribeAsync`来更好地利用处理器核心，以及磁盘/数据库操作和处理器操作之间的并行性，但使用几个微服务副本的事实已经利用了并行性。使用多个线程的优势在于创建线程的成本低于创建另一个副本，因此每个副本应该使用多个线程来优化性能。
- en: When the message handler successfully completes the task, a confirmation is
    automatically sent to RabbitMQ that deletes the message from the queue.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 当消息处理程序成功完成任务时，将自动向RabbitMQ发送确认，从队列中删除消息。
- en: On the contrary, if the message handler throws an unhandled exception, the configured
    consumer error strategy is applied. In our case, we requeue the message.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果消息处理程序抛出一个未处理的异常，将应用配置的消费者错误策略。在我们的例子中，我们将消息重新入队。
- en: 'Now, we are finally ready to write the main `ExecuteAsync` method. After our
    configuration and preparation methods, it became straightforward:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们终于准备好编写主要的`ExecuteAsync`方法。在我们的配置和准备方法之后，它变得非常直接：
- en: '[PRE30]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We just subscribe to all messages using our unique generic message handler,
    and then wait for the replica termination on the wait handle `stoppingToken.WaitHandle`.
    As soon as we receive notification that the replica is being terminated through
    `WaitOne()`, the wait handle is unblocked and we unsubscribe all messages by calling
    the `Dispose` methods of all `SubscriptionResult`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅使用我们独特的泛型消息处理程序订阅所有消息，然后等待等待句柄`stoppingToken.WaitHandle`上的副本终止。一旦我们通过`WaitOne()`收到副本正在终止的通知，等待句柄将被解除阻塞，我们通过调用所有`SubscriptionResult`的`Dispose`方法来取消订阅所有消息。
- en: Before moving on to the implementation of the two remaining hosted services,
    for completeness, we will also describe the EasyNetQ RPC facilities.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续实现剩余的两个托管服务之前，为了完整性，我们还将描述EasyNetQ的RPC功能。
- en: EasyNetQ’s RPC facilities
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: EasyNetQ的RPC功能
- en: 'An RPC request can be issued with the following methods:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下方法发出RPC请求：
- en: '[PRE31]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Once the request is issued, the returned task will eventually provide the response.
    We can wait it with `await` or specify a callback by calling `Task<T>.ContinueWith`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发出请求，返回的任务最终将提供响应。我们可以使用`await`等待它，或者通过调用`Task<T>.ContinueWith`指定一个回调。
- en: 'The recipient can listen for requests and provide responses with the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 接收者可以使用以下方式监听请求并提供响应：
- en: '[PRE32]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The recipient can stop handling requests by disposing of the `IDisposable` returned
    by the preceding methods.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 接收者可以通过处置前面方法返回的`IDisposable`来停止处理请求。
- en: Now, let’s move on to the remaining hosted services.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续处理剩余的托管服务。
- en: Other required hosted services
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他必需的托管服务
- en: 'We will start with the housekeeping hosted service. Let’s call it `HouseKeepingService`
    and place it in the `HostedServices` folder together with `MainService`:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从家务托管服务开始。让我们称它为`HouseKeepingService`，并将其与`MainService`一起放在`HostedServices`文件夹中：
- en: '[PRE33]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Before proceeding, let’s add the new hosted service to the dependency injection
    container, so it will be immediately executed at program start. We just need to
    add the following instruction to `Program.cs`:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们将新的托管服务添加到依赖注入容器中，这样它将在程序启动时立即执行。我们只需要将以下指令添加到`Program.cs`中：
- en: '[PRE34]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We need a `HouseKeepingCommand` whose constructor specifies the number of days
    to wait after a route or request expiration before deleting it. As usual, let’s
    define it in the `Commands` folder of `RoutesPlanningApplicationServices`:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个构造函数指定在删除路由或请求过期后等待多少天才能删除的`HouseKeepingCommand`。像往常一样，让我们在`RoutesPlanningApplicationServices`的`Commands`文件夹中定义它：
- en: '[PRE35]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We also need to define the `Timing__HousekeepingIntervalHours` and `Timing__HousekeepingDelayDays`
    environment variables in `launchSettings.json`:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要在`launchSettings.json`中定义`Timing__HousekeepingIntervalHours`和`Timing__HousekeepingDelayDays`环境变量：
- en: '[PRE36]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `ExecuteAsync` method must execute a loop until the application signals
    termination. Inside this loop, it executes the handler and then sleeps for the
    time specified by `Timing__HousekeepingIntervalHours` or until the replica terminates:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExecuteAsync`方法必须执行一个循环，直到应用程序发出终止信号。在这个循环内部，它执行处理器然后休眠由`Timing__HousekeepingIntervalHours`指定的时长，或者直到副本终止：'
- en: '[PRE37]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In case of errors, we simply do nothing and repeat the operation at the next
    iteration. The `Task.Delay` instruction at the end of the iteration leaves the
    thread sleeping until either the configured interval expires or `stoppingToken`
    signals the replica termination.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在出现错误的情况下，我们简单地什么也不做，并在下一次迭代中重复操作。迭代末尾的`Task.Delay`指令使线程休眠，直到配置的间隔到期或`stoppingToken`发出副本终止信号。
- en: 'Let’s move on to the last hosted service. Let’s repeat the same steps to create
    it and call it `OutputSendingService`:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续到最后一个托管服务。让我们重复相同的步骤来创建它并命名为`OutputSendingService`：
- en: '[PRE38]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As usual, let’s add the new hosted service to the dependency injection container:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，让我们将新的托管服务添加到依赖注入容器中：
- en: '[PRE39]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This time, we need a command that accepts `Func<RouteExtensionProposalsMessage,Task>`
    as input. This input action wraps the code for sending `RouteExtensionProposalsMessage`
    to RabbitMQ because commands can contain code that depends on a specific driver,
    which in our case is the RabbitMQ client. It also needs a `batchCount` parameter,
    which specifies how many output messages are simultaneously extracted from the
    output queue, and a `requeueDelay` parameter, which specifies the overall timeout
    after which a message is requeued if it is not successfully received by the message
    broker.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们需要一个命令，它接受`Func<RouteExtensionProposalsMessage,Task>`作为输入。这个输入操作封装了将`RouteExtensionProposalsMessage`发送到RabbitMQ的代码，因为命令可以包含依赖于特定驱动程序的代码，在我们的例子中是RabbitMQ客户端。它还需要一个`batchCount`参数，该参数指定从输出队列中同时提取多少条输出消息，以及一个`requeueDelay`参数，该参数指定在消息未成功被消息代理接收后，消息重新入队的整体超时时间。
- en: 'We can define a generic command that receives just `Func<T,Task>`, so we can
    reuse it with other output messages; let’s call it `OutputSendingCommand`:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义一个泛型命令，它只接收`Func<T,Task>`，这样我们就可以将其与其他输出消息一起重用；让我们称它为`OutputSendingCommand`：
- en: '[PRE40]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The command contains a flag where its handler will signal whether the output
    queue was found empty. We will use this flag to put the hosted service thread
    to sleep for a certain interval to avoid wasting resources.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 命令中包含一个标志，其处理器将指示输出队列是否为空。我们将使用这个标志将托管服务线程休眠一段时间，以避免资源浪费。
- en: 'Again, we need a `Timing__OutputEmptyDelayMS` environment variable to configure
    the time to wait when the output queue is empty. Let add it to `launchSettings.json`:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们需要一个`Timing__OutputEmptyDelayMS`环境变量来配置输出队列为空时等待的时间。让我们将它添加到`launchSettings.json`中：
- en: '[PRE41]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We need also the `batchCount` and `requeueDelay` values to pass to the command:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要传递给命令的`batchCount`和`requeueDelay`值：
- en: '[PRE42]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Suppose we have a `SafeInvokeCommand` we need to implement that also returns
    whether the output queue is empty:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要实现一个`SafeInvokeCommand`，它也返回输出队列是否为空：
- en: '[PRE43]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then, the `ExetuteAsync` method can be implemented as follows:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以实现`ExetuteAsync`方法如下：
- en: '[PRE44]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: An outermost loop that exits only when the replica is going to be terminated,
    and an inner loop that reads the internal output queue and sends messages to the
    messages broker until the output queue is empty. When the output queue is empty,
    the service sleeps to wait for new messages being inserted in the internal output
    queue.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 一个外层循环仅在副本即将终止时退出，一个内层循环读取内部输出队列并将消息发送到消息代理，直到输出队列为空。当输出队列为空时，服务休眠以等待新消息被插入到内部输出队列中。
- en: 'Before implementing `SafeInvokeCommand`, we must code the `Func<T,Task>` wrapper
    to pass to the command:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现`SafeInvokeCommand`之前，我们必须编写`Func<T,Task>`包装器以传递给命令：
- en: '[PRE45]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now, the implementation is analogous to the command invoker of `MainService`:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，实现与`MainService`的命令调用者类似：
- en: '[PRE46]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: In case of exceptions, we simply return `true` to put the thread to sleep for
    some time. In the next section, we will use the Polly library to define retry
    strategies.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在发生异常的情况下，我们简单地返回`true`以使线程休眠一段时间。在下一节中，我们将使用Polly库定义重试策略。
- en: Ensuring resilient task execution with Polly
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Polly确保弹性任务执行
- en: Message sending should always be protected with at least exponential retry and
    the circuit break strategies that we analyzed in the *Resilient task execution*
    subsection of[*Chapter 2*](Chapter_2.xhtml#_idTextAnchor038), *Demystifying Microservices
    Applications*. In this section, we will first describe the Polly library, which
    became a kind of standard for handling resilient task execution, and then we will
    apply it to the `SendMessage` method of `OutputSendingService`.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 消息发送应该始终使用至少指数重试和我们在[*第二章*](Chapter_2.xhtml#_idTextAnchor038)的*弹性任务执行*子节中分析的电路断开策略进行保护，该章节是《揭秘微服务应用》。在本节中，我们将首先描述Polly库，它已成为处理弹性任务执行的一种标准，然后我们将将其应用于`OutputSendingService`的`SendMessage`方法。
- en: The Polly library
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Polly库
- en: Resilient communication and, in general, resilient task execution can be implemented
    easily with the help of a .NET library called **Polly**, whose project is a member
    of the .NET Foundation. Polly is available through the `Polly` NuGet package.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 使用名为**Polly**的.NET库可以轻松实现弹性通信和一般弹性任务执行，该库的项目是.NET基金会的成员。Polly可以通过`Polly` NuGet包获得。
- en: 'In Polly, you define policies and then execute tasks in the context of those
    policies, as follows:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在Polly中，你首先定义策略，然后在策略的上下文中执行任务，如下所示：
- en: '[PRE47]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The first part of each policy specifies the exceptions that must be handled.
    Then, you specify what to do when one of those exceptions is captured. In the
    preceding code, the `Execute` method is retried up to three times if a failure
    is reported by either an `HttpRequestException` exception or an `OperationCanceledException`
    exception.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 每个策略的第一部分指定了必须处理的异常。然后，你指定当捕获到这些异常之一时应该做什么。在上面的代码中，如果报告失败是由`HttpRequestException`异常或`OperationCanceledException`异常引起的，则`Execute`方法会重试最多三次。
- en: 'The following is the implementation of an exponential retry policy:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是实现指数重试策略的代码：
- en: '[PRE48]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The first argument of `WaitAndRetryAsync` specifies that a maximum of six retries
    is performed in the event of failure. The lambda function passed as the second
    argument specifies how much time to wait before the next attempt. In this specific
    example, this time grows exponentially with the number of attempts by a power
    of 2 (two seconds for the first retry, four seconds for the second retry, and
    so on). The following is a simple circuit breaker policy:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '`WaitAndRetryAsync`的第一个参数指定在失败的情况下执行最多六次重试。作为第二个参数传递的lambda函数指定在下次尝试之前等待的时间。在这个特定的例子中，这个时间随着尝试次数的增加而指数增长，以2的幂次（第一次重试为两秒，第二次重试为四秒，依此类推）。以下是一个简单的电路断开策略：'
- en: '[PRE49]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: After six failures, the task can’t be executed for one minute since an exception
    is returned.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 经过六次失败后，任务由于返回异常而无法执行一分钟。
- en: 'The following is the implementation of the Bulkhead Isolation policy:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是实现隔离舱隔离策略的代码：
- en: '[PRE50]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: A maximum of 10 parallel executions is allowed in the `Execute` method. Further
    tasks are inserted in an execution queue. This has a limit of 15 tasks. If the
    queue limit is exceeded, an exception is thrown. For the Bulkhead Isolation policy
    to work properly and, in general, for every strategy to work properly, task executions
    must be triggered through the same policy instance; otherwise, Polly is unable
    to count how many executions of a specific task are active.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Execute`方法中允许最多10个并行执行。进一步的任务将被插入到执行队列中。该队列的容量为15个任务。如果队列容量超过限制，将抛出异常。为了使Bulkhead
    Isolation策略正常工作，以及在一般情况下，为了使每个策略正常工作，任务执行必须通过相同的策略实例触发；否则，Polly无法计算特定任务的活跃执行次数。
- en: 'Policies can be combined with the `Wrap` method:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 策略可以通过`Wrap`方法结合：
- en: '[PRE51]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Polly offers several more options, such as generic methods for tasks that return
    a specific type, timeout policies, task result caching, the ability to define
    custom policies, and so on. It is also possible to configure Polly as part of
    an `HttpClient` definition in the dependency injection section of any ASP. NET
    Core and .NET application. This way, it is quite immediate to define resilient
    HTTP clients. Finally, version 8 also introduced a new API based on creating pipelines
    of strategies.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: Polly提供了更多选项，例如为返回特定类型的任务提供通用方法、超时策略、任务结果缓存、定义自定义策略的能力等等。它还允许在ASP. NET Core和.NET应用程序的依赖注入部分的`HttpClient`定义中将Polly配置为一部分。这样，定义健壮的HTTP客户端就变得相当直接。最后，版本8还引入了一个基于创建策略管道的新API。
- en: 'Polly’s official documentation can be found in its GitHub repository here:
    [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: Polly的官方文档可以在其GitHub存储库中找到：[https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly)。
- en: In the next subsection, we will install and use Polly for a resilient transmission
    of the microservices output messages to the message broker.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将安装和使用Polly来对微服务输出消息进行健壮传输到消息代理。
- en: Adding Polly to our project
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将Polly添加到我们的项目中
- en: 'Using Polly in our project is straightforward. First of all, you must add a
    reference to the last version of the Polly NuGet package in the `RoutesPlanning`
    project. Then, you must modify the `SendMessage` method of the `OutputSendingService`
    class as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的项目中使用Polly很简单。首先，您必须在`RoutesPlanning`项目中添加对Polly最新版本的NuGet包的引用。然后，您必须修改`OutputSendingService`类的`SendMessage`方法，如下所示：
- en: '[PRE52]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: We first define an exponential retry policy, then a circuit breaker policy,
    and finally combine them and execute the message sending inside `combinedPolicy.ExecuteAsync`.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义一个指数重试策略，然后是一个断路器策略，最后在`combinedPolicy.ExecuteAsync`中结合它们并执行消息发送。
- en: All strategies’ parameters could be specified with environment variables, but
    for simplicity, we left constant all values but `circuitBreakDelay`, that is,
    the time a circuit break should last. In fact, this is the only critical parameter
    that might need to be tuned.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 所有策略的参数都可以通过环境变量指定，但为了简单起见，我们除了`circuitBreakDelay`之外的所有值都保持为常量，即断路器应该持续的时间。实际上，这是唯一可能需要调整的关键参数。
- en: '`circuitBreakDelay` can be configured in an environment variable in `launchSettings.json`
    as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`circuitBreakDelay`可以在`launchSettings.json`环境变量中配置，如下所示：'
- en: '[PRE53]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Then, it can be defined as an `OutputSendingService` field with the following:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它可以定义为`OutputSendingService`字段，如下所示：
- en: '[PRE54]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: From abstraction to implementation details
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从抽象到实现细节
- en: In the previous sections, we defined the overall organization of the route-planning
    microservice. In this final section, we will fill in all the details by first
    defining the domain layer and the database driver, and then defining all commands.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们定义了路线规划微服务的整体组织结构。在本节的最后，我们将通过首先定义领域层和数据库驱动程序，然后定义所有命令来填充所有细节。
- en: The domain layer
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 领域层
- en: We will define each aggregate in a separate folder that will contain the aggregate,
    the interface that defines the aggregate state, and the repository interface associated
    with the aggregate.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在单独的文件夹中定义每个聚合，该文件夹将包含聚合、定义聚合状态的接口以及与聚合关联的存储库接口。
- en: 'However, before starting the definition of all aggregates, we need to add a
    famous library for handling both geometric and GIS calculations: `NetTopologySuite`.
    It is available in both Java and .NET and all its types conform to a standard
    recognized by all main databases.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在开始定义所有聚合之前，我们需要添加一个用于处理几何和GIS计算的著名库：`NetTopologySuite`。它既适用于Java也适用于.NET，并且所有类型都符合所有主要数据库认可的标准。
- en: The .NET version is available through the `NetTopologySuite` NuGet package.
    Therefore, let’s add this package to the `RoutesPlanningDomainLayer` project.
    The meaning of GIS object coordinates is defined in documents classified with
    integers called **Spatial Reference Identifiers** (**SRIDs**). Each document specifies
    the meaning of the *x* and *y* coordinates, how to compute the distance between
    two points, and the part of the Earth’s surface it applies to. Each GIS object
    must specify the SRID used by its coordinates, and only objects with the same
    SRID can be used in the same computation.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: .NET 版本可通过 `NetTopologySuite` NuGet 包获得。因此，让我们将此包添加到 `RoutesPlanningDomainLayer`
    项目中。GIS 对象坐标的含义在称为**空间参考标识符**（**SRIDs**）的整数分类文档中定义。每个文档指定了 *x* 和 *y* 坐标的含义，如何计算两点之间的距离，以及它适用的地球表面部分。每个
    GIS 对象必须指定其坐标使用的 SRID，并且只有具有相同 SRID 的对象才能在同一计算中使用。
- en: We will use SRID 4326, which applies to the entire surface of the Earth. `X`
    is the longitude in degrees and `Y` is the latitude in degrees; the distance is
    computed in meters by approximating the Earth’s surface with an ellipsoid. More
    precise results can be obtained with SRIDs that apply to smaller portions of the
    Earth’s surface, but SRID 4326 is supported by all main databases.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 SRID 4326，它适用于地球的整个表面。`X` 是经度（以度为单位），`Y` 是纬度（以度为单位）；距离通过将地球表面近似为椭球体来计算。使用适用于地球表面较小部分的
    SRID 可以获得更精确的结果，但 SRID 4326 被所有主要数据库支持。
- en: 'Let’s define our overall default SRID in a static class defined in the root
    of the `RoutesPlanningDomainLayer` project:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 `RoutesPlanningDomainLayer` 项目的根目录中定义的静态类中定义我们的整体默认 SRID：
- en: '[PRE55]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'As in the case of messages, we need intermediate types. Let’s define them in
    a `RoutesPlanningDomainLayer -> Models -> BasicTypes` folder:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在消息的情况下，我们需要中间类型。让我们在 `RoutesPlanningDomainLayer -> Models -> BasicTypes`
    文件夹中定义它们：
- en: '**Route status**:'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**路线状态**：'
- en: '[PRE56]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '**Time interval**:'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间间隔**：'
- en: '[PRE57]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Town info:'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 城市信息：
- en: '[PRE58]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'User info:'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户信息：
- en: '[PRE59]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '`Point` is a `NetTopologySuite` type that specifies a point on the Earth’s
    surface. Please note that all of the preceding types are what we called value
    objects in the *The domain layer* subsection of[*Chapter 3*](Chapter_3.xhtml#_idTextAnchor067),
    *Setup and Theory: Docker and Onion Architecture*. Therefore, as suggested there,
    we defined them as .NET record types.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '`Point` 是一个 `NetTopologySuite` 类型，它指定了地球表面上的一个点。请注意，所有前面的类型都是我们在[*第 3 章*](Chapter_3.xhtml#_idTextAnchor067)的*域层*小节中称为值对象的内容，*设置和理论：Docker
    和洋葱架构*。因此，正如那里所建议的，我们将它们定义为 .NET 记录类型。'
- en: Now, we can start defining our aggregates. For each of them, we will first define
    its status interface, then the aggregate, and finally, the associated repository
    interface. Usually, the definition of all these data types is iterative; that
    is, we start with a first draft, and then, when we realize we need another property
    or method, we add it.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以开始定义我们的聚合。对于每一个，我们首先定义其状态接口，然后是聚合，最后是相关的存储库接口。通常，所有这些数据类型的定义是迭代的；也就是说，我们从一个初步草案开始，然后，当我们意识到我们需要另一个属性或方法时，我们添加它。
- en: The route request aggregate
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 路线请求聚合
- en: 'Let’s create a `Models -> Request` folder for all types related to a user request.
    The status of a user request can be represented as follows:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为所有与用户请求相关的类型创建一个 `Models -> Request` 文件夹。用户请求的状态可以表示如下：
- en: '[PRE60]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: All properties that cannot be changed by aggregates have been defined as get-only
    properties. `Id` uniquely identifies each request in the overall application.
    `Source` and `Destination` are, respectively, the desired departure and arrival
    towns, while `WhenStart` and `WhenEnd` define the acceptable days for travel.
    Then, we have information on the user that issued the request and the current
    timestamp associated with the request. Finally, `RouteId` is the unique identifier
    of the route that the request has been added to, if any. If the request is still
    open, this property is `null`.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 所有不能由聚合更改的属性都已定义为只读属性。`Id` 在整个应用程序中唯一标识每个请求。`Source` 和 `Destination` 分别是期望出发和到达的城市，而
    `WhenStart` 和 `WhenEnd` 定义了可接受的旅行日期。然后，我们有关于发起请求的用户和与请求相关联的当前时间戳的信息。最后，`RouteId`
    是请求已添加到的路线的唯一标识符（如果有的话）。如果请求仍然开放，此属性为 `null`。
- en: 'The aggregate can be defined as follows:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合可以定义为以下内容：
- en: '[PRE61]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: It is worth pointing out that once a request has been created, only its `state.RouteId`
    can be changed. This is because once issued, each request cannot be modified but
    just matched with existing routes.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，一旦请求被创建，只有其 `state.RouteId` 可以更改。这是因为一旦发出，每个请求都不能修改，只能与现有路由匹配。
- en: 'The repository interface is as follows:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 仓库接口如下：
- en: '[PRE62]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The `New` method creates a new instance of the aggregate and its database-attached
    state. Then, we have methods for getting a single or more existing aggregates
    from their `Id`, and all aggregates that are served by the same route.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '`New` 方法创建聚合的新实例及其数据库附加状态。然后，我们有方法从它们的 `Id` 获取单个或多个现有聚合，以及由同一路由提供的所有聚合。'
- en: The `GetMatch` method returns all aggregates that are the best match with a
    route. The route is specified by the coordinates of the towns it passes through
    (`geometry`), and by its date (`When`). `Coordinate` is a `NetTopologySuite` type
    that contains just the *X* and *Y* coordinates of a location without its SRID
    (the default SRID defined before is implicit). `distance` specifies the maximum
    distance between the request and a route for a match to occur. All results are
    ordered according to their distance from the route, and a maximum of `maxResults`
    requests is returned.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '`GetMatch` 方法返回所有与路由最佳匹配的聚合。路由由它通过的城镇的坐标（`geometry`）和日期（`When`）指定。`Coordinate`
    是一个 `NetTopologySuite` 类型，它只包含位置的 *X* 和 *Y* 坐标，没有其 SRID（之前定义的默认 SRID 是隐含的）。`distance`
    指定请求和路由之间的最大距离，以便发生匹配。所有结果都根据它们与路由的距离排序，并且返回最多 `maxResults` 个请求。'
- en: The `DeleteBefore` method is used to perform some housekeeping by deleting old,
    expired requests.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '`DeleteBefore` 方法用于通过删除旧的和过期的请求来执行一些维护工作。'
- en: The route offer aggregate
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 路线报价聚合
- en: 'Let’s create a `Models -> Route` folder for all types related to a user route
    offer. The status of a user request can be represented as follows:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为所有与用户路线报价相关的类型创建一个 `Models -> Route` 文件夹。用户请求的状态可以表示如下：
- en: '[PRE63]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '`LineString` is a `NetTopologySuite` type that represents a path made of consecutive
    segments on the Earth’s surface. Basically, it is a sequence of coordinates with
    an attached SRID. `Status` is the status of the route (open to other participants,
    closed, or aborted).'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '`LineString` 是一个 `NetTopologySuite` 类型，它表示由地球表面上的连续段组成的路径。基本上，它是一系列带有附加 SRID
    的坐标。`Status` 是路由的状态（对其他参与者开放、关闭或已取消）。'
- en: 'The aggregate can be defined as follows:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合可以定义如下：
- en: '[PRE64]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Here, dots have been added in place of methods we will analyze shortly. The
    `LineString` path contained in the aggregate state is exposed as an immutable
    list of its coordinates so that it can’t be modified directly, and can’t have
    its SRID changed.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经添加了点代替我们很快将要分析的方法。聚合状态中包含的 `LineString` 路径被公开为一个不可变的坐标列表，这样就不能直接修改它，也不能更改其
    SRID。
- en: 'It contains an `Extend` method that is called when a message requiring the
    extension of the route is received. The data contained in the message is passed
    as its parameters:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 它包含一个在接收到需要扩展路由的消息时被调用的 `Extend` 方法。消息中包含的数据作为其参数传递：
- en: '[PRE65]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The path is updated only if it is more recent than the path stored in the aggregate,
    while the requests contained in the extension message are always attached to the
    route offer, because each message doesn’t contain all matched requests but just
    the newly added ones, so they must also be added if we received an old message.
    The only case when the requests must not be added is when the route has already
    been aborted, because aborted routes release all their attached requests.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当路径比聚合中存储的路径更新时，路径才会更新，而扩展消息中包含的请求始终附加到路线报价，因为每个消息都不包含所有匹配的请求，而只是新添加的请求，所以如果收到旧消息，它们也必须被添加。唯一不需要添加请求的情况是当路线已被取消时，因为已取消的路线会释放所有附加的请求。
- en: 'The task of attaching the requests to the aggregate is left to an event handler
    for better modularity. Thus, the `Extend` method adds an `AttachedRequestEvent`
    event to the aggregate list of events. The event definition must be placed in
    the `Events` folder and is defined as follows:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 将请求附加到聚合的任务留给事件处理器以实现更好的模块化。因此，`Extend` 方法向聚合事件列表中添加一个 `AttachedRequestEvent`
    事件。事件定义必须放在 `Events` 文件夹中，并定义如下：
- en: '[PRE66]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Finally, if the extension message declares the route closed, the `Extend` method
    closes it by calling the `Close()` method, which is defined as follows:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果扩展消息声明路由已关闭，`Extend` 方法通过调用以下定义的 `Close()` 方法来关闭它：
- en: '[PRE67]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'There is also an `Abort` method, which declares the route aborted:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个 `Abort` 方法，它声明路由已中止：
- en: '[PRE68]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'It sets the aggregate status to aborted and then leaves the task of releasing
    all attached requests to an event handler for better modularity, with the `ReleasedRequestsEvent`
    event:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 它将聚合状态设置为已中止，然后通过 `ReleasedRequestsEvent` 事件将释放所有附加请求的任务留给事件处理器，以实现更好的模块化：
- en: '[PRE69]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Let’s move on to the repository interface:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续到仓储接口：
- en: '[PRE70]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: The `New` method creates a new aggregate, then we have a method to get an aggregate
    from its unique identifier. The `GetMatch` and `DeleteBefore` methods are completely
    analogous to the one of requests, but in this case, `GetMatch` returns all route
    offers matching a given request.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '`New` 方法创建一个新的聚合，然后我们有一个方法可以从其唯一标识符获取聚合。`GetMatch` 和 `DeleteBefore` 方法与请求的类似，但在这个情况下，`GetMatch`
    返回所有与给定请求匹配的路由报价。'
- en: The output queue item aggregate
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输出队列项聚合
- en: 'This aggregate represents a generic output queue item. Files will be placed
    in a `Models -> OutputQueue` folder. The aggregate state can be defined as follows:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这个聚合表示一个通用的输出队列项。文件将被放置在 `Models -> OutputQueue` 文件夹中。聚合状态可以定义如下：
- en: '[PRE71]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Each queue item has a unique ID and a message code that specifies which message
    type is stored in the item. While the message content is the JSON representation
    of the output messages. The aggregate is trivial:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 每个队列项都有一个唯一的 ID 和一个消息代码，指定存储在项中的消息类型。而消息内容是输出消息的 JSON 表示。聚合是简单的：
- en: '[PRE72]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: The `GetMessage` method deserializes the message contained in the item.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '`GetMessage` 方法反序列化项中包含的消息。'
- en: 'Finally, the repository interface is as follows:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，仓储接口如下：
- en: '[PRE73]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Each queue item has a time attached to it, and an item can be extracted by the
    queue only after this time expires. Moreover, queue items are extracted in increasing
    time order.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 每个队列项都附有时间，并且只有在时间过期后，队列项才能被队列提取。此外，队列项按时间顺序提取。
- en: The `Take` method extracts the first `N` items from the queue and then immediately
    requeues them by replacing their time with the time of their extraction plus the
    `requeueAfter` `TimeSpan`. This way, if messages are successfully sent before
    `requeueAfter`, they are removed from the queue; otherwise, they become available
    for extraction from the queue again, and their transmission is retried.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '`Take` 方法从队列中提取前 `N` 个项，然后立即通过将它们的提取时间替换为提取时间加上 `requeueAfter` `TimeSpan` 来重新排队。这样，如果消息在
    `requeueAfter` 之前成功发送，它们将从队列中删除；否则，它们将再次可用于从队列中提取，并且它们的传输将重试。'
- en: The `Confirm` method deletes all successfully sent messages, while the `New`
    method adds a new item to the output queue.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '`Confirm` 方法删除所有成功发送的消息，而 `New` 方法将新项添加到输出队列。'
- en: Now, we can move on to the implementation of all aggregate states with Entity
    Framework entities and to the implementation of all repositories.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以继续使用 Entity Framework 实体实现所有聚合状态，以及实现所有仓储。
- en: The database driver
  id: totrans-382
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库驱动
- en: 'Before getting started with the implementation of the `RoutesPlanningDBDriver`
    driver, we must add a reference to the `Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite`
    NuGet package, which adds support for all `NetTopolgySuite` types to Entity Framework
    Core. Then, we must declare the usage of `NetTopolgySuite` in the `Extensions
    -> DBExtensions.cs` file:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始实现 `RoutesPlanningDBDriver` 驱动之前，我们必须添加对 `Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite`
    NuGet 包的引用，该包为 Entity Framework Core 添加了对所有 `NetTopolgySuite` 类型的支持。然后，我们必须在 `Extensions
    -> DBExtensions.cs` 文件中声明对 `NetTopolgySuite` 的使用：
- en: '[PRE74]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Now, we can define all the entities we need in the `Entities` folder:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以在 `Entities` 文件夹中定义我们需要的所有实体：
- en: 'Route offer:'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路由报价：
- en: '[PRE75]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Route request:'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路由请求：
- en: '[PRE76]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Queue item:'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 队列项：
- en: '[PRE77]'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Then, in the `MainDBContext.cs` file, we must add the corresponding collections:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 `MainDBContext.cs` 文件中，我们必须添加相应的集合：
- en: '[PRE78]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Finally, in the `OnModelCreating` method of the same file, we must declare
    the relationship between `RouteOffer` and `RouteRequest`:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在同一个文件的 `OnModelCreating` 方法中，我们必须声明 `RouteOffer` 和 `RouteRequest` 之间的关系：
- en: '[PRE79]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'We must also declare some indices and the usage of value objects (with their
    indices) with `OwnsOne`:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须使用 `OwnsOne` 声明一些索引和值对象（及其索引）的使用：
- en: '[PRE80]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Let’s now move on to the implementation of all repositories.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续实现所有仓储。
- en: The IOutputQueueRepository implementation
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IOutputQueueRepository 实现
- en: 'All repository implementations follow the same basic pattern:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 所有仓储实现遵循相同的基本模式：
- en: '[PRE81]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: They take `IUnitOfWork` from their main constructor and cast it to the database
    context.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 它们从主构造函数中获取 `IUnitOfWork` 并将其转换为数据库上下文。
- en: 'The `New` method implementation is as follows:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '`New` 方法的实现如下：'
- en: '[PRE82]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The implementation of `Confirm` is straightforward, too:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '`Confirm` 的实现同样简单直接：'
- en: '[PRE83]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: It uses the changes tracker to get all already-loaded entities with the given
    IDs.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用更改跟踪器获取所有已加载的具有给定 ID 的实体。
- en: 'The `Take` implementation is a little bit more complex, because it requires
    a transaction to handle the competition between the various microservice replicas,
    since they all use the same database:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '`Take` 的实现稍微复杂一些，因为它需要事务来处理各种微服务副本之间的竞争，因为它们都使用相同的数据库：'
- en: '[PRE84]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Once all entities are extracted, `ReadyTime` is moved to a future time to prevent
    their usage from other replicas till `requeueAfter` expires and they become available
    again if they were not removed by `Confirm`. This way, if all retry and circuit
    break strategies fail in getting a successful transmission, the same operation
    can be retried after `requeueAfter`. Both read and update must be part of the
    same serializable transaction to prevent interferences from other replicas.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有实体都被提取出来，`ReadyTime` 就会被移动到未来时间，以防止在其他副本中使用，直到 `requeueAfter` 过期，如果它们没有被
    `Confirm` 移除，它们将再次变得可用。这样，如果在获取成功传输的过程中所有重试和断路器策略都失败了，可以在 `requeueAfter` 之后重试相同的操作。读取和更新必须作为同一可序列化事务的一部分，以防止来自其他副本的干扰。
- en: The IRouteRequestRepositoryimplementation
  id: totrans-411
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`IRouteRequestRepository` 的实现'
- en: 'The repository structure is completely analogous to the one of the previous
    repository:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 仓库结构与之前仓库的结构完全相同：
- en: '[PRE85]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The `DeleteBefore` method is easily implemented with the recent `ExecuteDeleteAsync`
    Entity Framework Core extension:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最近的 `ExecuteDeleteAsync` Entity Framework Core 扩展，`DeleteBefore` 方法很容易实现：
- en: '[PRE86]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'In the following code blocks, we can see the `New` method:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码块中，我们可以看到 `New` 方法：
- en: '[PRE87]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'It creates an Entity Framework Core entity, adds it to `ctx.RouteRequests`,
    and uses it as the state to create `RouteRequestAggregate`. It adds also a `NewMatchCandidateEvent<RouteRequestAggregate>`
    event to the aggregate. The associated event handler will take care of finding
    all routes that match the request and creating an output message for each of them.
    `NewMatchCandidateEvent<T>` is defined in the `Events` folder of the `RoutesPlanningDomainLayer`
    project, as follows:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 它创建一个 Entity Framework Core 实体，将其添加到 `ctx.RouteRequests` 中，并使用它作为状态来创建 `RouteRequestAggregate`。它还向聚合添加了一个
    `NewMatchCandidateEvent<RouteRequestAggregate>` 事件。关联的事件处理程序将负责找到所有与请求匹配的路由并为每个创建一个输出消息。`NewMatchCandidateEvent<T>`
    在 `RoutesPlanningDomainLayer` 项目的 `Events` 文件夹中定义，如下所示：
- en: '[PRE88]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'All other methods contain quite standard Entity Framework Core code, so we
    will describe here just the `GetMatch` method since it uses the Entity Framework
    special queries extensions. The code of all other methods is available in the
    `ch07` folder of the book’s GitHub repository ([https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp)):'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他方法都包含相当标准的 Entity Framework Core 代码，因此我们在这里只描述 `GetMatch` 方法，因为它使用了 Entity
    Framework 特殊查询扩展。所有其他方法的代码可以在书籍 GitHub 仓库的 `ch07` 文件夹中找到 ([https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp))：
- en: '[PRE89]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: First of all, we create a `LineString` geometry from the route path, and then
    we start the query. The `Where` clause first restricts the search to requests
    that are not already attached to other routes. Then, it verifies time compatibility
    and, finally, distance compatibility by using the `LineString.Distance` method.
    All geometry objects have a `Distance` method, so we can perform geometric queries
    involving any kind of geometric object.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从路线路径创建一个 `LineString` 几何对象，然后开始查询。`Where` 子句首先将搜索限制为尚未附加到其他路线的请求。然后，它通过使用
    `LineString.Distance` 方法验证时间兼容性和距离兼容性。所有几何对象都有一个 `Distance` 方法，因此我们可以执行涉及任何类型几何对象的几何查询。
- en: Finally, we return an anonymous object with both the distance and the retrieved
    entity. This way, we can sort data by distance and extract the best `maxResults`
    matches.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们返回一个包含距离和检索到的实体的匿名对象。这样，我们可以按距离排序数据并提取最佳 `maxResults` 匹配项。
- en: The IRouteOfferRepository implementation
  id: totrans-424
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`IRouteOfferRepository` 的实现'
- en: 'Again, the repository structure is the same as the one of all previous repositories:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，仓库结构与前一个仓库的结构相同：
- en: '[PRE90]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The `DeleteBefore` method is analogous to the one of the previous repository:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '`DeleteBefore` 方法与先前存储库中的方法类似：'
- en: '[PRE91]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: The `New` method is also the same as the one of the requests repository, but
    it generates the `NewMatchCandidateEvent<` `RouteOfferAggregate>` event, whose
    handler looks for matching requests.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '`New` 方法也与请求存储库中的方法相同，但它生成 `NewMatchCandidateEvent<` `RouteOfferAggregate>`
    事件，其处理器寻找匹配的请求。'
- en: 'Again, we describe just the `GetMatch` method since all other methods are quite
    standard:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们只描述了 `GetMatch` 方法，因为所有其他方法都非常标准：
- en: '[PRE92]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: The `Where` clause first restricts the search just to all open routes. Then,
    it verifies time and distance constraints as in the same `GetMatch` method of
    the previous repository. Also, sorting is the same as that in the previous repository.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '`Where` 子句首先将搜索限制为所有开放路线。然后，它验证时间和距离约束，就像在先前存储库的相同 `GetMatch` 方法中一样。排序方式也与先前存储库相同。'
- en: Having defined everything, we can now move on to migration.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 定义好一切之后，我们现在可以继续进行迁移。
- en: Creating migrations and databases
  id: totrans-434
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建迁移和数据库
- en: 'Before generating database migrations, we must implement the `IDesignTimeDbContextFactory<MainDbContext>`
    interface inside the database driver. All migration tools look for this implementation
    to create the instance of `MainDbContext` needed to get information on both the
    database configuration and the database connection string. Therefore, let’s add
    a `LibraryDesignTimeDbContextFactory` class to the root of the `RoutesPlanningDBDriver`
    project:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成数据库迁移之前，我们必须在数据库驱动程序内部实现 `IDesignTimeDbContextFactory<MainDbContext>` 接口。所有迁移工具都会寻找这个实现来创建
    `MainDbContext` 的实例，以便获取数据库配置和数据库连接字符串的信息。因此，让我们向 `RoutesPlanningDBDriver` 项目的根目录添加一个
    `LibraryDesignTimeDbContextFactory` 类：
- en: '[PRE93]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Please replace the placeholders I left in the string with your SQL Server instance
    name and password. The simplest way to get a connection string is by connecting
    to the database from within Visual Studio and then by copying the connection strings
    from the properties tab. Please don’t forget you can’t use the SQL database installed
    with Visual Studio since it is not able to listen to TCP/IP connections, so it
    cannot be accessed from within Docker images.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 请将我留下的字符串中的占位符替换为您的 SQL Server 实例名称和密码。获取连接字符串的最简单方法是从 Visual Studio 内连接到数据库，然后从属性选项卡中复制连接字符串。请记住，您不能使用与
    Visual Studio 一起安装的 SQL 数据库，因为它无法监听 TCP/IP 连接，因此无法从 Docker 镜像内部访问。
- en: 'Now, we can also add the SQL Server connection string we left empty in `launchSettings.json`:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们也可以添加在 `launchSettings.json` 中留空的 SQL Server 连接字符串：
- en: '[PRE94]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Again, please add your password. `host.docker.internal` is the network name
    of your development computer that hosts Docker or a local Kubernetes simulator.
    Use it if you performed a direct installation on your machine or if you ran a
    SQL Server Docker image on your computer. Replace it with the appropriate name
    if you are using a cloud or other network instance.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，请添加您的密码。`host.docker.internal` 是您的开发计算机的网络名称，该计算机运行 Docker 或本地 Kubernetes
    模拟器。如果您在您的机器上直接安装了它，或者如果您在您的计算机上运行了 SQL Server Docker 镜像，请使用它。如果您使用云或其他网络实例，请将其替换为适当的名称。
- en: 'Now, let’s make `RoutesPlanningDBDriver` our Visual Studio startup project,
    and select it in the Visual Studio **Package Manager Console**:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将 `RoutesPlanningDBDriver` 设置为我们的 Visual Studio 启动项目，并在 Visual Studio
    的 **Package Manager Console** 中选择它：
- en: '![](img/B31916_07_5.png)'
  id: totrans-442
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31916_07_5.png)'
- en: 'Figure 7.5: Selecting the project in Package Manager Console'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：在 Package Manager Console 中选择项目
- en: 'We are ready to issue our first migration in **Package Manager Console**:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始在 **Package Manager Console** 中发布我们的第一个迁移：
- en: '[PRE95]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Please note that if you copied the project from the GitHub repository associated
    with the book, you don’t need to execute the preceding command since migrations
    have already been created there. You just need to create the database with the
    following command.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果您从与本书相关的 GitHub 存储库中复制了项目，您不需要执行前面的命令，因为那里已经创建了迁移。您只需要使用以下命令创建数据库。
- en: 'If the previous command was successful, you can create the database with the
    following command:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 如果前一个命令成功，您可以使用以下命令创建数据库：
- en: '[PRE96]'
  id: totrans-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Done! We can now move on to the implementation of all command and event handlers.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 完成！我们现在可以继续实现所有命令和事件处理器。
- en: 'The application services: Defining all command and event handlers'
  id: totrans-450
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用程序服务：定义所有命令和事件处理器
- en: In this section, we will define all the required command and event handlers.
    Before starting, we need to add a reference to the `Microsoft.Extensions.Configuration.Abstractions`
    and `Microsoft.Extensions.Configuration.Binder` NuGet packages in the `RoutesPlanningApplicationServices`
    project. This way, we enable all handlers to receive configuration data from the
    dependency injection engine through the `IConfiguration` interface.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将定义所有必需的命令和事件处理器。在开始之前，我们需要在`RoutesPlanningApplicationServices`项目中添加对`Microsoft.Extensions.Configuration.Abstractions`和`Microsoft.Extensions.Configuration.Binder`
    NuGet包的引用。这样，我们就可以通过`IConfiguration`接口使所有处理器能够从依赖注入引擎接收配置数据。
- en: All command handler constructors require some repository interfaces, `IUnitofWork`
    for finalizing modifications and handling transactions, and an `EventMediator`
    instance for triggering all events added to the aggregates.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 所有命令处理器构造函数都需要一些存储库接口，`IUnitofWork`用于最终化修改和处理事务，以及一个`EventMediator`实例用于触发添加到聚合体的所有事件。
- en: We will not describe all handlers, just the ones with a didactic added value.
    You can find the entire code in the `ch07` folder of the book’s GitHub repository
    ([https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp)).
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会描述所有处理器，只描述那些具有教学附加值的处理器。你可以在书籍GitHub存储库的`ch07`文件夹中找到完整的代码([https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp](https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp))。
- en: We will place all command handlers that process messages in a `CommandHandlers
    -> Messages` folder.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所有处理消息的命令处理器放置在`CommandHandlers -> Messages`文件夹中。
- en: 'Let’s start with the `RouterOfferMessage` handler:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`RouterOfferMessage`处理器开始：
- en: '[PRE97]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: The handler extracts all data needed to create a new aggregate from the message
    and then passes it to the `New` repository method. Then, it verifies whether the
    created aggregate contains events and uses the `EventMediator` instances to trigger
    all associated event handlers. `ConstraintViolationException` is created by the
    `IUnitOdWork` implementation in case of unique key violations. In our case, this
    exception can be thrown just when we receive a duplicate `RouterOfferMessage`.
    Therefore, we simply capture it and do nothing, since duplicate messages must
    be ignored.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 处理程序从消息中提取创建新聚合体所需的所有数据，然后将它传递给`New`存储库方法。然后，它验证创建的聚合体是否包含事件，并使用`EventMediator`实例来触发所有相关的事件处理器。在发生唯一键违反的情况下，`ConstraintViolationException`由`IUnitOdWork`实现创建。在我们的情况下，这个异常仅在我们收到重复的`RouterOfferMessage`时才会抛出。因此，我们只需捕获它并什么都不做，因为重复的消息必须被忽略。
- en: '`RouteRequestMessageHandler` is completely analogous, so we will not describe
    it.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '`RouteRequestMessageHandler`与之完全类似，因此我们不会对其进行描述。'
- en: 'Let’s move on to the `RouteClosedAbortedMessage` handler:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续到`RouteClosedAbortedMessage`处理器：
- en: '[PRE98]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: The whole operation is enclosed in a serializable transaction to avoid interferences
    with other microservice replicas that might receive older or future messages concerning
    the same route offer. In fact, they might modify the same entity after it has
    been read but before it has been modified. The serializable transaction prevents
    this possibility.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 整个操作都封装在一个可序列化的事务中，以避免与其他可能接收到有关同一路由报价的较旧或未来消息的微服务副本之间的干扰。实际上，它们可能在读取之后但在修改之前修改相同的实体。可序列化事务防止了这种可能性。
- en: If we don’t find the entity, we do nothing and simply abort the transaction.
    In fact, this eventuality might take place only if the route expires and is deleted.
    However, if entities are deleted after enough time has passed since they expired,
    this should be a substantially impossible event.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有找到实体，我们将不采取任何行动，并简单地终止事务。实际上，这种情况可能只会在路由过期并被删除时发生。然而，如果实体在它们过期后的一段时间内被删除，这应该是一个几乎不可能发生的事件。
- en: If the message specifies that the route must be closed, we put the aggregate
    in the closed state by calling `Close()` only if the aggregate is still open.
    In fact, if it is either already closed or aborted, this will be an old message
    or a duplicate that must be ignored.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 如果消息指定路由必须关闭，只有当聚合体仍然处于开启状态时，我们才会通过调用`Close()`方法将聚合体置于关闭状态。实际上，如果它已经关闭或终止，这将是一条旧消息或重复消息，必须被忽略。
- en: Similarly, if the message specifies that the route should be aborted, it is
    processed only if the aggregate is not already in an aborted state.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果消息指定路由应该被终止，只有在聚合体尚未处于终止状态时才会进行处理。
- en: Finally, in case of errors, we abort the transaction and rethrow the exception,
    so the message will not be confirmed and the message will be processed again at
    a later time, possibly by a different replica.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在出现错误的情况下，我们中止事务并重新抛出异常，这样消息就不会被确认，并且消息将在稍后时间再次被处理，可能由不同的副本处理。
- en: 'Now, let’s move on to the `RouteExtendedMessage` handler:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续到 `RouteExtendedMessage` 处理器：
- en: '[PRE99]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Also, in this case, since the command handler performs both a read and a modification,
    we need an explicit transaction.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在这种情况下，由于命令处理器既执行了读取又执行了修改，我们需要显式的事务。
- en: Again, if no entity is found, we do nothing for the same reasons explained for
    the previous handler. We also do nothing if the message timestamp is identical
    to the one contained in the entity, because in this case, the message is a duplicate.
    Otherwise, we simply call the aggregate `Extend` method, and then trigger possible
    events generated by the `Extend` method.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，如果没有找到实体，我们将不采取任何行动，原因与之前处理器的解释相同。如果消息的时间戳与实体中包含的时间戳相同，我们也不会采取任何行动，因为在这种情况下，消息是重复的。否则，我们只需调用聚合的
    `Extend` 方法，然后触发 `Extend` 方法生成的可能事件。
- en: Let’s now move on to handlers that are not related to messages. They are placed
    in the root of the `CommandHandlers` folder.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续到与消息无关的处理器。它们被放置在 `CommandHandlers` 文件夹的根目录下。
- en: 'Let’s start with `HouseKeepingCommandHandler`, which deletes old expired requests
    and routes:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 `HouseKeepingCommandHandler` 开始，该处理器删除旧的过期请求和路由：
- en: '[PRE100]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: It is very simple, since it just subtracts the delay or the deletion of all
    expired entities from the current time and then calls the repository methods for
    deleting routes and requests. It doesn’t need to save changes since each of these
    methods already interacts with the database.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 它非常简单，因为它只是从当前时间减去延迟或删除所有过期实体的时间，然后调用删除路由和请求的存储库方法。它不需要保存更改，因为每个这些方法已经与数据库进行了交互。
- en: 'The `OutputSendingCommandHandler` that handles the output queue is a little
    bit more complex:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 处理输出队列的 `OutputSendingCommandHandler` 要复杂一些：
- en: '[PRE101]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: It tries to take `command.BatchCount` items from the output queue. If no item
    is found, it informs the command that the queue is empty, which, in turn, informs
    the queue-handling hosted service that it can sleep for a little while.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 它尝试从输出队列中取出 `command.BatchCount` 个项目。如果没有找到项目，它通知命令队列已为空，这反过来又通知队列处理托管服务它可以稍微休息一下。
- en: Then, it deserializes all messages and passes them to the `Sender` delegate.
    However, instead of awaiting each task returned by this method, it collects all
    of them, puts them in an array, and awaits the whole array with `Task.WhenAll`.
    This way, all messages are sent concurrently, thus improving performance. In case
    of exceptions, it simply does nothing, because unsent messages are detected in
    the LINQ instruction inside `repo.Confirm` and their associated queue items are
    excluded from the array of all items to confirm, so they will be retried at a
    later time.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它反序列化所有消息并将它们传递给 `Sender` 委托。然而，它不会等待此方法返回的每个任务，而是收集所有任务，将它们放入一个数组中，并使用 `Task.WhenAll`
    等待整个数组。这样，所有消息都并发发送，从而提高了性能。在出现异常的情况下，它什么也不做，因为未发送的消息在 `repo.Confirm` 内部的 LINQ
    指令中被检测到，并且它们相关的队列项被排除在所有要确认的项目数组之外，因此它们将在稍后时间重试。
- en: We are done with all the command handlers. Let’s move on to the event handlers.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了所有命令处理器。让我们继续到事件处理器。
- en: Coding all event handlers
  id: totrans-479
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编写所有事件处理器
- en: Usually, event handlers do not create transactions and do not attempt to store
    modifications in the database, since they are invoked by command handlers, which
    do this task for them; so, their code tends to be a little bit simpler. We have
    four event handlers, which are all placed in the root of the `EventHandlers` folder.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，事件处理器不会创建事务，也不会尝试将修改存储在数据库中，因为它们是由命令处理器调用的，这些处理器会完成这项任务；因此，它们的代码通常要简单一些。我们有四个事件处理器，它们都放置在
    `EventHandlers` 文件夹的根目录下。
- en: 'Let’s start with the `AttachedRequestEvent` handler:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 `AttachedRequestEvent` 处理器开始：
- en: '[PRE102]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'This handler is responsible for attaching requests to a route. Its code is
    trivial: it just retrieves all aggregates from their keys and then attaches them
    to the route referenced in the event.'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 此处理器负责将请求附加到路由上。其代码很简单：它只是检索所有聚合体及其键，然后将它们附加到事件中引用的路由。
- en: 'The `ReleasedRequestsEvent` handler is responsible for releasing all requests
    attached to an aborted route. Its code is trivial, too:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '`ReleasedRequestsEvent` 处理器负责释放附加到已中止路由的所有请求。其代码也很简单：'
- en: '[PRE103]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: It retrieves all requests attached to the route and simply detaches each of
    them.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 它检索所有附加到路由的请求，并简单地断开每个请求的连接。
- en: 'Finally, we have two event handlers that discover route-request matches and
    add them to the microservice output queue. The first one is triggered when a new
    request is added, while the second one is triggered when a new offer is added.
    Since they are very similar, we will describe just the first one:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有两个事件处理器，用于发现路由请求匹配项并将它们添加到微服务输出队列。第一个在添加新请求时触发，而第二个在添加新报价时触发。由于它们非常相似，我们只描述第一个：
- en: '[PRE104]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: The `PrepareMessage` method just fills a `RouteRequestMessage` using data contained
    in the corresponding `RouteRequest\regate`. We will not describe it, since it
    is trivial.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '`PrepareMessage` 方法只是使用对应 `RouteRequest\regate` 中包含的数据填充一个 `RouteRequestMessage`。我们不会对其进行描述，因为它非常简单。'
- en: The `HandleAsync` method first extracts the parameters needed for the search
    from configuration data. Then, it calls the repository `GetMatch` method to find
    all matches. Finally, for each route retrieved, it creates an output message and
    adds it to the internal queue. The request is turned into a singleton list since
    the output message requires a list.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '`HandleAsync` 方法首先从配置数据中提取搜索所需的参数。然后，它调用存储库的 `GetMatch` 方法来查找所有匹配项。最后，对于检索到的每个路由，它创建一个输出消息并将其添加到内部队列。由于输出消息需要一个列表，因此请求被转换为一个单例列表。'
- en: The code of our microservice is finished! We will test it in the next chapter
    after connecting it with message sources and message receivers. There, we will
    also implement the microservice health check endpoints and connect them to the
    orchestrator.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的微服务代码已经完成！在将其与消息源和消息接收者连接后，我们将在下一章对其进行测试。在那里，我们还将实现微服务的健康检查端点并将它们连接到编排器。
- en: Summary
  id: totrans-492
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter described in detail how to design and code a **Dockerized** microservice.
    In particular, it described how to design its input and output messages and endpoints,
    as well as how to use a message broker to implement event-based communication.
    It also described how to handle out-of-order and duplicated messages, concurrent
    output production with several microservice replicas, and transactional outputs
    with a database internal queue.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细介绍了如何设计和编码一个**容器化**的微服务。特别是，它描述了如何设计其输入和输出消息以及端点，以及如何使用消息代理来实现基于事件的通信。它还描述了如何处理乱序和重复的消息，多个微服务副本的并发输出生产，以及使用数据库内部队列的事务性输出。
- en: Then, it described how the organization of worker services is based on hosted
    services and how in this case, commands are carried out in one-to-one correspondence
    with all input messages. Finally, it described how to code all of the Onion Architecture
    levels of any microservice.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它描述了工作型服务组织的结构是基于托管服务，以及在这种情况下，命令与所有输入消息一一对应执行。最后，它描述了如何为任何微服务的洋葱架构的所有层级进行编码。
- en: All concepts were explained through the practical example of the route-planning
    worker microservice of the book’s case study application. You should now understand
    the practical usage of the RabbitMQ message broker and the `NetTopologySuite`
    library for implementing spatial calculations and queries.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 所有概念都是通过书中案例研究应用的路线规划工作型微服务的实际示例进行解释的。你现在应该理解了 RabbitMQ 消息代理和 `NetTopologySuite`
    库在实现空间计算和查询中的实际应用。
- en: The next chapter describes orchestrators with a specific focus on Kubernetes.
    There, we will test the microservice coded in this chapter by connecting it with
    other microservices, and by using an orchestrator to manage all microservices.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将描述编排器，特别关注 Kubernetes。在那里，我们将通过将其与其他微服务连接以及使用编排器来管理所有微服务来测试本章编写的微服务。
- en: Questions
  id: totrans-497
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Do worker microservices typically need authentication and authorization? What
    about encrypted communication protocols?
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作型微服务通常需要身份验证和授权吗？加密通信协议又是如何的呢？
- en: They don’t need authentication because their processing is not connected to
    a specific application user. Encrypted communication is advised but not always
    necessary since they run in an isolated environment.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们的处理过程不与特定应用程序用户相关联，因此不需要身份验证。建议使用加密通信，但由于它们在隔离环境中运行，因此并非总是必需。
- en: Where is it advised to place all microservices’ input and output messages?
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应该在哪里放置所有微服务的输入和输出消息？
- en: In some kind of queues.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些类型的队列中。
- en: What is the name of the technique for maintaining the right processing order
    of messages while using several microservice replicas?
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用多个微服务副本的同时保持消息正确处理顺序的技术叫什么？
- en: Sharding.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 分片。
- en: Is it true that if modification messages contain the whole updated entities,
    and if deletes are logical, then the order of messages doesn’t matter?
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果修改消息包含整个更新后的实体，并且删除是逻辑的，那么消息的顺序是否真的不重要？
- en: Yes, it is true.
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 这是真的。
- en: Which library is typically used in .NET for handling failures with retry policies?
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 .NET 中通常使用哪个库来处理具有重试策略的失败？
- en: Polly is used in .NET for handling failures with retry policies.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: Polly 在 .NET 中用于处理具有重试策略的失败。
- en: Where are domain events created? Where are they before their handlers are fired?
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 领域事件是在哪里创建的？在它们的处理器被触发之前它们在哪里？
- en: In a list contained in the aggregates that created them.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建它们的聚合体包含的列表中。
- en: Why do event handlers typically not use transactions and `IUnitOfWork.SaveEntitiesAsync`?
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么事件处理器通常不使用事务和 `IUnitOfWork.SaveEntitiesAsync`？
- en: Because transactions are created and handled by the Command Handlers that caused
    the events.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 因为事务是由引起事件的命令处理器创建和处理的。
- en: When sending several concurrent output messages, how can we discover which ones
    succeeded, which ones failed, and which ones were canceled?
  id: totrans-512
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在发送多个并发输出消息时，我们如何发现哪些成功了，哪些失败了，哪些被取消了？
- en: Through acknowledgments.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 通过确认。
- en: What is an SRID?
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SRID 是什么？
- en: Spatial Reference Identifiers. They name geographic coordinate systems.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 空间参考标识符。它们命名地理坐标系。
- en: Can the `Distance` method of all `NetTopologySuite` geometric objects be used
    in LINQ queries to a SQL Server database?
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有 `NetTopologySuite` 几何对象的 `Distance` 方法能否在 SQL Server 数据库的 LINQ 查询中使用？
- en: Yes.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。
- en: Further reading
  id: totrans-518
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'RabbitMQ official documentation: [https://www.rabbitmq.com/](https://www.rabbitmq.com/).'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RabbitMQ 官方文档：[https://www.rabbitmq.com/](https://www.rabbitmq.com/).
- en: 'EasyNetQ official documentation: [https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction](https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction).'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EasyNetQ 官方文档：[https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction](https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction).
- en: 'Polly documentation: [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Polly 文档：[https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly).
- en: 'RabbitMQ sharding plugin: [https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding).'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RabbitMQ 分片插件：[https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding).
- en: 'Spatial data extensions for Entity Framework Core: [https://learn.microsoft.com/en-us/ef/core/modeling/spatial](https://learn.microsoft.com/en-us/ef/core/modeling/spatial).'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Entity Framework Core 的空间数据扩展：[https://learn.microsoft.com/en-us/ef/core/modeling/spatial](https://learn.microsoft.com/en-us/ef/core/modeling/spatial).
- en: 'NetTopologySuite: [https://nettopologysuite.github.io/NetTopologySuite/](https://nettopologysuite.github.io/NetTopologySuite/).'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NetTopologySuite：[https://nettopologysuite.github.io/NetTopologySuite/](https://nettopologysuite.github.io/NetTopologySuite/).
- en: Join our community on Discord
  id: totrans-525
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的社区 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/PSMCSharp](https://packt.link/PSMCSharp)'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/PSMCSharp](https://packt.link/PSMCSharp)'
- en: '![A qr code with black squares  AI-generated content may be incorrect.](img/B31916_Discord-QR-Code.png)'
  id: totrans-528
  prefs: []
  type: TYPE_IMG
  zh: '![一个带有黑色方块的二维码 AI 生成的内容可能是不正确的](img/B31916_Discord-QR-Code.png)'
