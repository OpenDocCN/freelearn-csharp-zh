<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Streams, Threads, and Asynchronous Data</h1>
                </header>
            
            <article>
                
<p>With the resources available to us to start working with sending network requests, we need to look at how we can best incorporate those requests into our applications. We'll need to work with those resources in a way that won't impact the performance of our application's business logic or our user's experience. So, in this chapter, we'll look at how we can process data streams in such a way as to be resilient and non-blocking to the rest of our application's performance.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Understanding the nature of I/O streams in C#, and how to write to, read from, and manage open streams</li>
<li>How different I/O streams expose access to different types of data, and how the parent <kbd>Stream</kbd> class simplifies the use of those distinct stream types</li>
<li>The potential performance cost of processing large, or poorly performing data streams and how to mitigate that cost</li>
<li>Leveraging C#'s asynchronous programming feature set to maximize the performance and reliability of your software</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>This chapter will have a number of samples and driver programs to demonstrate the concepts discussed, all of which are available at <a href="https://github.com/PacktPublishing/Hands-On-Network-Programming-with-CSharp-and-.NET-Core/tree/master/Chapter%206">https://github.com/PacktPublishing/Hands-On-Network-Programming-with-CSharp-and-.NET-Core/tree/master/Chapter 6</a>.</p>
<p>As always, you're encouraged to clone this repository locally and begin playing with the source code, or writing your own in order to get comfortable with some of the topics in this chapter.</p>
<p><span>Check out the following video to see the code in action: <a href="http://bit.ly/2HYmhf7">http://bit.ly/2HYmhf7</a></span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Going with the flow – data streams in C#</h1>
                </header>
            
            <article>
                
<p class="mce-root">We looked briefly at accessing data streams in the last chapter when we talked about the request stream property of the <kbd>WebRequest</kbd> class. I glossed over that subject then, but now we should really understand how our data is prepared for transmission as a request payload. We'll look at the common interface for data streams in C#, and give special consideration for some of the trickier or less obvious aspects of streams that can introduce some difficult-to-find bugs into your code. So, let's start with the <kbd>Stream</kbd> class and go from there. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Initializing a data stream</h1>
                </header>
            
            <article>
                
<p><span>Just like with network requests, writing to and reading from data streams is a common and straightforward task in software engineering. So much so, in fact, that Microsoft provided an extremely well-designed common specification for doing this in C#. The methods defined by the base class are the same ones you'll use for any kind of data transmission that you would reasonably have to execute, so with that as our starting point, let's take a look at what the class provides.</span></p>
<p>The objective of the <kbd>Stream</kbd> class is, quite simply, to provide direct access to an ordered sequence of bytes. There is no additional context around this information, so the sequence of bytes could be anything from a file on your local disk storage, to the bytes of a packet from an incoming request stream, or to an open communication pipe between two co-located application processes and existing entirely in memory.</p>
<p>What this simple definition provides is an easy way to define generic environment and context-agnostic methods for working with the ordered list of zeros and ones. What it doesn't provide, however, is any useful way to parse, process, and convert those bytes to and from meaningful in-memory objects that make sense to the rest of your application. As a programming task, this can be a bit tedious, but thankfully, some of the specific implementations provide some reliable utility methods for more common parsing situations. This is especially nice because that's where most of the work of streams lie.</p>
<p>Once you've got your information ready to pass over a binary data stream, or ingest bytes from a data stream, there are only three primary operations that you'll care about. The first two are obvious: reading and writing, collecting bytes, in order, from the data stream, or pushing your own bytes onto it. The third is less obvious but just as important. Because the data stream is an ordered array of arbitrary bytes, reading from and writing to it are unidirectional operations. They are always processed in order. However, we don't always need or want the information from a data stream in order, so the ability to seek out a specific index in the stream is key, and will be the primary mechanism for traversing your data stream out of order.</p>
<p>So, with that in mind, let's take a look at it in action. First, create a basic application to take advantage of a data stream. To do so, you can use the .NET Core CLI, and create a new console app, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-906 image-border" src="assets/65ea8a27-8d27-4152-a31b-5a38e18d2d35.png" style="width:81.33em;height:42.83em;"/></p>
<p>Similarly to how we created our sample project in <a href="ec4ace03-62c3-4f7f-be9e-6a54f0438e57.xhtml">Chapter 2</a>, <em>DNS and Resource Location,</em> in the, <em>The DNS in C#</em> section<em>, </em>we used the <kbd>dotnet new</kbd> command to stand up a basic console application as our test bed. This time the difference is that we'll specifically create a new console app with the <kbd>dotnet new console</kbd> command. I'll keep making a note of this as we work with new projects to highlight the speed and value of the .NET Core CLI; its speed and utility really cannot be overstated.</p>
<p>Now, we want to establish a stream to work with, so we'll start by adding a using directive to include the <kbd>System.IO</kbd> namespace since I/O streams live in the I/O namespace. Then, for the sake of demonstration, we'll read from the file, and write to a file on disk with <kbd>FileStream</kbd>. We'll declare our variable to be of type <kbd>Stream</kbd>, so that the compiler's type checking doesn't allow us to use the <kbd>FileStream</kbd> specific methods or properties. The point is to understand how to use the abstraction that's provided by the <kbd>Stream</kbd> class. It doesn't actually matter what we're reading from; by the time it gets to our application code, it's all just incoming bytes, anyway. Using the local filesystem just gives us more direct access to the results of our actions without having to go through the process of setting up a local API and posting data to it. </p>
<div class="packt_tip">To the extent that you can, it's usually wise to use as generic a type as possible when declaring your variables. This allows you a lot more flexibility if you need to change your implementation strategy down the line. What might be a locally stored filesystem access today could become a remote API call tomorrow. If your code is only concerned with the generic concept of a <kbd>Stream</kbd> class, it's a lot easier to change it later for different sources later.</div>
<p>To write this demo, the first thing you'll want to understand is that a Stream is an active connection to a data source. That means it needs to be opened before it can be used, and it should be closed, and then disposed of before you're done with it. Failing to do so can result in memory leaks, thread starvation, and other performance or reliability issues with your code. Thankfully, .NET Core provides a built-in pattern for each of these life cycle tasks. The constructors for most <kbd>Stream</kbd> classes will return an already-opened instance of the class you're creating, so you can start reading from and writing to your streams right away. As for guaranteeing the disposal of your streams, we have the eternally useful <kbd>using</kbd> statement.</p>
<p>If you haven't seen it before, a <kbd>using</kbd> statement is different from the <kbd>using</kbd> directives at the top of your file that allows you to reference classes and data structures outside of your current namespace. In the context of a method, in C#, the <kbd>using</kbd> statement is used to instantiate a disposable class (which is to say, any class that implements the <kbd>IDisposable</kbd> interface), and define the scope within which the instance should be kept alive. The syntax for using this is as follows:</p>
<pre>using (variable assignment to disposable instance) {<br/>    scope in which the disposable instance is alive.<br/>}</pre>
<p>We'll see this in action momentarily. But just like declaring variables within the scope of a <kbd>for</kbd> loop or an <kbd>if</kbd> statement, the variable you create inside the signature of the <kbd>using</kbd> statement ceases to exist outside of the scope of the open and close curly brackets of the code block.</p>
<p> </p>
<p class="mce-root"/>
<p>Alternatively, with C# 8, you can avoid the deep nesting created by the <kbd>using</kbd> statement by choosing instead to leverage the <kbd>using</kbd> declaration. This functions the exact same as the <kbd>using</kbd> statement, but it declares the variable to the scope of the encapsulating method instead of establishing an inner-scope for the lifetime of the instance. So, instead of defining the scope with the <kbd>using</kbd> statement and its opening and closing curly braces, you would simply create your variable and declare it with the <kbd>using</kbd> keyword, as seen here:</p>
<pre>using var fileStream = new FileStream(someFileName);</pre>
<p>The only major distinction between the two is the scope to which the instance is bound. With a <kbd>using</kbd> statement, the scope of the instance is defined by the curly braces of the statement block. Meanwhile, with the <kbd>using</kbd> declaration, the scope is defined by the code block in which the disposable instance was declared. In most cases, the <kbd>using</kbd> declaration should be sufficient, and will help reduce deep nesting within your methods. However, you should always take care to consider how the disposable instance will be used and bind it to the appropriate scope for its use case.</p>
<p>Once the flow of program control exits the scope to which your instance is bound, the .NET runtime will take all the necessary steps to call the <kbd>Dispose()</kbd> method, which is responsible for ensuring that the state of the object is valid for disposal. In doing so, the <kbd>using</kbd> statement implicitly assumes the responsibility of cleaning up any unmanaged resources and any connection pools set up for the object it created. This well-defined scope means that anytime you step out of the scope of the <kbd>using</kbd> directive, you lose your resource handle and will have to instantiate a new one. </p>
<div class="packt_tip">This well-defined scope means that any time you close your <kbd>using</kbd> statement, you lose your resource handle. This means that accessing the resource later will require you to create a new handle for it and then dispose of it accordingly. This can incur a performance cost over the lifetime of the application, and so you should take care to dispose of a resource handle when you are certain you no longer need it.</div>
<p><span>Interestingly, while the object declared within the scope of the <kbd>using</kbd> statement will always be properly disposed of, the <kbd>using</kbd> statement does </span>not<em> </em><span>guarantee the disposal of any disposable instances that the</span><em> </em><span>object creates. The assumption is that if any <kbd>A</kbd> class creates an instance of a disposable <kbd>B</kbd> class as a member of itself, the owning instance of the <kbd>A</kbd> class should also be responsible for cleaning up the member instance of the <kbd>B</kbd> class whenever the owning instance of the <kbd>A</kbd> class is, itself, disposed of. The rule is, if you create it, you dispose of it.</span></p>
<p>Now that we know how to create an instance of <kbd>Stream</kbd>, let's get our hands dirty and start working with one.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Writing to and reading from a data stream</h1>
                </header>
            
            <article>
                
<p>Now that we know how the life cycle of the <kbd>Stream</kbd> class is managed, let's use it to write a message to a local file. First, we'll write a string to the stream, and then inspect the destination of the stream to confirm that it was written properly:</p>
<pre>using System;<br/>using System.Text;<br/>using System.IO;<br/>using System.Threading;<br/><br/>namespace StreamsAndAsync {<br/>  public class Program {<br/>    static void Main(string[] args) {<br/>      string testMessage = "Testing writing some arbitrary string to a stream";<br/>      byte[] messageBytes = Encoding.UTF8.GetBytes(testMessage);<br/>      using (Stream ioStream = new FileStream(@"stream_demo_file.txt", FileMode.OpenOrCreate)) {<br/>        if (ioStream.CanWrite) {<br/>          ioStream.Write(messageBytes, 0, messageBytes.Length);<br/>        } else {<br/>          Console.WriteLine("Couldn't write to our data stream.");<br/>        }<br/>      }<br/>      Console.WriteLine("Done!");<br/>      Thread.Sleep(10000);<br/>    }<br/>  }<br/>}</pre>
<p>Just like in <a href="b2bbfe0e-f0de-49ca-a3c8-b8ced18e42bf.xhtml">Chapter 5</a>, <em>Generating Web Requests in C#,</em> we couldn't write our string directly to the stream. It's not the job of a stream of bytes to figure out how more complicated objects should be represented as bytes. It's just the road over which they travel. So, we're responsible for first getting the byte representation of the string that we want to send. For this, we use the <kbd>System.Text.Encoding</kbd> class to get the byte representation for the specific string encoding that we want to use.</p>
<p>Once we have this, we can write it to the stream. Or, at least, we assume we can. It's always wise to check first, though. That's why the <kbd>Write</kbd> operation is wrapped in the conditional block that checks the <kbd>CanWrite</kbd> property of our stream. This is a wonderful convenience provided by the <kbd>Stream </kbd>class that allows you to confirm a valid state in your stream for the operation you're about to perform before<em> </em>you try to perform it. This puts error handling and correction in our control without having to use clunky <kbd>try</kbd>/<kbd>catch</kbd> blocks around everything.</p>
<p>So, we declared our <kbd>Stream</kbd> object in our <kbd>using</kbd> block and initialized it to open or create a file called <kbd>stream_demo_file.txt</kbd> in the root of the application executable's directory. Then, once we checked on it, we passed it our byte array and instructed the stream to write that array to its destination resource. But what were those two additional parameters in the <kbd>Write</kbd> method? Well, in the same way that a stream wouldn't reasonably have any knowledge of what is passing over it, it doesn't know what bytes should be read from the byte array when. It needs the array of bytes, then instructions on where to start reading from, and precisely how many of those bytes it should write. The second parameter in the <kbd>Write</kbd> method signature is your starting index. It starts at zero, just like the array does. The third parameter is the total number of bytes you want to send in this <kbd>Write</kbd> operation. There is a runtime error checking on this and if you try to send more bytes than there are left in the array (starting from whatever index you designate), you'll get an index out-of-bounds error.</p>
<p>So, if you navigate to the folder from which the application was run, you should find a new text file. Opening it, you should discover our message; it's as easy as that. But what happens if we run the file again? Will the message be concatenated to the first message that we wrote? Will it overwrite the existing message?</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The seek operation</h1>
                </header>
            
            <article>
                
<p>Run your application again, and then reload the file in a text editor. Whatever you were expecting to happen, you should see no change to the file. However, assuming your application ran successfully, and you saw the <span class="packt_screen">Done!</span> message on your console for 10 seconds instead of our error message, you should have confidence that the write operation was executed a second time. So, this should tell you that the operation was successful and it did, in fact, overwrite the value of the original message. It might not be initially obvious, because we used the same message the second time around, but if you want to confirm this behavior, just change the <kbd>testMessage</kbd> variable in your program to read <em>Testing writing a different string to a stream</em> and run it again. You should see the new message and, hopefully, it's a little more obvious what's happening.</p>
<p>Every time we open a stream connected to a data source, we're getting the complete ordered list of bytes stored at that source, along with a pointer to the start of that array. Every operation we execute on the stream moves our pointer in one direction. If we write 10 bytes, we find ourselves 10 positions further down the array than when we started. The same happens if we read 10 bytes. So, each of our primary operators can only ever move in one direction from whatever point along the stream we happen to be at when we start executing them. How, then, do we set those operations up to read or write what we want, where we want? The answer is, with the <kbd>Seek()</kbd> method.</p>
<p>The <kbd>Seek</kbd> method gives us arbitrary access to any index in our byte array through the specification of a few simple parameters. Simply specify where you want to start relative to a designated starting position, and then designate the starting position with one of the three values of the <kbd>SeekOrigin</kbd> enum.</p>
<p>So, if I wanted to start on the last byte of the current array, and append my current message onto the end of my last message, that would look like the following code block:</p>
<pre>using (Stream ioStream = new FileStream(@"../stream_demo_file.txt", FileMode.OpenOrCreate)) {<br/>  if (ioStream.CanWrite) {<br/>    ioStream.Seek(0, SeekOrigin.End);<br/>    ioStream.Write(messageBytes, 0, messageBytes.Length);<br/>  } else {<br/>    Console.WriteLine("Couldn't write to our data stream.");<br/>  }<br/>}</pre>
<p>Modify your <kbd>using</kbd> statement accordingly, and run the program again. Looking into your output file, you should see the following message:</p>
<pre>Testing writing a different string to a streamTesting writing a different string to a stream</pre>
<p>We started with our original byte array, navigated to the end of the stream of written bytes, and then wrote our message from there; easy as that.</p>
<p>This might seem like a trivial thing, but imagine that you're unpacking a message payload whose data is of a variable size. Typically, you'd have a series of headers or a map of your byte array designating the starting index and the total length of the different components of the payload. Using only those two pieces of information, you can navigate directly to the relevant components of the message and read only and exactly as much as you need to. Reducing this kind of data manipulation in the way that the <kbd>Stream</kbd> class does is incredibly powerful in its simplicity.</p>
<p>But maybe you don't want to write your data to a request stream. Maybe you've written the server code to read from requests and respond to them accordingly. Let's take a brief moment to look at how that's done.<span> </span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Reading from streams</h1>
                </header>
            
            <article>
                
<p>As I said, reading is a one-way operation. Whatever your current index, you will always read from the stream one byte at a time, and in doing so, move your cursor forward by one in the index. So, your next <kbd>Read</kbd> operation always starts one byte after wherever you last read. The trick here is that every time you want to read anything more than a single byte (which you can simply assign to a variable of the byte type), you have to read it into a destination array. So, you'll need to declare and assign a target destination array before you can read it. Let's see this in action; first, though, remove the <kbd>Seek</kbd> operation so that every time you run your app, you don't grow your text file:</p>
<pre>using (Stream ioStream = new FileStream(@"../stream_demo_file.txt", FileMode.OpenOrCreate)) {<br/>  if (ioStream.CanWrite) {<br/>    ioStream.Write(messageBytes, 0, messageBytes.Length);<br/>  } else {<br/>    Console.WriteLine("Couldn't write to our data stream.");<br/>  }<br/><br/>  if (ioStream.CanRead) {<br/>    byte[] destArray = new byte[10];<br/>    ioStream.Read(destArray, 0, 10);<br/>    string result = Encoding.UTF8.GetString(destArray);<br/>    Console.WriteLine(result);<br/>  }<br/>}</pre>
<p>So, like we did before, we check whether it's even valid to try to read from our stream. Then, we designate a new byte array into which we'll be reading our bytes, and then <kbd>Read</kbd>, starting at index zero, and reading for 10 bytes.</p>
<p>I'm sure at this point you're seeing a lot of the issues that this approach poses for developers. Even just the use of old-style square-bracket arrays instead of the more flexible and easy-to-work with List classes introduces a number of pain points for developers. In order to use an old-style array as the target of a <kbd>Read</kbd> operation, you must know the exact size of the array beforehand. This means that you'll either need to explicitly set a predetermined length for your array (and the subsequent <kbd>Read</kbd> operation), or you'll need to have an assigned variable from which you can determine the initial length of the array (since you can't initialize square-bracket arrays without specifying their length).</p>
<p>This is rigid and tedious to use. It makes your deserialization code brittle. The alternative is to designate a reasonable maximum length and use that value to initialize any byte arrays that will be read to from your data stream. Of course, this approach fixes your software to currently known limitations and makes it inflexible and difficult to extend in the future. All of these are challenges posed by the otherwise elegant simplicity of the <kbd>Stream</kbd> class definition. Thankfully, though, along with the power of the <kbd>Stream</kbd> class, comes the simplicity of a number of utility classes .NET Core provides out of the box.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The right stream for the job</h1>
                </header>
            
            <article>
                
<p>Working with the lowest-level data streams representing your network connections does give you a lot of power and control over exactly how incoming messages are parsed and handled. When performance or security is an issue, that byte-level control is invaluable in providing a skilled developer the tools they need to produce the most optimal solution for the task at hand.</p>
<p>However, most of us won't be writing network code with such high demands for performance or security. In fact, most of the code we write will all follow the same series of simple and straightforward patterns of serialization and message generation. That's where the additional <kbd>Stream</kbd> classes really come in handy.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Stream readers and writers</h1>
                </header>
            
            <article>
                
<p>While it is immeasurably useful to understand how to work directly with data streams and bend their use to your specific purposes when you need to, the simple fact is that most of the time, you won't need to. In fact, over my many years as a software engineer, I can count on two hands the total number of times I've needed to devise my own serialization strategies and implement them with lower-level classes for the sake of performance or security. In my professional career, it's much more common to use simpler, well-established serialization strategies that leverage the utility classes provided by the .NET core library.</p>
<p>On the modern web, the common language for communication is, irrefutably, <strong>Javascript Object Notation</strong> (<strong>JSON</strong>). This simple specification for composing and parsing hierarchical data translates so elegantly to almost every data structure you could possibly devise in almost any language that, at this point, it is the transport format of choice for almost every API or web service being written today.</p>
<p>Like everything we've talked about so far, its power comes from its simplicity. It's a string representation of data with simple rules for delimiting and nesting different objects and their respective properties. And while the hierarchy of a JSON object is rigidly defined, the order of properties within that object is entirely arbitrary, giving users a high degree of flexibility and reliability.</p>
<p>With such a ubiquitous standard for serialization, it should come as no surprise that there are widely supported and easy-to-use tools for working with objects in JSON notation. Not only that, but since simple strings account for so much of what we read and write between data sources on a network, there are <kbd>System.IO</kbd> classes designed explicitly for working with them over streams.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Newtonsoft.Json</h1>
                </header>
            
            <article>
                
<p>Let's familiarize ourselves with a non-Microsoft library that was so reliably popular it was ultimately adopted by Microsoft as the official library for parsing JSON in C# and .NET. The more you work with network transactions, the more you will come to appreciate the powerful simplicity of the <kbd>Newtonsoft.Json</kbd> library. There's not a whole lot to it, so let's take a moment now to take a peek under the hood, since we'll be relying on it quite a bit going forward.</p>
<p><span>It's important to know that while </span><kbd>Newtonsoft.Json</kbd><span> remains the library of choice for JSON parsing in C#, Microsoft has actually developed an alternative approach for .NET Core 3.0. The new library has been added as the </span><kbd>System.Text.Json</kbd><span> namespace. However, where <kbd>Netwonsoft.Json</kbd> is written for user-friendliness, providing a rich set of easy to leverage features, the focus of this new JSON library is on performance and fine-grained control over the serialization process. As a result, the feature set of the </span><kbd>System.Text.Json</kbd><span> library is severely limited when compared to </span><kbd>Newtonsoft.Json</kbd><span>. Since we're more concerned with the fundamental concepts behind JSON serialization than with performance, we'll be using </span><kbd>Newtonsoft.Json</kbd><span> as our library of choice throughout this book.</span></p>
<p>To get started with it, you'll need to include the library into your project. If you're using Visual Studio Code, it's as simple as entering the following command into the Terminal window of the editor:</p>
<pre>dotnet add package Newtonsoft.Json</pre>
<p>If you're using Visual Studio, you can simply right click on your project's <span class="packt_screen">Dependencies</span> in your <span class="packt_screen">Solution Explorer</span>, and select <span class="packt_screen">Manage NuGet Packages</span>. From there, search for <kbd>Newtonsoft.Json</kbd> and install the package.</p>
<p>Once you have it available, we'll want an object with a little bit of complexity to it to really show off what <kbd>Newtonsoft</kbd> can do. So, let's add a model definition to our project by adding a new file named <kbd>ComplexModels.cs</kbd> and define a few classes inside:</p>
<pre>using System;<br/>using System.Collections.Generic;<br/><br/>namespace StreamsAndAsync {<br/>    public class ComplexModel {<br/>        public string ComplexModelId { get; set; } = Guid.NewGuid().ToString();<br/>        public int NumberDemonstration { get; set; } = 12354;<br/>        public InnerModel smallInnerModel { get; set; }<br/>        public List&lt;InnerModel&gt; listOfInnerModels { get; set; } = new List&lt;InnerModel&gt;() {<br/>            new InnerModel(),<br/>            new InnerModel() <br/>        };<br/>    }<br/><br/>    public class InnerModel {<br/>        public string randomId { get; set; } = Guid.NewGuid().ToString();<br/>        public string nonRandomString { get; set; } = "I wrote this here.";<br/>    }<br/>}</pre>
<p>Here, we have one type with properties that are instances of another type and lists of instances of another type. Notice that I'm using the inline property initialization feature that was added with C# 6. This allows us to ensure the initialization of each member of our class without having to define the default constructor to do so. So, just by adding up an instance of our <kbd>ComplexModel</kbd>, we will have one fully initialized.</p>
<p>Now, I'm sure you can imagine the pain of trying to traverse that nested structure on your own and then parsing it into a well-formed serialized string. And that's for an object that we got to define ourselves! Consider the added complexity of writing a generic serialization code for any object that you might need to travel over your own network stream classes. It would be a mess of recursion or reflection and a whole bunch of other tedious and time-consuming tasks that few developers enjoy doing.</p>
<p>Thankfully, we often won't have to. If we wanted to take an instance of the class we just defined and write it to our data stream, it's as simple as a single line of code to generate the output string. Let's re-work our sample program to start with an instance of our new <kbd>ComplexModel</kbd> class, and then use <kbd>Newtonsoft.Json</kbd> to serialize it into something more stream-friendly:</p>
<pre>using System;<br/>using System.Text;<br/>using System.IO;<br/>using System.Threading;<br/>using Newtonsoft.Json;<br/><br/>namespace StreamsAndAsync<br/>{<br/>    public class Program<br/>    {<br/>        static void Main(string[] args)<br/>        {<br/>            ComplexModel testModel = new ComplexModel();<br/>            string testMessage = JsonConvert.SerializeObject(testModel);<br/>            byte[] messageBytes = Encoding.UTF8.GetBytes(testMessage);<br/><br/>            using (Stream ioStream = new FileStream(@"../stream_demo_file.txt", FileMode.OpenOrCreate)) {<br/>                if (ioStream.CanWrite) {<br/>                    ioStream.Write(messageBytes, 0, messageBytes.Length);<br/>                } else {<br/>                    Console.WriteLine("Couldn't write to our data stream.");<br/>                }<br/>            }<br/><br/>            Console.WriteLine("Done!");<br/>            Thread.Sleep(10000);<br/>        }<br/>    }<br/>}</pre>
<p>In that simple declaration in the second line of our method, we convert our model into a complete string representation fit for serialized transport. Run the program and then inspect your destination file once again. You should find yourself with a nest of double-quote-delimited property names and their values, and curly and square braces galore. Going the other direction is as simple as passing in your JSON string to the <kbd>Deserialize&lt;T&gt;()</kbd> method, as follows:</p>
<pre>ComplexModel model = JsonConvert.Deserialize&lt;ComplexModel&gt;(testMessage);</pre>
<p>And just like that, you can cleanly and reliably serialize and deserialize your data into a well-understood and widely-used format for network messaging.</p>
<p>The specification of the JSON notation isn't outside the scope of this book, but it should look pretty familiar to you if you have any experience programming JavaScript. Otherwise, I'd recommend checking out the MDN article on the subject here: <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON">https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON</a>.</p>
<p>And if you ever need help organizing a JSON string into something a little more well-structured, you can paste it into <a href="https://jsonlint.com/">http://jsonlint.com</a> to validate that the structure is well-formed, and get a prettified version of the string.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The StreamReader and StreamWriter classes</h1>
                </header>
            
            <article>
                
<p>So, if we can easily and efficiently serialize almost any object we can conceive of to a string, surely (you must be thinking) there is an easier way to write to and read from streams, directly with strings.</p>
<p>Of course, there is; you knew it when you started this section. Enter the ever-versatile <kbd>StreamReader</kbd> and <kbd>StreamWriter</kbd> classes. Each of these classes is explicitly designed to read/write strings specifically. In fact, they both sub-class the <kbd>TextReader</kbd> class from the <kbd>System.IO</kbd> namespace, and extend its functionality to interface directly with byte streams. They are tailor-made to work with strings, and each of them, combined with the simplicity of <kbd>Newtonsoft.Json</kbd>, can make short work of transporting even the most complex data structures over the wire. So, let's see how to use them for the purposes of our network streams.</p>
<p>First, we want to get our stream, just as before, with the <kbd>using</kbd> statement, as follows:</p>
<pre>using (Stream s = new FileStream(@"../stream_demo_file.txt", FileMode.OpenOrCreate)) {</pre>
<p>However, before we do anything else, we also want to initialize our <kbd>StreamWriter</kbd> instance, providing our stream as its initialization parameter:</p>
<pre>using (StreamWriter sw = new StreamWriter(s)) {</pre>
<p>There are a number of constructors for <kbd>StreamReader</kbd>/<kbd>StreamWriter</kbd> that accept encoding specifications, byte order mark detection, and buffer size for buffered streams. However, for network programming, we'll always be using the constructors that accept a <kbd>Stream</kbd> as their first parameter. The constructors that accept strings only ever create <kbd>FileStream</kbd> instances pointing to a local file path. Even though we're using a <kbd>FileStream</kbd> here for demonstration purposes, for real network programming, we'll want to connect directly to a data stream to a remote resource. To do so, we'll have to initialize the stream (likely an instance of the <kbd>NetworkStream</kbd> class) first, and then provide that to our writer/reader instances.</p>
<p>Once the <kbd>StreamWriter</kbd> is initialized, writing is as simple as calling <kbd>Write(string)</kbd> or <kbd>WriteLine(string)</kbd>. Since the class assumes it will be working with strings, our example method is simplified as follows:</p>
<pre>static void Main(string[] args) {<br/>  ComplexModel testModel = new ComplexModel();<br/>  string testMessage = JsonConvert.SerializeObject(testModel);<br/><br/>  using (Stream ioStream = new FileStream(@"../stream_demo_file.txt", FileMode.OpenOrCreate)) {<br/>    using (StreamWriter sw = new StreamWriter(ioStream)) {<br/>      sw.Write(testMessage);<br/>    }<br/>  }<br/><br/>  Console.WriteLine("Done!");<br/>  Thread.Sleep(10000);<br/>}</pre>
<p>And in only five lines of code, we're successfully serializing a complex, nested object instance, and writing it to our output stream.</p>
<div class="packt_tip">When working with strings from remote resources, knowing the specific encoding with which to translate the incoming bytes is key. If a character is encoded as UTF32, and decoded using ASCII, the result wouldn't match the input, rendering your output string a garbled mess. If you ever find a message that you've parsed to be indecipherable, make sure you're using the right encoding.</div>
<p>Since these classes are designed to work exclusively with string content, they even provide useful extensions, such as a <kbd>WriteLine(string)</kbd> method that will terminate the string you've passed in with a line terminator character (in C#, this defaults to a carriage-return followed by a line feed, or <kbd>\r\n</kbd>, though you can override this value based on your environment). Meanwhile, the <kbd>ReadLine()</kbd> method will return characters from your current index up to and including the next line terminator in the buffer. This isn't terribly useful with a serialized object, since you don't want to read a line of a JSON string. However, if you're working with a plain-text response, it can make reading and writing that response a breeze.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Seek versus Peek</h1>
                </header>
            
            <article>
                
<p>One caveat that may not be obvious, however, is the difference in changing your current index with a <kbd>StreamWriter</kbd> or <kbd>StreamReader</kbd> instance. With the <kbd>Stream</kbd> class and its sub-classes, we simply applied the <kbd>Seek</kbd> operation to move through our byte array by a given number of positions forward from a given starting point. However, when you're working with the writer/reader utility classes, you'll notice that you don't have that option. The wrapper classes can only move forward with their base operations using the current index on the stream. If you want to change that index, though, you can do so simply by accessing the underlying stream directly. It's exposed by the wrapper classes through the <kbd>BaseStream</kbd> property. So, if you want to change your position in the stream without performing the operations of the wrapper, you'd use the <kbd>BaseStream</kbd>'s <kbd>Seek</kbd> operation, as follows:</p>
<pre>using (Stream ioStream = new FileStream(@"../stream_demo_file.txt", FileMode.OpenOrCreate)) {<br/>    using (StreamWriter sw = new StreamWriter(ioStream)) {<br/>        sw.Write(testMessage);<br/>        sw.BaseStream.Seek(10, SeekOrigin.Begin);<br/>        sw.Write(testMessage);<br/>    }<br/>}</pre>
<p>Modifying the <kbd>Stream</kbd> class that is underlying the wrapper class will directly change the position to which the wrapper class can write. After running this code, our output file should look like the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7cc5e128-8c9b-4c5f-bb7e-bc803f86b255.png"/></p>
<p>The first 10 characters of our output are <kbd>null</kbd> because the underlying <kbd>Stream</kbd> class had its write index shifted forward by 10 characters!</p>
<p>It's not uncommon to forward search through a string until arriving at a terminating character or flag value. Doing so with the <kbd>StreamReader.Read()</kbd> operation will result in moving the index past the terminating character and popping the terminating character off the array. If you want to simply read the last character before the terminating character, though, you have the <kbd>Peek()</kbd> operation. <kbd>Peek()</kbd> will return the next character in the array without advancing the current index of the <kbd>StreamReader</kbd>. This little tidbit can provide a fair bit of flexibility when you're determining when to stop reading a segment from a string whose length is indeterminable.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The NetworkStream class</h1>
                </header>
            
            <article>
                
<p>While we're looking at the right streams for the right job, we should take a moment to look at the <kbd>NetworkStream</kbd> class. Operating much the same as the <kbd>FileStream</kbd> class that we've been using in our sample code thus far, its underlying data source is an instance of the <kbd>Socket</kbd> class connected to an external resource. Other than designating the underlying <kbd>Socket</kbd> connection for the stream to read from and write to, however, it functions almost entirely the same as the <kbd>FileStream</kbd> class. The various <kbd>Read</kbd>, <kbd>Write</kbd>, and <kbd>Seek</kbd> methods behave exactly as you've seen with our local file samples. And, just as importantly, an instance of <kbd>NetworkStream</kbd> can be used as <kbd>BaseStream</kbd> of an instance of the <kbd>StreamReader</kbd> and <kbd>StreamWriter</kbd> classes, so sending raw text messages over the wire is as easy as it is to write to a local text file. We'll use this class heavily when we start implementing our own socket connections in later chapters, but those will only build on the foundations that we've laid out in this chapter.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Picking up the pace – multithreading data processing</h1>
                </header>
            
            <article>
                
<p>So far, we've only looked at trivial examples of read and write operations on our data streams, and we've only done so with the synchronous <kbd>Read()</kbd> and <kbd>Write()</kbd> methods. This hasn't been an issue for our 50 or 500 character-long messages and single-purpose test applications. However, it isn't hard to imagine scenarios where the data stream is large enough to take a considerable amount of time just to be read through from start to finish. Imagine requesting a file over FTP that is 200 MB large, or imagine requesting 2 million records from a database table hosted on a remote server. If the process that had to perform those operations was also responsible for responding to user behavior through a graphical interface, the long-running data processing task would render the GUI completely unresponsive. Such behavior would be absolutely unacceptable. To that end, .NET Core provides programmers with the concept of <strong>threads</strong>.</p>
<p>With threads, certain operations can be relegated to background tasks that are executed as soon as is feasible for the host process to do so, but won't block the operations of the main thread of your application. So, with this simple, powerful concept, we can assign our potentially long-running, or processor-intensive operations to a background thread, and mitigates the impact of that operation on the performance of the rest of our application. This performance improvement is the single biggest benefit of working with threads.</p>
<p>This aspect of .NET Core applications is accessed through the <kbd>System.Threading</kbd> namespace, which provides everything from <kbd>ThreadPool</kbd> classes to <strong>semaphores</strong> for protecting resources from concurrent access or mutation, to <kbd>Timer</kbd> classes and <kbd>WaitHandles</kbd> classes for more granular control over when and how your background threads are provisioned.</p>
<p>Because of the volatile nature of network connections and the unreliable availability of remote resources, any attempt to access data or services from a remote resource should be handled on a background thread. Fortunately, assigning those tasks to a background thread for parallel processing is actually fairly simple to do. All we have to do is start leveraging those asynchronous methods that we've been glossing over until now.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Asynchronous programming for asynchronous data sources</h1>
                </header>
            
            <article>
                
<p>If you're not familiar with asynchronous programming then what we're about to talk about may seem a little confusing at first, but I promise that in practice, it's actually quite simple. All it means is performing individual computational tasks out of order, or out of sync. It allows engineers to defer blocking the execution of their program to wait for a long-running task until they absolutely have to. To make this clear, let's look at an example.</p>
<p>Let's imagine we have a method that must have step <strong>A</strong> send a request for a massive amount of data, with step <strong>B</strong> performing long-running calculations locally, and finally, <strong>C</strong> returns the two results as a single response. If we were to read the response from our network request synchronously, then the time it takes to complete our method would be the total of the time for each step, <strong>A</strong> + <strong>B</strong> + <strong>C</strong>. The processing time would look like the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f49cab49-4542-4285-9ef5-1af4af07c091.png" style="width:25.50em;height:6.75em;"/></p>
<p>But if we run our web request asynchronously<em>, </em>we can let this run in a background task simultaneously with our long-running local process. In doing so, we reduce the processing time down to only the longer of the two tasks between <strong>A</strong> and <strong>B</strong>, plus <strong>C</strong>. Our processing time now looks like the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/97e1b9d3-6633-4f70-b879-2360978d1adb.png" style="width:22.33em;height:8.75em;"/></p>
<p>Since <strong>C</strong> is the only step that is dependent on <strong>A</strong> to complete processing, we can defer blocking our application code on the completion of <strong>A</strong> until we're ready to execute <strong>C</strong>. To see what that looks like in code, let's first say that we have a <kbd>ResultObject</kbd> class that holds the local and remote information that we want to return to our users. Next, let's assume that the long-running work being done in part <strong>B</strong> of this method is done in the private local method named (appropriately) <kbd>LongRunningSlowMethod()</kbd>. So, with those simple assumptions, let's look at an asynchronous method for processing long-running network requests, as follows:</p>
<pre>public async Task&lt;ResultObject&gt; AsyncMethodDemo() {<br/>  ResultObject result = new ResultObject();<br/>  WebRequest request = WebRequest.Create("http://test-domain.com");<br/>  request.Method = "POST";<br/>  Stream reqStream = request.GetRequestStream();<br/><br/>  using (StreamWriter sw = new StreamWriter(reqStream)) {<br/>    sw.Write("Our test data query");<br/>  }<br/>  var responseTask = request.GetResponseAsync();<br/><br/>  result.LocalResult = LongRunningSlowMethod();<br/><br/>  var webResponse = await responseTask;<br/><br/>  using (StreamReader sr = new StreamReader(webResponse.GetResponseStream())) {<br/>    result.RequestResult = await sr.ReadToEndAsync();<br/>  }<br/>            <br/>  return result;<br/>}</pre>
<p>There's quite a lot going on here, but hopefully, now it's obvious why we approached these last couple chapters the way we did. Let's look at this a little at a time; first, notice the method signature, as follows:</p>
<pre>public async Task&lt;ResultObject&gt; AsyncMethodDemo() {</pre>
<p>Any method you write that takes advantage of asynchronous operations must be flagged with the <kbd>async</kbd> keyword in its signature. This tells users of the method that the operations in this method may take a while, and will run on background threads. And you might have noticed, the return type isn't simply <kbd>ResultObject</kbd>, even though our return value, <kbd>result</kbd>, is declared as such at the start of the method. This is because there are only three valid return types for an asynchronous method: <kbd>void</kbd>, <kbd>Task</kbd>, and <kbd>Task&lt;T&gt;</kbd>.</p>
<p>If your method returns a result, you must wrap that result's type in <kbd>Task&lt;&gt;</kbd> in your method signature. You do not, however, have to wrap the actual returned value in a <kbd>Task&lt;&gt;</kbd> object. This is done for you by the compiler when you have an asynchronous method signature. That's how we're able to declare a return type in our method signature that seems to mismatch the declared type of our returned value in the body of our method.</p>
<p>Moving on in our method, we create a <kbd>WebRequest</kbd> class pointing to our test domain, and then use <kbd>StreamWriter</kbd> to write our data query directly onto the <kbd>WebRequest</kbd>'s request stream. What happens next is where it gets interesting, though, that is, we get to call this following line in our code:</p>
<pre>var responseTask = request.GetResponseAsync();</pre>
<p>The result of the <kbd>GetResponseAsync()</kbd> method that is assigned to our <kbd>responseTask</kbd> variable is actually not<em> </em>the <kbd>WebResponse</kbd> class. Instead, it's a handle to the task that is started in a background thread by the <kbd>GetResponseAsync()</kbd> method. So, instead of waiting around for the response to come back from our server, <kbd>GetResponseAsync</kbd> just gives us a handle to the thread that is fetching that response, and then immediately returns the flow of control to the next operation in our method. This allows us to start our <kbd>LongRunningSlowMethod()</kbd> almost immediately.</p>
<p>Now, since our <kbd>LongRunningSlowMethod()</kbd> is not asynchronous, the flow of control blocks until it completes executing, and its output is assigned to <kbd>result.LocalResult</kbd>. Once that's complete, we can't actually proceed with the function until we've finished getting the result from our web request. Thus, the next line in our program is as follows:</p>
<pre>var webResponse = await responseTask;</pre>
<p>By calling the <kbd>await</kbd> keyword, we're telling our program that we cannot meaningfully proceed until the awaited operation is complete. So, if the task isn't done yet, the program should now block further execution until it is. This is what I meant by <span>defer blocking the execution of their program</span>. We were able to proceed with executing other, unrelated code while this task was finishing up. It's only when there is no more work that can be done without the result of the asynchronous task that you must block, and await the result. That's what we're doing here with the <kbd>await</kbd> call.</p>
<p>The result of awaiting this <kbd>async</kbd> task is whatever was wrapped by the <kbd>Task&lt;T&gt;</kbd> return type in the <kbd>async</kbd> method. So in this case, what gets assigned to the <kbd>webResponse</kbd> variable is the instance of the <kbd>WebResponse</kbd> class we were expecting earlier.</p>
<p>Now that we have our response, we can read from it. In our next few lines, we instantiate <kbd>StreamReader</kbd>, and provided it the response stream from the <kbd>WebResponse</kbd> instance we got back. Finally, we read from the response stream and assign it to our result object:</p>
<pre>result.RequestResult = await sr.ReadToEndAsync();</pre>
<p>Note that even though we have no additional code to execute in this function, we still use the <kbd>ReadToEndAsync()</kbd> method and await the result. The reason for this is because while we don't have anything further to execute in our method, someone invoking our method may be able to defer processing the result we pass back. Using the <kbd>await</kbd> operator tells the compiler that this is another opportunity for deferred execution, and so when this point is reached in our method, control may well return to the calling method until the result of our method is awaited again. For this reason, it's important to always use async methods wherever available, and use them all the way up the call chain. The performance gains will add up substantially over time.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">A final note on blocking code</h1>
                </header>
            
            <article>
                
<p>You might notice that there is a <kbd>Result</kbd> property on the task instance returned whenever you call an asynchronous method. While it may seem tempting to simply use <kbd>GetResponseAsync().Result</kbd> to avoid having to await your asynchronous operations, as well as avoid having to apply asynchronous patterns all the way up the stack, this is a terrible practice.</p>
<div class="packt_tip">Never use <kbd>.Result</kbd> to access the result of an asynchronous task.</div>
<p>It not only blocks your code by forcing synchronous execution, but it also prevents anyone who is calling your methods from being able to defer execution either. Unfortunately, this is one of the most common mistakes that new developers make when they first start working with asynchronous programming. <span>However, you should almost never mix async and blocking code together. A</span><span>s a very simple rule, if</span><span> </span>any<span> </span><span>of your code requires async processing,</span><span> </span>all<span> </span><span>of it does.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we further built on the foundations from which all network programming in C# is supported. We learned about how .NET encapsulates the basic physical concept of a physical stream of incoming or outgoing bits into an elegantly simple and broadly useful <kbd>Stream</kbd> class. Then we looked at the best patterns for working with <kbd>Stream</kbd> through the <kbd>StreamWriter</kbd> and <kbd>StreamReader</kbd> wrapper classes. To facilitate the ease with which we could transmit data through those classes, we got our first look at the incredible power of JSON, and the <kbd>Newtonsoft.Json</kbd> library.</p>
<p>Once we got data streams firmly under our belt, we looked at how to optimize working with them. We talked about the power of multithreading, and what that can mean for performance improvements with long-running tasks and operations. Finally, we took a crash course in asynchronous programming. Learning about how to leverage background tasks and the power of asynchronous method definitions, we saw how we could fully leverage multithreading and background tasks to mitigate the operation latency of potentially long-running operations. Now that we're more comfortably positioned to be working with remote data sources, we'll take the next chapter to learn how to respond to errors from remote data sources.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>What does JSON stand for and why is it useful?</li>
<li>What are the three primary operations available to you through the <kbd>Stream</kbd> class?</li>
<li>What is the purpose of a <kbd>using</kbd> statement?</li>
<li>What is the most important factor in working with strings through the <kbd>StreamReader</kbd> and <kbd>StreamWriter</kbd> classes?</li>
<li>What is the biggest single benefit of leveraging background threads in your programs?</li>
<li>What is the most common mistake programmers make when using asynchronous methods?</li>
<li>What are the only three valid return types of an asynchronous method?</li>
</ol>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<p><span>For more information about these subjects, I'd recommend taking a look at <em>Multithreading with C# Cookbook,</em> <em>Eugene Agafonov,</em> <em>Packt Publishing,</em> at </span><a href="https://www.packtpub.com/application-development/multithreading-c-cookbook-second-edition">https://www.packtpub.com/application-development/multithreading-c-cookbook-second-edition</a>.</p>
<p>For a deeper dive into modern asynchronous programming practices, you should check out <em>C# 7.1 and .NET Core 2.0 - Modern Cross-Platform Development,</em> <em>Mark J. Price, Packt Publishing</em>. You can find this at <a href="https://www.packtpub.com/application-development/c-71-and-net-core-20-modern-cross-platform-development-third-edition">https://www.packtpub.com/application-development/c-71-and-net-core-20-modern-cross-platform-development-third-edition</a>.</p>


            </article>

            
        </section>
    </body></html>