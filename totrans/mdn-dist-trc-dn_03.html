<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-53"><a id="_idTextAnchor052"/>3</h1>
<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>The .NET Observability Ecosystem</h1>
<p>In the previous chapter, we explored .NET observability features included into the platform and frameworks, but there are more instrumentations covering other libraries and environments.</p>
<p>In this chapter, we’ll learn how to find and evaluate instrumentations and then take a closer look at instrumentations for a few specific libraries: StackExchange.Redis, Azure, and AWS SDKs. We’ll also explore tracing and metrics coming from infrastructure using <strong class="bold">Dapr </strong>(<strong class="bold">distributed application runtime</strong>) as an example. Finally, we’ll see how to configure tracing in serverless environments where we have less control, but observability is even more important.</p>
<p>Through this chapter, you’ll learn:</p>
<ul>
<li>How to find, evaluate, and enable OpenTelemetry instrumentations</li>
<li>What Dapr and service meshes are capable of when it comes to observability</li>
<li>How to enable tracing in serverless environments</li>
</ul>
<p>By the end of this chapter, you’ll get hands-on experience with different kinds of instrumentations and you will be able to configure and use distributed tracing for a wide range of backend applications. Let’s get started!</p>
<h1 id="_idParaDest-55"><a id="_idTextAnchor054"/>Technical requirements</h1>
<p>In this chapter, we’re going to evolve our meme application and use a cloud object store, Amazon S3 or Azure Blob Storage, along with a local Redis cache. The code for this chapter is available in the book’s GitHub repository at <a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter3">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter3</a>, which has the following folder structure:</p>
<ul>
<li><code>libraries</code>: Contains library instrumentation sample app for the first section of this chapter</li>
<li><code>dapr</code>: Contains Dapr instrumentation sample for the second section</li>
<li><code>serverless</code>: Contains <code>aws</code> and <code>azure</code> folders with examples of AWS Lambda and Azure Functions instrumentations</li>
</ul>
<p>To run these applications, you would need the following tools:</p>
<ul>
<li>.NET SDK 7.0 or later</li>
<li>Visual Studio or VS Code, but any text editor would work</li>
<li>Docker and <code>docker-compose</code></li>
<li>Dapr CLI</li>
<li>An Azure subscription (optional):<ul><li>We’re going to use Blob Storage and Application Insights.</li><li>With Blob Storage, we’re going to stay well within free-tier limits. Application Insights does not have a free tier, but you can still try it out with Azure promotional credits.</li><li>We’ll use Azure Function Tools v4 and (optionally) Azure CLI.</li></ul></li>
<li>An AWS subscription (optional):<ul><li>We’re going to use S3, Lambda, and X-Ray. We’ll stay well within free-tier limits for each of them.</li><li>We’ll need AWS toolkit for VS or Lambda .NET CLI and (optionally) AWS CLI.</li></ul></li>
</ul>
<h2 id="_idParaDest-56"><a id="_idTextAnchor055"/>Configuring cloud storage</h2>
<p>If you don’t want to create an Azure<a id="_idIndexMarker149"/> or AWS subscription, you can still run <code>libraries</code> and <code>dapr</code> samples locally by setting <code>CloudStorage.Type</code> to <code>Local</code> in <code>storage/appsettings.json</code>. There is no local setup for serverless demos.</p>
<p>Otherwise, set <code>CloudStorage.Type</code> to the storage of your choice, <code>AwsS3</code> or <code>AzureBlob</code>, and let’s see how to configure them.</p>
<h3>AWS S3</h3>
<p>Create a new bucket<a id="_idIndexMarker150"/> using AWS console<a id="_idIndexMarker151"/> or CLI:</p>
<pre class="console">
$ aws s3api create-bucket –bucket &lt;name&gt; --region &lt;region&gt;</pre>
<p>Then, add bucket info to <code>libraries/storage/appsettings.json</code>.</p>
<p>We’ll also need credentials to access blob storage and we’re going to use the credentials file where we can. You can generate one using the <code>aws configure</code> command. Applications would search for AWS credentials file at <code>${HOME}/.aws/credentials</code>.</p>
<p>Replace the <code>HOME</code> environment variable in <code>docker-compose.yml</code> in the <code>libraries/</code> and <code>serverless/aws</code> folders.</p>
<h3>Azure Blob Storage</h3>
<p>Create a new storage<a id="_idIndexMarker152"/> account. You can use Azure portal<a id="_idIndexMarker153"/> or Azure CLI and then obtain a connection string:</p>
<pre class="console">
$ az storage account create –-resource-group &lt;group&gt; --name
&lt;account&gt;
$ az storage account show-connection-string -–resource-
group &lt;group&gt; --name &lt;account&gt;</pre>
<p>Add the connection string to <code>.env</code> file next to <code>libraries/docker-compose.yml</code> in the following format:</p>
<pre class="source-code">
AZURE_BLOB_CONNECTION_STRING="DefaultEndpointsProtocol=
  https;...."</pre>
<h1 id="_idParaDest-57"><a id="_idTextAnchor056"/>Using instrumentations for popular libraries</h1>
<p>In the previous chapter, we saw how to enable<a id="_idIndexMarker154"/> tracing for the .NET<a id="_idIndexMarker155"/> platform, ASP.NET Core, and Entity Framework to cover the basics, but anyone can create instrumentation for a popular library and share it with the community. Also, with tracing and metrics primitives being part of .NET and OpenTelemetry to collect data in a vendor-agnostic way, libraries<a id="_idIndexMarker156"/> can add native<a id="_idIndexMarker157"/> instrumentation.</p>
<p>There are multiple terms that describe different kinds of instrumentations:</p>
<ul>
<li><strong class="bold">Auto-instrumentation</strong> <em class="italic">sometimes</em> implies that instrumentation<a id="_idIndexMarker158"/> can be enabled without <em class="italic">any</em> modification of application code, but is sometimes used to describe any shared instrumentation that is easy to enable.</li>
<li><strong class="bold">Instrumentation library</strong> means that you can enable instrumentation<a id="_idIndexMarker159"/> by installing the corresponding NuGet package and configuring it with a few lines of code at startup time.</li>
<li><strong class="bold">Native instrumentation</strong> implies that instrumentation code<a id="_idIndexMarker160"/> is a part of the library, so no additional NuGet package is necessary, but you may still need to enable instrumentation.</li>
<li><strong class="bold">Manual instrumentation</strong> is the one that you write yourself<a id="_idIndexMarker161"/> as a part of your application code.</li>
</ul>
<p>The boundaries between automatic, native, and instrumentation libraries are blurry. For example, the HTTP client contains native instrumentation starting with .NET 7.0, but you might still enable it in a more convenient way with the corresponding instrumentations. Or, with some bytecode rewrite that configures OpenTelemetry, we can enable library instrumentations without changing any of the application code. In this book, we use a relaxed version of the auto-instrumentation term (for the lack of a better one) to describe all non-manual instrumentations, but we mention a specific kind when it’s relevant.</p>
<p>There are several sources<a id="_idIndexMarker162"/> where we can find available instrumentations:</p>
<ul>
<li><strong class="bold">OpenTelemetry registry</strong> (<a href="https://opentelemetry.io/registry):">https://opentelemetry.io/registry):</a> You can filter the instrumentations<a id="_idIndexMarker163"/> by language<a id="_idIndexMarker164"/> and component. Many instrumentations are not added to the registry though. It lists all kinds of instrumentation regardless of their kind.</li>
<li><strong class="bold">OpenTelemetry .NET repo</strong> (<a href="https://github.com/open-telemetry/opentelemetry-dotnet):">https://github.com/open-telemetry/opentelemetry-dotnet):</a> Contains library instrumentation<a id="_idIndexMarker165"/> for .NET frameworks and libraries. The ASP.NET Core<a id="_idIndexMarker166"/> and HTTP client instrumentations we used in the previous chapter live here along with SQL, gRPC, and exporters for OSS backends. These are instrumentation libraries.</li>
<li><strong class="bold">OpenTelemetry Contrib repo</strong> (<a href="https://github.com/open-telemetry/opentelemetry-dotnet-contrib):">https://github.com/open-telemetry/opentelemetry-dotnet-contrib):</a> Contains different OpenTelemetry components: instrumentation libraries, <a id="_idIndexMarker167"/>exporters, and other<a id="_idIndexMarker168"/> utilities. You can find instrumentations for AWS SDK, ElasticSearch, WCF, StackExchange.Redis, and more there. The Entity Framework instrumentation we used in the previous chapter also lives in this repo.</li>
<li><strong class="bold">OpenTelemetry instrumentation repo</strong> (<a href="https://github.com/open-telemetry/opentelemetry-dotnet-instrumentation):">https://github.com/open-telemetry/opentelemetry-dotnet-instrumentation):</a> Contains fully codeless auto-instrumentations<a id="_idIndexMarker169"/> that work via different<a id="_idIndexMarker170"/> mechanism - .NET profiling API. You can find GraphGL and MongoDB instrumentation there. In addition to auto-instrumentations for specific libraries; it provides a mechanism to configure OpenTelemetry in a codeless way that includes a set of common instrumentation libraries.</li>
<li><strong class="bold">Other sources</strong>: If you didn’t find what you’re looking for in the registry or the OpenTelemetry repos, search for issues in OpenTelemetry repos and don’t forget to check your library repo. For example, you can find MongoDB instrumentation at <a href="https://github.com/jbogard/MongoDB.Driver.Core.Extensions.DiagnosticSources">https://github.com/jbogard/MongoDB.Driver.Core.Extensions.DiagnosticSources</a>, which is leveraged in the <em class="italic">instrumentation</em> repo but can be used as a standalone instrumentation<a id="_idIndexMarker171"/> library.</li>
</ul>
<p>When adding<a id="_idIndexMarker172"/> instrumentations, pay attention to their stability<a id="_idIndexMarker173"/> and maturity. Instrumentations in the <code>opentelemetry-dotnet</code> repo are widely used but are not yet stable (it could have changed by the time you read this).</p>
<p>Instrumentations in the <em class="italic">contrib</em> repo have different statuses; for example, AWS is stable, while MySQL is in alpha and works for relatively old versions of the <code>MySQL.Data</code> package at the time of writing.</p>
<p class="callout-heading">Tip</p>
<p class="callout">If you decide to take dependency on a less common preview package, make sure to test it well. Compatibility with your version of the client library, stability, and performance should be the main concerns. All of them should be covered with integration and stress-testing—just make sure to enable instrumentation!</p>
<p>It’s good to get a basic idea of how the instrumentation works and check whether the mechanism behind it satisfies your performance requirements. For example, native instrumentations rely on <code>ActivitySource</code> or <code>DiagnosticSource</code>, and MongoDB and AWS instrumentations rely on hooks in corresponding libraries. All of these methods should work reasonably well, but the <code>MySQL.Data</code> instrumentation relies on <code>System.Diagnostics.TraceListener</code>, which is not thread-safe by default, and, when configured to be thread-safe, is not performant.</p>
<p>Even the most efficient instrumentations come with some performance hit. You should expect throughput to drop a few percent compared to non-instrumented code. Specific numbers heavily depend on your <a id="_idIndexMarker174"/>scenarios and OpenTelemetry <a id="_idIndexMarker175"/>configuration, such as sampling.</p>
<p class="callout-heading">Note</p>
<p class="callout">Many developers consider auto-instrumentations to be magical and avoid them for this reason. By learning the mechanisms behind instrumentation, you can identify areas for additional testing, understand limitations, and gain confidence to use it (or not).</p>
<p>So, let’s instrument the new version of the meme service and dig deep into each instrumentation we’re going to use.</p>
<h2 id="_idParaDest-58"><a id="_idTextAnchor057"/>Instrumenting application</h2>
<p>Our new demo application<a id="_idIndexMarker176"/> stores memes in Azure Blob Storage or AWS S3 and caches them in Redis, as shown in <em class="italic">Figure 3</em><em class="italic">.1</em>:</p>
<div><div><img alt="Figure 3.1 – Meme service with configurable cloud storage" src="img/B19423_03_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.1 – Meme service with configurable cloud storage</p>
<p>You can also set it up to store memes in Redis if you don’t want to configure a cloud subscription.</p>
<p>There are no changes on <strong class="bold">frontend</strong> from the previous chapter—we already enabled OpenTelemetry with HTTP instrumentations there. On <strong class="bold">storage</strong>, though we still need to add a few more instrumentations for AWS, Redis, and Azure SDK.</p>
<p>First, we need to install <code>OpenTelemetry.Contrib.Instrumentation.AWS</code> and <code>OpenTelemetry.Instrumentation.StackExchangeRedis</code> and then configure them:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">libraries\storage\Program.cs</p>
<pre class="source-code">
builder.Services.AddOpenTelemetry()
  .WithTracing(tracerProviderBuilder =&gt;
        tracerProviderBuilder.
<strong class="bold">      .AddRedisInstrumentation(redisConnection, o =&gt;</strong>
<strong class="bold">            o.SetVerboseDatabaseStatements = true)</strong>
<strong class="bold">      .AddAWSInstrumentation(o =&gt;</strong>
<strong class="bold">            o.SuppressDownstreamInstrumentation = false)</strong>
<strong class="bold">     ...);</strong></pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/libraries/storage/Program.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/libraries/storage/Program.cs</a></p>
<p>Let’s unpack it and explore instrumentations one by one.</p>
<h3>Redis</h3>
<p>Redis instrumentation<a id="_idIndexMarker177"/> is available<a id="_idIndexMarker178"/> via the <code>OpenTelemetry.Instrumentation.StackExchangeRedis</code> package and comes from the <em class="italic">contrib</em> repo—documentation and examples are available there.</p>
<p>Let’s see how we can evaluate this instrumentation. While any details about it might change, the approach can be applied to any other instrumentation library.</p>
<p>Redis instrumentation is not stable at the time of writing but it has a fair number of downloads on NuGet and no bugs reported. If we investigate how it works, we’ll see that it leverages the <code>StackExchange.Redis</code> profiling APIs—hooks allowing the start of a profiling session and recording events that happen during its execution. Despite the name, it doesn’t need the profiler attached.</p>
<p>It’s a relatively complex instrumentation—a profiling API is not designed for distributed tracing, so instrumentation must cover the gaps by maintaining an internal cache of sessions and cleaning them up.</p>
<p>To enable instrumentation, we call the <code>AddRedisInstrumentation</code> extension method on <code>TracerProviderBuilder</code> and pass the connection instance. If you have more than one connection, you’ll have to enable instrumentation for each of them.</p>
<p>We also passed instrumentation options and enabled verbose database statements to collect additional data including Redis keys and scripts by setting <code>SetVerboseDatabaseStatements</code> flag to <code>true</code>:</p>
<pre class="source-code">
AddRedisInstrumentation(redisConnection, o =&gt;
  o.SetVerboseDatabaseStatements = true)</pre>
<p>It’s a good idea to check how this configuration might affect application performance and the verbosity of the output before deploying it to production. If we look into the Redis instrumentation code, this flag guards reflection-based (but efficient) calls to obtain the command key and script.</p>
<p>Depending on what we store in Redis, we should also make sure it does not record any secrets or sensitive data.</p>
<p>You probably noticed that instrumentations follow a common pattern, but unlike Redis ones, most of them are global and don’t require a per-client instance setup.</p>
<p>There are other options that control tracing on Redis: you can specify callback to enrich activities, disable events with additional timings, and configure intervals to clean up completed profiling sessions.</p>
<p>If we start the application now and upload<a id="_idIndexMarker179"/> and download several memes on http://localhost:5051/, we’d see traces<a id="_idIndexMarker180"/> like the one shown in <em class="italic">Figure 3</em><em class="italic">.2</em> for meme download flow:</p>
<div><div><img alt="Figure 3.2 – Meme download with Redis span" src="img/B19423_03_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.2 – Meme download with Redis span</p>
<p>You can see the standard <code>net.peer.*</code> attributes describing generic network endpoint and <code>db.*</code> attributes describing database call with <code>db.statement</code> matching Redis command and key. We only see the key (<code>this_is_fine</code>) since we set <code>SetVerboseDatabaseStatements</code> to <code>true</code>, otherwise <code>db.statement</code> would match the command <code>HMGET</code>.</p>
<p>You can also see three logs (span events in Jaeger) describing additional timings for the Redis command. Since Redis<a id="_idIndexMarker181"/> is quite fast, you might find these events to be not very useful and disable<a id="_idIndexMarker182"/> them by setting <code>EnrichActivityWithTimingEvents</code> to <code>false</code>, which should decrease your observability bill and slightly improve performance.</p>
<h3>AWS SDK</h3>
<p>AWS SDK<a id="_idIndexMarker183"/> instrumentation<a id="_idIndexMarker184"/> is available in the <code>OpenTelemetry.Contrib.Instrumentation.AWS</code> NuGet package with the code residing in the <em class="italic">contrib</em> repo. Let’s try to evaluate it using the same approach.</p>
<p>It is stable and relies on a global tracing handler that applies to all AWS clients and instances, not just S3. This handler in turn leverages .NET tracing primitives: <code>Activity</code> and <code>ActivitySource</code>.</p>
<p>To enable AWS instrumentation, just call the <code>AddAWSInstrumentation</code> extension method on <code>TracerProviderBuilder</code>. At this moment, there’s just one configurable option that controls whether nested HTTP calls should be traced:</p>
<pre class="source-code">
AddAWSInstrumentation(o =&gt; o
  .SuppressDownstreamInstrumentation = false)</pre>
<p><em class="italic">Figure 3</em><em class="italic">.3</em> shows the meme upload trace: <code>PutObject</code> that in turn makes an <code>HTTP PUT</code> request to S3. After the meme is uploaded, it’s cached on Redis:</p>
<div><div><img alt="Figure 3.3 – Upload meme to S3" src="img/B19423_03_03.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.3 – Upload meme to S3</p>
<p>The nested HTTP span is coming from the HTTP Client instrumentation, and we only see it because <code>SuppressDownstreamInstrumentation</code> is set to <code>false</code>.</p>
<p>If we expand <code>S3.PutObject</code>, we’ll see attributes<a id="_idIndexMarker185"/> that describe this operation<a id="_idIndexMarker186"/>, as shown in <em class="italic">Figure 3</em><em class="italic">.4</em>:</p>
<p class="IMG---Figure"> </p>
<div><div><img alt="Figure 3.4 – AWS S3 span attributes" src="img/B19423_03_04.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.4 – AWS S3 span attributes</p>
<h3>Azure SDK</h3>
<p>Azure SDK instrumentation<a id="_idIndexMarker187"/> is native—it’s baked<a id="_idIndexMarker188"/> into modern libraries—and you don’t need to install any additional packages. Tracing code for all client libraries is available in the <a href="https://github.com/Azure/azure-sdk-for-net/">https://github.com/Azure/azure-sdk-for-net/</a> repo. Still, it’s not stable because of tracing semantic conventions being experimental. For example, attribute names, types, and relationships between activities may change in the future.</p>
<p>You can enable it with <code>AppContext</code> switch either in <code>csproj</code> or by adding the following code before Azure clients’ initialization:</p>
<pre class="source-code">
AppContext.SetSwitch(
  "Azure.Experimental.EnableActivitySource",
  true)</pre>
<p>Instrumentation uses <code>ActivitySource</code> and <code>Activity</code> directly, so all we need to enable it is to call the <code>AddSource("Azure.*")</code> method on <code>TracerProviderBuilder</code>. It enables all sources that start with <code>Azure</code>, but you can also enable individual sources.</p>
<p><em class="italic">Figure 3</em><em class="italic">.5</em> shows the Azure SDK blob<a id="_idIndexMarker189"/> upload trace—logical upload operation<a id="_idIndexMarker190"/> and nested HTTP request. We see one there, but for chunked downloads, complex calls, or in case of retries, we’d see multiple nested HTTP calls:</p>
<div><div><img alt="Figure 3.5 –  Azure Blob upload" src="img/B19423_03_05.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.5 –  Azure Blob upload</p>
<p>We explored tracing for several libraries<a id="_idIndexMarker191"/> and learned how to discover and evaluate<a id="_idIndexMarker192"/> instrumentations. Let’s now discover what we can get from infrastructure.</p>
<h1 id="_idParaDest-59"><a id="_idTextAnchor058"/>Leveraging infrastructure</h1>
<p>In this section, we’ll explore<a id="_idIndexMarker193"/> Dapr for microservices. Dapr provides service discovery, component bindings, secret management, locking, state management, observability, and more building blocks helping developers to focus on application logic. We’ll focus on distributed tracing.</p>
<p>In our demo application, we’re going to handle all network calls with Dapr and enable tracing and metrics on it. We’ll also keep telemetry enabled on the microservices. <em class="italic">Figure 3</em><em class="italic">.6</em> shows the new application layout:</p>
<div><div><img alt="Figure 3.6 – Meme application with Dapr runtime" src="img/B19423_03_06.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.6 – Meme application with Dapr runtime</p>
<p>Dapr runs as a sidecar—a separate process wrapping each application instance. <strong class="bold">Frontend</strong> in our setup calls into <strong class="bold">storage</strong> via Dapr, which handles service discovery, error handling, encryption, load balancing, and more. <strong class="bold">Storage</strong>, in turn, uses Dapr output <strong class="bold">binding</strong> to communicate to Azure, AWS, or store memes locally.</p>
<p>Dapr integrates well with Kubernetes, but we’ll use self-hosted mode and <code>docker-compose</code> to keep things simple.</p>
<p>Dapr supports distributed<a id="_idIndexMarker194"/> tracing and metrics for incoming and outgoing calls that applications make through Dapr. Let’s see what it means in practice.</p>
<h2 id="_idParaDest-60"><a id="_idTextAnchor059"/>Configuring secrets</h2>
<p>Dapr secrets configuration<a id="_idIndexMarker195"/> needs a different approach than we used for the libraries demo. We’ll need to update <code>darp/configs/dapr/storage-components/secrets.json</code> as follows:</p>
<ul>
<li>For AWS, put your access keys in <code>{"awsKey": &lt;key&gt;, "</code><code>awsSecret": &lt;secret&gt;}</code>.</li>
<li>For Azure, set <code>{"azStorageAccount": &lt;account&gt;, "azStorageKey": &lt;key&gt;}. </code>If you don't have Azure credentials, remove the <code>binding-azure.yaml</code> file from the <code>dapr/configs/dapr/storage-components</code> folder, otherwise samples will not work.</li>
<li>For local runs, set <code>CloudStorage.Type</code> to <code>Local</code> in <code>storage/appsettings.json</code>.</li>
</ul>
<h2 id="_idParaDest-61"><a id="_idTextAnchor060"/>Configuring observability on Dapr</h2>
<p>To enable tracing<a id="_idIndexMarker196"/> and metrics, let’s add corresponding<a id="_idIndexMarker197"/> sections to <code>Configuration spec</code>:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">./dapr/configs/dapr/config.yml</p>
<pre class="source-code">
spec:
  metric:
    enabled: true
  tracing:
    samplingRate: "1"
    zipkin:
      endpointAddress: "http://otelcollector:9412/
        api/v2/spans"</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/dapr/configs/dapr/config.yml">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/dapr/configs/dapr/config.yml</a></p>
<p>We also added Dapr sidecars to <code>docker-compose.yml</code>, enabled the Zipkin trace receiver on the OpenTelemetry collector, and added Dapr metrics endpoints to Prometheus targets<a id="_idIndexMarker198"/> to scrape from. As a result, we receive traces and metrics<a id="_idIndexMarker199"/> from the application and Dapr at the same time. Let’s check them out.</p>
<h2 id="_idParaDest-62"><a id="_idTextAnchor061"/>Tracing</h2>
<p>Let’s run the application<a id="_idIndexMarker200"/> now with <code>docker-compose up --build</code>, hit <code>http://localhost:16686</code> and find some upload requests, you should see something like the trace shown in <em class="italic">Figure 3</em><em class="italic">.7</em>:</p>
<div><div><img alt="Figure 3.7 – Trace from the application and Dapr " src="img/B19423_03_07.jpg"/>
</div>
</div>
<p class="IMG---Figure">Figure 3.7 – Trace from the application and Dapr</p>
<p>The first two spans coming from <code>frontend /memes/d8…</code> and <code>CallLocal/storage/memes/d8…</code> spans—they are new and are coming from Dapr.</p>
<p>If we expand them as shown in <em class="italic">Figure 3</em><em class="italic">.8</em>, we’ll also see the attributes it set:</p>
<div><div><img alt="Figure 3.8 – Dapr spans and attributes " src="img/B19423_03_08.jpg"/>
</div>
</div>
<p class="IMG---Figure">Figure 3.8 – Dapr spans and attributes</p>
<p>You would probably wonder<a id="_idIndexMarker201"/> if we still need distributed tracing on the service—let’s check it.</p>
<p>Stop containers and comment out the <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> environment variable in <code>docker-compose.yml</code> for <strong class="bold">frontend</strong> and <strong class="bold">storage</strong>; we don’t enable OpenTelemetry if the endpoint is not provided.</p>
<p>Then, restart the application and upload some memes again, and the result is shown in <em class="italic">Figure 3</em><em class="italic">.9</em>:</p>
<div><div><img alt="Figure 3.9 – Dapr tracing without OpenTelemetry enabled in the application" src="img/B19423_03_09.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.9 – Dapr tracing without OpenTelemetry enabled in the application</p>
<p>So, we see the spans coming from Dapr, but the trace does not look right—upload to Azure Blob is not a child of an incoming request represented with <code>CallLocal/storage</code> span. What happened there?</p>
<p>In <a href="B19423_02.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Native Monitoring in .NET</em>, we have shown that ASP.NET Core and <code>HttpClient</code> in .NET create activities regardless of OpenTelemetry presence. This is what happened here—<code>CallLocal</code> is a grandparent to <code>/v1.0/bindings/azureblob</code>, but the span between them is not recorded and causation is lost.</p>
<p>Similarly, if you use Dapr on an application that does not enable distributed tracing by default, the context will not be propagated within the <code>CallLocal</code> and <code>/v1.0/bindings/azureblob</code> would disappear.</p>
<p class="callout-heading">Note</p>
<p class="callout">Dapr or service mesh, such as Istio, can trace network calls, but they cannot propagate trace context within the application process and rely on applications to do it. They also can’t stamp context on the logs if your application does not do it.</p>
<p>If you can’t instrument your application, traces coming from Dapr or service mesh are still handy, despite being semi-correlated.</p>
<p>If you use Dapr for reasons<a id="_idIndexMarker202"/> beyond observability and your application is instrumented, then Dapr tracing gives you observability into Dapr itself to see how it handles requests, so you can compare latencies, debug configuration issues, and so on.</p>
<h2 id="_idParaDest-63"><a id="_idTextAnchor062"/>Metrics</h2>
<p>Dapr reports extensive metrics <a id="_idIndexMarker203"/>about application communication and bindings such as HTTP and gRPC request count, duration, and request and response size histograms. You could also find Go runtime stats for the Dapr itself.</p>
<p>These metrics look quite promising but by default they use the HTTP request path as an attribute on metrics, which has high cardinality. While they allow to reduce cardinality with a regular expression and convert path to an API route, it would be a problem in high-scale production application. Once they become production ready, they could be a great alternative to many in-process metrics covering network communication.</p>
<h1 id="_idParaDest-64"><a id="_idTextAnchor063"/>Instrumenting serverless environments</h1>
<p>Serverless environments<a id="_idIndexMarker204"/> need observability more than other systems—they are frequently used to integrate different services with little-to-no user code, making debugging and local testing difficult. With load balancing, scaling, and other common infrastructure pieces handled for us, we still need to understand what’s going on when things don’t work as expected.</p>
<p>In addition, as users, we are very limited with telemetry collection options—we can’t install agents, configure runtime, or run something in privileged mode—we can only use what cloud providers expose. At the same time, cloud providers have a great opportunity to instrument code for us. Let’s see what AWS Lambda and Azure Functions provide out of the box and what we can do on top of it.</p>
<h2 id="_idParaDest-65"><a id="_idTextAnchor064"/>AWS Lambda</h2>
<p>AWS Lambda<a id="_idIndexMarker205"/> supports invocation<a id="_idIndexMarker206"/> tracing with X-Ray out of the box; you just need to enable active tracing via console or CLI to trace incoming calls to your function and see basic invocation metrics:</p>
<div><div><img alt="Figure 3.10 – AWS X-Ray service map showing default Lambda instrumentation" src="img/B19423_03_10.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.10 – AWS X-Ray service map showing default Lambda instrumentation</p>
<p>To go further than this and trace what happens in your code, you’d need to use X-Ray SDK as a stable solution or OpenTelemetry, which is in beta at this point. We’re going to play with OpenTelemetry in this demo.</p>
<p>The configuration around OpenTelemetry is likely to change. So, we will kindly<a id="_idIndexMarker207"/> ask you to check out the latest instructions for <strong class="bold">ADOT Collector</strong> (<strong class="bold">AWS Distro for OpenTelemetry Collector</strong>), available at <a href="https://aws-otel.github.io/docs/getting-started/lambda/lambda-dotnet">https://aws-otel.github.io/docs/getting-started/lambda/lambda-dotnet</a>.</p>
<p>ADOT Collector is based on OpenTelemetry Collector; it’s also compatible with AWS environments and comes with a preselected set of community components. We’re going to send traces to X-Ray, which is a default configuration<a id="_idIndexMarker208"/> for ADOT Collector, but you can configure it to send data<a id="_idIndexMarker209"/> to your observability backend.</p>
<p>Now we’re ready to explore the tracing experience in Lambda.</p>
<h3>Enabling additional tracing</h3>
<p>Tracing configuration<a id="_idIndexMarker210"/> in Lambda is like any other service. First, we need to install the <code>OpenTelemetry.Instrumentation.AWSLambda</code> NuGet package and then configure it along with the exporter and other instrumentations:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Function.cs</p>
<pre class="source-code">
static Function()
{
<strong class="bold">  Sdk.SetDefaultTextMapPropagator(new</strong>
<strong class="bold">      AWSXRayPropagator());</strong>
    TracerProvider = Sdk.CreateTracerProviderBuilder()
<strong class="bold">      .AddAWSLambdaConfigurations()</strong>...;
}</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs</a></p>
<p>Let’s unpack what happens here. First, we set <code>AWSXRayPropagator</code> as a default context propagator—it enables context propagation over the <code>X-Amzn-Trace-Id</code> header.</p>
<p>Then, we enabled Lambda instrumentation with <code>AddAWSLambdaConfigurations</code>. If we look under the hood, this method does a couple of things:</p>
<ul>
<li>Detects and configures resource attributes such as cloud provider, region, function name, and version</li>
<li>Enables <code>ActivitySource</code> that reports Lambda invocations and stitches context</li>
</ul>
<p>Note that we do it in the static constructor to optimize performance and reduce costs. Despite being serverless, Lambda uses one process for multiple invocations.</p>
<p>As the last step, we need<a id="_idIndexMarker211"/> to implement the tracing handler that wraps our Lambda logic:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">Function.cs</p>
<pre class="source-code">
async Task&lt;APIGatewayProxyResponse&gt; TracingHandler(
  APIGatewayHttpApiV2ProxyRequest req, ILambdaContext ctx)
    =&gt;
    await AWSLambdaWrapper.TraceAsync(TracerProvider,
      MemeHandler, req, ctx);</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs</a></p>
<p>Note that we configured Lambda to invoke <code>TracingHandler</code> instead of inner <code>MemeHandler</code>.</p>
<p>If we get back to the configuration, the rest enables AWS SDK and HTTP Client instrumentation. We also configured the OTLP exporter without parameters—it uses the default endpoint (<code>localhost:4317</code>) and the default protocol (<code>gRPC</code>).</p>
<p>We also configured <strong class="bold">frontend</strong> to send data to ADOT with the X-Ray exporter, so we get all traces in the same place.</p>
<p>If you didn’t deploy your Lambda function yet, deploy it now, for example, with AWS Toolkit for Visual Studio or Lambda tools for .NET CLI.</p>
<p>Make sure to configure the function URL on <code>Storage__Endpoint</code> environment variable—you can set it in <code>./frontend/docker-compose.yml</code>. We don’t use authorization in the demo, but make sure to secure your real-life applications.</p>
<p>Now, let’s start <code>docker-compose up --build</code>, then upload and download some memes at <code>http://localhost:5051</code>.</p>
<p>Let’s switch to AWS X-Ray and check out the traces. You should see something similar to <em class="italic">Figure 3</em><em class="italic">.11</em>:</p>
<div><div><img alt="Figure 3.11 – Lambda tracing with OpenTelemetry" src="img/B19423_03_11.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 3.11 – Lambda tracing with OpenTelemetry</p>
<p>If you check the service<a id="_idIndexMarker212"/> map, it now shows S3 in addition to Lambda nodes.</p>
<p>Now that you know how to enable tracing for AWS Lambda, let’s see what Azure Functions are capable of.</p>
<h2 id="_idParaDest-66"><a id="_idTextAnchor065"/>Azure Functions</h2>
<p>Azure Functions<a id="_idIndexMarker213"/> support distributed tracing<a id="_idIndexMarker214"/> with Azure Monitor (Application Insights) out-of-the-box. It includes triggers and most bindings. If you use in-process functions, tracing covers user code too, with isolated workers, you need to enable and configure tracing in the worker process yourself.</p>
<p>Azure Functions rely on the instrumentations in client SDKs used for triggers and bindings. For example, they reuse ASP.NET Core Activities in HTTP Trigger and Azure SDK instrumentation for Azure Blob Storage inputs and outputs.</p>
<p>The Azure Functions runtime does not support OpenTelemetry for in-process functions yet, but your observability vendor may provide an extension that covers this gap.</p>
<p>In our sample, Azure Functions host automatically reports triggers and binding calls to Application Insights – this auto-collection lights up in presence of the  <code>APPLICATIONINSIGHTS_CONNECTION_STRING</code> environment variable, which we can set in the <code>local.settings.json</code> file, as shown in this example:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">./serverless/azure/memefunc/local.settings.json</p>
<pre class="source-code">
"Values": {
  ...
  "APPLICATIONINSIGHTS_CONNECTION_STRING":
       "InstrumentationKey=&lt;key&gt;;IngestionEndpoint=
           &lt;endpoint&gt;"
}</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/local.settings.json">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/local.settings.json</a></p>
<p>We also need to enable OpenTelemetry for the worker<a id="_idIndexMarker215"/> process with the following<a id="_idIndexMarker216"/> code:</p>
<p class="SC---Heading" lang="en-US" xml:lang="en-US">./serverless/azure/memefunc/Program.cs</p>
<pre class="source-code">
var host = new HostBuilder()
  .ConfigureFunctionsWorkerDefaults
  .ConfigureServices(services =&gt; services
    .AddOpenTelemetry()
    .WithTracing(builder =&gt; builder
<strong class="bold">      .AddSource("Microsoft.Azure.Functions.Worker")</strong>
      ...)
    )
  .Build();</pre>
<p class="SC---Link" lang="en-US" xml:lang="en-US"><a href="https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/Program.cs">https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/Program.cs</a></p>
<p>Here we use a familiar way to enable OpenTelemetry, but <code>the Microsoft.Azure.Functions.Worker</code> activity source is new. The source is part of Azure Functions Worker and propagates trace context from the host to isolated worker. It creates an activity representing worker invocation.</p>
<p>On the <code>Azure.Monitor.OpenTelemetry.Exporter</code> to send data to Application Insights endpoint directly. </p>
<p>To run the sample, we’ll need an Application Insights resource. You can create one with the following command: </p>
<pre class="console">
$ az monitor app-insights component create --app &lt;resource-
  name&gt; --location &lt;region&gt; -g &lt;resource-group&gt;</pre>
<p>It will return JSON<a id="_idIndexMarker217"/> output containing <code>connectionString</code>, which we’ll need to configure<a id="_idIndexMarker218"/> Functions. Let’s now set Azure Blob Storage and Application Insights connection strings in <code>memefunc/local.setting.json</code> and we’re ready to run the application:</p>
<pre class="console">
serverless/azure/frontend$ dotnet run
serverless/azure/memefunc$ func start --port 5050</pre>
<p>Hit <code>http://localhost:5051</code> to upload and download some memes, and then go to your Application Insights resource and search for recent requests. <em class="italic">Figure 3</em><em class="italic">.12</em> shows an example of captured trace:</p>
<div><div><img alt="Figure 3.12 – Azure Functions trace " src="img/B19423_03_12.jpg"/>
</div>
</div>
<p class="IMG---Figure">Figure 3.12 – Azure Functions trace</p>
<p>We traced this call from <code>storage-download</code> function that in turn downloaded a blob. We used Azure Blob Storage bindings, so all the communication with blob storage was handled by Azure Functions host and outside of the worker process. As a result, the Azure Functions invocation span (<code>storage-download</code>) and all spans related to blobs are reported by the Functions host.</p>
<p>The <code>Invoke</code> span is recorded by <code>Microsoft.Azure.Functions.Worker</code> activity source; it represents function invocation on the worker side. If we had any nested operations done inside worker, we’d see them reported as children of the <code>Invoke</code> span.</p>
<p>Even though most of the application<a id="_idIndexMarker219"/> logic happened outside of the application<a id="_idIndexMarker220"/> code, we can see what happened under the hood because of tracing.</p>
<h1 id="_idParaDest-67"><a id="_idTextAnchor066"/>Summary</h1>
<p>In this chapter, we explored instrumentations in the .NET ecosystem. You learned how to evaluate and configure different kinds of instrumentation libraries, how to enable and use tracing on Dapr, and what serverless environments can provide with different levels of configuration.</p>
<p>Client library auto-instrumentations can be found in OpenTelemetry repositories or registries, while some libraries don’t need instrumentations, providing tracing natively. Instrumentations’ maturity and stability levels vary, so it’s important to review and test them as a part of your normal integration and stress testing. Instrumentations usually provide configuration options to control the amount of details they capture, allowing you to find the right cost-value ratio for your system. Client libraries and frameworks are not the only sources of traces—your infrastructure such as service meshes, web servers, load balancers, and proxies can emit them. We checked out the tracing story in Dapr and confirmed that it provides insights into Dapr itself but can’t propagate the context and stamp it on the logs and other signals in the application. So, infrastructure traces complement but cannot substitute in-process tracing.</p>
<p>Serverless environments provide integration with tracing and monitoring tools; it’s critical for them since users are limited in the configuration of serverless runtime.</p>
<p>We explored AWS Lambda, which supports OpenTelemetry, with ADOT Collector and in-code configuration, and Azure Functions that supports vendor-specific codeless instrumentation for in-process mode, while out-of-the-box OpenTelemetry support is yet to come.</p>
<p>Now that you know how to discover and use third-party instrumentations in different environments, you should be able to get observability into a broad spectrum of distributed applications. However, to debug in-process issues such as deadlocks, memory leaks, or inefficient code, we’ll need lower-level telemetry—this is what we’re going to explore in the next chapter.</p>
<h1 id="_idParaDest-68"><a id="_idTextAnchor067"/>Questions</h1>
<ol>
<li>How would you find instrumentation for a popular library you use? When you find one, what would you check for?</li>
<li>What is a typical mechanism behind OpenTelemetry tracing instrumentations?</li>
<li>What service mesh can and cannot do in terms of tracing?</li>
</ol>
</div>
<div><div></div>
</div>
</body></html>