- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Master Data Management
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主数据管理
- en: In the previous chapter, we showed you a method to design information entities
    in such a way that they do not have any technical coupling, in an effort for the
    information system containing them to be free to evolve when the business changes.
    If the data model is a pure reflection of the business represented, it makes it
    much easier to follow business changes (and change is the only constant) because
    there won’t be some technical constraint in our way forcing us to compromise on
    the quality of the design, and thus on the performance of the system as a whole.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们向您展示了一种设计信息实体的方法，使它们没有任何技术耦合，努力使包含这些实体的信息系统在业务变化时能够自由发展。如果数据模型是业务代表的纯粹反映，那么它使得跟踪业务变化（变化是唯一不变的因素）变得容易得多，因为我们不会遇到一些技术约束，这会强迫我们妥协设计质量，从而影响整个系统的性能。
- en: In this chapter, we will start talking about the implementation of the data
    model into something concrete (if this can be said about software, which is mostly
    virtual). It is only in *Chapters 16 to 19* that we will code what we will call
    for the rest of the book the “*data referential(s)*”. For now, we will start some
    actual software architecture to welcome the data model, persist the associated
    entities, and so on. There are many responsibilities in the data referential,
    and the discipline of handling these essential resources in an information system
    is called **Master Data Management** (**MDM**). At first sight, these responsibilities
    might look like those you would trust a database with, or even find in a resource-based
    API. But this chapter should convince you that there are many more things to the
    model that justify this use of a neologism like “data referential”.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将开始讨论将数据模型具体化（如果可以这样说关于软件，它主要是虚拟的）的实施。只有在第16章到第19章，我们才会编写我们称之为本书其余部分“*数据参照*”的代码。现在，我们将开始一些实际的软件架构，以欢迎数据模型，持久化相关的实体，等等。数据参照有很多责任，而在信息系统中处理这些基本资源的学科被称为**主数据管理**（**MDM**）。乍一看，这些责任可能看起来像是你会信任数据库的，或者甚至可以在基于资源的API中找到的。但本章应该让你相信，模型中还有很多其他事情，这证明了使用“数据参照”这样的新词的合理性。
- en: In addition to defining the functions of the data referential, MDM is about
    choosing the right architecture, defining the streams of data in the overall information
    system, and even putting in place governance of the data, which involves finding
    who is responsible for what action on the data in order to keep the system in
    shape. Having clean and available master data may be the single most important
    factor in the quality of the system. Reporting cannot be done without clean data
    and most business processes depend on the availability of the data referential.
    Also, some regulatory reasons, such as accounting or compliance questions, demand
    high-quality data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 除了定义数据参照的功能外，MDM还涉及选择正确的架构，定义整个信息系统中的数据流，甚至实施数据治理，这包括确定谁对数据中的哪些行动负责，以保持系统处于良好状态。拥有干净且可用的主数据可能是系统质量的最重要因素。没有干净的数据就无法进行报告，而且大多数业务流程都依赖于数据参照的可用性。此外，一些监管原因，如会计或合规性问题，要求高质量的数据。
- en: After showing the different types of data referential that you may encounter
    – or create – in an information system, we will finish this chapter with an overview
    of possible issues with data, patterns of use, possible evolution of data in time,
    and some other general topics that will hopefully provide you with up-to-date
    knowledge about the MDM architecture.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在展示了你可能在信息系统中遇到（或创建）的不同类型的数据参照之后，我们将以对数据可能存在的问题、使用模式、数据随时间可能的演变以及一些其他一般性主题的概述来结束本章，这些主题希望为你提供有关MDM架构的最新知识。
- en: Responsibilities around the data
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据相关的责任
- en: The concept of the data referential as a unique point of truth for the data
    entities of a given domain has already been explained globally, but we have not
    formally described what functional responsibilities are contained in it. This
    section will explain each of the main responsibilities and features of the referential.
    Looking at the responsibilities explained in the following subsections, you might
    ask why we’re talking about the data referential instead of simply using the better-known
    expression of a database, but we will see in the second part of this chapter that
    a referential is much more than this.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数据参照作为给定领域数据实体的唯一真实点的概念已经在全局范围内解释过了，但我们还没有正式描述其中包含的功能责任。本节将解释参照的每个主要责任和功能。查看以下子节中解释的责任，你可能会问为什么我们谈论数据参照而不是简单地使用更为人熟知的数据库表达方式，但我们在本章的第二部分将会看到，参照远不止于此。
- en: Persistence
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持久性
- en: '**Persistence** is the responsibility that immediately comes to mind when we
    talk about managing data. After all, when we trust an information system’s data,
    the very first demand we have is that the computer does not forget it once it
    has learned about it. This demand is crucial, as even an electricity failure should
    not have an impact on it. This is why databases were invented and why engineers
    went such a long way to ensure the safe travel of data between memory and hard
    disks, both ways.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**持久性**是我们谈论数据管理时首先想到的责任。毕竟，当我们信任信息系统的数据时，我们首先的要求是计算机一旦了解这些数据，就不会忘记它们。这个要求至关重要，因为即使是电力故障也不应该对其产生影响。这就是为什么发明了数据库，工程师们也走过了如此长的路来确保数据在内存和硬盘之间安全传输，双向都是如此。'
- en: Persistence may be often reduced to **CRUD** (which stands for **Create, Read,
    Update, Delete** – the four main operations on data), but this concept is way
    too limited compared to the features encompassed by the data referential, though
    it is enough for most of the standard uses of low-importance data in the information
    system. Since we talk here about primary data used in many places in the information
    system, some other aspects of persistence have to be taken into account. The first
    one was talked about at length in [*Chapter 4*](B21293_04.xhtml#_idTextAnchor121)
    – namely, time. When one includes time in the MDM equation, storing the so-called
    “current” state of the data (which, most of the time, is only the last-known or
    best-known state of the corresponding business reality) suddenly becomes much
    more complicated and means, at least, storing the different states of data over
    time, with an indication of time to follow the history of these successive states.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 持久性可能经常被简化为**CRUD**（代表**创建、读取、更新、删除**——数据上的四个主要操作），但与数据参照所包含的功能相比，这个概念过于局限。尽管它对于信息系统中低重要性数据的多数标准用途来说已经足够，但当我们谈论信息系统中的主要数据时，必须考虑持久性的其他方面。第一个方面在[*第四章*](B21293_04.xhtml#_idTextAnchor121)中已经详细讨论过——即时间。当我们将时间纳入MDM方程时，存储所谓的“当前”数据状态（这通常只是对应业务现实的最后已知或最佳已知状态）突然变得复杂得多，这意味着至少要存储数据随时间变化的不同状态，并标明时间以追踪这些连续状态的历史。
- en: As we explained in [*Chapter 5*](B21293_05.xhtml#_idTextAnchor164), a good MDM
    is a “know it all” system that, instead of states, should store the actual commands
    modifying the data to enable us to retrace why the state of such an entity has
    evolved. This means that what will be written in the database is not a state with
    a date but, ideally, a “delta” command causing a change from one state to another
    – for example, modifying the zip code in the first address of an author in our
    sample information system. This way, not only can we reconstitute the state of
    a business entity at any time in its life cycle but we also avoid the complexity
    of optimistic/pessimistic locks, transactions, data reconciliation, compensation,
    and so on.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在[*第五章*](B21293_05.xhtml#_idTextAnchor164)中所述，一个好的MDM（Master Data Management）系统是一个“无所不知”的系统，它应该存储实际修改数据的命令，而不是状态，以便我们能够追溯这样一个实体的状态是如何演变的。这意味着数据库中将要写入的不是一个带有日期的状态，而是一个理想的“delta”命令，它导致从一个状态到另一个状态的变化——例如，修改我们样本信息系统中作者第一个地址的邮编。这样，我们不仅可以在业务实体的生命周期中的任何时间重新构建其实体的状态，而且还可以避免乐观/悲观锁、事务、数据协调、补偿等复杂性。
- en: Metadata is also an important addition to the simple CRUD approach. Indeed,
    it is of great importance in the manipulation of master data to be able to retrieve
    and manipulate information linked to the data changes – for example, its author,
    the IP of the machine where the command came from, the identifier of the interaction
    that has caused this change, the actual date of the interaction, maybe also a
    value date if it has been stipulated by the author, and so on. This allows for
    traceability, which becomes more and more important for the main business entities
    in an information system. It also provides powerful insights into the data itself.
    Being able to analyze the history of the data will help you fight fraud (for example,
    by checking which entity changes its bank coordinates often, or limiting how many
    representatives of a given company can change in a given period of time). It can
    also help with some regulatory questions that are becoming more and more common,
    as we will see a bit later when talking about data deletion.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据也是简单CRUD方法的一个重要补充。实际上，在主数据的操作中，能够检索和操作与数据变化相关联的信息非常重要——例如，其作者、命令来源的机器的IP地址、引起这种变化的交互的标识符、交互的实际日期，也许还有如果作者已经规定的话，一个价值日期，等等。这允许进行可追溯性，这对于信息系统中的主要业务实体变得越来越重要。它还提供了对数据的强大洞察力。能够分析数据的历史将帮助您打击欺诈（例如，通过检查哪个实体经常更改其银行坐标，或者限制在一定时期内一个特定公司的代表可以更改的数量）。它还可以帮助解决一些越来越常见的监管问题，我们将在稍后讨论数据删除时看到这一点。
- en: When talking about persistence, we often think of a given entity (and I, for
    one, have only been given examples of such atomic manipulations previously mentioned),
    but the ability to manipulate masses of data is also an important responsibility
    of the data referential. In most cases, this translates into being able to perform
    actions in batches, but the consequences are also in terms of performance management
    and the capacity to handle referential-wide transactions (which are very different
    from business entity-centered translations, which the data referential should
    help eliminate).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到持久性时，我们通常会想到一个特定的实体（而且我，至少，之前只给出了这种原子操作的例子），但操纵大量数据的能力也是数据引用的一个重要责任。在大多数情况下，这转化为能够批量执行操作，但后果也涉及性能管理和处理引用范围事务的能力（这与以业务实体为中心的转换非常不同，数据引用应该帮助消除这种转换）。
- en: The question of identifiers
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标识符的问题
- en: As soon as a business entity unit is created, the question of how to identify
    it arises, since persistence is the capability of retrieving data that the information
    system has been given, and this naturally means that a deterministic way must
    exist to point at this given entity. At the very least, a system-wide identifier
    should exist to do so. It can take a lot of forms but, for the sake of applicability,
    we will consider the following as a URI, for example, `https://demoeditor.com/authors/202312-007`
    or `urn:com:demoeditor:library:books:978-2409002205`. This kind of identifier
    is supposed to be understood globally, by any module participating in the information
    system. It acts a bit as the ubiquitous language in Domain-Driven Design but allows
    pointing at a given entity instead of defining a business concept.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了一个业务实体单元，如何识别它的问题就随之而来，因为持久性是指信息系统能够检索它所提供的数据的能力，这自然意味着必须存在一种确定性的方式来指向这个特定的实体。至少，应该存在一个系统级的标识符来做到这一点。它可以采取很多形式，但为了适用性，我们将考虑以下作为URI，例如，`https://demoeditor.com/authors/202312-007`
    或 `urn:com:demoeditor:library:books:978-2409002205`。这种标识符应该被任何参与信息系统的模块全球理解。它有点像领域驱动设计中的通用语言，但允许指向一个特定的实体而不是定义业务概念。
- en: Of course, local identifiers may exist. For example, the book pointed at by
    `urn:com:demo` **editor:library:books:978-2409002205** could be stored in a MongoDB
    database where its technical `ObjectID` would be `22b2e840-27ed-4315-bb33-dff8e95f1709`.
    This kind of identifier is local to the module it belongs to. Thus, it is generally
    a bad idea to make it known by other modules, as a change in the implementation
    could alter the link and make it impossible for them to retrieve the entity they
    were pointing at.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，可能存在本地标识符。例如，由 `urn:com:demo` **editor:library:books:978-2409002205** 指示的书籍可以存储在MongoDB数据库中，其技术
    `ObjectID` 将是 `22b2e840-27ed-4315-bb33-dff8e95f1709`。这种标识符属于它所属的模块是本地的。因此，通常不是一个好主意让其他模块知道它，因为实现的变化可能会改变链接，并使他们无法检索他们指向的实体。
- en: An entity can also have business identifiers that are not local per se but bear
    no guarantee of being understood anywhere in the information system. The book
    generally identified by `urn:com:demoeditor:library:books:978-2409002205` could
    be retrieved only by its 13-digit ISBN `978-2409002205`; in fact, it is the variable
    part of the unique system identifier. However, other identifiers exist. For example,
    the same book can also be retrieved by its 10-digit ISBN, which is `240900220X`.
    Business identifiers can also be created inside the information system for particular
    uses. In our sample edition company, one could imagine that a serial number is
    applied to a book to keep track at the printing station, where batches are used
    and a single integer might be easier to handle than a full-blown ISBN, without
    risking any confusion as the workshop only prints books of the sample editor.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 实体还可以有业务标识符，这些标识符本身不是本地的，但也不保证在信息系统中的任何地方都能被理解。通常通过`urn:com:demoeditor:library:books:978-2409002205`识别的书籍，只能通过其13位ISBN
    `978-2409002205`检索；实际上，它是唯一系统标识符的可变部分。然而，还存在其他标识符。例如，同一本书也可以通过其10位ISBN检索，即`240900220X`。业务标识符也可以在信息系统中为特定用途创建。在我们的样本版公司中，可以想象给一本书应用一个序列号，以便在印刷站跟踪，在那里使用批量，单个整数可能比完整的ISBN更容易处理，而不会引起任何混淆，因为车间只印刷样本编辑的书籍。
- en: Additional technical identifiers are more often encountered, particularly in
    information systems with legacy software applications. Indeed, those generally
    insist on having their own identifiers. This way, the accounting system of *DemoEditor*
    might know the `urn:com:demoeditor:` **library:books:978-2409002205** book by
    its local identifier, `BK4648`. The ERP system might have a technical identifier
    of `00000786` if the book is the 786th product that has been entered into it.
    And so on. Of course, the dream would be that all software applications are modern
    and can handle an externally-provided, HTTP-standards-aligned URN. But this is
    rarely the case and even modern web applications seem to forget that interoperating
    with other applications means using the URL that they provide indiscriminately.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息系统中，尤其是在具有遗留软件应用的信息系统中，经常会遇到额外的技术标识符。确实，这些系统通常坚持使用自己的标识符。例如，*DemoEditor*的会计系统可能通过其本地标识符`BK4648`来识别`urn:com:demoeditor:`
    **library:books:978-2409002205**`的书籍。ERP系统如果将这本书作为第786个产品录入，可能有一个技术标识符`00000786`。等等。当然，理想的情况是所有软件应用都是现代的，并且能够处理外部提供的、符合HTTP标准的URN。但这种情况很少见，甚至现代网络应用似乎也忘记了与其他应用互操作意味着无差别地使用它们提供的URL。
- en: To provide a good service and account for this reality of information systems,
    the data referential should provide the capacity to store the business identifiers
    for the other software modules participating in the system. At the very least,
    this should be a dictionary of identifiers associated with an entity, with each
    value pointed at by a key that globally identifies the module in the system. For
    example, `urn:com:demoeditor:accounting` could be the key that points to `BK4648`
    and `urn:com:demoeditor:erp` could point to `00000786`. When defining the keys,
    there is a natural tendency to use the name of the specific software used to implement
    the function, and it would not matter much because the identifier is indeed specific
    to this software. But it still remains a good idea to stay generic in order to
    prepare for any cases. To give just an example, in the fusion of two administrative
    regions in France, it proved very useful to have such a separation. The two existing
    software applications for finance management were competing to have a unique market
    after the merger. It happened that one of the software applications was more customizable
    than the other and could handle external identifiers, which was part of the decision
    to keep it as the new unique finance management application. However, since the
    identifiers used by the abandoned software were prefixed by a vendor mark and
    the key for the software that stayed was not generic but used its name, there
    were some strange associations of identifiers such as `urn:fr:region:VENDOR1=VENDOR2-KEY`.
    Since the two brands were well-known competing companies in France and the merger
    of the two administrative regions caused lots of team modification and change
    management, this additional confusion quickly became an irritant, with people
    not even able to tell which software they should use to manipulate financial data.
    In the end, switching to a generic key such as `urn:fr:region:FINANCE` really
    helped, even if this sounded like a little technical move.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供优质的服务并考虑到信息系统这一现实，数据参照应该具备存储系统中参与的其他软件模块的业务标识符的能力。至少，这应该是一个与实体关联的标识符字典，每个值都由一个键指向，该键全局标识系统中的模块。例如，`urn:com:demoeditor:accounting`
    可以是指向 `BK4648` 的键，而 `urn:com:demoeditor:erp` 可以指向 `00000786`。在定义键时，人们自然倾向于使用实现功能的特定软件的名称，这并不会太重要，因为标识符确实只针对这个软件。但仍然是一个好主意保持通用性，以备不时之需。仅举一个例子，在法国两个行政区域的合并中，这种区分证明非常有用。两个现有的财务管理软件应用在合并后竞争拥有一个独特的市场。结果，其中一个软件应用比另一个更可定制，并且可以处理外部标识符，这是将其保留为新唯一财务管理应用的一部分决策。然而，由于被废弃的软件使用的标识符以供应商标记为前缀，而保留的软件的键不是通用的而是使用了其名称，因此出现了诸如
    `urn:fr:region:VENDOR1=VENDOR2-KEY` 这样一些奇怪的标识符关联。由于这两个品牌在法国是众所周知且相互竞争的公司，两个行政区域的合并导致了大量的团队调整和变革管理，这种额外的混淆很快变成了一个烦恼，以至于人们甚至无法确定他们应该使用哪个软件来操作财务数据。最终，切换到通用的键如
    `urn:fr:region:FINANCE` 真的很有帮助，即使这听起来像是一个小小的技术举措。
- en: I will finish this review of identifiers with a very special case, which is
    the change of business identifier. Identifiers are, by essence, stable since they
    should be a deterministic way to point at an entity in the information system.
    A documented case of a change of global identifier is when a social security number
    is designated to a person who has not been born yet, typically because surgery
    is necessary on a fetus. As the first digit in French social security numbers
    uses the ISO gender equality standard to specify the gender of the owner, it may
    happen that instead of using 1 (for male) or 2 (for female), a social security
    number starts with 0 (for unknown). The identifier is then changed to a new one
    after the birth of the individual since the first number is then known (or maybe
    unknown in some other conditions – in this case, the norm specifies the number
    should be 9 for an undetermined gender). This is admittedly a very special case
    that provokes the change of the global, system-wide identifier. However, the architecture
    of the system has to be able to handle *any* existing business case (which does
    not mean there cannot be some manual adjustment for these cases) to be considered
    “aligned.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我将以一个非常特殊的情况来结束对标识符的审查，这个情况是业务标识符的变化。标识符本质上是不变的，因为它们应该是一种确定性的方式来指向信息系统中的实体。一个全球标识符变化的文档案例是当社会保障号被指定给一个尚未出生的人时，通常是因为需要对胎儿进行手术。由于法国社会保障号的第一位数字使用ISO性别平等标准来指定所有者的性别，所以可能会发生这种情况：而不是使用1（男性）或2（女性），社会保障号以0（未知）开头。然后，在个人出生后，标识符会改变为新标识符，因为第一个数字那时是已知的（或者在某些其他条件下可能是未知的——在这种情况下，规范指定该数字应为9，以表示性别不确定）。这确实是一个非常特殊的情况，它引发了全局、系统范围内标识符的变化。然而，系统的架构必须能够处理*任何*现有的业务案例（这并不意味着不能对这些案例进行一些手动调整）才能被认为是“对齐的”。
- en: The single entity reading responsibility
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单个实体读取责任
- en: Persistence really means nothing if data stored somewhere cannot be retrieved
    afterward for subsequent use. This is why reading data is the second responsibility
    of the data referential that we will study. This section details the different
    kinds of read operations and, contrarily to persisting the data, they are actually
    very diverse in their forms.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存储在某个地方的数据无法在之后被检索出来以供后续使用，那么坚持实际上什么也不是。这就是为什么读取数据是我们将要研究的数据引用的第二个责任。本节详细介绍了不同类型的读取操作，与持久化数据相比，它们在形式上实际上非常多样。
- en: The first reading act we naturally think of is the retrieval of a unique entity,
    directly using its identifier. In API terms, this sums up as calling a `GET` operation
    on the URL that has been sent back in the response under the `Location` header
    when creating the entity. Or at least, this sends the latest known state of the
    data because parameters can be added to specify which time version of the data
    should be retrieved. This normally raises the question of how to get the state
    of data since we said we would store changes, not states. The response there can
    be simple or complex, depending on the level of detail we go into. If we radically
    apply the “*premature optimization is the root of all evil*” principle made popular
    by Donald Knuth, then it is enough to specify that states can be deduced from
    changes by applying them to the previous state and consider this recursion uses
    the initial state of the date, which is an empty set of attributes designated
    by a unique identifier.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们自然而然会想到的第一个读取行为是检索一个唯一的实体，直接使用其标识符。在API术语中，这可以总结为在创建实体时，在响应的`Location`头下发送的URL上调用一个`GET`操作。或者至少，这会发送数据的最新已知状态，因为可以通过添加参数来指定应该检索哪个时间版本的数据。这通常引发一个问题，即如何获取数据的状态，因为我们说过我们会存储变化，而不是状态。那里的响应可以是简单的或复杂的，取决于我们深入到什么程度。如果我们激进地应用唐纳德·克努特（Donald
    Knuth）提出的“*过早优化是万恶之源*”原则，那么只需指定可以通过应用它们到前一个状态来从变化中推断状态，并考虑这种递归使用数据的初始状态，即由唯一标识符指定的属性集合。
- en: I know very well that most technically minded people (and thus at least 99%
    of you reading this book) will always think a step further and ponder the huge
    performance problem the data referential would have to deal with if each `GET`
    operation caused the iterative application of hundreds of patches to an entity
    in order to find its state at some point of its life cycle. The very least we
    would do would be to cache the calculated states to improve on this. But when
    you think about it, the vast majority of read operations ask for the best-so-far
    state of the entity, which is the latest known state. So, to improve storage while
    still keeping good performance, caching the last known state of the entities is
    the right choice.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我非常清楚，大多数技术导向的人（因此至少99%的正在阅读这本书的读者）总是会进一步思考，并思考如果每个`GET`操作都需要对实体进行数百次补丁迭代以找到其生命周期中某个点的状态，数据引用将不得不处理的巨大性能问题。我们至少会做的是缓存计算出的状态来改进这一点。但当你这么想的时候，绝大多数的读取操作都是请求实体的最佳已知状态，也就是最新的已知状态。因此，为了在保持良好性能的同时提高存储，缓存实体的最后已知状态是正确的选择。
- en: But there are, of course, some exceptions and, as has been many times explained
    in this book, business-justified exceptions have to be taken into account – not
    only because it is the goal of the alignment but mostly because these exceptions
    are generally great challenges on the data model and if it can accommodate them
    while staying simple, it means this design is mature and has a much greater chance
    of correctness and, hence, stability. One such exception can be when the data
    is often read using a `date` parameter value. In this case, improving the performance
    might mean storing all calculated states, but this uses lots of storage and wastes
    most of it, as not all states will be called in time. A good compromise might
    be to store only a state calculated every 20, 50, or 100 changes. This way, we
    can start from an existing state all the time and quickly calculate the specified
    state because we need only apply a few limited patches to the data. Depending
    on business constraints, some states that are more often used than others can
    be the milestones that are kept in the cache. For example, in financial applications,
    it is generally interesting to keep the value just before and just after the change
    of fiscal year.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，也有一些例外，正如这本书多次解释的那样，必须考虑业务合理的例外情况——不仅因为这是对齐的目标，而且主要是因为这些例外通常是对数据模型的大挑战，如果它能够在保持简单的同时容纳它们，这意味着这种设计是成熟的，并且有更大的正确性和稳定性机会。一个这样的例外可能是当数据经常使用`日期`参数值进行读取时。在这种情况下，提高性能可能意味着存储所有计算出的状态，但这会使用大量的存储，并且浪费了其中大部分，因为并非所有状态都会及时被调用。一个良好的折衷方案可能是只存储每20、50或100次更改计算出的状态。这样，我们就可以始终从一个现有的状态开始，并快速计算出指定的状态，因为我们只需要应用几个有限的补丁到数据上。根据业务约束，一些比其他更常用的状态可以作为缓存中保留的里程碑。例如，在金融应用中，通常很有趣的是保留财政年度变更前后的值。
- en: Another detail that has got to be taken into account is the optional possibility
    of inserting modifications in the life cycle of the entity. I understand how this
    may sound weird to “rewrite the history” and insert changes with potential impacts
    on the following ones, but there are some cases where this makes sense. For example,
    I have seen this happen in accounting systems when errors have been made and calculation
    rules were reapplied to find the correct result, inserting correcting operations
    at the time the initial error arose. Again, this is a rare case and it should
    be conditioned by strict authorization rules, but the situation has to be cited
    for the sake of exhaustivity.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个必须考虑的细节是实体生命周期中插入修改的可选可能性。我理解这听起来可能很奇怪，“重写历史”并插入可能对后续操作产生影响的更改，但有些情况下这是有意义的。例如，我见过这种情况在会计系统中发生，当出现错误并且重新应用计算规则以找到正确结果时，会在初始错误出现时插入纠正操作。再次强调，这是一个罕见的情况，它应该由严格的授权规则来限制，但为了全面性，这种情况必须被提及。
- en: Other kinds of reading responsibilities
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他类型的读取责任
- en: There are cases when the unique system-wide identifier of a business entity
    is not known or has been forgotten (which means not stored outside its original
    referential) and, in this case, the responsibility of searching the entities corresponding
    to given criteria has to be used. This responsibility is often called **querying
    data**. Based on the criteria specified in the request, the operation will return
    a set of results, which can be an empty set or one that contains corresponding
    data. There can be cases when the query attributes are such that the results will
    always contain zero or one entity – for example, because the constraint used is
    a unique business identifier. But there can also be cases where the results are
    particularly numerous, and an additional responsibility called **pagination**
    will be quite useful to reduce bandwidth consumption.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，业务实体的全局唯一标识符是未知的或已被遗忘（这意味着未存储在其原始参照之外），在这种情况下，必须使用搜索与给定标准对应的实体的责任。这种责任通常被称为**查询数据**。根据请求中指定的标准，操作将返回一组结果，这可能是一个空集或包含对应数据的集合。可能会有查询属性的情况，使得结果总是包含零个或一个实体——例如，因为使用的约束是一个唯一的业务标识符。但也可以有结果特别众多的情况，这时一个额外的责任称为**分页**将非常有用，以减少带宽消耗。
- en: 'Pagination can be active (the client specifies which page of data they want)
    but also passive (the server restricts the amount of data and provides a means
    for the client to request the next page of data). A standard way to implement
    the first approach is to use the `$skip` and `$top` attributes, as specified in
    the `$filter` attribute, which is used to specify the constraints reducing the
    query results that have been cited previously, when talking about performance
    in retrieving data. This book is not the place to explain the richness of this
    standard, which is sadly not used as often as it should be. Most API implementers
    indeed chose to use their attribute names, without realizing that they recreate
    functions (such as pagination offset, for example) that have been done so many
    times that they are completely normalized. Lack of interest in standards, and
    a “not invented here” syndrome that many developers suffer, are dragging our whole
    industry back. But enough ranting about this: a complete chapter has been dedicated
    to the importance of norms and standards, so we will just close the subject by
    taking you to the study of the OData standard, or in this case, the GraphQL syntax
    as well, since these two approaches can be seen as competing (though they are
    complementary one to the other, and a great API exposes both protocols).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 分页可以是主动的（客户端指定他们想要的数据页）也可以是被动的（服务器限制数据量并提供客户端请求下一页数据的方式）。实现第一种方法的一个标准方式是使用`$skip`和`$top`属性，如`$filter`属性中指定的，该属性用于指定减少查询结果的约束，这在讨论数据检索性能时已被提及。这本书不是解释这个标准丰富性的地方，这个标准遗憾的是没有被像应该的那样频繁使用。大多数API实现者实际上选择使用他们自己的属性名，而没有意识到他们正在重新创建（例如，分页偏移量）已经被多次完成并且完全规范化的功能。对标准的缺乏兴趣，以及许多开发者遭受的“不是这里发明的”综合症，正在将我们的整个行业拖回。但关于这一点就足够抱怨了：已经有一个完整的章节专门讨论规范和标准的重要性，所以我们将通过向您介绍OData标准来结束这个话题，或者在这个案例中，GraphQL语法也是如此，因为这两种方法可以被视为竞争（尽管它们是相互补充的，并且一个优秀的API会公开这两种协议）。
- en: 'Another type of reading responsibility is reporting: this can sometimes be
    implemented directly by the data referential but this is quite rare, as reporting
    is often done by crossing data coming from several business domains. Even if there
    are only a few of the reporting needs that demand such an external, shared-responsibility
    implementation, then it is better to handle all data for reporting to this entity.
    Depending on the technology you use, this may be a data warehouse, an OLAP cube,
    a data lake, or any other application. Again, the implementation does not really
    matter: as long as you are clean on the interfaces, you may change them any time
    you like with limited impact on the system.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种阅读责任是报告：这有时可以直接由数据参照实现，但这相当罕见，因为报告通常是通过跨多个业务领域的数据来完成的。即使只有少数报告需求需要这种外部、共享责任实现，那么最好是将所有数据用于报告给这个实体。根据你使用的科技，这可能是一个数据仓库、一个OLAP立方体、一个数据湖或任何其他应用。再次强调，实现方式并不重要：只要你在接口上保持清晰，你就可以随时更改它们，对系统的影响有限。
- en: 'In the case of reporting, these interfaces can be solicited with different
    time-based approaches:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在报告的情况下，可以使用不同的基于时间的方法来请求这些接口：
- en: A synchronous, on-demand, call is always possible but generally not used for
    performance reasons, at least in complex reports (this is the “pull” mode). Indeed,
    if the reporting system needs to wait for all sources to answer and then only
    calculates the aggregations on its side, the results are, of course, as fresh
    as possible, but they may take minutes to come and this is often not acceptable
    by users.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步、按需调用始终是可能的，但通常由于性能原因不使用，至少在复杂的报告中是这样（这是“拉”模式）。实际上，如果报告系统需要等待所有源响应，然后在其一侧仅计算聚合，那么结果当然是尽可能新鲜的，但可能需要几分钟才能到来，这通常用户无法接受。
- en: The asynchronous, regular read of data, is the most commonly used pattern. Here,
    data is collected at a given frequency (once a day or more often, sometimes down
    to once an hour), generally by an ETL, and sent to the data warehousing system
    where it is aggregated and prepared for reporting. This way, reports are sent
    to users quicker (sometimes, they are even produced and made available directly
    upon data retrieval). The counterpart is that the data is not as fresh as possible,
    and moving the cursor to a quicker sending of data increases the consumption of
    resources. Optimizations are possible – for example, by reducing the transfer
    to only new or updated data – but this only goes some way into improving the minimal
    time needed to update the whole data warehouse. The greatest technical drawback
    of this approach is that most of the calculations are reproduced even if the source
    data has not changed, which is a waste of resources.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步、定期的数据读取是最常用的模式。在这里，数据以一定的频率（每天一次或更频繁，有时每小时一次）收集，通常由ETL完成，并发送到数据仓库系统，在那里进行聚合和准备报告。这样，报告可以更快地发送给用户（有时，它们甚至可以在数据检索时直接生成并可供使用）。然而，缺点是数据可能不是最新鲜的，将光标移动到更快的数据发送会增加资源消耗。可以进行优化——例如，通过仅传输新或更新的数据来减少传输——但这只能在一定程度上提高更新整个数据仓库所需的最短时间。这种方法最大的技术缺点是，即使源数据没有变化，大部分计算也会重新进行，这是一种资源浪费。
- en: To go on further in the “push” approach, it is possible to use webhooks to register
    data refresh to an event of source data change. This way, the calculations are
    reproduced only when the data has changed, and the moment is as close as possible
    to the interaction that has changed the data, which means the reports are very
    fresh most of the time. Dealing with large amounts of events is a challenge, but
    grouping the changes into minimum packages (or with a maximum freshness time constraint)
    can help.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在“推送”方法中进一步深入，可以使用webhooks将数据刷新注册到源数据变更的事件中。这样，只有在数据发生变化时才会重新进行计算，并且时间尽可能接近数据变化的事件，这意味着大部分时间报告都非常新鲜。处理大量事件是一个挑战，但将变化分组为最小包（或带有最大新鲜时间约束）可以帮助。
- en: A very modern but technically demanding approach is to mix these “push” and
    “calculate on demand” strategies by using a system with queues of messages containing
    data changes and a dedicated architecture to apply fine-grained computations on
    each of these messages as needed. Such implementations of a big data approach
    include Kafka architectures or Apache Spark clusters. The goal here is not to
    detail these approaches but just to explain that they will collect all events
    at the source and then smartly calculate the consequences in aggregated data (the
    smartness being in the fact that they know the consequences and calculate only
    what is needed and they can balance these computations on many machines of a cluster
    and grouping the result in the end). They can even go as far as producing the
    final reports on aggregated data and making them available to end users, achieving
    a complete “push” paradigm.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种非常现代但技术要求很高的方法是，通过使用包含数据变化的队列消息的系统，以及一个用于在每个消息上应用细粒度计算的专用架构，来混合这些“推送”和“按需计算”策略。这种大数据方法的具体实现包括Kafka架构或Apache
    Spark集群。这里的目的是不详细说明这些方法，只是解释它们将收集源数据中的所有事件，然后智能地计算聚合数据中的后果（智能之处在于它们知道后果，只计算所需的，并且可以在集群的许多机器上平衡这些计算，并在最后分组结果）。它们甚至可以进一步到在聚合数据上生成最终报告，并将其提供给最终用户，实现完整的“推送”范式。
- en: 'These four approaches are symbolically represented in the following schema:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这四种方法在以下图中以象征性的方式表示：
- en: '![Figure 10.1 – Modes of reporting](img/Figure_10.1_B21293.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – 报告模式](img/Figure_10.1_B21293.jpg)'
- en: Figure 10.1 – Modes of reporting
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 报告模式
- en: To be exhaustive on these additional reading responsibilities, indexing is another
    function that is used to accelerate data (and some simple aggregates) reading.
    It does not go as far in data transformation as big data and the preceding reporting
    approaches, but can already prepare a few aggregates (such as sums, local joins,
    and so on) and make them available through simple protocols as raw data. Indexing
    engines such as SOLR or Elasticsearch are generally used to accompany the data
    referential on the speed of data retrieval. In this case, the data referential
    itself concentrates on data consistency and validation rules and then handles
    reference data to the indexing system to make it available in quick-read operations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了详尽地说明这些额外的阅读责任，索引是另一个用于加速数据（以及一些简单的聚合）读取的功能。它并不像大数据和先前的报告方法那样深入数据转换，但它已经可以准备一些聚合（如总和、局部连接等）并通过简单的协议作为原始数据提供。SOLR
    或 Elasticsearch 等索引引擎通常用于在数据检索速度上伴随数据参照。在这种情况下，数据参照本身专注于数据一致性和验证规则，然后处理索引系统中的参考数据，以便在快速读取操作中使其可用。
- en: The complex art of deleting data
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除数据的复杂艺术
- en: If deltas are stored instead of states, there is not much difference between
    `POST`, `PUT`, and `PATCH` operations on a resource, as they all translate into
    a change in the state of the entity, the particular case of a resource creation
    being a change from something completely empty. But as far as the `DELETE` operation
    is concerned, we are in a different situation. Indeed, we could blindly apply
    the same principle and consider that `DELETE` removes all attributes of an entity
    and brings it back to its initial state, but that would not be exactly true as
    the entity still keeps an identifier (otherwise, one would not be able to delete
    it). This means it is not in the same state as when it did not exist and there
    is no way to go back to this situation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存储的是 delta 而不是状态，那么在资源上的 `POST`、`PUT` 和 `PATCH` 操作之间并没有太大的区别，因为它们都转化为实体状态的改变，资源创建的特殊情况是从完全空的状态的改变。但是，就
    `DELETE` 操作而言，我们处于不同的情境。确实，我们可以盲目地应用相同的原理，并认为 `DELETE` 移除了实体的所有属性并将其恢复到初始状态，但这并不完全准确，因为实体仍然保留了一个标识符（否则将无法删除它）。这意味着它并不处于不存在时的状态，而且无法回到这种情况。
- en: 'The best way to handle the situation is generally to use a particular attribute
    of the date stating that it is not active anymore. When using a `status` attribute
    to keep the value of the calculated position in the life cycle of an entity, this
    attribute may be used with a value such as `archived` to realize a similar operation.
    This is the way the data referential can store the fact that the data has been
    deleted without actually suppressing data (which is incompatible with what has
    been said previously about the data referential and its responsibility for history
    persistence). Of course, this creates a bit of complexity in the referential because
    it has to take this into account in every operation it allows. For example, reading
    some piece of data that is inactive should react as if the data did not exist
    (with a `404` result, in the case of API access), unless in the exceptional case
    that the user accessing the referential has an `archive` role and can read erased
    data. Other questions naturally arise then, such as the possibility of reactivating
    data and continuing its life cycle (hint: it is generally a bad idea, as many
    business rules are not thought to handle this very peculiar case).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这种情况的最佳方式通常是使用日期的一个特定属性来表示它已不再活跃。当使用 `status` 属性来保持实体生命周期中计算出的位置时，此属性可以使用如
    `archived` 这样的值来实现类似操作。这就是数据参照能够存储数据已被删除的事实，而实际上并未删除数据（这与之前关于数据参照及其对历史持久性的责任的说法不符）。当然，这会在参照中增加一些复杂性，因为它必须在每个允许的操作中考虑这一点。例如，读取某些不活跃的数据应该表现得就像数据不存在一样（在
    API 访问的情况下，结果是 `404`），除非在特殊情况中，访问参照的用户具有 `archive` 角色，可以读取已删除的数据。随后自然会提出其他问题，例如重新激活数据并继续其生命周期的可能性（提示：这通常是一个坏主意，因为许多业务规则并未考虑到这种非常特殊的情况）。
- en: But let’s stop this digression here and come back to the initial idea of data
    conservation even after a deletion command has been issued. The functional rationale
    behind this is mainly regulatory, such as traceability, but also prohibiting data
    erasing for other purposes, such as forensics after a cyber-attack. An interesting
    fact is that some regulations also exist that specify when data should indeed
    be erased for real (and not simply rendered inactive). For example, the European
    GDPR states that personal data should not be kept longer than some legally defined
    periods, depending on the processes they are associated with. In the case of personal
    data collected for marketing reasons (with the consent of the user, of course),
    the delay is generally a year. After this time, without renewal of storage consent,
    the data shall be erased from the information system that has collected it. That
    means the actual removal of the data everywhere it may be (which includes backups).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们在这里停止这种离题，回到数据保留的最初想法，即使在发出删除命令之后。这一功能背后的主要原因是监管性的，例如可追溯性，但也禁止出于其他目的（如网络攻击后的取证）删除数据。一个有趣的事实是，一些法规还规定了数据确实应该被删除（而不是仅仅被停用）的确切时间。例如，欧洲的GDPR规定，个人数据不应保留超过某些法律定义的期限，具体取决于它们所关联的过程。在为营销目的收集的个人数据（当然，是在用户同意的情况下）的情况下，延迟通常是1年。在此之后，如果没有更新存储同意，则应从收集这些数据的信息系统中删除数据。这意味着实际上在所有可能的地方（包括备份）删除数据。
- en: Relation to specialized links
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与专用链接的关系
- en: 'As always, the devil lies in details, and links can become a problem when dealing
    with data. Imagine we use a link between a book and an `author` entity. The simplest
    expression of such an RFC link is the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 总是如此，魔鬼藏在细节中，处理数据时链接可能会成为一个问题。想象一下，我们使用一个链接在书籍和`作者`实体之间。这种RFC链接的最简单表达如下：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The links are often inherited from specialized links – in our case, a specialized
    author link that could contain additional important information in its schema,
    for example, extract restricted to the portion of JSON that has changed, for readability
    purposes:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 链接通常是从专用链接继承而来的——在我们的案例中，是一个包含其模式中额外重要信息的专用作者链接，例如，为了可读性目的，仅提取已更改的JSON部分：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Having additional information in links is useful when you know this is a piece
    of information that will frequently be used when manipulating the link, as it
    avoids an additional roundtrip to the other API to find this information. Of course,
    there should be a right balance, and including the phone number here is questionable
    because it can be considered volatile data, not changing frequently but on some
    specific occasions in the mass of authors of an editor’s database. The consequence
    is that all links should – in this case – be updated, which accounts for quite
    a large amount of work. When you know it is a piece of data that does not change
    (the author’s name, for example, does not change very often) or even data that
    should never be changed for regulatory reasons (an approved version, for example,
    should not be modified even if further versions appear), there is no such problem.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当你知道链接中包含的信息是经常在操作链接时使用的信息时，在链接中包含额外的信息是有用的，因为它避免了额外的往返到其他API以查找此信息的额外步骤。当然，应该有一个适当的平衡，在这里包含电话号码是可疑的，因为它可以被认为是易变数据，不会经常改变，但在编辑数据库的大量作者中的某些特定场合会改变。结果是，所有链接都应该（在这种情况下）更新，这需要相当大的工作量。当你知道这是一些不会改变的数据（例如，作者的名字不会经常改变）或出于监管原因不应更改的数据（例如，批准的版本不应修改，即使有进一步的版本出现）时，就没有这样的问题。
- en: 'This is the first issue that should be taken care of with links. The second
    one is more subtle: since the `title` attribute (which is not an extended one
    added through inheritance but exists in the standard RFC link definition) has
    been used to store the common designation of the author, as expected from the
    definition of this attribute in the RFC, deleting an author will end up with their
    name still existing in the book’s data referential through these links. This may
    be interesting for archiving reasons (even if we do not deal with this author
    anymore, for example, even though they have died, the books are still in their
    name). However, in some other regulatory contexts, this can be a tough problem:
    if we go back to the example of the European GDPR “right to be forgotten” for
    personal data, that means that when the author is deleted from the database, we
    should also go over all the books they authored and replace the `title` contents
    with something like `N/A (GDPR)`. This is how `DELETE` operations can work under
    specific functional circumstances!'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理链接时应注意的第一个问题是。第二个问题更为微妙：由于`title`属性（这不是通过继承添加的扩展属性，而是存在于标准RFC链接定义中）已被用来存储作者的通用名称，正如RFC中该属性的定义所预期的那样，删除一个作者将导致他们的名字仍然通过这些链接存在于书籍的数据参照中。这可能对存档原因很有趣（即使我们不再处理这位作者，例如，即使他们已经去世，书籍仍然以他们的名字命名）。然而，在某些其他监管环境中，这可能是一个棘手的问题：如果我们回到欧洲GDPR“被遗忘权”的例子，这意味着当作者从数据库中删除时，我们还应该检查他们所写的所有书籍，并将`title`内容替换为类似`N/A
    (GDPR)`的东西。这就是在特定功能情况下`DELETE`操作可以如何工作！
- en: So-called secondary features
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所称的次要功能
- en: Though we might think we have covered all the responsibilities of the data referential
    since we passed on the four letters of the CRUD acronym, the spectrum of a good
    application is much larger. To be thorough, we should talk about all the functions
    that are generally called “secondary,” even though they are critical and – in
    some cases – equally important as the persistence of the data itself.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可能认为我们已经覆盖了数据参照的所有责任，因为我们已经通过了CRUD缩略词的四字母，但一个好的应用程序的范围要大得多。为了彻底，我们应该讨论所有通常被称为“次要”的功能，尽管它们是关键的，而且在某些情况下，与数据本身的持久性一样重要。
- en: 'The first one of these additional features is **security**. There should be
    no doubt about the importance of this one anymore, but if it is necessary to convince
    anyone, let’s just stress the fact that the four criteria commonly used in security
    categorization are all about data:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些附加功能中的第一个是**安全性**。关于这一点的重要性不应再有疑问，但如果需要说服任何人，让我们强调这样一个事实：在安全分类中常用的四个标准都是关于数据的：
- en: '**Availability**: The data should be available to authorized persons, which
    means denial of service (among others) has to be treated. Though unavailable data
    is a good way to prevent leakage or unauthorized access, it remains the primary
    criterion, as the whole idea is to provide a service in a solid way. Availability
    also means that a simple mishap should not get the whole system offline.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性**：数据应可供授权人员使用，这意味着必须处理服务拒绝（以及其他情况）。尽管不可用数据是防止泄露或未经授权访问的好方法，但它仍然是首要标准，因为整个想法是以稳固的方式提供服务。可用性还意味着简单的失误不应该导致整个系统离线。'
- en: '**Integrity**: The data should not be tampered with by anyone and its correctness
    should be guaranteed – the consequence being that all functions underlying the
    service have to be secured as well (database, network, source code, etc.).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**诚信**：数据不应被任何人篡改，其正确性应得到保证——结果是，所有支撑服务的功能都必须得到保护（数据库、网络、源代码等）。'
- en: '**Confidentiality**: This is the counterpart of the first criterion, as access
    should be forbidden to non-authorized requesters. It is the basis for authorization
    management systems (more on this in the next chapter).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机密性**：这是第一个标准的对应项，因为应禁止非授权请求者访问。它是授权管理系统的基础（关于这一点将在下一章中详细介绍）。'
- en: '**Traceability**: This criterion is a more recent one but becomes more and
    more important with regulations on IT systems; it states that the modification
    and use of data should be stored in a log that cannot be tampered with, allowing
    it to retrieve what happened back in time. Traceability is most important after
    an attack has happened to understand where the vulnerability was and what the
    attackers have done.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可追溯性**：这个标准是一个较新的标准，但随着对IT系统监管的加强，它变得越来越重要；它规定数据的修改和使用应该存储在一个无法篡改的日志中，以便能够回溯过去发生的事情。在攻击发生后，可追溯性最为重要，可以用来了解漏洞在哪里以及攻击者做了什么。'
- en: '**Performance** and **robustness** are also so-called secondary features that
    have a high importance in MDM. They are very much linked to the first criterion
    (availability). Indeed, the robustness of the software underpins its capacity
    to answer requests in time with great confidence, and performance is a quality
    associated with the availability of the data. After all, if someone gets a response
    to their request for data after 5 minutes, they would not think of the service
    as being available, though it could be qualified as such since the data indeed
    arrived… at some point. Rapid availability of data has often been a drive to move
    existing “manual” information systems to a software-oriented approach.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能**和**健壮性**也是所谓的次要特性，在MDM中具有很高的重要性。它们与第一个标准（可用性）密切相关。确实，软件的健壮性是其能够以极大的信心及时回答请求的能力的基础，而性能是与数据的可用性相关联的质量。毕竟，如果某人在5分钟后收到了对数据请求的响应，他们不会认为该服务是可用的，尽管数据确实在某一点到达了……。数据的快速可用性往往推动了将现有的“手动”信息系统迁移到面向软件的方法。'
- en: Dealing with these features is the subject of many books, so we will just leave
    it there for now, since those are indeed responsibilities expected from the data
    referential.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这些特性是许多书籍的主题，所以我们现在就留在这里，因为这些确实是期望数据参照承担的责任。
- en: Metadata and special kinds of data
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元数据和特殊类型的数据
- en: Finally, the data referential should handle data and also metadata. Metadata
    is all the information that sits around the data entities themselves and allows
    for a good comprehension of them. This provides some additional richness to the
    data, but please be aware that metadata should have a different life cycle from
    the data itself. For example, storing information about the history of data is
    not metadata, though it can abide by the definition of metadata just given. As
    has been exposed many times now, the data referential keeps track of every change
    in the entities it hosts. So, information about who changed what at what times
    is data and not metadata for a complete and correct data referential. In the same
    way, dates of changes, indicators of modification, or reading frequency can be
    directly deduced from the series of operations in the data referential, so they
    are not metadata either.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，数据参照不仅应该处理数据，还应该处理元数据。元数据是围绕数据实体本身的所有信息，有助于对这些实体的良好理解。这为数据提供了一些额外的丰富性，但请注意，元数据应该与数据本身有不同的生命周期。例如，存储关于数据历史的信息不是元数据，尽管它可以符合前面给出的元数据定义。正如现在多次被揭露的那样，数据参照跟踪其托管实体的每一个变化。因此，关于谁在何时更改了什么的信息是数据，而不是完整和正确数据参照的元数据。同样，更改日期、修改指标或读取频率可以直接从数据参照的操作序列中推导出来，因此它们也不是元数据。
- en: A good example of metadata is the units associated with numeric data. Having
    a number in a named attribute of the entity is often not enough. Sure, the attribute
    can have a name that describes its content and also the units (examples would
    be `populationInMillions`, `lengthInMillimeters`, or `nbDaysBackupRotation`),
    but that does not make it any easier to manipulate the values and, in addition,
    that makes for longer names, which can be a bit cumbersome when the unit sounds
    obvious. Having metadata somewhere in the schema of the referential that states
    that *this* attribute of *this* entity uses *this* unit is a better way to communicate
    the handling of the data, and can also help in some modern database engines to
    directly calculate formulas between attributes that are not on the same scale
    of units, and even provide some warning when the formulas are not safe in terms
    of units definition, such as adding meters and seconds. These new servers generally
    use a standard definition of units that includes the powers in `kN` unit is associated
    with M1K1S-2 as seen previously, but with a multiplier of 10^3 and the name `kiloNewton`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据的一个好例子是与数值数据相关的单位。在实体的命名属性中有一个数字通常是不够的。当然，属性可以有一个描述其内容以及单位的名称（例如`populationInMillions`、`lengthInMillimeters`或`nbDaysBackupRotation`），但这并不使操作值变得更容易，而且，此外，这会使名称更长，当单位听起来很明显时可能会有些繁琐。在引用模式的某个地方有元数据声明说，*这个*实体的*这个*属性使用*这个*单位，这是一种更好的方式来传达数据的处理方式，并且还可以帮助在某些现代数据库引擎中直接计算不同单位尺度上的属性之间的公式，甚至当公式在单位定义方面不安全时提供一些警告，例如将米和秒相加。这些新服务器通常使用一个标准的单位定义，包括之前看到的`kN`单位与M1K1S-2相关联，但乘以10^3，名称为`kiloNewton`。
- en: Geographical attributes are another good example of metadata addition to the
    usual data in a database. Generally, longitude and latitude were expressed as
    double-precision numbers in `lon` and `lat` attributes, but this did not account
    for the kind of world-map projection (which can create some discrepancies in the
    number) and would not prevent silly computations such as adding the two numbers.
    With database or geographical servers able to understand the metadata added to
    the coordinates data, it is now possible to calculate distance, transpose coordinates
    from one projection system to another, and so on.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 地理属性是数据库中通常数据添加元数据的另一个好例子。一般来说，经度和纬度在`lon`和`lat`属性中以双精度数字表示，但这并没有考虑到世界地图投影（这可能会在数字上产生一些差异）并且不会阻止像将两个数字相加这样的愚蠢计算。随着数据库或地理服务器能够理解添加到坐标数据中的元数据，现在可以计算距离，将坐标从一个投影系统转换到另一个投影系统，等等。
- en: Metadata is the long-forgotten cousin of data. Apart from CMIS, the standard
    for electronic document management systems, where they enjoy first-order citizenship
    (supporting groups of metadata implemented in schemas that can be applied to the
    documents, used in the queries when searching, and sometimes even versioned independently
    of the documents supporting them), there are not that many standards that formalize
    them. The evolution of this depends entirely on engineers who are interested in
    doing their jobs in a professional and clean manner. As long as “quick and dirty”
    tricks are used in the software programming and the structuring of information
    systems, metadata will continue to be set aside. When people – hopefully after
    reading this book and some others advising in the same quality and long-term approach
    – decide that the burden of the coupling is too high and they have to address
    the problem by modernizing their information system, metadata use should naturally
    rise, making it in time as standard and usual as any other practice.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据是长久以来被遗忘的数据的表亲。除了CMIS，即电子文档管理系统标准，其中它们享有第一公民权（支持在模式中实现的元数据组，这些模式可以应用于文档，在搜索时使用，有时甚至可以独立于支持的文档进行版本控制）之外，没有多少标准将它们正式化。这一演变完全取决于对以专业和整洁的方式完成工作感兴趣的工程师。只要在软件编程和信息系统的结构化中使用“快速且脏”的技巧，元数据将继续被忽视。当人们——希望是在阅读这本书以及一些其他在相同质量和长期方法上提供建议的书之后——决定耦合的负担太高，他们必须通过现代化他们的信息系统来解决这个问题时，元数据的使用应该自然增加，使其及时成为像其他任何实践一样标准和常见。
- en: Now that we know how the data referential should be defined, we will dive into
    how this can be provided by a software system.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了数据引用应该如何定义，我们将深入探讨这是如何由软件系统提供的。
- en: The different kinds of data referential applications
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同类型的数据引用应用
- en: We will not talk about technical aspects in this section (this is the role of
    the following one, called *Some architectural choices*) but about architectural
    strategies to structure the data persistence.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们不会讨论技术方面（这是下一节，即*一些架构选择*的作用），而是关于如何构建数据持久性的架构策略。
- en: In the previous chapter, the metaphor of the flower was introduced to show how
    data can be organized inside an entity. We will follow this idea to represent
    how persistence can be implemented in the data referential that manages instances
    of such an entity. Before we dive into the main architectures, please remember
    that the main criteria of choice should always remain functional, which, in the
    case of data, means that the life cycle in your system is what will drive you
    principally into this or that architectural choice. Also keep in mind that the
    *people* aspect of data management is as important as the *technical* aspect;
    governance, designation of people responsible, and good communication about which
    team owns which pieces of data are essential to the correct use of data in your
    organization.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们引入了“花朵”的隐喻来展示数据如何在实体内部组织。我们将遵循这个想法来表示如何在管理此类实体实例的数据参照中实现持久性。在我们深入主要架构之前，请记住，选择的主要标准始终应该是功能性的，在数据的情况下，这意味着您系统中的生命周期将主要驱使您做出这个或那个架构选择。同时，请记住，数据管理的*人员*方面与*技术*方面一样重要；治理、指定负责人员以及关于哪个团队拥有哪些数据的好沟通对于您组织正确使用数据是至关重要的。
- en: Centralized architecture
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集中式架构
- en: 'The centralized (or “unique”) referential is the simplest one (as shown in
    *Figure 10**.2*) that everybody first thinks of and that solves so many problems
    in the information system when it can be applied: it consists of having a single
    storage mechanism for every bit of data concerning a given type of entity (including,
    of course, history, metadata, and so on). This way, all services working in the
    system know that, when needing to read or write something, they have to address
    their request to a single repository service, as the whole “flower” is in one
    well-known place.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 集中式（或“唯一”）参照是其中最简单的一种（如图 *图 10.2* 所示），是每个人首先想到的，并且当它能够应用时，在信息系统中解决了许多问题：它包括为给定类型的实体（当然包括历史、元数据等）的每一比特数据拥有一个单一的存储机制。这样，系统中所有工作的服务都知道，当需要读取或写入某些内容时，他们必须将请求地址到一个单一的资源库服务，因为整个“花朵”都在一个众所周知的地方。
- en: '![Figure 10.2 – Centralized data referential architecture](img/Figure_10.2_B21293.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 集中式数据参照架构](img/Figure_10.2_B21293.jpg)'
- en: Figure 10.2 – Centralized data referential architecture
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 集中式数据参照架构
- en: 'The great thing about this approach is that it simplifies the work for everyone
    in the information system. Of course, this constitutes a **single point of failure**
    (**SPOF**) and, if the implementing application is down, all applications needing
    this referential information will be impacted. But this is just a technical problem,
    with many battle-proven solutions such as active/active synchronization of the
    database, scaling of the application server, redundancy of hardware, and so on.
    By now, you should also be convinced that the functional aspects are always more
    important to take into account than the technical ones. As technicians, we tend
    to focus on low-occurrence problems such as hardware failure or a locked transaction,
    whereas the immensely greater problems in information systems nowadays are duplicates
    of data, poor cleanliness of the inputs, and other commonly observed issues that
    urgently need to be addressed. The SPOF might be more important in the people
    organization: a centralized data referential might mean that a single team or
    even a single person is in charge of the management of this set of data, and some
    drawbacks are always possible with too much centralization (feedback not taken
    into account, the relative obscurity of the changes, etc.).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的优点是它简化了信息系统中每个人的工作。当然，这构成了一个**单点故障**（SPOF），如果实施应用程序出现故障，所有需要此参照信息的应用程序都将受到影响。但这只是一个技术问题，有众多经过实战检验的解决方案，例如数据库的主动/主动同步、应用服务器的扩展、硬件的冗余等。到目前为止，你也应该已经相信，功能方面始终比技术方面更重要。作为技术人员，我们倾向于关注低发生频率的问题，如硬件故障或锁定事务，而如今信息系统中的巨大问题则是数据的重复、输入的清洁度差以及其他需要紧急解决的问题。SPOF可能在人员组织方面更为重要：集中式数据参照可能意味着一个团队甚至一个人负责管理这一组数据，过多的集中化总是可能带来一些缺点（如未考虑反馈、变化的相对不透明等）。
- en: Clone architecture
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 克隆架构
- en: One way to address this SPOF limitation is to locally copy some of the data
    that is needed by important applications. In this case, some applications will
    keep part of the “flower” in their own persistence system, and it is their choice
    to manage how fresh the data should be compared to the central referential, which
    remains the global single version of the truth.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这种SPOF限制的一种方法是在本地复制一些重要应用程序所需的数据。在这种情况下，一些应用程序将在它们自己的持久化系统中保留“部分花”，并且它们有权选择如何管理数据的新鲜度与中央参照之间的比较，而中央参照仍然是全球唯一的真实版本。
- en: 'When the data is initially scattered around an information system, it can be
    a first step toward cleaning it, by obeying centralized business rules while still
    keeping the data as it was stored. The advantage is that, for legacy applications,
    nothing changes: they still consume the data locally, so all reading functions
    work as before. With some effort, writing commands can even be kept in the software
    – for example, by using database triggers that will implement a return of data
    to the unique referential. Most of the time, though, and particularly if the application
    is composable and has a unique graphical interface to create entities, it is easier
    to plug the referential GUI into this application instead of the legacy form.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据最初散布在信息系统周围时，通过遵守集中式业务规则同时保持数据存储的原样，这可以成为清理数据的第一步。其优势在于，对于遗留应用程序，没有任何变化：它们仍然在本地消耗数据，因此所有读取功能都像以前一样工作。经过一些努力，写入命令甚至可以保留在软件中——例如，通过使用数据库触发器来实现数据返回到唯一参照。然而，大多数情况下，尤其是如果应用程序是可组合的并且具有创建实体的唯一图形界面，将参照性GUI插入到该应用程序中而不是遗留形式会更简单。
- en: 'The main difficulty with this approach is consistency: as there are several
    copies of data in the system, discrepancies can happen and it is thus important
    to keep them as reduced in time and impact as possible. If applications are well
    separated in function silos, it can end up being very easy, but if the way the
    application has been decomposed is bad, then you may have to implement distributed
    transactions, which can be quite complicated. Eventual consistency will be your
    friend in this situation, but it may not be applicable everywhere.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要困难在于一致性：由于系统中存在多个数据副本，可能会出现差异，因此尽可能减少它们的时间和影响是很重要的。如果应用程序在功能隔间中很好地分离，这可能会变得非常简单，但如果应用程序分解的方式不佳，那么可能需要实现分布式事务，这可能会相当复杂。在这种情况下，最终一致性将是你的朋友，但它可能并不适用于所有地方。
- en: 'The most efficient form of the clone architecture is the following one, where
    the cloning of the data (only part of the flower, as only a partial set of the
    petals are normally useful) is synchronously based on events in the data referential
    and the data modification GUI has been replaced by the one coming from the centralized
    data-managing application:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆架构最有效形式如下，其中数据克隆（仅部分花朵，因为通常只有部分花瓣是有用的）基于数据参照中的事件，并且数据修改 GUI 已被来自集中式数据管理应用程序的
    GUI 替换：
- en: '![Figure 10.3 – Cloned data referential, the most efficient form](img/Figure_10.3_B21293.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – 克隆数据参照，最有效形式](img/Figure_10.3_B21293.jpg)'
- en: Figure 10.3 – Cloned data referential, the most efficient form
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 克隆数据参照，最有效形式
- en: An option in this form is to add a synchronization mechanism for all the data,
    which compensates at night for messages of data change that could be skipped during
    the day due to network micro-failures or such low-frequency but still existing
    incidents if one does not want to put a full-blown **message-oriented middleware**
    (**MOM**) to work for this simple stream.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种形式中，有一个选项是为所有数据添加同步机制，在夜间补偿白天由于网络微故障或此类低频但仍存在的意外事件而可能被跳过的数据更改消息，如果不想为这个简单的流使用完整的
    **消息导向中间件**（**MOM**）。
- en: 'An alternative to the first form is when the synchronization connector uses
    an asynchronous, typically time-based mechanism to keep the clone database similar
    to the referential information. The best approach in this case is to call the
    data referential APIs, as they give the best quality of information:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当同步连接器使用异步、通常是基于时间的机制来保持克隆数据库与参照信息相似时，这是一种对第一种形式的替代方案。在这种情况下，最佳做法是调用数据参照 API，因为它们提供最佳的信息质量：
- en: '![Figure 10.4 – Cloned data referential, with asynchronous alternative](img/Figure_10.4_B21293.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.4 – 克隆数据参照，使用异步替代方案](img/Figure_10.4_B21293.jpg)'
- en: Figure 10.4 – Cloned data referential, with asynchronous alternative
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 克隆数据参照，使用异步替代方案
- en: An often-seen alternative (but I really do not recommend it) is to have an ETL
    perform the synchronization, as shown in *Figure 10**.5*. This is often seen in
    companies that have invested lots of money in ETL to keep data in sync with their
    system and use this tool for everything. When there is an API (and every good
    data referential should have one), it is better to not couple ourselves directly
    on the data. Sadly, lots of companies still have this kind of stream in place,
    starting their own “spaghetti dish” of an information system, with all responsibilities
    and streams of data entangled and not clearly defined (see [*Chapter 1*](B21293_01.xhtml#_idTextAnchor014)
    for more explanation on this).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的替代方案（但我真的不推荐）是让 ETL 执行同步，如图 *图 10*.5* 所示。这在那些投入大量资金用于 ETL 以保持数据与系统同步并使用此工具做一切事情的公司中很常见。当存在
    API（每个好的数据参照都应该有一个）时，最好不要直接将我们与数据耦合。遗憾的是，许多公司仍然有这种类型的流，开始自己的“意大利面”信息系统，所有责任和数据流都纠缠在一起，定义不明确（有关更多解释，请参阅
    [*第 1 章*](B21293_01.xhtml#_idTextAnchor014)）。
- en: '![Figure 10.5 – Cloned data referential, using an ETL (not recommended)](img/Figure_10.5_B21293.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.5 – 克隆数据参照，使用 ETL（不推荐）](img/Figure_10.5_B21293.jpg)'
- en: Figure 10.5 – Cloned data referential, using an ETL (not recommended)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 克隆数据参照，使用 ETL（不推荐）
- en: 'As explained previously, some implementations cannot be changed and have to
    rely on their legacy GUI. In this case, the only possible approach is to rely
    on specific triggers on the database to get the creation and modification commands
    and send them as requests to the MDM application:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，某些实现无法更改，必须依赖其遗留 GUI。在这种情况下，唯一可能的方法是依赖于数据库上的特定触发器来获取创建和修改命令，并将它们作为请求发送到
    MDM 应用程序：
- en: '![Figure 10.6 – Cloned data referential, with legacy GUI still in place](img/Figure_10.6_B21293.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.6 – 克隆数据参照，保留原有 GUI](img/Figure_10.6_B21293.jpg)'
- en: Figure 10.6 – Cloned data referential, with legacy GUI still in place
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 克隆数据参照，保留原有 GUI
- en: The difficulty in this approach is when the data changes in the data referential
    due to some business rules, as the change cannot be sent back to the GUI. Indeed,
    most applications will keep the state of the data when they have submitted the
    change to their server. Even for the rare applications that listen to the returned
    data by their back office, the difficulty is that the complete roundtrip will
    not be finished before this reading, and the “updated” data will only be the latest
    in the local database, but not the latest that will come back moments later from
    the webhook callback. When stuck in this situation, it is best to explain to the
    users that this is a temporary situation before reaching the centralized referential
    architecture and that they can refresh their GUI a bit later to see the effects
    of their change. Even better, learn how to use the new centralized referential,
    which will always give them the freshest information, at the price of using two
    graphical interfaces instead of one (which is not such a high price when those
    are web applications that can be opened in two browser tabs).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法中的困难在于，当数据引用由于某些业务规则而发生变化时，因为这种变化无法发送回GUI。确实，大多数应用在将更改提交给服务器后，会保持数据的状态。即使是那些很少会监听其后台办公室返回数据的罕见应用，困难在于，在这次读取之前，完整的往返过程不会完成，而“更新”的数据将只是本地数据库中的最新数据，而不是随后从webhook回调返回的最新数据。当陷入这种困境时，最好向用户解释这是在达到集中引用架构之前的一种暂时情况，他们可以在稍后刷新他们的GUI以看到更改的效果。更好的是，学习如何使用新的集中引用，这始终会提供最新信息，代价是使用两个图形界面而不是一个（当这些是可以在两个浏览器标签中打开的Web应用时，这并不是一个很高的代价）。
- en: Important note
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 重要注意事项
- en: In [*Chapter 8*](B21293_08.xhtml#_idTextAnchor271), we briefly talked about
    enterprise integration patterns. They are the ideal bricks to construct the synchronization
    connectors that we talked about previously, particularly if a **message-oriented
    middleware** (**MOM**) solution is put in place during the project of information
    system reorganization/data referential structuring.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第8章*](B21293_08.xhtml#_idTextAnchor271)中，我们简要地讨论了企业集成模式。它们是我们之前讨论的理想砖块，用于构建同步连接器，尤其是在信息系统重组/数据引用结构化项目期间实施**消息导向的中介**（**MOM**）解决方案时。
- en: Consolidated and distributed architectures
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成和分布式架构
- en: 'This type of referential consists of exposing, from a central point of view
    (an API, generally), data that is actually placed into different parts of the
    information system. Generally, the core of the flower and some petals are in the
    data referential dedicated persistence. But for other petals, persistence can
    stay in the business applications they are associated with because it is considered
    they know the content of these petals better. In the most collaborative form of
    this approach, the referential exposes the full data for every actor of the information
    system and shares ownership of the petals:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这种引用类型包括从一个中心视角（通常是API）暴露数据，这些数据实际上被放置到信息系统的不同部分。通常，花朵的核心和一些花瓣位于专门用于持久化的数据引用中。但对于其他花瓣，持久化可以留在与之关联的商业应用中，因为认为它们对这些花瓣的内容了解得更深入。在这种最协作的形式中，引用暴露了信息系统中每个角色的全部数据，并共享花瓣的所有权：
- en: '![Figure 10.7 – Consolidated referential architecture](img/Figure_10.7_B21293.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7 – 集成引用架构](img/Figure_10.7_B21293.jpg)'
- en: Figure 10.7 – Consolidated referential architecture
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – 集成引用架构
- en: The data referential can produce an entire flower of data through, and expose
    it in, its API but that means it has to consume the different petals it does not
    own from the business applications (keeping a local cache of these petals is a
    choice of implementation based on freshness, rate of change, and performance but
    does not change the ownership of the data). To expose the whole flower with fresh
    content, the data referential needs to have access to its own database, and also
    to the business applications data (or, again, the cache it may keep locally).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 数据引用可以通过其API生成并暴露整个数据花朵，但这意味着它必须从它不拥有的业务应用中消费不同的花瓣（基于新鲜度、变化率和性能，保留这些花瓣的本地缓存是实施选择之一，但这并不改变数据的所有权）。为了以新鲜内容暴露整个花朵，数据引用需要访问自己的数据库，以及业务应用数据（或者，再次强调，它可能保留的本地缓存）。
- en: Also, some applications, such as `App2` in *Figure 10**.7*, may not need anything
    other than the petal they own (notice that, of course, everyone has the core of
    the flower, by definition). Some applications, such as `App1`, may need some additional
    petals, and in this case, they have to call the data referential API to obtain
    this data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些应用程序，如 *图 10.7* 中的 `App2`，可能除了它们拥有的花瓣之外不需要任何东西（请注意，当然，根据定义，每个人都拥有花朵的核心）。一些应用程序，如
    `App1`，可能需要一些额外的花瓣，在这种情况下，它们必须调用数据引用 API 来获取这些数据。
- en: 'Another difference has been made in *Figure 10**.7* to show that the data referential
    may use a business application API to obtain the data (best case) or may resort
    to direct access to the database of the business application, which causes more
    coupling but is sometimes the only way to go. The alternative shown on the right
    is dangerous and should not be applied: in this case, `App3` is not talked to
    but this is not the main problem. The actual issue is that using an ETL to feed
    the referential database should never be done, as this shortcuts the business
    and validation rules inside the data referential. No application should ever touch
    the referential database but the referential application itself. In fact, this
    rule is so important that, when deploying on-premises, it is a good practice to
    hide, obfuscate, deny access, or use any other possible way to prevent anyone
    from directly accessing a referential database. The results are already bad enough
    when this is a “normal” database, with its trail of coupling and other bad consequences;
    doing so on such an important database is the recipe for problems.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 10.7* 中，又做出了一项区别，以表明数据引用可能使用业务应用 API 来获取数据（最佳情况）或者可能求助于直接访问业务应用的数据库，这会导致更多的耦合，但有时这是唯一可行的方式。右侧显示的替代方案是危险的，不应应用：在这种情况下，`App3`
    没有被提及，但这不是主要问题。真正的问题是使用 ETL 向引用数据库提供数据永远不应该做，因为这绕过了数据引用中的业务和验证规则。没有任何应用程序应该直接接触引用数据库，而只能是引用应用程序本身。实际上，这条规则非常重要，当在本地部署时，隐藏、混淆、拒绝访问或使用任何其他可能的方式防止任何人直接访问引用数据库是一种良好的实践。当这是一个“正常”数据库时，其耦合和其它不良后果已经足够糟糕；在如此重要的数据库上这样做是问题的根源。
- en: 'When the data referential exposes all the data possible on an entity (the complete
    “flower”), the architecture is also called “consolidated.” It is possible, in
    some cases, that some bits of data are only useful by the owner application and
    will not be of any use to anyone else. In this case, the term “consolidated” is
    not appropriate as some data is – willingly – not available, and the referential
    should be considered “distributed” only. Such a situation would be schematized
    as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据引用公开了一个实体上所有可能的数据（完整的“花朵”）时，该架构也被称为“统一”。在某些情况下，某些数据可能只对拥有它的应用程序有用，而对其他人没有任何用处。在这种情况下，“统一”这个术语并不合适，因为某些数据——自愿地——不可用，并且引用应该被视为“分布式”的。这种情况可以简化如下：
- en: '![Figure 10.8 – Distributed referential architecture](img/Figure_10.8_B21293.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.8 – 分布式引用架构](img/Figure_10.8_B21293.jpg)'
- en: Figure 10.8 – Distributed referential architecture
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – 分布式引用架构
- en: The main difficulty of a distributed referential architecture is to maintain
    performance. Optimizations are of course possible, such as the cache mechanism
    we talked about or the parallelism of calls to the different business applications
    when no cache is used, but all of these technical additions come with a price
    that should not be underestimated, particularly when we know that the situation
    is temporary and that the goal is a centralized architecture. It often happens
    that a “temporary” situation, supposedly cheaper and made as a stepping stone
    to the next architecture, actually costs as much as directly putting in place
    the target architecture. Most of the time, the decision comes from the fact that
    the difficulties of the target vision are well known, but the ones associated
    with the intermediate step are less envisioned, mostly because these unstable
    situations are numerous and thus not as well documented as the final architecture.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式引用架构的主要困难在于保持性能。当然，可以进行优化，例如我们提到的缓存机制或者在没有使用缓存时对不同的业务应用的调用并行化，但所有这些技术补充都伴随着一个不应被低估的成本，尤其是当我们知道这种情况是暂时的，目标是集中式架构时。常常发生的情况是，“暂时”的情况，本应更便宜，作为通向下一个架构的垫脚石，实际上却与直接实施目标架构的成本相当。大多数时候，决策来自对目标愿景的困难有很好的了解，但对中间步骤的困难则考虑不足，主要是因为这些不稳定的情况数量众多，因此不如最终架构那样得到良好的记录。
- en: Let me give you an example of how hard it can be to set up an intermediate distributed
    system, by talking about the pagination of data. When calling the data referential
    API with a `$top=10` query attribute, if the referential is distributed and consolidates
    data from two business applications, it will have to make two requests to the
    application, but the limiting thing is that, depending on the order of the data
    requested by the `$order` attribute, there may be zero data coming from one source
    and 10 pieces from the other one, or the other way around, or any situation between
    these two extremes. This means that the gateway in charge of merging the data
    will have to take 10 lines from one application and 10 lines from the other, then
    re-apply an ordering algorithm on the 20 lines, finally sending the first 10 to
    the requesting client and discarding the following 10 lines.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我通过谈论数据的分页来给你一个例子，说明设置中间分布式系统可能有多困难。当使用 `$top=10` 查询属性调用数据引用API时，如果引用是分布式的并且从两个业务应用中整合数据，它将不得不向应用发出两个请求，但关键问题是，根据
    `$order` 属性请求的数据的顺序，可能来自一个源的数据为零而来自另一个源的数据为10条，或者相反，或者介于这两种极端之间的任何情况。这意味着负责合并数据的网关将不得不从一个应用中取出10行数据，从另一个应用中取出10行数据，然后对这20行数据重新应用排序算法，最后将前10行发送给请求客户端，并丢弃随后的10行。
- en: 'Do not think it would be easier to use a local cache, as you would have to
    implement the query mechanism on it in addition to the ordering algorithm just
    talked about. Imagine if this has to be done with more applications! With 5 business
    applications, you already cache 50 lines in order to actually use only 10, which
    is an 80% waste of resources. You may think of pre-querying the applications in
    order to know which will provide data out of the filtered values, but that means
    you should already query one application and then adjust the counting querying
    to the other ones, maybe to realize that the optimization will not reduce the
    number of queries but only the number of lines retrieved. The choice of a pivot
    application may be difficult in itself for a resulting improvement that may be
    weak since we deal with reduced sets of data anyway (this is the goal of paginating
    the requests). Wait! We have not talked yet about the worst part of it: when paginating
    for the 10th page of data (between 90 and 100, if we stay on 10-line pages), you
    will not be able to simply call 10 lines from each of the 5 applications, because
    there may be one application that will account for almost all the lines in the
    order applied since the beginning of the pagination, and some others will provide
    nothing in the same range. This means that you may very well have the first result
    coming from an application only when calling the 10th page! You now see it coming,
    don’t you? Yes, we will have to query the 5 applications for 100 lines to extract
    the 10 lines corresponding to the 90 to 100 range of the aggregated data, which
    means a huge waste of 98%… and, the cherry on this sad cake is that, if an application
    does not support dynamic range, you will have to query it several times in order
    to compose the complete range of data needed. Sure, it may be possible with some
    implementations to keep cursors on the database queries in the state, but that
    means that your application is now stateful, and this will account for some other
    technical limitations in terms of scalability. Well, the only thing that will
    save us there is that, generally, the users will stop at the second or third page
    of data, refining their `$filter` attribute to reach quicker results.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 不要认为使用本地缓存会更简单，因为你除了要实现刚才提到的排序算法外，还必须在上面实现查询机制。想象一下，如果这需要更多应用程序来完成！有5个业务应用程序，你已经缓存了50行数据，实际上只使用了10行，这造成了80%的资源浪费。你可能想到预先查询应用程序，以了解哪些会提供过滤值中的数据，但这意味着你已经开始查询一个应用程序，然后调整计数查询到其他应用程序，也许是为了实现优化不会减少查询次数，而只会减少检索的行数。选择一个枢纽应用程序本身就可能很困难，因为结果可能很微弱，因为我们无论如何都在处理减少的数据集（这是分页请求的目标）。等等！我们还没有谈到最糟糕的部分：当分页到第10页数据时（如果我们保持在每页10行的情况下，在90到100之间），你将无法简单地从每个5个应用程序中调用10行，因为可能有一个应用程序会占据从分页开始以来几乎所有的行，而其他一些应用程序在同一范围内将提供没有任何数据。这意味着你可能会在调用第10页时，第一个结果只来自一个应用程序！你现在看到了，不是吗？是的，我们将不得不查询5个应用程序以提取对应于聚合数据90到100范围的10行，这意味着98%的巨大浪费……而且，这个悲伤的蛋糕上的樱桃是，如果一个应用程序不支持动态范围，你可能需要多次查询它，以组成所需数据的完整范围。当然，在某些实现中，可能可以保持数据库查询的游标状态，但这意味着你的应用程序现在是状态化的，这将导致一些其他技术限制，例如可扩展性。好吧，唯一能救我们的是，通常，用户会在第二页或第三页数据处停止，细化他们的`$filter`属性以获得更快的结果。
- en: Consistency problems also exist, but they are a bit easier to deal with as long
    as the cutting of data follows a functionally logical order. This is generally
    the case because the distribution of data is done in business applications, so
    the risk that they have duplicate data (apart from the core of the flower, of
    course, which is always shared) is normally very low.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性问题也存在，但只要数据的切割遵循功能逻辑顺序，它们就更容易处理。这通常是这种情况，因为数据分布是在业务应用程序中完成的，所以他们有重复数据的风险（当然，除了花蕊，花蕊总是共享的）通常非常低。
- en: Other types of referential architectures
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他类型的参照架构
- en: 'A “virtual” data referential is a particular case of a “distributed” referential
    where the central part simply holds no data by itself, and thus has no persistance,
    relying on the surrounding business applications databases. Schematically, this
    is the following state:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: “虚拟”数据参照是“分布式”参照的一个特例，其中中心部分本身不持有数据，因此没有持久性，依赖于周围的业务应用程序数据库。示意图如下：
- en: '![Figure 10.9 – Virtual referential architecture](img/Figure_10.9_B21293.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图10.9 – 虚拟参照架构](img/Figure_10.9_B21293.jpg)'
- en: Figure 10.9 – Virtual referential architecture
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 – 虚拟参照架构
- en: Other, more exotic, referential architectures exist but it does not sound really
    useful to expose them here. For those of you who are curious, the French government-issued
    document called *Cadre Commun d’Architecture des Référentiels* (common framework
    for referential architectures, freely available on the internet and in the French
    language) should not be a limitation, as the different possibilities are shown
    using mainly diagrams.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 其他，更为罕见的参照架构也存在，但在这里展示它们似乎并不真正有用。对于那些好奇的人，法国政府发布的文件名为*Cadre Commun d’Architecture
    des Référentiels*（参照架构的共同框架，可在互联网和法语中免费获取）不应成为限制，因为不同的可能性主要是通过图表展示的。
- en: Now the architecture patterns have been shown, we can talk about the implementation
    itself, including what technical choices should be made and how when creating
    the data referential.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经展示了架构模式，我们可以谈论实现本身，包括在创建数据参照时应该做出哪些技术选择以及如何做出选择。
- en: Some architectural choices
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一些架构选择
- en: One of the first is, of course, the database. By the way, I should even say
    the persistence mechanism because a database is a very well-known persistence
    mechanism, but there are others, as we will see at the end of this section. Some
    other technical considerations will have to be dealt with – in particular, on
    the streams of data.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 其中之一当然是数据库。顺便说一句，我甚至应该说持久化机制，因为数据库是一个非常著名的持久化机制，但还有其他，我们将在本节末尾看到。还有一些其他技术考虑因素需要处理——特别是关于数据流。
- en: This section will also be an opportunity for a little rant about the dogmas
    in IT, and how they delay the long-awaited industrialization of information systems.
    Lots of technical choices remain based on the knowledge of the teams available
    rather than on the adequateness of the functional problem at hand. This is not
    to say that competencies should not be taken into account, but training should
    sometimes be forced on technical people who have not changed their way of thinking
    for decades and may hinder your information system development because they simply
    apply the wrong tool to the problem. You have likely heard the proverb “When all
    you have is a hammer, all problems look like nails.” If you have this kind of
    person in your team, a manager’s job is to open their eyes through training, whether
    it be internal, external, formal, or not.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 本节也将是一个机会，对IT中的教条进行一番抱怨，以及它们如何延迟了信息系统工业化的长期期待。许多技术选择仍然基于可用团队的知识，而不是当前功能问题的适宜性。这并不是说不应考虑能力，但有时应强迫那些几十年来没有改变思维方式的技术人员接受培训，因为他们可能因为简单地应用了错误工具到问题上而阻碍了信息系统的发展。你可能听说过谚语“如果你只有锤子，所有问题看起来都像钉子。”如果你团队中有这样的人，管理者的工作就是通过培训打开他们的眼界，无论是内部、外部、正式还是非正式的。
- en: Tabular versus NoSQL
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 表格式与NoSQL
- en: 'One of the very first decisions one has to make when implementing the data
    referential is the kind of database paradigm to use. Should it be tabular or document-oriented?
    SQL or NoSQL? Knowing that the natural shape of 99% of business entities is a
    document structure with many levels, like a tree of attributes and arrays with
    varying depth, the obvious choice if you want to reach business / IT alignment
    should be a NoSQL database, adapted to the shape of your data: document-based
    NoSQL if you manage business entities, or graph-based NoSQL if you manipulate
    data entities linked to other entities by many typed relationships, causing a
    network of entities that can be traversed by many paths, and so on.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施数据参照时，必须做出的第一个决定之一是选择哪种数据库范式。应该是表格式的还是面向文档的？SQL还是NoSQL？考虑到99%的商业实体自然形状是具有许多层级的文档结构，如属性树和具有不同深度的数组，如果你想要达到业务/IT的协调一致，那么显然的选择应该是一个适应你数据形状的NoSQL数据库：如果你管理的是业务实体，那么是文档型NoSQL；如果你操作的是通过许多类型关系与其他实体相连的数据实体，导致一个可以通过许多路径遍历的实体网络，那么是图型NoSQL，等等。
- en: If one really applies business/IT alignment and looks for a persistence mechanism
    that closely mimics the shape of their data, SQL tabular databases should be used
    for business entities that are naturally tabular… which is almost never! Sure,
    there are cases, just like there are some for key-value pair lists in the NoSQL
    domain, but they are very scarce. In fact, it looks like the main reason SQL is
    still largely used for the data referential is simply history. And this is a justified
    reason when dealing with legacy software… After all, if it has worked for years
    this way, you are better off not touching it. But the real problem is when a new
    data referential, designed during a project of information system modernization,
    also uses a non-efficient approach.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果真正实现了业务/IT对齐，并寻找一个与他们的数据形状紧密匹配的持久化机制，那么对于自然表格形式的业务实体，应该使用SQL表格数据库……但这几乎从未发生过！当然，有一些情况，就像在NoSQL领域中的一些键值对列表一样，但它们非常罕见。实际上，看起来SQL仍然被大量用于数据引用的主要原因仅仅是历史。当处理遗留软件时，这是一个合理的理由……毕竟，如果它以这种方式工作了多年，你最好不去碰它。但真正的问题是，在信息系统现代化项目期间设计的新数据引用也使用了非高效的方法。
- en: Why do I say *non-efficient*? The history of computer science and databases
    should be invoked in order to explain why… In the old times of data storage, when
    spin disks were used with random-access controllers, data was not randomized in
    the magnetic disks but placed in sequences of blocks (preferably on the outermost
    lines of the hard disk, as the linear speed was higher, providing for quicker
    reads). In order to quickly access the right block, database engines would force
    the size of a line of data in order to quickly jump to the next, knowing the total
    length of each line of data in advance. This is why old types of strings in the
    database required a fixed length, by the way. This is also why the data has to
    be stored in tabular blocks, and structured data decomposed into many tables where
    lines are related to each other by keys, as this was the only way to calculate
    the next block index.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我为什么说*低效*？为了解释这一点，需要回顾计算机科学和数据库的历史……在数据存储的早期，当使用随机访问控制器与旋转磁盘一起使用时，数据并没有在磁盘中随机化，而是放置在一系列的块中（最好放在硬盘的最外圈，因为线性速度更高，提供更快的读取）。为了快速访问正确的块，数据库引擎会强制数据行的尺寸，以便快速跳转到下一个，提前知道每行数据的总长度。顺便说一句，这也是为什么数据库中的旧类型字符串需要固定长度。这也是为什么数据必须以表格块的形式存储，结构化数据分解成许多表，其中行通过键相互关联，因为这是计算下一个块索引的唯一方法。
- en: 'These assumptions came with a high price, though: since data was tabular, the
    only way to store multiple values for an attribute of an entity was to create
    another table in the database and join the two lines of data. The consequence
    of this was that complicated mechanisms were necessary to handle global consistency,
    such as transactions. In turn, transactions made it necessary to create the concepts
    of pessimistic and optimistic locks, then manage isolation levels for transactions
    (as the only fully **ACID** ones, which are the serializable transactions, have
    a dramatic impact on performance), then deadlock management and so many other
    complicated things.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设虽然代价高昂：由于数据是表格形式的，存储实体属性的多个值唯一的方法是在数据库中创建另一个表并将两行数据连接起来。其结果是，需要复杂的机制来处理全局一致性，例如事务。反过来，事务使得必须创建悲观锁和乐观锁的概念，然后管理事务的隔离级别（因为唯一的完全**ACID**事务，即可序列化事务，对性能有显著影响），然后是死锁管理以及许多其他复杂的事情。
- en: 'When you think about it and realize that hard disk controllers have been providing
    randomized access for decades (and the very concept of a spinning disk does not
    exist in SSD), it is hard to understand why the consequences of this remain so
    pervasive today. One of the reasons is the change management, as nobody likes
    changing. But if there is a job where one should adapt and embrace change, that
    should definitely be a developer. I can also understand that SQL is still used
    in workshops where people only know this as a persistence technique. It is much
    better to start an important work with maybe not the best tool but one that is
    well known by the whole team, and I would not advise starting with a complex technology
    that nobody knows. But in this particular case of not using NoSQL for a business
    entity data referential, there would be two problems:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当你思考并意识到硬盘控制器已经提供了数十年的随机访问（而且旋转磁盘的概念在SSD中根本不存在），很难理解为什么这种后果在今天仍然如此普遍。其中一个原因是变更管理，因为没有人喜欢改变。但如果有工作需要适应和接受变化，那肯定应该是开发者。我也能理解为什么SQL仍然在人们只把它当作持久化技术的研讨会中使用。最好是用整个团队都熟悉的工具开始一项重要工作，我不会建议从没有人知道的复杂技术开始。但在这种特定情况下，不使用NoSQL作为业务实体数据引用，会有两个问题：
- en: First, this would be a training problem, as these technologies have been here
    for more than a decade now, and returns on experience are perfectly established,
    with trustworthy operators.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，这是一个培训问题，因为这些技术已经存在十多年了，经验回报已经确立，有可信赖的操作员。
- en: 'Second, there are actually few technologies as easy as document-based NoSQL.
    Take MongoDB, for example – writing a full-fledged JSON entity into a MongoDB-compatible
    database is as simple as follows (example in C#):'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，实际上很少有技术像文档型NoSQL那样容易。以MongoDB为例——将一个完整的JSON实体写入兼容MongoDB的数据库就像以下这样简单（C#示例）：
- en: '[PRE2]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The equivalent with an SQL-based tabular **RDBMS** (short for, **Relational
    Database Management System**) is the following:'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与基于SQL的表格型**关系型数据库管理系统（RDBMS**）（简称**关系数据库管理系统**）相对应的是以下内容：
- en: '[PRE3]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And I am not even talking about the **Data Definition Language** (**DDL**) commands
    to create the tables and columns, which would add many lines. MongoDB does not
    need any, as it is schemaless and collections are created as objects are added.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我甚至没有提到创建表和列的**数据定义语言（DDL**）命令，这将增加很多行。MongoDB不需要这些，因为它是无模式的，并且随着对象的添加，集合会创建为对象。
- en: Again, there are cases where SQL is needed. Reporting tools are very numerous
    using this grammar and it is good practice to expose SQL endpoint to access data,
    as it eases its consumption. Big data tools and even NoSQL databases have SQL
    endpoints. This is valuable as there are lots of people who are competent in using
    this way of interrogating data and computing complex aggregations. However, choosing
    a tabular database to store structured data just in order to be able to use a
    well-known query language is a problem, as it will cause lots of unwanted complexity.
    In your next data referential, please consider using NoSQL, as you will gain a
    lot of time with it. And if you know this kind of project will arrive next on
    your project portfolio, start getting training for your team. Only a few days
    are required to understand everything that is needed to be proficient with document-based
    NoSQL servers such as MongoDB, and they are extremely well adapted to storing
    business entities.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，有些情况下需要SQL。报告工具非常多，使用这种语法，公开SQL端点以访问数据是一种好习惯，因为它简化了数据的消费。大数据工具甚至NoSQL数据库都有SQL端点。这是有价值的，因为有很多人在使用这种方式查询数据并计算复杂聚合方面很在行。然而，仅仅为了能够使用众所周知的查询语言而选择表格数据库来存储结构化数据是一个问题，因为它将导致很多不必要的复杂性。在你下一个数据引用中，请考虑使用NoSQL，因为它会为你节省很多时间。如果你知道这类项目将是你下一个项目组合中的下一个，请开始为你的团队进行培训。只需要几天时间就能理解所有需要熟练掌握文档型NoSQL服务器（如MongoDB）所需的知识，而且它们非常适合存储业务实体。
- en: CQRS and event sourcing
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CQRS和事件溯源
- en: While we are at it, you may also want to ditch your old data stream architectures
    where reading and writing are handled by the same process. After all, these two
    sets of operations are so different in their frequency (most **Line Of Business**
    (**LOB**) applications have 80% of reads and 20% of writes), functions (no locks
    necessary for reading, consistency needed for writing), and performance (low importance
    for unique writing, very important for massive queries) that it sounds logical
    to separate them.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论这个问题时，你可能还想要放弃那些由同一过程处理读写操作的老旧数据流架构。毕竟，这两组操作在频率（大多数**业务线应用程序**（**LOB**）有80%的读取和20%的写入）、功能（读取不需要锁，写入需要一致性）和性能（独特的写入不太重要，大规模查询非常重要）上都有很大的不同，因此将它们分开似乎是合理的。
- en: 'This is what **Command and Query Responsibility Segregation** (**CQRS**) is
    about: it separates the storage system receiving the commands for altering or
    creating the data from the system ready to answer queries on the same data. Event
    sourcing is closely associated with this architectural approach as it stores a
    series of business events generated by writing commands and lets the queries use
    this storage to get the aggregated results they need in a highly scalable way,
    thus allowing performance on large data.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是**命令和查询责任分离**（**CQRS**）的含义：它将接收更改或创建数据命令的存储系统与准备好回答相同数据查询的系统分开。事件源与这种架构方法密切相关，因为它存储了一系列由写入命令生成的业务事件，并允许查询以高度可扩展的方式使用此存储来获取所需的聚合结果，从而允许在大数据上实现性能。
- en: In some way, CQRS could be thought of as a type of referential architecture
    between the distributed and the clone approaches. It does not separate data between
    applications with a criterion that is on the data itself, but rather on the kind
    of operation that is going to be performed on it (mainly, write or different kinds
    of reads). At the same time, the prepared reading servers can be considered as
    clones of the *single version of the truth* data. As their number can rise without
    any limit since the single version of the truth is in the main persistence, the
    performance can always be adjusted, however complex the queries and with high
    volumes as well.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在某种程度上，CQRS可以被看作是分布式和克隆方法之间的一种参考架构。它不是根据数据本身的标准来分离应用程序之间的数据，而是根据将要对其执行的操作类型（主要是写入或不同类型的读取）。同时，准备好的读取服务器可以被认为是“单一版本的真实数据”的克隆。由于单一版本的真实数据主要在持久化中，它们的数量可以无限增加，因此性能总是可以调整，无论查询多么复杂，以及数据量有多大。
- en: Again, this is not the place to discuss these subjects in detail but they had
    to be cited in a chapter about data referential and MDM, as they are the indisputable
    best approach to implementing high-volume solutions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这不是详细讨论这些主题的地方，但它们必须在关于数据参考和MDM的章节中被引用，因为它们是实现高容量解决方案无可争议的最佳方法。
- en: One more step beyond databases – storing in memory
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超越数据库的又一步——存储在内存中
- en: Let’s come back to our discussion about the origin of the tabular database system
    and even a bit before. Why do we actually need database and storage systems? Mostly
    because hard disks can store more data than only RAM, and because databases would
    not fit in small amounts of RAM. Thus, it is necessary to have a system that is
    good at quickly putting data on disk (in order to keep it safe in case of hardware
    failure, the database first writes in the log files) and good at retrieving some
    parts of data from the disk and putting them back into memory for application
    use (this is the SQL part and, in particular, the role of the `SELECT` and `WHERE`
    keywords).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到关于表格数据库系统起源的讨论，甚至更早一些。我们为什么实际上需要数据库和存储系统？主要是因为硬盘可以存储比RAM更多的数据，而且数据库无法适应少量的RAM。因此，需要一个能够快速将数据写入磁盘（以便在硬件故障的情况下保持数据安全，数据库首先写入日志文件）并擅长从磁盘检索部分数据并将其放回内存以供应用程序使用的系统（这就是SQL部分，特别是`SELECT`和`WHERE`关键字的作用）。
- en: Of course, this was a major problem when computers had 640 kilobytes of RAM
    and databases would need a few megabytes. But how about today? Sure, there are
    huge databases, but we commonly have databases with a few gigabytes only. And
    how about server RAM? Well, it is very common to have servers with tens of gigabytes,
    and it is easy to acquire online servers with 192 GB RAM. In this case, why is
    there a need for manipulating data in and out of the disks? Sure, SSD disks are
    some kind of memory, but they are still slower than RAM. Also, there is indeed
    this persistence under hardware failure that has to be taken care of. But how
    about the manipulation of data itself? Would the manipulation of queries into
    RAM not go much quicker?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，当计算机只有640千字节RAM，数据库需要几个兆字节时，这是一个主要问题。但今天呢？当然，有巨大的数据库，但我们通常只有几个吉字节大小的数据库。至于服务器RAM呢？嗯，拥有数十吉字节的服务器非常普遍，而且很容易在线获得192
    GB RAM的服务器。在这种情况下，为什么还需要在磁盘内外操作数据呢？当然，SSD磁盘是一种内存，但它们仍然比RAM慢。此外，确实需要处理硬件故障下的持久性问题。但数据操作本身怎么办？将查询操作到RAM中不是会更快吗？
- en: 'In fact, it does and there is a rarely-used and scarcely-known technique called
    “object prevalence” that acts as an in-memory database. We are not talking about
    files stored in a RAM disk or a high-speed SSD, but having the data used directly
    in the object-oriented model of your application. How can we be sure not to lose
    any data if there is a hardware failure, you might ask? Well, exactly as a database
    does: by keeping a disk-based log of all the commands sent to the system. The
    difference then is that the reference model for manipulating data and extracting,
    filtering, and aggregating results is not on some tabular writing on the disk
    that has to be accompanied with indexes in order to improve performance, but directly
    in the RAM, and in a binary format that is the one directly used by your application,
    which means nothing can go faster. By doing so, requests in SQL are replaced by
    code in your language of choice – for example, C# with LINQ queries.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，确实如此，并且存在一种很少使用且鲜为人知的技巧，称为“对象普遍性”，它充当内存数据库。我们不是在谈论存储在RAM磁盘或高速SSD上的文件，而是在应用的对象模型中直接使用数据。你可能会问，如果发生硬件故障，我们如何确保不丢失任何数据？嗯，正好像数据库一样：通过记录发送到系统的所有命令的基于磁盘的日志。那么区别在于，操作数据和提取、过滤和汇总结果的数据参考模型不是在磁盘上的某些表格上，而需要伴随索引以提高性能，而是在RAM中，并且是以二进制格式存在的，这是直接由你的应用程序使用的，这意味着没有什么能更快。通过这样做，SQL中的请求被你选择的语言中的代码所取代——例如，使用LINQ查询的C#。
- en: 'It is quite astonishing that object prevalence has never reached a wider audience
    but all the people I know who used it were convinced of its high value. Personally,
    when I need to implement a data referential that is limited in volume but has
    one of the following requirements, I always go for this technology:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，对象普遍性从未达到更广泛的受众，但我所知道的所有使用过它的人都对其高价值深信不疑。就我个人而言，当我需要实现一个体积有限但具有以下要求的数据参考时，我总是选择这项技术：
- en: High performance required
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要高性能
- en: Very complex queries that would be hard to write in SQL
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常复杂的查询，这些查询在SQL中很难编写
- en: A data model that evolves often
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个经常演变的数据模型
- en: One of the best data referential implementations that I have participated in
    was on a project calculating advanced financial simulations and optimizing them
    with genetic algorithms; the performance boost was huge and the ability to write
    extremely complex cases of data manipulations made the whole project a clear win
    for the customer, who was surprised in the first test drives by the sheer velocity
    of the simulations – the old platform this one replaced provided results in minutes,
    whereas the new one responded in no more than a few seconds.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我参与过的最好的数据参考实现之一是在一个项目中，该项目计算高级金融模拟并使用遗传算法进行优化；性能提升巨大，能够编写极其复杂的数据操作案例使得整个项目对客户来说是一个明显的胜利，客户在第一次测试中就被模拟的速度所震惊——这个取代了旧平台的新平台只需几秒钟就能给出结果，而旧平台则需要几分钟。
- en: Another example of a successful implementation was in the handling of low-moving
    data such as country codes. In this particular example, people were not feeling
    great with the in-memory approach, even though data is safe in logs on the disk
    (and we even had a backup, as a third set of data for improved reassurance). So,
    testing this quite innovative approach with some data that they could easily feed
    back into the data referential made it more comfortable for a first try of the
    technology. The test went well, but the customer did not expand it to other data.
    Sadly, I do not know more examples of uses of this technology, which is a bit
    sad as the potential was huge.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个成功的实施例子是在处理低流动数据，如国家代码。在这个特定的例子中，人们对内存方法并不感到满意，尽管数据在磁盘上的日志中是安全的（我们甚至有备份，作为第三组数据以提高可靠性）。因此，用他们可以轻松反馈到数据参照中的某些数据测试这个相当创新的方法，使得第一次尝试这项技术更加舒适。测试进行得很顺利，但客户并没有将其扩展到其他数据。遗憾的是，我不知道更多关于这项技术使用的例子，这有点令人遗憾，因为潜力是巨大的。
- en: 'Though this example may not be the best as this technology did not hit it off,
    the message still remains: in order to respect business/IT alignment, which is
    the best way to ensure long-term evolution, always favor a technology that closely
    fits your business needs and data shape.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个例子可能不是最好的，因为这项技术并没有取得成功，但信息仍然存在：为了尊重业务/IT的协同，这是确保长期发展的最佳方式，始终优先考虑与您的业务需求和数据形状紧密匹配的技术。
- en: In the last section of the book, we are going to talk again about time and how
    it influences what we do with data referential, in our case.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的最后部分，我们将再次讨论时间以及它如何影响我们对数据参照的处理，在我们的案例中。
- en: Patterns of data evolution in time
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据随时间演变的模式
- en: In [*Chapter 4*](B21293_04.xhtml#_idTextAnchor121), we studied the importance
    of time management in information systems, and one of the major impacts of time
    handling is on data. Data handled in MDM systems must be taken into account with
    the time factor, and we talked abundantly about data history management. But the
    very act of MDM should also be done according to time.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第四章*](B21293_04.xhtml#_idTextAnchor121)中，我们研究了在信息系统中对时间管理的重要性，以及时间处理对数据的主要影响。在MDM系统中处理的数据必须考虑时间因素，我们广泛地讨论了数据历史管理。但MDM本身的行为也应该根据时间来执行。
- en: Data governance
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据治理
- en: '**Data governance** is the act of establishing functional responsibilities
    around the management of data referential. Who is responsible for which reference
    data? Who can manipulate and clean the data? Who decides the evolution of the
    model? How are impacted teams and applications informed about changes? What business
    rules should be followed when manipulating the data? When should data be erased
    or archived? Those all are governance questions and they are always related to
    time. In particular, the responses have to be reviewed at regular periods, just
    like business processes, in order for the data to remain under control.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据治理**是围绕数据参照管理建立功能责任的行为。谁负责哪些参照数据？谁可以操作和清理数据？谁决定模型的演变？如何通知受影响的团队和应用关于变更的信息？在操作数据时应该遵循哪些业务规则？数据应该在何时被删除或存档？这些都是治理问题，并且它们始终与时间相关。特别是，这些回应必须定期审查，就像业务流程一样，以便数据保持受控。'
- en: 'Data governance is mostly handled in the second layer of the Cigref map, which
    is the business capability map and usually contains a zone dedicated to reference
    data management. This is where you should draw the different data referentials,
    and store the detailed definition of the entities that are stored, along with
    the versions to prove compatibility between them or document incompatible changes.
    Here, you should also find at least the name and contact of two of the main data
    governance roles:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理主要在Cigref地图的第二层处理，即业务能力地图，通常包含一个专门用于参照数据管理的区域。这就是您应该绘制不同的数据参照，并存储存储的实体的详细定义，以及版本以证明它们之间的兼容性或记录不兼容的变更。在这里，您至少应该找到两个主要数据治理角色的名称和联系方式：
- en: '**The data owner**: This person is ultimately responsible for the quality and
    usability of the data inside the information system. They define all the business
    rules around the data: how it must be manipulated, who can access it, in which
    conditions, and so on.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据所有者**：此人是信息系统内数据质量和可用性的最终责任人。他们定义围绕数据的所有业务规则：数据必须如何操作，谁可以访问它，在什么条件下，等等。'
- en: '**The data steward**: Under the delegation of the data owner, this person is
    responsible for the daily maintenance of the data. Following data manipulation
    rules issued by the data owner, they clean data and ensure its availability and
    integrity, as well as the respect for authorization rules.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据管理员**：在数据所有者的委托下，此人是负责数据的日常维护。他们根据数据所有者发布的数据操作规则，清理数据并确保其可用性和完整性，以及遵守授权规则。'
- en: One of the obvious consequences of having data governance is that there is a
    clear responsibility for a given data referential. Having shared responsibility
    for a referential is a problem because there can be competing needs that evolve
    in an uncontrolled evolution of the entity’s format or the services provided.
    In the worst case scenario, the IT team does not know who to consider as the decider
    and implements both demands, making the data referential progressively harder
    to use and not fit for its purpose. Having no responsibility is even worse because,
    as the implementation belongs to the IT team, the technical people become, by
    default, the owners of the data, which may be the worst move ever as they do not
    have the best knowledge of the business stakes associated with the data. Sure,
    they basically know what the data is about (after all, we all know in a company
    what a customer is or a product) but again, the devil lies in the details, and
    when the IT team is in charge of defining data, no one should act surprised that
    organizations only support one address, or that there is no distinction between
    a product and an article. Such mistakes would never be made by a specialist in
    the subject, and we all know how destructive a bad entity definition can be. So
    leaving such business-driven decisions to the IT team because nobody wants to
    take ownership is a risky move and everyone should be warned about this.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理的一个明显后果是，对于特定的数据参照有明确的职责。对于参照的共有责任是一个问题，因为可能会有竞争性的需求，这些需求在实体格式或提供的服务的不受控制的演变中发展。在最坏的情况下，IT团队不知道该考虑谁作为决策者，并实施两个需求，使得数据参照越来越难以使用，并且不适合其目的。没有责任甚至更糟，因为实施属于IT团队，技术人员默认成为数据的所有者，这可能是有史以来最糟糕的举动，因为他们对与数据相关的业务风险了解得最差。当然，他们基本上知道数据是什么（毕竟，我们都在公司里知道客户或产品是什么）但同样，魔鬼在于细节，当IT团队负责定义数据时，没有人应该对组织只支持一个地址或产品与商品之间没有区别感到惊讶。这种错误永远不会由该领域的专家犯下，我们都知道一个糟糕的实体定义可以有多具破坏性。因此，由于没有人愿意承担责任，将这样的业务驱动决策留给IT团队是一个风险举动，每个人都应该对此保持警惕。
- en: Progressive implementation of a unique referential
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逐步实施独特的参照
- en: When presenting the distributed and consolidated data referential architectures,
    it has been stated that, sometimes, these intermediary steps toward a centralized
    referential (which, most of the time, is the ultimate goal) can cost as much as
    directly going to the target state because of hidden efforts or lesser-known shortcomings.
    On the contrary, there are times when directly addressing the final vision is
    impossible, and convergence toward this should be done in several progressive
    steps. This might be because the information system is so coupled that a violent
    move may destroy it; most of the time, the problem is with the human capacity
    to embrace change, and a progressive approach has to be followed for the organization
    itself to be able to adjust.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在展示分布式和合并的数据参照架构时，已经指出，有时，这些走向集中参照（通常，这是最终目标）的中间步骤可能花费与直接进入目标状态一样多的时间，因为隐藏的努力或不太为人所知的缺点。相反，有时直接面对最终愿景是不可能的，而应该通过几个逐步步骤来实现这种收敛。这可能是由于信息系统耦合得太紧密，剧烈的变动可能会破坏它；大多数时候，问题在于人类接受变化的能力，而必须采取逐步的方法，以便组织本身能够调整。
- en: This has been the case for me in many situations where I consulted for companies
    who, in order to successfully manage their merger or acquisition of another company,
    needed to apply a merging program to the two information systems, incorporating
    them into a single system. This kind of thing generally takes years in big organizations
    (the quickest that I have ever witnessed was done in less than 18 months, but
    all flags were green, which rarely happens). As you will see in the following
    sections, these plans need numerous steps to be realized.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我作为顾问为那些需要成功管理他们的合并或收购其他公司的公司提供服务时，这种情况就发生了。为了成功管理合并或收购，他们需要将合并计划应用于两个信息系统，将它们合并为一个单一的系统。这类事情在大组织中通常需要数年（我见证的最快的是在不到18个月内完成的，但所有标志都是绿色的，这种情况很少发生）。正如您将在以下部分中看到的，这些计划需要许多步骤才能实现。
- en: 'For privacy reasons, I will show a mix of two progressive transformations that
    I designed for a public customer (a fusion of two regional councils in France)
    and an agriculture cooperative that was born out of the merger of two giant entities
    in the West of France. Both of them needed to address the MDM of the individuals
    and legal entities that their information systems deal with (customers, agents,
    prospects, farmers, students, etc.). In order to simplify the diagrams, I will
    consider the starting point to be where the two entities each had a consolidated
    data referential, with some applications showing a clone referential pattern.
    This often happens when there are many applications needing referential data:
    the most important are directly plugged into the highest-level data referential
    application, and the secondary applications are simply cloning what happens in
    their leading business application. In the following schema, I have also highly
    reduced the number of applications, again, for simplification reasons. I have
    not drawn the relationships between them and with other software in the information
    system, as they were mostly ERPs with much interoperability.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 由于隐私原因，我将展示我为一个公共客户（法国两个地区委员会的融合）和一个由法国西部两个大型实体合并而成的农业合作社设计的两种渐进式转换的混合。他们都需要解决他们的信息系统处理（客户、代理商、潜在客户、农民、学生等）的个人和法律实体的MDM。为了简化图表，我将考虑起点是两个实体各自都有一个综合数据参照，一些应用程序显示出克隆参照模式。这种情况通常发生在有许多需要参照数据的应用程序时：最重要的是直接连接到最高级的数据参照应用程序，而次要应用程序只是简单地克隆其主导业务应用程序中的内容。在以下方案中，我也大大减少了应用程序的数量，再次，出于简化的原因。我没有绘制它们与其他信息系统软件之间的关系，因为它们大多是具有高度互操作性的ERP系统。
- en: Step 1 – same infrastructure but no link
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第1步 – 相同的基础设施但没有链接
- en: 'All this being said, the first step can be schematized as this:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，第一步可以概括如下：
- en: '![Figure 10.10 – Fusion of two MDM systems – step 1](img/Figure_10.10_B21293.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图10.10 – 两个MDM系统的融合 – 第1步](img/Figure_10.10_B21293.jpg)'
- en: Figure 10.10 – Fusion of two MDM systems – step 1
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 – 两个MDM系统的融合 – 第1步
- en: The two companies have completely separate MDM systems, hence data referential
    for their “actors,” if this is the name we should use to describe the entities
    at play. Notice that most applications are different in each case, except for
    `App1`, which is a common ERP between the two companies (this does not mean it
    will be compatible, as versions may differ and customization definitely will,
    but this can make a good candidate to put things in common at some point). The
    very first step is, of course, to connect the two internal networks, even if everything
    that will be shown next could very well be applied by only communicating through
    the Internet.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这两家公司拥有完全独立的MDM系统，因此对于他们的“演员”，如果这是我们应该用来描述这些实体的名称，那么数据参照就是这样的。请注意，大多数应用程序在每个案例中都是不同的，除了`App1`，这是两家公司之间的一个共同ERP（这并不意味着它们将是兼容的，因为版本可能不同，定制肯定会有，但这可以成为一个很好的候选，以便在某些时候将事物放在共同之处）。当然，第一步是连接两个内部网络，即使接下来将要展示的所有内容完全可以仅通过互联网通信来实现。
- en: Step 2 – providing a common interface
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第2步 – 提供一个公共接口
- en: 'The second step was to provide all users in the new fusion entity with an API
    to read actors:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是为新融合实体的所有用户提供一个API来读取演员：
- en: '![Figure 10.11 – Fusion of two MDM systems – step 2](img/Figure_10.11_B21293.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图10.11 – 两个MDM系统的融合 – 第2步](img/Figure_10.11_B21293.jpg)'
- en: Figure 10.11 – Fusion of two MDM systems – step 2
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 – 两个MDM系统的融合 – 第2步
- en: 'Notice how symmetrical the diagram is: choosing a neutral pivotal format was
    of utmost importance, as using the proprietary format of one of the companies
    would have been a clear disadvantage to the other one (which would have to change
    all its connectors and mapping code) and this would have caused human problems,
    as tensions are always exacerbated during company fusions, particularly when they
    were previously competitors. We thus spent a lot of time crafting a nice pivotal
    format for the users, using the best data representations coming from both sides.
    At this step, not only is reading the sole operation available but no company
    can read the other’s data! You might wonder how useful this step is since the
    goal is to reach a unique MDM system for both companies and, for now, it does
    not change anything. In fact, it is indeed harder for no functional effect, but
    preparing a common pivotal format is the basis for adequately sharing data. Also,
    it provides a way for all new software functions that would be created during
    the fusion process to read actors in a standardized, fusion-ready way. This means
    we will not have to come back to these new applications, and this is much-appreciated
    news when you know hundreds of applications have to be dealt with in the whole
    project. Finally, it started the work on the mediation connectors (there again,
    this is the kind of thing that is best implemented in Apache Camel, or another
    flavor of enterprise integration patterns), which was an important piece of work,
    better started early in the project.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这个图是如何对称的：选择一个中立的中心格式至关重要，因为使用其中一家公司的专有格式将对另一家公司（它将不得不更改所有连接器和映射代码）造成明显的劣势，这还会引起人为问题，因为在公司合并期间，尤其是当它们之前是竞争对手时，紧张局势总是加剧的。因此，我们花了很多时间为用户制作了一个漂亮的中心格式，使用了来自两边的最佳数据表示。在这一步，不仅读取是唯一可用的操作，而且没有任何一家公司可以读取另一家的数据！你可能会想知道这一步有多有用，因为目标是达到两家公司都有的唯一MDM系统，而现在它并没有改变任何事情。事实上，没有功能性效果确实更难，但准备一个共同的中心格式是适当共享数据的基础。此外，它为在融合过程中创建的所有新软件功能以标准化的、融合就绪的方式读取参与者提供了一种方法。这意味着我们不必回到这些新应用，当你知道整个项目中要处理数百个应用时，这是一个非常受欢迎的消息。最后，它开始了中介连接器的工作（同样，这是最好在Apache
    Camel或另一种企业集成模式中实现的事情），这是一项重要的工作，最好在项目早期开始。
- en: Step 3 – merging data from the secondary source with the primary
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3步 – 将次要来源的数据与主要来源合并
- en: 'From now on, we will only represent the difference in streams from the point
    of view of company A, but the opposite is always true. The next step was to start
    obtaining some data from one information system and transferring it to the other.
    Again, this was very progressive: it was only done for the reading operations
    of the data for now and, as shown in the following diagram, the data was first
    read on the system of the person initiating the request, and then only completed
    with data “from the other side of the barrier.” At any time, the data from the
    originating side would win, except if the date of modification clearly showed
    that the data coming from the other information system was fresher.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在起，我们将只从公司A的角度来表示流之间的差异，但情况总是相反。下一步是开始从信息系统之一获取一些数据并将其传输到另一个系统中。这同样是非常进步的：目前只针对数据的读取操作进行了操作，如图所示，数据首先在发起请求的人的系统上读取，然后仅使用“来自屏障另一侧”的数据来完成。在任何时候，原始侧的数据都会获胜，除非修改日期清楚地表明来自另一个信息系统的数据更新。
- en: '![Figure 10.12 – Fusion of two MDM systems – step 3](img/Figure_10.12_B21293.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图10.12 – 两个MDM系统的融合 – 第3步](img/Figure_10.12_B21293.jpg)'
- en: Figure 10.12 – Fusion of two MDM systems – step 3
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12 – 两个MDM系统的融合 – 第3步
- en: For this previous step to work, it was necessary to find a way to look for similar
    actors, for example, with their VAT number or other business identifiers.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使前面的步骤工作，有必要找到一种方法来寻找类似的角色，例如，使用他们的增值税号或其他商业标识符。
- en: Step 4 – storing identifiers from the other source
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第4步 – 存储来自另一来源的标识符
- en: 'Since this is a complex operation to realize, once the correspondence was found,
    the technical identifier from one side was stored in the other, and vice versa,
    which will allow for quicker access next time. This was the first time the system
    would write in the MDM system, but this was limited to storing the identifier
    from the other side:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个复杂的操作来实现，一旦找到了对应关系，一方的技术标识符被存储在另一方，反之亦然，这将允许下次更快地访问。这是系统第一次在 MDM 系统中写入，但仅限于存储另一方的标识符：
- en: '![Figure 10.13 – Fusion of two MDM systems – step 4](img/Figure_10.13_B21293.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.13 – 两个 MDM 系统的融合 – 第 4 步](img/Figure_10.13_B21293.jpg)'
- en: Figure 10.13 – Fusion of two MDM systems – step 4
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.13 – 两个 MDM 系统的融合 – 第 4 步
- en: However, this opened up an entirely new approach to sharing data because, once
    the *write* authorizations were provided and the “external” identifier known,
    each side was able to share information with the other side.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这开辟了共享数据的新方法，因为一旦提供了“写入”授权并且知道了“外部”标识符，每一方都能够与另一方共享信息。
- en: Step 5 – sending information to the other side
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 5 步 – 向另一侧发送信息
- en: 'Every time there was a change in the actor on one side, the other was informed.
    The receiving information system was free to deal with this information at its
    own pace, maybe doing nothing with it the first time, but then choosing which
    pieces of data were interesting and storing them, and so on. At this point, keeping
    the origin of the data change was necessary in order to not start a loop of information,
    sending back to the initial information system the event that the data changed
    because of its initial event. The diagram – once again represented only from A
    to B for simplicity reasons – was as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 每当一方上的行为者发生变化时，另一方都会得到通知。接收信息系统能够自由地以自己的节奏处理这些信息，也许第一次什么也不做，但随后选择哪些数据片段是有趣的并将它们存储起来，等等。在这个阶段，保持数据变更的来源是必要的，以避免启动一个信息循环，将数据变更的事件发送回初始信息系统，因为它的初始事件。为了简化，图表再次仅从
    A 到 B 表示 – 如下所示：
- en: '![Figure 10.14 – Fusion of two MDM systems – step 5](img/Figure_10.14_B21293.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.14 – 两个 MDM 系统的融合 – 第 5 步](img/Figure_10.14_B21293.jpg)'
- en: Figure 10.14 – Fusion of two MDM systems – step 5
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.14 – 两个 MDM 系统的融合 – 第 5 步
- en: Now, since the initial write was started and information systems (and people)
    were starting to trust each other better, the next step was to generalize the
    modification of data.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于初始写入已经开始，信息系统（和人）开始更好地相互信任，下一步就是推广数据的修改。
- en: Step 6 – centralizing the writing of data and extending the perimeter
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 6 步 – 集中数据写入并扩展边界
- en: This means that both sides started to use the centralized API in writing and
    the implementation of this API was to push the data on both sides, in order for
    each information system to know about the latest data. Again, using the data depended
    on whether the receiving end knew the actor (or should record it) but, in some
    cases, data was simply ignored, for example, when this was about a change in a
    supplier that was only used in the other company. As for prospects, though, the
    data was shared because the commercial approach started to get unified between
    the two parts of the slowly emerging fusion company.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着双方开始使用集中的 API 进行写入，该 API 的实现是在双方推送数据，以便每个信息系统都能了解最新的数据。再次强调，使用数据取决于接收端是否知道行为者（或应该记录它），但在某些情况下，数据被简单地忽略，例如，当这涉及到一个只在另一家公司使用的供应商的变化时。至于潜在客户，数据是共享的，因为商业方法开始在这两个逐渐融合的公司部分之间统一。
- en: '![Figure 10.15 – Fusion of two MDM systems – step 6](img/Figure_10.15_B21293.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.15 – 两个 MDM 系统的融合 – 第 6 步](img/Figure_10.15_B21293.jpg)'
- en: Figure 10.15 – Fusion of two MDM systems – step 6
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15 – 两个 MDM 系统的融合 – 第 6 步
- en: The enterprise integration pattern used in the MOM implementation was a “duplicate
    message” one, sending the data pushed by the initial request in two similar messages
    to the mediation routes and waiting for both acknowledgment messages to come back
    in order to emit its own acknowledgment along the route it was called by, effectively
    creating a robust delivery of the change both sides.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MOM 实现中使用的企业集成模式是“重复消息”模式，将初始请求推动的数据发送到两个类似的消息中，并通过中介路由，等待两个确认消息返回，以便在其被调用的路由上发出自己的确认，从而有效地创建一个健壮的变更交付，双方都能收到。
- en: Step 7 – access unified
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 7 步 – 统一访问
- en: 'This was the time when the old data referential started to act only as gatekeepers
    for the messages, checking that they were related to their side of the information
    system. But, since actors were now largely shared, this was not such an important
    feature, so some applications started to register their actors’ messages directly
    to the top data referential:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这段时间，旧的数据参照系统开始仅作为消息的守门人，检查它们是否与其信息系统的相关部分相关。但是，由于参与者现在主要是共享的，这并不是一个特别重要的功能，因此一些应用程序开始直接将它们的参与者消息注册到顶级数据参照中：
- en: '![Figure 10.16 – Fusion of two MDM systems – step 7](img/Figure_10.16_B21293.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图10.16 – 两个MDM系统的融合 – 第7步](img/Figure_10.16_B21293.jpg)'
- en: Figure 10.16 – Fusion of two MDM systems – step 7
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16 – 两个MDM系统的融合 – 第7步
- en: '`App1` (an ERP used on both sides) was a great candidate to start this new
    approach, as the mediation connector to it could directly be shared between the
    two information systems, making for the first common deployment, thus lowering
    the height of the “barrier.” Since this approach worked quite well, it was a kickstart
    for the rest of the applications and some dedicated connectors quickly appeared
    on the other application, which was easy since the common pivotal format had then
    evolved and was easier than the previous ones, also covering more business cases.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`App1`（在双方都使用的ERP）是开始这种新方法的绝佳候选者，因为连接到它的中介连接器可以直接在两个信息系统之间共享，从而实现首次共同部署，降低“门槛”的高度。由于这种方法工作得相当好，它为其他应用程序的启动提供了动力，并且很快在另一个应用程序上出现了专门的连接器，因为共同的枢纽格式已经演变，比之前的格式更容易，也覆盖了更多的业务案例。'
- en: Step 8 – eliminating unnecessary calls
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第8步 – 消除不必要的调用
- en: 'The situation rapidly evolved to something schematized as this, where the old
    MDM system basically had nothing more to do since all data was coming from the
    new centralized one:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 情况迅速演变成如下所示的方案，因为旧的MDM系统基本上已经没有更多的事情要做，因为所有数据都来自新的集中式系统：
- en: '![Figure 10.17 – Fusion of two MDM systems – step 8](img/Figure_10.17_B21293.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图10.17 – 两个MDM系统的融合 – 第8步](img/Figure_10.17_B21293.jpg)'
- en: Figure 10.17 – Fusion of two MDM systems – step 8
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.17 – 两个MDM系统的融合 – 第8步
- en: In addition, some applications, such as `App7`, had time to evolve and were
    able to directly take some JSON-representing actors without resorting to a mediation
    connector. Also, some applications started to be used in common between the two
    organizations (which clearly appeared more and more like becoming a single organization
    at this point), and `App4` disappeared in favor of the common use of `App6`.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些应用程序，如`App7`，有足够的时间进行演变，能够直接采用一些表示参与者的JSON，而不需要借助中介连接器。还有一些应用程序开始在两个组织之间共同使用（这一点越来越明显地表明它们正在成为一个单一的组织），`App4`因`App6`的通用使用而消失。
- en: Step 9 – removing unnecessary intermediate applications
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第9步 – 移除不必要的中间应用程序
- en: 'Some “low strategy” applications remained under the control of business applications
    such as `App3`, but this was not a problem as their parent application was now
    under the main data referential and would deal with the change of format for them.
    These applications did not see any change in the system, which was great for their
    users, who were not impacted at all by the otherwise major change. The resulting
    information system started to look like the following:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一些“低策略”应用程序仍然受业务应用程序（如`App3`）的控制，但这并不是问题，因为它们的父应用程序现在位于主数据参照之下，将为他们处理格式变化。这些应用程序没有看到系统有任何变化，这对用户来说是个好消息，因为用户根本未受到其他重大变化的影响。由此产生的信息系统开始看起来如下：
- en: '![Figure 10.18 – Fusion of two MDM systems – step 9](img/Figure_10.18_B21293.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图10.18 – 两个MDM系统的融合 – 第9步](img/Figure_10.18_B21293.jpg)'
- en: Figure 10.18 – Fusion of two MDM systems – step 9
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.18 – 两个MDM系统的融合 – 第9步
- en: 'Since `App6` was used by all teams, the barrier between the two formerly separated
    companies went one more step down, reaching a point where it was not a problem,
    as it only divided some secondary business applications used in some corner cases
    by a dedicated team on activities that were not part of the fusion process. There
    was now a unique centralized MDM system, with a few important applications acting
    as local referential for actors on which secondary applications would clone some
    parts of data. This took many years in total but the objectives were reached:
    merging the actors used by both sides and doing this in such a progressive way
    that the business was never affected by technical choices.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`App6`被所有团队使用，两个原本分离的公司之间的障碍又降低了一步，达到了一个点，即它不再成为问题，因为它只分割了一些由专门团队在非融合过程中的某些特定情况下使用的次要业务应用程序。现在有一个独特的集中式MDM系统，其中一些重要应用程序作为本地参考，供次要应用程序克隆部分数据。这总共花费了许多年，但目标已经达成：合并双方使用的参与者，并以这种方式逐步进行，以至于业务从未受到技术选择的影响。
- en: Keeping an eye on dogma and useless complexity
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关注教条和无用的复杂性
- en: I hope I have convinced you in this chapter (and in this book in general) to
    keep a critical eye on technologies and practices for which their use sounds obvious.
    As with SQL databases for data referential storage, or hard disk-based data manipulation,
    there are lots of preconceived approaches in the development itself that do not
    fit the problem very well when you think purely in business/IT alignment terms.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望在这一章（以及本书整体）中已经说服你，对那些使用起来看似明显的技术和实践保持批判性的眼光。就像用于数据参考存储的SQL数据库，或基于硬盘的数据操作一样，在开发过程中有许多先入为主的观念，当纯粹从业务/IT对齐的角度思考时，这些观念并不非常适合问题。
- en: Just one example is data validation. In most programming languages, validators
    are associated with fields or properties of data entities, through attributes,
    for example, in C#. This approach is, in my opinion, very wrong and has proved
    several times in my practice to be a real pain as one will almost always find
    a particular case where these validating attributes are not correct. In the case
    of business identifiers, product owners would sometimes insist on the fact that
    no entity should ever be created without such a value, and then, within a year
    or so, realize that there is this particular case where the identifier is not
    known yet and we should still have the entity in the system. This can, for example,
    be the case with a medical patient database where the product owner will assure
    you that an entity without a social security number would make no sense as it
    is absolutely mandatory before even considering providing medication to them…
    After insisting on putting a strict `NOT NULL` validator on this for data quality
    reasons, the same person may come back a few months later, when the database is
    in production and a major impact change would have a huge cost, telling you that
    they forgot the particular case of a newborn that should be given drugs but they
    do not have a social security number yet.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 只举一个例子，就是数据验证。在大多数编程语言中，验证器与数据实体的字段或属性相关联，例如在C#中通过属性。在我看来，这种方法非常错误，在我的实践中已经多次证明这是一个真正的痛点，因为几乎总是可以找到一个特定的情况，这些验证属性是不正确的。在业务标识符的情况下，产品所有者有时会坚持认为没有任何实体应该在没有这种值的情况下创建，然后大约一年后，他们会意识到存在这样一个特定的情况，即标识符尚未知道，我们仍然应该将实体保留在系统中。例如，这可能是一个医疗患者数据库，产品所有者会向你保证，没有社会保障号码的实体在考虑提供药物之前是没有意义的，这是绝对必要的……在坚持为了数据质量原因在这个字段上放置严格的`NOT
    NULL`验证器之后，同一个人几个月后可能会回来，当数据库处于生产状态且重大影响变更将产生巨大成本时，告诉你他们忘记了新生儿的特定情况，这个新生儿应该接受药物，但他们还没有社会保障号码。
- en: In this particular example, I have personally taken the habit of never describing
    any entity attribute as mandatory, as only the context of its use makes it mandatory
    or not. And it is so easy to add a business rule or a form behavior blocking the
    `null` value that it really is not a problem to not put it on the entity itself.
    On the other hand, sorting out the mess when this mandatory characteristic has
    been implemented down the lowest levels of your information system is such a pain
    and a cause of errors that it is, in my opinion, never justified to call a field
    “mandatory” (except the one exception for a technical identifier, as there is
    otherwise no way to univocally retrieve an entity once created).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的例子中，我个人的习惯是永远不会将任何实体属性描述为强制性的，因为只有其使用的上下文才使其成为强制性的或不强制性的。添加一个阻止`null`值的业务规则或表单行为是如此简单，以至于在实体本身上不放置它根本不是问题。另一方面，当这种强制特性已经在你的信息系统最低层实现时，整理混乱和错误的原因是如此痛苦，以至于在我看来，永远不应该将字段称为“强制性的”（除了一个技术标识符的例外，否则一旦创建就无法唯一检索实体）。
- en: Important note
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: I really like it when I read articles such as [https://jonhilton.net/why-use-blazor-edit-forms/](https://jonhilton.net/why-use-blazor-edit-forms/),
    where the author questions there being “too much magic” in the technology exposed.
    Generally, there is, indeed, and such critical eyes are the best reads one can
    have on a given technology, rather than the numerous blog articles that simply
    explain how to use a function without digging into when it is useful and when
    it is actually more of a danger than a real advantage. This article really has
    a great point of view on validation included in forms and data definitions.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 当我阅读像[https://jonhilton.net/why-use-blazor-edit-forms/](https://jonhilton.net/why-use-blazor-edit-forms/)这样的文章时，我很喜欢，作者在那里质疑技术中存在“太多的魔法”。实际上，确实如此，这样的批判性眼光是阅读给定技术的最佳方式，而不是众多仅仅解释如何使用函数而不深入探讨何时有用以及何时实际上更多的是危险而不是真正优势的博客文章。这篇文章对表单和数据定义中包含的验证确实有一个很好的观点。
- en: 'The same goes for cardinalities as for the identifiers cited previously, by
    the way: if you do not have the absolute, definitive, and fully responsible engagement
    of your product owner that an attribute should be with a zero or one cardinality,
    always make it as an array with *N* cardinality. What is the worst that could
    happen? The arrays always being filled with only one item? Well, that does not
    really matter, does it? A developer complaining that, on all these occasions,
    they must type `deliveryAddresses[0]` instead of `deliveryAddress`? Show them
    how to create a property in the language they used and it will be sorted out.
    As far as the GUI is concerned, we will simply display a single piece of information
    for as long as we do not have a use case corresponding to handling several values
    in the array. Only when this new business case appears, where we need to handle
    several pieces of data, will we adjust the GUI with a list instead of a single
    text zone, for example. But the great thing about this approach is that this will
    be done smoothly, as the previously unique data will simply become the first of
    the list, and much more importantly, all the clients of the API will remain compatible
    and will not be broken by this new use. They will even be able to continue using
    only the first piece of data in the list as long as they do not want to use the
    other ones and stick to the old behavior. Since all clients and the server can
    advance at their own pace on the business change, we know we have a low coupling.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，对于之前提到的标识符，同样适用于基数：如果你没有产品所有者绝对、明确和完全负责的承诺，即一个属性应该具有零或一基数，总是将其作为一个具有*N*基数的数组。最坏的情况会是什么？数组总是只填充一个项目？嗯，这其实并不重要，对吧？开发者会抱怨，在这些场合，他们必须输入`deliveryAddresses[0]`而不是`deliveryAddress`？向他们展示如何在所使用的语言中创建属性，问题就会解决。至于GUI，我们将在没有对应处理数组中多个值的用例的情况下，简单地显示一条信息。只有当出现这个新的业务案例，我们需要处理多个数据时，我们才会调整GUI，用列表代替单个文本区域，例如。但这种方法的好处是，这将顺利地进行，因为之前唯一的数据将简单地成为列表中的第一个，更重要的是，所有API的客户端都将保持兼容性，不会因为这种新的用途而损坏。他们甚至可以在不使用其他数据的情况下继续只使用列表中的第一个数据，只要他们不想使用其他数据并坚持旧的行为。由于所有客户端和服务器都可以根据自己的步伐在业务变化上前进，我们知道我们有一个低耦合。
- en: This extends to many other technical approaches that are supposed to help the
    business but, in the end, can hinder it. To name just a last example, most of
    the technical approaches to data robustness actually go against the business concepts.
    The outbox pattern ([https://microservices.io/patterns/data/transactional-outbox.html](https://microservices.io/patterns/data/transactional-outbox.html)),
    for example, should only be used when eventual consistency is not an option. But
    when you know that even banks have always used eventual consistency (and will
    definitely go on doing so in the future), that limits the usefulness of such techniques
    quite a lot. Of course, understanding the business in depth is less fun than using
    the latest technology or pattern that will drop your rate of transaction errors
    to a bare minimum. But it is the only way to win in the long term.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点也适用于许多其他旨在帮助企业的技术方法，但最终可能会阻碍企业的发展。仅举最后一个例子，大多数关于数据鲁棒性的技术方法实际上与商业概念相悖。例如，出站模式([https://microservices.io/patterns/data/transactional-outbox.html](https://microservices.io/patterns/data/transactional-outbox.html))，只有在最终一致性不是选项时才应使用。但是，当你知道即使是银行也一直使用最终一致性（并且肯定会继续这样做），这大大限制了这些技术的实用性。当然，深入理解业务不如使用最新的技术或模式有趣，这些技术或模式可以将交易错误率降至最低。但从长远来看，这是唯一获胜的方式。
- en: So, once again, because this is such an important message, **think of the business
    functions first and then find the technology that adapts to it**. In order to
    do so, the easiest way is to imagine what would happen in the real world between
    business actors if there were no computers involved.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，再次强调，因为这是一个如此重要的信息，**首先考虑业务功能，然后找到适应它的技术**。为了做到这一点，最简单的方法是想象在没有计算机参与的情况下，业务参与者之间在现实世界中会发生什么。
- en: Summary
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, the principles of MDM have been applied and implementation
    techniques exposed, not only from the architectural point of view but also with
    technical choices that may prove useful when constructing a data referential.
    The main behaviors of such server applications have been covered and their evolution
    in time has been described with a few examples. This should make you quite knowledgeable
    about how to implement your own data referential.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，MDM的原则已被应用，实施技术已被公开，不仅从架构的角度，还包括在构建数据参照时可能有用的技术选择。这些服务器应用的主要行为已被涵盖，并通过一些示例描述了它们随时间的变化。这应该使你相当了解如何实现自己的数据参照。
- en: We will come back to the subject of MDM in [*Chapter 15*](B21293_15.xhtml#_idTextAnchor548),
    where we will go down to the lowest level of implementation, with actual lines
    of code and the design and development of two data referential implementations
    in C#, in order to deal with authors and with books, respectively. This will be
    the final piece where we will join the principles of service management and APIs
    learned about in [*Chapter 8*](B21293_08.xhtml#_idTextAnchor271), the domain-driven
    design of the entities shown in [*Chapter 9*](B21293_09.xhtml#_idTextAnchor318),
    and the architecture approaches described in the present chapter.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第15章*](B21293_15.xhtml#_idTextAnchor548)中回到MDM的主题，我们将深入到实施的最底层，使用实际的代码行以及用C#设计和开发两个数据参照实现的示例，分别处理作者和书籍。这将是我们最终要完成的部分，我们将结合在第8章中学习的服务管理和API的原则，第9章中展示的实体的领域驱动设计，以及本章中描述的架构方法。
- en: But before we reach this point, we will study the two other parts of an ideal
    information system, just like we did here for the MDM part. The next chapter is
    about business process modeling and how we can use **BPMN** (short for, **Business
    Process Modeling Notation**) and BPMN engines in order to implement business processes
    inside our information systems. Some other subjects such as middleware, no-code/low-code
    approaches, and orchestration versus choreography will be exposed in the next
    chapter as well.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们达到这一点之前，我们将研究理想信息系统中的另外两个部分，就像我们在MDM部分所做的那样。下一章将介绍业务流程建模以及我们如何使用**BPMN**（即，**业务流程建模符号**）和BPMN引擎在我们的信息系统中实现业务流程。下一章还将介绍其他一些主题，例如中间件、无代码/低代码方法以及编排与协奏曲的比较。
