- en: Chapter 5. Lightweight Concurrency – Task Parallel Library (TPL)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In .NET 4.0, Microsoft delivered what is called the **Task Parallel Library**
    (**TPL**) and answered users' concerns by developing multithreaded applications.
    TPL allows developers to focus on the functionality that they are trying to implement
    and not get bogged down with managing multiple threads, the threadpool, and the
    number of processing cores available to them.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have covered the `BackgroundWorker` component and the `Thread` class
    to show ways to accomplish multithreaded functionality in a C#/.NET application.
    These two ways to perform multithreaded functionality have been around since the
    very early stages of .NET. The `Thread` class was introduced in Version 1.1 of
    .NET and the `BackgroundWorker` in Version 2.0 of .NET. We classify these methods
    as heavyweight concurrency because they take quite a bit of work from the developer
    and add to the complexity of the code's design. The developer has to manage the
    different threads, and to achieve maximum performance, determine the number of
    processing cores in a machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'After completing this chapter you will:'
  prefs: []
  type: TYPE_NORMAL
- en: Have a complete understanding of the Task Parallel Library and the different
    classes that make it up
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand how to create and use the `Task` class
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand how tasks are managed in .NET and the threadpool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the `Parallel` class and how to start tasks using it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Know the evolution of multithreading from heavyweight to lightweight concurrency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn when to use tasks instead of `Threads`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand task parallelism versus data parallelism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand concurrent data collection and concurrent data processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Task Parallel Library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Task Parallel Library was introduced as part of .NET with the release of
    Version 4.0\. Originally, it was developed under the name Parallel Extensions,
    which was a joint effort by Microsoft Research and the CLR team. Parallel Extensions
    consisted of the TPL and **Parallel LINQ** (**PLINQ**), which we will cover in
    a later chapter. TPL is now preferred over threads and `BackgroundWorker` components
    to develop multithreaded applications.
  prefs: []
  type: TYPE_NORMAL
- en: The idea was to create a managed concurrency library to take the multithreaded
    capabilities of .NET to the next level. TPL consists of a set of APIs and public
    types located in the `System.Threading` and `System.Threading.Tasks` namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: One of the advantages of using TPL over threads is that .NET can dynamically
    scale an application to most effectively use the processing cores of the hardware
    it is running. .NET is smart enough to determine the number of processing cores
    in a machine and manage the `ThreadPool` appropriately. When programming with
    threads directly, the developer has to handle this work. No longer does the developer
    have to determine the number of cores and corresponding threads created to achieve
    maximum performance. If you remember our earlier examples with threads and `BackgroundWorker`
    components, we had to do this in code.
  prefs: []
  type: TYPE_NORMAL
- en: TPL also manages the `ThreadPool` for us. It handles scheduling of threads,
    cancelation of threads, and state management. This managed `ThreadPool` allows
    .NET to have a higher degree of intelligence in managing tasks versus threads.
    The `Task.Factory` class can be told if a task is a long running one that is not
    CPU-intensive versus a CPU-intensive task. With this information, it can be managed
    by the `ThreadPool` to create a single thread per core (CPU-intensive tasks) or
    multiple threads per core (long running tasks that wait on other resources). This
    is the logic that previously needed to be handled by the developer. Now .NET does
    it for you.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will examine the center of the TPL, the `Task` class.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Task class represents some work that can be done atomically in an asynchronous
    manner. It is an item of work executed and managed on the `ThreadPool` by the
    TPL. It is very similar to a thread but with a higher level of abstraction and
    functionality built around it. It is the central control of the Task Parallel
    Library.
  prefs: []
  type: TYPE_NORMAL
- en: The `Task` class has a complete set of methods for status updates, cancelation,
    exception handling, scheduling, and waiting that allows it to be "lightweight"
    compared to the thread. It can also make more efficient use of system resources
    given the functionality that the TPL provides to manage the `ThreadPool` behind
    the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start by creating and executing a task. First, we will create a couple
    of methods that will represent the work to be done. Then we will execute this
    work using tasks. There are two main ways to accomplish this: `Parallel.Invoke`
    and `Task.Factory.StartNew`. Let''s take a look at each. We will start with tasks
    that do not return a value. The next section will look at ways to run tasks that
    return values.'
  prefs: []
  type: TYPE_NORMAL
- en: How to do it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start by creating a new console application using Visual Studio 2013\.
    We will name our application, `TaskExample`.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will add two `using` statements to the `Program.cs` file to allow
    us to work with the TPL classes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, let''s define three different `static` methods that will represent the
    work done by three tasks: `WriteNumbers`, `WriteWords`, and `WriteColors`. One
    will loop through the first 20 numbers and write each one to the console. The
    other will loop through a sentence and write each word to the console. The final
    one will loop through an array of colors and write each color to the console.
    Now, add the following three methods to your `Program.cs` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we will add code to run each method as a task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, compile and run the application and you should see a console window that
    looks something like this:![How to do it](img/8321EN_05_01.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is a simple example, but allows you to see the three tasks run in separate
    threads with each executing a different method. You can see the thread name of
    each task and you will notice that the threads do not always run concurrently
    in sequence.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, let''s replace the code in the `Main` method with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, rebuild and run the application again. You should see an identical or almost
    identical result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
- en: The reason the results may be different is because the three methods are being
    run in three separate threads on three separate cores. So, depending on performance
    and other items running on your computer, the three tasks can run with different
    timings, as a result of which the console output can be in a different order.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous exercise, you learned two ways to use the `Task` class to implement
    functionality in a separate thread. These examples take methods that do not return
    a value and instantiate a `Task` class to execute the methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Task` constructor takes an `Action` delegate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We use a lambda expression to define the `Action` delegate, which encapsulates
    a method to be performed. Later in this chapter, we will define delegates and
    lambdas in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: First, we used the `Task.Start()` method to execute the task. This puts the
    task on the `ThreadPool` and lets .NET manage the execution of it. To instantiate
    the `Task` class, we used a lambda expression in the constructor.
  prefs: []
  type: TYPE_NORMAL
- en: In the second example, we used another class in the TPL and ran the tasks using
    the `Parallel.Invoke()` method. Here, we were able to put all three tasks on the
    `ThreadPool` at once by using this method and the `Action` class.
  prefs: []
  type: TYPE_NORMAL
- en: We use the `Console.ReadLine()` command to just hold the command window open
    after the execution of the threads has completed. This allows us to study the
    results and control the closing of the window. To close the window, simply press
    the *Enter* key; this will complete the `ReadLine` statement. The console is waiting
    to read a line of input.
  prefs: []
  type: TYPE_NORMAL
- en: Tasks with return values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will take a look at how to start a task that returns a value. In most
    cases, if we care about the result of a task or if a task does some work to be
    consumed by the rest of the program, then we will want the task to return some
    values for us to use. We will demonstrate this by developing a simple console
    application that starts three tasks and then prints the return values of these
    three tasks.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start by creating a new console application using Visual Studio 2013\.
    We will name our application, `TaskExampleWithReturnValues`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, place the following code in the `Program` class of `Program.cs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s build and run our application. Your console window should look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it](img/8321EN_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this example, we use the `Task<TResult>` version of the `Task` class, which
    allows us to specify a return object from the task when it has completed execution.
    The return value will be placed in the `Task.Result` property and will be of the
    type you define in the declaration. So, in the following line of code, we tell
    .NET to create an object of type `Task` that will execute the `WriteNumbers()`
    method and return a `String` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This is very helpful because it allows us to return any object type.
  prefs: []
  type: TYPE_NORMAL
- en: By using the line `Console.WriteLine(t1.Result);`, we automatically tell .NET
    to block or halt the main thread and wait on the `t1` task to complete and return
    the value `t1.Result`. .NET is smart enough to know that we want to wait until
    a value is present before executing this statement. Otherwise, if it is executed
    immediately, the value may or may not be there. If it was not there, we would
    get a null reference error. This is another way to say that using TPL is easier
    than using threads. The TPL API handles these details for you, the developer,
    managing it in the code itself.
  prefs: []
  type: TYPE_NORMAL
- en: Also, in each method, we set the current thread name, so in our output, we can
    see that each of the three tasks operate in a different thread.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will examine the API in TPL that allows us to use concurrent collections.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another namespace that was introduced in .NET 4.0 is `Systems.Collections.Concurrent`.
    This is not directly a part of TPL, but it is often used in conjunction with TPL
    to provide much of the common parallel design patterns such as producer-consumer
    that we will discuss in [Chapter 9](ch09.html "Chapter 9. Pipeline and Producer-consumer
    Design Patterns"), *Pipeline and Producer-consumer Design Patterns*.
  prefs: []
  type: TYPE_NORMAL
- en: '`System.Collections.Concurrent` provides a thread-safe version of collection
    classes in the `Systems.Collections` namespace. These work very well in conjunction
    with tasks. This namespace has `ConcurrentBag`, which is a collection of objects
    such as `ConcurrentDictionary`, `ConcurrentQueue`, `ConcurrentStack`, and `BlockingCollection`
    to name the most popular ones.'
  prefs: []
  type: TYPE_NORMAL
- en: All of these concurrent collections implement interfaces for the underlying
    collection. This essentially wraps the collection and provides a thread-safety
    mechanism. This is handy for the multithreaded developer because you can use them
    and not have to design thread-safe logic around them.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will look at the `ConcurrentQueue` class and show an example
    of how to use this with tasks to perform a simple multithreaded example. This
    will demonstrate the power and simplicity that TPL provides for multithreaded
    processing. We do not have to worry about locking resources to make them thread-safe.
    We do not have to worry about the number of processing cores on our hardware.
    We do not have to worry about race conditions between variables. And we do not
    have to worry about using global variables in a class to provide thread-safety.
    All of this is handled for us with the classes. We just have to worry about the
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: Having a set of thread-safe collections to be used by many threads makes multithreaded
    design easy. Notice how fewer things we have to account for than our previous
    examples. Before we divided up work, we had to know the number of cores to create
    a thread for. This is handled by `Task` and `ThreadPool` now.
  prefs: []
  type: TYPE_NORMAL
- en: We had to divide our dataset into chunks and give each thread a known chunk
    of the data (that is, in the image-processing example, each thread got a distinct
    section of the image). Also, we had to come back in the end and reassemble the
    results from each thread. We no longer have to worry about these three concerns.
  prefs: []
  type: TYPE_NORMAL
- en: In this project, we will take a list of numbers from 0 to 5000 (that is, 0 +
    1 + 2 + 3 + 4 and so on) and sum them up by three different threads. We will not
    give each thread a range to sum then add the results from the three, like before.
    We will just use a `ConcurrentQueue` collection with the 5000 numbers in queue
    and have each of the three threads remove items, sum them up, and add the sum
    to the overall total.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s open Visual Studio and create a new console application project named
    `ConcurrentCollection`; then perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Place the following code in the `Program.cs` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, let's build and run the application. What do you think the results will
    be? They should look like the following output:![How to do it](img/8321EN_05_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this program, we declare a `ConcurrentQueue` object using the following
    statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we place into the queue the numbers from 1 to 5000 using the following
    loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we start three parallel tasks that each dequeue items from the queue
    without having to lock the queue to protect thread-safety because it is a concurrent
    queue. They use the following command to take all the items out of the queue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: By using this `ConcurrentQueue` object, .NET handles all of the thread-safety
    issues and allows all three tasks to just focus on the work to be performed. They
    all then add their local sums to the `MultiThreadSum` value. But notice that this
    value needs to be locked because it is not thread-safe by default, since three
    separate tasks are all trying to add to it in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: So, in the end, no matter how the three independent tasks run, the `MultiThreadSum`
    will always be the same because each number between 1 and 5000 is taken from the
    queue only once and added to the overall sum.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the TaskFactory class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A key class of the TPL in the `System.Threading.Tasks` namespace is the `TaskFactory`
    class. `TaskFactory` is used in the creation and scheduling of tasks. The `TaskFactory`
    class has a number of methods that make scheduling and managing tasks very easy.
    These include starting and continuing methods as well as a series of methods that
    conform to the asynchronous programming model that we will cover in [Chapter 11](ch11.html
    "Chapter 11. The Asynchronous Programming Model"), *The Asynchronous Programming
    Model*. Essentially, this class wraps many of the common task design patterns
    into methods for ease of use and development. This is yet another way that TPL
    makes multithreaded development "lightweight".
  prefs: []
  type: TYPE_NORMAL
- en: Most of our work with `TaskFactory` will be covered in [Chapter 6](ch06.html
    "Chapter 6. Task-based Parallelism"), *Task-based Parallelism*, and [Chapter 7](ch07.html
    "Chapter 7. Data Parallelism"), *Data Parallelism*, and then again in [Chapter
    11](ch11.html "Chapter 11. The Asynchronous Programming Model"), *The Asynchronous
    Programming Model*. But in this chapter, we will perform a simple example to demonstrate
    how they are used.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s start by opening up Visual Studio and creating a new console application
    named `TaskFactoryExample`. Now, let''s add the following code to our `Program.cs`
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s compile and run this application. You should see results as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![How to do it](img/8321EN_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s now examine what we just accomplished and why it worked. You can see
    from the output that we ran five tasks all in different threads and then waited
    on them to complete. First, we created a static `TaskFactory` class to use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: There are several overloads for the `TaskFactory` constructor. The one we used
    just takes a `TaskScheduler` object and we chose the default. In the next section
    of this chapter, we will examine the `TaskScheduler` class in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we created and ran the five tasks using the `StartNew()` method of the
    `TaskFactory` class, as shown in the following line of code. There are many overloads
    for this method to allow you to create and start tasks according to your requirements
    and design pattern. In [Chapter 6](ch06.html "Chapter 6. Task-based Parallelism"),
    *Task-based Parallelism*, and [Chapter 7](ch07.html "Chapter 7. Data Parallelism"),
    *Data Parallelism*, we will examine more of these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a minute to look at the different parameters passed into the `StartNew()`
    method. We passed it a cancellation token, a task-creation option, and a scheduler.
    This allows a lot of the thread management of the task to be handled without having
    to manually do it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The cancellation token allows us to tell .NET if the tasks can be canceled
    or not. It also allows us to set a wait handle that is signaled if the task is
    canceled. The task creation options allow for the following settings, which give
    us a lot more control over the task than we had with the thread (referenced from
    [http://msdn.microsoft.com/en-us/library/vstudio/system.threading.tasks.taskcreationoptions](http://msdn.microsoft.com/en-us/library/vstudio/system.threading.tasks.taskcreationoptions)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![How it works](img/8321EN_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'We also passed the `TaskFactory` constructor a lambda expression for the `Action`
    object, which tells it what the task should execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we performed a `Task.WaitAll` on the list of tasks, so we had to wait
    for all of the tasks to complete. We will see in the next chapter how we can do
    this directly with the `TaskFactory` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This is a basic example of using `TaskFactory` but you can see the many benefits
    it provides and how much work is reduced for the developers as compared to using
    straight threads.
  prefs: []
  type: TYPE_NORMAL
- en: Task schedulers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main benefits of the Task Parallel Library versus developing using
    the `Thread` class is the `TaskScheduler`. This class does a lot of the logic
    that you had to program into your multithreaded code to achieve maximum performance
    and efficiency. This is what truly makes using TPL "lightweight" concurrency programming.
    The main job of the `TaskScheduler` class is to handle the work of queuing tasks
    to threads, or more specifically, the `ThreadPool`, and managing the `ThreadPool`
    to best utilize the number of processing cores on the machine it is being executed
    on.
  prefs: []
  type: TYPE_NORMAL
- en: One of the best features of the `TaskScheduler` is that it is an `abstract`
    class that you can derive your own classes from. The `TaskScheduler` allows you
    to schedule tasks on the `ThreadPool` exactly how you need if the default `TaskScheduler`
    does not meet your needs. This gives you the ultimate in flexibility and control.
  prefs: []
  type: TYPE_NORMAL
- en: Let's talk for a minute about the `ThreadPool`. The `ThreadPool` consists of
    a queue (FIFO) of work items for threads in an application domain. Tasks are put
    on this queue until a thread is available to process them. In .NET 4.0, the `ThreadPool`
    was enhanced to improve performance by essentially making the work queue a `ConcurrentQueue`
    collection object, which eliminates the need for the locking logic to make the
    queue thread-safe.
  prefs: []
  type: TYPE_NORMAL
- en: Another point to note is that tasks that are not the children of other tasks
    are put in a **global** queue, while tasks that are children of other tasks are
    put in **local** queues of the parent task. So, when a thread is finished processing
    a work item, it first looks in the task's local queue for more work before going
    to the global queue. This is another way .NET 4.0 improved the performance of
    the `ThreadPool`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are four ways that the `TaskScheduler` improves performance of
    the `ThreadPool` and removes work from the developer (referenced from [http://msdn.microsoft.com/en-us/library/dd997402(v=vs.110).aspx](http://msdn.microsoft.com/en-us/library/dd997402(v=vs.110).aspx)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Task schedulers](img/8321EN_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Introducing the Parallel class
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The last class we will touch on in this TPL primer is the `Parallel` class.
    This class will be covered in detail in [Chapter 7](ch07.html "Chapter 7. Data
    Parallelism"), *Data Parallelism*, when we discuss data parallelism; but it is
    worth an introduction here. The `Parallel` class is part of the `System.Threading.Tasks`
    namespace and provides functionality for using parallel loops. The two most used
    methods are `Parallel.For` and `Parallel.ForEach`, which allow you to loop through
    a collection and perform logic on each item of the collection concurrently.
  prefs: []
  type: TYPE_NORMAL
- en: We briefly saw it earlier in this chapter when we used the `Parallel.Invoke`
    method to run a group of tasks in parallel. But its main use is for data parallelism.
  prefs: []
  type: TYPE_NORMAL
- en: We can call the `Parallel.For` method using a named method, an anonymous method,
    or a lambda expression.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are examples of the three ways:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: In the named method version, you would need to write a method called `Method`
    that receives an integer parameter and does not return anything. Using `Parallel.For`
    causes .NET to run each iteration of the loop concurrently. Whether it does this
    or not depends on the number of processing cores and other work going on at the
    same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `Parallel.ForEach` method takes an `IEnumerable` data source and an `Action`
    delegate and iterates through the data source and calls the `Action` delegate
    on each item. It also returns a `ParallelLoopResult` object with the results for
    the processing, if there are any. The basic syntax for this is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: How to do it
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s see a simple example. Open Visual Studio, create a new console application
    named `ParallelForEach`, and perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Place the following code in the `Program.cs` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, let's compile and run the application. Your results should look like this:![How
    to do it](img/8321EN_05_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we create an `IEnumerable` collection by splitting a sentence into an
    array of strings for each word in the sentence. Then we perform a `Parallel.ForEach`
    looping on each word and simply print the word and current thread ID to the console.
  prefs: []
  type: TYPE_NORMAL
- en: Something to note here is that you see thread IDs 8, 9, 10, and 11\. There is
    a separate thread for each iteration of the loop and the thread IDs are not starting
    with 0 or 1\. Remember that the TPL uses `ThreadPool`. So, the `Action` delegate
    is queued as a separate task to the `ThreadPool` for each iteration of the list,
    which has 11 words. The `TaskScheduler` and .NET use the `ThreadPool` as efficiently
    as they can to process these queued tasks concurrently. On my particular machine,
    there are four processing cores. So, it does split the work out between four threads.
    But then, based on the rest of the work the computer is doing, thread 8 handles
    two of the tasks, thread 9 handles seven of the tasks, and thread 10 and 11 handle
    one task each.
  prefs: []
  type: TYPE_NORMAL
- en: But the thing to note here is that we did not have to manage any of this. Using
    threads directly, we would have had to interrogate the hardware and realize there
    are four processing cores. Then, break the array into four smaller arrays and
    hand each of the smaller arrays to a single thread to achieve maximum performance.
  prefs: []
  type: TYPE_NORMAL
- en: Delegates and lambda expressions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have used delegates and lambda expressions. These two concepts
    are confusing for some new developers, so let's take a moment to discuss them
    in a little more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Delegates are often used when creating event handlers. A **delegate** defines
    a reference type that encapsulates a method with a certain set of parameters and
    a return type. It functions a lot like a function pointer in C++. It allows us
    to pass a delegate object that can be used to call a method without having to
    know the method at compile time.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, the `Task` constructor takes an `Action` delegate to define
    the *action* to be performed by the task. In our example, we set the method for
    the delegate in the constructor definition, but we do not have to. We can write
    it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This way, we declare the `Action` delegate. Then we instantiate it with the
    method `WriteNumbers`, and finally, we instantiate a `Task` object with the delegate.
    Later in the code, we can always change the method the `Action` delegate uses,
    based on business logic. So, we are not bound for this task to have to execute
    the `WriteNumbers` method, every time the task is performed.
  prefs: []
  type: TYPE_NORMAL
- en: All we need to know at design time is that we want to execute a method with
    no parameters and no return type in this task. This gives us a lot of power and
    flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'A lambda expression is an anonymous function that can be used to create delegates.
    In a lambda expression, there is the lambda operator, `=>`, and the left- and
    right-hand side of this operator. The left-hand side contains any input parameters
    and the right-hand side contains the expression of the code block. Empty parentheses
    represent zero parameters. Let''s look at the following statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In this statement, we are using a lambda expression to represent the delegate
    that the `Task` constructor takes as an input: `() => WriteNumbers()`'
  prefs: []
  type: TYPE_NORMAL
- en: This lambda expression is telling us that the delegate has no input parameters(`()`)
    and that the code block for the method of the delegate is `WriteNumbers()`.
  prefs: []
  type: TYPE_NORMAL
- en: So, we can see that in the preceding examples, the `Task` constructor takes
    a delegate reference type and we use a lambda expression to define that delegate.
    By doing this, we have flexibility to change at runtime what method a task will
    execute when it is run. The only constraint at compile time is the parameters
    passed into the delegate and the return type of the delegate.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we started our journey into the Task Parallel Library and this
    will be the focus of the rest of the book. You learned about the `Task`, `Action`,
    `TaskFactory`, `Parallel`, and `TaskScheduler` classes.
  prefs: []
  type: TYPE_NORMAL
- en: You also learned what the meaning of lightweight concurrency versus heavyweight
    concurrency is, and started to see the many benefits for the developer.
  prefs: []
  type: TYPE_NORMAL
- en: The code examples in this chapter were very simple but designed to get you to
    start thinking from a TPL mindset and out of the `Thread` and `BackgroundWorker`
    mindset. Throughout the rest of this book, we will explore many more detailed
    features of the TPL classes and several common parallel design patterns and how
    they are implemented using TPL.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should already be able to see just how powerful the TPL is and how much
    of the complexity to make an application designed for concurrency it handles.
    When building a multithreaded application, there are usually four considerations
    that need to be handled by the developer that are not part of a single-threaded
    application; they are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: What pieces of functionality in the application can we process concurrently?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I manage achieving maximum performance without knowing ahead of time
    what machine it will be running on and how many processing cores it might have?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I ensure thread-safety in the data and values that overlap between threads?
    Or split the data and values to not overlap?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I manage and coordinate the different threads?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even though we have only just begun discussing TPL, you can already see how
    the last three are handled for you unlike doing concurrent programming with threads
    directly.
  prefs: []
  type: TYPE_NORMAL
- en: The first one is a design decision and, as we discuss common parallel design
    patterns, you will see that TPL helps us there as well.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's move on to [Chapter 6](ch06.html "Chapter 6. Task-based Parallelism"),
    *Task-based Parallelism*, and start to really become comfortable developing software
    using the TPL.
  prefs: []
  type: TYPE_NORMAL
