# 分布式系统的缓存策略

在上一章中，我们学习了将安全性应用于托管在网络上的应用程序的常见模式。在本章中，我们将探讨通过建立中间缓存来提高我们网络软件性能的各种方法。我们将看到使用缓存来持久化频繁访问的高可用数据如何使我们获得这些性能提升。我们将探讨缓存是什么以及它可以以各种方式被使用的各种方法。然后，我们将对网络缓存的常见且复杂的架构模式进行彻底的审查。最后，我们将演示如何在应用架构的各个级别使用缓存，以在合理的开发人员努力和延迟减少之间达到我们的目标。

本章将涵盖以下主题：

+   通过缓存常见请求的结果所能获得的潜在性能提升

+   缓存会话数据的基本模式，以实现与应用程序并行部署的可靠交互

+   了解如何在我们的 .NET Core 应用程序中利用缓存

+   各种缓存提供者的优缺点，包括分布式网络托管缓存、内存缓存和数据库缓存

# 技术要求

本章将包含示例代码，以演示我们讨论的每种缓存策略。要使用该代码，您需要您信任的 IDE（Visual Studio）或代码编辑器（Visual Studio Code）。您可以从本书的 GitHub 仓库直接下载示例代码：[https://github.com/PacktPublishing/Hands-On-Network-Programming-with-C-and-.NET-Core/tree/master/Chapter%2015](https://github.com/PacktPublishing/Hands-On-Network-Programming-with-C-and-.NET-Core/tree/master/Chapter%2015)。

查看以下视频以查看代码的实际运行情况：[http://bit.ly/2HY67CM](http://bit.ly/2HY67CM)

我们还将使用 Windows Subsystem for Linux 在本地机器上托管基于 Linux 的 Redis 缓存服务器。当然，如果您已经在运行类似 OS X 或 Linux 发行版的 *nix 系统上运行，您不必担心这一点。或者，当您在本地运行应用程序时，如果您没有管理员权限或对学习 Redis 缓存服务器不感兴趣，您可以稍微修改示例代码以使用不同的缓存提供者，您将在本章的学习过程中了解到。然而，我建议您熟悉 Redis 缓存，因为它被广泛使用，并且是大多数情况下的优秀选择。如果您选择这样做，您可以在以下链接中找到安装 Linux 子系统的说明：[https://docs.microsoft.com/en-us/windows/wsl/install-win10](https://docs.microsoft.com/en-us/windows/wsl/install-win10)

一旦完成，您可以在以下链接中找到安装和运行 Redis 的说明：[https://redislabs.com/blog/redis-on-windows-10/](https://redislabs.com/blog/redis-on-windows-10/)

# 为什么需要缓存呢？

虽然它给负责实施它的开发者带来了额外的复杂性，但一个精心设计的缓存策略可以显著提高应用程序的性能。如果你的软件严重依赖网络资源，最大限度地利用缓存可以在更快的性能上节省用户的时间，并在降低网络开销上为公司节省金钱。然而，知道何时缓存数据，何时这样做不合适，对于开发者来说并不总是直观的。那么，你何时应该利用缓存策略，为什么？

# 理想的缓存场景

假设你有一个基于季度销售数据生成报告的应用程序。想象一下，它必须从几个不同的数据库中提取数十万条记录，每个数据库的响应时间各不相同。一旦获取了所有这些数据，它必须在返回的记录上运行广泛的聚合计算，以生成报告中显示的统计数据。此外，这些报告是由数十甚至数百名不同的业务分析师在一天内生成的。大多数情况下，每个报告都会汇总相同的信息，但有些报告的结构是为了突出不同分析师不同业务关注点的数据。对这个问题的天真方法就是按需访问请求的数据，并可靠地返回结果，但响应时间极差。但这一定是必须的吗？

我刚才描述的实际上是一个设计和实施缓存策略的理想场景。我描述的是一个依赖于外部资源或过程拥有的数据的系统，这意味着往返延迟可以被消除。我还指出这是季度销售数据，这意味着它可能最多每三个月更新一次。最后，我提到有用户每天数十次甚至数百次使用这些远程访问的数据生成报告。对于一个分布式系统来说，几乎没有比在按需应用程序操作中预先缓存远程数据以实现更快和更可靠的访问更明显的情境了。

驱动缓存使用的情境不会总是那么明确，但总的来说，这三个标准将是一个强有力的指导，告诉你何时应该考虑使用缓存。但始终要问自己是否满足以下任何一个条件：

+   访问应用程序托管环境外的资源

+   访问那些更新频率不高的资源

+   访问应用程序频繁使用的资源

如果满足上述任何一种情况，你就应该开始思考通过缓存可能带来的好处。如果所有这些条件都满足，你可能需要提出一个强有力的理由来解释为什么你不应该实施缓存策略。当然，要理解为什么这些标准使缓存变得必要，你必须首先确切地了解缓存是什么，同样重要的是，它不是什么。

# 数据缓存的原则

简而言之，缓存不过是一个中间数据存储，它可以比缓存数据来源更快地提供其数据。缓存可以提供这些速度提升的原因有很多，每个原因都需要单独考虑，所以让我们看看几个例子。

# 缓存长时间运行的查询

如果你有任何正式的数据库设计经验，你很可能知道关系数据库倾向于高度规范化的设计，以消除重复数据存储，并提高稳定性和数据完整性。这种规范化将数据记录分解成具有高度原子字段定义的各种表，以及用于聚合分层数据结构的交叉引用表。如果你不熟悉这些数据库设计原则，那么可以说，它通常以牺牲记录查找的访问时间为代价，提高了空间利用率。

如果你有一个高度规范化的关系数据库，存储的信息你想以去规范化扁平记录的形式访问，表示其应用程序模型，那么用于扁平化这些记录的查询通常既耗时又冗余。在这种情况下，你可能有一个存储扁平化记录的缓存，其设计优化了你的应用程序的使用。这意味着每当需要更新记录时，去规范化数据的过程可以恰好发生一次，将扁平结构发送到你的缓存。因此，你的应用程序与底层数据存储的交互可以从对多个表的潜在大量聚合查询减少到对单个应用程序特定表的简单查找。

在这种情况下，只需为长时间运行的数据访问操作添加一个中间缓存，就可以保证性能提升，即使缓存的实际数据存储系统与原始系统相同。缓存缓解的主要性能瓶颈是查询操作本身，因此即使没有减少网络延迟，你仍然可以期待获得一些有意义的收益。

应该指出的是，这种策略可以应用于应用程序流程中的任何长时间运行的操作。我使用慢速数据库查询作为例子，因为那些是大型企业系统中最常见到的瓶颈。然而，在你的工作中，你可能发现缓存应用程序主机进程中执行的计算密集型操作的结果是有益的。在这种情况下，你可能会使用内存缓存或托管在你自己系统上的缓存，因此没有可能提高你的延迟。但想象一下，如果你的应用程序部署到按应用程序运行时间收费的云托管提供商，那么在应用程序最常用的流程中删除多秒的计算可以节省数千美元的计算成本。当你缓存系统本地的方法调用或计算的结果时，这被称为**记忆化**。

# 缓存高延迟网络请求

缓存的另一个常见动机因素是高延迟的网络请求。在这种情况下，你的软件将依赖于网络资源，但网络基础设施的某些方面使得访问该资源变得非常慢。这可能是因为你的应用程序托管在防火墙后面，而传入或传出的请求验证协议引入了高延迟。或者，这可能是由于地理位置的问题，你的应用程序服务器托管在与你最近的数据中心不同的物理区域。

无论原因如何，解决这个问题的常见方法是通过在更靠近数据存储的地方缓存结果来最小化网络延迟的影响。例如，假设问题是网关或防火墙向你的数据访问请求引入了不可接受的延迟。在这种情况下，你可以在防火墙后面建立一个缓存来消除它引入的延迟。在这种类型的缓存策略中，你的目标是存储你的缓存数据在某些主机上，这些主机引入的延迟比源主机要少。即使在你缓存中查找记录的时间不比在源主机上查找同一记录的时间快，最小化延迟仍然是目标。

# 缓存以保留状态

缓存数据的最后一种策略是促进状态管理。在云部署的应用程序架构中，你可能有用户与多个应用程序实例交互，这些实例在不同的服务器上并行运行。然而，如果他们的应用程序交互依赖于持久化任何类型的会话状态，你将需要在会话期间可能为单个请求服务的应用程序的所有实例之间共享该状态。在这种情况下，你可能会使用一个共享缓存，所有应用程序实例都可以访问并从中读取，以确定用户的请求是否依赖于由另一个实例确定的某个状态。

# 何时写入缓存

如我之前所描述的，缓存可能听起来就像是一个优化了的应用程序的数据存储副本。在某种程度上，这是真的，但技术上并不正确，因为缓存永远不应该完美地镜像其源系统。毕竟，如果你可以在一个高性能缓存中存储底层数据存储的完整副本，那么底层数据存储最初的价值在哪里呢？

相反，缓存通常只包含底层数据存储的一小部分。在大多数情况下，缓存的小尺寸对于其性能优势是必要的，因为即使是一个简单的查询也会随着查询集合的大小线性扩展。但是，如果我们的数据缓存不是源系统的完美镜像，那么我们必须确定哪些数据被包含在我们的缓存中，以及何时被包含。

# 预缓存数据

将数据写入缓存的简单而有效策略被称为**预缓存**。在一个预缓存其数据的系统中，开发者将确定哪些可能是性能最低或最频繁请求的数据访问操作，这些操作的结果在应用程序的生命周期内最不可能发生变化。一旦做出这种决定，这些操作就会执行一次，通常是在应用程序的初始化过程中，并在接收到或由应用程序处理任何请求之前将其加载到缓存中。

我之前提到的例子，涉及频繁请求的季度销售数据报告，是预缓存数据的理想场景。在这种情况下，我们可以在应用程序启动时请求销售数据并运行所有必要的统计操作以生成报告。然后，我们可以缓存应用程序服务的每种报告类型的完成视图模型。在接收到报告请求时，我们的应用程序可以可靠地查询缓存以获取视图模型，然后根据报告模板相应地填充，从而在应用程序的生命周期中节省时间和计算成本。

然而，这种方法的一个缺点是它需要同步底层数据更新与应用程序缓存的刷新。在应用程序和底层数据存储由同一团队工程师拥有和管理的情况下，这种同步是微不足道的。然而，如果数据存储由负责应用程序的不同团队拥有，协调会引入风险。一次更新同步失败可能导致向客户提供过时数据。为了减轻这种风险，你应该制定一个明确且弹性强的缓存刷新策略，并在可能的情况下自动化这项任务。

# 按需缓存写入

大多数缓存系统的实现都将设计为按需将数据写入缓存。在一个按需系统中，应用程序需要某些数据，它可以确信这些数据存储在底层数据库中。然而，在将较慢的数据访问请求发送到底层数据库之前，应用程序将首先检查缓存中是否有请求的数据。如果找到数据，就称为**缓存命中**。在缓存命中时，使用缓存条目，并且不会对数据集进行额外的调用，从而提高应用程序的性能。

在另一种情况下，当请求的数据尚未写入缓存时，应用程序会出现所谓的**缓存未命中**。在未命中时，应用程序必须对底层数据存储进行较慢的调用。然而，此时访问请求数据的成本已经付出。因此，现在应用程序可以使用为其设置的任何启发式方法来确定检索到的数据是否应该写入缓存，从而在后续请求相同数据时节省时间。

# 缓存替换策略

如果你的缓存大小固定有限，你可能会发现自己需要定义一个缓存替换策略。缓存替换策略是你确定何时用新的、可能更相关的记录替换旧记录的方法。这通常发生在应用程序遇到缓存未命中时。一旦数据被检索，应用程序将确定是否将其写入缓存。如果最终将记录写入缓存，它将需要确定要删除哪个记录。然而，问题在于很难确定一个一致的启发式方法来识别哪些记录很快就不会再被需要。

你可能在心中想到了一个看似明显的答案，仅仅通过思考就能得出；当我第一次了解到这个问题时，我也是这样。但大多数显而易见的解决方案在仔细审查时并不成立。例如，一种相当流行的替换策略涉及删除最近最少使用的记录。这仅仅意味着替换了在一系列缓存查询中未生成缓存命中的条目。然而，可能的情况是，一个记录被使用的时间越长，它被下一次使用的可能性就越大，记录的查找是按循环顺序进行的。在这种情况下，删除最近最少使用的记录会增加后续请求中另一个缓存未命中的可能性。

或者，你可以尝试使用最少使用替换策略。这将丢弃系统上所有记录中缓存命中次数最少的记录，无论这些命中发生的时间有多近。当然，这种方法的缺点是，没有考虑到最近的使用情况，你忽略了最近使用过的记录可能因为用户打算使用它进行一系列后续操作而变得相关的可能性。由于它的命中率低而被删除，并且忽略了命中的最近性，这增加了未来缓存未命中的可能性。

每种缓存替换策略都有其自身的缺点，应该在应用程序的上下文中考虑。然而，有一个关键指标可以帮助你确定替换策略的相对成功程度。一旦你的初始启发式方法设计并部署，你可以跟踪你的缓存命中率。一个缓存的命中率非常简单，就是缓存命中次数除以缓存未命中次数。这个数字越接近1.0，你的缓存替换策略就越好。

# 缓存失效

当你考虑你的缓存替换策略时，你可能会发现缓存中存储的一些信息可能只对应用程序在短时间内相关。在这种情况下，与其等待新的缓存未命中来覆盖无关数据，你可能会想要在某个超时后使条目过期。这就是所谓的**缓存失效**。简单来说，缓存失效是确定你的缓存中的记录不应再用于服务后续请求的过程。

在我描述的情况下，如果你为写入缓存中的任何给定记录有一个已知的有效期，使这些记录失效就像在写入记录时设置并执行一个过期策略一样简单。然而，在其他情况下，可能并不明显地需要使缓存记录失效。考虑一个网络浏览器缓存来自服务器的响应。如果没有预定的过期日期，浏览器无法确定缓存响应是否仍然代表服务器的当前状态，除非首先检查服务器，从而消除了缓存带来的性能优势。

由于你不应该向用户提供过时或无效的数据，你应该始终设计一些机制来使你的缓存记录无效。我刚刚讨论了两种最常见的方法，你很难找到不实施其中至少一种的理由。所以，如果你控制着缓存本身，比如在你的应用程序架构中包含的缓存，你应该始终在底层数据存储更新时勤勉地使缓存记录无效。而对于你无法控制响应被缓存的情况，确保你始终为你的响应设置合理的缓存过期时间。

到目前为止，我们已经了解了什么是缓存，为什么你可能在你的软件架构中实现一个缓存，以及你可以利用哪些策略来优化其性能。因此，现在是我们来看看现代基于云部署的网络架构中最常见的缓存策略之一的时候了。

# 分布式缓存系统

在上一节中，我讨论了使用缓存来在相同应用程序的并行部署之间保留应用程序状态的目的。这是现代基于云的架构中缓存最常见用例之一。然而，尽管这种分布式会话缓存可能非常有用，但它可能会给应用程序设计带来一系列挑战。

# 缓存友好的架构

缓存在历史上一直被用来通过减少延迟或操作时间来提高性能。然而，对于分布式架构中的会话缓存，缓存本身并不旨在对特定操作提供任何特定的性能改进。相反，它旨在促进多个应用程序实例之间必要的交互。其设计是为了促进状态管理，否则将涉及多个主机复杂的编排。为了理解这是如何实现的，让我们考虑一个例子。

假设你有一个托管在云上的API，该API负责验证用户的身份和年龄。为了做到这一点，它请求各种信息，这些信息加在一起可以用来验证用户。为了设计尽可能不干扰用户体验，你首先只问一些关于他们的出生日期和当前地址的问题，这些问题最有可能成功地验证他们的年龄和身份。一旦他们提交了答案，你的应用程序将尝试验证他们。如果成功，用户可以继续，但如果最初的问题集不成功，你的应用程序将跟进更多的问题，这些问题与第一组答案结合在一起，高度可能验证用户的身份。用户提交了答案，你再次尝试失败，最终提出一个要求用户提供社会保险号码最后四位数字的问题。提交后，用户要么成功验证，要么永久无法访问你的系统。

从业务逻辑的角度来看，这个过程相对简单，但你如何在保持网络请求之间完全无状态的网络上实现它？作为一个云托管的应用程序，你如何维护用户在流程中的当前位置，这跨越了处理给定请求的多个可能的应用服务器实例？

# 分布式缓存的案例

在这个特定情况下，有一些技术可用，每种技术都有其自身的优点和缺点。您可以使用粘性会话来强制后续请求来自特定主机在给定会话中由处理初始请求的同一应用服务器提供服务。这将在会话期间允许进行一些轻微的本地状态管理。这种方法的缺点是，它消除了云托管系统中水平扩展的性能优势。如果用户在整个会话过程中始终被迫与单个服务器交互，无论该服务器的流量如何或其他服务器的可用性如何，他们实际上就是在与单体应用架构的单实例交互。此外，您将不再坚持“无状态”服务的架构理想，因为您将实现某种机制来在您的活动服务交互过程中保留用户在工作流程中的位置。

或者，您可以使用我们在第14章“网络上的身份验证和授权”中看到的相同原则，即*自编码令牌*部分。在这种情况下，您将在服务器的响应中自行编码用户的当前状态，而您的用户将负责在后续请求中将该自编码状态返回到服务器。这允许每个请求体充当一条通往客户端首次交互的面包屑路径，服务器可以根据之前的交互重建在后续交互中创建的状态。

这种方法会增加您请求/响应模型的复杂性。它还会引入无法强制执行的验证尝试限制的风险。假设出于安全考虑，您的业务规则规定用户只能尝试每轮问题一次。如果您在请求/响应模型中自行编码用户会话的状态，您就依赖于您的用户在每次请求中返回每个先前尝试的准确表示。一个有意的恶意行为者可以通过简单地从后续请求中清除工作流程状态来随意进行尽可能多的尝试。

在这种情况下，我会认为，在请求之间维护状态的可靠解决方案是云环境中每个应用服务器共享的分布式缓存。这阻止了您在应用服务器之间维护状态，从而保留了云部署服务架构的无状态原则，同时仍然允许您的服务完全控制用户通过验证工作流程的进度。

为了实现这一点，您将需要在独立于您的云中应用程序服务器实例的服务器上托管缓存提供程序。任何成功处理工作流程中给定步骤的服务器都会拒绝完全解析交互并向客户端提供响应，除非并且直到该步骤的结果成功写回到您的数据缓存中。这样，当前的应用程序服务器实例可以执行以下操作：

+   通过确认用户在缓存中不存在该工作流程步骤的记录，验证没有其他实例已成功处理相同的请求

+   通知其他应用程序实例该步骤已被处理，以便它们停止重复事务

# 分布式缓存的好处

我所描述的系统具有确保用户状态在其与所有部署的应用程序实例交互过程中一致性的好处，只需对缓存进行少量读取和写入操作即可实现。这种数据一致性，即使在您的分布式缓存不用于状态管理时也是关键的。它可以防止多个应用程序实例尝试对同一份数据进行两个不兼容的修改，或者在将事务提交到底层数据库之前，允许跨多个应用服务器同步事务。最重要的是，从开发者的角度来看，它可以消除由服务之间的竞争条件引起的难以重现和难以追踪的bug。

独立于所有其他应用程序托管缓存服务器也为其提供了一定程度的对应用程序重启或崩溃的弹性。通过隔离您的数据存储，您可以隔离与您的云提供商提供的更高可用性和弹性保证相关的成本。这还可以帮助最小化您在应用程序服务器上运行的容器内存占用。如果您按RAM使用付费，这可以在缓存扩展时为您节省数千美元。那么，我们如何在代码中具体获得这些好处呢？

# 在代码中处理缓存

为了了解我们如何从.NET Core支持的多种缓存机制中受益，我们将设置一个相对复杂的演示应用程序结构。我们首先要做的事情是创建一个远程数据存储，它具有长时间运行的操作以返回查询结果。一旦完成，我们将设置一个依赖于该数据的应用程序，并为其提供一个缓存策略，以减轻我们人为减缓的远程数据存储的影响。

# 编写我们的后端数据系统

我们将创建我们的后端数据系统作为一个简单的Web API项目。目标是创建一个控制器，在该控制器上暴露几个端点，以展示如何将值写入我们的缓存，而不管记录之间的类型差异。首先，让我们使用.NET Core CLI创建我们的项目。让我们看看以下命令：

[PRE0]

接下来，由于我们将在缓存准备好的应用程序的同时托管此项目，我们希望配置它使用自己的端口，而不是默认设置。在你的`Program.cs`文件中，修改你的`CreateWebHostBuilder(string[] args)`方法以使用你希望此应用程序监听的任何自定义URL：

[PRE1]

然后，我们将修改`ValuesController.cs`类以提供我们的数据。首先，我们将类的名称更改为`DataController`，以便我们的路由更加直观。我们将移除所有预配置的端点，并用三个新的端点替换它们，每个端点返回唯一的数据类型。首先，让我们为我们返回的数据创建一个新的数据类型。它将是一个简单的模型，具有ID和两个任意属性；一个将是`string`类型，另一个将是`List<string>`：

[PRE2]

在这个模型设置好之后，我们可以定义我们将要公开的端点。在这个演示中，我们将返回一个简单的`List<string>`字符串，一个单独的`OutputRecord`实例，以及一个`List<OutputRecord>`方法。因此，当我们为每种数据类型定义了查找端点之后，我们将有返回简单字符串、字符串列表、复杂记录和复杂记录列表的方法。让我们看看以下代码：

[PRE3]

这些定义了我们的简单字符串响应，并且用我们的缓存进行测试将会相对简单。然而，对于我们的`OutputRecord`端点，我们希望为每个属性应用独特的数据，以便我们可以确认整个对象被正确缓存。因此，返回单个`OutputRecord`实例的端点将看起来像这样：

[PRE4]

这给我们一个具有不同属性值的对象，它们通过相同的ID连接在一起，这将使我们能够轻松验证缓存的行为。最后，我们将定义一个端点来返回`OutputRecord`实例的列表：

[PRE5]

这些端点中的每一个都返回一些带有提供ID的简单对象或字符串，这些对象用于响应对象中，但这只是区分一个响应与下一个响应的一种方式。我们响应的重要方面将是我们将应用的感知延迟。为此，我们将在返回结果之前为每个方法添加五秒钟的延迟。这将给我们一个明显的方式来识别当后端数据存储被击中时与当我们的用户界面应用程序成功缓存击中时的情况。

为了模拟这种延迟，我们将使当前线程休眠五秒钟，然后返回一个包含给定ID的任意字符串：

[PRE6]

每个额外的方法都将做同样的事情，应用延迟然后使用任意值初始化其预期的返回类型。现在，如果你运行应用程序并ping你的`/data/value/1234`端点，你应该会在五秒后看到结果返回：

![图片](img/e26b5043-1f91-4888-a09d-441220d4f5ab.png)

注意响应时间为5269ms。这个延迟将是我们未来缓存未命中的指示。并且有了我们的数据存储就绪，我们可以构建我们的应用程序并定义其缓存策略。

# 利用缓存

要开始使用我们的缓存，我们首先需要安装并运行一个Redis服务器的本地实例。Redis是一个开源的内存数据存储。它通常在企业部署中用作简单的键值数据存储或缓存。它还由Azure云托管环境直接支持，这使得它对于基于.NET的微服务和基于云的应用程序非常受欢迎。

要安装它，请遵循本章*技术要求*部分中的说明。一旦完成，你将有一个本地实例正在运行。如果你已经安装了服务器，请确保它已启动并运行，通过打开你的Windows子系统Linux界面，并输入以下命令以验证其监听端口：

![图片](img/f5d37ee1-04b1-41e7-b710-bcf809ee71b5.png)

一旦你的Redis实例运行起来，你就可以实现你的示例微服务了。由于我们将从我们的后端API加载缓存未命中，我们希望在`Startup.cs`文件中为该特定应用程序配置`HttpClient`。为此，我创建了一个静态的`Constants`类，以避免在我的代码中使用魔法字符串，并在`ConfigureServices(IServiceCollection services)`方法中使用`DATA_CLIENT`属性注册一个命名的`HttpClient`实例：

[PRE7]

接下来，我们将创建一个服务客户端来抽象我们将要进行的HTTP请求的细节，使用我们在第9章中建立的相同模式，即*.NET中的HTTP*。我们的接口定义将提供以下简单的方法：

[PRE8]

在实现此接口的类中，我们将有一个`IHttpClientFactory`的私有实例，我们将使用我们的命名`HttpClient`实例来访问我们的后端数据存储。这个常见任务被隔离到一个私有方法中，用于实际的HTTP交互：

[PRE9]

然后，每个公共接口方法都实现了这里建立的一般模式的端点特定变体：

[PRE10]

将此逻辑扩展到我们所有四种访问方法，我们将完成我们的后端数据客户端。在这个时候，我们应该修改我们的控制器以公开每个后端API端点，并使用它们来测试我们的数据访问服务。我们将公开与我们的后端API相同的同一服务合约，为每种可能查找的记录类型提供四个端点。我们不会重命名我们的文件，而是重新定义我们控制器的路由，并定义一个公共构造函数以允许依赖注入框架提供我们的`DataService`实例（只是别忘了在`Startup.cs`中注册具体的实现）。让我们看看以下代码：

[PRE11]

一旦我们有了我们的数据服务，我们就可以使用我们的API端点从我们的后端系统调用每个请求的对象：

[PRE12]

到目前为止，通过运行你的后端 API 和缓存服务 API，你应该能够从你的缓存服务请求相同的值，并且有相同的五秒延迟。所以，现在我们的应用程序已经完全连接到请求后端服务的数据，让我们通过缓存来提高其性能。

# .NET 的分布式缓存客户端

使用 Redis 作为我们的分布式缓存解决方案的主要好处之一是它由 .NET Core 默认支持。甚至还有一个针对 `IServicesCollection` 类的扩展方法，专门用于在应用程序中使用 Redis 缓存进行注册。只需为你的当前项目安装 `Microsoft.Extensions.Caching.Redis` NuGet 包，然后添加以下代码：

[PRE13]

这将自动将 `RedisCache` 类的实例注册为任何注入到你的服务中的 `IDistributedCache` 实例的具体实现。本地主机配置设置将使用 Redis 客户端本地部署的默认配置，因此除非你明确更改本地部署，否则不需要指定 IP 地址和端口。同时，`InstanceName` 字段将为由该应用程序设置的缓存条目提供应用程序特定的前缀。所以，在这个例子中，如果我用本地设置设置了一个 `1234` 键的记录，那么这个键将存储在缓存中为 `local1234`。通过 `AddDistributedRedisCache()` 方法注册的 `RedisCache` 实例将自动查找我们选项中指定的 `InstanceName` 前缀的键。我们将在稍后检查我们的缓存实例时看到这一点。

在我们的 Redis 缓存运行，并且我们的 `IDistributedCache` 实例配置并注册到我们的依赖注入容器后，我们可以编写一个 `CacheService` 类。这个类将遵循与我们的 `DataService` 类相似的模板，其中只公开少量逻辑操作作为公共方法，隐藏缓存交互的细节。我们为这个 `CacheService` 类的接口如下：

[PRE14]

在这里，我们区分了写入单个字符串和写入更复杂的记录，以区分在每个方法实现中序列化和反序列化我们条目的需求。

# 获取和设置缓存记录

`IDistributedCache` 类提供了一个简单的机制来与我们的缓存数据交互。它基于简单的 get/set 模式运行，尝试获取记录将根据给定的 ID 返回缓存的字节数组或字符串，如果不存在记录则返回 null。没有错误处理或状态检查。缓存的速度取决于这种简单的交互机制和失败状态。

同样，设置记录同样简单。只需定义记录的ID，然后提供记录的序列化表示形式以供存储。这种序列化格式可以是使用`SetString(string id, string value)`方法的字符串，或者使用`Set(string id, byte[] value)`方法的字节数组。

此外，当你向缓存写入值时，你可以为你的缓存记录设置额外的选项来指定过期时间范围。你可以应用的过期设置类型如下：

+   **绝对过期**：这将在特定的时间点设置过期，此时记录将被失效，无论它最近是否被使用。

+   **绝对过期相对于现在**：这将在记录被设置在缓存中的那一刻起，设置一个固定的时间点，无论它最近是否被使用，记录都将被失效。与绝对过期不同的是，过期时间是以记录设置在缓存中的那一刻起的一段时间长度来表示的。

+   **滑动过期**：这将在记录最后访问的时间点设置一个过期时间。因此，如果滑动过期设置为60分钟，并且记录在62分钟后没有被再次访问，它将过期。然而，如果记录在58分钟后再次被访问，过期时间将从第二次访问的那一秒重置为60分钟。

因此，让我们看看我们将如何实现这个缓存。首先，我们必须注入在`Startup.cs`类中注册的`IDistributedCache`实例：

[PRE15]

然后，我们将实现我们的接口方法。第一个方法相当直接，仅在我们缓存命中时通知我们的消费者：

[PRE16]

接下来，我们将实现我们的记录检索方法。这些方法之间的唯一区别是，检索复杂的数据类型（记录和字符串列表）将需要额外的反序列化步骤。除此之外，我们的`Fetch...()`方法应该看起来相当直接：

[PRE17]

最后，我们需要实现写入方法。为了演示，我们将使用`DistributedCacheEntryOptions`类将所有记录的滑动过期时间设置为60分钟。之后，我们可以简单地传递我们的键和序列化值（我们将使用JSON，以利用`Newtonsoft.Json`库）以及过期选项到缓存中：

[PRE18]

有了这些，我们的缓存应该已经准备好使用了。现在，是时候在我们的控制器端点中整合所有内容了。为此，每个方法的交互模式都将相同，唯一的区别是我们对缓存执行的读写操作类型。所以，让我们看看我们将如何实现我们的缓存策略：

[PRE19]

你首先会注意到，我为给定的ID添加了一个后缀，这与我的路由匹配。这是为了允许我的缓存中每个不同数据类型的重复ID。接下来，我们检查我们的`HasCacheRecord`（键）方法，以确定我们是否有一个缓存命中。如果有，我们只需获取缓存记录并返回结果。然而，当我们没有命中时，我们必须从我们的底层数据存储中获取数据。一旦我们有了它，我们就将其写入我们的缓存，以便在后续请求中更快地检索，然后返回该值。

在对每个端点进行适当的修改后应用此模式，我们就准备好进行测试了。为了确认缓存的运行行为，首先对具有新ID的任何端点运行相同的查询，连续两次。如果一切正常，你的第一次请求应该有5秒的延迟，而后续请求的延迟几乎为零。

一旦你在缓存中存储了至少一条或两条记录，你就可以在Windows Subsystem for Linux控制台中使用redis-cli观察这些值。`RedisCache`类将条目作为哈希类型存储在底层缓存中，因此你需要使用这些命令来查找键值。我在测试应用程序时查找记录的操作如下：

![](img/9584f3f5-0bfa-480a-b9dd-01b711217714.png)

第一个命令`keys *`简单地搜索所有匹配给定模式（*是通配符，所以`keys *`匹配所有键）的活跃键。然后，我使用了`hgetall [key]`命令来获取我条目哈希中的每个属性。在这个输出中，你可以清楚地看到从我应用程序写入缓存中的JSON，这证明了我的应用程序和缓存之间成功且预期的交互。

我还想指出键的结构。正如我之前提到的，我设置的键（在这种情况下，2345条记录）以`RedisCacheOptions`的`InstanceName`为前缀，我在`Startup.cs`文件中配置了`RedisCache`。通过这个输出，你已经看到了微软为与Redis缓存实例交互而建立的完整交互模式。

# 缓存提供者

尽管我们在示例代码中演示了使用`IDistributedCache`类实例的数据缓存，但这并不是.NET Core中我们所能访问的唯一缓存提供者。在我们结束缓存主题之前，我想简要讨论框架中另外两个最常见的提供者。

# SqlServerCache提供者

Redis无疑是工程师们中流行的高性能缓存实现。然而，它并不是唯一的分布式提供者。实际上，当需要时，微软自己的SQL Server也可以作为缓存使用，并且他们为`IDistributedCache`类定义了一个类似的实现来公开它。

与 `SqlServerCache` 提供程序和 `RedisCache` 实例最大的不同之处在于它们所需的配置。由于 Redis 是一个简单的键值存储，`SqlServer` 仍然是一个功能齐全的关系型数据库。因此，为了提供高性能缓存所需的轻量级交互，您必须在将其设置为 `IDistributedCache` 提供程序时指定您打算利用的确切模式、表和数据库连接。并且由于 SQL Server 不支持 Redis 所支持的哈希表，您的应用程序连接用于缓存的表应实现 `IDistributedCache` 记录的预期结构。幸运的是，.NET Core CLI 提供了一个用于建立此类表的实用命令：`sql-cache create` 命令。值得注意的是，由于您的应用程序应该始终只与注入的 `IDistributedCache` 实例交互，您甚至可能不会注意到差异，除非是在性能方面。然而，出于性能的考虑，我建议尽可能使用 Redis。它正迅速成为行业标准，其速度确实无法与 SQL Server 相匹敌。

# MemoryCache 提供程序

最后，如果您的应用程序既没有需求，也没有支持独立缓存实例的手段，您始终可以依赖内存缓存策略。`System.Runtime.Caching` 命名空间中的 `MemoryCache` 类将提供所需的一切。配置它就像在 `Startup.cs` 中调用 `services.AddMemoryCache()` 方法一样简单，并且它提供了一个与我们已经查看过的 `IDistributedCache` 类相似的接口。

然而，它也带来了一些重要的注意事项。由于您在应用程序自己的进程中托管缓存，内存变得更为宝贵。对缓存替换策略的纪律性使用和积极的过期时间在内存缓存解决方案中变得尤为重要。此外，由于任何必须在会话生命周期内持久化的状态都只会在应用程序的单个实例中持久化，您需要实现粘性会话。这将确保用户始终与具有其数据缓存在内存中的应用服务器交互。

最终，您的业务需求和环境限制将在确定您应在应用程序中利用哪些缓存策略和策略方面发挥重要作用。然而，凭借本章中的信息，您应该能够为您的具体情况做出最佳决策。同时，我们将在下一章继续考虑性能优化，届时我们将考虑网络托管应用程序中的性能监控和数据跟踪。

# 摘要

在本章中，我们广泛探讨了分布式网络应用程序中数据缓存的动机和用例。我们首先探索了一些可能从缓存策略中受益的常见商业和设计问题。在这样做的时候，我们确定了在确定引入缓存管理系统复杂性的复杂性是否是您应用程序的正确决策时可以做出的基本考虑。然后，我们探讨了缓存可以带来的确切好处，以及缓存如何精确地提供这些好处。

一旦我们了解了为什么我们可能会使用缓存，我们就研究了在实现缓存时必须解决的常见问题。首先，我们解决了预缓存数据和按需缓存结果的战略。然后，我们探讨了如何确定哪些数据或资源应该被缓存。我们学习了如何建立适合您应用程序最常见数据交互的缓存替换策略，以及如何使缓存中的记录失效以确保您永远不会返回过时的结果。

最后，我们看到了如何在我们的应用程序中使用缓存。我们学习了如何运行分布式缓存，并看到了如何在代码中写入和读取该缓存。我们看到了缓存记录可以是任意数据结构，具有任意键，以及如何在我们的缓存实例中检测命中。最后，我们探讨了 C# 和 .NET Core 中可用的替代缓存机制。

在下一章中，我们将继续关注优化我们的应用程序在网络中的性能，并探讨可用于监控应用程序性能和识别网络中任何瓶颈的工具。

# 问题

1.  应该有哪些标准来激励缓存策略？

1.  缓存可以帮助解决哪些常见的痛点？

1.  缓存命中是什么？缓存未命中是什么？

1.  什么是缓存替换策略？有哪些常见的缓存替换策略？

1.  命中率是什么，它与替换策略有何关系？

1.  缓存失效是什么？

1.  使用分布式缓存有哪些好处？

# 进一步阅读

对于在现代 .NET 环境中构建缓存的更多实践指导，我推荐由 *Rod Stephens* 编著的书籍 *The Modern C# Challenge*。它深入探讨了与本章中讨论的相同类型的模式和惯例，并以极其易于理解的方式呈现。您可以通过 Packt 出版公司找到它，网址为：[https://www.packtpub.com/application-development/modern-c-challenge-0.](https://www.packtpub.com/application-development/modern-c-challenge-0)

或者，如果你想考虑分布式、水平扩展的应用架构固有的其他挑战，你应该查看*Vinicius Feitosa Pacheco*的*《微服务模式和最佳实践》*。它也由Packt出版，你可以在这里获取： [https://www.packtpub.com/application-development/microservice-patterns-and-best-practices.](https://www.packtpub.com/application-development/microservice-patterns-and-best-practices)
