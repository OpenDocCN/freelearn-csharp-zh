<html><head></head><body><div class="chapter" title="Chapter&#xA0;6.&#xA0;Using Concurrent Collections"><div class="titlepage"><div><div><h1 class="title"><a id="ch06"/>Chapter 6. Using Concurrent Collections</h1></div></div></div><p>In this chapter, we will look through the different data structures for concurrent programming included in the .NET Framework base class library. You will learn the following recipes:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Using <code class="literal">ConcurrentDictionary</code></li><li class="listitem" style="list-style-type: disc">Implementing asynchronous processing using <code class="literal">ConcurrentQueue</code></li><li class="listitem" style="list-style-type: disc">Changing the asynchronous processing order with <code class="literal">ConcurrentStack</code></li><li class="listitem" style="list-style-type: disc">Creating a scalable crawler with <code class="literal">ConcurrentBag</code></li><li class="listitem" style="list-style-type: disc">Generalizing asynchronous processing with <code class="literal">BlockingCollection</code></li></ul></div><div class="section" title="Introduction"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec58"/>Introduction</h1></div></div></div><p>Programming requires understanding and knowledge of basic data structures and algorithms. To choose the best-suited data structure for a concurrent situation, a programmer has to know about many things, such as algorithm time, space complexity, and the big O notation. In different, well-known scenarios, we always know which data structures are more efficient.</p><p>For concurrent computations, we need to have appropriate data structures. These data structures have to be scalable, avoid locks when possible, and at the same time provide thread-safe access. .NET Framework, since version 4, has the <code class="literal">System.Collections.Concurrent</code> namespace with several data structures in it. In this chapter, we will cover several data structures and show you very simple examples of how to use them.</p><p>Let's start with <code class="literal">ConcurrentQueue</code>. This collection<a id="id254" class="indexterm"/> uses atomic <span class="strong"><strong>Compare and Swap</strong></span> (<span class="strong"><strong>CAS</strong></span>) operations, which allow us to safely exchange values of two variables, and <code class="literal">SpinWait</code> to ensure thread safety. It implements a <span class="strong"><strong>First In, First Out</strong></span> (<span class="strong"><strong>FIFO</strong></span>) collection, which <a id="id255" class="indexterm"/>means that the items go out of the queue in the same order in which they were added to the queue. To add an item to a queue, you call the <code class="literal">Enqueue</code> method. The <code class="literal">TryDequeue</code> method tries to take the first item from the<a id="id256" class="indexterm"/> queue, and the <code class="literal">TryPeek</code> method tries to get the <a id="id257" class="indexterm"/>first item without<a id="id258" class="indexterm"/> removing it from the queue.</p><p>The <code class="literal">ConcurrentStack</code> collection is also implemented without using any locks and only with CAS operations. This is<a id="id259" class="indexterm"/> the <span class="strong"><strong>Last In, First Out</strong></span> (<span class="strong"><strong>LIFO</strong></span>) collection, which means that the most recently added item will be returned first. To add items, you can use the <code class="literal">Push</code> and <code class="literal">PushRange</code> methods; to retrieve, you use <code class="literal">TryPop</code> and <code class="literal">TryPopRange</code>, and to inspect, you can use the <code class="literal">TryPeek</code> method.</p><p>The <code class="literal">ConcurrentBag</code> collection is an unordered collection that supports duplicate items. It is optimized for a scenario where multiple threads partition their work in such a way that each thread produces and consumes its own tasks, dealing with other threads' tasks very rarely (in which case, it uses locks). You add items to a bag using the <code class="literal">Add</code> method; you inspect with <code class="literal">TryPeek</code>, and take items from a bag with the <code class="literal">TryTake</code> method.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note14"/>Note</h3><p>Avoid using the <code class="literal">Count</code> property on the collections mentioned. They are implemented using linked lists, and therefore, <code class="literal">Count</code> is an <code class="literal">O(N)</code> operation. If you need to check whether the collection is empty, use the <code class="literal">IsEmpty</code> property, which is an <code class="literal">O(1)</code> operation.</p></div></div><p><code class="literal">ConcurrentDictionary</code> is a<a id="id260" class="indexterm"/> thread-safe dictionary collection implementation. It is lock-free for read operations. However, it requires locking for write operations. The concurrent dictionary uses multiple locks, implementing a fine-grained locking model over the dictionary buckets. The number of locks could be defined using a constructor with the <code class="literal">concurrencyLevel</code> parameter, which means that an estimated number of threads will update the dictionary concurrently.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note15"/>Note</h3><p>Since a concurrent dictionary uses locking, there are a number of operations that require acquiring all the locks inside the dictionary. These operations are: <code class="literal">Count</code>, <code class="literal">IsEmpty</code>, <code class="literal">Keys</code>, <code class="literal">Values</code>, <code class="literal">CopyTo</code>, and <code class="literal">ToArray</code>. Avoid using these operations without need.</p></div></div><p><code class="literal">BlockingCollection</code> is an advanced wrapper over the <code class="literal">IProducerConsumerCollection</code> generic interface implementation. It has many features that <a id="id261" class="indexterm"/>are more advanced and is very useful for implementing pipeline scenarios when you have some steps that use the results from processing the previous steps. The <code class="literal">BlockingCollection</code> class supports features such as blocking, bounding inner collections capacity, canceling collection operations, and retrieving values from multiple blocking collections.</p><p>The concurrent algorithms can be very complicated, and covering all the concurrent collections—whether more or less advanced—would require writing a separate book. Here, we illustrate only the simplest examples of using concurrent collections.</p></div></div>
<div class="section" title="Using ConcurrentDictionary"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec59"/>Using ConcurrentDictionary</h1></div></div></div><p>This recipe shows<a id="id262" class="indexterm"/> you a very simple scenario, comparing the performance of a usual dictionary collection with the concurrent dictionary in a single-threaded environment.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec146"/>Getting ready</h2></div></div></div><p>To work through this recipe, you will need Visual Studio 2015. There are no other prerequisites. The source code for this recipe can be found at <code class="literal">BookSamples\Chapter6\Recipe1</code>.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec147"/>How to do it...</h2></div></div></div><p>To understand the difference between the performance of a usual dictionary collection and the concurrent dictionary, perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Start Visual Studio 2015. Create a new C# console application project.</li><li class="listitem">In the <code class="literal">Program.cs</code> file, add the following <code class="literal">using</code> directives:<div class="informalexample"><pre class="programlisting">using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Diagnostics;
using static System.Console;</pre></div></li><li class="listitem">Add the following code snippet below the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">const string Item = "Dictionary item";
const int Iterations = 1000000;
public static string CurrentItem;</pre></div></li><li class="listitem">Add the following code snippet inside the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">var concurrentDictionary = new ConcurrentDictionary&lt;int, string&gt;();
var dictionary = new Dictionary&lt;int, string&gt;();

var sw = new Stopwatch();

sw.Start();
for (int i = 0; i &lt; Iterations; i++)
{
  lock (dictionary)
  {
    dictionary[i] = Item;
  }
}
sw.Stop();
WriteLine($"Writing to dictionary with a lock: {sw.Elapsed}");

sw.Restart();
for (int i = 0; i &lt; Iterations; i++)
{
  concurrentDictionary[i] = Item;
}
sw.Stop();
WriteLine($"Writing to a concurrent dictionary: {sw.Elapsed}");

sw.Restart();
for (int i = 0; i &lt; Iterations; i++)
{
  lock (dictionary)
  {
    CurrentItem = dictionary[i];
  }
}
sw.Stop();
WriteLine($"Reading from dictionary with a lock: {sw.Elapsed}");

sw.Restart();
for (int i = 0; i &lt; Iterations; i++)
{
  CurrentItem = concurrentDictionary[i];
}
sw.Stop();
WriteLine($"Reading from a concurrent dictionary: {sw.Elapsed}");</pre></div></li><li class="listitem">Run the program.</li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec148"/>How it works...</h2></div></div></div><p>When the program<a id="id263" class="indexterm"/> starts, we create two collections. One of them is a standard dictionary collection, and the other is a new concurrent dictionary. Then, we start adding to them, using a standard dictionary with a lock and measuring the time it takes for one million iterations to complete. Then, we measure the <code class="literal">ConcurrentDictionary</code> collection's performance in the same scenario, and we finally compare the performance of retrieving values from both collections.</p><p>In this very simple scenario, we find that <code class="literal">ConcurrentDictionary</code> is significantly slower on write operations than a usual dictionary with a lock but is faster on retrieval operations. Therefore, if we need many thread-safe reads from a dictionary, the <code class="literal">ConcurrentDictionary</code> collection is the best choice.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note16"/>Note</h3><p>If you need just read-only multithreaded access to the dictionary, it may not be necessary to perform thread-safe reads. In this scenario, it is much better to use just a regular dictionary or the <code class="literal">ReadOnlyDictionary</code> collections.</p></div></div><p>The <code class="literal">ConcurrentDictionary</code> collection is implemented using the <span class="strong"><strong>fine-grained locking</strong></span> technique, and<a id="id264" class="indexterm"/> this allows it to scale better on multiple writes than using a regular dictionary with a lock (which is called <span class="strong"><strong>coarse-grained locking</strong></span>). As we saw in this example, when we <a id="id265" class="indexterm"/>use just one thread, a concurrent dictionary is much slower, but when we scale<a id="id266" class="indexterm"/> this up to five-six threads (if we have enough CPU cores that could run them simultaneously), the concurrent dictionary will actually perform better.</p></div></div>
<div class="section" title="Implementing asynchronous processing using ConcurrentQueue"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec60"/>Implementing asynchronous processing using ConcurrentQueue</h1></div></div></div><p>This recipe will show<a id="id267" class="indexterm"/> you an example <a id="id268" class="indexterm"/>of creating a set of tasks to be processed asynchronously by multiple workers.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec149"/>Getting ready</h2></div></div></div><p>To work through this recipe, you will need Visual Studio 2015. There are no other prerequisites. The source code for this recipe can be found at <code class="literal">BookSamples\Chapter6\Recipe2</code>.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec150"/>How to do it...</h2></div></div></div><p>To understand the working of creating a set of tasks to be processed asynchronously by multiple workers, perform the<a id="id269" class="indexterm"/> following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Start Visual Studio 2015. Create a new C# console application project.</li><li class="listitem">In the <code class="literal">Program.cs</code> file, add the following <code class="literal">using</code> directives:<div class="informalexample"><pre class="programlisting">using System;
using System.Collections.Concurrent;
using System.Threading;
using System.Threading.Tasks;
using static System.Console;</pre></div></li><li class="listitem">Add the <a id="id270" class="indexterm"/>following code snippet below the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">static async Task RunProgram()
{
  var taskQueue = new ConcurrentQueue&lt;CustomTask&gt;();
  var cts = new CancellationTokenSource();

  var taskSource = Task.Run(() =&gt; TaskProducer(taskQueue));

  Task[] processors = new Task[4];
  for (int i = 1; i &lt;= 4; i++)
  {
    string processorId = i.ToString();
    processors[i-1] = Task.Run(
      () =&gt; TaskProcessor(taskQueue, $"Processor {processorId}", cts.Token));
  }

  await taskSource;
  cts.CancelAfter(TimeSpan.FromSeconds(2));

  await Task.WhenAll(processors);
}

static async Task TaskProducer(ConcurrentQueue&lt;CustomTask&gt; queue)
{
  for (int i = 1; i &lt;= 20; i++)
  {
    await Task.Delay(50);
    var workItem = new CustomTask {Id = i};
    queue.Enqueue(workItem);
    WriteLine($"Task {workItem.Id} has been posted");
  }
}

static async Task TaskProcessor(
  ConcurrentQueue&lt;CustomTask&gt; queue, string name, CancellationToken token)
{
  CustomTask workItem;
  bool dequeueSuccesful = false;

  await GetRandomDelay();
  do
  {
    dequeueSuccesful = queue.TryDequeue(out workItem);
    if (dequeueSuccesful)
    {
      WriteLine($"Task {workItem.Id} has been processed by {name}");
    }

    await GetRandomDelay();
  }
  while (!token.IsCancellationRequested);
}

static Task GetRandomDelay()
{
  int delay = new Random(DateTime.Now.Millisecond).Next(1, 500);
  return Task.Delay(delay);
}

class CustomTask
{
  public int Id { get; set; }
}</pre></div></li><li class="listitem">Add the <a id="id271" class="indexterm"/>following code snippet<a id="id272" class="indexterm"/> inside the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">Task t = RunProgram();
t.Wait();</pre></div></li><li class="listitem">Run the program.</li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec151"/>How it works...</h2></div></div></div><p>When the program<a id="id273" class="indexterm"/> runs, we create a queue of tasks with an instance of the <code class="literal">ConcurrentQueue</code> collection. Then, we create a cancelation token, which will be used to stop work after we are done posting tasks to the queue. Next, we start a separate worker thread that will post tasks to the tasks queue. This part produces a workload for our asynchronous processing.</p><p>Now, let's define a task-consuming part of the program. We create four workers that will wait a random time, get a task from the task queue, process it, and repeat the whole process until we signal the cancelation token. Finally, we start the task-producing thread, wait for its completion, and then signal the consumers that we've finished work with the cancelation token. The last step will be to wait for all our consumers to complete, to finish processing all tasks.</p><p>We see that we have tasks being processed from start to end, but it is possible that a later task will be processed before an earlier one because we have four workers running independently and the task processing time is not constant. We see that the access to the queue is thread-safe; no work item was taken twice.</p></div></div>
<div class="section" title="Changing asynchronous processing order with ConcurrentStack"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec61"/>Changing asynchronous processing order with ConcurrentStack</h1></div></div></div><p>This recipe is a slight modification of the previous one. We will, once again, create a set of tasks to be <a id="id274" class="indexterm"/>processed<a id="id275" class="indexterm"/> asynchronously by multiple workers, but this time, we implement it with <code class="literal">ConcurrentStack</code> and see the differences.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec152"/>Getting ready</h2></div></div></div><p>To work through this recipe, you will need Visual Studio 2015. There are no other prerequisites. The source code for this recipe can be found at <code class="literal">BookSamples\Chapter6\Recipe3</code>.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec153"/>How to do it...</h2></div></div></div><p>To understand the processing of a set of tasks implemented with <code class="literal">ConcurrentStack</code>, perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Start Visual Studio 2015. Create a new C# console application project.</li><li class="listitem">In the <code class="literal">Program.cs</code> file, add the following <code class="literal">using</code> directives:<div class="informalexample"><pre class="programlisting">using System;
using System.Collections.Concurrent;
using System.Threading;
using System.Threading.Tasks;
using static System.Console;</pre></div></li><li class="listitem">Add the<a id="id276" class="indexterm"/> following code <a id="id277" class="indexterm"/>snippet below the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">static async Task RunProgram()
{
  var taskStack = new ConcurrentStack&lt;CustomTask&gt;();
  var cts = new CancellationTokenSource();

  var taskSource = Task.Run(() =&gt; TaskProducer(taskStack));

  Task[] processors = new Task[4];
  for (int i = 1; i &lt;= 4; i++)
  {
    string processorId = i.ToString();
    processors[i - 1] = Task.Run(
      () =&gt; TaskProcessor(taskStack, $"Processor {processorId}", cts.Token));
  }

  await taskSource;
  cts.CancelAfter(TimeSpan.FromSeconds(2));

  await Task.WhenAll(processors);
}

static async Task TaskProducer(ConcurrentStack&lt;CustomTask&gt; stack)
{
  for (int i = 1; i &lt;= 20; i++)
  {
    await Task.Delay(50);
    var workItem = new CustomTask { Id = i };
    stack.Push(workItem);
    WriteLine($"Task {workItem.Id} has been posted");
  }
}

static async Task TaskProcessor(
  ConcurrentStack&lt;CustomTask&gt; stack, string name, CancellationToken token)
{
  await GetRandomDelay();
  do
  {
    CustomTask workItem;
    bool popSuccesful = stack.TryPop(out workItem);
    if (popSuccesful)
    {
      WriteLine($"Task {workItem.Id} has been processed by {name}");
    }

    await GetRandomDelay();
  }
  while (!token.IsCancellationRequested);
}

static Task GetRandomDelay()
{
  int delay = new Random(DateTime.Now.Millisecond).Next(1, 500);
  return Task.Delay(delay);
}

class CustomTask
{
  public int Id { get; set; }
}</pre></div></li><li class="listitem">Add the following code snippet inside the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">Task t = RunProgram();
t.Wait();</pre></div></li><li class="listitem">Run the program.</li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec154"/>How it works...</h2></div></div></div><p>When the program runs, we now create an instance of the <code class="literal">ConcurrentStack</code> collection. The rest is almost like in the previous recipe, except instead of using the <code class="literal">Push</code> and <code class="literal">TryPop</code> methods<a id="id278" class="indexterm"/> on the concurrent stack, we use <code class="literal">Enqueue</code> and <code class="literal">TryDequeue</code> on a concurrent queue.</p><p>We now see that the<a id="id279" class="indexterm"/> task processing order has been changed. The stack is a LIFO collection, and workers process the latter tasks first. In case of a concurrent queue, tasks were processed in almost the same order in which they were added. This means that by depending on the number of workers, we will surely process the task that was created first in a given time frame. In the case of a stack, the tasks that were created earlier will have lower priority and may be not processed until a producer stops giving more tasks to the stack. This behavior is very specific and it is much better to use a queue in this scenario.</p></div></div>
<div class="section" title="Creating a scalable crawler with ConcurrentBag"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec62"/>Creating a scalable crawler with ConcurrentBag</h1></div></div></div><p>This recipe shows you<a id="id280" class="indexterm"/> how to scale workload <a id="id281" class="indexterm"/>between a number of independent workers that both produce work and process it.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec155"/>Getting ready</h2></div></div></div><p>To work through this recipe, you will need Visual Studio 2015. There are no other prerequisites. The source code for this recipe can be found at <code class="literal">BookSamples\Chapter6\Recipe4</code>.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec156"/>How to do it...</h2></div></div></div><p>The following steps demonstrate how to scale workload between a number of independent workers that both produce work and process it:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Start Visual Studio 2015. Create a new C# console application project.</li><li class="listitem">In the <code class="literal">Program.cs</code> file, add the following <code class="literal">using</code> directives:<div class="informalexample"><pre class="programlisting">using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Threading.Tasks;
using static System.Console;</pre></div></li><li class="listitem">Add the following code snippet below the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">static Dictionary&lt;string, string[]&gt; _contentEmulation = new Dictionary&lt;string, string[]&gt;();

static async Task RunProgram()
{
  var bag = new ConcurrentBag&lt;CrawlingTask&gt;();

  string[] urls = {"http://microsoft.com/", "http://google.com/", "http://facebook.com/", "http://twitter.com/"};
    
  var crawlers = new Task[4];
  for (int i = 1; i &lt;= 4; i++)
  {
    string crawlerName = $"Crawler {i}";
    bag.Add(new CrawlingTask { UrlToCrawl = urls[i-1], ProducerName = "root"});
    crawlers[i - 1] = Task.Run(() =&gt; Crawl(bag, crawlerName));
  }

  await Task.WhenAll(crawlers);
}

static async Task Crawl(ConcurrentBag&lt;CrawlingTask&gt; bag, string crawlerName)
{
  CrawlingTask task;
  while (bag.TryTake(out task))
  {
    IEnumerable&lt;string&gt; urls = await GetLinksFromContent(task);
    if (urls != null)
    {
      foreach (var url in urls)
      {
        var t = new CrawlingTask
        {
          UrlToCrawl = url,
          ProducerName = crawlerName
        };

        bag.Add(t);
      }
    }
    WriteLine($"Indexing url {task.UrlToCrawl} posted by " +
       $"{task.ProducerName} is completed by {crawlerName}!");
  }
}

static async Task&lt;IEnumerable&lt;string&gt;&gt; GetLinksFromContent(CrawlingTask task)
{
  await GetRandomDelay();

  if (_contentEmulation.ContainsKey(task.UrlToCrawl)) return _contentEmulation[task.UrlToCrawl];

  return null;
}

static void CreateLinks()
{
  _contentEmulation["http://microsoft.com/"] = new [] { "http://microsoft.com/a.html", "http://microsoft.com/b.html" };
  _contentEmulation["http://microsoft.com/a.html"] = new[] { "http://microsoft.com/c.html", "http://microsoft.com/d.html" };
  _contentEmulation["http://microsoft.com/b.html"] = new[] { "http://microsoft.com/e.html" };

  _contentEmulation["http://google.com/"] = new[] { "http://google.com/a.html", "http://google.com/b.html" };
  _contentEmulation["http://google.com/a.html"] = new[] { "http://google.com/c.html", "http://google.com/d.html" };
  _contentEmulation["http://google.com/b.html"] = new[] { "http://google.com/e.html", "http://google.com/f.html" };
  _contentEmulation["http://google.com/c.html"] = new[] { "http://google.com/h.html", "http://google.com/i.html" };

  _contentEmulation["http://facebook.com/"] = new [] { "http://facebook.com/a.html", "http://facebook.com/b.html" };
  _contentEmulation["http://facebook.com/a.html"] = new[] { "http://facebook.com/c.html", "http://facebook.com/d.html" };
  _contentEmulation["http://facebook.com/b.html"] = new[] { "http://facebook.com/e.html" };

  _contentEmulation["http://twitter.com/"] = new[] { "http://twitter.com/a.html", "http://twitter.com/b.html" };
  _contentEmulation["http://twitter.com/a.html"] = new[] { "http://twitter.com/c.html", "http://twitter.com/d.html" };
  _contentEmulation["http://twitter.com/b.html"] = new[] { "http://twitter.com/e.html" };
  _contentEmulation["http://twitter.com/c.html"] = new[] { "http://twitter.com/f.html", "http://twitter.com/g.html" };
  _contentEmulation["http://twitter.com/d.html"] = new[] { "http://twitter.com/h.html" };
  _contentEmulation["http://twitter.com/e.html"] = new[] { "http://twitter.com/i.html" };
}

static Task GetRandomDelay()
{
  int delay = new Random(DateTime.Now.Millisecond).Next(150, 200);
  return Task.Delay(delay);
}

class CrawlingTask
{
  public string UrlToCrawl { get; set; }

  public string ProducerName { get; set; }
}</pre></div></li><li class="listitem">Add the following code snippet inside the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">CreateLinks();
Task t = RunProgram();
t.Wait();</pre></div></li><li class="listitem">Run the program.</li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec157"/>How it works...</h2></div></div></div><p>The program simulates web page indexing with multiple web crawlers. A web crawler is a program that opens<a id="id282" class="indexterm"/> a web page by its address, indexes the content, tries to visit all the links that this page contains, and indexes these<a id="id283" class="indexterm"/> linked pages as well. At the beginning, we define a dictionary containing different web-page URLs. This dictionary simulates web pages containing links to other pages. The implementation is very naive; it does not care about indexing the already visited pages, but it is simple and allows us to focus on the concurrent workload.</p><p>Then, we create a concurrent bag, containing crawling tasks. We create four crawlers and provide a different site root URL to each of them. Then, we wait for all crawlers to compete. Now, each crawler starts to index the site URL it was given. We simulate the network I/O process by waiting for some random amount of time; then, if the page contains more URLs, the crawler posts more crawling tasks to the bag. Then, it checks whether there are any tasks left to crawl in the bag. If not, the crawler is complete.</p><p>If we check the output below the first four lines, which are root URLs, we will see that usually, which were root URLs, we will see that usually a task posted by the crawler number <span class="emphasis"><em>N</em></span> is processed by the same crawler. However, the later lines will be different. This happens because internally, <code class="literal">ConcurrentBag</code> is optimized for exactly this scenario where there are multiple threads that both add items and remove them. This is achieved by letting each thread work with its own local queue of items, and thus, we do not need any locks while this queue is occupied. Only when we have no items left in the local queue will we perform some locking and try to <span class="emphasis"><em>steal</em></span> the work from another thread's local queue. This behavior helps to distribute the work between all workers and avoid locking.</p></div></div>
<div class="section" title="Generalizing asynchronous processing with BlockingCollection"><div class="titlepage"><div><div><h1 class="title"><a id="ch06lvl1sec63"/>Generalizing asynchronous processing with BlockingCollection</h1></div></div></div><p>This recipe <a id="id284" class="indexterm"/>will describe how to use <code class="literal">BlockingCollection</code> to simplify implementation of workload asynchronous<a id="id285" class="indexterm"/> processing.</p><div class="section" title="Getting ready"><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec158"/>Getting ready</h2></div></div></div><p>To work through this recipe, you will need Visual Studio 2015. No other prerequisites are required. The source code for this recipe can be found at <code class="literal">BookSamples\Chapter6\Recipe5</code>.</p></div><div class="section" title="How to do it..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec159"/>How to do it...</h2></div></div></div><p>To understand how <code class="literal">BlockingCollection</code> simplifies the implementation of workload asynchronous processing, perform the following steps:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">Start Visual Studio 2015. Create a new C# console application project.</li><li class="listitem">In the <code class="literal">Program.cs</code> file, add the following <code class="literal">using</code> directives:<div class="informalexample"><pre class="programlisting">using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;
using static System.Console;</pre></div></li><li class="listitem">Add the following code snippet below the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">static async Task RunProgram(IProducerConsumerCollection&lt;CustomTask&gt; collection = null)
{
  var taskCollection = new BlockingCollection&lt;CustomTask&gt;();
  if(collection != null)
    taskCollection= new BlockingCollection&lt;CustomTask&gt;(collection);

  var taskSource = Task.Run(() =&gt; TaskProducer(taskCollection));

  Task[] processors = new Task[4];
  for (int i = 1; i &lt;= 4; i++)
  {
    string processorId = $"Processor {i}";
    processors[i - 1] = Task.Run(
      () =&gt; TaskProcessor(taskCollection, processorId));
  }

  await taskSource;

  await Task.WhenAll(processors);
}

static async Task TaskProducer(BlockingCollection&lt;CustomTask&gt; collection)
{
  for (int i = 1; i &lt;= 20; i++)
  {
    await Task.Delay(20);
    var workItem = new CustomTask { Id = i };
    collection.Add(workItem);
    WriteLine($"Task {workItem.Id} has been posted");
  }
  collection.CompleteAdding();
}

static async Task TaskProcessor(
  BlockingCollection&lt;CustomTask&gt; collection, string name)
{
  await GetRandomDelay();
  foreach (CustomTask item in collection.GetConsumingEnumerable())
  {
    WriteLine($"Task {item.Id} has been processed by {name}");
    await GetRandomDelay();
  }
}

static Task GetRandomDelay()
{
  int delay = new Random(DateTime.Now.Millisecond).Next(1, 500);
  return Task.Delay(delay);
}

class CustomTask
{
  public int Id { get; set; }
}</pre></div></li><li class="listitem">Add the following code snippet inside the <code class="literal">Main</code> method:<div class="informalexample"><pre class="programlisting">WriteLine("Using a Queue inside of BlockingCollection");
WriteLine();
Task t = RunProgram();
t.Wait();

WriteLine();
WriteLine("Using a Stack inside of BlockingCollection");
WriteLine();
t = RunProgram(new ConcurrentStack&lt;CustomTask&gt;());
t.Wait();</pre></div></li><li class="listitem">Run the program.</li></ol></div></div><div class="section" title="How it works..."><div class="titlepage"><div><div><h2 class="title"><a id="ch06lvl2sec160"/>How it works...</h2></div></div></div><p>Here, we take exactly the first scenario, but now, we use a <code class="literal">BlockingCollection</code> class that provides <a id="id286" class="indexterm"/>many useful benefits. First of all, we are able to change the way the tasks are stored inside the blocking <a id="id287" class="indexterm"/>collection. By default, it uses a <code class="literal">ConcurrentQueue</code> container, but we are able to use any collection that implements the <code class="literal">IProducerConsumerCollection</code> generic interface. To illustrate this, we run the program twice, using <code class="literal">ConcurrentStack</code> as the underlying collection the second time.</p><p>Workers get work items by iterating the <code class="literal">GetConsumingEnumerable</code> method call result on a blocking collection. If there are no items inside the collection, the iterator will just block the worker thread until an item is posted to the collection. The cycle ends when the producer calls the <code class="literal">CompleteAdding</code> method on the collection. It signals that the work is done.</p><div class="note" title="Note" style=""><div class="inner"><h3 class="title"><a id="note17"/>Note</h3><p>It is very easy to make a mistake and just iterate <code class="literal">BlockingCollection</code> as it implements <code class="literal">IEnumerable</code> itself. Do not forget to use <code class="literal">GetConsumingEnumerable</code>, or else, you will just iterate a "snapshot" of a collection and get completely unexpected program behavior.</p></div></div><p>The workload producer inserts the tasks into <code class="literal">BlockingCollection</code> and then calls the <code class="literal">CompleteAdding</code> method, which causes all the workers to get completed. Now, in the program output, we see two result sequences illustrating the difference between the concurrent queue and stack collections.</p></div></div></body></html>