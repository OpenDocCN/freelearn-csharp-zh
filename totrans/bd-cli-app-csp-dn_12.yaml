- en: '12'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance Optimization and Tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Performance separates applications that are used and loved from those that are
    uninstalled and forever forgotten.
  prefs: []
  type: TYPE_NORMAL
- en: It is not enough to have an application that responds to users’ needs. To be
    used frequently (and likely daily), an application needs to bootstrap and perform
    tasks quickly.
  prefs: []
  type: TYPE_NORMAL
- en: This speed and responsiveness directly impact user satisfaction, as people have
    increasingly high expectations for digital experiences. Studies have shown that
    even small delays in load times or task completion can significantly reduce user
    engagement and overall satisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss different areas where performance can be improved
    and what techniques we can use to achieve this. More specifically, we will cover
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The different areas to be considered to improve application performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to instrument an application to identify performance problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to improve your application performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The code for this chapter can be found in the GitHub repository accompanying
    this book, [https://github.com/PacktPublishing/Building-CLI-Applications-with-C-Sharp-and-.NET/tree/main/Chapter12](https://github.com/PacktPublishing/Building-CLI-Applications-with-C-Sharp-and-.NET/tree/main/Chapter12).
  prefs: []
  type: TYPE_NORMAL
- en: Performance optimization areas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The performance of an application is not only a matter of code. It is a series
    of fine tuning, at different levels, that helps achieve performance efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'Performance optimization therefore occurs in areas such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Application design and architecture**: The longer the path you must walk,
    the longer it takes you to get to your destination. As I always tell my customers,
    you may run twice as fast as me, but if your path is twice as long as mine, we
    will arrive at our destination at the same time. The idea here is that using performant
    frameworks and libraries is of little use if your architecture is not efficient.
    Too often, I see architectures that are over-decoupled, with too many hops and
    context switching, leading to applications that are not performant and slow. The
    key is to build an architecture that balances performance with the optimal level
    of decoupling. From a design perspective, I often see designs that can be improved
    (leading to more efficient and performant applications) by finding a shorter path
    to achieve a goal. Of course, you won’t do that for every piece of code, but you
    will want to focus your attention on hot paths, namely paths that are often used
    by your users. There may be no point in optimizing the performance of a functionality
    that is used by one user once a year. You must find a balance between the cost
    of the optimization effort (it takes time, so it has a cost) and the benefit you
    are expecting from it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Infrastructure**: If we host the application on an infrastructure, we must
    ensure that this infrastructure is efficient and has been optimized to maximize
    the throughput of the application while minimizing its latency. However, in the
    context of CLI applications, the application runs on the user’s computer, so we
    might be tempted to say that there is nothing to do here, but we would be wrong!
    There are tuning tasks we can perform that will positively impact performance.
    For example, we can reduce resource utilization so that running the application
    on the user’s computer will consume the least amount of resources and therefore
    will be executed efficiently, even if the computer is running other applications
    side by side or has little horsepower.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frameworks and libraries**: Of course, using efficient and performant frameworks
    and libraries helps to improve the application’s performance. For example, every
    new release of .NET promises better performance. Hence, upgrading the .NET version
    can be an easy way to improve the performance of our application. The same goes
    for the libraries that we use: some are known to have better performance than
    others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Coding practices**: The last piece of the puzzle is the coding practices.
    We have already mentioned hot spots and hot paths, but coding practices also include
    using the most appropriate data structures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we start optimizing our application’s performance, we need to instrument
    it and identify its hot spots and hot paths.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting .NET applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multiple tools exist to help us instrument.NET applications. The main difference
    between these tools is their scope of action.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, a key benefit of instrumentation is the ability to detect memory
    leaks and identify slow code paths.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumentation can be achieved both during the development phase and continuously,
    while the application is running in production.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Development-time profiling** | Visual Studio Diagnostic Tools, `BenchmarkDotNet`,
    `dotTrace`, `dotMemory`, and `PerfView` are great for profiling CPU, memory leaks
    and allocation, and application performance. |'
  prefs: []
  type: TYPE_TB
- en: '| **Production-time monitoring** | Azure Application Insights, AppDynamics,
    and New Relic help monitor and diagnose performance issues in real time in production
    environments. |'
  prefs: []
  type: TYPE_TB
- en: Table 12.1 – Some popular instrumentation tools
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed the terms *“profiling”* and *“monitoring.”* There are
    some key differences between them:'
  prefs: []
  type: TYPE_NORMAL
- en: Profiling provides a detailed, granular view of an application’s performance,
    often focusing on specific code sections or methods. This includes CPU usage per
    functionality or method, memory allocation, execution time, and method call frequency
    and duration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring is usually done in production and provides an overview of the application’s
    health, looking at broader performance trends and operational data over time rather
    than focusing on individual code paths. This includes CPU and memory usage across
    the entire application, error rates (exceptions, failures), response times and
    throughput (e.g., how long requests take, how many requests per second), and the
    application’s resource usage (disk I/O, network usage, etc.).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because a CLI application runs on the user’s computer, it may be harder to monitor
    it. It requires permission from the user to collect the necessary data, usually
    at frequent intervals. We may then expect the user to refuse to share telemetry
    data, and therefore monitoring may not be possible.
  prefs: []
  type: TYPE_NORMAL
- en: While it is important to know the tools that help us instrument our applications,
    it is equally important to understand where to use them, in other words, how to
    identify these areas that may be good candidates for performance optimization.
    In that regard, it is important to be able to identify hot spots and hot paths.
  prefs: []
  type: TYPE_NORMAL
- en: Hot spots versus hot paths
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is not the first time in this chapter that I have mentioned hot spots and
    hot paths. However, I haven’t taken the time to explain them. Let’s fix this right
    away!
  prefs: []
  type: TYPE_NORMAL
- en: A **hot spot** is an area of intense activity in the code, typically referring
    to frequently executed methods that consume a significant amount of execution
    time. Therefore, a hot spot represents a potential optimization target for improving
    the overall performance of the application.
  prefs: []
  type: TYPE_NORMAL
- en: A **hot path** refers to an execution path through the code that is frequently
    taken and therefore contributes *significantly* to the application’s runtime.
    Hot paths can help locate inefficiently used resources, such as memory usage and
    allocation.
  prefs: []
  type: TYPE_NORMAL
- en: The question that may arise here is *“what process can we follow to identify
    the application’s hot spots and* *hot paths?”*
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the application’s hot spots and hot paths
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fortunately, identifying an application’s hot spots and hot paths does not
    have to be done by shots in the dark. Instead, we can follow a structured process
    that consists of three steps: profiling, analysis, and optimization. If monitoring
    is implemented, it will serve as an input for that process, since this process
    should be performed periodically to ensure optimal performance of the application.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The process is described in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Step** | **What** **to do** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Profiling and data collection
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Use performance profilers to gather data about your application’s execution.
    A library such as `BenchmarkDotNet` can collect detailed information about CPU
    usage, memory consumption, and execution times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collect metrics on method execution times, resource usage, and frequency of
    calls to identify performance bottlenecks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis and identification
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Analyze the profiler output and find:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methods with high execution times
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Frequently called methods
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Areas of high CPU or memory usage
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Long-running database queries or I/O operations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Look for patterns in the data that indicate potential hot spots or hot paths:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Methods that consume a disproportionate amount of resources
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Execution paths that are frequently taken and contribute significantly to the
    overall runtime
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Once hot spots and hot paths are identified, implement optimizations targeting
    these areas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use benchmarking tools such as `BenchmarkDotNet` to measure and compare the
    performance of the code before and after optimization to assess the gain in performance.
    You may also measure and compare different implementations to identify the most
    optimal one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 12.2 – Identifying hot spots and hot paths
  prefs: []
  type: TYPE_NORMAL
- en: We mentioned that `BenchmarkDotNet` can help us profile our application. Then,
    it is time to learn how to use it.
  prefs: []
  type: TYPE_NORMAL
- en: Profiling Bookmarkr with BenchmarkDotNet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although `BenchmarkDotNet` is considered to be a benchmarking library (that
    is, it is used to compare different implementation alternatives against a baseline
    to identify which one is the most performant), when used strategically, it can
    also identify hot spots and hot paths in our code.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how we can leverage this library to profile our CLI application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we need to do is to reference the `BenchmarkDotNet` library.
    This can be achieved by executing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to configure benchmark collection and reporting. For that
    matter, let’s add the following block of code at the very beginning of the `Main`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This allows us to run the benchmarks if we execute the application and pass
    `benchmark` as a parameter.
  prefs: []
  type: TYPE_NORMAL
- en: What this block of code does is ask `BenchmarkDotNet` (via the `BenchmarkRunner`
    class) to run all the benchmarks that will be found in the `Benchmarks` class.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create that `Benchmarks` class!
  prefs: []
  type: TYPE_NORMAL
- en: Following the folder structure convention that we defined in previous chapters,
    we will create a `Benchmarks` folder within which we will create a `Benchmarks.cs`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: We can either have a single class where all benchmarks are located, or we can
    create one benchmark class for every command or service to be benchmarked. We
    will take the first approach in this chapter as we will only benchmark the `export`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s add our first benchmark method. Its code looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This method creates an instance of the `ExportCommand` class and executes it
    by calling its `InvokeAsync` method, passing in the required parameters for the
    command.
  prefs: []
  type: TYPE_NORMAL
- en: Right now, this method is not yet considered as a benchmark by the `BenchmarkRunner`
    class. The reason is that for a method to be considered as a benchmark, it needs
    to be decorated with the `[Benchmark]` attribute. Let’s fix this!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Awesome! But we are not ready to run it yet…
  prefs: []
  type: TYPE_NORMAL
- en: See what’s missing?
  prefs: []
  type: TYPE_NORMAL
- en: You got it! The `ExportCommand` class takes an instance of type `IBookmarkService`
    as a parameter, but we haven’t so far provided such an instance of an object.
  prefs: []
  type: TYPE_NORMAL
- en: Since we already have such an instance defined in the `Program` class, you may
    expect that we can pass it to the `Benchmarks` class through its constructor,
    and this would be a perfectly reasonable assumption. However, the `BenchmarkRunner`
    class does not allow us to do so (at least with the current version of `BenchmarkDotNet`).
  prefs: []
  type: TYPE_NORMAL
- en: 'What we will do instead is to instantiate this object in the `Benchmarks` class
    directly. The code will then look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the instantiation of the service is not performed in the class constructor
    but rather in a method decorated with the `[GlobalSetup]` attribute. This special
    attribute instructs `BenchmarkDotNet` to call this method once before executing
    each benchmark method. This is to have a clean instance of the service for each
    benchmark method, hence preventing side effects from previous benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: GlobalSetup versus class constructor
  prefs: []
  type: TYPE_NORMAL
- en: The execution time of the `[GlobalSetup]` method is not taken into account in
    calculating the benchmarked method execution time, as opposed to the execution
    time of the constructor. While this might seem negligible, it will not be if the
    method is meant to be executed a significant number of times.
  prefs: []
  type: TYPE_NORMAL
- en: We are now ready to execute our benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, we first need to build the application, but this time we need to
    build it in `Release` mode. Otherwise, `BenchmarkDotNet` will generate an error.
    The reason is that running a program in `Debug` mode is not optimal and has a
    significant performance cost compared to running the program in `Release` mode,
    which is the mode the application should be run on in production. Therefore, when
    benchmarking our application, we should do it in its optimal performance mode.
  prefs: []
  type: TYPE_NORMAL
- en: Debug vs Release modes
  prefs: []
  type: TYPE_NORMAL
- en: Building the code in `Debug` mode produces unoptimized code with full symbolic
    `debug` information, enabling easier debugging and breakpoint setting. In contrast,
    `Release` mode generates optimized code for better performance and smaller file
    sizes. `Release` builds typically omit `debug` symbols, inline methods, and apply
    various optimizations that can make debugging more challenging but result in faster
    execution. While `Debug` builds are ideal for development and troubleshooting,
    `Release` builds are used when deploying to production.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building the application in `Release` mode can be achieved by typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We then run the benchmarks by typing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`C:\code\Chap12\bookmarkr\bin\Release\net8.0` is the location of the generated
    DLL of the Bookmarkr application.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The result is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1 – Benchmarking the export command](img/B22400_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.1 – Benchmarking the export command
  prefs: []
  type: TYPE_NORMAL
- en: The benchmark method has run 98 times and, on average, it takes 6.356 milliseconds
    to run the `export` command, which is not bad at all, is it?
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see the table in the middle of the screen. This table compiles the
    metrics per benchmark method. Let’s explain what each of its columns represents:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Mean`: This represents the average duration of the benchmarked method over
    all its executions (98 in our example).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Error`: Simply stated, this value represents the precision of the mean value’s
    measurement. The smaller the error, the more precise the measurement of the mean
    value. As an example, since our mean value is 6.356 ms and the error is 0.7840
    ms, all measurements fall within the range of 6.356 ms ± 0.7840 ms, which means
    between 5.572 ms and 7.140 ms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`StdDev`: This value represents the standard deviation of all measurements.
    It quantifies the amount of variation or dispersion in the execution times. In
    other words, a lower value of `StdDev` indicates that the execution times are
    clustered closely around the mean.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Benchmarking is not only for commands!
  prefs: []
  type: TYPE_NORMAL
- en: Although we are benchmarking a command here, it is important to note that benchmarking
    does not only apply to commands but rather to all code artifacts that may have
    an impact on the application’s performance, which also includes services. Therefore,
    by benchmarking commands *and* the services they use, we can determine the percentage
    of the execution time and memory consumption that is attributable to the service
    and the command.
  prefs: []
  type: TYPE_NORMAL
- en: Great! There is, however, one measurement that we haven’t seen here, which is
    the measurement of memory consumption. Let’s fix that!
  prefs: []
  type: TYPE_NORMAL
- en: 'To collect data about memory consumption, we simply need to add the `[MemoryDiagnoser]`
    tag on top of the `Benchmarks` class, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, if we run the code in exactly the same way as before, we get the following
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.2 – Benchmarking memory consumption](img/B22400_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.2 – Benchmarking memory consumption
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that now we have a new column called `Allocated`, which represents the
    amount of allocated memory for every execution of the benchmarked method, in kilobytes.
    This column is interesting for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It allows us to see if the benchmarked method is using way too much memory than
    it should (or way more than it is expected to use). This can indicate memory leaks
    in our code that require deeper investigation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we optimize our code, we can see if the new implementation has an impact
    on memory consumption. For example, we could come up with an implementation that
    speeds up the execution time at the expense of significant memory consumption.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execution time versus memory consumption optimization
  prefs: []
  type: TYPE_NORMAL
- en: You may be wondering whether we should concentrate on optimizing memory consumption
    or execution time. The decision about where to focus our attention and energy
    depends on what we value the most, memory consumption or execution time. It is
    interesting to note that, in some situations, we may even be able to optimize
    both at the same time! To do that, we have to come up with a creative implementation
    that addresses both concerns by leveraging advanced features of the frameworks
    and libraries that we use, combined with advanced and creative algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: While `BenchmarkDotNet` helps us identify optimization opportunities during
    the development phase, it is important to implement monitoring so that we can
    continuously check the application’s performance while it is being used in production.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring BookmarkrSyncr with Azure Application Insights
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We mentioned earlier that a CLI application runs locally on the user’s computer
    and that the user may refuse to allow us to collect telemetry data that is absolutely
    essential for monitoring. That is why we won’t implement monitoring in Bookmarkr
    but rather in **BookmarkrSyncr**, the external web service invoked by Bookmarkr.
    Since this is a web service hosted and managed by us, we can implement monitoring
    and ensure that telemetry data will be collected, therefore ensuring that monitoring
    can take place.
  prefs: []
  type: TYPE_NORMAL
- en: Since this web service is deployed to the **Microsoft Azure** cloud platform,
    we will rely on Azure Application Insights, the **application performance monitoring**
    (**APM**) solution provided natively by the Microsoft Azure cloud platform.
  prefs: []
  type: TYPE_NORMAL
- en: When we deployed BookmarkrSyncr to Microsoft Azure, we created an infrastructure
    for hosting it. More specifically, we created an **Azure App Service** instance.
    As part of the process of creating this service, we are offered the opportunity
    to create an instance of the **Azure Application Insights** service. This service
    is a monitoring solution that is provided and managed for us by Microsoft.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Application Insights is a fantastic service that allows us to monitor
    performance, availability, failed requests, exceptions, page views, traces, browser
    timings, usage (including **user flows**, which allow us to identify hot paths
    in the application), and even access live metrics so we can monitor in real time.
    Another great feature of **Azure Application Insights** is the ability to configure
    alerts to be triggered if a certain metric reaches a certain threshold, for example,
    if the server response time (which measures the duration between receiving the
    HTTP request and sending the response to the client) is above the maximum allowed
    value as defined by our organization’s standards. When an alert is raised, we
    can then trigger an automated processing or a notification (such as an email to
    a specific group of people).
  prefs: []
  type: TYPE_NORMAL
- en: To seewhat monitoring with **Azure Application Insights** may look like, check
    out (this article on Microsoft Learn, which can be found at [https://learn.microsoft.com/en-us/azure/azure-monitor/app/overview-dashboard](https://learn.microsoft.com/en-us/azure/azure-monitor/app/overview-dashboard).
  prefs: []
  type: TYPE_NORMAL
- en: Okay. Now that we know how to identify the areas of our application that require
    performance tuning (using profiling and monitoring), let’s discuss the most common
    techniques that we can use to enhance the performance of our application.
  prefs: []
  type: TYPE_NORMAL
- en: Common performance optimization techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is worth mentioning that the techniques we will be discussing here do not
    only apply to CLI applications but can rather be applied to any kind of application.
    Let’s break these techniques down according to the categories we presented earlier.
    For every category, I will give you a list of techniques commonly used for it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Application design** **and architecture**:'
  prefs: []
  type: TYPE_NORMAL
- en: Establish the shortest path to achieve a goal, removing all unnecessary intermediaries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be achieved by using efficient algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Find the optimal balance between decoupling and low latency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use lazy loading for resources that aren't immediately needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement efficient error handling and logging mechanisms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design for scalability from the start.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Infrastructure**:'
  prefs: []
  type: TYPE_NORMAL
- en: When packaging and distributing your application, compile it in `Release` mode.
    While `Debug` mode is great during the development phase, it may add a significant
    performance overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, when packaging and distributing your application, compile it as platform-specific
    if the target platform is known ahead of time or if the packaging and distribution
    mechanism is not cross-platform. For example, distributing our application as
    a **Winget** package means that it will exclusively be used on the Windows platform.
    The same goes with an apt-get package (where the application will run exclusively
    on **Linux**) and with **Homebrew** (where the application will run exclusively
    on **macOS**). It is therefore easy to know what platform-specific compilation
    should be used and will make .NET apply all the possible optimizations, which
    is something it wouldn’t do if the target platform is not known ahead of time
    (an example of that is file handling, which is different on Windows, Linux, and
    macOS). This will result in a version of the application that runs in the most
    efficient manner on that target platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might also choose to use **AOT** (**Ahead-Of-Time**) compilation to precompile
    your code to native code (instead of relying on **JIT**) for faster startup times
    or to reduce the dependency on runtime compilation. This could be particularly
    useful if you're targeting environments like mobile (iOS/Android) or WebAssembly,
    where JIT might not be feasible. Note that platform targeting and AOT can be combined
    for even better performance optimization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Frameworks** **and libraries:**'
  prefs: []
  type: TYPE_NORMAL
- en: Avoid using libraries that rely on reflection, unless absolutely necessary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose lightweight frameworks and libraries that align with your specific needs.
    Beware of libraries that pull off tenth of other libraries when you reference
    them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep dependencies up to date to benefit from performance improvements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider using micro-frameworks for smaller, focused tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Coding practices:**'
  prefs: []
  type: TYPE_NORMAL
- en: Rely on asynchronous operations whenever possible. This will avoid blocking
    the main thread and increases the feeling of responsiveness of the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choose the most optimized data types or data structures for the pursued purpose.
    This will ensure we have the minimal footprint on the computer’s resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whenever possible, try to achieve a task with as little memory allocation as
    possible. For example, at the time of this writing, .NET 9 was released and introduces
    split operations with no memory allocation by calling `AsSpan().Split(…)`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement a caching mechanism to avoid unnecessary calls to external dependencies
    (such as web services or databases).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimize database queries and implement proper indexing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speaking about databases, if you are using an `AsNoTracking()` to significantly
    improve query performance and reduce memory usage, especially when dealing with
    large datasets or read-only operations. This method tells the ORM not to track
    changes to the retrieved entities, bypassing the change tracking mechanism and
    resulting in faster queries with lower memory overhead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use connection pooling, which consists in reusing established database connections
    instead of creating a new one for every request. This is because it can be expensive
    to establish a connection to a database, therefore connection pooling reduces
    connection latency and enables high database throughput (transactions per second)
    on the server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement proper memory management and dispose of unused resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have seen a bunch of techniques that are commonly used for optimizing the
    performance of any kind of application that is built with any technology stacks,
    including CLI applications built with .NET.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now apply some of these techniques to enhance Bookmarkr’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing Bookmarkr’s performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We cannot optimize what is already perfect, can we?
  prefs: []
  type: TYPE_NORMAL
- en: Just kidding. Of course we can! There is always room for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see some of the quick wins that we can apply to enhance the performance
    of our beloved CLI application.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the handler method of the `ExportCommand` class (namely, `OnExportCommand`),
    we can see that it already leverages async operations. This is a great start and
    is actually one of the techniques we described earlier.
  prefs: []
  type: TYPE_NORMAL
- en: However, the handler method can be optimized. To illustrate this, let’s create
    a copy of the `ExportCommand` class and name it `ExportCommandOptimized`. Let’s
    copy the code from the `ExportCommand` as is, and we will optimize it in a moment.
  prefs: []
  type: TYPE_NORMAL
- en: The reason we are creating a copy of the original class rather than directly
    optimizing it is so that we can add a benchmark method for the optimized version
    and compare it with the original one.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the handler method of the `ExportCommandOptimized` class, let’s change these
    two lines of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace them with the following two lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see what we have done:'
  prefs: []
  type: TYPE_NORMAL
- en: Using `JsonSerializer.SerializeAsync` is more efficient for large datasets as
    it streams the JSON directly to the file without keeping the entire serialized
    string in memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `FileStream` with async operations allows better control over file I/O
    operations and can improve performance, especially for large files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Okay. Let’s compare this new implementation with the original one.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, let’s add the following benchmark method to the `Benchmarks` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This `benchmark` method is identical to the previous one. Well, almost identical…
    The only difference is that we are instantiating (and invoking) the `ExportCommandOptimized`
    class rather than the `ExportCommand` class.
  prefs: []
  type: TYPE_NORMAL
- en: Since we want to compare the new, optimized, implementation against the original
    one, we will modify the `[``Benchmark]` attribute of the original method to look
    like this.
  prefs: []
  type: TYPE_NORMAL
- en: 'This instructs `BenchmarkDotNet` to use this method as a baseline for the comparison:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Let’s rebuild the application (in `Release` mode, of course) and execute the
    benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Benchmarking the new implementation against the original one](img/B22400_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Benchmarking the new implementation against the original one
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice the appearance of two new columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Ratio`: This indicates the average measure of the performance relative to
    the baseline benchmark method'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RatioSD`: This indicates the average standard deviation relative to the standard
    deviation of the baseline benchmark method'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The value of `0.91` in the `Ratio` column indicates that the optimized implementation
    (`ExportCommandOptimized`) is on average 9% faster than the baseline implementation
    (`ExportCommand`). We mentioned earlier that the implementation we made in `ExportCommandOptimized`
    is especially more performant when dealing with large files. Therefore, we can
    expect it to be even faster than the baseline implementation as the output file
    becomes larger.
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! We now know how to improve the performance of our beloved CLI application
    and we have made our users happy.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the various areas of performance optimization,
    we learned techniques to identify performance hot spots and hot paths, and we
    saw how to improve their performance, with the ultimate goal of offering our users
    a great and efficient application that they will love to use.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, you have understood that there is not one single area or action that
    leads to better performance, but rather a series of fine-tuning here and there
    that do the trick.
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! So, we have an application that efficiently provides great functionality.
  prefs: []
  type: TYPE_NORMAL
- en: There is, however, one key area that we have not yet covered when it comes to
    building CLI applications (and, for that matter, any kind of application). That
    key area is **security**, and this is the topic of the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Your turn!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Following along with the provided code is a great way to learn through practice.
  prefs: []
  type: TYPE_NORMAL
- en: A better way is by challenging yourself to achieve tasks. Hence, I challenge
    you to improve the Bookmarkr application by adding the following features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Task #1 – Write more benchmarks'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we have illustrated writing benchmark methods by only writing
    a benchmark for the `export` command. However, as we mentioned earlier, benchmarks
    do not only apply to commands, but they can also apply to services.
  prefs: []
  type: TYPE_NORMAL
- en: That’s why you are tasked with writing additional benchmark methods for each
    command and for the services used by the Bookmarkr application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Task #2 – Fine-tune Bookmarkr for optimal performance'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this chapter, we haven’t implemented every performance optimization
    opportunity, and we have probably missed some (was that intentional? *wink wink*).
    Therefore, you are tasked with identifying other potential performance optimizations
    in Bookmarkr and implementing them.
  prefs: []
  type: TYPE_NORMAL
