<html><head></head><body>
<div><h1 class="chapterNumber"><a id="_idTextAnchor151"/>7</h1>
<h1 class="chapterTitle" id="_idParaDest-114"><a id="_idTextAnchor152"/>Microservices in Practice</h1>
<p class="normal">This chapter is dedicated to the practical implementation of each microservice that exists after the design of the general application architecture and after that all interfaces of all Microservices have been defined. The interaction between, and orchestration of, microservices will be detailed in the remaining chapters of this book. </p>
<p class="normal">All concepts will be illustrated with the example of a worker microservice taken from the book’s case study application that we introduced in the <a id="_idTextAnchor153"/><em class="italic">Car-sharing example </em>subsection of<em class="italic"> </em><a href="Chapter_2.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>,<em class="italic"> Demystifying Microservices Applications</em>. </p>
<p class="normal">After a short description of the example worker microservice specifications, we will describe how to design microservices’ input and output communication subsystems, and how to organize the microservice request-serving logic. </p>
<p class="normal">Finally, we will discuss the details of how to implement a microservice with the Onion Architecture project templates introduced in the <em class="italic">A solution template based on the Onion Architecture </em>section of<em class="italic"> </em><a href="Chapter_3.xhtml#_idTextAnchor067"><em class="italic">Chapter 3</em></a>, <em class="italic">Setup and Theory: Docker and Onion Architecture</em>. </p>
<p class="normal">More specifically, this chapter covers the following:</p>
<ul>
<li class="bulletList"><a id="_idTextAnchor154"/>The route-planning microservice of the car-sharing application</li>
<li class="bulletList">Microservice basic design</li>
<li class="bulletList"><a id="_idTextAnchor155"/>Ensuring resilient communication with Polly</li>
<li class="bulletList">From abstraction to implementation details</li>
</ul>
<h1 class="heading-1" id="_idParaDest-115"><a id="_idTextAnchor156"/>Technical requirements</h1>
<p class="normal">This chapter requires the following:</p>
<ol>
<li class="numberedList" value="1">Visual Studio 2022, at least the free <em class="italic">Community </em>edition. </li>
<li class="numberedList">A SQL instance that accepts TCP/IP requests and user/password authentication since it must communicate with clients running inside Docker containers. Please note that the SQL instance that comes with the Visual Studio installation doesn’t support TCP/IP, so you need to either install SQL Express or use a cloud instance. For local installation, both the installer and instructions are available here: <a href="https://www.microsoft.com/en-US/download/details.aspx?id=104781">https://www.microsoft.com/en-US/download/details.aspx?id=104781</a>. You may also run the SQL Server Developer edition as a Docker image with the following code:
        <pre class="programlisting con-one"><code class="hljs-con">docker run -e "ACCEPT_EULA=Y" -e "MSSQL_SA_PASSWORD=yourStrong(!)Password" -p 1433:1433 -d mcr.microsoft.com/mssql/server:2022-latest
</code></pre>
</li>
<li class="numberedList">The username corresponding to the chosen password will be <code class="inlineCode">sa</code>.</li>
<li class="numberedList">Docker Desktop for Windows (<a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a>).</li>
<li class="numberedList">Docker <a id="_idIndexMarker345"/>Desktop, in turn, requires <strong class="keyWord">Windows Subsystem for Linux (WSL)</strong>, which can be installed by following these steps:<ol class="numberedList level-2" style="list-style-type: decimal;">
<li class="numberedList level-2" value="1">Type <code class="inlineCode">powershell</code> in the Windows 10/11 search bar.</li>
<li class="numberedList level-2">When <strong class="screenText">Windows PowerShell</strong> is proposed as a search result, click on <strong class="screenText">Run as an administrator</strong>.</li>
<li class="numberedList level-2">In the Windows PowerShell administrative console that appears, run the <code class="inlineCode">wsl --install</code> command.</li>
</ol>
</li>
</ol>
<p class="normal">You can find the sample code for this chapter at <a href="https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp">https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp</a>.</p>
<h1 class="heading-1" id="_idParaDest-116"><a id="_idTextAnchor157"/>The route-planning microservice of the car-sharing application </h1>
<p class="normal">In this <a id="_idIndexMarker346"/>section, we describe our example microservice, how to handle security, and how to prepare the solution for its implementation into three separate subsections.</p>
<h2 class="heading-2" id="_idParaDest-117"><a id="_idTextAnchor158"/>Microservice specifications</h2>
<p class="normal">The <a id="_idIndexMarker347"/>route-planning microservice stores and matches pending requests to move from one town to another with existing routes that are still open to other participants. </p>
<p class="normal">When an opened route of a car owner is created, it is matched with requests whose start and end towns are close to the car owner’s route and whose date constraints are compatible. If matches are found, a proposal to modify the route to include them is created and sent to other interested microservices. A symmetric operation is also done when a new request is inserted.</p>
<p class="normal">When a proposal to extend the route is accepted, the original route is extended.</p>
<p class="normal">After the initial match attempt, both requests and routes are stored for possible future matches. Requests and routes are removed or modified under the following circumstances:</p>
<ol>
<li class="numberedList" value="1">A route is removed from possible matches when it is closed to new participants or aborted. </li>
<li class="numberedList">A route is extended when it is merged with some requests. No new matches are attempted as a consequence of this operation.</li>
<li class="numberedList">A request is removed from possible matches when it is merged with a route.</li>
<li class="numberedList">A request becomes available again when the route it was merged with is aborted. After this operation, new matches are attempted.</li>
<li class="numberedList">Both requests and routes are deleted <em class="italic">N</em> days after their maximum travel day expires, where <em class="italic">N</em> is a parameter to be provided.</li>
</ol>
<p class="normal">Matches between routes and requests are done when the following circumstances are met:</p>
<ol>
<li class="numberedList" value="1">The route date falls between the minimum and maximum dates associated with the request.</li>
<li class="numberedList">Both the request start and end towns are close enough to the route.</li>
</ol>
<p class="normal">We will implement most microservice-to-microservice communication with the publisher/subscriber pattern in order to maximize microservice decoupling. This choice will also minimize the overall communication-related code, since message handlers and their client libraries take care of most of the asynchronous communication problems. Please refer to the <em class="italic">Event-based communications </em>subsection of<em class="italic"> </em><a href="Chapter_2.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Demystifying Microservices Applications</em>, for more details on event-based communication.</p>
<p class="normal">Moreover, in order to maximize application portability, we will use the <strong class="keyWord">RabbitMQ</strong> message broker, which is not <a id="_idIndexMarker348"/>tied to a specific platform or cloud but can be installed in any Kubernetes-based network with an adjustable number of replicas. <strong class="keyWord">RabbitMQ</strong> will be described in a dedicated subsection of the next section.</p>
<p class="normal">Since the car-sharing application doesn’t exchange heavy messages, we may avoid non-standard binary <a id="_idIndexMarker349"/>serializations such as <strong class="keyWord">gRPC Protobuf</strong> and opt for a simple <strong class="keyWord">JSON</strong> message serialization.</p>
<div><p class="normal">Most web servers and communication libraries can be configured to automatically compress JSON data. Web servers negotiate compression with the client.</p>
</div>
<p class="normal">Finally, since our worker microservice in-out communication is based on message brokers and not <a id="_idIndexMarker350"/>on the usual <strong class="keyWord">HTTP </strong>and <strong class="keyWord">gRPC</strong> ASP.NET Core <a id="_idIndexMarker351"/>protocols, we might consider the ad hoc <strong class="screenText">Worker service</strong> project template <a id="_idIndexMarker352"/>based on the so-called <strong class="keyWord">hosted services</strong> (<strong class="keyWord">hosted services</strong> will be <a id="_idIndexMarker353"/>discussed in the next section). However, microservices best practices prescribe that each microservice should expose an HTTP endpoint to verify its health status, so we will adopt a minimal API-based ASP.NET Core Web API<strong class="screenText"> </strong>project since it also supports the hosted services that we need for receiving message-broker-based communication.</p>
<p class="normal">Having clarified the microservice responsibilities, we can move on to security considerations.</p>
<h2 class="heading-2" id="_idParaDest-118"><a id="_idTextAnchor159"/>Handling security and authorization </h2>
<p class="normal">The authorization of requests coming from actual users is handled with the usual ASP.NET Web API techniques, that is, with <a id="_idIndexMarker354"/>web tokens (typically a <strong class="keyWord">JSON bearer token</strong>) and <code class="inlineCode">Authorize</code> attributes. Web tokens are provided by the login and token-renew <a id="_idIndexMarker355"/>endpoints of a specialized microservice that acts as the authorization server.</p>
<p class="normal">Requests coming from other services instead are usually secured with mTLS, that is, with certificate-based client authentication. Client certificates are handled by the lower-level TCP/IP protocol together with the server certificate used for encrypting the HTTPS communication. Then, the information extracted by the client certificate is passed to the ASP.NET Core authentication middleware to create a <code class="inlineCode">ClaimsPrincipal </code>(the usual ASP.NET Core <strong class="keyWord">User</strong> object). When the application runs within an orchestrator, it is also possible to use orchestrator-specific authorization, and when the application runs in the cloud, it is possible to use cloud-specific authorization.</p>
<div><p class="normal">Luckily, if both communicating microservices are exposed in a private network, or better, in a private network handled by a microservices orchestrator, we may replace user authentication with firewall rules and/or with other communication-securing facilities offered by the orchestrator. </p>
</div>
<p class="normal">We will analyze the Kubernetes orchestrator in <a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>, and its communication-securing facilities in <a href="Chapter_10.xhtml#_idTextAnchor297"><em class="italic">Chapter 10</em></a>, <em class="italic">Security and Observability for Serverless and Microservices Applications</em>. Even in a private network, it is recommended to encrypt internal communication using mTLS or other encryption methods to mitigate insider threats and network attacks, but for the sake of simplicity in this book, we will only secure communication with the outside world. </p>
<p class="normal">Therefore, if we adequately organize our private network, we need to secure just communication with the outside world, that is, communication with frontend microservices. However, as discussed in the <em class="italic">Interfacing the external world </em>subsection of<em class="italic"> </em><a href="Chapter_2.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Demystifying Microservices Applications</em>, microservices-based applications use API gateways to communicate with the external world. In the simplest case, the interface with the external world <a id="_idIndexMarker356"/>is just a load-balanced web server that performs HTTPS termination, that is, that receives HTTPS communications from the external world. While some architectures terminate HTTPS at the API gateway and use HTTP internally, it is recommended to maintain encryption within the private network using mTLS or re-encryption to ensure security within the microservices ecosystem. This way, we may use just a single HTTPS certificate for the whole application, thus avoiding the whole certificate issuing and renewal procedure for all microservices that compose the application.</p>
<div><p class="normal">Summing up, if we use any kind of HTTPS-termination interface to access the microservice application, we may avoid using HTTPS communication in all microservices.</p>
</div>
<p class="normal">Now we are ready to prepare the Visual Studio solution that will host the route-planning microservice!</p>
<h2 class="heading-2" id="_idParaDest-119"><a id="_idTextAnchor160"/>Creating the Visual Studio solution </h2>
<p class="normal">Since we decided to implement the outermost layer of our worker microservice with an ASP.NET <a id="_idIndexMarker357"/>Core Web API project, let’s create a <code class="inlineCode">CarSharing</code> Visual Studio solutio<a id="_idTextAnchor161"/>n containing an ASP.NET Core Web API<strong class="screenText"> </strong>project called <code class="inlineCode">RoutesPlanning</code>. The <strong class="screenText">ASP.NET Core Web API </strong>project can be easily found by selecting <strong class="screenText">C#</strong>, <strong class="screenText">All platforms</strong>, and<strong class="screenText"> Web API</strong> from the dropdowns of the Visual Studio project selection window, as shown here:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B31916_07_1.png"/> </figure>
<p class="packt_figref">Figure 7.1: Project selection</p>
<p class="normal">As <a id="_idIndexMarker358"/>discussed previously, we may avoid HTTPS communication, and worker microservices do not need authentication. However, we need Docker support since microservices are usually containerized. </p>
<p class="normal">Finally, we don’t need controllers but just a minimal API since we need to expose just a couple of trivial endpoints for health checks:</p>
<figure class="mediaobject"><img alt="Figure 7.2: Project settings" src="img/B31916_07_2.png"/></figure>
<p class="packt_figref">Figure 7.2: Project settings</p>
<p class="normal">We will <a id="_idIndexMarker359"/>use the Onion Architecture, so we need to also add a project for the application services and domain layer. Therefore, let’s add two more <strong class="screenText">Class Library</strong> projects, called <code class="inlineCode">RoutesPlanningApplicationServices</code> and <code class="inlineCode">RoutesPlanningDomainLayer</code>. We will adapt the Onion Architecture template introduced in the<em class="italic"> A solution template based on the Onion Architecture </em>section of<em class="italic"> </em><a href="Chapter_3.xhtml#_idTextAnchor067"><em class="italic">Chapter 3</em></a>, <em class="italic">Setup and Theory: Docker and Onion Architecture</em>.</p>
<p class="normal">Let’s open the <code class="inlineCode">OnionArchitectureComplete</code> project template, which you can find in the <code class="inlineCode">ch03</code> folder of the book’s GitHub repository. In the <code class="inlineCode">RoutesPlanningDomainLayer</code> project, delete the <strong class="screenText">Class1.cs</strong> file, select the three folders in the <code class="inlineCode">DomainLayer</code> project of the <code class="inlineCode">ch03</code> project template, copy them, and paste them into the <code class="inlineCode">RoutesPlanningDomainLayer</code> project. If you have the latest Visual Studio 2022 version installed, you should be able to perform the copy operation from within Visual Studio Solution Explorer. Also, add a reference to the <code class="inlineCode">Microsoft.Extensions.DependencyInjection.Abstractions</code> NuGet package to the <code class="inlineCode">RoutesPlanningDomainLayer</code> project.</p>
<p class="normal">Then, perform the analogous operations on the <code class="inlineCode">RoutesPlanningApplicationServices</code> and <code class="inlineCode">ApplicationServices</code> projects.</p>
<p class="normal">Now that you have all the Onion Architecture files in place, you need to add just a reference to <code class="inlineCode">RoutesPlanningDomainLayer</code> in <code class="inlineCode">RoutesPlanningApplicationServices</code> and a reference to <code class="inlineCode">RoutesPlanningApplicationServices</code> in <code class="inlineCode">RoutesPlanning</code>. </p>
<p class="normal">After the last operation, your solution should compile, but we have not finished preparing our solution yet. We need to also add an <strong class="keyWord">Entity Framework Core</strong>-based library in order to provide an implementation driver for our domain layer. </p>
<p class="normal">Let’s <a id="_idIndexMarker360"/>add a new class library project and call it <code class="inlineCode">RoutesPlanningDBDriver</code>. Add references to the <code class="inlineCode">Microsoft.EntityFrameworkCore.SqlServer</code> and <code class="inlineCode">Microsoft.EntityFrameworkCore.Tools</code> Nuget packages, and to the <code class="inlineCode">RoutesPlanningDomainLayer</code> project.</p>
<p class="normal">After that, delete the <strong class="screenText">Class1.cs</strong> file and replace it with all code files and folders from the <code class="inlineCode">DBDriver</code> project of the <code class="inlineCode">ch03</code> project template.</p>
<pre>RoutesPlanning</code> <code class="inlineCode">Program.cs</code> file:</pre>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddOpenApi();
//Code snippet start
builder.Services.AddApplicationServices();
builder.Services.AddDbDriver(
    builder.Configuration?.GetConnectionString("DefaultConnection") ?? string.Empty);
//Code snippet end
</code></pre>
<p class="normal"><code class="inlineCode">RoutesPlanning</code> needs a reference to <code class="inlineCode">RoutesPlanningDBDriver</code> because the outermost layer of an Onion Architecture must reference all implementation-specific drivers. <code class="inlineCode">AddApplicationServices</code> adds all queries, commands, and event handlers to the dependency injection engine, while <code class="inlineCode">AddDbDtiver</code> adds all repository implementations and the <code class="inlineCode">IUnitOfWork</code> implementation to the dependency injection.</p>
<p class="normal">For more information on the Onion Architecture project template that we used to prepare our solution, please refer to the <em class="italic">A solution template based on the Onion Architecture </em>section of<em class="italic"> </em><a href="Chapter_3.xhtml#_idTextAnchor067"><em class="italic">Chapter 3</em></a>, <em class="italic">Setup and Theory: Docker and Onion Architecture</em>.</p>
<p class="normal">Now, our solution is finally ready! We can start designing our worker microservice!</p>
<h1 class="heading-1" id="_idParaDest-120"><a id="_idTextAnchor162"/>Microservice basic design </h1>
<p class="normal">In this section, we will define all the main microservice abstractions, that is, the overall communication strategy, all Onion Architecture commands and events, and the top-level loops of the required hosted services. We will start with a description of the chosen message broker: <strong class="keyWord">RabbitMQ</strong>.</p>
<h2 class="heading-2" id="_idParaDest-121"><a id="_idTextAnchor163"/>The message broker: RabbitMQ</h2>
<p class="normal">Natively, RabbitMQ <a id="_idIndexMarker361"/>supports the <strong class="keyWord">AMQP</strong> asynchronous message protocol, which is one of the most used asynchronous protocols, the other being <strong class="keyWord">MQTT</strong>, which has a specific syntax <a id="_idIndexMarker362"/>for the publisher/subscriber pattern. Support for <strong class="keyWord">MQTT</strong> can be added with a plugin, but RabbitMQ has facilities for easily implementing a publisher/subscriber pattern on top of <strong class="keyWord">AMQP</strong>. Moreover, RabbitMQ offers several tools to support scalability, disaster recovery, and redundancy, so it fulfills all requirements to be a first-class actor in cloud and microservices environments. More specifically, by defining a RabbitMQ cluster, we may achieve both load balancing and data replication which is required in most SQL and NoSQL databases. </p>
<p class="normal">In this section, we will just describe RabbitMQ’s basic operation, while the installation and usage of RabbitMQ clusters in Kubernetes will be discussed in <a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>. You can find more details in the tutorials and documentation <a id="_idIndexMarker363"/>on the RabbitMQ official website: <a href="https://www.rabbitmq.com/">https://www.rabbitmq.com/</a>. </p>
<p class="normal">RabbitMQ messages must be prepared in binary format, since RabbitMQ messages must be just an array of bytes. However,<a id="_idTextAnchor164"/> we will use the <strong class="keyWord">EasyNetQ</strong> client, which takes care of object serialization and of most <a id="_idIndexMarker364"/>of the client-server wiring and error recovery. <strong class="keyWord">EasyNetQ</strong> is a NuGet <a id="_idIndexMarker365"/>package built on top of RabbitMQ’s low-level <strong class="keyWord">RabbitMQ.Client</strong> NuGet client, which makes the usage of RabbitMQ easy while reducing the communication-code overhead and enhancing its modularity and modifiability.</p>
<p class="normal">Once sent to RabbitMQ, messages are placed in <strong class="keyWord">queues</strong>. More specifically, they are placed in one or more <strong class="keyWord">queues </strong>by passing <a id="_idIndexMarker366"/>through other entities, called <strong class="keyWord">exchanges</strong>. The exchanges route the messages to <strong class="keyWord">queues</strong> using a routing strategy that depends on the <strong class="keyWord">exchange</strong> type. Exchanges are an <strong class="keyWord">AMQP</strong>-specific concept, and they are the RabbitMQ way to configure complex communication protocols like the publishing/subscriber protocol, as shown in the following figure: </p>
<figure class="mediaobject"><img alt="Figure 7.3: RabbitMQ exchanges" src="img/B31916_07_3.png"/></figure>
<p class="packt_figref">Figure 7.3: RabbitMQ exchanges</p>
<p class="normal">By adequately <a id="_idIndexMarker367"/>defining the exchange routing strategy, we can <a id="_idIndexMarker368"/>implement several patterns. More specifically, the following apply:</p>
<ul>
<li class="bulletList">When we use a <strong class="keyWord">default exchange</strong>, the message is sent to a single queue and we can implement asynchronous direct calls.</li>
<li class="bulletList">When we use a <strong class="keyWord">fanout exchange</strong>, the exchange will send the messages to all queues that subscribe to that exchange. This way, we can implement the publisher/subscriber pattern. </li>
</ul>
<p class="normal">There is also a <strong class="keyWord">topic exchange</strong>, which enhances the publisher/subscriber pattern by enabling the matching of named event subclasses called topics. Matching between receivers and topics also supports wildcard chars. We will describe its practical usage with enterprise microservices in the <em class="italic">Ensuring that messages are processed in the proper order</em> subsection.</p>
<p class="normal">Whenever several receivers are attached to the same queue, messages are equally distributed among them according to a round-robin pattern. This is the case of <em class="italic">N</em> identical replicas of the same microservice. Therefore, replicas are automatically load-balanced by RabbitMQ.</p>
<p class="normal">Luckily, <strong class="keyWord">EasyNetQ</strong> directly exposes the publish/subscribe protocol (possibly enriched with topics) and the direct call protocol, together with a request/response asynchronous RPC protocol, taking care of creating and connecting all needed queues and exchanges. Details on how to use <strong class="keyWord">EasyNetQ</strong> will be <a id="_idIndexMarker369"/>provided when describing the code of our route-planning microservice.</p>
<p class="normal">The easiest way to install RabbitMQ is by using its Docker image. We will adopt this option since all our microservices will also be containerized, and since in the final Kubernetes version of the overall application, we will use containerized RabbitMQ clusters.</p>
<p class="normal">We can just run the following command in a Linux shell:</p>
<pre class="programlisting con"><code class="hljs-con">docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:4.0-management
</code></pre>
<p class="normal">Since we <a id="_idIndexMarker370"/>provided the <code class="inlineCode">-it</code> flags, after the image is downloaded and the container is <a id="_idIndexMarker371"/>created and started, the Linux shell remains blocked in the container filesystem. Moreover, since we also added the <code class="inlineCode">–-rm</code> option, the container is destroyed as soon as it is stopped with the following line:</p>
<pre class="programlisting con"><code class="hljs-con">docker stop rabbitmq
</code></pre>
<p class="normal">In order to verify that RabbitMQ is working properly, please navigate to <a href="http://localhost:15672">http://localhost:15672</a>. The RabbitMQ management console should appear. You can log in with the startup credentials, which are <code class="inlineCode">guest</code><strong class="screenText"> </strong>for both the username and password.</p>
<p class="normal">You don’t need to leave the container running; you can stop it and re-execute the <code class="inlineCode">run</code> command when you need RabbitMQ to test the microservice code.</p>
<p class="normal">The disk space needed by RabbitMQ is mounted as a Docker volume with the following volume statement directly inserted in the <code class="inlineCode">Dockerfile</code> image:</p>
<pre class="programlisting code"><code class="hljs-code">VOLUME /var/lib/rabbitmq
</code></pre>
<p class="normal">This means that the disk content is reset when the container is destroyed and run again. Therefore, if you want to keep the disk content, avoid running the container with the <code class="inlineCode">–-rm</code> option, so it will not be destroyed when it is stopped.</p>
<p class="normal">If you need customized credentials, please add the following environment variables to the <code class="inlineCode">run</code> command:</p>
<pre class="programlisting con"><code class="hljs-con">-e RABBITMQ_DEFAULT_USER=my_user_name -e RABBITMQ_DEFAULT_PASS=my_password
</code></pre>
<div><p class="normal">This is necessary when RabbitMQ is accessed outside of <code class="inlineCode">localhost</code>, because in this case, the default username and password are not accepted for security reasons.</p>
</div>
<p class="normal">Now, we can move on to designing the input and output messages of our worker microservices.</p>
<h2 class="heading-2" id="_idParaDest-122"><a id="_idTextAnchor165"/>Input communication</h2>
<p class="normal">Since classes that represent intra-microservices messages must be known to both clients and servers, the best <a id="_idIndexMarker372"/>option is defining them during the initial microservices external interfaces design and placing them in one or more shared libraries. Since our <a id="_idIndexMarker373"/>project contains a reasonably small number of microservices, we may assume that all messages are visible to all microservices, so we can use a single shared library.</p>
<p class="normal">However, in more complex scenarios containing hundreds or thousands of microservices, their organization must be hierarchical, so we will have level 0 messages, known to all microservices; level 1 messages, known just within level 1 groups of microservices, and so on.</p>
<p class="normal">Let’s add a new <strong class="screenText">Class Library</strong> project called <code class="inlineCode">SharedMessages</code> to our solution, and we’ll select <strong class="screenText">standard 2.1</strong> for its version. Then, let’s add a reference to this new project to the <code class="inlineCode">RoutesPlanningApplicationServices</code> project. We will place all application messages here.</p>
<p class="normal">From the specifications of the route-planning microservice, we have just four messages:</p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord">New<a id="_idTextAnchor166"/> request</strong>: It will contain a unique request identifier, an interval of acceptable travel dates, and two unique identifiers for the start and arrival towns, their display names, and their latitude and longitude. Moreover, it will contain a unique identifier representing the user that issued the request and their display name.</li>
<li class="numberedList"><strong class="keyWord">New route</strong>: It will contain a unique route identifier, a travel date, and two unique identifiers representing the start and arrival towns, their display names, and their latitude and longitude. Moreover, it will contain a unique identifier representing the car owner that issued the route proposa<a id="_idTextAnchor167"/>l and their display name.</li>
<li class="numberedList"><strong class="keyWord">Route closed/aborted</strong>: It will contain just the unique route identifier and a flag specifying whether the route was succes<a id="_idTextAnchor168"/>sfully closed or aborted.</li>
<li class="numberedList"><strong class="keyWord">Route extension</strong>: It informs that the car owner accepted extending the route with the start and ending towns of other requests. It contains the same information contained in the new route message as well as new request messages.</li>
</ol>
<p class="normal-one">It also contains a flag that specifies whether, after the extension, the route has been closed to other participants.</p>
<p class="normal">The message content might appear redundant for the route-planning microservice. For instance, most of the information contained in the route extension message is already known to the route-planning microservice. As a matter of fact, the route-planning microservice needs just the unique identifiers of the request and route to join. </p>
<p class="normal">However, messages sent with the publisher/subscriber pattern are used by several potentially unknown subscribers, so they can’t assume specific a priori knowledge of the subscribers. For instance, the route extension message will also be subscribed by the microservice that handles all requests that don’t contain information about all existing route proposals, so all information needed <a id="_idIndexMarker374"/>on the merged route must be received through this message. </p>
<p class="normal">On the contrary, the route <a id="_idIndexMarker375"/>closed/aborted message doesn’t need to convey the whole route information, since any service interested in the event must already know of this route and must already have all the data it needs about it. It might lack this data if it has never interacted with this route, but in this case, the event represented by the message can’t modify its state and must simply be ignored.</p>
<p class="normal">An important question we must always ask about all microservices input is: what happens if the messages arrive in the wrong order, that is, in a different order than they were sent? If the message order matters, we either ensure that all messages arrive and are processed in the right order or we reorder messages with the technique explained in the <em class="italic">Efficacious handling of asynchronous communication </em>subsection of <a href="Chapter_2.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Demystifying Microservices Applications</em>. Unfortunately, reordering input messages is not enough; we must also process them in the right order. </p>
<p class="normal">This is not a trivial task if several replicas of the same microservice process these input messages concurrently. Luckily, no application needs a fixed ordering for all input messages. But some <em class="italic">related messages</em>, for instance, all messages that contain the same route, must be processed in the right order. Therefore, we can avoid <em class="italic">just</em> concurrent processing of <em class="italic">related messages</em> by passing all related messages to the same replica. We will analyze techniques for achieving a similar load-balancing strategy of all replicas in the <em class="italic">Ensuring that messages are processed in the proper order</em> section.</p>
<p class="normal">In our case, the order in which new route offers and route requests arrive is not an issue, since we can correctly process out-of-order messages with simple tricks. We just need to add an update version number to detect past updates. Update version numbers must be unique and must correspond to the real order in which updates were applied to a given entity. When the entity is created, it starts with version 0, and then this number is incremented at each new update.</p>
<div><p class="normal">As a general rule, if all modification and creation messages contain the entire entity data, and if all deletes are logical, that is, entities are just marked as deleted, then messages don’t need to be ordered. </p>
</div>
<p class="normal"> </p>
<p class="normal">In fact, we can recognize and apply an incoming modification only if it is more recent than the one already applied. Moreover, we can always verify whether the entity mentioned in a modification message has already been deleted and discard the modification. Finally, if an entity mentioned in a modification has not already been created, we can always create it with the data contained in the modification message, since each modification contains the entire entity data. </p>
<p class="normal">In our case, the order of the route extension messages doesn’t matter, because request merged to a route <a id="_idIndexMarker376"/>simply sum up and it is enough to <a id="_idIndexMarker377"/>select the more recent list of towns of the one stored in the route and the one contained in the message.</p>
<p class="normal">Inversions of route extensions and route closed/aborted messages do not cause problems, too, since it is enough to ignore extensions of aborted routes, and to merge previous requests that arrived after the closure. </p>
<p class="normal">Inversions of route creations and extensions can never take place, since only successfully created routes can cause request-route matches that can subsequently cause route extensions.</p>
<p class="normal">Deleted routes do not cause problems since both route aborted and closed messages are de facto logical deletes. We can delete them after the travel day has expired by <em class="italic">N</em> days, since at that point, previous delayed messages can’t arrive (messages can be delayed by some hours or even a day in the case of severe failures). This can be done with cron jobs.</p>
<p class="normal">Possible duplication of messages due to timeouts and resends also do not cause problems since they can always be recognized and ignored. As an exercise, you can analyze all possibilities in detail.</p>
<p class="normal">All required messages can be easily defined in terms of some basic types that we will place in a <code class="inlineCode">BasicTypes</code> folder of the <code class="inlineCode">SharedMessages</code> project. They are as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public class GeoLocalizationMessage
{
    public double Latitude { get; set; }
    public double Longitude { get; set; }
}
public class TimeIntervalMessage
{
    public DateTime Start {  get; set; }
    public DateTime End { get; set; }
}
public class UserBasicInfoMessage
{
    public Guid Id { get; set; }
    public string? DisplayName { get; set; }
}
public class TownBasicInfoMessage
{
    public Guid Id { get; set; }
    public string? Name { get; set; }
    public GeoLocalizationMessage? Location { get; set; }
}
</code></pre>
<p class="normal">Moreover, since all <a id="_idIndexMarker378"/>messages must contain an update time, we may let all <a id="_idIndexMarker379"/>of them inherit from the following class:</p>
<pre class="programlisting code"><code class="hljs-code">public class TimedMessage
{
    public long TimeStamp { get; set; }
}
</code></pre>
<p class="normal">Let’s place this class in the <code class="inlineCode">BasicTypes</code> folder, too. </p>
<p class="normal">Now, all messages can be defined as follows: </p>
<ol>
<li class="numberedList" value="1"><strong class="keyWord">New request</strong>:
        <pre class="programlisting code-one"><code class="hljs-code">public class RouteRequestMessage: TimedMessage
{
    public Guid Id { get; set; }
    public TownBasicInfoMessage? Source { get; set; }
    public TownBasicInfoMessage? Destination { get; set; }
    public TimeIntervalMessage? When { get; set; }
    public UserBasicInfoMessage? User { get; set; }
}
</code></pre>
</li>
<li class="numberedList"><strong class="keyWord">New route</strong>:
        <pre class="programlisting code-one"><code class="hljs-code">public class RouteOfferMessage: TimedMessage
{
    public Guid Id { get; set; }
    public IList&lt;TownBasicInfoMessage&gt;? Path { get; set; }
    public DateTime? When { get; set; }
    public UserBasicInfoMessage? User { get; set; }
}
</code></pre>
</li>
<li class="numberedList"><strong class="keyWord">Route closed/aborted</strong>:
        <pre class="programlisting code-one"><code class="hljs-code">public class RouteClosedAbortedMessage: TimedMessage
{
    public Guid RouteId { get; set; }
    public bool IsAborted { get; set; }
}
</code></pre>
</li>
<li class="numberedList"><strong class="keyWord">Route extension</strong>:
        <pre class="programlisting code-one"><code class="hljs-code">public class RouteExtendedMessage: TimedMessage
{
    public RouteOfferMessage? ExtendedRoute {  get; set; }
    public IList&lt;RouteRequestMessage&gt;? AddedRequests { get; set; }
    public bool Closed { get; set; }
}
</code></pre>
</li>
</ol>
<p class="normal">Place them <a id="_idIndexMarker380"/>in a <code class="inlineCode">SharedMessages</code> project folder <a id="_idIndexMarker381"/>called <code class="inlineCode">RouteNegotiation</code>.</p>
<p class="normal">We have just <a id="_idIndexMarker382"/>finished with the microservice input design! Let’s move on to the output.</p>
<h2 class="heading-2" id="_idParaDest-123"><a id="_idTextAnchor169"/>Output communication</h2>
<p class="normal">The output of the route-planning microservice consists of proposals to augment routes with matching requests. These <a id="_idIndexMarker383"/>proposals must be accepted by the users that <a id="_idIndexMarker384"/>own the routes. A single route extension message contains the unique identifier of the route and all its newly discovered matching requests:</p>
<pre class="programlisting code"><code class="hljs-code">public class RouteExtensionProposalsMessage: TimedMessage
{
    public Guid RouteId { get; set; }
    public IList&lt;RouteRequestMessage&gt;? Proposals { get; set; }
}
</code></pre>
<p class="normal">Let’s place this class in the <code class="inlineCode">RouteNegotiation</code> folder of the <code class="inlineCode">SharedMessages</code> project.</p>
<p class="normal">Please notice that the timestamp associated with this message is the more recent timestamp associated with the route that this worker microservice received. In fact, this microservice doesn’t perform actual route updates, but just computes update proposals, which might be turned intoactual updates by another microservice. </p>
<div><p class="normal">As a rule of thumb, all updates to an entity must be performed on a single database replica. This way, computing entity versions becomes a feasible task that requires just a simple database transaction. Otherwise, each update should be coordinated among <em class="italic">N</em> different microservices with a complex distributed transaction. Therefore, if several microservices have different views of the same conceptual entity in their databases, each of them can change the entity private data it uses without needing to version them. But there should be a single microservice that is in charge of updating all shared properties of the entity, versioning them, and sending them to all interested microservices.</p>
</div>
<p class="normal">Unfortunately, sometimes distributed transactions are unavoidable, but still, in these cases, a single microservice replica proposes a new version number that is accepted by all microservices involved in the transaction if the transaction succeeds.</p>
<p class="normal">Output messages <a id="_idIndexMarker385"/>can be placed in an internal queue <a id="_idIndexMarker386"/>implemented with permanent storage immediately after their creation, as explained in the <em class="italic">Efficacious handling of asynchronous communication</em> section of <a href="Chapter_2.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Demystifying Microservices Applications</em>. However, if we use a broker, that strategy needs to be modified a little bit. There, we applied an exponential retry strategy, by retrying the failed messages after an exponentially increasing time, while continuing to send other messages from the internal queue. When messages are not mediated by a message broker, this strategy makes sense, since the failure is connected either to the destination or to some component in the path between the source and destination. So, if the next message has a different destination, it would probably succeed.</p>
<p class="normal">If we use a message broker, the failure depends on the message broker itself since the confirmation simply states that the message broker successfully received the message, not that the message was received and confirmed by the destination. Therefore, immediately attempting a new message transmission would probably result in another failure. </p>
<p class="normal">We may conclude that when communication is mediated by a message broker, we don’t need to delay the single faulty message; instead, we must stop sending messages to the message broker applying both exponential retry and circuit break strategies. Moreover, since keeping too many threads waiting for confirmations might congest the system, we must also apply a Bulkhead Isolation strategy to limit the number of pending tasks. </p>
<p class="normal">At this point, you might ask: why do we need an internal queue if we already have the message broker external queue? There are two reasons; the first one, in particular, is quite compelling:</p>
<ol>
<li class="numberedList" value="1">The internal queue is implemented with a database table, so it is populated in the same database transaction as the database update that triggered the output event. Therefore, if something goes wrong, the whole transaction is aborted, thus giving the possibility to retry it at a later time. </li>
<li class="numberedList">The performance cost for achieving the same result directly with the message broker queue is higher: we should keep the database transaction open until we receive a confirmation, an error, or a timeout from the message transmission to the message broker. This time becomes several orders of magnitude higher if we use exponential retry.</li>
<li class="numberedList">Once the message is in the internal queue, in case of failures, we don’t need to undo the database update but we need simply to retry the message transmission at a later time.</li>
<li class="numberedList">Due to the different <a id="_idIndexMarker387"/>ways databases and message brokers are <a id="_idIndexMarker388"/>implemented, and due to the fact that the database is shared just by the microservice replicas, the confirmation of the successful execution of the whole database transaction (required update plus registration of the output message in the internal queue) is faster than the message broker confirmation.</li>
</ol>
<p class="normal">Now that we have clarified how to handle both input and output messages, in general and for our route-planning microservice, we can discuss how to recover and maint<a id="_idTextAnchor170"/>ain the proper message-processing order.</p>
<h2 class="heading-2" id="_idParaDest-124"><a id="_idTextAnchor171"/>Ensuring that messages are processed in the proper order</h2>
<p class="normal">As discussed in the previous subsections, our route-planning microservice doesn’t need to enforce the <a id="_idIndexMarker389"/>correct message-processing order. However, there are cases where processing all messages in the right order is unavoidable, so in this <a id="_idIndexMarker390"/>subsection, we will discuss how they are usually handled.</p>
<p class="normal">It is worth pointing out that strategies for enforcing the right message-processing order have a non-negligible impact on performance and scalability, so any trick to avoid their usage is welcome.</p>
<p class="normal">Usually, order constraints must be enforced just within the same group of related messages, so it is enough to ensure the following:</p>
<ol>
<li class="alphabeticList" value="1">All messages belonging to the same group of related messages are processed by the same microservice replica, so concurrence between replicas can’t shuffle the message-processing order.</li>
<li class="alphabeticList">Each replica processes a message only after all previous messages have been successfully processed. </li>
</ol>
<p class="normal">Proper operation of the preceding technique requires that each message contains its sequence number in its group.</p>
<p class="normal">Often, groups coincide with database entities, or better, with database aggregates. That is, two messages belong to the same group if they represent different operations performed on the same entity. Thus, in the case of our route-planning service, we might have a group for each request and for each route. </p>
<p class="normal">Now suppose that <a id="_idIndexMarker391"/>that there are <em class="italic">N</em> microservice replicas, indexed by the integers from 1 to <em class="italic">N</em>. We can define a hash function that, given a <a id="_idIndexMarker392"/>group identifier, returns a number between 1 and <em class="italic">N</em>. This way, if we route each message to the replica indexed by the result of the hash function applied to the group of the message, all messages in the same group will be processed by the same replica. The following figure exemplifies the message-routing strategy:</p>
<figure class="mediaobject"><img alt="Figure 7.4: Message sharding" src="img/B31916_07_4.png"/></figure>
<p class="packt_figref">Figure 7.4: Message sharding</p>
<p class="normal">This technique <a id="_idIndexMarker393"/>is called <strong class="keyWord">sharding</strong>, and if the hash function is fair, each replica will receive the same <em class="italic">average</em> load. </p>
<div><p class="normal">Thus, if we have no order constraints, we achieve exact load-balancing with a round-robin strategy, while with order constraints, we can just achieve <em class="italic">average</em> load-balancing with sharding. This means that probabilistic balancing fluctuations will for sure cause temporary congestion.</p>
</div>
<p class="normal">Sharding will also cause a loss of flexibility in scaling the number of replicas. In fact, changing the number of replicas changes both the hash function and the group of messages received by each replica. For these reasons, scaling operations will have a higher cost and consequently can be performed less frequently. In practice, most orchestrators automatically scale non-indexed replicas according to customizable criteria, but don’t offer the same service for replicas that need to be indexed. We will analyze in more detail the difference between these different sets of replicas and automating scaling in <a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>.</p>
<p class="normal">Sharding can be implemented with a single-replica microservice that receives all messages from the message broker and routes them to the appropriate replicas by sending them to a replica-specific <a id="_idIndexMarker394"/>message broker queue. This technique is more complex and requires more coding, but it is more flexible. In fact, for instance, if it is <a id="_idIndexMarker395"/>informed by changes in the number of replicas, it can dynamically adapt its behavior to the number of replicas.</p>
<p class="normal">Sharding can also be achieved with RabbitMQ topics. Basically, a topic is a string attached to a message, and event subscribers can be enabled just for some topics. Therefore, if we attach the result of the hash function to each message as a topic, then each replica can subscribe just to the topic equal to its index, thus implementing sharding with no need for an extra component. </p>
<p class="normal">The disadvantage of the topic-based sharding technique is that the number of replicas must be known to all senders and can be changed just by restarting the whole application. Moreover, since the topic to assign to each message depends on both how the destination microservice defines message groups and the destination microservice, the number of replicas technique can’t be used with the publisher/subscriber pattern where messages are received by several heterogeneous microservices.</p>
<p class="normal">RabbitMQ <a id="_idIndexMarker396"/>also has a sharding plugin (<a href="https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding">https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding</a>) that computes a modulo <em class="italic">N</em> hash. This plugin defines a new type of exchange with a sharding-based routing strategy that we can attach immediately before each separate subscriber queue. Moreover, the plugin takes care of splitting the unique subscriber queue into <em class="italic">N</em> different sharded queues and distributing all subscribers among the <em class="italic">N</em> sharded queue<a id="_idTextAnchor172"/>. This technique is completely analogous to the single-replica routing microservice technique, but being integrated inside the message broker requires trading reduced flexibility for better performance. This technique solves all the problems of the <a id="_idIndexMarker397"/>topics-based technique but is not supported by the high-level <strong class="keyWord">EasyNetQ</strong> interface, so it increases the code complexity and maintainability. Moreover, it requires a broker configuration that depends on the exact topology of all subscribers, thus undermining the application’s extensibility.</p>
<p class="normal">Summing up, when using publisher/subscriber communication, the best option is almost always the single-replica routing microservice technique.</p>
<p class="normal">Having discussed microservices input and output, we can now move on to the design of the microservice container input parameters.</p>
<h2 class="heading-2" id="_idParaDest-125"><a id="_idTextAnchor173"/>Designing Docker image environment parameters</h2>
<p class="normal">As already hinted at in the <em class="italic">A few more Docker commands and options </em>subsection of<em class="italic"> </em><a href="Chapter_3.xhtml#_idTextAnchor067"><em class="italic">Chapter 3</em></a>, <em class="italic">Setup and Theory: Docker and Onion Architecture</em>, containers usually adapt to their deployment <a id="_idIndexMarker398"/>environment by being passed as environment variables of the container’s virtual filesystem. In a .NET environment, parameters <a id="_idIndexMarker399"/>are available through the <code class="inlineCode">IConfiguration</code> interface together with all parameters defined in the .NET configuration files, such as <code class="inlineCode">appsettings.json</code>. Nested JSON paths are represented in the <code class="inlineCode">IConfiguration</code> dictionary arguments by separating all segments with colons, as is the case for <code class="inlineCode">IConfiguration[“ConnectionStrings:DefaultConnection”]</code>, which represents the usual default database connection string. When nested paths are represented by environment variables, colons are replaced with double underscores, in order to get valid environment variables names. Therefore, <code class="inlineCode">ConnectionStrings:DefaultConnection</code> must be defined with an environment variable named <code class="inlineCode">ConnectionStrings__DefaultConnection</code>. If environment variable names are prefixed with <code class="inlineCode">ASPNETCORE_</code> or <code class="inlineCode">DOTNET_</code>, these prefixes are removed; therefore, <code class="inlineCode">ASPNETCORE_ENVIRONMENT</code> can be accessed with <code class="inlineCode">IConfiguration[“ENVIRONMENT”]</code>. These prefixes are used to pass ASP.NET Core- and .NET-specific settings, such as staging, production, or development environment, and <code class="inlineCode">ASPNETCORE_HTTP_PORTS</code> is also used, which contains a semicolon-separated list of all ports that Kestrel must listen on.</p>
<p class="normal">You can also define your own custom prefix to apply to all your environment variables to avoid name collisions. However, since each microservice has a private container, collisions between environment variables used by different applications are impossible. Anyway, a new environment variable’s custom prefix can be defined inside the application services definition section with code analogous to the following:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Configuration.AddEnvironmentVariables(prefix: "MyCustomPrefix_");
</code></pre>
<p class="normal">As we will see in <a href="Chapter_8.xhtml#_idTextAnchor205"><em class="italic">Chapter 8</em></a>, <em class="italic">Practical Microservices Organization with Kubernetes</em>, defining configuration settings with environment variables allows the easy specification of their values in the code files for the chosen orchestrator.</p>
<p class="normal">During development, environment variable values can be specified in the <code class="inlineCode">Properties -&gt; launchSettings.json</code> file of the top-level project of the Onion Architecture, which, in our case, is the <code class="inlineCode">RoutesPlanning</code> project. The following snippet shows where to place your environment variable values:</p>
<pre class="programlisting code"><code class="hljs-code">"Container (Dockerfile)": {
"commandName": "Docker",
"launchUrl": "{Scheme}://{ServiceHost}:{ServicePort}",
"environmentVariables": {
"ASPNETCORE_HTTP_PORTS": "8080"
//place here your application specific environment variables
},
</code></pre>
<p class="normal">In our case, we need the following:</p>
<ol>
<li class="numberedList" value="1">The database connection string</li>
<li class="numberedList">The RabbitMQ connection string.</li>
<li class="numberedList">The maximum distance for proposing a match between a request and a route, and the maximum number of best matches to retrieve from the database.</li>
<li class="numberedList">The subscription ID prefix for all our microservice replicas. This string is used as a prefix for all subscription queue names in our microservice replicas. </li>
</ol>
<p class="normal">You don’t <a id="_idIndexMarker400"/>need to discover all the settings <a id="_idIndexMarker401"/>you need at this stage, just the ones that play a fundamental role in your microservice. Further settings can be easily added at a later time. </p>
<p class="normal">Therefore, let’s define all settings in the <code class="inlineCode">launchSettings.json</code> file as follows:</p>
<pre class="programlisting code"><code class="hljs-code">"environmentVariables": {
"ASPNETCORE_HTTP_PORTS": "8080",
//place here your environment variables
"ConnectionStrings__DefaultConnection": "",
"ConnectionStrings__RabbitMQConnection":
"host=localhost:5672;username=guest;password=guest;publisherConfirms=true;
timeout=10",
"Messages__SubscriptionIdPrefix": "routesPlanning",
"Topology__MaxDistanceKm": "50",
"Topology__MaxMatches": "5"
},
</code></pre>
<p class="normal">We left the database connection string empty. We will fill it once we have defined the SQL Server development database. </p>
<p class="normal">The RabbitMQ connection string contains the server URL and the default credential. Note that the <a id="_idIndexMarker402"/>default credentials are accepted just <a id="_idIndexMarker403"/>when RabbitMQ is accessed from <code class="inlineCode">localhost</code>, so you are encouraged to change them once you have installed the server. <code class="inlineCode">publisherConfirms=true</code> informs RabbitMQ that it must confirm that the message was safely received, and <code class="inlineCode">timeout=10</code> specifies the connection timeout in seconds.</p>
<h2 class="heading-2" id="_idParaDest-126"><a id="_idTextAnchor174"/>The microservice main service</h2>
<p class="normal">All modern .NET applications based <a id="_idIndexMarker404"/>on a host allow the definition of the so-called <strong class="keyWord">hosted services</strong>, which <a id="_idIndexMarker405"/>are services similar to Windows services running for the entire application lifetime. They can be defined by <a id="_idIndexMarker406"/>implementing the <code class="inlineCode">IHostedService</code> interface and adding them to the services definition section of the application with the following code:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddHostedService&lt;MyHostedService&gt;();
</code></pre>
<p class="normal">In practice, hosted services are defined by inheriting from <code class="inlineCode">BackgroundService</code>, which contains a partial implementation of the service and exposes a single <code class="inlineCode">ExecuteAsync</code> method that we must override.</p>
<p class="normal">Our microservice needs three hosted services. The main one listens to all input messages arriving from the message broker and processes them. Another hosted service extracts messages from the output internal queue and sends them to the message broker. Finally, the third hosted service performs housekeeping jobs, such as deleting expired requests and routes.</p>
<p class="normal">This subsection describes the main hosted service. The job of this hosted service is quite simple it listens for all four input messages we defined, and once it has received a message, it will create a command specific to that message and invoke the command handler associated with that command. Commands and command handlers are Onion Architecture building blocks that were discussed in the <em class="italic">Commands </em>subsection of<em class="italic"> </em><a href="Chapter_3.xhtml#_idTextAnchor067"><em class="italic">Chapter 3</em></a>, <em class="italic">Setup and Theory: Docker and Onion Architecture</em>. </p>
<p class="normal">Let’s create a <code class="inlineCode">HostedServices</code> folder in the <code class="inlineCode">RoutesPlanning</code> project. Then, add a class named <code class="inlineCode">MainService</code> that inherits from <code class="inlineCode">BackgroundService</code> to it:</p>
<pre class="programlisting code"><code class="hljs-code">public class MainService() : BackgroundService
{
    protected override Task ExecuteAsync(CancellationToken stoppingToken)
    {
        throw new NotImplementedException();
    }
}
</code></pre>
<p class="normal">The class name is followed by a couple of parentheses since it is the principal constructor where we will add parameters. In fact, all parameters of a hosted service constructor are automatically <a id="_idIndexMarker407"/>taken from the dependency engine container, so we can put all services it needs to perform its job there: an <code class="inlineCode">IConfiguration</code> parameter, and an <code class="inlineCode">IServiceProvider</code> interface that we will use to get scoped services. In fact, command handlers are <a id="_idIndexMarker408"/>scoped services, so we need to create a request scope before requiring them for the dependency injection container.</p>
<p class="normal">Summing up our principal constructor, it looks as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public class MainService(IConfiguration configuration, IServiceProvider services) : BackgroundService
</code></pre>
<p class="normal">Before proceeding, let’s add this hosted service to the dependency injection container, so it will be immediately executed at the start of the program. We just need to add the following instruction to <code class="inlineCode">Program.cs</code>:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddHostedService&lt;MainService&gt;();
</code></pre>
<p class="normal">In the case of the worker microservice, there is a one-to-one mapping between messages and commands, and all input needed by the command is contained in the message, so a unique generic command called <code class="inlineCode">MessageCommand&lt;T&gt;</code> suffices. Let’s define it in the <code class="inlineCode">Commands</code> folder of the <code class="inlineCode">RoutesPlanningApplicationServices</code> project:</p>
<pre class="programlisting code"><code class="hljs-code">public class MessageCommand&lt;T&gt;(T message): ICommand
{
    public T Message =&gt; message;
}
</code></pre>
<p class="normal">Now, let’s define a method that given a message of type <code class="inlineCode">T</code> creates a scope, requires the appropriate command handler, and executes it: </p>
<pre class="programlisting code"><code class="hljs-code">protected async Task ProcessMessage&lt;T&gt;(T message)
{
    using (var scope = services.CreateScope()) 
    {
    var handler=scope.ServiceProvider.GetRequiredService&lt;ICommandHandler&lt;
                                                    MessageCommand&lt;T&gt;&gt;&gt;();
        await handler.HandleAsync(new MessageCommand&lt;T&gt;(message));
    }
}
</code></pre>
<p class="normal">Errors, that is, exceptions thrown during a <code class="inlineCode">ProcessMessage&lt;T&gt;</code> execution, are handled by counting the number of consecutive errors and then rethrowing the exception. As we will see, rethrowing the <a id="_idIndexMarker409"/>exception basically undoes the <a id="_idIndexMarker410"/>extraction of the messages from the message broker queue so it can be processed again. </p>
<p class="normal">Error counting can be performed with a thread-safe critical region, as shown here:</p>
<pre class="programlisting code"><code class="hljs-code">private readonly Lock _countErrorsLock = new();
private static int _errorCount = 0;
public static int ErrorsCount =&gt; _errorCount;
private void DeclareSuccessFailure(bool isFailure=false)
{
    using (_countErrorsLock.EnterScope())
    {
        if (isFailure) _errorCount++;
        else _errorCount = 0;
    }
}
</code></pre>
<p class="normal">Consecutive error counts can be used to define the microservice health state. Now, we can define an error-protected wrapper of <code class="inlineCode">ProcessMessage&lt;T&gt;</code>:</p>
<pre class="programlisting code"><code class="hljs-code">protected async Task SafeProcessMessage&lt;T&gt;(T message)
{
    try
    {
        await ProcessMessage(message);
        DeclareSuccessFailure();
    }
    catch 
    {
        DeclareSuccessFailure(true);
        throw;
    }
}
</code></pre>
<p class="normal">Let’s also define a small method that computes the subscription ID to use for each message:</p>
<pre class="programlisting code"><code class="hljs-code">string SubscriptionId&lt;T&gt;()
{
    return string.Format("{0}_{1}",
        configuration["Messages__SubscriptionIdPrefix"<a id="_idTextAnchor175"/>],
        typeof(T).Name);
}
</code></pre>
<p class="normal">Now, we are ready to define our main <code class="inlineCode">ExecuteAsync</code> method; but before doing that, we must add a reference to the EasyNetQ NuGet package. Please select a version greater than or equal to 8, also if it is a prerelease. Once we have installed this package, we need to add its services to dependency injection in <code class="inlineCode">Program.cs</code> by calling the <code class="inlineCode">AddEasyNetQ</code> extension method and passing it the RabbitMQ connection string:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddEasyNetQ(
    builder.Configuration?.GetConnectionString(
"RabbitMQConnection")??string.Empty)
    .UseAlwaysNackWithRequeueConsumerErrorStrategy();;
</code></pre>
<p class="normal">The chained <a id="_idIndexMarker411"/>call defines how to handle errors in the received message handlers. We decided to requeue faulty messages so that they can be retried. If a microservice <a id="_idIndexMarker412"/>replica is faulty and generates an error on all messages, the message will eventually be processed by a healthy replica, while the unhealthy replica will eventually be discovered thanks to the consecutive error count that we will expose on a health endpoint. Unhealthy replicas are killed and recreated by all microservice orchestrators. </p>
<p class="normal">The requeue strategy is usually the best error-handling strategy for enterprise microservices. Anyway, there are other strategies available. If no strategy is specified, faulty messages, that is, messages whose handlers throw exceptions, are enqueued in a special error queue where they can be handled manually with administrative tools (see <a href="https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe">https://github.com/EasyNetQ/EasyNetQ/wiki/Re-Submitting-Error-Messages-With-EasyNetQ.Hosepipe</a>).</p>
<p class="normal">Access to all EasyNetQ communication facilities is done through an <code class="inlineCode">IBus</code> interface. Let’s add it to our hosted service main constructor:</p>
<pre class="programlisting code"><code class="hljs-code">public class MainService(IConfiguration configuration, IBus bus,  
IServiceProvider services): BackgroundService
</code></pre>
<p class="normal">The <code class="inlineCode">IBus</code> interface handles all communication with three properties:</p>
<ul>
<li class="bulletList"><code class="inlineCode">PubSub</code>: This contains all methods for sending and receiving messages with the publisher/subscriber pattern</li>
<li class="bulletList"><code class="inlineCode">SendReceive</code>: This contains all methods for sending and receiving messages with direct communication</li>
<li class="bulletList"><code class="inlineCode">Rpc</code>: This contains all methods for issuing asynchronous remote procedure calls and returning their responses</li>
</ul>
<p class="normal">Here, we will describe <code class="inlineCode">PubSub</code>, but <code class="inlineCode">SendReceive</code> is completely analogous. The only difference is that the <code class="inlineCode">Send</code> method explicitly specifies the name of the destination queue, while <code class="inlineCode">Publish</code> does not. The <code class="inlineCode">Publish</code> RabbitMQ exchange name is implicitly defined through the type of the message.</p>
<p class="normal">The following are the publish methods:</p>
<pre class="programlisting code"><code class="hljs-code">Task PublishAsync(T message, CancelationToken cancel = default)
Task PublishAsync(T message, string topic, 
    CancelationToken cancel = default)
Task PublishAsync(T message, Action&lt;IPublishConfiguration &gt; configuration, 
    CancelationToken cancel = default)
</code></pre>
<p class="normal">The second <a id="_idIndexMarker413"/>overload lets you specify a message topic, while the <a id="_idIndexMarker414"/>third lets you specify various configuration settings that may also include the message topic. </p>
<p class="normal">The following are the subscribe methods:</p>
<pre class="programlisting code"><code class="hljs-code">SubscriptionResult Subscribe&lt;T&gt;(string subscriptionId,  
Func&lt;T, Task&gt; messageHandler, CancelationToken cancel = default)
SubscriptionResult Subscribe&lt;T&gt;(string subscriptionId,  
Func&lt;T, CancelationToken , Task&gt; messageHandler, 
Action&lt;IsubscriptionConfiguration&gt; configuration, 
    CancelationToken cancel = default)
</code></pre>
<p class="normal">The returned value must be disposed of to unsubscribe. The second overload accepts a <code class="inlineCode">CancelationToken</code> in the message handler, and also accepts a configuration action. The configuration of the receiver contains more useful settings, among them the following: </p>
<ul>
<li class="bulletList"><code class="inlineCode">conf =&gt; conf.WithTopic(“mytopic”).WithTopic(“anothertopic”)</code>: The consumer will receive just the messages tagged with one of the selected topics.</li>
<li class="bulletList"><code class="inlineCode">conf =&gt; conf.WithPrefetchCount(N)</code>: <code class="inlineCode">N</code> is the maximum number of messages extracted from the queue by the consumer and waiting to be processed. <em class="italic">N</em> defaults to 20.</li>
<li class="bulletList"><code class="inlineCode">Conf =&gt; conf.WithDurable(durable)</code>: If <code class="inlineCode">durable</code> is <code class="inlineCode">true</code>, all consumer queue messages are recorded on disk by RabbitMQ. The default is <code class="inlineCode">true</code>.</li>
</ul>
<p class="normal">If messages must be processed in the same order that they were inserted in the queue, the prefetch count must be set to <code class="inlineCode">1</code> and we must also apply one of the strategies described in the <em class="italic">Ensuring that messages are processed in the proper order</em> subsection.</p>
<p class="normal">If we use <code class="inlineCode">Subscribe</code>, all prefetched messages are put in an internal in-memory queue and processed <a id="_idTextAnchor176"/>in a unique thread. However, there is also a completely analogous <code class="inlineCode">SubscribeAsync</code> that creates several parallel threads. Moreover, <code class="inlineCode">SubscribeAsync</code>, as usual, returns <code class="inlineCode">Task&lt;SubscriptionResult&gt;</code>.</p>
<p class="normal">We will use <code class="inlineCode">SubscribeAsync</code> to better exploit processor cores, and parallelism between disk/database operations and processor operations, but the simple fact of using several microservice replicas <a id="_idIndexMarker415"/>already exploits parallelism. The advantage of <a id="_idIndexMarker416"/>using several threads is that creating a thread costs less than creating another replica, so each replica should use several threads to optimize performance.</p>
<div><p class="normal">When the message handler successfully completes the task, a confirmation is automatically sent to RabbitMQ that deletes the message from the queue. </p>
<p class="normal">On the contrary, if the message handler throws an unhandled exception, the configured consumer error strategy is applied. In our case, we requeue the message.</p>
</div>
<p class="normal">Now, we are finally ready to write the main <code class="inlineCode">ExecuteAsync</code> method. After our configuration and preparation methods, it became straightforward:</p>
<pre class="programlisting code"><code class="hljs-code">protected override async Task ExecuteAsync(CancellationToken stoppingToken)
{
    var routeOfferSubscription = await bus.PubSub.
        SubscribeAsync&lt;RouteOfferMessage&gt;(
        SubscriptionId&lt;RouteOfferMessage&gt;(),SafeProcessMessage, 
        stoppingToken);
    var routeClosedAbortedSubscription = await bus.PubSub.SubscribeAsync&lt;
        RouteClosedAbortedMessage&gt;(
        SubscriptionId&lt;RouteClosedAbortedMessage&gt;(), SafeProcessMessage, 
            stoppingToken);
    var routeExtendedSubscription = 
    await bus.PubSub.SubscribeAsync&lt;RouteExtendedMessage&gt;(
        SubscriptionId&lt;RouteExtendedMessage&gt;(), SafeProcessMessage, 
           stoppingToken);
    var routeRequestSubscription = await bus.PubSub.
        SubscribeAsync&lt;RouteRequestMessage&gt;(
        SubscriptionId&lt;RouteRequestMessage&gt;(), SafeProcessMessage, 
           stoppingToken);
     
    stoppingToken.WaitHandle.WaitOne();
    routeRequestSubscription.Dispose();
    routeExtendedSubscription.Dispose();
    routeClosedAbortedSubscription.Dispose();
    routeOfferSubscription.Dispose();
}
</code></pre>
<p class="normal">We just subscribe to all messages using our unique generic message handler, and then wait for the replica <a id="_idIndexMarker417"/>termination on the wait handle <code class="inlineCode">stoppingToken.WaitHandle</code>. As soon as we receive notification that the replica is being terminated through <code class="inlineCode">WaitOne()</code>, the wait handle is unblocked and we unsubscribe all messages by <a id="_idIndexMarker418"/>calling the <code class="inlineCode">Dispose</code> methods of all <code class="inlineCode">SubscriptionResult</code>.</p>
<p class="normal">Before moving on to the implementation of the two remaining hosted services, for completeness, we will also describe the EasyNetQ RPC facilities.</p>
<h2 class="heading-2" id="_idParaDest-127"><a id="_idTextAnchor177"/>EasyNetQ’s RPC facilities</h2>
<p class="normal">An RPC <a id="_idIndexMarker419"/>request can be issued with the following methods:</p>
<pre class="programlisting code"><code class="hljs-code">Task&lt;TResponse&gt; bus.Rpc.RequestAsync&lt;TRequest, TResponse&gt;(
TRequest request, CancelationToken cancel = default)
Task&lt;TResponse&gt; bus.Rpc.RequestAsync&lt;TRequest, TResponse&gt;(
TRequest request,  Action&lt;IRequestConfiguration&gt; configuration, 
CancelationToken cancel = default)
</code></pre>
<p class="normal">Once the <a id="_idIndexMarker420"/>request is issued, the returned task will eventually provide the response. We can wait it with <code class="inlineCode">await</code> or specify a callback by calling <code class="inlineCode">Task&lt;T&gt;.ContinueWith</code>.</p>
<p class="normal">The recipient can listen for requests and provide responses with the following:</p>
<pre class="programlisting code"><code class="hljs-code">Task&lt;IDisposable&gt; bus.Rpc.RequestAsync&lt;TRequest, TResponse&gt;(
    Func&lt;TRequest, Task&lt; TResponse &gt;&gt; handler, 
    CancelationToken cancel = default);
Task&lt;IDisposable&gt; bus.Rpc.RequestAsync&lt;TRequest, TResponse&gt;(
    Func&lt;TRequest, Task&lt; TResponse &gt;&gt; handler, 
    Action&lt;IResponderConfiguration&gt; configuration,
    CancelationToken cancel = default);
</code></pre>
<p class="normal">The recipient can stop handling requests by disposing of the <code class="inlineCode">IDisposable</code> returned by the preceding methods.</p>
<p class="normal">Now, let’s move on to the remaining hosted services.</p>
<h2 class="heading-2" id="_idParaDest-128"><a id="_idTextAnchor178"/>Other required hosted services</h2>
<p class="normal">We will <a id="_idIndexMarker421"/>start with the housekeeping hosted service. Let’s call it <code class="inlineCode">HouseKeepingService</code> and place it in the <code class="inlineCode">HostedServices</code> folder together with <code class="inlineCode">MainService</code>:</p>
<pre class="programlisting code"><code class="hljs-code">public class HouseKeepingService(IConfiguration configuration, IBus bus, 
    IServiceProvider services): BackgroundService
{
    protected override Task ExecuteAsync(CancellationToken stoppingToken)
    {
        throw new NotImplementedException();
    }
}
</code></pre>
<p class="normal">Before proceeding, let’s add the new hosted service to the dependency injection container, so it will <a id="_idIndexMarker422"/>be immediately executed at program start. We just need to add the following instruction to <code class="inlineCode">Program.cs</code>:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddHostedService&lt;HouseKeepingService&gt;();
</code></pre>
<p class="normal">We need a <code class="inlineCode">HouseKeepingCommand</code> whose constructor specifies the number of days to wait after a route or request expiration before deleting it. As usual, let’s define it in the <code class="inlineCode">Commands</code> folder of <code class="inlineCode">RoutesPlanningApplicationServices</code>:</p>
<pre class="programlisting code"><code class="hljs-code">public record H<a id="_idTextAnchor179"/>ouseKeepingCommand(int DeleteDelay): ICommand;
</code></pre>
<p class="normal">We also need to define the <code class="inlineCode">Timing__HousekeepingIntervalHours</code> and <code class="inlineCode">Timing__HousekeepingDelayDays</code> environment variables in <code class="inlineCode">launchSettings.json</code>:</p>
<pre class="programlisting code"><code class="hljs-code">"Topology__MaxDistanceKm": "50",
//new environment variables
"Timing__HousekeepingIntervalHours": "4",
"Timing__HousekeepingDelayDays": "10"
</code></pre>
<p class="normal">The <code class="inlineCode">ExecuteAsync</code> method must <a id="_idIndexMarker423"/>execute a loop until the application signals <a id="_idIndexMarker424"/>termination. Inside this loop, it executes the handler and then sleeps <a id="_idIndexMarker425"/>for the time specified by <code class="inlineCode">Timing__HousekeepingIntervalHours</code> or until the replica terminates:</p>
<pre class="programlisting code"><code class="hljs-code">protected override async Task ExecuteAsync(CancellationToken stoppingToken)
{
    //update interval in milliseconds
    int updateInterval = configuration.GetValue&lt;int&gt;(
        "Timing:HousekeepingIntervalHours")*3600000;
    int deleteDelayDays = configuration.GetValue&lt;int&gt;(
        "Timing:HousekeepingDelayDays");
    while (!stoppingToken.IsCancellationRequested)
    {
        try
        {
            using (var scope = services.CreateScope())
            {
                var handler = scope.ServiceProvider
                    .GetRequiredService&lt;
                        ICommandHandler&lt;HouseKeepingCommand&gt;&gt;();
                await handler.HandleAsync(new HouseKeepingCommand(
                    deleteDelayDays));
            }
        }
        catch { 
          // actual production application should log the error
        }
        await Task.Delay(updateInterval, stoppingToken);
    }
}
</code></pre>
<p class="normal">In case of errors, we simply do nothing and repeat the operation at the next iteration. The <code class="inlineCode">Task.Delay</code> instruction at the end of the iteration leaves the thread sleeping until either the configured interval expires or <code class="inlineCode">stoppingToken</code> signals the replica termination.</p>
<p class="normal">Let’s move on to the last hosted service. Let’s repeat the same steps to create it and call it <code class="inlineCode">OutputSendingService</code>:</p>
<pre class="programlisting code"><code class="hljs-code">public class OutputSendingService(IConfiguration configuration, IBus bus,
    IServiceProvider services) : BackgroundService
{
    protected override Task ExecuteAsync(CancellationToken stoppingToken)
    {
        throw new NotImplementedException();
    }
}
</code></pre>
<p class="normal">As usual, let’s add the new hosted service to the dependency injection container:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Services.AddHost<a id="_idTextAnchor180"/><a id="_idTextAnchor181"/>edService&lt;OutputSendingService&gt;();
</code></pre>
<p class="normal">This time, we need a command that accepts <code class="inlineCode">Func&lt;RouteExtensionProposalsMessage,Task&gt;</code> as input. This input action wraps the code for sending <code class="inlineCode">RouteExtensionProposalsMessage</code> to RabbitMQ because commands can contain code that depends on a specific driver, which in our case is the RabbitMQ client. It also needs a <code class="inlineCode">batchCount</code> parameter, which specifies how many output messages are simultaneously extracted from the output queue, and a <code class="inlineCode">requeueDelay</code> parameter, which specifies the <a id="_idIndexMarker426"/>overall timeout after which a message is requeued if it is not successfully received by the message broker.</p>
<p class="normal">We can define a <a id="_idIndexMarker427"/>generic command that receives just <code class="inlineCode">Func&lt;T,Task&gt;</code>, so we can reuse it with other output messages; let’s call it <code class="inlineCode">OutputSendingCommand</code>:</p>
<pre class="programlisting code"><code class="hljs-code">public class OutputSendingCommand&lt;T&gt;(Func&lt;T, Task&gt; sender, 
int batchCount, TimeSpan requeueDelay): ICommand
{
    public Func&lt;T, Task&gt; Sender =&gt; sender;
    public int BatchCount =&gt; batchCount;
    public TimeSpan RequeueDelay =&gt; requeueDelay;
    public bool OutPutEmpty { get; set; } = false;
}
</code></pre>
<p class="normal">The command contains a flag where its handler will signal whether the output queue was found empty. We will use this flag to put the hosted service thread to sleep for a certain interval to avoid wasting resources.</p>
<p class="normal">Again, we need a <code class="inlineCode">Timing__OutputEmptyDelayMS</code> environment variable to configure the time to wait when the output queue is empty. Let add it to <code class="inlineCode">launchSettings.json</code>:</p>
<pre class="programlisting code"><code class="hljs-code">"Timing__OutputEmptyDelayMS": "500"
</code></pre>
<p class="normal">We need also the <code class="inlineCode">batchCount</code> and <code class="inlineCode">requeueDelay</code> values to pass to the command:</p>
<pre class="programlisting code"><code class="hljs-code">"Timing__OutputBatchCount": "10",
"Timing__OutputRequeueDelayMin": "5"
</code></pre>
<p class="normal">Suppose we have a <code class="inlineCode">SafeInvokeCommand</code> we need to implement that also returns whether the output queue is empty:</p>
<pre class="programlisting code"><code class="hljs-code">protected Task&lt;bool&gt; SafeInvokeCommand()
{
    throw new NotImplementedException();
}
</code></pre>
<p class="normal">Then, the <code class="inlineCode">ExetuteAsync</code> method can be implemented as follows:</p>
<pre class="programlisting code"><code class="hljs-code">readonly int updateBatchCount =
        configuration.GetValue&lt;int&gt;("Timing:OutputBatchCount");
readonly TimeSpan requeueDelay = TimeSpan.FromMinutes(
        configuration.GetValue&lt;int&gt;("Timing:OutputRequeueDelayMin"));
protected override async Task ExecuteAsync(CancellationToken stoppingToken)
{
    //update interval in milliseconds
    int updateInterval =
        configuration.GetValue&lt;int&gt;("Timing:HousekeepingIntervalHours") ;
    bool queueEmpty = false;
    while (!stoppingToken.IsCancellationRequested)
    {
        while (!queueEmpty &amp;&amp; !stoppingToken.IsCancellationRequested)
        {
            queueEmpty=await SafeInvokeCommand();
        }
        await Task.Delay(updateInterval, stoppingToken);
        queueEmpty = false;
    }
}
</code></pre>
<p class="normal">An outermost <a id="_idIndexMarker428"/>loop that exits only when the replica is going to be terminated, and an <a id="_idIndexMarker429"/>inner loop that reads the internal output queue and sends messages to the messages broker until the output queue is empty. When the output queue is empty, the service sleeps to wait for new messages being inserted in the internal output queue.</p>
<p class="normal">Before implementing <code class="inlineCode">SafeInvokeCommand</code>, we must code the <code class="inlineCode">Func&lt;T,Task&gt;</code> wrapper to pass to the command:</p>
<pre class="programlisting code"><code class="hljs-code">protected  Task SendMessage(RouteExtensionProposalsMessage message)
{
    return bus.PubSub.PublishAsync&lt;
        RouteExtensionProposalsMessage&gt;(message);
}
</code></pre>
<p class="normal">Now, the implementation <a id="_idIndexMarker430"/>is analogous to the command <a id="_idIndexMarker431"/>invoker of <code class="inlineCode">MainService</code>:</p>
<pre class="programlisting code"><code class="hljs-code">protected async Task&lt;bool&gt; InvokeCommand()
{
    using (var scope = services.CreateScope())
    {
        var handler = scope.ServiceProvider.GetRequiredService&lt;
            ICommandHandler&lt;OutputSendingCommand&lt;
                RouteExtensionProposalsMessage&gt;&gt;&gt;();
        var command = new OutputSendingCommand&lt;
            RouteExtensionProposalsMessage&gt;(
                SendMessage,updateBatchCount, requeueDelay);
        await handler.HandleAsync(command);
        return command.OutPutEmpty;
    }
}
protected async Task&lt;bool&gt; SafeInvokeCommand()
{
    try
    {
        return await InvokeCommand();
    }
    catch
    {
        return true;
    };
}
</code></pre>
<p class="normal">In case of exceptions, we simply return <code class="inlineCode">true</code> to put the thread to sleep for some time. In the next section, we will use the Polly library to define retry strategies.</p>
<h1 class="heading-1" id="_idParaDest-129"><a id="_idTextAnchor182"/>Ensuring resilient task execution with Polly </h1>
<p class="normal">Message sending <a id="_idIndexMarker432"/>should always be protected <a id="_idIndexMarker433"/>with at least exponential retry and the circuit break strategies that we analyzed in the <em class="italic">Resilient task execution </em>subsection of<em class="italic"> </em><a href="Chapter_2.xhtml#_idTextAnchor038"><em class="italic">Chapter 2</em></a>, <em class="italic">Demystifying Microservices Applications</em>. In this section, we will first describe the Polly library, which became a kind of standard for handling resilient task execution, and then we will apply it to the <code class="inlineCode">SendMessage</code> method of <code class="inlineCode">OutputSendingService</code>. </p>
<h2 class="heading-2" id="_idParaDest-130"><a id="_idTextAnchor183"/>The Polly library</h2>
<p class="normal">Resilient <a id="_idIndexMarker434"/>communication and, in general, resilient task execution can be implemented easily with the help of a .NET library called <strong class="keyWord">Polly</strong>, whose project is a member of the .NET Foundation. Polly is available through the <code class="inlineCode">Polly</code> NuGet package.</p>
<p class="normal">In Polly, you define policies and then execute tasks in the context of those policies, as follows:</p>
<pre class="programlisting code"><code class="hljs-code">var myPolicy = Policy
  .Handle&lt;HttpRequestException&gt;()
  .Or&lt;OperationCanceledException&gt;()
  .RetryAsync(3);
....
....
await myPolicy.ExecuteAsync(()=&gt;{
//your code here
});
</code></pre>
<p class="normal">The first part of each policy specifies the exceptions that must be handled. Then, you specify what to do when one of those exceptions is captured. In the preceding code, the <code class="inlineCode">Execute</code> method is retried up to three times if a failure is reported by either an <code class="inlineCode">HttpRequestException</code> exception or an <code class="inlineCode">OperationCanceledException</code> exception.</p>
<p class="normal">The following is the implementation of an exponential retry policy:</p>
<pre class="programlisting code"><code class="hljs-code">var retryPolicy= Policy
...
//Exceptions to handle here
.WaitAndRetryAsync(6,retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
</code></pre>
<p class="normal">The first argument of <code class="inlineCode">WaitAndRetryAsync</code> specifies that a maximum of six retries is performed in the event of failure. The lambda function passed as the second argument specifies how much time to wait before the next attempt. In this specific example, this time grows exponentially with the number of attempts by a power of 2 (two seconds for the first retry, four seconds for the second retry, and so on). The following is a simple circuit breaker policy:</p>
<pre class="programlisting code"><code class="hljs-code">var breakerPolicy =Policy
.Handle&lt;SomeExceptionType&gt;()
.CircuitBreakerAsync (6, TimeSpan.FromMinutes(1));
</code></pre>
<p class="normal">After six failures, the task can’t be executed for one minute since an exception is returned.</p>
<p class="normal">The following is the implementation of the Bulkhead Isolation policy:</p>
<pre class="programlisting code"><code class="hljs-code">Policy
.BulkheadAsync(10, 15)
</code></pre>
<p class="normal">A maximum of 10 parallel executions is allowed in the <code class="inlineCode">Execute</code> method. Further tasks are inserted in an execution queue. This has a limit of 15 tasks. If the queue limit is exceeded, an exception is thrown. For the Bulkhead Isolation policy to work properly and, in general, for every strategy to <a id="_idIndexMarker435"/>work properly, task executions must be triggered through the same policy instance; otherwise, Polly is unable to count how many executions of a specific task are active.</p>
<p class="normal">Policies can be combined with the <code class="inlineCode">Wrap</code> method:</p>
<pre class="programlisting code"><code class="hljs-code">var combinedPolicy = Policy
.WrapAsync(retryPolicy, breakerPolicy);
</code></pre>
<p class="normal">Polly offers several more options, such as generic methods for tasks that return a specific type, timeout policies, task result caching, the ability to define custom policies, and so on. It is also possible to configure Polly as part of an <code class="inlineCode">HttpClient</code> definition in the dependency injection section of any ASP. NET Core and .NET application. This way, it is quite immediate to define resilient HTTP clients. Finally, version 8 also introduced a new API based on creating pipelines of strategies.</p>
<p class="normal">Polly’s official documentation can be found in its GitHub repository here: <a href="https://github.com/App-vNext/Polly">https://github.com/App-vNext/Polly</a>.</p>
<p class="normal">In the next subsection, we will install and use Polly for a resilient transmission of the microservices output messages to the message broker.</p>
<h2 class="heading-2" id="_idParaDest-131"><a id="_idTextAnchor184"/>Adding Polly to our project</h2>
<p class="normal">Using Polly in our project is straightforward. First of all, you must add a reference to the last version of <a id="_idIndexMarker436"/>the Polly NuGet package in the <code class="inlineCode">RoutesPlanning</code> project. Then, you must modify the <code class="inlineCode">SendMessage</code> method of the <code class="inlineCode">OutputSendingService</code> class as follows:</p>
<pre class="programlisting code"><code class="hljs-code">protected  Task SendMessage(RouteExtensionProposalsMessage message)
{
    var retryPolicy = Policy
            .Handle&lt;Exception&gt;()
            .WaitAndRetryAsync(4,
               retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(1,
                retryAttempt)));
    var circuitBreakerPolicy = Policy
        .Handle&lt;Exception&gt;()
        .CircuitBreakerAsync(4, circuitBreakDelay);
    var combinedPolicy = Policy
        .WrapAsync(retryPolicy, circuitBreakerPolicy);
    return combinedPolicy.ExecuteAsync(
        async () =&gt; await bus.PubSub.PublishAsync&lt;
RouteExtensionProposalsMessage&gt;(message));
    
}
</code></pre>
<p class="normal">We first define an exponential retry policy, then a circuit breaker policy, and finally combine them and <a id="_idIndexMarker437"/>execute the message sending inside <code class="inlineCode">combinedPolicy.ExecuteAsync</code>. </p>
<p class="normal">All strategies’ parameters could be s<a id="_idTextAnchor185"/>pecified with environment variables, but for simplicity, we left constant all values but <code class="inlineCode">circuitBreakDelay</code>, that is, the time a circuit break should last. In fact, this is the only critical parameter that might need to be tuned.</p>
<p class="normal"><code class="inlineCode">circuitBreakDelay</code> can be configured in an environment variable in <code class="inlineCode">launchSettings.json</code> as follows:</p>
<pre class="programlisting code"><code class="hljs-code">"Timing:OutputCircuitBreakMin": "4"
</code></pre>
<p class="normal">Then, it can be defined as an <code class="inlineCode">OutputSendingService</code> field with the following:</p>
<pre class="programlisting code"><code class="hljs-code">readonly TimeSpan circuitBreakDelay = TimeSpan.FromMinutes(
        configuration.GetValue&lt;int&gt;("Timing:OutputCircuitBreakMin"));
</code></pre>
<h1 class="heading-1" id="_idParaDest-132"><a id="_idTextAnchor186"/>From abstraction to implementation details </h1>
<p class="normal">In the previous sections, we defined the overall organization of the route-planning microservice. In this final section, we will fill in all the details by first defining the domain layer and the database driver, and then defining all commands. </p>
<h2 class="heading-2" id="_idParaDest-133"><a id="_idTextAnchor187"/>The domain layer</h2>
<p class="normal">We will define <a id="_idIndexMarker438"/>each aggregate in a separate folder that will contain the aggregate, the interface that defines the aggregate state, and the repository interface associated with the aggregate. </p>
<p class="normal">However, before starting the definition of all aggregates, we need to add a famous library for handling both geometric and GIS calculations: <code class="inlineCode">NetTopologySuite</code>. It is available in both Java and .NET and all its types conform to a standard recognized by all main databases.</p>
<p class="normal">The .NET version is available through the <code class="inlineCode">NetTopologySuite</code> NuGet package. Therefore, let’s add this package to the <code class="inlineCode">RoutesPlanningDomainLayer</code> project. The meaning of GIS object coordinates is <a id="_idIndexMarker439"/>defined in documents classified with integers called <strong class="keyWord">Spatial Reference Identifiers </strong>(<strong class="keyWord">SRIDs</strong>). Each document specifies the meaning of the <em class="italic">x</em> and <em class="italic">y</em> coordinates, how to compute the distance between two points, and the part of the Earth’s surface it applies to. Each GIS object must specify the SRID used by its coordinates, and only <a id="_idIndexMarker440"/>objects with the same SRID can be used in the same computation.</p>
<p class="normal">We will use SRID 4326, which applies to the entire surface of the Earth. <code class="inlineCode">X</code> is the longitude in degrees and <code class="inlineCode">Y</code> is the latitude in degrees; the distance is computed in meters by approximating the Earth’s surface with an ellipsoid. More precise results can be obtained with SRIDs that apply to smaller portions of the Earth’s surface, but SRID 4326 is supported by all main databases.</p>
<p class="normal">Let’s define our overall default SRID in a static class defined in the root of the <code class="inlineCode">RoutesPlanningDomainLayer</code> project:</p>
<pre class="programlisting code"><code class="hljs-code">namespace RoutesPlanningDomainLayer
{
    public static class GeometryConstants
    {
        public static int DefaultSRID =&gt; 4326;
    }
}
</code></pre>
<p class="normal">As in the case of messages, we need intermediate types. Let’s define them in a <code class="inlineCode">RoutesPlanningDomainLayer -&gt; Models -&gt; BasicTypes</code> folder:</p>
<ul>
<li class="bulletList"><strong class="keyWord">Route status</strong>:
        <pre class="programlisting code-one"><code class="hljs-code">public enum RouteStatus { Open=0, Closed=1, Aborted=2 };
</code></pre>
</li>
<li class="bulletList"><strong class="keyWord">Time interval</strong>:
        <pre class="programlisting code-one"><code class="hljs-code">public record TimeInterval
{
    public DateTime Start { get; init; }
    public DateTime End { get; init; }   
}
</code></pre>
</li>
<li class="bulletList">Town info:
        <pre class="programlisting code-one"><code class="hljs-code">public record TownBasicInfo
{
    public Guid Id { get; init; }
    public string Name { get; init; } = null!;
    public Point Location { get; init; } = null!;
}
</code></pre>
</li>
<li class="bulletList">User info:
        <pre class="programlisting code-one"><code class="hljs-code">public record UserBasicInfo()
{
    public Guid Id { get; init; }
    public string DisplayName { get; init; } = null!;
}
</code></pre>
</li>
</ul>
<p class="normal"><code class="inlineCode">Point</code> is a <code class="inlineCode">NetTopologySuite</code> type that specifies a point on the Earth’s surface. Please note that all of the preceding types are what we called value objects in the <em class="italic">The domain layer </em>subsection of<em class="italic"> </em><a href="Chapter_3.xhtml#_idTextAnchor067"><em class="italic">Chapter 3</em></a>,<em class="italic"> Setup and Theory: Docker and Onion Architecture</em>. Therefore, as suggested there, we defined them as .NET record types.</p>
<p class="normal">Now, we can start <a id="_idIndexMarker441"/>defining our aggregates. For each of them, we will first define its status interface, then the aggregate, and finally, the associated repository interface. Usually, the definition of all these data types is iterative; that is, we start with a first draft, and then, when we realize we need another property or method, we add it.</p>
<h3 class="heading-3" id="_idParaDest-134"><a id="_idTextAnchor188"/>The route request aggregate</h3>
<p class="normal">Let’s <a id="_idIndexMarker442"/>create a <code class="inlineCode">Models -&gt; Request</code> folder for all types related <a id="_idIndexMarker443"/>to a user request. The status of a user request can be represented as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IRouteRequestState
{
    Guid Id { get; }
    TownBasicInfo Source { get; }
    TownBasicInfo Destination { get;  }
    DateTime WhenStart { get; }
    DateTime WhenEnd { get; }
    UserBasicInfo User { get; }
    Guid? RouteId { get; set; }
    public long TimeStamp { get; set; }
}
</code></pre>
<p class="normal">All properties that cannot be changed by aggregates have been defined as get-only properties. <code class="inlineCode">Id</code> uniquely identifies each request in the overall application. <code class="inlineCode">Source</code> and <code class="inlineCode">Destination</code> are, respectively, the desired departure and arrival towns, while <code class="inlineCode">WhenStart</code> and <code class="inlineCode">WhenEnd</code> define the acceptable days for travel. Then, we have information on the user that issued the request and the current timestamp associated with the request. Finally, <code class="inlineCode">RouteId</code> is the unique identifier of the <a id="_idIndexMarker444"/>route that the request has been added to, if any. If the <a id="_idIndexMarker445"/>request is still open, this property is <code class="inlineCode">null</code>.</p>
<p class="normal">The aggregate can be defined as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public class RouteRequestAggregate(IRouteRequestState state): 
    Entity&lt;Guid&gt;
{
    public override Guid Id =&gt; state.Id;
    public TownBasicInfo Source =&gt; state.Source;
    public TownBasicInfo Destination =&gt; state.Destination;
    TimeInterval _When = null!;
    public TimeInterval When =&gt; _When ?? 
        (_When=new TimeInterval {Start = state.WhenStart, End = state.
                                 WhenEnd });    
    public UserBasicInfo User =&gt; state.User;
    public bool Open =&gt; state.RouteId == null; 
    public long TimeStamp =&gt; state.TimeStamp;
    public void DetachFromRoute() =&gt; state.RouteId = null;
    public void AttachToRoute(Guid routeId) =&gt; state.RouteId = routeId;
}
</code></pre>
<p class="normal">It is worth pointing out that once a request has been created, only its <code class="inlineCode">state.RouteId</code> can be changed. This is because once issued, each request cannot be modified but just matched with existing routes.</p>
<p class="normal">The repository interface is as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IRouteRequestRepository : IRepository
{
    RouteRequestAggregate New(
        Guid id,
        TownBasicInfo source, 
        TownBasicInfo destination,
        TimeInterval when,
        UserBasicInfo user
        );
    Task&lt;RouteRequestAggregate?&gt; Get(Guid id);
    Task&lt;IList&lt;RouteRequestAggregate&gt;&gt; Get(Guid[] ids);
    Task&lt;IList&lt;RouteRequestAggregate&gt;&gt; GetInRoute(Guid routeId);
    Task&lt;IList&lt;RouteRequestAggregate&gt;&gt; GetMatch(IEnumerable&lt;Coordinate&gt; 
        geometry, 
       DateTime when, double distance, int maxResults);
    Task DeleteBefore(DateTime milestone);
}
</code></pre>
<p class="normal">The <code class="inlineCode">New</code> method creates a new instance of the aggregate and its database-attached state. Then, we have <a id="_idIndexMarker446"/>methods for getting a single or more existing aggregates from their <code class="inlineCode">Id</code>, and all aggregates that are served by the same route.</p>
<p class="normal">The <code class="inlineCode">GetMatch</code> method <a id="_idIndexMarker447"/>returns <a id="_idIndexMarker448"/>all aggregates that are the best match with a route. The route is specified by the coordinates of the towns it passes through (<code class="inlineCode">geometry</code>), and by its date (<code class="inlineCode">When</code>). <code class="inlineCode">Coordinate</code> is a <code class="inlineCode">NetTopologySuite</code> type that contains just the <em class="italic">X</em> and <em class="italic">Y</em> coordinates of a location without its SRID (the default SRID defined before is implicit). <code class="inlineCode">distance</code> specifies the maximum distance between the request and a route for a match to occur. All results are ordered according to their distance from the route, and a maximum of <code class="inlineCode">maxResults</code> requests is returned.</p>
<p class="normal">The <code class="inlineCode">DeleteBefore</code> method is used to perform some housekeeping by deleting old, expired requests.</p>
<h3 class="heading-3" id="_idParaDest-135"><a id="_idTextAnchor189"/>The route offer aggregate</h3>
<p class="normal">Let’s create a <code class="inlineCode">Models -&gt; Route</code> folder <a id="_idIndexMarker449"/>for all types related to a user route <a id="_idIndexMarker450"/>offer. The status of a user request can be represented as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IRouteOfferState
{
    Guid Id { get; }
    LineString Path { get; set; }
    DateTime When { get; }
    UserBasicInfo User { get; }
    RouteStatus Status { get; set; }
    public long TimeStamp { get; set; }
}
</code></pre>
<p class="normal"><code class="inlineCode">LineString</code> is a <code class="inlineCode">NetTopologySuite</code> type that represents a path made of consecutive segments on the Earth’s surface. Basically, it is a sequence of coordinates with an attached SRID. <code class="inlineCode">Status</code> is the status of the route (open to other participants, closed, or aborted).</p>
<p class="normal">The aggregate can be defined as follows: </p>
<pre class="programlisting code"><code class="hljs-code">public class RouteOfferAggregate
    (IRouteOfferState state): Entity&lt;Guid&gt;
{
    public override Guid Id =&gt; state.Id;
    IReadOnlyList&lt;Coordinate&gt;? _Path=null;
    public IReadOnlyList&lt;Coordinate&gt; Path =&gt; _Path != null ? _Path : (
        _Path = state.Path.Coordinates.ToImmutableList());
    public DateTime When =&gt; state.When;
    public UserBasicInfo User =&gt; state.User;
    public RouteStatus Status =&gt; state.Status;
    public long TimeStamp =&gt; state.TimeStamp;
    …
    …
}
</code></pre>
<p class="normal">Here, dots have been added in place of methods we will analyze shortly. The <code class="inlineCode">LineString</code> path contained in the <a id="_idIndexMarker451"/>aggregate state is exposed as an immutable <a id="_idIndexMarker452"/>list of its coordinates so that it can’t be modified directly, and can’t have its SRID changed.</p>
<p class="normal">It contains an <code class="inlineCode">Extend</code> method that is called when a message requiring the extension of the route is received. The data contained in the message is passed as its parameters:</p>
<pre class="programlisting code"><code class="hljs-code">public void Extend(long timestamp, 
IEnumerable&lt;Guid&gt; addedRequests, 
Coordinate[] newRoute, bool closed)
{
    if (timestamp &gt; TimeStamp)
    {
        state.Path = new LineString(newRoute)
            { SRID = GeometryConstants.DefaultSRID };
        _Path = null;
        state.TimeStamp = timestamp;
    }
    if(state.Status != RouteStatus.Aborted)
        AddDomainEvent(new AttachedRequestEvent { 
            AddedRequests = addedRequests,
            RouteOffer = Id
        });
    Close();
}
</code></pre>
<p class="normal">The path is updated only if it is more recent than the path stored in the aggregate, while the requests contained in the extension message are always attached to the route offer, because each message doesn’t contain all matched requests but just the newly added ones, so they must also be added if we received an old message. The only case when the requests must not be added is when <a id="_idIndexMarker453"/>the route has already been aborted, because aborted routes release all their attached requests.</p>
<p class="normal">The task of <a id="_idIndexMarker454"/>attaching the requests to the aggregate is left to an event handler for better modularity. Thus, the <code class="inlineCode">Extend</code> method adds an <code class="inlineCode">AttachedRequestEvent</code> event to the aggregate list of events. The event definition must be placed in the <code class="inlineCode">Events</code> folder and is defined as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public class AttachedRequestEvent : IEventNotification
{
    public IEnumerable&lt;Guid&gt; AddedRequests { get; set; } = new List&lt;Guid&gt;();
    public Guid RouteOffer { get; set; } 
}
</code></pre>
<p class="normal">Finally, if the extension message declares the route closed, the <code class="inlineCode">Extend</code> method closes it by calling the <code class="inlineCode">Close()</code> method, which is defined as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public void Close()
{
    state.Status = RouteStatus.Closed;
}
</code></pre>
<p class="normal">There is also an <code class="inlineCode">Abort</code> method, which declares the route aborted:</p>
<pre class="programlisting code"><code class="hljs-code">public void Abort()
{
    state.Status = RouteStatus.Aborted;
    AddDomainEvent(new ReleasedRequestsEvent
    {
        AbortedRoute = Id
    });
}
</code></pre>
<p class="normal">It sets the aggregate status to aborted and then leaves the task of releasing all attached requests to an event handler for better modularity, with the <code class="inlineCode">ReleasedRequestsEvent</code> event:</p>
<pre class="programlisting code"><code class="hljs-code">public class ReleasedRequestsEvent:IEventNotification
{
    public Guid AbortedRoute {  get; set; }
}
</code></pre>
<p class="normal">Let’s move <a id="_idIndexMarker455"/>on to the repository interface:</p>
<pre class="programlisting code"><code class="hljs-code">public interface IRouteOfferRepository : IRepository
{
    RouteOfferAggregate New(Guid id, Coordinate[] path, UserBasicInfo 
        user, DateTime When);
    Task&lt;RouteOfferAggregate?&gt; Get(Guid id);
    Task&lt;IList&lt;RouteOfferAggregate&gt;&gt; GetMatch(
        Point source, Point destination, TimeInterval when, 
        double distance, int maxResults);
    Task DeleteBefore(DateTime milestone);
} 
</code></pre>
<p class="normal">The <code class="inlineCode">New</code> method creates <a id="_idIndexMarker456"/>a new aggregate, then we have a method to get an aggregate from its unique identifier. The <code class="inlineCode">GetMatch</code> and <code class="inlineCode">DeleteBefore</code> methods are completely analogous to the one of requests, but in this case, <code class="inlineCode">GetMatch</code> returns all route offers matching a given request.</p>
<h3 class="heading-3" id="_idParaDest-136"><a id="_idTextAnchor190"/>The output queue item aggregate</h3>
<p class="normal">This aggregate <a id="_idIndexMarker457"/>represents a generic output queue item. Files will <a id="_idIndexMarker458"/>be placed in a <code class="inlineCode">Models -&gt; OutputQueue</code> folder. The aggregate state can be defined as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public  interface IQueueItemState
{
    Guid Id { get; }
    int MessageCode { get; }
    public string MessageContent { get; }
}
</code></pre>
<p class="normal">Each queue item has a unique ID and a message code that specifies which message type is stored in the item. While the message content is the JSON representation of the output messages. The aggregate is trivial:</p>
<pre class="programlisting code"><code class="hljs-code">public class QueueItem(IQueueItemState state): Entity&lt;Guid&gt;
{
    public override Guid Id =&gt; state.Id;
    public int MessageCode =&gt; state.MessageCode;
    public T? GetMessage&lt;T&gt;() 
    {
        if (string.IsNullOrWhiteSpace(state.MessageContent)) 
        return default;
        return JsonSerializer.Deserialize&lt;T&gt;(state.MessageContent);
    }
}
</code></pre>
<p class="normal">The <code class="inlineCode">GetMessage</code> method <a id="_idIndexMarker459"/>deserializes the message contained in the item.</p>
<p class="normal">Finally, the repository interface is as follows: </p>
<pre class="programlisting code"><code class="hljs-code">public interface IOutputQueueRepository: IRepository
{
    Task&lt;IList&lt;QueueItem&gt;&gt; Take(int N, TimeSpan requeueAfter);
    void Confirm(Guid[] ids);
    QueueItem New&lt;T&gt;(T item, int messageCode);
}
</code></pre>
<p class="normal">Each queue <a id="_idIndexMarker460"/>item has a time attached to it, and an item can be extracted <a id="_idIndexMarker461"/>by the queue only after this time expires. Moreover, queue items are extracted in increasing time order.</p>
<p class="normal">The <code class="inlineCode">Take</code> method extracts the first <code class="inlineCode">N</code> items from the queue and then immediately requeues them by replacing their time with the time of their extraction plus the <code class="inlineCode">requeueAfter</code> <code class="inlineCode">TimeSpan</code>. This way, if messages are successfully sent before <code class="inlineCode">requeueAfter</code>, they are removed from the queue; otherwise, they become available for extraction from the queue again, and their transmission is retried.</p>
<p class="normal">The <code class="inlineCode">Confirm</code> method deletes all successfully sent messages, while the <code class="inlineCode">New</code> method adds a new item to the output queue.</p>
<p class="normal">Now, we can move on to the implementation of all aggregate states with Entity Framework entities and to the implementation of all repositories.</p>
<h2 class="heading-2" id="_idParaDest-137"><a id="_idTextAnchor191"/>The database driver</h2>
<p class="normal">Before getting <a id="_idIndexMarker462"/>started with the implementation of the <code class="inlineCode">RoutesPlanningDBDriver</code> driver, we must add a reference to the <code class="inlineCode">Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite</code> NuGet package, which adds support for all <code class="inlineCode">NetTopolgySuite</code> types to Entity Framework Core. Then, we must declare the usage of <code class="inlineCode">NetTopolgySuite</code> in the <code class="inlineCode">Extensions -&gt; DBExtensions.cs</code> file:</p>
<pre class="programlisting code"><code class="hljs-code">options.UseSqlServer(connectionString, 
    b =&gt; {
        b.MigrationsAssembly("DBDriver");
       // added code
        b.UseNetTopologySuite();
     }));
</code></pre>
<p class="normal">Now, we can define <a id="_idIndexMarker463"/>all the entities we need in the <code class="inlineCode">Entities</code> folder:</p>
<ul>
<li class="bulletList">Route offer:
        <pre class="programlisting code-one"><code class="hljs-code">internal class RouteOffer: IRouteOfferState
{
    public Guid Id { get; set; }
    public LineString Path { get; set; } = null!;
    public DateTime When { get; set; }
    public UserBasicInfo User { get; set; } = null!;
    public RouteStatus Status { get; set; }
    public ICollection&lt;RouteRequest&gt; Requests { get; set; } = null!;
    public long TimeStamp { get; set; }
}
</code></pre>
</li>
<li class="bulletList">Route request:
        <pre class="programlisting code-one"><code class="hljs-code">internal class RouteRequest: IRouteRequestState
{
    public Guid Id { get; set; }
    public TownBasicInfo Source { get; set; }=null!;
    public TownBasicInfo Destination { get; set; } = null!;
    public DateTime WhenStart { get; set; }
    public DateTime WhenEnd { get; set; }
    public long TimeStamp { get; set; }
    public UserBasicInfo User { get; set; } = null!;
    public Guid? RouteId { get; set; }
    public RouteOffer? Route { get; set; }
    
}
</code></pre>
</li>
<li class="bulletList">Queue item:
        <pre class="programlisting code-one"><code class="hljs-code">internal class OutputQueueItem: IQueueItemState
{
    public Guid Id { get; set; }
    public int MessageCode { get; set; }
    public string MessageContent { get; set; } = null!;
    public DateTime ReadyTime { get; set; }
}
</code></pre>
</li>
</ul>
<p class="normal">Then, in the <code class="inlineCode">MainDBContext.cs</code> file, we must add the corresponding collections:</p>
<pre class="programlisting code"><code class="hljs-code">public DbSet&lt;RouteRequest&gt; RouteRequests { get; set; } = null!;
public DbSet&lt;RouteOffer&gt; RouteOffers { get; set; } = null!;
public DbSet&lt;OutputQueueItem&gt; OutputQueueItems { get; set; } = null!;
</code></pre>
<p class="normal">Finally, in the <code class="inlineCode">OnModelCreating</code> method of <a id="_idIndexMarker464"/>the same file, we must <a id="_idIndexMarker465"/>declare the relationship between <code class="inlineCode">RouteOffer</code> and <code class="inlineCode">RouteRequest</code>:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Entity&lt;RouteOffer&gt;().HasMany(m =&gt; m.Requests)
    .WithOne(m =&gt; m.Route)
    .HasForeignKey(m =&gt; m.RouteId)
    .OnDelete(DeleteBehavior.Cascade);
</code></pre>
<p class="normal">We must also declare some indices and the usage of value objects (with their indices) with <code class="inlineCode">OwnsOne</code>:</p>
<pre class="programlisting code"><code class="hljs-code">builder.Entity&lt;RouteRequest&gt;().OwnsOne(m =&gt; m.Source);
builder.Entity&lt;RouteRequest&gt;().OwnsOne(m =&gt; m.Destination);
builder.Entity&lt;RouteRequest&gt;().OwnsOne(m =&gt; m.User);
builder.Entity&lt;RouteRequest&gt;().HasIndex(m =&gt; m.WhenStart);
builder.Entity&lt;RouteRequest&gt;().HasIndex(m =&gt; m.WhenEnd);
builder.Entity&lt;RouteOffer&gt;().OwnsOne(m =&gt; m.User);
builder.Entity&lt;RouteOffer&gt;().HasIndex(m =&gt; m.When);
builder.Entity&lt;RouteOffer&gt;().HasIndex(m =&gt; m.Status);
builde<a id="_idTextAnchor192"/>r.Entity&lt;OutputQueueItem&gt;().HasIndex(m =&gt; m.ReadyTime);
</code></pre>
<p class="normal">Let’s now move on to the implementation of all repositories.</p>
<h3 class="heading-3" id="_idParaDest-138"><a id="_idTextAnchor193"/>The IOutputQueueRepository implementation</h3>
<p class="normal">All <a id="_idIndexMarker466"/>repository implementations <a id="_idIndexMarker467"/>follow the same basic pattern:</p>
<pre class="programlisting code"><code class="hljs-code">internal class OutputQueueRepository(IUnitOfWork uow) : IOutputQueueRepository
{
    readonly MainDbContext ctx = (uow as MainDbContext)!;
    public void Confirm(Guid[] ids)
    …
    public QueueItem New&lt;T&gt;(T item, int messageCode)
    …
    public async Task&lt;IList&lt;QueueItem&gt;&gt; Take(int N, TimeSpan requeueAfter)
    …
    }
}
</code></pre>
<p class="normal">They take <code class="inlineCode">IUnitOfWork</code> from <a id="_idIndexMarker468"/>their main constructor <a id="_idIndexMarker469"/>and cast it to the database context.</p>
<p class="normal">The <code class="inlineCode">New</code> method implementation is as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public QueueItem New&lt;T&gt;(T item, int messageCode)
{
    var entity = new OutputQueueItem()
    {
        Id = Guid.NewGuid(),
        MessageCode = messageCode,
        MessageContent = JsonSerializer.Serialize(item)
    };
    var res = new QueueItem(entity);
    ctx.OutputQueueItems.Add(entity);
    return res;
}
</code></pre>
<p class="normal">The implementation of <code class="inlineCode">Confirm</code> is straightforward, too:</p>
<pre class="programlisting code"><code class="hljs-code">public void Confirm(Guid[] ids)
{
    var entities = ctx.ChangeTracker.Entries&lt;OutputQueueItem&gt;()
        .Where(m =&gt; ids.Contains(m.Entity.Id)).Select(m =&gt; m.Entity);
    ctx.OutputQueueItems.RemoveRange(entities);
}
</code></pre>
<p class="normal">It uses the changes tracker to get all already-loaded entities with the given IDs.</p>
<p class="normal">The <code class="inlineCode">Take</code> implementation is a little bit more complex, because it requires a transaction to handle the competition between the various microservice replicas, since they all use the same database:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task&lt;IList&lt;QueueItem&gt;&gt; Take(int N, TimeSpan requeueAfter)
{
    List&lt;OutputQueueItem&gt; entities;
    using (var tx = 
        await ctx.Database.BeginTransactionAsync(IsolationLevel.
            Serializable))
    {
        var now = DateTime.Now;
        entities = await ctx.OutputQueueItems.Where(m =&gt; m.ReadyTime &lt;= 
                                                    now)
            .OrderBy(m =&gt; m.ReadyTime)
            .Take(N)
            .ToListAsync();
        if (entities.Count &gt; 0)
        {
            foreach (var entity in entities) 
                { entity.ReadyTime = now + requeueAfter; }
            await ctx.SaveChangesAsync();
            await tx.CommitAsync();
        }
        return entities.Select(m =&gt; new QueueItem(m)).ToList();
    }
}
</code></pre>
<p class="normal">Once all <a id="_idIndexMarker470"/>entities are extracted, <code class="inlineCode">ReadyTime</code> is moved to a future time to prevent their usage from other replicas till <code class="inlineCode">requeueAfter</code> expires and <a id="_idIndexMarker471"/>they become available again if they were not removed by <code class="inlineCode">Confirm</code>. This way, if all retry and circuit break strategies fail in getting a successful transmission, the same operation can be retried after <code class="inlineCode">requeueAfter</code>. Both read and update must be part of the same serializable transaction to prevent interferences from other replicas.</p>
<h3 class="heading-3" id="_idParaDest-139"><a id="_idTextAnchor194"/>The IRouteRequestRepositoryimplementation</h3>
<p class="normal">The <a id="_idIndexMarker472"/>repository structure is completely analogous <a id="_idIndexMarker473"/>to the one of the previous repository:</p>
<pre class="programlisting code"><code class="hljs-code">internal class RouteRequestRepository(IUnitOfWork uow) : IRouteRequestRepository
{
    readonly MainDbContext ctx = (uow as MainDbContext)!;
    public async Task DeleteBefore(DateTime milestone)
    …
    public async Task&lt;RouteRequestAggregate?&gt; Get(Guid id)
    …
    public async Task&lt;IList&lt;RouteRequestAggregate&gt;&gt; GetInRoute(Guid 
        routeId)
    …
    public async Task&lt;IList&lt;RouteRequestAggregate&gt;&gt; GetMatch(
        IEnumerable&lt;Coordinate&gt; geometry, DateTime when, 
        double distance, int maxResults)
    …
    public RouteRequestAggregate New(Guid id, 
        TownBasicInfo source, TownBasicInfo destination, 
        TimeInterval when, UserBasicInfo user)
    …
}
</code></pre>
<p class="normal">The <code class="inlineCode">DeleteBefore</code> method is <a id="_idIndexMarker474"/>easily implemented with the recent <code class="inlineCode">ExecuteDeleteAsync</code> Entity Framework Core extension:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task DeleteBefore(DateTime milestone)
{
    await ctx.RouteRequests.Where(m =&gt; m.WhenEnd &lt; milestone).ExecuteDeleteAsync(); 
}
</code></pre>
<p class="normal">In the <a id="_idIndexMarker475"/>following code blocks, we <a id="_idIndexMarker476"/>can see the <code class="inlineCode">New</code> method: </p>
<pre class="programlisting code"><code class="hljs-code">public RouteRequestAggregate New(Guid id, TownBasicInfo source, 
TownBasicInfo destination, TimeInterval when, UserBasicInfo user)
{
    var entity = new RouteRequest()
    {
        Id = id,
        Source = source,
        Destination = destination,
        WhenStart = when.Start,
        WhenEnd = when.End,
        User = user
    };
    var res = new RouteRequestAggregate(entity);
    res.AddDomainEvent(new NewMatchCandidateEvent&lt;RouteRequestAggregate&gt;(res));
    ctx.RouteRequests.Add(entity);
    return res;
}
</code></pre>
<p class="normal">It creates an Entity Framework Core entity, adds it to <code class="inlineCode">ctx.RouteRequests</code>, and uses it as the state to create <code class="inlineCode">RouteRequestAggregate</code>. It adds also a <code class="inlineCode">NewMatchCandidateEvent&lt;RouteRequestAggregate&gt;</code> event to the aggregate. The associated event handler will take care of finding all routes that match the request and creating an output message for each of them. <code class="inlineCode">NewMatchCandidateEvent&lt;T&gt;</code> is defined in the <code class="inlineCode">Events</code> folder of the <code class="inlineCode">RoutesPlanningDomainLayer</code> project, as follows:</p>
<pre class="programlisting code"><code class="hljs-code">public class NewMatchCandidateEvent&lt;T&gt;(T matchCandidate):
    IEventNotification
{
    public T MatchCandidate =&gt; matchCandidate;
}
</code></pre>
<p class="normal">All other <a id="_idIndexMarker477"/>methods contain quite standard Entity Framework <a id="_idIndexMarker478"/>Core code, so we will describe here just the <code class="inlineCode">GetMatch</code> method since it uses the Entity Framework special queries extensions. The code of all other methods is available in the <code class="inlineCode">ch07</code> folder of the book’s GitHub repository (<a href="https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp">https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp</a>):</p>
<pre class="programlisting code"><code class="hljs-code">public async Task&lt;IList&lt;RouteRequestAggregate&gt;&gt; GetMatch(
    IEnumerable&lt;Coordinate&gt; geometry, DateTime when, 
    double distance, int maxResults)
{
    var lineString = new LineString(geometry.ToArray())
        { SRID = GeometryConstants.DefaultSRID };
    var entities = await ctx.RouteRequests.Where(m =&gt;
        m.RouteId == null &amp;&amp;
        when &lt;= m.WhenEnd &amp;&amp; when &gt;= m.WhenStart &amp;&amp;
        lineString.Distance(m.Source.Location) &lt; distance &amp;&amp;
        lineString.Distance(m.Destination.Location) &lt; distance)
        .Select(m =&gt; new
        {
            Distance = lineString.Distance(m.Source.Location),
            Entity = m
        })
        .OrderBy(m =&gt; m.Distance)
        .Take(maxResults).ToListAsync();
    return entities
       .Select(m =&gt; new RouteRequestAggregate(m.Entity))
       .ToList();
}
</code></pre>
<p class="normal">First of all, we create a <code class="inlineCode">LineString</code> geometry from the route path, and then we start the query. The <code class="inlineCode">Where</code> clause first restricts the search to requests that are not already attached to other routes. Then, it verifies time compatibility and, finally, distance compatibility by using the <code class="inlineCode">LineString.Distance</code> method. All geometry objects have a <code class="inlineCode">Distance</code> method, so we can perform <a id="_idIndexMarker479"/>geometric queries <a id="_idIndexMarker480"/>involving any kind of geometric object. </p>
<p class="normal">Finally, we return an anonymous object with both the distance and the retrieved entity. This way, we can sort data by distance and extract the best <code class="inlineCode">maxResults</code> matches.</p>
<h3 class="heading-3" id="_idParaDest-140"><a id="_idTextAnchor195"/>The IRouteOfferRepository implementation</h3>
<p class="normal">Again, the <a id="_idIndexMarker481"/>repository structure is the same as the <a id="_idIndexMarker482"/>one of all previous repositories:</p>
<pre class="programlisting code"><code class="hljs-code">internal class RouteOfferRepository(IUnitOfWork uow) : IRouteOfferRepository
{
    readonly MainDbContext ctx = (uow as MainDbContext)!;
    public async Task DeleteBefore(DateTime milestone)
    …
    public async Task&lt;RouteOfferAggregate?&gt; Get(Guid id)
    …
    public async Task&lt;IList&lt;RouteOfferAggregate&gt;&gt; GetMatch(
        Point source, Point destination, TimeInterval when, 
 double distance, int maxResults)
    …
    public RouteOfferAggregate New(Guid id, Coordinate[] path, 
        UserBasicInfo user, DateTime When)
    …   
}
</code></pre>
<p class="normal">The <code class="inlineCode">DeleteBefore</code> method is analogous to the one of the previous repository:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task DeleteBefore(DateTime milestone)
{
    await ctx.RouteOffers.Where(m =&gt; m.When &lt; milestone).ExecuteDeleteAsync();
}
</code></pre>
<p class="normal">The <code class="inlineCode">New</code> method is also the same as the one of the requests repository, but it generates the <code class="inlineCode">NewMatchCandidateEvent&lt;</code> <code class="inlineCode">RouteOfferAggregate&gt;</code> event, whose handler looks for matching requests.</p>
<p class="normal">Again, we <a id="_idIndexMarker483"/>describe just the <code class="inlineCode">GetMatch</code> method since all other methods are quite standard:</p>
<pre class="programlisting code"><code class="hljs-code">public async Task&lt;IList&lt;RouteOfferAggregate&gt;&gt; GetMatch(
    Point source, Point destination, 
    TimeInterval when, double distance, int maxResults)
{
    var entities = await ctx.RouteOffers.Where(m =&gt; 
         m.Status == RouteStatus.Open &amp;&amp;
        m.When &lt;= when.End &amp;&amp; m.When &gt;= when.Start &amp;&amp;
        source.Distance(m.Path) &lt; distance)
        .Select(m =&gt; new
        {
            Distance = source.Distance(m.Path),
            Entity = m
        })
        .OrderBy(m =&gt; m.Distance)
        .Take(maxResults).ToListAsync();
            return entities
        .Select(m =&gt; new RouteOfferAggregate(m.Entity))
        .ToList();
}
</code></pre>
<p class="normal">The <code class="inlineCode">Where</code> clause first <a id="_idIndexMarker484"/>restricts the search just to all open routes. Then, it verifies time and distance constraints as in the same <code class="inlineCode">GetMatch</code> method of the previous repository. Also, sorting is the same as that in the previous repository.</p>
<p class="normal">Having defined everything, we can now move on to migration.</p>
<h3 class="heading-3" id="_idParaDest-141"><a id="_idTextAnchor196"/>Creating migrations and databases</h3>
<p class="normal">Before generating database migrations, we must implement the <code class="inlineCode">IDesignTimeDbContextFactory&lt;MainDbContext&gt;</code> interface inside the database driver. All migration tools look <a id="_idIndexMarker485"/>for this implementation to create the instance <a id="_idIndexMarker486"/>of <code class="inlineCode">MainDbContext</code> needed to get information on both the dat<a id="_idTextAnchor197"/>abase configuration and the database connection string. Therefore, let’s add a <code class="inlineCode">LibraryDesignTimeDbContextFactory</code> class to the root of the <code class="inlineCode">RoutesPlanningDBDriver</code> project:</p>
<pre class="programlisting code"><code class="hljs-code">internal class LibraryDesignTimeDbContextFactory : 
    IDesignTimeDbContextFactory&lt;MainDbContext&gt;
{
    private const string connectionString =
        @"Server=&lt;your sql server instance name&gt;;Database=RoutesPlanning;
        User Id=sa;Password=&lt;your password&gt;;Trust Server Certificate=True;
        MultipleActiveResultSets=true ";
    public MainDbContext CreateDbContext(string[] args)
    {
        var builder = new DbContextOptionsBuilder&lt;MainDbContext&gt;();
        builder.UseSqlServer(
            connectionString, 
            x =&gt; x.UseNetTopologySuite());
        return new MainDbContext(builder.Options);
    }
}
</code></pre>
<p class="normal">Please replace the placeholders I left in the string with your SQL Server instance name and password. The simplest way to get a connection string is by connecting to the database from within Visual <a id="_idIndexMarker487"/>Studio and then by copying the connection <a id="_idIndexMarker488"/>strings from the properties tab. Please don’t forget you can’t use the SQL database installed with Visual Studio since it is not able to listen to TCP/IP connections, so it cannot be accessed from within Docker images.</p>
<p class="normal">Now, we can also add the SQL Server connection string we left empty in <code class="inlineCode">launchSettings.json</code>:</p>
<pre class="programlisting code"><code class="hljs-code">"ConnectionStrings__DefaultConnection":
 "Server=host.docker.internal;Database=RoutesPlanning;User Id=sa;
    Password=&lt;our password&gt;;Trust Server Certificate=True;MultipleActiveResultSets=true"
</code></pre>
<p class="normal">Again, please add your password. <code class="inlineCode">host.docker.internal</code> is the network name of your development computer that hosts Docker or a local Kubernetes simulator. Use it if you performed a direct installation on your machine or if you ran a SQL Server Docker image on your computer. Replace it with the appropriate name if you are using a cloud or other network instance.</p>
<p class="normal">Now, let’s make <code class="inlineCode">RoutesPlanningDBDriver</code> our Visual Studio startup project, and select it in the Visual Studio <strong class="screenText">Package Manager Console</strong>:</p>
<figure class="mediaobject"><img alt="" role="presentation" src="img/B31916_07_5.png"/> </figure>
<p class="packt_figref">Figure 7.5: Selecting the project in Package Manager Console</p>
<p class="normal">We are ready <a id="_idIndexMarker489"/>to issue our first migration in <strong class="screenText">Package Manager Console</strong>:</p>
<pre class="programlisting con"><code class="hljs-con">Add-Migration initial
</code></pre>
<div><p class="normal">Please note that if you copied the project from the GitHub repository associated with the book, you don’t need to execute the preceding command since migrations have already been created there. You just need to create the database with the following command.</p>
</div>
<p class="normal">If the previous <a id="_idIndexMarker490"/>command was successful, you can create the database with the following command:</p>
<pre class="programlisting con"><code class="hljs-con">Update-Database
</code></pre>
<p class="normal">Done! We can now move on to the implementation of all command and event handlers.</p>
<h2 class="heading-2" id="_idParaDest-142"><a id="_idTextAnchor198"/>The application services: Defining all command and event handlers</h2>
<p class="normal">In this section, we will define all the required command and event handlers. Before starting, we need <a id="_idIndexMarker491"/>to add a reference to the <code class="inlineCode">Microsoft.Extensions.Configuration.Abstractions</code> and <code class="inlineCode">Microsoft.Extensions.Configuration.Binder</code> NuGet packages in the <code class="inlineCode">RoutesPlanningApplicationServices</code> project. This way, we enable all handlers to receive configuration data from the dependency injection engine through the <code class="inlineCode">IConfiguration</code> interface.</p>
<p class="normal">All command handler <a id="_idIndexMarker492"/>constructors require some repository interfaces, <code class="inlineCode">IUnitofWork</code> for finalizing <a id="_idIndexMarker493"/>modifications and handling transactions, and an <code class="inlineCode">EventMediator</code> instance for triggering all events added to the aggregates. </p>
<p class="normal">We will not describe all handlers, just the ones with a didactic added value. You can find the entire code in the <code class="inlineCode">ch07</code> folder of the book’s GitHub repository (<a href="https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp">https://github.com/PacktPublishing/Practical-Serverless-and-Microservices-with-Csharp</a>).</p>
<p class="normal">We will place all command handlers that process messages in a <code class="inlineCode">CommandHandlers -&gt; Messages</code> folder.</p>
<p class="normal">Let’s start with the <code class="inlineCode">RouterOfferMessage</code> handler: </p>
<pre class="programlisting code"><code class="hljs-code">internal class RouterOfferMessageHandler(
    IRouteOfferRepository repo,
    IUnitOfWork uow,
    EventMediator mediator
    ) : ICommandHandler&lt;MessageCommand&lt;RouteOfferMessage&gt;&gt;
{
    public async Task HandleAsync(MessageCommand&lt;RouteOfferMessage&gt; 
        command)
    {
        var message = command.Message;
        var toCreate = repo.New(message.Id,
          message.Path!.Select(m =&gt;
new Coordinate(m.Location!.Longitude, m.Location.Latitude)).
                           ToArray(),
            new UserBasicInfo { Id = message.User!.Id, 
                DisplayName = message.User.DisplayName! },
            message.When!.Value
           );
        if (toCreate.DomainEvents != null &amp;&amp; toCreate.DomainEvents.Count &gt; 
<a id="_idTextAnchor199"/> 0)
            await mediator.TriggerEvents(toCreate.DomainEvents);
        try
        {
            await uow.SaveEntitiesAsync();
        }
        catch (ConstraintViolationException) { }
    }
}
</code></pre>
<p class="normal">The handler extracts <a id="_idIndexMarker494"/>all data needed to create a new aggregate from the <a id="_idIndexMarker495"/>message and then passes it to the <code class="inlineCode">New</code> repository method. Then, it verifies whether the created aggregate contains events and uses the <code class="inlineCode">EventMediator</code> instances to trigger all associated event handlers. <code class="inlineCode">ConstraintViolationException</code> is created by the <code class="inlineCode">IUnitOdWork</code> implementation in case of unique key violations. In our case, this exception can be thrown just when we receive a duplicate <code class="inlineCode">RouterOfferMessage</code>. Therefore, we simply capture it and do nothing, since duplicate messages must be ignored.</p>
<p class="normal"><code class="inlineCode">RouteRequestMessageHandler</code> is completely analogous, so we will not describe it. </p>
<p class="normal">Let’s move <a id="_idIndexMarker496"/>on to <a id="_idIndexMarker497"/>the <code class="inlineCode">RouteClosedAbortedMessage</code> handler:</p>
<pre class="programlisting code"><code class="hljs-code">    public async Task HandleAsync(MessageCommand&lt;RouteClosedAbortedMessage&gt; command)
    {
        var message = command.Message;
        await uow.StartAsync(System.Data.IsolationLevel.Serializable);
        try
        {
            var route = await repo.Get(message.RouteId);
            if (route is not null)
            {
                if(!message.IsAborted)
                {
                    if(route.Status != RouteStatus.Open)
                    {
                        await uow.RollbackAsync();
                        return;
                    }
                    else route.Close();
                }
                else
                {
                    if(route.Status == RouteStatus.Aborted)
                    {
                        await uow.RollbackAsync();
                        return;
                    }
                    else route.Abort();
                }
                if (route.DomainEvents != null &amp;&amp; route.DomainEvents.Count 
                    &gt; 0)
                    mediator.Equals(route.DomainEvents);
                await uow.SaveEntitiesAsync();
                await uow.CommitAsync();
            }
            else
            {
                await uow.RollbackAsync();
                return;
            }
        }
        catch
        {
            await uow.RollbackAsync();
            throw;
        }
        
    }
}
</code></pre>
<p class="normal">The whole operation is enclosed in a serializable transaction to avoid interferences with other microservice replicas that might receive older or future messages concerning the same route offer. In fact, they might modify the same entity after it has been read but before it has been modified. The serializable transaction prevents this possibility.</p>
<p class="normal">If we don’t find the entity, we do nothing and simply abort the transaction. In fact, this eventuality might take place only if the route expires and is deleted. However, if entities are deleted after enough time has passed since they expired, this should be a substantially impossible event.</p>
<p class="normal">If the message specifies <a id="_idIndexMarker498"/>that the route must be closed, we put the aggregate <a id="_idIndexMarker499"/>in the closed state by calling <code class="inlineCode">Close()</code> only if the aggregate is still open. In fact, if it is either already closed or aborted, this will be an old message or a duplicate that must be ignored.</p>
<p class="normal">Similarly, if the message specifies that the route should be aborted, it is processed only if the aggregate is not already in an aborted state.</p>
<p class="normal">Finally, in case of errors, we abort the transaction and rethrow the exception, so the message will not be confirmed and the message will be processed again at a later time, possibly by a different replica.</p>
<p class="normal">Now, let’s move on to the <code class="inlineCode">RouteExtendedMessage</code> handler:</p>
<pre class="programlisting code"><code class="hljs-code">internal class RouteExtendedMessageHandler(
    IRouteOfferRepository repo,
    IUnitOfWork uow,
    EventMediator mediator
    ) : ICommandHandler&lt;MessageCommand&lt;RouteExtendedMessage&gt;&gt;
{
    public async Task HandleAsync(MessageCommand&lt;RouteExtendedMessage&gt; command)
    {
        var message = command.Message;
        await uow.StartAsync(System.Data.IsolationLevel.Serializable);
        try
        {
            var route = await repo.Get(message.ExtendedRoute!.Id);
            if (route is not null &amp;&amp; route.TimeStamp != message.TimeStamp)
            {
                route.Extend(message.TimeStamp,
                    message.AddedRequests!.Select(m =&gt; m.Id),
                    message.ExtendedRoute.Path!
                        .Select(m =&gt; new Coordinate(m.Location!.Longitude,
                            m.Location.Latitude)).ToArray(),message.
                              Closed);
                if (route.DomainEvents != null &amp;&amp; route.DomainEvents.Count 
                    &gt; 0)
                    mediator.Equals(route.DomainEvents);
                await uow.SaveEntitiesAsync();
                await uow.CommitAsync();
            }
            else
            {
                await uow.RollbackAsync();
                return;
            }
        }
        catch
        {
            await uow.RollbackAsync();
            throw;
        }
    }
}
</code></pre>
<p class="normal">Also, in this case, since the <a id="_idIndexMarker500"/>command handler performs both a read <a id="_idIndexMarker501"/>and a modification, we need an explicit transaction. </p>
<p class="normal">Again, if no entity is found, we do nothing for the same reasons explained for the previous handler. We also do nothing if the message timestamp is identical to the one contained in the entity, because in this case, the message is a duplicate. Otherwise, we simply call the aggregate <code class="inlineCode">Extend</code> method, and then trigger possible events generated by the <code class="inlineCode">Extend</code> method.</p>
<p class="normal">Let’s now move on to handlers that are not related to messages. They are placed in the root of the <code class="inlineCode">CommandHandlers</code> folder.</p>
<p class="normal">Let’s start with <code class="inlineCode">HouseKeepingCommandHandler</code>, which deletes old expired requests and routes:</p>
<pre class="programlisting code"><code class="hljs-code">internal class HouseKeepingCommandHandler(
    IRouteRequestRepository requestRepo,
    IRouteOfferRepository offerRepo
    ) : ICommandHandler&lt;HouseKeepingCommand&gt;
{
    public async Task HandleAsync(HouseKeepingCommand command)
    {
        var deleteTrigger = DateTime.Now.AddDays( -command.DeleteDelay );
        await offerRepo.DeleteBefore(deleteTrigger);
        await requestRepo.DeleteBefore(deleteTrigger);
    }
}
</code></pre>
<p class="normal">It is very simple, since it just subtracts the delay or the deletion of all expired entities from the current time and <a id="_idIndexMarker502"/>then calls the repository methods for deleting routes <a id="_idIndexMarker503"/>and requests. It doesn’t need to save changes since each of these methods already interacts with the database.</p>
<p class="normal">The <code class="inlineCode">OutputSendingCommandHandler</code> that handles the output queue is a little bit more complex:</p>
<pre class="programlisting code"><code class="hljs-code">internal class OutputSendingCommandHandler(
    IOutputQueueRepository repo,
    IUnitOfWork uow
    ): ICommandHandler&lt;
        OutputSendingCommand&lt;RouteExtensionProposalsMessage&gt;&gt;
{
    public async Task HandleAsync(OutputSendingCommand&lt;
        RouteExtensionProposalsMessage&gt; command)
    {
        var aggregates =await repo.Take
            (command.BatchCount, command.RequeueDelay);
        if(aggregates.Count==0)
        {
            command.OutPutEmpty = true;
            return;
        }
        var allTasks = aggregates.Select(
            m =&gt; (m, command.Sender(m.GetMessage&lt;
                RouteExtensionProposalsMessage&gt;()!)))
            .ToDictionary(m =&gt; m.Item1!, m =&gt; m.Item2 );
        try
        {
            await Task.WhenAll(allTasks.Values.ToArray());
        }
        catch
        {
        }
        repo.Confirm(aggregates
            .Where(m =&gt;!allTasks[m].IsFaulted &amp;&amp; !allTasks[m].IsFaulted)
            .Select(m =&gt; m.Id).ToArray());
        await uow.SaveEntitiesAsync();
    } 
</code></pre>
<p class="normal">It tries to take <code class="inlineCode">command.BatchCount</code> items from the output queue. If no item is found, it informs the command that the queue is empty, which, in turn, informs the queue-handling hosted service that it can sleep for a little while. </p>
<p class="normal">Then, it deserializes all <a id="_idIndexMarker504"/>messages and passes them to the <code class="inlineCode">Sender</code> delegate. However, instead of awaiting each task returned by this method, it collects all of them, puts them <a id="_idIndexMarker505"/>in an array, and awaits the whole array with <code class="inlineCode">Task.WhenAll</code>. This way, all messages are sent concurrently, thus improving performance. In case of exceptions, it simply does nothing, because unsent messages are detected in the LINQ instruction inside <code class="inlineCode">repo.Confirm</code> and their associated queue items are excluded from the array of all items to confirm, so they will be retried at a later time.</p>
<p class="normal">We are done with all the command handlers. Let’s move on to the event handlers.</p>
<h3 class="heading-3" id="_idParaDest-143"><a id="_idTextAnchor200"/>Coding all event handlers</h3>
<p class="normal">Usually, event handlers do not create transactions and do not attempt to store modifications in the database, since they <a id="_idIndexMarker506"/>are invoked by command handlers, which do this task for them; so, their code tends to be a little bit simpler. We have four event handlers, which are all placed in the root of the <code class="inlineCode">EventHandlers</code> folder.</p>
<p class="normal">Let’s start with the <code class="inlineCode">AttachedRequestEvent</code> handler:</p>
<pre class="programlisting code"><code class="hljs-code">internal class AttachedRequestEventHandler(
    IRouteRequestRepository repo
    ) : IEventHandler&lt;AttachedRequestEvent&gt;
{
    public async Task HandleAsync(AttachedRequestEvent ev)
    {
        var requests = await repo.Get(ev.AddedRequests.ToArray());
        foreach (var request in requests) request.AttachToRoute(
            ev.RouteOffer);
    }
}
</code></pre>
<p class="normal">This handler is responsible for attaching requests to a route. Its code is trivial: it just retrieves all aggregates from their keys and then attaches them to the route referenced in the event.</p>
<p class="normal">The <code class="inlineCode">ReleasedRequestsEvent</code> handler is responsible for releasing all requests attached to an aborted route. Its code is trivial, too:</p>
<pre class="programlisting code"><code class="hljs-code">internal class ReleasedRequestsEventHandler(
    IRouteRequestRepository repo
    ) : IEventHandler&lt;ReleasedRequestsEvent&gt;
{
    public async Task HandleAsync(ReleasedRequestsEvent ev)
    {
        var requests=await repo.GetInRoute(ev.AbortedRoute);
        foreach(var request in requests) request.DetachFromRoute();
    }
}
</code></pre>
<p class="normal">It retrieves all requests attached to the route and simply detaches each of them.</p>
<p class="normal">Finally, we have two <a id="_idIndexMarker507"/>event handlers that discover route-request matches and add them to the microservice output queue. The first one is triggered when a new request is added, while the second one is triggered when a new offer is added. Since they are very similar, we will describe just the first one:</p>
<pre class="programlisting code"><code class="hljs-code">internal class RequestMatchCandidateEventHandler(
    IRouteOfferRepository offerRepo,
    IOutputQueueRepository queueRepo,
    IConfiguration configuration) : 
        IEventHandler&lt;NewMatchCandidateEvent&lt;RouteRequestAggregate&gt;&gt;
{
    private RouteRequestMessage PrepareMessage(RouteRequestAggregate m)
        =&gt; new RouteRequestMessage
        …
         …
    public async Task HandleAsync(
NewMatchCandidateEvent&lt;RouteRequestAggregate&gt; ev)
    {
        double maxDistance = configuration
            .GetValue&lt;double&gt;("Topology:MaxDistanceKm") * 1000d;
        int maxResults = configuration
            .GetValue&lt;int&gt;("Topology:MaxMatches");
        var offers = await offerRepo.GetMatch(
            ev.MatchCandidate.Source.Location, 
            ev.MatchCandidate.Destination.Location,
            ev.MatchCandidate.When, maxDistance, maxResults);
        var proposals = Enumerable.Repeat(ev.MatchCandidate, 1)
            .Select(m =&gt; PrepareMessage(m)).ToList();
        foreach (var offer in offers)
        {
            var message = new RouteExtensionProposalsMessage
            {
                RouteId = offer.Id,
                Proposals = proposals,
            };
            queueRepo.New&lt;RouteExtensionProposalsMessage&gt;(message, 1);
        }
    }
}
</code></pre>
<p class="normal">The <code class="inlineCode">PrepareMessage</code> method <a id="_idIndexMarker508"/>just fills a <code class="inlineCode">RouteRequestMessage</code> using data contained in the corresponding <code class="inlineCode">RouteRequest\regate</code>. We will not describe it, since it is trivial.</p>
<p class="normal">The <code class="inlineCode">HandleAsync</code> method first <a id="_idIndexMarker509"/>extracts the parameters needed for the search <a id="_idIndexMarker510"/>from configuration data. Then, it calls the repository <code class="inlineCode">GetMatch</code> method to find all matches. Finally, for each route retrieved, it creates an output message and adds it to the internal queue. The request is turned into a singleton list since the output message requires a list.</p>
<p class="normal">The code of our microservice is finished! We will test it in the next chapter after connecting it with message sources and message receivers. There, we will also implement the microservice health check endpoints and connect them to the orchestrator.</p>
<h1 class="heading-1" id="_idParaDest-144"><a id="_idTextAnchor201"/>Summary</h1>
<p class="normal">This chapter described in detail how to design and code a <strong class="keyWord">Dockerized</strong> microservice. In particular, it described how to design its input and output messages and endpoints, as well as how to use a message broker to implement event-based communication. It also described how to handle out-of-order and duplicated messages, concurrent output production with several microservice replicas, and transactional outputs with a database internal queue.</p>
<p class="normal">Then, it described how the organization of worker services is based on hosted services and how in this case, commands are carried out in one-to-one correspondence with all input messages. Finally, it described how to code all of the Onion Architecture levels of any microservice.</p>
<p class="normal">All concepts were explained through the practical example of the route-planning worker microservice of the book’s case study application. You should now understand the practical usage of the RabbitMQ message broker and the <code class="inlineCode">NetTopologySuite</code> library for implementing spatial calculations and queries.</p>
<p class="normal">The next chapter describes orchestrators with a specific focus on Kubernetes. There, we will test the microservice coded in this chapter by connecting it with other microservices, and by using an orchestrator to manage all microservices.</p>
<h1 class="heading-1" id="_idParaDest-145"><a id="_idTextAnchor202"/>Questions</h1>
<ol>
<li class="numberedList" value="1">Do worker microservices typically need authentication and authorization? What about encrypted communication protocols?</li>
</ol>
<p class="normal-one">They don’t need authentication because their processing is not connected to a specific application user. Encrypted communication is advised but not always necessary since they run in an isolated environment.</p>
<ol>
<li class="numberedList" value="2">Where is it advised to place all microservices’ input and output messages?</li>
</ol>
<p class="normal-one">In some kind of queues.</p>
<ol>
<li class="numberedList" value="3">What is the name of the technique for maintaining the right processing order of messages while using several microservice replicas?</li>
</ol>
<p class="normal-one">Sharding.</p>
<ol>
<li class="numberedList" value="4">Is it true that if modification messages contain the whole updated entities, and if deletes are logical, then the order of messages doesn’t matter? </li>
</ol>
<p class="normal-one">Yes, it is true.</p>
<ol>
<li class="numberedList" value="5">Which library is typically used in .NET for handling failures with retry policies?</li>
</ol>
<p class="normal-one">Polly is used in .NET for handling failures with retry policies.</p>
<ol>
<li class="numberedList" value="6">Where are domain events created? Where are they before their handlers are fired?</li>
</ol>
<p class="normal-one">In a list contained in the aggregates that created them.</p>
<ol>
<li class="numberedList" value="7">Why do event handlers typically not use transactions and <code class="inlineCode">IUnitOfWork.SaveEntitiesAsync</code>?</li>
</ol>
<p class="normal-one">Because transactions are created and handled by the Command Handlers that caused the events.</p>
<ol>
<li class="numberedList" value="8">When sending several concurrent output messages, how can we discover which ones succeeded, which ones failed, and which ones were canceled?</li>
</ol>
<p class="normal-one">Through acknowledgments.</p>
<ol>
<li class="numberedList" value="9">What is an SRID?</li>
</ol>
<p class="normal-one">Spatial Reference Identifiers. They name geographic coordinate systems.</p>
<ol>
<li class="numberedList" value="10">Can the <code class="inlineCode">Distance</code> method of all <code class="inlineCode">NetTopologySuite</code> geometric objects be used in LINQ queries to a SQL Server database?</li>
</ol>
<p class="normal-one">Yes.</p>
<h1 class="heading-1" id="_idParaDest-146"><a id="_idTextAnchor203"/>Further reading</h1>
<ul>
<li class="bulletList">RabbitMQ official documentation: <a href="https://www.rabbitmq.com/">https://www.rabbitmq.com/</a>.</li>
<li class="bulletList">EasyNetQ official documentation: <a href="https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction">https://github.com/EasyNetQ/EasyNetQ/wiki/Introduction</a>.</li>
<li class="bulletList">Polly documentation: <a href="https://github.com/App-vNext/Polly">https://github.com/App-vNext/Polly</a>.</li>
<li class="bulletList">RabbitMQ sharding plugin: <a href="https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding">https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_sharding</a>.</li>
<li class="bulletList">Spatial data extensions for Entity Framework Core: <a href="https://learn.microsoft.com/en-us/ef/core/modeling/spatial">https://learn.microsoft.com/en-us/ef/core/modeling/spatial</a>.</li>
<li class="bulletList">NetTopologySuite: <a href="https://nettopologysuite.github.io/NetTopologySuite/">https://nettopologysuite.github.io/NetTopologySuite/</a>.</li>
</ul>
<h1 class="heading-1" id="_idParaDest-147"><a id="_idTextAnchor204"/>Join our community on Discord</h1>
<p class="normal">Join our community’s Discord space for discussions with the author and other readers:</p>
<p class="normal"><a href="https://packt.link/PSMCSharp">https://packt.link/PSMCSharp</a></p>
<p class="normal"><img alt="A qr code with black squares  AI-generated content may be incorrect." src="img/B31916_Discord-QR-Code.png"/></p>
</div>
</body></html>