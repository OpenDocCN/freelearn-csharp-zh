<html><head></head><body>
  <div><h1 class="chapter-number" id="_idParaDest-182">
    <a id="_idTextAnchor183">
    </a>
    
     11
    
   </h1>
   <h1 id="_idParaDest-183">
    <a id="_idTextAnchor184">
    </a>
    
     Cloud-Native Development with ASP.NET Core 9
    
   </h1>
   <p>
    
     Modern applications are designed to operate in cloud environments and take advantage of the various features provided, such as agility, scalability, availability, and resilience.
    
    
     ASP.NET Core 9 provides us with a set of powerful tools that allow us to develop high-quality solutions.
    
    
     However, it is important to be aware of the patterns and best practices related to the cloud-native
    
    
     
      development model.
     
    
   </p>
   <p>
    
     In this chapter, we will learn about important aspects related to applications hosted in cloud environments, exploring patterns, best practices, the mindset required for cloud-native application development, the principles of the twelve-factor app, and architectural design principles so that you can get the most out of your
    
    
     
      cloud environment.
     
    
   </p>
   <p>
    
     In this chapter, we will focus on the
    
    
     
      following topics:
     
    
   </p>
   <ul>
    <li>
     
      Creating a
     
     
      
       cloud-native mindset
      
     
    </li>
    <li>
     
      Working with
     
     
      
       cloud-native tools
      
     
    </li>
    <li>
     
      The principles of the
     
     
      
       twelve-factor app
      
     
    </li>
    <li>
     
      Understanding cloud
     
     
      
       architecture principles
      
     
    </li>
   </ul>
   <h1 id="_idParaDest-184">
    <a id="_idTextAnchor185">
    </a>
    
     Technical requirements
    
   </h1>
   <p>
    
     The code examples used in this chapter can be found in the book’s GitHub
    
    
     
      repository:
     
    
    <a href="https://github.com/PacktPublishing/ASP.NET-Core-9.0-Essentials/tree/main/Chapter11">
     
      
       https://github.com/PacktPublishing/ASP.NET-Core-9.0-Essentials/tree/main/Chapter11
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     In order for you to take advantage of all the examples proposed in this chapter, it is important that you fork the book repository.
    
    
     Forking is a feature available on GitHub that copies a repository so that it can be managed by a Git user.
    
    
     You can learn how to fork a repository using the following
    
    
     
      URL:
     
    
    <a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo">
     
      
       https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo
      
     
    </a>
    
     
      .
     
    
   </p>
   <h1 id="_idParaDest-185">
    <a id="_idTextAnchor186">
    </a>
    
     Creating a cloud-native mindset
    
   </h1>
   <p>
    
     Every year brings new
    
    <a id="_idIndexMarker912">
    </a>
    
     innovations in cloud computing: there are always new features that bring new possibilities and companies that want new ways to deliver value to users in an increasingly
    
    
     
      demanding market.
     
    
   </p>
   <p>
    
     In previous chapters, we learned about various tools, patterns, and best practices and interacted with cloud resources.
    
    
     But even in a scenario where applications are built with best practices and standards in mind, are they able to benefit from all the features that a cloud environment
    
    
     
      can provide?
     
    
   </p>
   <p>
    
     Even today, there are many organizations that run applications in private environments (on-premises), which brings several benefits.
    
    
     Consequently, applications developed in these environments have limited scalability and deal with high costs for purchasing servers and qualified professionals to maintain them..
    
    
     In this solution model, computing resources are limited, but at the same time, it brings benefits of greater control, compliance, and security
    
    
     
      for companies.
     
    
   </p>
   <p>
    
     The cloud appears is an alternative to this model that enhances computing power for organizations, but at the same time, several other challenges arise, including in the development model
    
    
     
      and process.
     
    
   </p>
   <p>
    
     To use the cloud model, we need to understand how it works, its service layers, the necessary investments, and how we can adapt our applications to a
    
    
     
      cloud-native model.
     
    
   </p>
   <p>
    
     Let’s start by looking at the service layers offered in
    
    
     
      cloud environments.
     
    
   </p>
   <h2 id="_idParaDest-186">
    <a id="_idTextAnchor187">
    </a>
    
     Understanding the service layers in a cloud environment
    
   </h2>
   <p>
    
     Maybe you’ve already heard about
    
    <strong class="bold">
     
      CapEx
     
    </strong>
    
     and
    
    <strong class="bold">
     
      OpEx
     
    </strong>
    
     and how important these two words are in the
    
    
     
      corporate world:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Capital expenditure
      
     </strong>
     
      (
     
     <strong class="bold">
      
       CapEx
      
     </strong>
     
      ): CapEx is
     
     <a id="_idIndexMarker913">
     </a>
     
      not a term exclusive to the IT area but is a financial term related to expenses or investments in assets.
     
     
      The calculation is simple: if there is a need for more servers to support user demand, CAPex comes into play and is related to the cost of investment in servers, physical location for installing the servers, electricity, UPS, and
     
     
      
       so on.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Operating expenditure
      
     </strong>
     
      (
     
     <strong class="bold">
      
       OpEx
      
     </strong>
     
      ): OpEx refers to the ongoing costs of running daily operations.
     
     
      This
     
     <a id="_idIndexMarker914">
     </a>
     
      includes expenses for services, utilities, rent, software licensing, and other operational activities such as
     
     
      
       staff salaries.
      
     
    </li>
   </ul>
   <p>
    
     Observing these concepts, every organization needs to reflect on its investments, costs, and professionals to
    
    
     
      remain competitive.
     
    
   </p>
   <p>
    
     When moving to an approach involving cloud computing, the transition from
    
    <a id="_idIndexMarker915">
    </a>
    
     CapEx to OpEx takes place.
    
    
     This change has
    
    
     
      several implications:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Reduced upfront costs
      
     </strong>
     
      : Adopting cloud services reduces the need for large upfront investments in physical hardware and infrastructure.
     
     
      Instead, organizations pay for the cloud services
     
     
      
       they use.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Scalable costs
      
     </strong>
     
      : Cloud services offer a pay-as-you-go model, allowing organizations to scale their usage and expenses according
     
     
      
       to demand.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Operational flexibility
      
     </strong>
     
      : Ability to quickly adapt to changes in business needs without dependence on investments
     
     
      
       in hardware.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Maintenance and updates
      
     </strong>
     
      : Cloud providers such as Azure provide infrastructure maintenance, updates, and security services, reducing the operational burden on an organization’s IT team and allowing them to focus on
     
     
      
       strategic initiatives.
      
     
    </li>
   </ul>
   <p>
    
     However, having services running in the cloud does not mean that there will be less cost as there is a pay-as-you-go model.
    
    
     As with any tool or strategy, if not used correctly, the cloud can cause major problems
    
    
     
      for organizations.
     
    
   </p>
   <p>
    
     Cloud providers such as Azure take care of the entire infrastructure for providing computing services; however, there is shared management with the organizations that use the services.
    
    
     This service model is very important
    
    
     
      to understand.
     
    
   </p>
   <p>
    
     In the cloud computing model, organizations focus their efforts on their products and services, benefiting from shared management with cloud providers.
    
    
     Organizations basically have three options to choose from when deciding what service model
    
    
     
      they want:
     
    
   </p>
   <div><div><img alt="Figure 11.1 – Cloud computing services offer" src="img/B21788_11_01.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.1 – Cloud computing services offer
    
   </p>
   <p>
    
     As shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .1
     
    </em>
    
     , we have the following types of
    
    
     
      service layers:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Infrastructure as a Service (IaaS)
      
     </strong>
     
      : Provides virtualized computing resources, where the company dynamically
     
     <a id="_idIndexMarker916">
     </a>
     
      provisions virtual machines, storage, and networking.
     
     
      It is a common adoption model in on-premises migration strategies to
     
     
      
       the cloud.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Platform as a Service (PaaS)
      
     </strong>
     
      : Provides a platform that abstracts infrastructure, allowing organizations and development teams to focus on solutions and data.
     
     
      We used a PaaS
     
     <a id="_idIndexMarker917">
     </a>
     
      resource in
     
     <a href="B21788_10.xhtml#_idTextAnchor162">
      
       <em class="italic">
        
         Chapter 10
        
       </em>
      
     </a>
     
      when publishing an Azure App
     
     
      
       Service application.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Software as a Service (SaaS)
      
     </strong>
     
      : Provides
     
     <a id="_idIndexMarker918">
     </a>
     
      software applications on a subscription basis, such as streaming applications and Microsoft
     
     
      
       365 applications.
      
     
    </li>
   </ul>
   <p>
    
     Cloud services are essential components of cloud-native development, helping to define migration strategies, cost optimization, scalability, resiliency, security,
    
    
     
      and deployment.
     
    
   </p>
   <p>
    
     So that we can understand how we should adapt our tools and development processes and benefit from the power of cloud computing, it is important to start with
    
    
     
      best practices.
     
    
   </p>
   <h2 id="_idParaDest-187">
    <a id="_idTextAnchor188">
    </a>
    
     Cloud-native development best practices
    
   </h2>
   <p>
    
     Microsoft provides extensive documentation and powerful services in Azure, where it is possible to host applications using different technologies and, of course, solutions developed in ASP.NET
    
    
     
      Core 9.
     
    
   </p>
   <p>
    
     In addition to documenting the resources available in Azure, it is very important that development teams know about
    
    <a id="_idIndexMarker919">
    </a>
    
     the
    
    <strong class="bold">
     
      Cloud Adoption Framework
     
    </strong>
    
     (
    
    <strong class="bold">
     
      CAF
     
    </strong>
    
     ) and the
    
    <strong class="bold">
     
      Well-Architected Framework
     
    </strong>
    
     (
    
    <strong class="bold">
     
      WAF
     
    </strong>
    
     ).
    
    
     These two resources have different use cases and help teams
    
    <a id="_idIndexMarker920">
    </a>
    
     deal with various challenges posed by
    
    
     
      cloud environments.
     
    
   </p>
   <p>
    
     Let’s briefly learn about each of
    
    
     
      these features.
     
    
   </p>
   <h3>
    
     The CAF
    
   </h3>
   <p>
    
     Microsoft’s CAF
    
    <a id="_idIndexMarker921">
    </a>
    
     has an excellent collection of documentation, implementation guidance, best practices, and tools designed to help organizations plan and execute their cloud
    
    
     
      adoption strategy.
     
    
   </p>
   <p>
    
     The CAF basically consists of
    
    
     
      seven phases:
     
    
   </p>
   <ol>
    <li>
     <strong class="bold">
      
       Strategy
      
     </strong>
     
      : Define
     
     <a id="_idIndexMarker922">
     </a>
     
      business outcomes, establish a cloud adoption plan, and prioritize workloads
     
     
      
       for migration.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Plan
      
     </strong>
     
      : Assess
     
     <a id="_idIndexMarker923">
     </a>
     
      your current digital estate, create a cloud adoption plan, and identify gaps in required skills
     
     
      
       and resources.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Ready
      
     </strong>
     
      : Prepare
     
     <a id="_idIndexMarker924">
     </a>
     
      the environment for cloud adoption by configuring a landing zone that includes governance, security, and
     
     
      
       management tools.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Migrate
      
     </strong>
     
      : Migrate
     
     <a id="_idIndexMarker925">
     </a>
     
      workloads to the cloud, using tools and methodologies to ensure a
     
     
      
       smooth transition.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Innovate
      
     </strong>
     
      : Develop new
     
     <a id="_idIndexMarker926">
     </a>
     
      cloud-native applications or modernize existing applications to make the most of
     
     
      
       cloud capabilities.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Govern
      
     </strong>
     
      : Implement
     
     <a id="_idIndexMarker927">
     </a>
     
      governance best practices to ensure compliance, manage risk, and establish
     
     
      
       security controls.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Manage
      
     </strong>
     
      : Operate and
     
     <a id="_idIndexMarker928">
     </a>
     
      manage the cloud environment, using monitoring and management tools to ensure performance, reliability, and
     
     
      
       cost efficiency.
      
     
    </li>
   </ol>
   <p class="callout-heading">
    
     CAF
    
   </p>
   <p class="callout">
    
     CAF has extensive documentation and resources that should be part of a software engineer’s daily life.
    
    
     To learn
    
    <a id="_idIndexMarker929">
    </a>
    
     more,
    
    
     
      visit
     
    
    <a href="https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/">
     
      
       https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     The CAF aims to help organizations adopt a cloud-native mindset, emphasizing the importance of planning, governance, and continuous improvement, ensuring that cloud adoption aligns with
    
    
     
      business objectives.
     
    
   </p>
   <p>
    
     The CAF
    
    <a id="_idIndexMarker930">
    </a>
    
     is an excellent source of knowledge, and generally, the focus is not exactly on one application (or workload, as they are commonly called) but on structuring the entire environment in general.
    
    
     However, it can be used as an excellent source of knowledge and planning for new workloads, as it involves business teams, development, infrastructure, and the entire continuous
    
    
     
      delivery flow.
     
    
   </p>
   <p>
    
     In addition to the CAF, there is another very important resource that must be taken into consideration when defining application architectural models for your
    
    
     
      cloud environment.
     
    
   </p>
   <h3>
    
     The WAF
    
   </h3>
   <p>
    
     The WAF is a
    
    <a id="_idIndexMarker931">
    </a>
    
     set of capabilities offered by Microsoft that contains best practices, principles, and architectural guidance for designing, building, and operating secure, high-performance, resilient, and efficient infrastructures for your cloud applications.
    
    
     The WAF is subdivided into
    
    
     
      five pillars:
     
    
   </p>
   <ol>
    <li>
     <strong class="bold">
      
       Operational excellence
      
     </strong>
     
      : This
     
     <a id="_idIndexMarker932">
     </a>
     
      pillar focuses on operational processes that keep applications running smoothly and efficiently.
     
     
      This includes monitoring, automation, and
     
     
      
       incident response.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Security
      
     </strong>
     
      : This pillar
     
     <a id="_idIndexMarker933">
     </a>
     
      ensures that applications and data are protected from threats.
     
     
      It covers identity management, infrastructure protection, data encryption, and
     
     
      
       threat detection.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Reliability
      
     </strong>
     
      : This pillar
     
     <a id="_idIndexMarker934">
     </a>
     
      ensures that applications can recover from failures and continue to function as expected.
     
     
      This includes disaster recovery strategies, fault tolerance, and
     
     
      
       data backup.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Performance efficiency
      
     </strong>
     
      : This
     
     <a id="_idIndexMarker935">
     </a>
     
      pillar ensures that applications use resources efficiently and can scale to meet demand.
     
     
      It covers capacity planning, resource optimization, and
     
     
      
       performance monitoring.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Cost optimization
      
     </strong>
     
      : This pillar
     
     <a id="_idIndexMarker936">
     </a>
     
      focuses on effectively managing costs while delivering optimal performance and value.
     
     
      This includes cost monitoring, usage analysis, and implementing cost
     
     
      
       reduction strategies.
      
     
    </li>
   </ol>
   <p class="callout-heading">
    
     Learn more about the WAF
    
   </p>
   <p class="callout">
    
     The WAF not only provides great documentation containing strategies and best practices in relation to each of the five pillars, but it also provides tools, such as
    
    <strong class="bold">
     
      Assessment
     
    </strong>
    
     , where it is possible to analyze your existing cloud workloads to improve them, checklists, and many other resources.
    
    
     To
    
    <a id="_idIndexMarker937">
    </a>
    
     learn more about the WAF,
    
    
     
      visit
     
    
    <a href="https://learn.microsoft.com/en-us/azure/well-architected/">
     
      
       https://learn.microsoft.com/en-us/azure/well-architected/
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     Each of the pillars presented previously supports a cloud-native mindset, providing clear and practical guidelines for each workload.
    
    
     This allows teams to not only analyze solutions from different perspectives but also make the best of the cloud environment through high-quality solutions that meet organizational objectives, such as
    
    
     
      cost optimization.
     
    
   </p>
   <h2 id="_idParaDest-188">
    <a id="_idTextAnchor189">
    </a>
    
     Going beyond code development
    
   </h2>
   <p>
    
     To achieve a cloud-native solutions mindset, as software engineers, we must be prepared to go beyond the boundaries of
    
    
     
      code development.
     
    
   </p>
   <p>
    
     The DevOps culture brings a collaboration model that is not just restricted to different teams communicating effectively but extends to sharing knowledge, standards, and
    
    
     
      best practices.
     
    
   </p>
   <p>
    
     Operations teams have adapted to the code development model by using technology such as Infrastructure as Code, GitHub repositories, and
    
    
     
      even pipelines.
     
    
   </p>
   <p>
    
     Likewise, it is important that we learn concepts related to networking, infrastructure, security, and data.
    
    
     This will make all the difference in the architectural design and development of solutions that make the best of cloud environments and will help create a
    
    
     
      cloud-native mindset.
     
    
   </p>
   <p>
    
     Now that we have an insight into the challenges associated with cloud computing, it’s time to learn about
    
    
     
      cloud-native tools.
     
    
   </p>
   <h1 id="_idParaDest-189">
    <a id="_idTextAnchor190">
    </a>
    
     Working with cloud-native tools
    
   </h1>
   <p>
    
     In an increasingly competitive market, being agile and delivering solutions quickly has become synonymous
    
    
     
      with success.
     
    
   </p>
   <p>
    
     The cloud-native approach
    
    <a id="_idIndexMarker938">
    </a>
    
     is associated with agility and speed, allowing teams to create solutions, and adding layers of services and functionalities with loose coupling, resilience, management,
    
    
     
      and observability.
     
    
   </p>
   <p>
    
     However, we must understand the relationship between agility and speed when it comes to developing cloud-native applications.
    
    
     Being agile is not being fast, and being fast does not necessarily mean being agile.
    
    
     That completely changes the way we think about
    
    
     
      a solution.
     
    
   </p>
   <p>
    
     Let’s say your team received a
    
    <a id="_idIndexMarker939">
    </a>
    
     request to create an API that aims to provide data on products available for sale in an online store, as shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .2
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.2 – Online store consuming a Product API" src="img/B21788_11_02.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.2 – Online store consuming a Product API
    
   </p>
   <p>
    
     In the example shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .12
     
    </em>
    
     , the Product API would be an application in ASP.NET Core 9, containing good layer and package separation practices – let’s say it’s hosted in Microsoft Azure.
    
    
     From an application perspective, all expected API features have most likely been implemented according to functional and non-functional requirements.
    
    
     It is also expected that the quality process has been carried out satisfactorily, as shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .3
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.3 – Development and publishing flow" src="img/B21788_11_03.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.3 – Development and publishing flow
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .3
     
    </em>
    
     shows a common
    
    <a id="_idIndexMarker940">
    </a>
    
     scenario of a software development process, involving task management, requirements, coding, deployment, and
    
    
     
      application maintenance.
     
    
   </p>
   <p>
    
     The main objective is to quickly meet market needs, that is, reducing the lead time for
    
    
     
      delivering value.
     
    
   </p>
   <p>
    
     The shorter the lead time, the better.
    
    
     For teams and organizations to be able to strike a good balance between agility and speed, it is very important to understand the factors in each of the process steps shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .3
      
     </em>
    
    
     
      .
     
    
   </p>
   <p>
    
     An application developed and delivered in an environment is not necessarily a cloud-native solution.
    
    
     As software engineers, we must go beyond the artifact generated after compiling a code, and, prepare applications to be able to take full advantage of cloud environments and handle growing user demand., we must be prepared to act in different areas
    
    
     
      of knowledge.
     
    
   </p>
   <p>
    
     Therefore, cloud-native solutions must be based on factors such as
    
    
     
      the following:
     
    
   </p>
   <ul>
    <li>
     
      
       Infrastructure
      
     
    </li>
    <li>
     
      
       Modern design
      
     
    </li>
    <li>
     
      
       DevOps
      
     
    </li>
    <li>
     
      
       Support services
      
     
    </li>
    <li>
     
      Containers
     
     
      
       and orchestrators
      
     
    </li>
    <li>
     
      
       Microservices
      
     
    </li>
   </ul>
   <p>
    
     These factors can be represented graphically
    
    
     
      as follows:
     
    
   </p>
   <p class="IMG---Figure">
   </p>
   <div><div><img alt="Figure 11.4 – Cloud-native factors" src="img/B21788_11_04.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.4 – Cloud-native factors
    
   </p>
   <p>
    
     These factors
    
    <a id="_idIndexMarker941">
    </a>
    
     form the basis for the development of cloud-native solutions and must be worked on continuously, since changes, both in service requirements and market needs,
    
    
     
      are constant.
     
    
   </p>
   <p>
    
     Another important factor that we can notice in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .4
     
    </em>
    
     is that there is no relationship between the factors and a specific cloud provider, such as Azure, AWS, or GCP.
    
    
     On the contrary, the cloud-native model is a vendor-agnostic paradigm, and therefore, contrary to what generally happens with hyped-up technologies, there are a range of adoption patterns, definitions, and good practices, maintained
    
    <a id="_idIndexMarker942">
    </a>
    
     by the
    
    <strong class="bold">
     
      Cloud Native Computing
     
    </strong>
    
     <strong class="bold">
      
       Foundation
      
     </strong>
    
    
     
      (
     
    
    
     <strong class="bold">
      
       CNCF
      
     </strong>
    
    
     
      ).
     
    
   </p>
   <h2 id="_idParaDest-190">
    <a id="_idTextAnchor191">
    </a>
    
     Getting to know CNCF
    
   </h2>
   <p>
    
     CNCF is a
    
    <a id="_idIndexMarker943">
    </a>
    
     consortium created in 2015 within the scope of the Linux Foundation.
    
    
     It involves more than 400 companies that aim to create a common language between technologies, standards, and best practices, independent of the supplier.
    
    
     CNCF aims to build sustainable solution ecosystems for cloud-native software by bringing together communities of developers, end users,
    
    
     
      and vendors.
     
    
   </p>
   <p>
    
     CNCF promotes cloud-native technologies, supporting and maintaining projects that enable the adoption of practices such as containerization, microservices, and dynamic orchestration, promoting open standards and best practices, and allowing cloud-native applications to work in an interoperable manner.
    
    
     Additionally, CNCF supports innovation by nurturing a community of contributors and maintaining a neutral ground for the development of cutting-edge cloud-native tools
    
    
     
      and projects.
     
    
   </p>
   <p>
    
     One of the important resources of
    
    <a id="_idIndexMarker944">
    </a>
    
     CNCF is the technology landscape, which is a visual representation and interactive guide that maps the cloud-native ecosystem in a categorized way, displaying a wide range of tools, projects, and technologies that are part of or related to the mission
    
    
     
      of CNCF.
     
    
   </p>
   <p class="callout-heading">
    
     The CNCF landscape
    
   </p>
   <p class="callout">
    
     The CNCF landscape
    
    <a id="_idIndexMarker945">
    </a>
    
     is an excellent resource for organizations and professionals, helping you to understand the technology and tool options available, their relationships, and their roles in the cloud-native ecosystem.
    
    
     To learn more about the CNCF landscape, visit the following
    
    
     
      URL:
     
    
    <a href="https://landscape.cncf.io">
     
      
       https://landscape.cncf.io
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     To understand how we could use CNCF to our advantage, let’s look at a development scenario for an ASP.NET Core 9 solution hosted on
    
    
     
      Microsoft Azure.
     
    
   </p>
   <h2 id="_idParaDest-191">
    <a id="_idTextAnchor192">
    </a>
    
     Working with CNCF
    
   </h2>
   <p>
    
     Imagine the
    
    
     
      following scenario:
     
    
   </p>
   <p>
    <em class="italic">
     
      You are developing a web application using ASP.NET Core 9 and the application is hosted in Azure.
     
     
      You want to ensure that your application is developed using cloud-native principles and that it leverages the best tools available for deployment, monitoring,
     
    </em>
    
     <em class="italic">
      
       and management.
      
     </em>
    
   </p>
   <p>
    
     Let’s see how the use of
    
    <a id="_idIndexMarker946">
    </a>
    
     CNCF can support us in the architectural definition and development of the application in
    
    
     
      the scenario:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Containerization strategy
      
     </strong>
     
      : Based on the knowledge acquired in the previous chapter, you choose to use Docker and containerize your ASP.NET Core 9 application.
     
     
      To recap, Docker, a
     
     <a id="_idIndexMarker947">
     </a>
     
      project formed by CNCF, allows you to package your application and its dependencies in a container, ensuring consistency in
     
     
      
       different environments.
      
     
     <ul>
      <li>
       
        These are
       
       
        
         the benefits:
        
       
       <ul>
        <li>
         
          Ensures application consistency across development, testing, and
         
         
          
           production environments
          
         
        </li>
        <li>
         
          Simplifies dependency management
         
         
          
           and isolation
          
         
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     <strong class="bold">
      
       Container orchestration
      
     </strong>
     
      : For this application to be hosted, you decide to use Kubernetes, which is another CNCF graduate project, for container orchestration.
     
     <strong class="bold">
      
       Azure Kubernetes Service
      
     </strong>
     
      (
     
     <strong class="bold">
      
       AKS
      
     </strong>
     
      ) provides a managed Kubernetes environment in Azure, making it
     
     <a id="_idIndexMarker948">
     </a>
     
      easy to deploy, manage, and scale your containerized applications.
     
     
      AKS
     
     <a id="_idIndexMarker949">
     </a>
     
      uses the same standards defined by the CNCF in relation to Kubernetes but abstracts the complexity of creating a cluster and offers several
     
     
      
       other services.
      
     
     <ul>
      <li>
       
        These are
       
       
        
         the benefits:
        
       
       <ul>
        <li>
         
          Manages the container lifecycle, scaling, and
         
         
          
           load balancing
          
         
        </li>
        <li>
         
          Ensures high availability
         
         
          
           and resilience
          
         
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     <strong class="bold">
      
       Automation
      
     </strong>
     
      : You decide to use CI/CD tools such as Jenkins or GitHub Actions to automate your build, test, and deployment processes.
     
     
      These tools ensure that your code changes are continually integrated and deployed, improving your
     
     
      
       development workflow.
      
     
     <ul>
      <li>
       
        These are
       
       
        
         the benefits:
        
       
       <ul>
        <li>
         
          Automates the deployment process, ensuring consistency and reducing the risk of
         
         
          
           human error
          
         
        </li>
        <li>
         
          Accelerates the development cycle, enabling continuous integration
         
         
          
           and deployment
          
         
        </li>
       </ul>
      </li>
     </ul>
    </li>
    <li>
     <strong class="bold">
      
       Monitoring and logging
      
     </strong>
     
      : Completing development, performing continuous integration, and achieving continuous deployment are just the first steps to working on a project as a cloud-native solutions software engineer.
     
     
      It’s important to incorporate observability tools such
     
     <a id="_idIndexMarker950">
     </a>
     
      as
     
     <strong class="bold">
      
       Prometheus
      
     </strong>
     
      and
     
     <strong class="bold">
      
       Grafana
      
     </strong>
     
      , both
     
     <a id="_idIndexMarker951">
     </a>
     
      incubating CNCF projects, to monitor the performance and health of your application.
     
     
      Prometheus collects metrics and Grafana visualizes them, providing insights into your application’s behavior.
     
     
      Azure Monitor is also an observability tool featured in the CNCF landscape.
     
     
      Furthermore, other types of tools such as
     
     <strong class="bold">
      
       OpenTelemetry
      
     </strong>
     
      , also
     
     <a id="_idIndexMarker952">
     </a>
     
      incubated by CNCF, would be a great option for applications to have a vendor-agnostic collector, which reduces the dependence on proprietary libraries
     
     
      
       in applications.
      
     
     <ul>
      <li>
       
        These are
       
       
        
         the benefits:
        
       
       <ul>
        <li>
         
          Provides real-time monitoring and alerts for
         
         
          
           your application
          
         
        </li>
        <li>
         
          Helps you quickly diagnose and resolve
         
         
          
           performance issues
          
         
        </li>
       </ul>
      </li>
     </ul>
    </li>
   </ul>
   <p>
    
     Leveraging
    
    <a id="_idIndexMarker953">
    </a>
    
     CNCF and its landscape provides numerous tools and best practices for developing, deploying, and managing cloud-native applications.
    
    
     By adopting these tools, a software engineer working on an ASP.NET Core 9 application hosted in Azure can ensure that their application is scalable, resilient, and maintainable.
    
    
     Containerization with Docker, orchestration with Kubernetes, observability with Prometheus and Grafana, and automated CI/CD pipelines with Jenkins or GitHub Actions are just a few examples of how CNCF projects can enhance your cloud-native
    
    
     
      development workflow.
     
    
   </p>
   <p>
    
     However, the scenario mentioned previously provides an Azure-agnostic solution model, making it possible to be hosted on different cloud providers, as each of the tools mentioned follows the standards established by CNCF for
    
    
     
      cloud-provider-agnostic solutions.
     
    
   </p>
   <p>
    
     It is very important to regularly visit the CNCF website to be aware of news and changes in cloud models and analyze the tools available in the CNCF landscape for the needs of your solutions.
    
    
     These resources will help you create increasingly powerful solutions that adapt to the different needs of your organization and
    
    
     
      the market.
     
    
   </p>
   <p>
    
     We know that CNCF is an important resource that sets the standard for cloud-native solutions and should be added to any software engineer’s toolbox.
    
    
     Additionally, there are other principles that, in a practical way, guide us in the process of developing cloud-native solutions.
    
    
     ASP.NET Core 9 can help us implement these principles, such as
    
    <a id="_idIndexMarker954">
    </a>
    
     the
    
    <strong class="bold">
     
      twelve-factor app methodology
     
    </strong>
    
     .
    
    
     We will discuss these principles in the
    
    
     
      next section.
     
    
   </p>
   <h1 id="_idParaDest-192">
    <a id="_idTextAnchor193">
    </a>
    
     The twelve-factor app principles
    
   </h1>
   <p>
    
     The
    
    <a id="_idIndexMarker955">
    </a>
    
     twelve-factor app methodology (
    
    <a href="https://12factor.net">
     
      https://12factor.net
     
    </a>
    
     ) is a set of best practices designed to help
    
    <a id="_idIndexMarker956">
    </a>
    
     developers build modern, scalable, and maintainable cloud-native applications.
    
    
     It was created by Heroku developers to provide a framework for developing applications that can be deployed and managed in
    
    
     
      the cloud.
     
    
   </p>
   <p class="callout-heading">
    
     Heroku
    
   </p>
   <p class="callout">
    
     According to the website’s own definition, Heroku is a cloud platform that allows companies to create, deliver, monitor, and
    
    
     
      scale applications.
     
    
   </p>
   <p class="callout">
    
     Heroku
    
    <a id="_idIndexMarker957">
    </a>
    
     is a cloud PaaS offering, founded in 2007, that allows developers to build, run, and operate applications
    
    <a id="_idIndexMarker958">
    </a>
    
     entirely in the cloud in a simplified way.
    
    
     To learn more,
    
    
     
      visit
     
    
    <a href="https://www.heroku.com/home">
     
      
       https://www.heroku.com/home
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     The twelve-factor app methodology, as the name suggests, has twelve factors
    
    
     
      or principles:
     
    
   </p>
   <ol>
    <li>
     <strong class="bold">
      
       Code base
      
     </strong>
     
      : Use a code base tracked in
     
     
      
       version control.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Dependencies
      
     </strong>
     
      : Explicitly declare and
     
     
      
       isolate dependencies.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Config
      
     </strong>
     
      : Store the configuration in
     
     
      
       the environment.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Backing services
      
     </strong>
     
      : Treat supporting services as
     
     
      
       attached resources.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Build, release, run
      
     </strong>
     
      : Strictly separate the build and
     
     
      
       run stages.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Processes
      
     </strong>
     
      : Run the application as one or more
     
     
      
       stateless processes.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Port binding
      
     </strong>
     
      : Export services via
     
     
      
       port binding.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Concurrency
      
     </strong>
     
      : Expansion through the
     
     
      
       process model.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Disposability
      
     </strong>
     
      : Maximize robustness with fast startup and
     
     
      
       smooth shutdown.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Dev/prod parity
      
     </strong>
     
      : Keep development, staging, and production as similar
     
     
      
       as possible.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Logs
      
     </strong>
     
      : Treat logs as streams
     
     
      
       of events.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Administrative processes
      
     </strong>
     
      : Perform administrative/management tasks as
     
     
      
       single processes.
      
     
    </li>
   </ol>
   <p>
    
     Let’s get into more detail about each of the
    
    
     
      factors mentioned.
     
    
   </p>
   <h2 id="_idParaDest-193">
    <a id="_idTextAnchor194">
    </a>
    
     Code base
    
   </h2>
   <p>
    
     During the
    
    <a id="_idIndexMarker959">
    </a>
    
     solution development cycle, you should maintain the source code in a remote repository, such as a
    
    
     
      Git-based repository.
     
    
   </p>
   <p>
    
     The code base factor entails that there should be a code base for each application context, allowing the correct separation of responsibilities and improving
    
    
     
      code management.
     
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .5
     
    </em>
    
     illustrates the management of the different contexts of an application, such as configurations, source code, and infrastructure scripts.
    
    
     Each of these contexts can be distributed in different environments, at different times in the
    
    
     
      development flow.
     
    
   </p>
   <div><div><img alt="Figure 11.5 – Code base management" src="img/B21788_11_05.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.5 – Code base management
    
   </p>
   <p>
    
     Despite being a principle considered natural during the application development flow, its importance goes beyond source code management on remote servers.
    
    
     Development teams must take ownership of the end-to-end solution, defining source code management processes such as the use of branches, development standards, code review, quality processes,
    
    
     
      and documentation.
     
    
   </p>
   <p>
    
     In cloud environments, it is common to have one repository for managing application code and another repository specifically for storing infrastructure code.
    
    
     The contextualization and separation of contexts in repositories allow for constant collaboration and management between the development and
    
    
     
      operations teams.
     
    
   </p>
   <p>
    
     The code base
    
    <a id="_idIndexMarker960">
    </a>
    
     principle is the basis for all other principles.
    
    
     Next, we will learn
    
    
     
      about dependencies.
     
    
   </p>
   <h2 id="_idParaDest-194">
    <a id="_idTextAnchor195">
    </a>
    
     Dependencies
    
   </h2>
   <p>
    
     Dependencies are
    
    <a id="_idIndexMarker961">
    </a>
    
     part of application development, as we have already seen in some examples in the book when using NuGet packages.
    
    
     Using packages brings benefits such as reusability and, together with package management mechanisms, allows for easy package updates.
    
    
     Most programming languages currently provide extensibility mechanisms based on
    
    
     
      package management.
     
    
   </p>
   <p>
    
     The dependencies principle defines that dependencies must be managed in a manifest file and a package management tool must
    
    
     
      be used.
     
    
   </p>
   <p>
    
     For example, ASP.NET Core 9 applications have the NuGet package manager, and all dependencies are managed through the
    
    <strong class="source-inline">
     
      &lt;ProjectName&gt;.csproj
     
    </strong>
    
     file, which contains the references and versions of the packages used in
    
    
     
      the application.
     
    
   </p>
   <p>
    
     Through this feature, we can benefit from the interoperability of the .NET platform, and in conjunction with the .NET CLI tool, we are able to obtain dependencies in a simple way, executing the
    
    <strong class="source-inline">
     
      dotnet restore
     
    </strong>
    
     command and allowing us to build and generate deployment packages without running the risk of
    
    
     
      human error.
     
    
   </p>
   <p>
    
     Using package management avoids managing dependency
    
    
     
      files manually.
     
    
   </p>
   <p>
    
     Just as dependencies are necessary in an application, configurations are important.
    
    
     Let’s understand how the config factor helps in
    
    
     
      configuration management.
     
    
   </p>
   <h2 id="_idParaDest-195">
    <a id="_idTextAnchor196">
    </a>
    
     Config
    
   </h2>
   <p>
    
     All applications have some type of
    
    <a id="_idIndexMarker962">
    </a>
    
     configuration file, which can include sensitive information such as encryption keys and connection strings.
    
    
     Keeping settings in configuration files is an excellent practice and avoids having to change the source code if there is a
    
    
     
      configuration change.
     
    
   </p>
   <p>
    
     In the cloud, applications generally have different environments to ensure that with each update, the quality of the solution remains high.
    
    
     Furthermore, production environments have access restrictions for security reasons; application configurations in production environments should not
    
    
     
      be accessible.
     
    
   </p>
   <p>
    
     The config factor says that configurations must be kept separate from code, making it easier to manage different environments.
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .6
     
    </em>
    
     illustrates the approach proposed by the
    
    
     
      config factor:
     
    
   </p>
   <div><div><img alt="Figure 11.6 – Configuration server and environments" src="img/B21788_11_06.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.6 – Configuration server and environments
    
   </p>
   <p>
    
     As we can see in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .6
     
    </em>
    
     , the development flow uses an automation pipeline, CI, and CD, and when the artifact is obtained, it will be published in
    
    
     
      different environments.
     
    
   </p>
   <p>
    
     The application then obtains its respective configurations based on the
    
    
     
      execution environment.
     
    
   </p>
   <p>
    
     In
    
    <a href="B21788_10.xhtml#_idTextAnchor162">
     
      <em class="italic">
       
        Chapter 10
       
      </em>
     
    </a>
    
     , we learned how to manage application configurations and behaviors using Azure App Configuration.
    
    
     This way, we can abstract the management of developers’ configurations and define access to sensitive configurations, and the application can be dynamically deployed in
    
    
     
      different environments.
     
    
   </p>
   <p>
    
     Configurations are very
    
    <a id="_idIndexMarker963">
    </a>
    
     important in the context of any application, as are the integrations that are made.
    
    
     The next factor suggests a best practice that directly influences the architectural definitions of
    
    
     
      a solution.
     
    
   </p>
   <h2 id="_idParaDest-196">
    <a id="_idTextAnchor197">
    </a>
    
     Backing services
    
   </h2>
   <p>
    
     Most applications have some dependency
    
    <a id="_idIndexMarker964">
    </a>
    
     on external resources or, in this case, backing services.
    
    
     These resources can be databases, email servers, and storage servers, among
    
    
     
      other services.
     
    
   </p>
   <p>
    
     Applications must be prepared to isolate such dependencies and, at the same time, be able to use these services independently of the execution environment, without any changes to the code.
    
    
     Backing services must be exposed through a URL and respective credentials, depending on the resource.
    
    
     Resources must be maintained and made available in isolation and applications must reference them.
    
    
     Let’s look at
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .7
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.7 – Interaction between an application and backing services" src="img/B21788_11_07.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.7 – Interaction between an application and backing services
    
   </p>
   <p>
    
     As we can see in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .7
     
    </em>
    
     , the application’s architectural model proposes isolation between services that are consumed externally, such as database, message broker, and storage services.
    
    
     When
    
    <a id="_idIndexMarker965">
    </a>
    
     reflecting on architectural approaches at the
    
    <a id="_idIndexMarker966">
    </a>
    
     source code level, the use of
    
    <strong class="bold">
     
      hexagonal architecture
     
    </strong>
    
     or
    
    <strong class="bold">
     
      Onion Architecture
     
    </strong>
    
     can
    
    <a id="_idIndexMarker967">
    </a>
    
     help in this context of
    
    
     
      service isolation.
     
    
   </p>
   <p class="callout-heading">
    
     Hexagonal architecture and Onion Architecture
    
   </p>
   <p class="callout">
    
     Hexagonal architecture (or ports-and-adapters architecture) is a design pattern that aims to create a clear separation between core
    
    <a id="_idIndexMarker968">
    </a>
    
     business logic and external elements, such as user interfaces, databases, and other services.
    
    
     In this architecture, the core application logic is in the center, surrounded by several ports, which define interfaces for different functionalities.
    
    
     Adapters are the specific implementation of the interfaces for interacting with some
    
    
     
      external resource.
     
    
   </p>
   <p class="callout">
    
     The
    
    <a id="_idIndexMarker969">
    </a>
    
     Onion Architecture, also a design pattern, emphasizes the separation of concerns within an application.
    
    
     It places the core domain in the center, surrounded by layers that contain infrastructure and presentation concerns.
    
    
     The innermost layer represents the domain model and business logic, which are independent of external concerns.
    
    
     Surrounding this core are layers for application services, followed by infrastructure and user interfaces in the outermost layer.
    
    
     Dependencies flow inward, which means that external layers can depend on internal layers, but not
    
    
     
      vice versa.
     
    
   </p>
   <p class="callout">
    
     To learn more about the
    
    <a id="_idIndexMarker970">
    </a>
    
     hexagonal architecture and the
    
    <a id="_idIndexMarker971">
    </a>
    
     Onion Architecture, visit
    
    <a href="https://alistair.cockburn.us/hexagonal-architecture/">
     
      https://alistair.cockburn.us/hexagonal-architecture/
     
    </a>
    
     
      and
     
    
    <a href="https://jeffreypalermo.com/blog/the-onion-architecture-part-1/">
     
      
       https://jeffreypalermo.com/blog/the-onion-architecture-part-1/
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     The backing services factor, if
    
    <a id="_idIndexMarker972">
    </a>
    
     analyzed further, allows us to reflect on other architectural aspects that are important in a cloud environment, such as resilience and availability.
    
    
     As applications depend on other services, certain questions arise, such
    
    
     
      as these:
     
    
   </p>
   <ul>
    <li>
     <em class="italic">
      
       How should the application behave if the database or cache is
      
     </em>
     
      <em class="italic">
       
        not working?
       
      </em>
     
    </li>
    <li>
     <em class="italic">
      
       What if the email service is
      
     </em>
     
      <em class="italic">
       
        not working?
       
      </em>
     
    </li>
   </ul>
   <p>
    
     The answers to these questions allow us to expand our horizons beyond source code, moving us toward
    
    
     
      cloud-native thinking.
     
    
   </p>
   <p>
    
     The isolation proposed by the backing services factor allows automation approaches to be used in the value
    
    
     
      delivery flow.
     
    
   </p>
   <h2 id="_idParaDest-197">
    <a id="_idTextAnchor198">
    </a>
    
     Build, release, run
    
   </h2>
   <p>
    
     In
    
    <a href="B21788_10.xhtml#_idTextAnchor162">
     
      <em class="italic">
       
        Chapter 10
       
      </em>
     
    </a>
    
     , we learned about the
    
    <a id="_idIndexMarker973">
    </a>
    
     importance of DevOps and automated processes, in the
    
    <em class="italic">
     
      Understanding the DevOps approach with
     
    </em>
    
     <em class="italic">
      
       CI/CD
      
     </em>
    
    
     
      section.
     
    
   </p>
   <p>
    
     Automation is exactly the concept defined by the build, release,
    
    
     
      run factor.
     
    
   </p>
   <p>
    
     The CI process is associated with the moment of building the artifact, where processes such as downloading dependencies and building and executing quality and security flows are carried out, in addition to making the artifact available to be consumed by another process, such
    
    
     
      as CD.
     
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .8
     
    </em>
    
     demonstrates the
    
    <a id="_idIndexMarker974">
    </a>
    
     
      CI process:
     
    
   </p>
   <div><div><img alt="Figure 11.8 – CI and the pull-request approach" src="img/B21788_11_08.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.8 – CI and the pull-request approach
    
   </p>
   <p>
    
     In addition to the CI process, we have CD, whose objective is to deploy the artifact in
    
    
     
      different environments.
     
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .9
     
    </em>
    
     demonstrates the
    
    
     
      CD process:
     
    
   </p>
   <div><div><img alt="Figure 11.9 – CD with the rollback approach" src="img/B21788_11_09.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.9 – CD with the rollback approach
    
   </p>
   <p>
    
     As seen in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .9
     
    </em>
    
     , the use
    
    <a id="_idIndexMarker975">
    </a>
    
     of automated processes brings great benefits to the CD flow.
    
    
     CD is executed after CI, and if there is any inconsistency in any environment, or even in the production environment, rollback processes can be executed quickly to publish the latest stable version of the application again.
    
    
     Furthermore, other techniques can be used in this process, such as feature toggles, as discussed in
    
    <a href="B21788_10.xhtml#_idTextAnchor162">
     
      <em class="italic">
       
        Chapter 10
       
      </em>
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     The next factor is very important for
    
    
     
      cloud-native environments.
     
    
   </p>
   <h2 id="_idParaDest-198">
    <a id="_idTextAnchor199">
    </a>
    
     Processes
    
   </h2>
   <p>
    
     The processes
    
    <a id="_idIndexMarker976">
    </a>
    
     factor defines that an application should be executed in an environment, independently and without the state.
    
    
     If state storage is required, it must be stored through external support services.
    
    
     Stateless processes are easily sized and replaced without losing the state, improving reliability
    
    
     
      and scalability.
     
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .10
     
    </em>
    
     shows a high-level view of an application running in different processes and interacting with a database-based state
    
    
     
      persistence model.
     
    
   </p>
   <div><div><img alt="Figure 11.10 – Managing application states with a database" src="img/B21788_11_10.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.10 – Managing application states with a database
    
   </p>
   <p>
    
     Web APIs developed in
    
    <a id="_idIndexMarker977">
    </a>
    
     ASP.NET Core are an example of stateless applications, where there is no state management through sessions in memory.
    
    
     Each request has the context of the information that needs to be processed by the API, as we learned in
    
    <a href="B21788_06.xhtml#_idTextAnchor093">
     
      <em class="italic">
       
        Chapter 6
       
      </em>
     
    </a>
    
     , where we implement authentication and authorization.
    
    
     For each request, the user information is sent in the request header as a token.
    
    
     Then, the API, using ASP.NET Core 9 middleware, contextualizes the request with the user’s information, allowing, or not, an action to be performed.
    
    
     Each request is independent, and the state is obtained during the request cycle of
    
    
     
      the request.
     
    
   </p>
   <p>
    
     This is an important feature that allows applications to be ableto scale dynamically , such as the execution of multiple instances of the same application in a
    
    
     
      Docker container.
     
    
   </p>
   <p>
    
     See the example shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .11
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.11 – Stateless application" src="img/B21788_11_11.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.11 – Stateless application
    
   </p>
   <p>
    
     The diagram
    
    <a id="_idIndexMarker978">
    </a>
    
     presented in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .11
     
    </em>
    
     illustrates how an application performs several stateless processes (using container instances) to deal with requests.
    
    
     The following is a brief description of each component of
    
    
     
      the diagram:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       User
      
     </strong>
     
      : The user makes an
     
     
      
       API request.
      
     
    </li>
    <li>
     <strong class="bold">
      
       API Gateway
      
     </strong>
     
      : The API gateway receives the request and acts as a
     
     
      
       load balancer.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Load Balancer
      
     </strong>
     
      : The load balancer distributes API requests to various instances of the
     
     
      
       container application.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Container Instances
      
     </strong>
     
      : Several container instances process
     
     
      
       requests independently.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Database
      
     </strong>
     
      : Each container instance interacts with a shared database to process the request and recover or store the
     
     
      
       necessary data.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Response Flow
      
     </strong>
     
      : After requesting the request, each container instance sends the response back through the API gateway, which returns the final response to
     
     
      
       the user.
      
     
    </li>
   </ul>
   <p>
    
     In addition to the processes factor, it is essential to understand the concept of
    
    
     
      port binding.
     
    
   </p>
   <h2 id="_idParaDest-199">
    <a id="_idTextAnchor200">
    </a>
    
     Port binding
    
   </h2>
   <p>
    
     Like the previous factor, here, each
    
    <a id="_idIndexMarker979">
    </a>
    
     application should be mapped and made available at a specific address and via a
    
    
     
      specific port.
     
    
   </p>
   <p>
    
     If each server has an address and URL, each server can be responsible for responding to multiple applications at the same time.
    
    
     To differentiate which application will respond to a particular request, you must map the port.
    
    
     Thus,
    
    <strong class="bold">
     
      Service A
     
    </strong>
    
     can be hosted on a server through port 4040,
    
    <strong class="bold">
     
      Service B
     
    </strong>
    
     through port 3030, and
    
    <strong class="bold">
     
      Service C
     
    </strong>
    
     through port 8080, as in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .12
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.12 – Port binding" src="img/B21788_11_12.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.12 – Port binding
    
   </p>
   <p>
    
     When performing the applications developed in this book using the
    
    <strong class="source-inline">
     
      dotnet run
     
    </strong>
    
     command, we observed that a URL is provided in the format
    
    <strong class="source-inline">
     
      http:// localhost:&lt;port&gt;
     
    </strong>
    
     .
    
    
     The door may vary from environment to environment, and the application may define which door will
    
    
     
      be executed.
     
    
   </p>
   <p>
    
     This pattern even applies when adopting the container strategy using Docker, where we map the host and container doors, as shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .13
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.13 – Port binding for containers" src="img/B21788_11_13.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.13 – Port binding for containers
    
   </p>
   <p>
    
     In
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .13
     
    </em>
    
     , there are three instances of the same application, responding to different ports through the host.
    
    
     Despite being the same application, each container is performed in an isolated process.
    
    
     Having different instances of a container is a common scenario in applications that
    
    <a id="_idIndexMarker980">
    </a>
    
     require scalability for the needs of competing requests from users, which is the theme of the
    
    
     
      next factor.
     
    
   </p>
   <h2 id="_idParaDest-200">
    <a id="_idTextAnchor201">
    </a>
    
     Concurrency
    
   </h2>
   <p>
    
     The cloud environment allows
    
    <a id="_idIndexMarker981">
    </a>
    
     applications to deal with different needs in a dynamic way.
    
    
     The characteristic of elasticity not only enables software engineers to keep their applications working properly according to user needs but also allows insights that help
    
    
     
      optimize applications.
     
    
   </p>
   <p>
    
     Each application hosted in an environment needs resources to run, whether memory, CPU, or storage.
    
    
     These metrics are of paramount importance to define the limits of the applications and determine when it is necessary
    
    
     
      to scale.
     
    
   </p>
   <p>
    
     Generally speaking, the use of techniques with cargo and monitoring tests should be a constant part of this continuous application flow, directing decisions that are based on
    
    
     
      concrete data.
     
    
   </p>
   <p>
    
     If there is a need for scalability, we must define whether the strategy will be horizontal or vertical, as shown in the
    
    
     
      following example:
     
    
   </p>
   <div><div><img alt="Figure 11.14 – Vertical and horizontal scalability" src="img/B21788_11_14.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.14 – Vertical and horizontal scalability
    
   </p>
   <p>
    
     Basically, there are two types
    
    
     
      of scalability:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Vertical scalability
      
     </strong>
     
      : This is
     
     <a id="_idIndexMarker982">
     </a>
     
      applied when adding more features to a server, such
     
     <a id="_idIndexMarker983">
     </a>
     
      as memory, CPU, or storage, to support
     
     
      
       application processing.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Horizontal scalability
      
     </strong>
     
      : Horizontal scalability
     
     <a id="_idIndexMarker984">
     </a>
     
      involves the creation of new instances of servers, such as clusters.
     
     
      In this approach, processing is
     
     <a id="_idIndexMarker985">
     </a>
     
      staggered between servers to support load demand through a load balancer.
     
     
      Horizontal scalability is a strategy widely used by orchestrators such as Kubernetes to create different instances of an application container to support constant
     
     
      
       user requests.
      
     
    </li>
   </ul>
   <p>
    
     In addition to the points mentioned, each application, in its context, may depend on different types of simultaneous processing, which can be divided into background processes.
    
    
     Perhaps your application includes the asynchronous processing of an HTTP request and at the same time information is generated that must be processed in the background because it is a long-term execution.
    
    
     Therefore, its architecture can provide a web application for HTTP processing and another application that works with a worker, capable of processing long-term requests in the background.
    
    
     In conjunction with this strategy, the web application and the processes in the background, following the characteristics of the twelve-factor application, can be scaled vertically
    
    
     
      and/or horizontally.
     
    
   </p>
   <p>
    
     In the next section, we will
    
    
     
      understand disposability.
     
    
   </p>
   <h2 id="_idParaDest-201">
    <a id="_idTextAnchor202">
    </a>
    
     Disposability
    
   </h2>
   <p>
    
     The principle of disposability
    
    <a id="_idIndexMarker986">
    </a>
    
     emphasizes the importance of maximizing the robustness of an application, including fast startup and graceful closure, allowing the application to deal with rapid changes of scale, deployment, and code with no impact on user experience or
    
    
     
      system stability.
     
    
   </p>
   <p>
    
     Fast startup times enable quick outages and recoveries, while graceful shutdowns ensure that ongoing requests are completed and resources are released correctly before
    
    
     
      application interruption.
     
    
   </p>
   <p>
    
     In
    
    <a href="B21788_10.xhtml#_idTextAnchor162">
     
      <em class="italic">
       
        Chapter 10
       
      </em>
     
    </a>
    
     , when learning about the principles of Docker, we used a multi-stage build, with the aim of generating an optimized container image, which supports the rapid boot of the container
    
    
     
      if necessary.
     
    
   </p>
   <p>
    
     Moreover, the principle of disposability helps maintain system resilience and reliability, allowing applications to better resist hardware failures, producing dynamic cloud environments where instances can be created and
    
    
     
      destroyed frequently.
     
    
   </p>
   <p>
    
     See
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .15
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.15 – Disposability example" src="img/B21788_11_15.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.15 – Disposability example
    
   </p>
   <p>
    
     The diagram presented shows how applications should deal with quick startup and graceful startup processes to maintain robustness and reliability in a native
    
    
     
      cloud environment.
     
    
   </p>
   <p>
    
     In the following points, we can see the details of each item mentioned in
    
    
     
      the diagram:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       User
      
     </strong>
     
      : The user makes a request for
     
     
      
       load balancing.
      
     
    </li>
    <li>
     <strong class="bold">
      
       Load Balancer
      
     </strong>
     
      : The load balancer distributes input requests to the available
     
     
      
       container instances.
      
     
    </li>
    <li>
     
      <strong class="bold">
       
        Scaling
       
      </strong>
     
     
      
       :
      
     
     <ul>
      <li>
       <strong class="bold">
        
         New Container Instance - Starting Up
        
       </strong>
       
        : Upon scaleout, a new container instance is created.
       
       
        The application starts up quickly, making the instance ready to handle requests in
       
       
        
         minimal time.
        
       
      </li>
      <li>
       
        The load balancer begins to distribute requests to this new instance once it
       
       
        
         is ready.
        
       
      </li>
     </ul>
    </li>
    <li>
     
      <strong class="bold">
       
        Shutdown
       
      </strong>
     
     
      
       :
      
     
     <ul>
      <li>
       <strong class="bold">
        
         Old Container Instance
        
       </strong>
       
        : When
       
       <a id="_idIndexMarker987">
       </a>
       
        scaling in or deploying a new version, the load balancer stops sending new requests to the old
       
       
        
         container instance.
        
       
      </li>
      <li>
       <strong class="bold">
        
         Graceful Shutdown
        
       </strong>
       
        : The old instance completes any in-progress requests before shutting down, ensuring no request is
       
       
        
         abruptly terminated.
        
       
      </li>
      <li>
       <strong class="bold">
        
         Terminated
        
       </strong>
       <strong class="bold">
        
         Instance
        
       </strong>
       
        : After completing all requests and releasing resources, the old instance
       
       
        
         is terminated.
        
       
      </li>
     </ul>
    </li>
   </ul>
   <p>
    
     In ASP.NET Core 9, you can implement graceful shutdown by setting up the hosting and handling of cancellation tokens to ensure that continuous requests are completed before
    
    
     
      application shutdown.
     
    
   </p>
   <p>
    
     Let’s look at an example of code in a
    
    
     <strong class="source-inline">
      
       Program.cs
      
     </strong>
    
    
     
      file:
     
    
   </p>
   <pre class="source-code">
using Microsoft.AspNetCore.Builder;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;
var builder = WebApplication.CreateBuilder(args);
builder.Services.AddControllers();
var app = builder.Build();
app.UseRouting();
app.UseEndpoints(endpoints =&gt;
{
    endpoints.MapControllers();
});
<strong class="bold">var host = app.Services</strong>
<strong class="bold">  .GetService&lt;IHostApplicationLifetime&gt;();</strong>
// Handle graceful shutdown
<strong class="bold">host.ApplicationStopping.Register(() =</strong>&gt;
{
    var logger = app.Services
      .GetService&lt;ILogger&lt;Program&gt;&gt;();
    logger.LogInformation("Application is shutting down...");
    // Add more cleanup tasks here
});
app.Run();</pre>
   <p>
    
     In the previous code, the
    
    <strong class="source-inline">
     
      app.Services.GetService&lt;IHostApplicationLifetime&gt;()
     
    </strong>
    
     service was configured to deal with application
    
    
     
      stop events.
     
    
   </p>
   <p>
    
     The
    
    <strong class="source-inline">
     
      host.ApplicationStopping.Register
     
    </strong>
    
     method allows you to register a callback that will be invoked when the application
    
    
     
      is stops.
     
    
   </p>
   <p>
    
     In a registered call return, you can perform the necessary cleaning tasks, such as registration shutdown events, release of resources, and filling in
    
    
     
      ongoing tasks.
     
    
   </p>
   <p>
    
     By following this approach, you
    
    <a id="_idIndexMarker988">
    </a>
    
     can ensure that your app is gracefully stopped, keeping robustness and reliability.
    
    
     In addition, it is also important that we have consistency at the level of applications and environments, as we will understand when looking at the next factor,
    
    
     
      dev/prod parity.
     
    
   </p>
   <h2 id="_idParaDest-202">
    <a id="_idTextAnchor203">
    </a>
    
     Dev/prod parity
    
   </h2>
   <p>
    
     For years one of the most quoted phrases by
    
    <a id="_idIndexMarker989">
    </a>
    
     
      developers was:
     
    
   </p>
   <p class="author-quote">
    
     It works on my machine!
    
   </p>
   <p>
    
     In a way, this statement is true.
    
    
     Applications may behave differently in different execution environments.
    
    
     There are numerous variables that can contribute to malfunctions, such as the amount of CPU, memory, storage, or even access permissions to resources
    
    
     
      and dependencies.
     
    
   </p>
   <p>
    
     To minimize problems related to the environment, there must be as much compatibility as possible between
    
    
     
      each server.
     
    
   </p>
   <p>
    
     That’s why it’s important for teams to work with technologies for creating infrastructure as code, such as Terraform and Bicep, which, in addition to providing agility, improve management, governance, compliance,
    
    
     
      and security.
     
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .16
     
    </em>
    
     demonstrates
    
    
     
      this concept:
     
    
   </p>
   <div><div><img alt="Figure 11.16 – Dev/prod parity" src="img/B21788_11_16.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.16 – Dev/prod parity
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .16
     
    </em>
    
     demonstrates a flow in a development process that involves the delivery of applications in an automated manner and the automation of the creation of infrastructure environments through an IaC approach, ensuring that all environments
    
    
     
      are similar.
     
    
   </p>
   <p>
    
     In addition to infrastructure, as
    
    <a id="_idIndexMarker990">
    </a>
    
     we have already learned, the container strategy also allows containerized applications to run in different types
    
    
     
      of environments.
     
    
   </p>
   <p>
    
     Now let’s talk about the logs factor, which goes beyond just recording application events in
    
    
     
      a file.
     
    
   </p>
   <h2 id="_idParaDest-203">
    <a id="_idTextAnchor204">
    </a>
    
     Logs
    
   </h2>
   <p>
    
     For a long time, logs
    
    <a id="_idIndexMarker991">
    </a>
    
     were treated purely as records of events during the application execution flow, being recorded, in most cases, in text files, which were only accessed when there was a need to
    
    
     
      correct issues.
     
    
   </p>
   <p>
    
     However, in a cloud environment, writing logs to files can pose some challenges for teams working on applications that are
    
    
     
      constantly changing.
     
    
   </p>
   <p>
    
     The logs factor determines that this type of information should be treated as streams of events, not managed by
    
    <a id="_idIndexMarker992">
    </a>
    
     files but maintained by specific monitoring-related
    
    <a id="_idIndexMarker993">
    </a>
    
     environments, such
    
    <a id="_idIndexMarker994">
    </a>
    
     as
    
    <strong class="bold">
     
      Elasticsearch
     
    </strong>
    
     ,
    
    <strong class="bold">
     
      Logstash
     
    </strong>
    
     ,
    
    <strong class="bold">
     
      Azure Monitor
     
    </strong>
    
     , and
    
    <strong class="bold">
     
      Datadog
     
    </strong>
    
     , or
    
    <a id="_idIndexMarker995">
    </a>
    
     open source solutions
    
    <a id="_idIndexMarker996">
    </a>
    
     such
    
    <a id="_idIndexMarker997">
    </a>
    
     as
    
    <strong class="bold">
     
      Prometheus
     
    </strong>
    
     
      and
     
    
    
     <strong class="bold">
      
       Grafana
      
     </strong>
    
    
     
      .
     
    
   </p>
   <p>
    
     Thus, each flow of events generated through applications can provide important information about the execution flow of a given request, generate trend graphs, or even monitor in real time how the application behaves in relation
    
    
     
      to demand.
     
    
   </p>
   <p>
    
     The data generated by log collection plays a fundamental role in decision-making, allowing teams to act proactively, optimize resources, define limits for automatic scaling, and, of course, support
    
    
     
      issue corrections.
     
    
   </p>
   <p>
    
     There are several solutions on the market that support the event streaming management model, including paid and open source solutions.
    
    
     Many of these solutions are referenced in the
    
    
     
      CNCF landscape.
     
    
   </p>
   <p>
    
     When implementing the
    
    <a id="_idIndexMarker998">
    </a>
    
     logs factor in our applications, we must take into account that telemetry and log information must be collected in a transparent manner; however, managing this information is not part of the
    
    
     
      application context.
     
    
   </p>
   <p>
    
     Therefore, each logging and
    
    <a id="_idIndexMarker999">
    </a>
    
     metrics solution has different collection methods, which creates a dependency on SDKs in the applications that are necessary to connect to the collection tools.
    
    
     This dependency can be a disadvantage if there is any need to change the log
    
    
     
      instrumentation tool.
     
    
   </p>
   <p>
    
     It is important to isolate mechanisms and dependencies.
    
    
     To help with this task, there are options such as
    
    <strong class="bold">
     
      OpenTelemetry
     
    </strong>
    
     , which
    
    <a id="_idIndexMarker1000">
    </a>
    
     offers a vendor-independent approach and allows collaboration and delivery of logs and metrics to be distributed across several monitoring services, avoiding greater coupling between applications, as shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .17
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.17 – Isolating a log collector mechanism with OpenTelemetry" src="img/B21788_11_17.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.17 – Isolating a log collector mechanism with OpenTelemetry
    
   </p>
   <p class="callout-heading">
    
     Learn more about OpenTelemetry
    
   </p>
   <p class="callout">
    
     OpenTelemetry
    
    <a id="_idIndexMarker1001">
    </a>
    
     is an open source observability framework for cloud-native software maintained by CNCF that provides a standardized way to collect, process, and export telemetry data such as traces, metrics, and logs from applications.
    
    
     OpenTelemetry provides some SDKs that abstract the collection of data from the application and distribute them into
    
    <a id="_idIndexMarker1002">
    </a>
    
     different log management tools.
    
    
     For more details,
    
    
     
      visit
     
    
    <a href="https://opentelemetry.io/docs/">
     
      
       https://opentelemetry.io/docs/
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     Log collection is an important and strategic task in cloud-native applications and, as mentioned previously, allows teams to gain insights into the execution flow of application processes and supports bug fixes in applications.
    
    
     Associated with the logs strategy, strategies for sending alerts for nonconformities, exceptions, and the misbehavior of applications can be included, giving teams the possibility to
    
    
     
      act proactively.
     
    
   </p>
   <p>
    
     Logs are also
    
    <a id="_idIndexMarker1003">
    </a>
    
     essential in architecture strategies based on events and microservices where there is the distributed processing of information.
    
    
     Through logs, it is possible to map the entire execution flow, if there is a need for auditing, optimization, and
    
    
     
      bug fixing.
     
    
   </p>
   <p>
    
     We can see that when working with cloud-native solutions, we isolate responsibilities, ensuring that each part of a solution is decoupled, giving teams flexibility, improved maintenance, and better security, among other aspects.
    
    
     The admin process factor also plays
    
    
     
      into this.
     
    
   </p>
   <h2 id="_idParaDest-204">
    <a id="_idTextAnchor205">
    </a>
    
     Admin process
    
   </h2>
   <p>
    
     When talking about the twelve
    
    <a id="_idIndexMarker1004">
    </a>
    
     factors, we most often mention the contextualization of the application domain, ensuring that it is built and delivered independently, with as little coupling
    
    
     
      as possible.
     
    
   </p>
   <p>
    
     However, even in this scenario, the complexity of the application implies interactions with administrative tasks, such as performing
    
    
     
      database migrations.
     
    
   </p>
   <p>
    
     Although the database is part of the solution that makes up the application, tasks such as migrations and scripts for seeding basic information, among other types of administrative tasks, are not the responsibility of
    
    
     
      the application.
     
    
   </p>
   <p>
    
     The admin
    
    <a id="_idIndexMarker1005">
    </a>
    
     process factor suggests that administrative tasks must be carried out in isolation from applications, in a single process, and that it must be possible to monitor
    
    
     
      such changes.
     
    
   </p>
   <p>
    
     Processes such as CI/CD run outside the scope of the application.
    
    
     Thus, during the execution of a pipeline and CI, the execution of tasks, such as generating database migration scripts, for example, can be performed, and these scripts are shared with CD pipelines, which may have different tasks required to apply the changes, as shown in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .18
      
     </em>
    
    
     
      :
     
    
   </p>
   <p class="IMG---Figure">
   </p>
   <div><div><img alt="Figure 11.18 – Example of the admin process implementation" src="img/B21788_11_18.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.18 – Example of the admin process implementation
    
   </p>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .18
     
    </em>
    
     demonstrates a pipeline flow whereby, through the CD process, two distinct tasks are executed so that the application can be prepared for its correct execution in
    
    
     
      an environment.
     
    
   </p>
   <p>
    
     Performing one-time administrative processes helps maintain the application state and ensures that any changes made during these tasks are immediately reflected in the live environment, reducing discrepancies and
    
    
     
      potential errors.
     
    
   </p>
   <p>
    
     The admin process factor plays an important role in the application life cycle, as do the other factors proposed in the twelve-factor
    
    
     
      app methodology.
     
    
   </p>
   <h2 id="_idParaDest-205">
    <a id="_idTextAnchor206">
    </a>
    
     The importance of the twelve-factor app methodology
    
   </h2>
   <p>
    
     As we discussed in
    
    <a id="_idIndexMarker1006">
    </a>
    
     previous topics, the principles described in the twelve-factor app methodology were designed to help developers create modern, scalable, and maintainable applications, reinforcing the cloud-native mindset necessary for applications that deliver
    
    
     
      constant value.
     
    
   </p>
   <p>
    
     Some of the principles are already present in the software engineer’s daily life; others open our minds to different perspectives and possibilities.
    
    
     However, we can note that the 12 principles are connected and, furthermore, are closely aligned with the main characteristics of cloud-native computing, such as microservices architecture, containerization,
    
    
     
      and CI/CD.
     
    
   </p>
   <p>
    
     Using the methodology proposed by the twelve-factor app methodology, together with the other approaches presented in this chapter, such as the CAF, WAF, and projects available at CNCF, is a great model of best practices for any
    
    
     
      software engineer.
     
    
   </p>
   <p>
    
     The concepts and capabilities provided by ASP.NET Core 9 easily allow such principles to
    
    
     
      be implemented.
     
    
   </p>
   <p>
    
     In the next section, we will learn about concepts related to
    
    
     
      cloud architecture.
     
    
   </p>
   <h1 id="_idParaDest-206">
    <a id="_idTextAnchor207">
    </a>
    
     Understanding cloud architecture principles
    
   </h1>
   <p>
    
     Modern cloud architectures are the foundation of scalable, resilient, and highly available applications.
    
    
     In this chapter, we have learned about several principles and tools necessary for software engineers to combine the development of solutions in ASP.NET Core 9 and fully leverage the benefits of cloud environments such as
    
    
     
      Microsoft Azure.
     
    
   </p>
   <p>
    
     The availability of resources in a cloud environment is not enough to deliver the quality and experience needed by users in such a demanding
    
    
     
      market today.
     
    
   </p>
   <p>
    
     Each stage of the development flow helps organizations provide applications and services that meet users’ needs, in addition to enhancing companies’ return on investment and, of course, making users increasingly loyal to the
    
    
     
      solutions developed.
     
    
   </p>
   <p>
    
     In this context, we must go beyond the boundaries of source code and layered definitions, and think about strategies that allow applications to deal with users’ demands and needs.
    
    
     Therefore, it is important to adapt to the architectural concepts available in
    
    
     
      cloud-native applications.
     
    
   </p>
   <p>
    
     Let’s understand some of these architectural principles and how they can enhance applications developed in ASP.NET
    
    
     
      Core 9.
     
    
   </p>
   <h2 id="_idParaDest-207">
    <a id="_idTextAnchor208">
    </a>
    
     Working with modern design architecture
    
   </h2>
   <p>
    
     As software engineers, we are used
    
    <a id="_idIndexMarker1007">
    </a>
    
     to dealing with the implementation of code that is based on best practices and architectural styles such as Clean Code, hexagonal architecture, and design patterns, among
    
    
     
      other approaches.
     
    
   </p>
   <p>
    
     By developing using a cloud-native approach, we not only add great possibilities to applications but also add other challenges, such as those mentioned in
    
    
     
      this chapter.
     
    
   </p>
   <p>
    
     Software engineers must go beyond writing code and explore a world of different variables and approaches, such as DevOps, infrastructure, network, resilience, availability, agility, security, cost, and
    
    
     
      other aspects.
     
    
   </p>
   <p>
    
     Organizations have shifted their focus to emphasize not only the importance of user interfaces such as forms and screens in business contexts and strategies but also the critical need for processing large volumes of data, providing services such as APIs, implementing artificial intelligence, and facilitating seamless integrations between
    
    
     
      diverse systems.
     
    
   </p>
   <p>
    
     Dealing with large demands for data requests, ingestion, and analysis is an important feature for organizations
    
    
     
      to consider.
     
    
   </p>
   <p>
    
     As a result, some modern architectural styles allow organizations to get the best out of cloud environments and at the same time bring great robustness to
    
    
     
      the business.
     
    
   </p>
   <p>
    
     Imagine what an online store application would be like during a promotional event such as Black Friday that did not have the ability to adapt to user demands and deal with growing purchase requests to a payment gateway.
    
    
     If there were a bug in that virtual store application’s payment flow, what would be the company’s loss if the system was inactive for
    
    
     
      five minutes?
     
    
   </p>
   <p>
    
     Certainly, the consequences would be bad.
    
    
     Therefore, there is a need to have the ability to deal with asynchronous processing and work with event-based
    
    
     
      architectural styles.
     
    
   </p>
   <h2 id="_idParaDest-208">
    <a id="_idTextAnchor209">
    </a>
    
     Event-driven architectures
    
   </h2>
   <p>
    
     Event-driven architectures allow applications
    
    <a id="_idIndexMarker1008">
    </a>
    
     to process information asynchronously, enabling real-time reactions based on events or state changes.
    
    
     They also enable better consistency for the processing of important business flows, such as payment processing for an online store.
    
    
     Another powerful feature of event-driven architecture is the ability to decouple components, generating independence and improving the maintenance and evolution of applications.
    
    
     ASP.NET Core 9 can be integrated with event-driven systems to create scalable and resilient applications.
    
    
     Let’s look at the example illustrated in
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    
     <em class="italic">
      
       .19
      
     </em>
    
    
     
      :
     
    
   </p>
   <div><div><img alt="Figure 11.19 – Event-driven architecture example" src="img/B21788_11_19.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.19 – Event-driven architecture example
    
   </p>
   <p>
    
     In this example, the following flow is executed as an event-driven architecture
    
    
     
      implementation approach:
     
    
   </p>
   <ul>
    <li>
     
      <strong class="bold">
       
        Event Producer
       
      </strong>
     
     
      
       :
      
     
     <ul>
      <li>
       <strong class="bold">
        
         Order Service
        
       </strong>
       
        : The order
       
       <a id="_idIndexMarker1009">
       </a>
       
        service acts as the event producer.
       
       
        When an order is created, it publishes an
       
       
        
         order-created event.
        
       
      </li>
     </ul>
    </li>
    <li>
     
      <strong class="bold">
       
        Event Broker
       
      </strong>
     
     
      
       :
      
     
     <ul>
      <li>
       <strong class="bold">
        
         Azure Event Grid
        
       </strong>
       
        : Azure Event
       
       <a id="_idIndexMarker1010">
       </a>
       
        Grid acts as the event broker.
       
       
        It receives the event from the order service and distributes it to the
       
       
        
         subscribed consumers.
        
       
      </li>
     </ul>
    </li>
    <li>
     
      <strong class="bold">
       
        Event Consumers
       
      </strong>
     
     
      
       :
      
     
     <ul>
      <li>
       <strong class="bold">
        
         Inventory Service
        
       </strong>
       
        : The
       
       <a id="_idIndexMarker1011">
       </a>
       
        inventory service consumes the order-created event and updates the
       
       
        
         inventory accordingly.
        
       
      </li>
      <li>
       <strong class="bold">
        
         Notification Service
        
       </strong>
       
        : The notification service consumes the event to send a notification to the user about the
       
       
        
         order creation.
        
       
      </li>
      <li>
       <strong class="bold">
        
         Billing Service
        
       </strong>
       
        : The billing service consumes the event to process the billing for
       
       
        
         the order.
        
       
      </li>
     </ul>
    </li>
   </ul>
   <p>
    
     The example of
    
    <a id="_idIndexMarker1012">
    </a>
    
     architecture, combined with other techniques such as scalability, further improves the quality
    
    
     
      of solutions.
     
    
   </p>
   <p>
    
     Some event-driven architecture strategies must be considered according to the application requirements, such
    
    
     
      as these:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Event source
      
     </strong>
     
      : The event source
     
     <a id="_idIndexMarker1013">
     </a>
     
      works like a trace, capturing all state changes as they are executed sequentially.
     
     
      This approach favors the complete traceability of the entire execution chain, in addition to providing replay of executed events.
     
     
      ASP.NET Core 9 easily integrates with technologies such as Azure Event Hubs and Apache Kafka to implement event sourcing, as in the example shown in
     
     
      <em class="italic">
       
        Figure 11
       
      </em>
     
     
      <em class="italic">
       
        .20
       
      </em>
     
     
      
       :
      
     
    </li>
   </ul>
   <p class="IMG---Figure">
   </p>
   <div><div><img alt="Figure 11.20 – Event source example" src="img/B21788_11_20.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.20 – Event source example
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Command Query Responsibility Segregation (CQRS)
      
     </strong>
     
      : CQRS separates the read and write operations of
     
     <a id="_idIndexMarker1014">
     </a>
     
      an application.
     
     
      This approach is very powerful in contexts where the flow of persistence or writing of information, called commands (writes), is independent of the flow of queries (reads) .
     
     
      <em class="italic">
       
        Figure 11
       
      </em>
     
     <em class="italic">
      
       .21
      
     </em>
     
      illustrates the use
     
     
      
       of CQRS:
      
     
    </li>
   </ul>
   <p class="IMG---Figure">
   </p>
   <div><div><img alt="Figure 11.21 – CQRS in ASP.NET Core 9" src="img/B21788_11_21.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.21 – CQRS in ASP.NET Core 9
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Message brokers
      
     </strong>
     
      : Message brokers
     
     <a id="_idIndexMarker1015">
     </a>
     
      facilitate communication between decoupled services by sending and receiving messages.
     
     
      They ensure that messages are delivered reliably and allow services to scale independently.
     
     
      A great example of this approach is payment processing in an online store.
     
     
      Upon receiving a payment request, the application delivers a message to a broker.
     
     
      This message is handled by one or more applications with the aim of communicating with payment gateways, among other services.
     
     
      If there is a problem with the broker on the server, the messages are persisted in a queue called a
     
     <a id="_idIndexMarker1016">
     </a>
     
      dead-letter queue.
     
     
      Therefore, when the broker resource re-establishes its operation, unprocessed messages will re-enter the queue, ensuring that applications can process them.
     
     
      ASP.NET Core 9 applications can integrate with message brokers such as Azure Service Bus or RabbitMQ to handle asynchronous processing and inter-service communication, as in
     
     
      <em class="italic">
       
        Figure 11
       
      </em>
     
     
      <em class="italic">
       
        .22
       
      </em>
     
     
      
       :
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 11.22 – Message broker with a dead-letter queue" src="img/B21788_11_22.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.22 – Message broker with a dead-letter queue
    
   </p>
   <p class="callout-heading">
    
     Dead-Letter queue
    
   </p>
   <p class="callout">
    
     A
    
    <strong class="bold">
     
      dead-letter queue
     
    </strong>
    
     (
    
    <strong class="bold">
     
      DLQ
     
    </strong>
    
     ) is
    
    <a id="_idIndexMarker1017">
    </a>
    
     a specialized message queue used to store messages that cannot be processed due to some server or broker failure.
    
    
     Messages are kept isolated in the DLQ and retrieved for reprocessing after server problems are resolved.
    
    
     For more information, you can visit the Azure Service Bus DLQ
    
    <a id="_idIndexMarker1018">
    </a>
    
     
      documentation:
     
    
    <a href="https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dead-letter-queues">
     
      
       https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-dead-letter-queues
      
     
    </a>
    
     
      .
     
    
   </p>
   <p>
    
     Understanding and applying Event-Driven architecture approaches is essential for creating cloud-native solutions, prepared to deal with different types of
    
    
     
      user demands.
     
    
   </p>
   <p>
    
     Based on event-driven architecture principles, another crucial architectural paradigm for cloud-native development is microservices, further enhancing application modularity
    
    
     
      and scalability.
     
    
   </p>
   <h2 id="_idParaDest-209">
    <a id="_idTextAnchor210">
    </a>
    
     Understanding microservices
    
   </h2>
   <p>
    
     Microservices are an
    
    <a id="_idIndexMarker1019">
    </a>
    
     architectural style that fully supports the development of cloud-native solutions and, in essence, applies the best practices mentioned in
    
    
     
      this chapter.
     
    
   </p>
   <p>
    
     Microservices offer an approach
    
    <a id="_idIndexMarker1020">
    </a>
    
     that means an application has the
    
    
     
      following characteristics:
     
    
   </p>
   <ul>
    <li>
     
      It has a bounded
     
     
      
       implementation context
      
     
    </li>
    <li>
     
      It is autonomous and can therefore be
     
     
      
       deployed independently
      
     
    </li>
    <li>
     
      It is independent
     
     
      
       and scalable
      
     
    </li>
    <li>
     
      It does not depend on a specific language, so there can be different microservices with
     
     
      
       different technologies
      
     
    </li>
    <li>
     
      Your process runs independently and can benefit from different types of communication protocols, such as HTTP/HTTPS and gRPC and
     
     
      
       message queues
      
     
    </li>
    <li>
     
      In general, microservices manage their own
     
     
      
       data independently
      
     
    </li>
   </ul>
   <p>
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .23
     
    </em>
    
     illustrates a comparison between microservices
    
    <a id="_idIndexMarker1021">
    </a>
    
     
      and monoliths:
     
    
   </p>
   <p class="IMG---Figure">
   </p>
   <div><div><img alt="Figure 11.23 – Monolithic versus microservices" src="img/B21788_11_23.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.23 – Monolithic versus microservices
    
   </p>
   <p>
    
     It is very important
    
    <a id="_idIndexMarker1022">
    </a>
    
     to keep in mind that microservices are not there to replace monolithic applications.
    
    
     Each approach has its respective advantages, disadvantages, and challenges.
    
    
     The choice of one approach over another will depend on the context and
    
    
     
      application requirements.
     
    
   </p>
   <p>
    
     When analyzing
    
    
     <em class="italic">
      
       Figure 11
      
     </em>
    
    <em class="italic">
     
      .23
     
    </em>
    
     , we can see that in the monolithic approach, the application layer is responsible for managing all associated processes, represented by symbols, in addition to sharing access with all application states in the
    
    
     
      same database.
     
    
   </p>
   <p>
    
     In the microservices approach, each service is contextualized in an independent application, managing the state in isolation, independently, but delivering the same business flow as in the
    
    
     
      monolithic approach.
     
    
   </p>
   <p>
    
     There are several challenges associated with microservices, such as communication, transaction management, scalability, granularity, teams, distributed data, consistency, availability, reliability,
    
    
     
      and resilience.
     
    
   </p>
   <p>
    
     Microservices can even be developed using a container strategy in conjunction with ASP.NET Core 9, which provides a powerful and performant platform, bringing several benefits to
    
    
     
      software engineers.
     
    
   </p>
   <p>
    
     Furthermore, in addition to the development process, regardless of the architectural strategy used, at some point we must deliver solutions in a cloud environment.
    
    
     This process is very important and must cause as little impact as possible to users, which requires
    
    
     
      deployment strategies.
     
    
   </p>
   <h2 id="_idParaDest-210">
    <a id="_idTextAnchor211">
    </a>
    
     Considering deployment strategies
    
   </h2>
   <p>
    
     Deployment strategies
    
    <a id="_idIndexMarker1023">
    </a>
    
     are essential in cloud-native development, enabling applications to be delivered with the least possible impact
    
    
     
      on users.
     
    
   </p>
   <p>
    
     Cloud environments and other technologies support different deployment strategies.
    
    
     The following points mention the most
    
    
     
      common strategies:
     
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Blue-green deployment
      
     </strong>
     
      : Blue-green deployment
     
     <a id="_idIndexMarker1024">
     </a>
     
      is based on
     
     <a id="_idIndexMarker1025">
     </a>
     
      the use of two identical environments: blue (current production) and green (new version).
     
     
      New versions of an application are deployed in the green environment and, after carrying out validations, a swap is performed; that is, the traffic goes from blue to green.
     
     
      In Azure, this strategy can be implemented by configuring separate slots in Azure App Service.
     
     
      Through deployment slots, it is possible to carry out deployments in a secure manner, and if the new version has any errors, even after validation, you can simply run the swap again for the previous version to be made available.
     
     
      Azure App Service implements load balancing and directs user requests to avoid losses, as demonstrated in
     
     
      <em class="italic">
       
        Figure 11
       
      </em>
     
     
      <em class="italic">
       
        .24
       
      </em>
     
     
      
       :
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 11.24 – Blue-green deployment with Azure App Service" src="img/B21788_11_24.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.24 – Blue-green deployment with Azure App Service
    
   </p>
   <ul>
    <li>
     <strong class="bold">
      
       Canary deployment
      
     </strong>
     
      : Canary deployment
     
     <a id="_idIndexMarker1026">
     </a>
     
      is a variation of
     
     <a id="_idIndexMarker1027">
     </a>
     
      blue-green deployment that gradually introduces the new version to a small subset of users before rolling it out to the entire user base.
     
     
      Microsoft Azure provides traffic management tools, such as Azure Traffic Manager, to direct some traffic to the new version while monitoring its performance, as illustrated in
     
     
      <em class="italic">
       
        Figure 11
       
      </em>
     
     
      <em class="italic">
       
        .25
       
      </em>
     
     
      
       :
      
     
    </li>
   </ul>
   <div><div><img alt="Figure 11.25 – Canary deployment with Azure Traffic Manager" src="img/B21788_11_25.jpg"/>
     
    </div>
   </div>
   <p class="IMG---Caption" lang="en-US" xml:lang="en-US">
    
     Figure 11.25 – Canary deployment with Azure Traffic Manager
    
   </p>
   <p>
    
     The
    
    <a id="_idIndexMarker1028">
    </a>
    
     blue-green and canary
    
    <a id="_idIndexMarker1029">
    </a>
    
     deployment strategies significantly improve the reliability, flexibility, and
    
    <a id="_idIndexMarker1030">
    </a>
    
     security of the deployment process, minimizing
    
    <a id="_idIndexMarker1031">
    </a>
    
     impacts to users, in addition to allowing the restoration of the last stable environment in an
    
    
     
      agile manner.
     
    
   </p>
   <p>
    
     The combination of these strategies, tools, and modern architectural models strengthens the mindset needed for
    
    
     
      cloud-native solutions.
     
    
   </p>
   <p>
    
     ASP.NET Core 9 is a platform that is prepared for different contexts and challenges and offers powerful solutions in a
    
    
     
      cloud environment.
     
    
   </p>
   <p>
    
     As a software engineer, it is important to consider the approaches and techniques mentioned in this book to take your solutions to a
    
    
     
      higher level.
     
    
   </p>
   <h1 id="_idParaDest-211">
    <a id="_idTextAnchor212">
    </a>
    
     Summary
    
   </h1>
   <p>
    
     In this chapter, we discussed various resources, tools, strategies, and architectural approaches with the aim of developing a mindset focused on cloud-native solutions.
    
    
     We learned about the different layers of services offered by cloud environments, and we learned about CNCF and the CNCF landscape, which details excellent open source projects that implement cloud concepts and best practices.
    
    
     We also learned about the principles of the twelve-factor app, the CAF, and the WAF, and we discussed the principles of modern cloud architectures and value delivery strategies.
    
    
     The combination of all the content available in this chapter, together with the ASP.NET Core 9 platform, will enable any software engineer to go beyond code and deliver high-value solutions.
    
    
     It all starts with
    
    
     <em class="italic">
      
       Hello World
      
     </em>
    
    
     
      .
     
    
   </p>
  </div>
 </body></html>