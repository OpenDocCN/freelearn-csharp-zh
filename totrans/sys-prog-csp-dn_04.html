<html><head></head><body>
		<div><h1 class="chapter-number" id="_idParaDest-88"><a id="_idTextAnchor087"/>4</h1>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor088"/>The One with the  Thread Tangles</h1>
			<p><em class="italic">Concurrency </em><em class="italic">and threading</em></p>
			<p><strong class="bold">Threading</strong> and <strong class="bold">concurrency</strong> are <a id="_idIndexMarker251"/>things that most developers think they know all about. The theory sounds so simple, yet in practice, threading is where a lot of mistakes are made and where all those frustrating bugs originate. Threading can be quite<a id="_idIndexMarker252"/> complex, but the people of the BCL and CLR teams have done their best to help us as much as they can to make things simpler.</p>
			<p>Once you get the hang of it, threading is a great addition to your skills and can make a major difference in your systems.</p>
			<p>We will look at the following topics in this chapter:</p>
			<ul>
				<li>What is concurrency and threading?</li>
				<li>How do threads work internally in .NET and Windows?</li>
				<li>How does the CLR help us?</li>
				<li>What is async/await?</li>
				<li>How do we synchronize threads and make them work together?</li>
				<li>How can I make sure my code behaves nicely when working with threads?</li>
				<li>How can I use collections over threads?</li>
			</ul>
			<p>Let’s look into this fascinating topic!</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor089"/>Technical requirements</h1>
			<p>All the source code and samples in this chapter can be downloaded from this book’s GitHub repository at <a href="https://github.com/PacktPublishing/Systems-Programming-with-C-Sharp-and-.NET/tree/main/SystemsProgrammingWithCSharpAndNet/Chapter04">https://github.com/PacktPublishing/Systems-Programming-with-C-Sharp-and-.NET/tree/main/SystemsProgrammingWithCSharpAndNet/Chapter04</a>.</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor090"/>Concurrency and threading – the basics</h1>
			<p>This morning, I woke up as I do every day. I got out of bed, took a shower, and got dressed. Then I walked the dog for 30 minutes (it’s a Sunday today). I returned home, made some coffee, and then sat down to write this.</p>
			<p>I am sure that<a id="_idIndexMarker253"/> your day looks the same in general. You do something, then you do the next thing. Things are done in order. Sometimes, I make a phone call to people in other time zones when I walk the dog, but most of the time, I do the things I do <a id="_idIndexMarker254"/>one at a time. It is more efficient that way. If I were to sit down to write this chapter but stop to walk the dog a bit after five minutes, then leave him standing near a tree while I run back to the house to write for five more minutes, followed by me running back to the dog to walk another 500 meters, things would never get done. I would get a workout with all the running back and forth, but it would be inefficient.</p>
			<p>That is a silly way to lead your life (no judgment; if this is what you do, I am okay with it, it just doesn’t work for me).</p>
			<p>However, in the case of computers, we tend to assume that this way of working enables work to get done quicker. Why do we think that?</p>
			<p>Computers cannot do two things at the same time. No, wait. Let me rephrase that. CPU cores cannot do two things at the same time. In the old days, before AMD released the <strong class="bold">Athlon 64 X2 processor</strong> in 2005 and before Intel released the Pentium D in the same year, regular computers were all single-core. That means that computers, before 2005, could generally only do one thing at a time.</p>
			<p>These days, most devices have multiple cores. Your computer, laptop, and phone all have a multi-core processor. However, as a system programmer, you might encounter devices with only one core. Think of IoT devices: they need to be cheap and very low in power consumption. Those systems often have a single core. Systems programmers run into single-core devices more often than people writing other software.</p>
			<p>However, in the end, that doesn’t really matter. My primary development machine has 16 cores. That sounds like a lot. However, if I look at my Task Manager, I can see many things running simultaneously, much more than those 16 cores can handle. So, even in a multi-core environment, machines must do something to enable all those tasks. As systems programmers, we have to be aware of how to write our software to get the most benefit out of those cores.</p>
			<p>We are thus dealing with two separate topics here. One is concurrency; the other is threading.</p>
			<p>Concurrency<a id="_idIndexMarker255"/> is the concept<a id="_idIndexMarker256"/> whereby the system executes several sequences of operations in overlapping periods. It is not really simultaneous execution; that is called parallelism. It is all about tasks running at what seems to be the same time without waiting for other tasks. It is a concept, not a programming technique.</p>
			<p>Threads, on the other hand, are a programmer’s construct. Threading is one of the ways to achieve concurrency.</p>
			<p class="callout-heading">Nice to know</p>
			<p class="callout">Threads can be hardware threads or software threads. The CPU handles the first type; the second is handled in our software. The <strong class="bold">Operating System</strong> (<strong class="bold">OS</strong>) can assign threads to actual hardware threads, but as a developer, you are almost always going to be working with software threads. I will mostly be talking about software threads here, but I will point it out when I mean hardware threads instead.</p>
			<h2 id="_idParaDest-92"><a id="_idTextAnchor091"/>The beginnings of concurrency – the IRQ</h2>
			<p>For now, let us ignore the fact that computers cannot multitask aside from spreading the load across the physical cores a CPU might have. To make life easier, we will assume that a computer can do two things at once.</p>
			<p>This has not always been the case. In the early days, a computer did one thing at a time. That meant that if you wrote some software for a computer, you had complete control over all available hardware. Everything was yours and yours alone.</p>
			<p>Well, when I say that it was yours, I mean that it was mainly yours. Sometimes, something would happen that would need the attention of the CPU. In those days, we had something<a id="_idIndexMarker257"/> called an <strong class="bold">Interrupt Request</strong> (<strong class="bold">IRQ</strong>). An<a id="_idIndexMarker258"/> IRQ is a hardware feature that is usually tied to other hardware. An external device, such as a floppy disk drive or a modem, could signal the CPU (by putting a voltage on a particular connection to the CPU). When this happened, the CPU finished the instruction it was doing, stored all of its state in memory, looked up the address belonging to that IRQ (there could be more than one), and started the code in that address. When that function finished, the whole thing would be reversed: the CPU would load the previous stored state and continue executing the original code as if nothing had happened.</p>
			<p>This mechanism <a id="_idIndexMarker259"/>worked reasonably well, but there were a lot of potential issues. For instance, there were only a handful of IRQ lines available. If your code overwrote the registration of another piece of code attached to some hardware, that hardware would fail to work.</p>
			<p>To make things worse, if you made a silly mistake and your code never returned from the IRQ, you could bring the whole machine to a halt. It would simply never return from your code and the running program would be on hold indefinitely. So you had to be very careful to ensure that you had no such bugs in your code!</p>
			<p>IRQs are still used today, especially in low-power devices such as Raspberry Pi. We will encounter those later in this book.</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor092"/>Cooperative and preemptive multitasking</h2>
			<p>IRQs work okay, but they should be used by hardware devices. Since there aren’t that many IRQs, and since they have the potential to kill running processes, we have moved away from using them in normal software.</p>
			<p>However, having a computer and only being able to do one thing at a time with it seemed like a waste of resources. Computers became more and more powerful. They could soon do more things than we asked them to do. That was when multitasking OSs came into play.</p>
			<p>For instance, the<a id="_idIndexMarker260"/> versions of Windows before Windows 95, such as Windows 3.1, used something called <strong class="bold">cooperative multitasking</strong>. The principle was reasonably straightforward. A piece of code would do something, and when it thought it could use a break, it would just tell the OS: “Hey, I am on a break; if you need me to do something, just let me know.” It would then halt execution. This meant that the OS could allocate CPU time to another process.</p>
			<p>We called this cooperative multitasking because we expected the software to cooperate and share the resources fairly.</p>
			<p>Of course, if a program misbehaved, it could still claim all the CPU time, thus stopping other software from running as intended.</p>
			<p>A better way <a id="_idIndexMarker261"/>was needed. Windows NT 3.1 and later Windows 95 did much better: they introduced <strong class="bold">preemptive multitasking</strong>.</p>
			<p>The idea is straightforward: allocate some time for a process to run, and when that time is out, store the state of that process, park it somewhere, and move on to the next process. When the time comes for the original process to do something again, the OS loads the program<a id="_idIndexMarker262"/> back into memory and restores the state, then the process can continue. The process was utterly oblivious to the time it had been dormant unless it kept track of the clock.</p>
			<p>Processes could no longer claim all of the available CPU time. The OS would pause the process if its time had run out.</p>
			<p>Preemptive multitasking is still the way modern OSs work today.</p>
			<p>However, all of this deals with multiple processes on a computer running simultaneously. How can we have one process doing multiple things at the same time? Well, one solution would be to use threads.</p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor093"/>Threads in C#</h1>
			<p>Threads are<a id="_idIndexMarker263"/> a concept that allows computers to seem to be doing more than one thing at once in your program. Just as an OS allows multiple programs to run simultaneously, threads allow your program to run multiple flows in your application concurrently. A thread is nothing more than an <strong class="bold">execution flow</strong> in your program. You always have at least one thread: the one that got started when the program began its execution. We call this the main thread. The runtime manages this thread and you have little control over it. All the other threads, however, are yours, and you can do whatever you want with them.</p>
			<p>Threads are nothing magical. The<a id="_idIndexMarker264"/> basic principle is quite easy:</p>
			<ol>
				<li>Create a method, function, or any other piece of code you want to run.</li>
				<li>Create a thread, giving it the address of the method.</li>
				<li>Start the thread.</li>
				<li>The OS or runtime executes that method or function while running the main thread simultaneously.</li>
				<li>You can monitor the progress of that thread. You can wait for it to end, or you can use a fire-and-forget strategy by just letting it do its work.</li>
			</ol>
			<p>How you do these steps depends on which version you want to use. Do you choose the .NET way or go <a id="_idIndexMarker265"/>down the rabbit hole we know as the Win32 API?</p>
			<p>In .NET, threads are represented by an actual class (or, more precisely, an instance of a class). In Win32, they are just something created by the Win32 API.</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor094"/>Win32 threads</h2>
			<p>In Win32, you <a id="_idIndexMarker266"/>use the <code>CreateThread</code> API to create a thread. I <a id="_idIndexMarker267"/>want to show you how this works, but I must be honest: you will probably never do this in your code. There are better ways to create threads than using the Win32 API. Still, there might be circumstances when having complete control of the Win32 threads might be necessary.</p>
			<p>Let me show you how to do this in the Win32 API.</p>
			<p>We will begin by declaring a <code>delegate</code>. This <code>delegate</code> is the form of the function that contains the work that the thread executes:</p>
			<pre class="source-code">
public delegate uint ThreadProc(IntPtr lpParameter);</pre>			<p>Since we are calling Win32 APIs, we need to import them:</p>
			<pre class="source-code">
[DllImport("kernel32.dll", SetLastError = true)]
public static extern IntPtr CreateThread(
    IntPtr lpThreadAttributes,
    uint dwStackSize,
    ThreadProc lpStartAddress,
    IntPtr lpParameter,
    uint dwCreationFlags,
    out uint lpThreadId
);
[DllImport("kernel32.dll", SetLastError = true)]
public static extern bool CloseHandle(IntPtr hObject);
[DllImport("kernel32.dll", SetLastError = true)]
public static extern uint WaitForSingleObject(IntPtr
hHandle, uint dwMilliseconds);</pre>			<p>We will import three APIs: <code>CreateThread</code>, <code>CloseHandle</code>, and <code>WaitForSingleObject</code>.</p>
			<p>Before we <a id="_idIndexMarker268"/>can use these APIs, we have to write the code that does<a id="_idIndexMarker269"/> something useful. In this case, it is not really useful, but this is the code that will be executed in the thread:</p>
			<pre class="source-code">
public uint MyThreadFunction(IntPtr lpParameter)
{
    for (int i = 0; i &lt; 1000; i++)
        Console.WriteLine("Unmanaged thread");
    return 0;
}</pre>			<p>This <code>MyThreadFunction</code> function matches the delegate that we defined earlier.</p>
			<p>With all of that out of our way, we can create the threads and have our program do something. Or rather, it can do lots of somethings simultaneously. Here we go:</p>
			<pre class="source-code">
public void DoWork()
{
    uint threadId;
    var threadHandle = CreateThread(
        IntPtr.Zero,
        0,
        MyThreadFunction,
        IntPtr.Zero,
        0,
        out threadId
    );
    // Wait for the thread to be finished
    WaitForSingleObject(threadHandle, 1000);
    // Clean up
    CloseHandle(threadHandle);
}</pre>			<p>The <code>DoWork()</code> method <a id="_idIndexMarker270"/>creates a thread by calling the <code>CreateThread</code> Win32 API. This API has<a id="_idIndexMarker271"/> some parameters. Let me explain what they do with the help of <em class="italic">Table 4.1</em>:</p>
			<table class="No-Table-Style _idGenTablePara-1" id="table001-4">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Parameter</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Description</strong></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>IntPtr lpThreadAttributes</p>
						</td>
						<td class="No-Table-Style">
							<p>A pointer to the security attributes struct</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>uint dwStackSize</p>
						</td>
						<td class="No-Table-Style">
							<p>The size of the stack required for this thread</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>ThreadProc lpStartAddress</p>
						</td>
						<td class="No-Table-Style">
							<p>A pointer to the function that the thread runs</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>IntPtr lpParameter</p>
						</td>
						<td class="No-Table-Style">
							<p>A pointer to a variable that is passed to the thread</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>uint dwCreationFlags</p>
						</td>
						<td class="No-Table-Style">
							<p>Additional flags determining how the thread is created</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>out uint lpThreadId</p>
						</td>
						<td class="No-Table-Style">
							<p>An out parameter with the ID of the thread</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.1: Parameters for the CreateThread Win32 API</p>
			<p>The security attributes define who or what has access to the thread and what this thread can use. The security attributes are rather complex. I will not be diving into them here, mainly because with threads they are not often used. Here, we have set the security attribute to <code>IntPtr.Zero</code>.</p>
			<p>The <code>dwStackSize</code> parameter<a id="_idIndexMarker272"/> defines the stack size that the thread uses. As discussed before, each thread gets its own stack, where it can store its value types. This stack is reclaimed when the thread is done.</p>
			<p>Then, we get the function pointer that the thread will execute as soon as that thread starts. In C#, we can pass the method’s name and let the compiler do the hard work of figuring out the memory address.</p>
			<p>After supplying the start address of the method, we get something more interesting: we can pass data into the thread method. The <code>lpParameter</code> parameter is a pointer to the memory where that data is located. To get data into the thread is quite a lot of work unless you want to use a simple <code>Int32</code>. After all, an <code>IntPtr</code> is a 32-bit value, so you can take an int and cast it back and forth to get that data in the thread function. I am not passing anything here, but will I show you how to do that a little later in this chapter.</p>
			<p>Next are the flags that define how the system creates the thread. There are two flags that we can use, not counting the default <code>0</code>, which means “do nothing special.” These flags are explained in <em class="italic">Table 4.2</em>.</p>
			<table class="No-Table-Style _idGenTablePara-1" id="table002-3">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Flag</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Value</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Meaning</strong></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>0</p>
						</td>
						<td class="No-Table-Style">
							<p>0x00000000</p>
						</td>
						<td class="No-Table-Style">
							<p>Do nothing special</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><code>CREATE_SUSPENDED</code></p>
						</td>
						<td class="No-Table-Style">
							<p>0x00000004</p>
						</td>
						<td class="No-Table-Style">
							<p>Create the thread, but suspend it immediately instead of starting it.</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><code>STACK_SIZE_PARAM_IS_A_RESERVATION</code></p>
						</td>
						<td class="No-Table-Style">
							<p>0x00010000</p>
						</td>
						<td class="No-Table-Style">
							<p>If this is set, the stack size is a reservation. If not, the stack size is committed.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.2: Thread creation options</p>
			<p><code>CREATE_SUSPENDED</code> creates the thread but puts it in a suspended state when it is created. The default behavior is to run the code that <code>lpStartAddress</code> points to immediately.</p>
			<p><code>STACK_SIZE_PARAM_IS_A_RESERVATION</code> is an interesting one. This flag is one of the main reasons you might want to use the Win32 version of creating threads instead of the .NET one. Each<a id="_idIndexMarker273"/> thread has its own stack. You can specify how big that stack should be, but when you do that, all that happens is that the system reserves <a id="_idIndexMarker274"/>that memory. This reserving is a quick operation. Reservation only tells the system that you want to use this amount of memory at some point. You will get an error if the system doesn’t have enough memory to fulfill your request.</p>
			<p>However, the memory is not yet committed. Committed means that the OS reserves the memory you requested and marks it as being used by a process. Reservation is just telling it that you want the memory to be available later.</p>
			<p class="callout-heading">Page faults</p>
			<p class="callout">When your application requests memory or tries to access memory from the system, certain things can happen.</p>
			<p class="callout">The first instance happens when the memory is available in your stack or heap. You get the pointer to that memory; it’s all yours now.</p>
			<p class="callout">The next happens if the memory is <em class="italic">not</em> in your stack or heap yet but it is available on the system. This results in a soft page fault. The system will add the new memory to the current stack or heap.</p>
			<p class="callout">Next, it’s possible that the memory you want to reach is not in your computer’s memory chips. In this case, it has probably been swapped to disk. This is a hard page fault. The OS will load the memory from the disk and add it to your working set.</p>
			<p class="callout">Page faults are great for adding flexibility to the system. However, they come with a big performance hit.</p>
			<p>A page fault <a id="_idIndexMarker275"/>might occur when you reserve memory and want<a id="_idIndexMarker276"/> to access it. When this happens, your application’s performance will degrade.</p>
			<p>If you commit <a id="_idIndexMarker277"/>memory, it is guaranteed to be available when it is needed. This makes your memory footprint larger and faster since you will not get a page fault.</p>
			<p>You must choose here: which of the two scenarios do you prefer? You can control that for the stack with the <code>STACK_SIZE_PARAM_IS_A_RESERVATION</code> flag.</p>
			<p>The code sample ends with two statements: <code>WaitForSingleObject()</code> and <code>CloseHandle()</code>. The <em class="italic">Synchronizing threads</em> section in this chapter explains <code>WaitForSingleObject()</code> in much more detail. Still, the short description is as follows: wait for the thread to finish before continuing on the main thread.</p>
			<p><code>CloseHandle</code> clears up all used resources. Yes, this is an unmanaged resource. This would be a great place to use the <code>IDisposable</code> pattern.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor095"/>.NET threads</h2>
			<p>Threads in <a id="_idIndexMarker278"/>the .NET BCL are much simpler to use. Of course, when something is simplified, you usually sacrifice flexibility as a result.</p>
			<p>The following <a id="_idIndexMarker279"/>sample shows how to do the same work as we did with the Win32 thread using the .NET constructs.</p>
			<p>We will begin with the thread function, which runs on the new thread. It is almost the same as the Win32 sample. The following snippet shows the code that we want to run inside the thread:</p>
			<pre class="source-code">
void MyThreadFunction()
{
    for (var i = 0; i &lt; 1000; i++)
        Console.WriteLine("Managed thread");
}</pre>			<p>In the main<a id="_idIndexMarker280"/> body of our code, we create the thread, give it the function to run, and start it:</p>
			<pre class="source-code">
var myManagedThread = new Thread(MyThreadFunction);
myManagedThread.Start();
myManagedThread.Join();</pre>			<p>We create a new instance of the <code>Thread</code> class and pass the method we want to use in the constructor. Then we start it. Then, we use <code>Join()</code> to wait for it, effectively pausing the main thread until our new thread is done doing whatever it is doing.</p>
			<p>That’s it. If <a id="_idIndexMarker281"/>you compare this with the Win32 version, I am sure that you will appreciate this simplicity.</p>
			<p>However, do not be fooled: this simplicity does not mean that you cannot control your threads. You can control them and you can do much more than what I have just shown you. For instance, you can also specify the stack size you want to use for your thread:</p>
			<pre class="source-code">
var myHugeStackSize = 8 * 1024 * 1024; // 8 MB
var myManagedThread = new Thread(MyThreadFunction, myHugeStackSize);</pre>			<p>Here, we allocate 8 MB for the stack for our new thread.</p>
			<p class="callout-heading">Nice to know</p>
			<p class="callout">The default stack size for a 32-bit application is 1 MB; for a 64-bit application, it is 4 MB. You will rarely need more than that. Requesting a big stack should only be done if you have tested your application and found that you really need it.</p>
			<p>In the Win32 sample, we had to explicitly state that we wanted to create a thread in a suspended state. If we did not do that, it would have started immediately. In .NET, things work differently. A <a id="_idIndexMarker282"/>newly created thread in .NET is considered <em class="italic">unstarted</em>. This means that it will not be starting immediately. It is also not yet suspended; there is quite a difference in behavior.</p>
			<p>A suspended thread<a id="_idIndexMarker283"/> is fully formed and placed on the OS’s scheduler list. Its stack is allocated and all resources are present.</p>
			<p>An <code>Thread</code> class. The stack is not yet allocated and it has not yet been given to the OS, so it is not yet on the scheduler, and so on.</p>
			<p>When we call <code>Start()</code> on that .NET thread, the runtime does all that work. Creating a thread is much faster than the <code>CreateThread()</code> call in Win32, but that performance gain is lost when you start the thread. Think of it as lazy initialization.</p>
			<p>The designers of the CLR took advantage of this. If it is relatively cheap to create threads and only becomes expensive when we use them, why not move that burden of creation to the beginning of the program? Starting an application takes time; if we extend that a bit, it does not matter. However, that would mean that we have a faster system when it is in use. We can have a pool of threads available when we need one or two. That is precisely what they did.</p>
			<p>An example <a id="_idIndexMarker285"/>will probably make this clearer. However, before I can show you that, we must make some modifications. We want to create many threads that run simultaneously. To distinguish the output from each thread, we need to pass some data to that thread so that it can display it. Thus, we need to have something to store data in.</p>
			<p>We need immutable data for reasons that will become clear when we discuss thread safety later in this chapter. The <code>record</code>, which was added to C# 9, is a great way to do this::</p>
			<pre class="source-code">
internal record ThreadData(int LoopCounter);</pre>			<p>We can now work on our method that executes in that thread:</p>
			<pre class="source-code">
void MyThreadFunction(object? myObjectData)
{
    // Verify that we have a ThreadData object
    if (myObjectData is not ThreadData myData)
        throw new ArgumentException("Parameter is not a                     ThreadData object");
    // Get the thread ID
    var currentThreadId = Thread.CurrentThread.ManagedThreadId;
    // Write the data to the Console
    Console.WriteLine(
        $"Managed thread in Thread {currentThreadId} " +
        $"with loop counter {myData.LoopCounter}");
}</pre>			<p>The<a id="_idIndexMarker286"/> thread gets a parameter of the <code>Nullable&lt;object&gt;</code> type. We cannot declare it as any other type, as this is what the runtime expects.</p>
			<p>To use this <a id="_idIndexMarker287"/>data, we need to cast it to the right type.</p>
			<p>Then, we will get the ID of the current thread. Each thread has a unique ID, so we can interact with it, although we will only display it here.</p>
			<p>Let us create some threads:</p>
			<pre class="source-code">
for (int i = 0; i &lt; 100; i++)
{
    ThreadData threadData = new(i);
    var newThread = new Thread(MyThreadFunction);
    newThread.Start(threadData);
}
Console.ReadKey();</pre>			<p>We will create one hundred threads and start them immediately after creation. We will give them some data to see where in the loop we are.</p>
			<p>After the loop, I added the <code>Console.ReadKey()</code> so the program does not exit before all threads are done. The main thread that starts when running your program is special: if that ends, the CLR ends the whole program and unloads all memory. So, keeping your main thread alive is crucial until you are sure that all work is done. In a real-world scenario, you wouldn’t use <code>Console.ReadLine()</code> for this, but for this demo, it works just fine.</p>
			<p>If you run this, you will probably see the thread ID increasing in line with the loop counter. They are not equal. The CLR already created a dozen or so threads before you ran your loop.</p>
			<p>If you increase<a id="_idIndexMarker288"/> the loop to do a much higher number of iterations, you will eventually see the same thread ID now and then. The CLR reuses threads to avoid thread starvation.</p>
			<p>However, I promised to show you the thread pool. Replace the part of the code where we had the for-loop with the following code:</p>
			<pre class="source-code">
for (int i = 0; i &lt; 100; i++)
{
    ThreadData threadData = new(i);
    ThreadPool.QueueUserWorkItem(MyThreadFunction, threadData);
}
Console.ReadKey();</pre>			<p>We will<a id="_idIndexMarker289"/> use the thread pool here to pull threads out of the pool when needed. If you run this, you repeatedly see the same thread IDs. Threads are pulled out of the pool and started with the correct data. When the thread is done, it is winded down, its resources are de-allocated, and it is placed back in the pool, ready to be used again if needed.</p>
			<p>The overhead is minimal and the advantages are enormous. Systems using this are much more efficient.</p>
			<p><code>ThreadPool</code> hides many more secrets and tricks that you can use, but its usage has largely been replaced by the <strong class="bold">Task Parallel Library</strong> (<strong class="bold">TPL</strong>), which handles most of this for you. Let us have a look.</p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor096"/>Tasks and Parallel Library – the TPL</h1>
			<p>The TPL has <a id="_idIndexMarker290"/>been around for quite some time. It was introduced back in 2010 with the release of .NET 4.0.</p>
			<p>The TPL simplifies many of the things we used to do with threads. Threads still have their place, especially when dealing with third-party libraries. However, in most cases, we can let the TPL figure things out.</p>
			<p>In the TPL, the <code>Task</code> class is the main class to work with. <code>Task</code> is a class that handles the instantiation of threads when needed. It does much more, but we will deal with that later.</p>
			<p>I said “when needed” because it is smart enough to determine when a new thread is needed.</p>
			<p>Let us begin with a straightforward example and then work from there:</p>
			<pre class="source-code">
Task myTask = Task.Run(() =&gt; { Console.WriteLine("Hello from the task."); });
Console.WriteLine("Main thread is done.");
Console.ReadKey();</pre>			<p><code>Task</code> is just another C# class that handles much of the concurrency for us. In this case, we call <code>static method Run()</code>, which takes a delegate that it performs.</p>
			<p>We can rewrite this as follows:</p>
			<pre class="source-code">
Task myTask = Task.Run(DoWork);
Console.WriteLine("Main thread is done.");
Console.ReadKey();
return 0;
void DoWork()
{
    Console.WriteLine("Hello from the task.");
}</pre>			<p>This code<a id="_idIndexMarker291"/> snippet does the same, but we call the method instead of using the lambda expression.</p>
			<p>We can more or less do the same thing in a slightly different way:</p>
			<pre class="source-code">
Task myTask = new Task(DoWork);
myTask.Start();</pre>			<p>I have omitted the <code>Console</code> stuff and the actual method; they will remain the same (until I say that I have changed them).</p>
			<p>This code does more or less the same thing as the previous sample. The difference is that the <code>Task</code> does not start unless we explicitly call <code>Start()</code>.</p>
			<p>The second example gives you more control over the <code>Task</code>. You can set properties and change the task’s behavior before starting it. <code>Task.Run()</code> is mostly designed for fire-and-forget scenarios. <code>Start()</code> is more flexible; it allows us to change the scheduling and, for instance, tell it to run on a specific thread. You can also specify the priority of the <code>Task</code> this way.</p>
			<p>This example is not very exciting. Let us try to make it a bit more exhilarating. We can change our method to the following:</p>
			<pre class="source-code">
void DoWork(int id)
{
    Console.WriteLine($"call Id {id}.");
}</pre>			<p>We will add a parameter to our method to identify who calls the method. Since we now have a parameter, we must also change how we pass this to the <code>Task</code> constructor. Let’s not stop there. Imagine that we want to chain method calls. After the <code>Task</code> has finished with <code>DoWork</code> with <code>Id 1</code>, we want it to call that method again but with <code>Id 2</code> this time. In real life, you would probably chain two completely different methods, but the way of working is the same.</p>
			<p>The code looks like this:</p>
			<pre class="source-code">
Task myTask = new Task(() =&gt; DoWork(1));
myTask.ContinueWith((prevTask) =&gt; DoWork(2));
myTask.Start();</pre>			<p>We have <a id="_idIndexMarker292"/>changed the parameter in the constructor so that we can pass that <code>1</code> integer to the method. The following line is more interesting. It says: “When you finish the first step, call <code>DoWork</code> again, but this time with <code>Id 2</code>.” The <code>prevTask</code> parameter is the previous <code>Task</code> that has finished its work. This triggered the start of the second <code>Task</code>.</p>
			<p>If you run this, you will see the lines printed to the console in the correct order.</p>
			<p>Let us rewrite the method that gets called one more time:</p>
			<pre class="source-code">
void DoWork(int id)
{
    Console.WriteLine($"call Id {id}, " +
                      $"running on thread " +
                      $"{Thread.CurrentThread.ManagedThreadId}.");
}</pre>			<p>We added the <code>id</code> of the thread this method runs on to the output. I also want to see that <code>id</code> thread before we start the tasks. Our calling code now looks like this:</p>
			<pre class="source-code">
Console.WriteLine($"Our main thread id =
{Thread.CurrentThread.ManagedThreadId}.");
Task myTask = new Task(() =&gt; DoWork(1));
myTask.ContinueWith((prevTask) =&gt; DoWork(2));
myTask.Start();</pre>			<p>If you run this, you will probably see that the tasks run on a different thread rather than the main one. If you repeat this a few times, it might even happen that the second task runs on a different thread from the first one. It is impossible to predict when this will happen; the scheduler picks whatever works best given the current conditions. We do not have to worry about this. It just works. Neat, isn’t it?</p>
			<p>Another nice class that is available in the TPL is the <code>Parallel</code> class. It allows us to do stuff in parallel. Let’s see that</p>
			<pre class="source-code">
Console.WriteLine($"Our main thread id =
{Thread.CurrentThread.ManagedThreadId}.");
int[] myIds = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};
Parallel.ForEach(myIds, (i) =&gt; DoWork(i));</pre>			<p>First, we<a id="_idIndexMarker293"/> will print the <code>id</code> of the current thread. Then we will create an array of integers from <code>1</code> to <code>10</code>; nothing special here. After that, we will call the static <code>ForEach</code> method on the <code>Parallel</code> class and give it the array and the lambda to call. The method iterates through the array and calls the lambda with the correct parameter. It does that in parallel, not sequentially, as with a standard <code>ForEach</code> loop.</p>
			<p>When you run this, you will see some exciting results. The order in which the program prints the IDs is entirely random. You will see that the runtime uses multiple threads, but sometimes it reuses some of these threads.</p>
			<p>Again, the TPL determines the best way to do this and handles all the threads’ creation and scheduling for you.</p>
			<p>TPL is extremely powerful. It is also the backbone of the async await pattern. This is a pattern that simplifies working with concurrency so much that most users do not realize what is happening behind the scenes. With your newfound knowledge, you should have no problem following what is happening. So, let’s have a look at async/await.</p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor097"/>Async/await</h1>
			<p>Software <a id="_idIndexMarker294"/>hardly ever runs in isolation. Most software needs to reach outside of its boundaries and access something that is not part of the code block at some point. Examples include reading and writing files, reading data from a network, sending something to a printer, and so on. Suppose that a typical machine can access a byte in memory in about 10 nanoseconds. Reading that same byte from an SSD takes approximately 1,000,000 nanoseconds or even longer. Reading data from external devices is usually about 100,000 to 1,000,0000 times slower than reading local data from memory. Think about that when you try to optimize your code if you know that your software transfers data to and from external hardware.</p>
			<p>Let’s take this one step further. Let us assume that you have a decent machine that can quickly process data. You need to read data from an external website. Your program must wait very long before that data is available. It can take milliseconds before that data reaches us. For us mere humans, that is pretty fast, but the computer could have done a million other tasks in the meantime. That seems like a colossal waste of our expensive resources, right?</p>
			<p>Threading <a id="_idIndexMarker295"/>can help, of course. You can create a thread to call the external website and wait for that to finish, doing other things in the meantime. However, as we have seen, threads can be quite cumbersome. The TPL helps, but still, things can get complicated. Reading data from external sources or writing data to external targets is so common that the CLR designers decided to help us by introducing async/await.</p>
			<p>The top-down approach is simple: anything that takes more time than simple operations should be done asynchronously. However, we do not want to deal with the threads themselves. Async/await, which uses the TPL internally, is a pattern that can help.</p>
			<p>What it does is this: as soon as you have code that needs to be run asynchronously, the compiler injects code that wraps our code into a state machine. This state machine tracks the threads and the progress of our code and switches back and forth between the blocks of code that need attention.</p>
			<p>Does that sound complicated? Well, it is. The usage, however, is straightforward. However, before I show it to you, I want to introduce a little piece of helper code I often use when discussing async/await. This code is just an extension method on the <code>string</code> class and outputs a <code>string</code> to the console and adds the <code>ManagedThreadId</code>. It even allows for coloring the output, making it easier to distinguish between the different threads. If you want to use this, go ahead. If you would rather use <code>Console.WriteLine()</code> everywhere yourself instead, be my guest. However, using this makes the critical part of the code more readable. Here is my extension method:</p>
			<pre class="source-code">
using static System.Threading.Thread;
namespace ExtensionLibrary;
public static class StringExtensions
{
    public static string Dump(this string message,         ConsoleColor printColor = ConsoleColor.Cyan)
    {
        var oldColor = Console.ForegroundColor;
        Console.ForegroundColor = printColor;
      Console.WriteLine($"({CurrentThread.ManagedThreadId})\t :         {message}");
        Console.ForegroundColor = oldColor;
        return message;
    }
}</pre>			<p>You can also<a id="_idIndexMarker296"/> find this code in the GitHub repository.</p>
			<p>First, I want to show you the most simple example:</p>
			<pre class="source-code">
using ExtensionLibrary;
DoWork();
// The program is paused until DoWork is finished.
// This is a waste of CPU!
"Just before calling the long-running DoWork()"
    .Dump(ConsoleColor.DarkBlue);
"Program has finished".Dump(ConsoleColor.DarkBlue);
Console.ReadKey();
void DoWork()
{
    "We are doing important stuff!".Dump(ConsoleColor.DarkYellow);
    // Do something useful, then wait a bit.
    Thread.Sleep(1000);
}</pre>			<p>Imagine<a id="_idIndexMarker297"/> that we want do something that takes a long time, such as reading a file from storage, in our <code>DoWork()</code> method. I have simulated that here by pausing the current thread for a second. Our entire program is paused while we call this in our main method. Our costly and powerful CPU is left to do nothing (at least not for our program). That seems wasteful! We’ve seen that we can use threads or the TPL to improve that. However, that code is also wrapped in the async/await pattern, so why not use this?</p>
			<p>To do this, I replaced <code>Thread.Sleep()</code> with a call to <code>Task.Delay()</code>. That more or less does the same thing but allows us to improve on our code. Remember: this <code>Thread.Sleep()</code> and the new <code>Task.Delay()</code> method are just a stand-in for the real work your application should be doing. Having a <code>Sleep()</code> or <code>Delay()</code> method in your code is usually a bad idea.</p>
			<p>If you have to call an async method, you must wait for it. So, we will add the <code>await</code> keyword before the call to <code>Task.Delay()</code>.</p>
			<p>Once we have done that replacement, I will also prefix our method with the <code>async</code> keyword. This keyword tells the compiler that it should wrap this method in the state machine I mentioned earlier. However, any async method should never return void for reasons that will become clear later. We need to return a <code>Task</code> or a <code>Task&lt;&gt;</code> if you actually return something. So, we changed our void to <code>Task</code>. Again, any async method needs to be called with the <code>await</code> keyword. So, the result looks like this:</p>
			<pre class="source-code">
using ExtensionLibrary;
"Just before calling the long-running DoWork()"
    .Dump(ConsoleColor.DarkBlue);
await DoWork();
// The program is no longer paused until DoWork is finished.
// This allows the CPU to keep working!
"Program has finished".Dump(ConsoleColor.DarkBlue);
Console.ReadKey();
async Task DoWork()
{
    "We are doing important stuff!".Dump(ConsoleColor.DarkYellow);
    // Do something useful, then wait a bit.
    await Task.Delay(1000);
}</pre>			<p>Run this and see what happens.</p>
			<p>You will probably see that <a id="_idIndexMarker298"/>the program starts on one thread and then carries out the <code>DoWork()</code> method on that same thread, but that it switches to a new thread when that is done. That is because the compiler sees our <code>Task.Delay()</code> await and decides to free up the CPU to do other things. The runtime puts our current thread on hold and stores its state in memory, leaving our main code free to do other things. Only when <code>Task.Delay()</code> finishes is our main thread revived. However, since the main thread is no longer associated with our code here, we need a new thread. That one is pulled from the <code>ThreadPool</code> (remember: that is fast since the threads there were created at startup) and populated with the state we had. Then the system can continue on that thread. The program ends on that new thread as well!</p>
			<p>I mentioned that all async methods need the async modifier and should return a <code>Task</code> instead of a void. There is a simple reason for this. If you do not do this, your code will work but not as expected. The <strong class="bold">Async all the way to the top</strong> rule is simple but very important.</p>
			<p class="callout-heading">Async all the way to the top!</p>
			<p class="callout">If you have a method <a id="_idIndexMarker299"/>containing an <code>await</code> keyword, the method needs to be async and return a <code>Task</code>. However, since you will probably call that method yourself somewhere, the calling code must also be async and return some form of <code>Task</code> or <code>Task&lt;&gt;</code>. Since that method is also called… well, you get the idea. The rule is: async all the way to the top! Every method in that chain needs to have that async!</p>
			<p>Another rule, which is <a id="_idIndexMarker300"/>not as strict as the “Async all the way to the top” rule, is that all async methods should be named as such. Our <code>DoWork()</code> method should be renamed to <code>DoWorkAsync()</code>.</p>
			<p>However, before we do that, let us see what happens if we are sloppy and do not return a <code>Task</code>. Try it yourself: replace the <code>Task</code> return type with a void and remove the await before <code>DoWork()</code> (you cannot await a void, so you will get an error if you do not remove that).</p>
			<p>Run it. It works just fine, right? Okay, there is no new thread created, but who cares? The software does what it needs to do.</p>
			<p>Now, let’s change our <code>DoWork()</code> method a bit:</p>
			<pre class="source-code">
using ExtensionLibrary;
"Just before calling the long-running DoWork()"
    .Dump(ConsoleColor.DarkBlue);
DoWork();
"Program has finished".Dump(ConsoleColor.DarkBlue);
//Console.ReadKey();
async void DoWork()
{
    "We are doing important stuff!"
        .Dump(ConsoleColor.DarkYellow);
    await Task.Delay(1000);
    throw new Exception(
        "Something went terribly wrong."
    );
    "We're done with the hard work."
        .Dump(ConsoleColor.DarkYellow);
}</pre>			<p>I also temporarily removed the <code>ReadLine()</code> to make the program more lifelike. The main thread finishes when everything is done.</p>
			<p>Run it. See<a id="_idIndexMarker301"/> that we do not get the <code>“We’re done with the hard work” </code>message. That makes sense; there is an exception in front of it. However, please notice that we also do not see that exception.</p>
			<p>Why is this? It’s complicated, but the simplified explanation is that the state machine is still created since <code>DoWork</code> is still an async method. The exception is raised on a different thread (after the <code>Task.Delay()</code> await). However, since the state machine is not configured to wait for all results (because we omitted the <code>await</code> keywords), it just ignores that thread. If you move that “We’re done with the hard work” <code>Dump()</code> line to the line before the exception, you will see that it is not called. In reality, it <em class="italic">is</em> called; you just don’t see it. This thread has become a fire-and-forget thread. You lost all control over it.</p>
			<p>Can you imagine a complex piece of software where something goes wrong deep in the bowels of your code? Can you imagine not getting the exception? Can you imagine the horror of debugging that?</p>
			<p>You will get that exception if you use async/await all the way up.</p>
			<p>Oh, before I forget: the reason that I removed the <code>Console.ReadKey()</code> line is that by doing so, I forced the main thread to quit as soon as possible, resulting in unloading the application from memory. If you restore that line, you will see the exception, since the main thread is paused there. Now other things will be allowed to happen.</p>
			<p>However, that is <a id="_idIndexMarker302"/>not really a solution to our problem. You do not want to wait for the main thread to become idle before you get exceptions. It could take ages for that to happen.</p>
			<p>Please restore the async/await keywords, replace the void in <code>DoWork()</code> with <code>Task</code>, and run it. The exception is thrown precisely where you would expect it to be.</p>
			<p>This is really important, so I like to repeat it once more: async all the way to the top!</p>
			<h2 id="_idParaDest-99"><a id="_idTextAnchor098"/>Task.Wait() and Task.Result</h2>
			<p>There are<a id="_idIndexMarker303"/> many blog posts and articles about why you should not use <code>Task.Wait()</code> or <code>Task.Result</code>. The<a id="_idIndexMarker304"/> reason for this is pretty simple: these calls block the current thread. Using them removes the scheduler’s ability to resume work on the calling thread and return to the execution flow when the <code>Task</code> is done. If you do this, why use async/await in the first place? Async/await also allows for thread synchronization, so there is no need to use <code>Wait()</code> and <code>Result</code>.</p>
			<p>Hold on. There are some situations where you might decide to use them anyway:</p>
			<ul>
				<li>You may want to use them if you are working on legacy code that you are modernizing. The rule is “Async all the way to the top,” which might require extensive code refactoring. That is not always feasible. In those cases, you might use <code>Wait()</code> and <code>Result</code> instead.</li>
				<li>In unit tests, you can mock or stub async methods. However, sometimes it might be better for the unit test to use <code>Wait()</code> and <code>Result</code>.</li>
				<li>You might not care about the main thread staying responsive in systems programming. There is no user interface, after all. So, blocking the main thread may not be a big problem. I still think that it is bad form not to use async/await, but in these cases, you can get away with using <code>Wait()</code> and <code>Result</code>.</li>
			</ul>
			<p>As with all rules in software development, be vigilant about these rules and apply them as much as possible, only breaking them if you have a good reason and have thought about it well. Also, please do your future self a favor and document why you chose to deviate from the usual way of working in the source code.</p>
			<p>So, now you know how to use async/await. Although they do not always result in multiple threads, they are a great way to balance the load in your application. They help tremendously in keeping your code organized. You are relieved of the burden to do all synchronization between threads. However, that doesn’t mean that you never have to care about synchronization at all. There is no avoiding that, so I think we should talk about it right now.</p>
			<h1 id="_idParaDest-100"><a id="_idTextAnchor099"/>Synchronizing threads</h1>
			<p>The async/await pattern<a id="_idIndexMarker305"/> has made life easier for us developers. If you have a long-running task (and remember: anything that uses devices outside the CPU is long-running), you can call that method asynchronously. Then you can sit back and wait for it to finish without blocking the execution of your app in other places. The TPL takes care of the thread management.</p>
			<p>However, sometimes you may want to have a bit more control. You might have a situation where you must wait for a method to finish before you can continue. Imagine that you have your main thread and call the <code>A()</code> method. That method is long-running, so you make it async (rename it to something ending with ‘async’) and change the return type to <code>Task</code> or <code>Task&lt;&gt;</code>. Now you can wait for it. However, another thread might have to wait until your <code>Aasync()</code> method is finished. How do you do that?</p>
			<p>Welcome to the wonderful world of thread synchronization.</p>
			<h2 id="_idParaDest-101"><a id="_idTextAnchor100"/>Synchronization – how do we do that?</h2>
			<p>In the old days, when <a id="_idIndexMarker306"/>we still used threads and the <code>ThreadPool</code>, synchronization could be a hassle. However, with <code>Task</code> and async/await, things have become much easier without having real downsides. Before I show you that, I want to show you how to synchronize threads instead of tasks.</p>
			<p>Let me start with the base program:</p>
			<pre class="source-code">
using ExtensionLibrary;
"In the main part of the app.".Dump(ConsoleColor.White);
ThreadPool.QueueUserWorkItem(DoSomethingForTwoSeconds);
ThreadPool.QueueUserWorkItem(DoSomethingForOneSecond);
"Main app is done.\nPress any key to
stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;
void DoSomethingForOneSecond(object? notUsed)
{
    $"Doing something for one second.".Dump(ConsoleColor.Yellow);
    Thread.Sleep(1000);
    $"Finished something for one second".Dump(ConsoleColor.Yellow);
}
void DoSomethingForTwoSeconds(object? notUsed)
{
    "Doing something for two
        seconds.".Dump(ConsoleColor.DarkYellow);
    Thread.Sleep(2900);
    "Done doing something for two
        seconds.".Dump(ConsoleColor.DarkYellow)
}</pre>			<p>This sample should be obvious now. I have two methods that do something that takes a long time to finish. I pull some threads out of the <code>ThreadPool</code> and run all of this simultaneously.</p>
			<p>If you run this, the <code>Console.ReadKey()</code> in place. What could we do if we want to wait for the two methods to be finished before we move on?</p>
			<p>The answer is to<a id="_idIndexMarker307"/> use a synchronization mechanism. This means that we have an object that we can use to flag certain states. We can write it ourselves, but we must take care of a lot of synchronization and thread safety. Luckily, we do not have to. The Win32 API provides tools that are neatly wrapped in BCL classes.</p>
			<p>One of these is the <code>CountdownEvent</code> class. As the name suggests, it allows us to count down events.</p>
			<p>Change your main method to look like this:</p>
			<pre class="source-code">
"In the main part of the app.".Dump(ConsoleColor.White);
// Tell the system we want to wait for 2 threads to finish.
CountdownEvent countdown = new(2);
ThreadPool.QueueUserWorkItem(DoSomethingForOneSecond);
ThreadPool.QueueUserWorkItem(DoSomethingForTwoSeconds);
// Do the actual waiting.
countdown.Wait();
"Main app is done.\nPress any key to stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;</pre>			<p>We will create a new instance of the <code>CountdownEvent</code> class and initialize it to <code>2</code>.</p>
			<p>Then, we will get the threads and allow them to do their work.</p>
			<p>In the code in the methods, I have added one line:</p>
			<pre class="source-code">
void DoSomethingForOneSecond(object? notUsed)
{
    $"Doing something for one second.".Dump(ConsoleColor.Yellow);
    Thread.Sleep(1000);
    $"Finished something for one second".Dump(ConsoleColor.Yellow);
    countdown.Signal();
}</pre>			<p>At the bottom <a id="_idIndexMarker308"/>of the method, you will see the <code>.Signal()</code> countdown. Since that instance is reachable in this method, I can use it. <code>Signal()</code> tells the countdown to decrease the number of events to wait for.</p>
			<p>I did the same to the <code>DoSomethingForTwoSeconds()</code> method.</p>
			<p>That means that when both methods are done, they call <code>Signal()</code> on the countdown. In the main method, I added <code>countdown.Wait()</code> after the <code>ThreadPool</code> code, telling the main thread to pause until the countdown reaches zero.</p>
			<p>If you run this, you will see it works wonderfully and that the rest of the main thread is perfectly synchronized with the threads.</p>
			<p>However, what if I want the <code>DoSomethingForTwoSeconds</code> method to start when <code>DoSomethingForOneSecond</code> is finished?</p>
			<p>That is almost as easy. We can use one of the other synchronization classes to help us out. Let me show you how to do this using the <code>ManualResetEvent</code>. This class does more or less the same as the <code>CountdownEvent</code>. The difference is that the <code>ManualResetEvent</code> class does not count; it just waits for a signal.</p>
			<p>In the main method, before calling the <code>ThreadPool</code>, I have added this line:</p>
			<pre class="source-code">
ManualResetEvent mre = new(false);</pre>			<p>I have set it in the initial <code>False</code> state. Doing so results in any thread waiting for the event to be set.</p>
			<p>In <code>DoSomethingForOneSecond()</code>, I have added one line right at the end:</p>
			<pre class="source-code">
// Tell the second thread it can start
mre.Set();</pre>			<p>The call to <code>Set</code> tells the <code>ManalResetEvent</code> that any waiting thread can continue.</p>
			<p>In <code>DoSomethingForTwoSeconds()</code>, I have added the following to the beginning of the method:</p>
			<pre class="source-code">
// Wait for the first thread to finish.
mre.WaitOne();</pre>			<p><code>WaitOne()</code> tells the code to pause the thread until the <code>mre</code> gets a signal (which happens at the end of <code>DoSomethingForOneSecond()</code>).</p>
			<p>If you run your <a id="_idIndexMarker309"/>program now, you will notice that everything is nicely synchronized and waiting for other stuff to finish.</p>
			<p>Of course, you might have achieved precisely the same result by not using threads. We have basically removed all multitasking from our application. If you need to synchronize threads, now you know how. However, be careful: you might introduce weird errors if you make mistakes. Trust me: debugging multithreaded applications is no walk in the park.</p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor101"/>Synchronization with async/await</h2>
			<p>You might<a id="_idIndexMarker310"/> have guessed by now that using async/await dramatically reduces the complexity of working with threads and synchronizing between them.</p>
			<p>Let us return to our example of the <code>DoSomethingForOneSecond</code> and <code>DoSomethingForTwoSeconds</code> methods. This time, we will rewrite them to use async/await.</p>
			<p>Your <code>DoSomethingForOneSecond</code> should be like this:</p>
			<pre class="source-code">
async Task DoSomethingForOneSecondAsync()
{
    $"Doing something for one second.".Dump(ConsoleColor.Yellow);
    await Task.Delay(1000);
    $"Finished something for one second".Dump(ConsoleColor.Yellow);
}</pre>			<p>I renamed the function to end with async, as I should have done much earlier.</p>
			<p>The <code>DoSomethingForTwoSecondsAsync()</code> should get the same treatment.</p>
			<p>Calling the <a id="_idIndexMarker311"/>methods in the main method now looks like this:</p>
			<pre class="source-code">
"In the main part of the app.".Dump(ConsoleColor.White);
await DoSomethingForOneSecondAsync();
await DoSomethingForTwoSecondsAsync();
"Main app is done.\nPress any key to stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;</pre>			<p>The results are identical to those from the example where we did all the synchronization ourselves, with the only difference being that we have no blocking threads anymore. So this is not only easier to do but it is also much better.</p>
			<p>However, what happens if we do not want to do the methods sequentially? What if we want them to run simultaneously?</p>
			<p>Well, that is easy enough. Since our methods return a <code>Task</code>, we can work with that. Instead of waiting for them individually, we can simultaneously wait for them. Let me show you:</p>
			<pre class="source-code">
var task1 = DoSomethingForOneSecondAsync();
var task2 = DoSomethingForTwoSecondsAsync();
// Wait for all tasks to be finished
Task.WaitAll(task1, task2);
"Main app is done.\nPress any key to stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;</pre>			<p>We will take advantage of the fact that we get tasks back. The <code>Task</code> class has a static method called <code>WaitAll()</code> that only returns when all tasks are finished.</p>
			<p>There are<a id="_idIndexMarker312"/> other methods, such as <code>WaitAny</code> (only continue when any of the tasks finish), WhenAll (do something when they are all done), and WhenAny (you can figure this out by yourself).</p>
			<p>The difference between <code>WaitAll</code> or <code>WaitAny</code> and <code>WhenAll</code> or <code>WhenAny</code> is that <code>WaitXXX</code> is a blocking call. It blocks the current thread until the condition has been met<code>. WhenXXX</code> returns a Task itself that you can await and thus does not block the thread.</p>
			<p>However, there is a bigger difference: <code>WhenAll</code> allows you to capture the return result. If any tasks that you want to wait for return a result, you can get that with <code>WhenAll</code>. <code>WhenAll</code> returns the results to you in an array. You can get at them, which is something you cannot do with <code>WaitAll</code> or <code>WaitAny</code>.</p>
			<p>In case you were wondering, <code>WhenAny</code> returns a <code>Task&lt;T&gt;</code>. That <code>Task&lt;T&gt;</code> has a property called <code>Result</code>; you can read that property to get access to the result of that Task. This is one example when using <code>Result</code> is actually a good thing!</p>
			<h2 id="_idParaDest-103"><a id="_idTextAnchor102"/>Canceling a thread</h2>
			<p>Sometimes, you want to <a id="_idIndexMarker313"/>stop a thread from running. There might be several good reasons to do this, but whatever your reason, be sure to clean up after yourself. Threads are expensive to use and leaving them in an unknown state is a horrible practice: you shoot yourself in the foot one day.</p>
			<p>In the days of.NET Framework, the <code>Thread</code> class had a method called <code>Abort()</code>. However, it turned out that the method did more harm than good, so the BCL and CLR people decided to get rid of it. If you try to abort a thread, you will get a <code>PlatformNotSupportedException</code>. I guess they really do not want us to use that anymore.</p>
			<p>The best way to stop a running thread is the same way you should stop a running <code>Task</code>: using something we <a id="_idIndexMarker314"/>call <strong class="bold">cooperative cancellation</strong>. A calling thread can request another thread to stop. It is up to that second thread to honor that request – or not. There is no guarantee.</p>
			<p>The standard way of doing this is by using a <code>CancellationToken</code>. A <code>CancellationToken</code> is an object we use to signal that we want to cancel something.</p>
			<p>Of course, you <a id="_idIndexMarker315"/>can write this class yourself. There is not much going on besides some thread safety. However, having a <code>CancellationToken</code> in your threads or tasks makes it clear to the user that it can be canceled.</p>
			<p>I am going to rewrite our <code>DoSomethingForOneSecondAsyncMethod()</code> a bit:</p>
			<pre class="source-code">
async Task DoSomethingForOneSecondAsync()
{
    $"Doing something for one second.".Dump(ConsoleColor.Yellow);
    for(int i=0;i&lt;1000;i++)
        await Task.Delay(1);
    $"Finished something for one second".Dump(ConsoleColor.Yellow);
}</pre>			<p>Instead of having the <code>Task.Delay(1000) </code>call, I do <code>1000 </code>await <code>Task.Delay1)</code>. In theory, that would result in a one-second delay. However, when you run this, it takes considerably longer. The await call itself takes up some time as well.</p>
			<p>I could measure how long it takes and then recalculate the number of iterations, or I could simply rename the method to <code>DoSomethingForSomeUnderterminedAmountOfTimeAsync()</code>. I will leave that decision up to you.</p>
			<p>Assume that we get bored after 500 milliseconds after waiting in our main method and decide to stop this thread. How would we achieve that?</p>
			<p>This is where the <code>CancellationToken</code> steps in. Again, a <code>CancellationToken</code> is a simple class. You can create one if you want to, but it is better to use a specialized class. This <code>CancellationTokenSource</code> class is created specifically for this and works in all sorts of weird conditions. It is inherently thread-safe.</p>
			<p>Let us create <a id="_idIndexMarker316"/>one right at the beginning of the main method:</p>
			<pre class="source-code">
using ExtensionLibrary;
"In the main part of the app.".Dump(ConsoleColor.White);
using var cts = new CancellationTokenSource();
var task1 = DoSomethi<a id="_idTextAnchor103"/>ngForOneSecondAsync();
Task.WaitAny(task1);
"Main app is done.\nPress any key to stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;</pre>			<p>I use <code>WaitAny</code> here because we want to cancel that task after the moment when we create it and before it has finished. Also, note the <code>using</code> statement. <code>CancellationTokenSource</code> implements <code>IDisposable</code>, so we must honor that.</p>
			<p>Canceling is simple. Between the <code>var task1</code> and <code>Task.WaitAny()</code> lines, add the following:</p>
			<pre class="source-code">
await Task.Delay(500);
"We got bored. Let's cancel.".Dump(ConsoleColor.White);
cts.Cancel();</pre>			<p>We will wait a bit, then get bored and call <code>cts.Cancel()</code>.</p>
			<p>However, if you run this, nothing will happen. That’s not entirely true; many things will happen. To be precise, the entire loop in <code>DoSomethingForOneSecondAsync</code> happens.</p>
			<p><code>CancellationToken</code> is not a magic way to cancel running tasks. You have to check for that token yourself.</p>
			<p>We have to add a parameter to our method of the <code>CancellationToken</code> type. The method signature will now look like this:</p>
			<pre class="source-code">
async Task DoSomethingForOneSecondAsync(CancellationToken cancellationToken)</pre>			<p>We have to <a id="_idIndexMarker317"/>pass in that token when we call it. In our main method, change the line calling this method to this:</p>
			<pre class="source-code">
var task1 = DoSomethingForOneSecondAsync(cts.Token);</pre>			<p>We will take our <code>CancellationTokenSource</code> and get its token. That is what we will pass on to our method.</p>
			<p>Inside our method, we must check to see whether we need to cancel. Yes, that is why I added the loop around the <code>Delay</code>. The full method will now look like this:</p>
			<pre class="source-code">
async Task DoSomethingForOneSecondAsync(CancellationToken cancellationToken)
{
    $"Doing something for one second.".Dump(ConsoleColor.Yellow);
    bool hasBeenCancelled = false;
    int i = 0;
    for (i = 0; i &lt; 1000; i++)
    {
        if (cancellationToken.IsCancellationRequested)
        {
            hasBeenCancelled = true;
            break;
        }
        await Task.Delay(1);
    }
    if(hasBeenCancelled)
    {
        $"We got interrupted after {i} iterations.".Dump(ConsoleColor.            Yellow);
    }
    else
    {
        $"Finished something for one second".Dump(ConsoleColor.            Yellow);
    }
}</pre>			<p>If someone calls <code>Cancel</code> on the <code>CancellationTokenSource</code>, the <code>IsCancellationRequested</code> flag on the token will be set to <code>True</code>. We have to honor that. I do that by breaking out of the <code>for</code> loop. I have also set a <code>hasBeenCancelled</code> variable to <code>True</code> so I can inform our users that we have canceled this loop and tell them after how many iterations it was canceled.</p>
			<p>We could <a id="_idIndexMarker318"/>have skipped this boolean and used <code>IsCancellationRequested</code> again. However, there might have been a risk of the request coming in right after the loop was done but before the printing of the message. In that case, the loop was not interrupted. But we said it was anyway, which is incorrect. This way we avoid printing the wrong message.</p>
			<p>Run it and see what happens. On my machine, I get about 40 iterations before it cancels.</p>
			<p>There is one bug in this code. It is good practice to pass on the <code>CancellationToken</code> to any method that accepts it. In our case, that would be <code>Task.Delay()</code>. There is an overload that accepts a <code>CancellationToken</code>.</p>
			<p>I deliberately left that out here. Since the code would be in that line almost 100% of the time, awaiting the Delay, we would cancel that and never see any printed messages. However, let’s now add it:</p>
			<pre class="source-code">
await Task.Delay(1, cancellationToken);</pre>			<p>Rerun it and see what happens.</p>
			<p>You might notice that we are missing a lot of screen output. The reason is simple. <code>Task.Delay()</code> throws an <code>OperationCancelledException</code> when it is canceled. However, we are not using <code>await</code> on our <code>Task</code> in the main method, so we will miss the <a id="_idIndexMarker319"/>exception. Remember when I said it was all too easy to miss exceptions when not everything is done right?</p>
			<p>Synchronization helps to prevent errors from happening. However, there are a lot of techniques to make sure our code is thread-safe. Let’s dive into those now.</p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor104"/>Thread-safe programming techniques</h1>
			<p>Look at this <a id="_idIndexMarker320"/>piece of code. Run it and see what happens:</p>
			<pre class="source-code">
using ExtensionLibrary;
int iterationCount = 100;
ThreadPool.QueueUserWorkItem(async (state) =&gt;
{
    await Task.Delay(500);
    iterationCount = 0;
    $"We are stopping it...".Dump(ConsoleColor.Red);
});
await WaitAWhile();
$"In the main part of the app.".Dump(ConsoleColor.White);
"Main app is done.\nPress any key to stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;
async Task WaitAWhile()
{
    do
    {
        $"In the loop at iterations {iterationCount}".            Dump(ConsoleColor.Yellow);
        await Task.Delay(1);
    }while (--iterationCount &gt; 0) ;
}</pre>			<p>We have a <code>Task</code> that counts down from 100 to 0. Since we <code>await</code> this, the main part of the code waits nicely for this to finish before continuing. However, we also have a second thread that waits for 500 milliseconds and then sets the counter to <code>0</code>. The result is that the loop finishes prematurely.</p>
			<p>What we see here is easy to debug. Every line of code is one screen, so I imagine that you will be able to spot the bug quite easily.</p>
			<p>However, what<a id="_idIndexMarker321"/> if the integer used here is a member of a class? As you know, instances of classes are reference types. Reference types get passed on by reference, not by value. So if the Task has access to that instance, it can alter the members in that instance. However, every other task, thread, or piece of code sees the effects of that.</p>
			<p>Thread safety is all about avoiding these kinds of things.</p>
			<p>Value types are inherently safe. You will have no issues if you pass a value type such as integer to your <code>Task</code>. The value of the integer is copied and you are not changing the original value.</p>
			<p>However, if you need to access more complex types, you will need to think about this. The good news is that the runtime offers us several tools to mitigate this issue.</p>
			<p>One of the tools you get is the <code>Lock()</code> keyword.</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor105"/>Lock()</h2>
			<p>The<a id="_idIndexMarker322"/> simplest way to safeguard your data is to have a lock around it. A lock is an object that more or less works as a moat around a piece of code. A lock ensures that only one thread can simultaneously be in that code block. The syntax is straightforward:</p>
			<pre class="source-code">
lock (new object())
{
    iterationCount--;
}</pre>			<p>The lock takes one argument. It uses this to identify the area to lock. It doesn’t do anything with this object; this is just something to hook the lock to. So, having a new <code>object()</code> will suffice.</p>
			<p>Any code in this code block is safe, meaning that only one thread can decrement the <code>iterationCount</code> simultaneously. When another thread tries to do the same thing simultaneously, it blocks as soon as it reaches the lock statement. That thread remains blocked until the previous threat exits the code block.</p>
			<p>Yes, this means that if the other thread crashes in that code (not very likely in this example: crashing on a <code>--</code> operator happens very infrequently), the rest of the system can never enter that code block.</p>
			<p><code>Lock()</code> is syntactic sugar around a monitor object. The compiler actually uses <code>Monitor</code>s. So, the following code results in the same IL (Intermediate language):</p>
			<pre class="source-code">
var lockObject = new object();
Monitor.Enter(lockObject);
try
{
    iterationCount--;
}
finally
{
    Monitor.Exit(lockObject);
    lockObject = null;
}</pre>			<p>I do not know <a id="_idIndexMarker323"/>about you, but the <code>lock()</code> statement looks much more effortless to me.</p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor106"/>Records</h2>
			<p>The <a id="_idIndexMarker324"/>best way to ensure that data is not accidentally overridden is to ensure that the data cannot be altered. Immutable types are designed to do just that.</p>
			<p>Let me create a record first:</p>
			<pre class="source-code">
record Counter(int InitialValue);</pre>			<p>A record is a reference type, so its memory is allocated on the heap. However, records are meant to be immutable. You can create records that are not immutable, but that does not help us here.</p>
			<p>Right now, I have a record with one member, <code>InitialValue</code>. I have to set the value for that when constructing the <code>Counter</code>, but I can never change it after that. So, no thread can come along and mess with that value anymore.</p>
			<p>However, since I cannot change it anywhere, I also have to change the code in the <code>Task</code>. It will now look like this:</p>
			<pre class="source-code">
async Task WaitAWhile()
{
    var actualCounter = myCounter.InitialValue;
    do
    {
        $"In the loop at iterations {actualCounter}".            Dump(ConsoleColor.Yellow);
        await Task.Delay(1);
    } while (--actualCounter &gt; 0);
}</pre>			<p>I have made a copy of the value to decrement that in the loop. If you are a bit like me, you might say, “Wait a minute. Why didn’t I just copy that original <code>iterationCount</code> to a local variable and use that instead of this record?”</p>
			<p>I see many <a id="_idIndexMarker325"/>people doing that. However, that is not guaranteed to work. What if a separate thread changes the value of <code>iterationCount</code> before you can make a copy? You would start with the wrong initial value.</p>
			<p>Immutable records guarantee that the values inside it do not change, ever. Period. You are safe.</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor107"/>Avoid static members and classes</h2>
			<p>I know that<a id="_idIndexMarker326"/> it can be a nuisance to create instances of classes. Sometimes, it seems easier to create a static class filled with static members and use those instead. They certainly do have some use cases. However, remember this: static classes are not thread-safe out of the box. Static members are shared across threads so that anybody can change them.</p>
			<h2 id="_idParaDest-108"><a id="_idTextAnchor108"/>Using the volatile keyword</h2>
			<p>Sometimes, code <a id="_idIndexMarker327"/>seems straightforward, but it might not be. Look at this line:</p>
			<pre class="source-code">
int a=42;</pre>			<p>We know how this works. This integer is on the stack. If we change the value, the value at that memory address changes. Simple, right? Wrong. The compiler does all sorts of tricks to optimize our code, especially when you build it in Release mode. Building in Release mode means that the compiler might cache the value of even a simple integer to speed things up. It might even decide to move that line to another place in the code if it thinks it will not make a difference in the execution.</p>
			<p>That is not a problem until multiple threads or tasks deal with that code. The compiler might make mistakes. It cannot determine which tasks can access that variable simultaneously.</p>
			<p>Yes, even simple writing to an integer can go wrong in a multithreaded system.</p>
			<p>If we use <code>lock()</code>, we can guarantee that only one thread can access that code block, but that still does not mitigate the issue of the compiler optimizations.</p>
			<p>To solve this problem, we can use the <code>volatile</code> keyword. It looks like this:</p>
			<pre class="source-code">
private static volatile int _initialValue = 100;</pre>			<p>Instead <a id="_idIndexMarker328"/>of using a cached value, the compiler ensures that we always go directly to the memory address and stored value. That means that all threads will go to the same place and work with the same integer, thus eliminating the risk of working on old, stale, or cached data.</p>
			<p>You might be tempted to add that <code>volatile</code> keyword everywhere, but I suggest that you refrain. It does mess with the compiler’s optimization techniques. You should only use it if you suspect that there might be an issue with that particular piece of code.</p>
			<p>So, now you know how to be more safe when dealing with threads. This is very important: if you mess things up you can get horrible and hard-to-debug bugs in your code. This is especially true if you are dealing with collections in multiple threads. How do you keep them synchronized? We’re in luck though; the BCL has got us covered there. Let’s talk about concurrent collections.</p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor109"/>Concurrent collections in .NET</h1>
			<p>Collections are <a id="_idIndexMarker329"/>the backbone of many programs. Arrays, lists, dictionaries – we use them all the time. However, are they thread-safe? Let us find out:</p>
			<pre class="source-code">
using ExtensionLibrary;
var allLines = new List&lt;string&gt;();
for(int i = 0; i &lt; 1000; i++)
{
    allLines.Add($"Line {i:000}");
}
ThreadPool.QueueUserWorkItem((_) =&gt;
{
    Thread.Sleep(1000);
    allLines.Clear();
});
await DumpArray(allLines);
"Main app is done.\nPress any key to stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;
async Task DumpArray(List&lt;string&gt; someData)
{
    foreach(var data in someData)
    {
        data.Dump(ConsoleColor.Yellow);
        await Task.Delay(100);
    }
}</pre>			<p>We have a <code>List&lt;string&gt;</code>. Then we added 1000 strings to that list We have a task that iterates through them, displays them on the screen, and waits a bit.</p>
			<p>We also have a separate thread that clears the list after waiting for a second.</p>
			<p>If you have read the previous section in this chapter, you might expect the loop in the task to abort prematurely. It should not print all items, since the list is suddenly empty and thus the <code>ForEach()</code> stops.</p>
			<p>However, if you run it, you will see a different result. You will get a nice <code>InvalidOperationException</code> telling you that the collection was modified, which messed up the <code>ForEach</code> code.</p>
			<p>Collections in the<a id="_idIndexMarker330"/> BCL are not thread-safe. If one thread works with them and another decides it needs to deal with that collection, things go wrong.</p>
			<p>The following collections are not thread-safe and should be avoided when working with tasks:</p>
			<ul>
				<li><code>List&lt;T&gt;</code></li>
				<li><code>Dictionary&lt;TKey</code> and <code>TValue&gt;</code></li>
				<li><code>Queue&lt;T&gt;</code></li>
				<li><code>Stack&lt;T&gt;</code></li>
				<li><code>HashSet&lt;T&gt;</code></li>
				<li><code>ArrayList</code></li>
				<li><code>HashTable</code></li>
				<li><code>SortedList&lt;TKey</code>, <code>TValue&gt;</code>, and <code>TSortedList</code></li>
			</ul>
			<p>Do not use these in multiple threads or tasks simultaneously.</p>
			<p>Some collections are thread-safe. This is what they are and what they do:</p>
			<table class="No-Table-Style _idGenTablePara-1" id="table003-2">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Collection name</strong></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Description</strong></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><code>ConcurrentDictionary&lt;TKey, TValue&gt;</code></p>
						</td>
						<td class="No-Table-Style">
							<p>A thread-safe collection of key-value pairs. It allows for concurrent adds, updates, and removals.</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><code>ConcurrentQueue&lt;T&gt;</code></p>
						</td>
						<td class="No-Table-Style">
							<p>A thread-safe version of a <strong class="bold">First-in, First-out</strong> (<strong class="bold">FIFO</strong>) collection.</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><code>ConcurrentStack&lt;T&gt;</code></p>
						</td>
						<td class="No-Table-Style">
							<p>A thread-safe version of a <strong class="bold">Last-in, First-out</strong> (<strong class="bold">LIFO</strong>) collection.</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><code>ConcurrentBag&lt;T&gt;</code></p>
						</td>
						<td class="No-Table-Style">
							<p>A thread-safe, unordered collection of objects. It is suitable for scenarios where the order is not important.</p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><code>BlockingCollection&lt;T&gt;</code></p>
						</td>
						<td class="No-Table-Style">
							<p>Represents a thread-safe collection that can be bounded in size. It provides blocking and non-blocking <code>add</code> and <code>take</code> operations.</p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 4.3: Thread-safe collections</p>
			<p>The first four <a id="_idIndexMarker331"/>collections are just thread-safe versions of the collections that we already know. Most people, however, would not recognize the last one: the <code>BlockingCollection&lt;T&gt;</code> collection.</p>
			<p>This collection is, first of all, thread-safe. It also allows for blocking. Let me give you an example:</p>
			<pre class="source-code">
using ExtensionLibrary;
using System.Collections.Concurrent;
// We have a collection that blocks as soon as
// 5 items have been added. Before this thread
// can continue, one has to be taken away first.
var allLines = new BlockingCollection&lt;string&gt;(boundedCapacity:5);
ThreadPool.QueueUserWorkItem((_) =&gt; {
    for (int i = 0; i &lt; 10; i++)
    {
        allLines.Add($"Line {i:000}");
        Thread.Sleep(1000);
    }
    allLines.CompleteAdding();
});
// Give the first thread some time to add items before
// we take them away again.
Thread.Sleep(6000);
// Read all items by taking them away
ThreadPool.QueueUserWorkItem((_) =&gt; {
    while (!allLines.IsCompleted)
    {
        try
        {
            var item = allLines.Take();
            item.Dump(ConsoleColor.Yellow);
            Thread.Sleep(10);
        }
        catch (InvalidOperationException)
        {
            // This can happen if
            // CompleteAdding has been called
            // but the collection is already empty
            // in our case: this thread finished before the
            // first one
        }
    }
});
"Main app is done.\nPress any key to stop.".Dump(ConsoleColor.White);
Console.ReadKey();
return 0;</pre>			<p>A lot is happening here, so let me walk you through it.</p>
			<p>First, we created an instance of the <code>BlockingCollection</code>. This class has a nice overloaded constructor that only allows this number of items to be added. If there are more, block the thread. I do not need that functionality here, but I found adding it funny.</p>
			<p>Then we<a id="_idIndexMarker332"/> spun up a new thread that adds items to this collection. We can try to add 10, but again, it only allows five items. So, when the fifth item is added, this thread blocks until we have removed one of those items.</p>
			<p>At the end of the loop, we told the collection that we had nothing left to add. We did this by calling <code>CompleteAdding()</code>.</p>
			<p>Before we read the data in the second thread, we waited for a few seconds so the first one had time to fill the collection.</p>
			<p>The second thread (third if you also count the main thread) took that collection and took an item from it. It is a FIFO collection, so the first item we could take was the first item added to the list. We displayed what we took and waited a bit. We needed to catch the <code>InvalidOperationException</code>. If the <code>CompleteAdding</code> was called due to timings by the time we had already taken all the items from the collection, an exception would have occurred. We need to catch that.</p>
			<p>Due to our timings and <code>Thread.Sleep()</code> calls, we will see a fascinating effect. The first thread fills up the collection with five items. Then it waits. This operation takes five seconds in total. Six seconds after the start of the program, we will start taking items. Since there are plenty of them (five to be exact), the program will print these items on the screen quickly. When we take one item, the first thread gets permission to add a new item. However, since it takes a second to add an item, the second thread has to wait until it has been added. <code>Take()</code> will also block if there is nothing to take yet.</p>
			<p>Only when the first thread calls the <code>CompleteAdding()</code> method does the second thread know it is done (since we checked the <code>IsCompleted</code> property). Then, we can exit the threads.</p>
			<p>There is much synchronization behind the scenes, but it works amazingly well. This is undoubtedly an excellent addition to your toolbox!</p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor110"/>Next steps</h1>
			<p>That was quite a ride. Threading can be complicated, but we got through it all right.</p>
			<p>We looked at many different things in this chapter. We described what multitasking is, starting with old-fashioned IRQs, walking through cooperative multitasking, and arriving at the modern style of pre-emptive multitasking.</p>
			<p>Then, we investigated Win32 threads and their .NET counterparts. We saw how to create threads but quickly found that the <code>Threadpool</code> offers a better way of doing so in most cases. However, we learned that most of that is moot, since the TPL handles many details for us.</p>
			<p>In particular, we learned that async/await hides much complexity and makes writing multithreaded code a breeze. As with all tools, we learned that async/await comes with risks. You have to know what happens and where bad things can happen. Luckily, we covered those situations as well.</p>
			<p>We looked at collections and how to make your code thread-safe. We also learned something fundamental regarding async/await: async all the way to the top!</p>
			<p>Asynchronous programming is imperative when dealing with devices outside the CPU. One of the areas where we need to use these techniques extensively is in the file system. However, file systems have a lot of other things that you need to know about. So, it’s great that the next chapter deals with that topic!</p>
		</div>
	</body></html>