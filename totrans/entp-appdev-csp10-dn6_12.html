<html><head></head><body>
		<div><h1 id="_idParaDest-165"><em class="italic"><a id="_idTextAnchor860"/>Chapter 9</em>: Working with Data in .NET 6</h1>
			<p>One of the essential components for any application is the ability to persist data to a permanent data store; some forethought in picking the right persistent store can help a system scale better in the future.</p>
			<p>One of the common operations in any application is to log in to the system, perform some reads/updates, log off, and then come back later to see whether the changes were retained. Databases play a significant<a id="_idIndexMarker688"/> role in persisting these actions, which are typically called <strong class="bold">user transactions</strong>. Apart from transactional data, for monitoring and debugging purposes, an application may additionally need to store logging data and auditing data, such as who modified the date. An important step for designing any such application is to understand the requirements and design the database accordingly. It's also important to choose/design a database according to various data retention requirements and any data protection policies, such as the <strong class="bold">General Data Protection Regulation</strong> (<strong class="bold">GDPR</strong>).</p>
			<p>There can be multiple data providers for an application, such as a <strong class="bold">Structured Query Language</strong> (<strong class="bold">SQL</strong>) data provider, NoSQL data provider, and file data provider. In this chapter, we will discuss various data providers that can be used for storage and data handling in .NET 6. We will cover the following topics:</p>
			<ul>
				<li>Introduction to data</li>
				<li>Disk, files, and directories</li>
				<li>SQL, Azure Cosmos DB, and Azure Storage</li>
				<li>Working with EF Core</li>
				<li>Designing a Data Access service using Azure Cosmos DB<a id="_idTextAnchor861"/><a id="_idTextAnchor862"/></li>
			</ul>
			<h1 id="_idParaDest-166"><a id="_idTextAnchor863"/>Technical requirements</h1>
			<p>A basic understanding of .NET Core, C#, Azure, and the .NET <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) is required.</p>
			<p>The code files for this chapter can be found at the following link: <a href="https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Chapter08">https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Chapter08</a>.</p>
			<p>The instructions for the code can be found here: <a href="https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application">https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application</a>.<a id="_idTextAnchor864"/><a id="_idTextAnchor865"/></p>
			<h1 id="_idParaDest-167"><a id="_idTextAnchor866"/>Introduction to data</h1>
			<p>Any web application, be it a content<a id="_idIndexMarker689"/> management system, social networking platform, or e-commerc<a id="_idTextAnchor867"/>e application, needs to persist data to a permanent store so that users can retrieve, consume, and process data as needed. In <a href="B18507_08_Epub.xhtml#_idTextAnchor714"><em class="italic">Chapter 8</em></a>, <em class="italic">All You Need to Know about Caching</em>, we discussed using cache stores; however, cache stores are temporary storage and data still needs to be persisted in permanent<a id="_idIndexMarker690"/> storage. So, we need a store that n<a id="_idTextAnchor868"/>ot only supports various <strong class="bold">Create/Read/Update/Delete</strong> (<strong class="bold">CRUD</strong>) operations on different entities but also supports high availability and recovers any data in case of an outage, that is, disaster recovery.</p>
			<p>One of the key criteria for better system design is to have a data model designed at an early stage of the system. The data model should try to define all the possible entities that are required for the system to function and interact between various entities. Having a data model defined early on in the system design helps in identifying the right strategies on how to manage data and what data store can be used, and in deciding various replication/partition strategies.</p>
			<p>Two commonly classified data stores are explained in the following section<a id="_idTextAnchor869"/><a id="_idTextAnchor870"/>s.</p>
			<h2 id="_idParaDest-168"><a id="_idTextAnchor871"/>Relational database management system (RDBMS)</h2>
			<p>Relational databases<a id="_idIndexMarker691"/> store data in tables. Each entity is defined as one or more tables an<a id="_idTextAnchor872"/>d a database is defined using multiple tables. The process of segregating tables<a id="_idIndexMarker692"/> into multiple tables is called <strong class="bold">normalization</strong>. The relat<a id="_idTextAnchor873"/>ions between various tables are defined by foreign key constraints. Properties of entities are defined as columns, and multiple entities of the same type are stored as rows. Some commonly used relational databases are Microsoft SQL Server, MySQL, PostgresSQL, and Oracle.</p>
			<p>A typical relational database<a id="_idIndexMarker693"/> to store employee information could possibly have an <code>employee</code> table defining various properties of employees, such as name, employee ID, and so on, and columns with employee ID as the primary key. Multiple employees are stored in separate rows in this table. Any properties of employees can further be normalized into a separate table; for example, an employee's projects can be stored in a separate table (as there can be more than one project), say, <code>employeeproject</code>, and can be linked to the <code>employee</code> table using the employee ID, as shown in the following diag<a id="_idTextAnchor874"/>ram:</p>
			<div><div><img src="img/Figure_9.1_18507.jpg" alt="Figure 9.1 – Employee ER diagram&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.1 – Employee ER diagram</p>
			<p>The follo<a id="_idTextAnchor875"/>wing are a few key characteris<a id="_idTextAnchor876"/>tics<a id="_idIndexMarker694"/> of the relational database:</p>
			<ul>
				<li>Relational databases are queried using SQL.</li>
				<li>Tables mostly have a well-defined schema and constraints and are less likely to change<a id="_idTextAnchor877"/>.</li>
				<li>All the transactions have <strong class="bold">Atomicity/Consistency/Isolation/Durability</strong> (<strong class="bold">ACID</strong>) properties, hence maintaining<a id="_idIndexMarker695"/> the data integrity and consistency.</li>
				<li>As data is normalized, redundancy<a id="_idIndexMarker696"/> is minimized.</li>
				<li>Rel<a id="_idTextAnchor878"/>ational databases usually support vertical scaling, that is, scaling up (they do support replication, but it is an expensive operation compared to replication in NoSQL data<a id="_idTextAnchor879"/><a id="_idTextAnchor880"/>bases).</li>
			</ul>
			<h2 id="_idParaDest-169"><a id="_idTextAnchor881"/>NoSQL</h2>
			<p>Another kind of data store is NoSQL databases, which store data<a id="_idIndexMarker697"/> in an unstructured form<a id="_idTextAnchor882"/>at where the data doesn't need to have a predefined schema. Most commonly, data is either stored as a key-value pair (such as in Redis), stored as a document (such as in MongoDB and CouchDB), or stored as a graph using a graph structure (for example, in Neo4j).</p>
			<p>If we take the same employee example and persist it in a NoSQL database, such as MongoDB, we will end up storing it in something such as an <code>employee</code> collection, with each document storing all the properties of the employee, as shown here:</p>
			<pre class="source-code">{</pre>
			<pre class="source-code">  "employee": [</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">      "employeeid": 1,</pre>
			<pre class="source-code">      "name": "Ravindra",</pre>
			<pre class="source-code">      "salary": 100,</pre>
			<pre class="source-code">      "Projects": [</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">          "id": 1,</pre>
			<pre class="source-code">                  "name": "project1",</pre>
			<pre class="source-code">        },</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">                     "id": 2,</pre>
			<pre class="source-code">                  "name": "project2",</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">      ]</pre>
			<pre class="source-code">    }</pre>
			<pre class="source-code">  ]</pre>
			<pre class="source-code">}</pre>
			<p>The f<a id="_idTextAnchor883"/>ollowing are a few key characteristics<a id="_idIndexMarker698"/> of NoSQL databases:</p>
			<ul>
				<li>Entities do not necessarily need to support a fixed schema and, at any point in time, additional properties can be added.</li>
				<li>They are a good fit for unstructured data, for example, storing the location in a ride-sharing app.</li>
				<li>They can easily support horizontal scaling at a much lower cost compared to relational databases.</li>
				<li>Data is highly redundant; however, that gives a significant performance boost, as data is readily available without performing joins across tables.</li>
			</ul>
			<p>Azure Cosmos <a id="_idTextAnchor884"/>DB is one such cloud-managed NoSQL database that we will use in our e-commerce application as a data store.</p>
			<p>Let's look at the various storage options in detail in the next<a id="_idTextAnchor885"/><a id="_idTextAnchor886"/><a id="_idTextAnchor887"/> section.</p>
			<h1 id="_idParaDest-170"><a id="_idTextAnchor888"/>SQL, Azure Cosmos DB, and Azure Storage</h1>
			<p>Earlier, we talked about the broader classification of data stores into RDBMSs and NoSQL. In this section, let's get into the details of some of the data providers available in the <a id="_idTextAnchor889"/>Microsoft ecosystem<a id="_idIndexMarker699"/> and their integration<a id="_idIndexMarker700"/> with .NET 6. There is a wide variety<a id="_idIndexMarker701"/> of providers, including SQL, Azure Cosmos DB, and Azure Storage, and t<a id="_idTextAnchor890"/>he selection of data providers is completely driven by the application needs. However, in real life, application requirements evolve quite a bit, so the key is to abstract your data framework implementation with the business layer and <strong class="bold">user interface</strong> (<strong class="bold">UI</strong>), which further helps in evolving the design as required. With that, let's look at our first data provider, SQL, in the n<a id="_idTextAnchor891"/><a id="_idTextAnchor892"/>ext section.</p>
			<h2 id="_idParaDest-171"><a id="_idTextAnchor893"/>SQL Server</h2>
			<p>One of the dominant databases in the RDBMS market is Microsoft SQL Server, popularly known as SQL Server<a id="_idTextAnchor894"/>, which uses SQL<a id="_idIndexMarker702"/> to interact with the database. SQL Server supports all the RDBMS-based entities, such as tables, views, stored procedures, and indexes, and primarily works on the Windows environment. However, from SQL Server 2017 onward, it supports both Windows and Linux environments.</p>
			<p>The primary component of SQL Server is its database engine, which takes care of processing queries and managing data in files. Apart from the database engine, SQL Server comes<a id="_idIndexMarker703"/> with various data management tools, such as the following:</p>
			<ul>
				<li><strong class="bold">SQL Server Management Studio</strong> (<strong class="bold">SSMS</strong>): To connect to SQL Serv<a id="_idTextAnchor895"/>er and perform operations<a id="_idIndexMarker704"/> such as creating a database, monitoring a database, querying databases, and backing up databases</li>
				<li><strong class="bold">SQL Server Integration Serv<a id="_idTextAnchor896"/>ice</strong> (<strong class="bold">SSIS</strong>): For data integration<a id="_idIndexMarker705"/> and transformation</li>
				<li><strong class="bold">SQL Server Analysis Serv<a id="_idTextAnchor897"/>ices</strong> (<strong class="bold">SSAS</strong>): For data<a id="_idIndexMarker706"/> analysis</li>
				<li><strong class="bold">SQL Server Reporting Ser<a id="_idTextAnchor898"/>vices</strong> (<strong class="bold">SSRS</strong>): For reporting and<a id="_idIndexMarker707"/> visualization</li>
			</ul>
			<p>To configure SQL Server on a local machine, we need to install<a id="_idIndexMarker708"/> one of the editions of SQL Server that installs the database engine and one or more preceding compo<a id="_idTextAnchor899"/>nents. Installation typically involves downloading the installer<a id="_idIndexMarker709"/> and installing it either through the <strong class="bold">graphical user interface</strong> (<strong class="bold">GUI</strong>) or command line. For more<a id="_idIndexMarker710"/> details on installation, refer to <a href="https://docs.microsoft.com/en-us/sql/database-engine/install-windows/install-sql-server?view=sql-server-ver15">https://docs.microsoft.com/en-us/sql/database-engine/install-windows/install-sql-server?view=sql-server-ver15</a>.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">There are also other editions of SQL Server such as the Developer edition and Express edition, which are lightweight<a id="_idIndexMarker711"/> and free and can be downloaded from <a href="https://www.microsoft.com/en-in/sql-server/sql-server-downloads">https://www.microsoft.com/en-in/sql-server/sql-server-downloads</a>.</p>
			<p>Although on-premises, SQL Server has been widely used; there is always overhead to managing datab<a id="_idTextAnchor901"/>ases, upgrades, and so on, and that's where Microsoft<a id="_idIndexMarker712"/> has come up with Azure SQL, which is a fully managed <strong class="bold">Platform as a Service</strong> (<strong class="bold">PaaS</strong>) component that runs on the same database engine as on-premises SQL Server.</p>
			<p>Azure SQL comes with the<a id="_idIndexMarker713"/> following variants:</p>
			<ul>
				<li><strong class="bold">Azure SQL Database (single database)</strong>: This is a mana<a id="_idTextAnchor902"/>ged database<a id="_idIndexMarker714"/> server that allows you to create a fully isolated database with dedicated resources.</li>
				<li><strong class="bold">Azure SQL Database (elastic pool)</strong>: Elastic pool allows you to run<a id="_idIndexMarker715"/> multiple single databases in a predefined pool of resources (in terms of CPU, memory, and <strong class="bold">input/output</strong> (<strong class="bold">I/O</strong>)) on a single server. It is ideal for businesses th<a id="_idTextAnchor903"/>at have multiple databases with a mix of low and high usage. The advantage of using an elastic pool in such situations is that a database that needs more CPU usage can utilize it during high demand and release it when demand is low. The ideal situation to use an elastic pool is when there is a set of databases and their consumption is unpredictable. Anytime you see a database<a id="_idIndexMarker716"/> consistently consuming the same set of resources, it can be moved out of the elastic pool into a single database and vice versa.</li>
				<li><strong class="bold">Azure SQL Managed Instance</strong>: This model provides a way for the seamless migration of on-premises SQL infrastructure<a id="_idIndexMarker717"/> to Azure<a id="_idTextAnchor904"/> SQL without re-architecting the on-premises<a id="_idIndexMarker718"/> applications and allows you to take advantage of PaaS. This is ideal for applications that have huge on-premises database infrastructure and need to migrate to the cloud without too much operational overhead.</li>
				<li><strong class="bold">SQL Server o<a id="_idTextAnchor905"/>n VM (Windows/Linux)</strong>: SQL VMs come under the <strong class="bold">Infrastructure as a Service<a id="_idTextAnchor906"/></strong> (<strong class="bold">IaaS</strong>) category and are very similar<a id="_idIndexMarker719"/> to on-premises SQL Server, except<a id="_idIndexMarker720"/> that VMs are on Azure instead of your local network.<p class="callout-heading">Tip</p><p class="callout">It's recommended to install SSMS<a id="_idIndexMarker721"/> for performing various operations on SQL Server (on-premises or the cloud), as it supports all the database operations. There is also Azure Data Studio, which is lightweight and can connect to on-premise or cloud SQL<a id="_idIndexMarker722"/> Server and can be downloaded from <a href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver15">https://docs.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver15</a>.</p></li>
			</ul>
			<p>From a .NET 6 application<a id="_idIndexMarker723"/> standpoint, connecting to Azure SQL is the same as connecting to on-premises SQL Server. You can use ADO.NET, which we import using <code>System.Data.SqlClient</code> and then use the <code>SqlConnection</code> object to connect to SQL; then, use the <code>SqlCommand</code> object to execute the SQL query and the <code>SQLReader</code> class to return<a id="_idIndexMarker724"/> the values. Apart from this, we can use an <strong class="bold">object-relational mapping</strong> (<strong class="bold">ORM</strong>) such as <strong class="bold">Entity Framework Core</strong> (<strong class="bold">EF Core</strong>) to work with Azure SQL, which<a id="_idIndexMarker725"/> is discussed in the <em class="italic">Worki<a id="_idTextAnchor908"/>ng with EF Core</em> section.</p>
			<p>So, in this se<a id="_idTextAnchor909"/>ction, we have briefly covered Azure SQL. <a id="_idTextAnchor910"/>However, I would recommend reviewing<a id="_idIndexMarker726"/> all the functionality of Azure SQL here: <a href="https://docs.microsoft.com/en-us/azure/azure-sql/">https://docs.microsoft.com/en-us/azure/azure-sql/</a>. For more samples please refer to <a href="https://github.com/microsoft/sql-server-samples">https://github.com/microsoft/sql-server-samples</a>.</p>
			<p>With this, let's move on to Azure Cosmos DB, the database our e-commerce applic<a id="_idTextAnchor911"/><a id="_idTextAnchor912"/>ation will use as a persistent store.</p>
			<h2 id="_idParaDest-172"><a id="_idTextAnchor913"/>Azure Cosmos DB</h2>
			<p>Azure Cosmos DB is a fully managed (PaaS) NoSQL, globally<a id="_idIndexMarker727"/> distributed, and highly scalable database. One of the key things about Azure Cosmos DB is<a id="_idTextAnchor914"/> its multi-modeled nature, which helps in passing data in various formats, such as JSON and BSON, using different API models, such as SQL, MongoDB, and Gremlin. Developers have the flexibility to query the database using the API they are comfortable with. For example, SQL developers can continue to query the database using SQL query syntax, MongoDB developers can continue to query the database using MongoDB syntax, and so on. Under the hood, Azure Cosmos DB <a id="_idIndexMarker728"/>stores the database in a format known as <strong class="bold">atom-record-sequence</strong> (<strong class="bold">AR<a id="_idTextAnchor915"/>S</strong>) and exposes data as an API depending on the mode selected during the creation of the database.</p>
			<p>Another important thing about Azure Cosmos DB is its capability to automatically index all the data, independent of the API model that is used. All this happens without developers additionally creating an index, so enabling the faster retrieval of data.</p>
			<p>Azure Cosmos DB supports the following APIs<a id="_idIndexMarker729"/> to perform operations on the database, which we choose while creating the database:</p>
			<ul>
				<li><code>SELECT * FROM product WHERE product.Name = ' Mastering enterprise application development Book'</code>.</li>
				<li><code>db.product.find({"Name": ' Mastering enterprise application development Book'})</code>. Just like MongoDB, data is represented in BSON.</li>
				<li><strong class="bold">Gremlin (graph) API</strong>: This API supports <a id="_idIndexMarker733"/>usin<a id="_idTextAnchor918"/>g the Gremlin language<a id="_idIndexMarker734"/> to query and traverse data in graph format. This is ideal for situations where data can be represented in the form of a graph and can be queried through their relationships. A typical example can be a recommendation engine that can establish the relationship between two entities and come up with a recommendation.</li>
			</ul>
			<p>Apart from these, there is the Cassandra API, which uses the <strong class="bold">Cassandra Query Language</strong> (<strong class="bold">CQL</strong>) to operate on databases, and then the Table<a id="_idIndexMarker735"/> API, which can be used by applications built on top of Azure Table storage <a id="_idTextAnchor919"/>as their data store.</p>
			<p>As you can see, there are quite<a id="_idIndexMarker736"/> a number of APIs and more are getting added. Choosing the right API depends purely on the application requirements; however, the following few points can be used to narrow down the choice:</p>
			<ul>
				<li>If it's a new application, go with the Core (SQL) API.</li>
				<li>If it's an existing application built on NoSQL, choose the relevant API based on the underlying data store. For example, if the existing database is MongoDB, choose the Mongo API, and so on.</li>
				<li>For handling a specific scenario, such as establishing relationships between data, go with the Gremlin API.</li>
			</ul>
			<p>For our enterprise application, since we are building this application from scratch, we will go with the Core (SQL) API as our API<a id="_idTextAnchor920"/> to interact with Azure Cosmos DB.</p>
			<p>Let's create a simple console application<a id="_idIndexMarker737"/> to start with and perform a few operations on Azure Cosmos DB, and we will later reuse these concepts in building our Data Access service:</p>
			<ol>
				<li>To start with, we need to have an Azure Cosmos DB account, so sign in to the Azure portal, click <strong class="bold">Create resource</strong>, and select <strong class="bold">Databases</strong> | <strong class="bold">Azure Cosmos DB</strong>.</li>
				<li>This will open the <strong class="bold">Create Azure Cosmos DB Account</strong> page. Fill in the details as shown in the following screenshot and click <strong class="bold">Review + create</strong>. This is the page where we select the API we want to c<a id="_idTextAnchor921"/>hoose, which is the Core (SQL) API in our case:</li>
			</ol>
			<div><div><img src="img/Figure_9.2_18507.jpg" alt="Figure 9.2 – Create Azure Cosmos DB Account page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure<a id="_idTextAnchor922"/> 9.2 – Create Azure Cosmos DB Account page</p>
			<ol>
				<li value="3">O<a id="_idTextAnchor923"/>nce the account<a id="_idIndexMarker738"/> is created, navigate to <strong class="bold">Azure Cosmos DB Account</strong> | <strong class="bold">Keys</strong>. Copy the <strong class="bold">URI</strong> and <strong class="bold">PRIMARY KEY</strong> values.</li>
				<li>Open the command line and create a console application by using the following command:<pre><strong class="bold">dotnet new console --framework net6.0 --name EcommerceSample</strong></pre></li>
				<li>Navigate to the <code>EcommerceSample</code> folder and install<a id="_idIndexMarker739"/> the Azure Cosmos DB SDK using the following command:<pre><strong class="bold">dotnet add package Microsoft.Azure.Cosmos -s https://api.nuget.org/v3/index.json</strong></pre></li>
				<li>At this stage, we can open the folder in VS Code. Once we open the folder in VS Code, it will look as shown in the following screenshot:</li>
			</ol>
			<div><div><img src="img/Figure_9.3_18507.jpg" alt="Figure 9.3 – EcommerceSample in VS Code &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.3 – EcommerceSample in VS Code </p>
			<ol>
				<li value="7">Open <code>Program.cs</code> and add the following static variables to the <code>Program</code> class that will hold the <strong class="bold">URI</strong> and <strong class="bold">PRIMARY KEY</strong> values that were copied in <em class="italic">Step 3</em>:<pre><strong class="bold">string Uri = "YOUR URI HERE ";</strong>
<strong class="bold">string PrimaryKey = "YOUR PRIMARY KEY HERE";</strong></pre></li>
				<li>Now, let's add code to create an object of the <code>CosmosClient</code> class and use that to create an Azure Cosmos<a id="_idIndexMarker740"/> DB da<a id="_idTextAnchor924"/>tabase. Subsequently, this object will be used to communicate with our Azure Cosmos DB database. As <code>CosmosClient</code> implements <code>IDisposable</code>, we will create it inside a <code>using</code> block so that the object can be disposed of automatically after the <code>using</code> block. Once you run this code and navigate to <code>Ecommerce</code> will be created. As we have created our Azure Cosmos DB account using the Core (SQL) API, this database will support querying in SQL syntax:<pre><strong class="bold">using (CosmosClient cosmosClient = new CosmosClient(Uri,</strong>
<strong class="bold"> PrimaryKey))</strong>
<strong class="bold">{</strong>
<strong class="bold"> DatabaseResponse createDatabaseResponse</strong>
<strong class="bold">= await cosmosClient.CreateDatabaseIfNotExistsAsync</strong>
<strong class="bold">("ECommerce");</strong>
<strong class="bold"> Database database = createDatabaseResponse.Database;</strong>
<strong class="bold">}</strong></pre></li>
				<li>Now, let's create a container that is analogous to a table in SQL by adding the following code after <code>createDatabaseResponse</code>. As we are using <code>CreateDatabaseIfNotExistsAsync</code> to create the database, running the same code will not cause any exceptions:<pre><strong class="bold">var containerProperties = new ContainerProperties</strong>
<strong class="bold">("Products", "/Name");</strong>
<strong class="bold">var createContainerResponse</strong><strong class="bold"> = await </strong>
<strong class="bold">database.CreateContainerIfNotExistsAsync(</strong>
<strong class="bold">containerProperties, 10000); </strong>
<strong class="bold">var productContainer = createContainerResponse.</strong>
<strong class="bold">Containe<a id="_idTextAnchor925"/>r;</strong></pre></li>
			</ol>
			<p>Once we run this code, we can see in the Azure portal<a id="_idIndexMarker741"/> that a container with the name <code>Products</code> is created under the <code>Ecommerce</code> database:</p>
			<div><div><img src="img/Figure_9.4_18507.jpg" alt="Figure 9.4 – Products container &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.4 – Products container </p>
			<p>A container is a unit in Azure Cosmos DB that is horizontally partitioned and replicated across multiple regions. In the preceding code, we have passed <code>ContainerProperties</code> while creating a container, and you can see that one of the values is <code>Name</code>, which is nothing but a partition key.</p>
			<p>Partitioning is one of the key features of Azure Cosmo<a id="_idTextAnchor926"/>s DB that segregates data within a container into multiple logical partitions based on the partition key, that is, all the items with the same partition key are part of the same logical partition. Using a partition key, Azure Cosmos DB achieves horizontal scaling of the database, therefore, satisfying the scalability and performance needs of the application. </p>
			<p>Choosing a partition key is a key design decision, as it will significantly help the database to scale and better perform. Also, the partition key cannot be changed and has to be defined during the creation of the container. The following few points can be kept in mind when choosing the partition key:</p>
			<ul>
				<li>It should have a maximum number of unique values; the higher the number of unique values, the better the partitioning<a id="_idIndexMarker742"/> will be. For example, if we are creating a container for products, the product ID or name could be the partition key as these two attributes can uniquely identify most products. Under the hood, if a product name is chosen for the partition key and there are 100 products internally, it is represented by 100 logical containers in Azure Cosmos DB. Here, the product category can also be a partition key but, before choosing that as the partition key, we need to evaluate the sample data and decide based on the requirements.</li>
				<li>If there is no obvious unique choice, we can pick the most used field in the filtering query, so basically, a column that is very often used in the <code>where</code> clause.<p class="callout-heading">Tip</p><p class="callout">In real-world applications, the creation o<a id="_idTextAnchor927"/>f an Azure Cosmos DB account should be implemented using ARM templates or using Terraform<a id="_idIndexMarker743"/> so that templates can be easily integrated wi<a id="_idTextAnchor928"/>th <strong class="bold">continuous deployment</strong> (<strong class="bold">CD</strong>).</p></li>
			</ul>
			<p>With this, let's add some data<a id="_idIndexMarker744"/> to our product container<a id="_idIndexMarker745"/> and query it:</p>
			<ol>
				<li value="1">We will add this entity based on the following sample JSON. Based on the product category, there could be different attributes.</li>
			</ol>
			<p>For example, if the product category is <code>Books</code>, there would be values in fields such as <code>Authors</code> and <code>Format</code>; however, if the category is <code>Clothing</code>, there would be values for fields such as <code>Size</code> and <code>Color</code>. This schema could be reused in our e-commerce application:</p>
			<pre>{
  "Id": "Book.1",
  "Name": "Mastering enterprise application
      development Book",
  "Category": "Books",
  "Price": 100,
  "Quantity": 100,
  "CreatedDate": "20-02-2020T00:00:00Z",
  "ImageUrls": [],
  "Rating": [
    {"Stars": 5, "Percentage": 95},
    {"Stars": 4, "Percentage": 5}
  ],
  "Format": ["PDF","Hard Cover"],
  "Authors": ["Rishabh Verma","Neha Shrivastava",
      "Ravindra Akela","Bhupe<a id="_idTextAnchor929"/>sh Guptha"],
  "Size": [],
  "Color": []
}</pre>
			<ol>
				<li value="2">Now, let's create <code>Product</code>. On<a id="_idTextAnchor930"/>e of the mandatory fields for any entity in Azure Cosmos DB with the Core (SQL) API is the <code>id</code> field, which is something like a primary key. So, it is necessary for our parent models to define the <code>id</code> field. These classes would look like the following:<pre>public class Rating{
    public int Stars { get; set; }
    public int Percentage { get; set; }
}
public class Product{
    [JsonProperty(PropertyName = "id")]
    public string ProductId { get; set; }
    public string Name { get; set; }
    public string Category { get; set; }
    public int Price { get; set; }
    public int Quantity { get; set; }
    public DateTime CreatedDate { get; set; }
    public List&lt;string&gt;  ImageUrls { get; set; }
    public List&lt;Rating&gt; Rating { get; set; }
    public List&lt;string&gt; Format { get; set; }
    public List&lt;string&gt; Authors { get; set; }
    public List&lt;int&gt; Size { get; set; }
<a id="_idTextAnchor931"/>    public List&lt;string&gt; Color { get; set; }
}</pre></li>
				<li>Now, let's create the following<a id="_idIndexMarker749"/> object of the <code>Product</code> class<a id="_idIndexMarker750"/> and insert it into the database:<pre>Product book = new Product()
{
    ProductId = "Book.1", Category = "Books", Price =
    100,
    Name = "Mastering enterprise application
    development Book",                    
    Rating = new List&lt;Rating&gt;() { new Rating { Stars =
    5, Percentage = 95 }, new Rating { Stars = 4,
    Percentage = 5 } },
    Format = new List&lt;string&gt;() { "PDF", "Hard Cover" 
    },
    Authors = new List&lt;string&gt;() { "Suneel", "Arun", 
      "Ravindra", "Bhupesh" }
};</pre></li>
				<li>Now, we will call the <code>CreateItemAsync</code> method using the <code>productContainer</code> object, as shown<a id="_idIndexMarker751"/> in the following <a id="_idIndexMarker752"/>code snippet. (There are other ways to retrieve records from the database, one of which is shown in the next point.) Also, we should ensure that an object with the same <code>ProductId</code> value isn't already present:<pre>try
{
    // Check if item it exists.  
    ItemResponse&lt;Product&gt; productBookResponse = await 
      productContainer.ReadItemAsync&lt;Product&gt;(
      book.ProductId, new PartitionKey(book.Name));
}
catch (CosmosException ex) when (ex.StatusCode == System.Net.HttpStatusCode.NotFound)
{
    ItemResponse&lt;Product&gt; productBookResponse = await 
      productContainer.CreateItemAsync&lt;Product&gt;(book, 
      new PartitionKey(book.Name));
    Console.WriteLine($"Created item <a id="_idTextAnchor932"/>
      {productBookResponse.Resource.ProductId}");
}</pre></li>
			</ol>
			<p>Once we run this code, data <a id="_idIndexMarker753"/>should be inserted<a id="_idIndexMarker754"/> into the <code>Ecommerce</code> database under the <code>Products</code> container.</p>
			<ol>
				<li value="5">If we want to query this record other than the way mentioned in the previous point, we can use the following code to query the database. As you can see, the syntax is very similar to querying data from a SQL database:<pre>string getAllProductsByBooksCAtegory = "SELECT * FROM p WHERE p.Category = 'Books'";
QueryDefinition query = new QueryDefinition(getAllProductsByBooksCAtegory);
FeedIterator&lt;Product&gt; iterator = productContainer.GetItemQueryIterator&lt;Product&gt;(query);
while (iterator.HasMoreResults)
{
    FeedResponse&lt;Product&gt; result = await 
      iterator.ReadNextAsync();
    foreach (Product product in result)
    {
        Console.WriteLine($"Book retrived –
        {product.Name}");
    }
}</pre></li>
			</ol>
			<p>Similarly, <code>ContainerClass</code> provides<a id="_idIndexMarker755"/> all the relevant methods that can be used for various CRUD operations. All those APIs can be found here: <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.container?view=azure-dotnet">https://docs.microsoft.com/en-us/dotnet/api/microsoft.azure.cosmos.container?view=azure-dotnet</a>.</p>
			<p>With this foundation, we wil<a id="_idTextAnchor933"/>l design<a id="_idIndexMarker756"/> the data model required for our e-commerce<a id="_idIndexMarker757"/> application and the relevant data service layer to be consumed by various APIs. Up to now, we have seen SQL and NoSQL<a id="_idTextAnchor934"/><a id="_idTextAnchor935"/> providers. Let's see what other options<a id="_idTextAnchor936"/> we have to persist data.</p>
			<h2 id="_idParaDest-173"><a id="_idTextAnchor937"/>Azure Storage</h2>
			<p>Azure Storage is a highly available and scalable<a id="_idIndexMarker758"/> data store that supports storing data in various formats, including files. Primarily, Azure Stora<a id="_idTextAnchor938"/>ge supports the following four types<a id="_idIndexMarker759"/> of data:</p>
			<ul>
				<li><strong class="bold">Azure Table</strong>: A NoSQL impleme<a id="_idTextAnchor939"/>ntation<a id="_idIndexMarker760"/> that supports persisting schemaless data.</li>
				<li><strong class="bold">Azure Blob</strong>: Blobs are unstructured <a id="_idIndexMarker761"/>data that are suitable for applications that<a id="_idTextAnchor940"/> have lots of files to upload, download, or stream.</li>
				<li><strong class="bold">Azure Queue</strong>: This allows you to queue<a id="_idIndexMarker762"/> a message in any serializable format and can then be processed by a service. Queues are ideal for scenarios that have lots of service-to-service communication and <a id="_idTextAnchor941"/>act as a p<a id="_idTextAnchor942"/>ersistent layer for messages.</li>
				<li><strong class="bold">Azure Files/Azure Disk</strong>: A data store for files<a id="_idIndexMarker763"/> and ideal for systems that are built on native file APIs.</li>
			</ul>
			<p>The following are a few points that make Azure Storage one of the important components of application development:</p>
			<ul>
				<li><strong class="bold">High availability</strong>: Da<a id="_idTextAnchor943"/>ta stored in Azure Storage<a id="_idIndexMarker764"/> gives out-of-the-box support for replication across data centers/regions, which further ensures that hardware failure in one region doesn't result in losing<a id="_idIndexMarker765"/> data.</li>
				<li><strong class="bold">Performance</strong>: Out-of-the-box support<a id="_idIndexMarker766"/> for CDN integration that helps to cache and load data (esp<a id="_idTextAnchor944"/>ecially static files) from locations (edge servers) closer to the user and further improves the performance. In addition to this, the storage type can be upgraded to premium storage, which takes advantage of SSDs to <a id="_idTextAnchor945"/>further speed up disk I/O and improve performance.</li>
				<li><strong class="bold">Fully managed</strong>: Hardwar<a id="_idTextAnchor946"/>e is fully managed by Azure for any<a id="_idIndexMarker767"/> updates/maintenance.</li>
				<li><strong class="bold">Security</strong>: All the data stored<a id="_idIndexMarker768"/> on disks is encrypted and access to the data in Azure Storage fur<a id="_idTextAnchor947"/>ther supports private, public, and anonymous modes.</li>
				<li><strong class="bold">Pay as you go</strong>: Just like all other Azure services, Azure Storage also supports a pay-as-you-go model based<a id="_idIndexMarker769"/> on the size of the data/operations.</li>
			</ul>
			<h3>Azure Storage accounts</h3>
			<p>Let's <a id="_idTextAnchor948"/>create a simple console application that uploads a file to Blob and downloads the file from Blob. To communicate<a id="_idIndexMarker770"/> with Azure Storage services, the prerequisite is to create an Azure Storage account that provides access to all Azure Storage services and gives us access to the data stored in Azure Storage over HTTP/HTTPS by a unique namespace to Azure Storage. To create an Azure Storage account, take the following steps:</p>
			<ol>
				<li value="1">Sign in to the Azure portal, click <strong class="bold">Create resource</strong>, and select <strong class="bold">Storage Account</strong>. This will open the <strong class="bold">Create storage account</strong> page. Fill i<a id="_idTextAnchor949"/>n the details as shown in the following screenshot and click <strong class="bold">Review + create</strong>:</li>
			</ol>
			<div><div><img src="img/Figure_9.5_18507.jpg" alt="Figure 9.5 – Creating an Azure Storage account&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.5 – Creating an Az<a id="_idTextAnchor950"/>ure Storage account</p>
			<p>There are two important properties<a id="_idIndexMarker771"/> <strong class="bold">Account Kind</strong> and <strong class="bold">Replication</strong> for Standard tier. For <strong class="bold">Account Kind</strong><strong class="bold">,</strong> we have the following possible values:</p>
			<ul>
				<li><strong class="bold">StorageV2 (general purpose v2)</strong>: The latest version of the account type, which gives access to all storage types, such as files, blobs, and queues. This is preferable for newly created storage accounts.</li>
				<li><strong class="bold">Storage (general purpose v1)</strong>: An older version of the account type, which gives access to all storage types, such as files, blobs, and queues.</li>
				<li><strong class="bold">BlobStorage</strong>: An account type that only supports blob storage.</li>
			</ul>
			<p>The other is <strong class="bold">Replication</strong>, which supports replication of the storage data across<a id="_idTextAnchor951"/> data centers/regions. Possible values<a id="_idIndexMarker772"/> are shown in the following scree<a id="_idTextAnchor952"/>nshot:</p>
			<div><div><img src="img/Figure_9.6_18507.jpg" alt="Figure 9.6 – Replication options in an Azure Storage account&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.6 – Replication options in an Azure Storage account</p>
			<ol>
				<li value="2">Once the account is created, navigate to <strong class="bold">Storage Account</strong> | <strong class="bold">Keys</strong>. Copy the <strong class="bold">Connection String</strong> value.</li>
				<li>Create a new .NET 6 console application and install the <code>Azure.Storage.Blobs</code> NuGet package.</li>
				<li>To upload content to Azure Storage, we need to first create a container. We will make use of the <code>Azure.Storage.Blobs.BlobContainerClient</code> class and its <code>CreateIfNotExistsAsync</code> method to create the container if it doesn't exist. With this, update the <code>Program</code> class, as shown in the following code snippet:<pre>   string connectionString = «CONNECTION_STRING";
   string containerName = «fileuploadsample";
   string blobFileName = «sample.png";
   // Upload file to blob            
   BlobContainerClient containerClient = new 
   BlobContainerClient(connectionString, 
   containerName);
   await containerClient.CreateIfNotExistsAsync(
     PublicAccessType.None);//Making blob private.</pre></li>
				<li>Next, we need to upload<a id="_idIndexMarker773"/> the file to the container for which we will make use of <code>Azure.Storage.Blobs.BlobClient</code>, which takes the connection string, container name, and blob name as input parameters. For this sample, we are uploading a local <code>sample.png</code> file to the blob, which we will read using the <code>FileStream</code> class, and pass it to the <code>UploadAsync</code> method of the <code>Azure.Storage.Blobs.BlobClient</code> class. Add the following code snippet after container creation in the <code>Main</code> method:<pre>BlobClient blobClient = new BlobClient(connectionString, 
containerName, blobFileName);
using FileStream fileStream = File.OpenRead(blobFileName); // blobFileName is relative path of the file.
await blobClient.UploadAsync(fileStream, true);
fileS<a id="_idTextAnchor953"/>tream.Close();
Console.WriteLine(blobClient.Uri.ToString());</pre></li>
			</ol>
			<p>Running the sample at this stage will upload the file to the blob and display t<a id="_idTextAnchor954"/>he blob URL in the command line. However, if we try to access the URL, it won't be accessible as the blob created is private. To access private<a id="_idIndexMarker774"/> blobs, we need to generate a <code>Main</code> method:</p>
			<pre>BlobSasBuilder sasBuilder = new BlobSasBuilder()
{
    BlobContainerName = containerClient.Name,
    Resource = "b", // c for container
    BlobName = blobClient.Name
};
sasBuilder.ExpiresOn = DateTimeOffset.UtcNow.AddHours(1); // Setting expiry time of the SAS link to 1 hour
sasBuilder.SetPermissions(BlobContainerSasPermissions.Read);
if (blobClient.CanGenerateSasUri)
{
    Uri blobSasUri = 
      blobClient.GenerateSasUri(sasBuilder);
<a id="_idTextAnchor955"/>    Console.WriteLine(blobSasUri.ToString());
}
Console.ReadLine();</pre>
			<p>Here, we are using the <code>Azure.Storage.Sas.BlobSasBuilder</code> class to configure various parameters, such as permissions<a id="_idIndexMarker775"/> and the expiry time, to generate a SAS URI for the uploaded f<a id="_idTextAnchor956"/>ile. Finally, the output of the preceding code is shown in the followin<a id="_idTextAnchor957"/>g figure:</p>
			<div><div><img src="img/Figure_9.7_18507.jpg" alt="Figure 9.7 – Blob upload output and Storage Explorer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.7 – Blob upload output and Storage Explorer</p>
			<p>This is a small sample that makes<a id="_idIndexMarker776"/> use of Azure Storage for a file upload. This can be further enhanced as an API, which can eventually be used for file upload and download scenarios. For our e-commerce appli<a id="_idTextAnchor958"/>cation, we will use Azure Blob to store the images of the products.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">For more advanced concepts on Azure Storage<a id="_idIndexMarker777"/> and samples, refer to the following links:</p>
			<p class="callout"><a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview">https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview</a></p>
			<p class="callout"><a href="https://github.com/Azure/azure-sdk-for-net/tree/master/sdk/storage/Azure.Storage.Blobs/samples">https://github.com/Azure/azure-sdk-for-net/tree/master/sdk/storage/Azure.Storage.Blobs/samples</a></p>
			<p>In this section, we have discussed various data providers available in .NET 6. However, one important library that simpl<a id="_idTextAnchor960"/><a id="_idTextAnchor961"/>ifies persisting data is EF. Let's see how to integrate EF in .NET 6 applications.</p>
			<h1 id="_idParaDest-174"><a id="_idTextAnchor962"/>Working with EF Core</h1>
			<p>EF Core is an<a id="_idTextAnchor963"/> ORM that is recommended for any<a id="_idIndexMarker778"/> ASP.NET Core 6 application that uses a relational database<a id="_idIndexMarker779"/> as the data store. Earlier, we saw how in ADO.NET, we must create <code>Connection</code>, <code>Command</code>, and <code>Reader</code> objects. EF simplifies this process by providing abstraction and allowing developers to write application code, and like any other ORM, EF helps in performing various operations on databases using the object model paradigm.</p>
			<p>Configuring EF Core is as simple as installing the required NuGet packages, injecting the required services in the <code>Program</code> class, and then using them wherever required. As part of this process, one of the key classes that needs to be defined is the database context, and that needs to inherit the <code>Microsoft.EntityFrameworkCore.DbCon<a id="_idTextAnchor964"/><a id="_idTextAnchor965"/>text</code> class. Let's see how we do that along with the remaining EF Core configuration.</p>
			<h2 id="_idParaDest-175"><a id="_idTextAnchor966"/>Configuration and querying</h2>
			<p>The <code>DbContext</code> cl<a id="_idTextAnchor967"/>ass in EF Core holds <a id="_idIndexMarker780"/>all th<a id="_idTextAnchor968"/>e required abstraction for our application to communicate<a id="_idIndexMarker781"/> with the database, so a key setup that needs to be part of integrating EF Core is to define our application-specific context class. This class will primarily hold all the SQL tables/views in the form of public property of the <code>DbSet</code> type, as shown in the following code:</p>
			<pre class="source-code">public virtual DbSet&lt;Employee&gt; Employees { get; set; }</pre>
			<p>Here, <code>Employee</code> is the POCO class representing tables in our database. The application context class should have the parameterized constructor that accepts <code>DbContextOptions</code> or <code>DbContextOptions&lt;T&gt;</code> and passes it to the base class.</p>
			<p>Let's create a simple web application based on Razor Pages and SQLite, and read data using EF Core. For this sample, we will take a simple empl<a id="_idTextAnchor969"/>oyee database that holds employee details with the fol<a id="_idTextAnchor970"/>lowing data model usin<a id="_idTextAnchor971"/>g SQLite:</p>
			<div><div><img src="img/Figure_9.8_18507.jpg" alt="Figure 9.8 – Employee database model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.8 – Employee database model</p>
			<p>If you haven't worked in Razor Pages<a id="_idIndexMarker782"/> before, do not worry about that; it's a page-based framework<a id="_idIndexMarker783"/> that can be used to build data-driven applications in ASP.NET Core 6 and is covered in <a href="B18507_11_Epub.xhtml#_idTextAnchor1228"><em class="italic">Chapter 11</em></a>, <em class="italic">Creating an ASP.NET Core 6 Web Application</em>.</p>
			<p>Now, let's now create our application as mentioned in the following steps:</p>
			<ol>
				<li value="1">Create a new Razor Pages application using the following command from the command line, which will create a new Razor Pages application inside the <code>EmployeeEF</code> folder:<pre><strong class="bold">dotnet new webapp --framework net6.0 --name EmployeeEF</strong></pre></li>
				<li>Navigate to the <code>EmployeeEF</code> folder and open it in Visual Studio Code, and then install the following NuGet packages:<ul><li><code>Microsoft.EntityFrameworkCore.Sqlite</code></li><li><code>Microsoft.EntityFrameworkCore.Design</code></li></ul></li>
			</ol>
			<p>The former package is the EF Core provider for SQLite and the latter one is to be used to create a database based on C# POCOs using EF Core migrations.</p>
			<ol>
				<li value="3">Now, add the <code>Models</code> folder and add the necessary POCO classes as follows. These classes represent the database schema from <em class="italic">Figure 9.8</em>:<pre>    public class Address
    {
     public int AddressId { get; set; }
     public int EmployeeId { get; set; }
     public string City { get; set; }
     public Employee Employee { get; set; }
    }
    public class Employee
    {
     public int EmployeeId { get; set; }
     public string Name { get; set; }
     public string Email { ge<a id="_idTextAnchor972"/>t; set; }
     public IC<a id="_idTextAnchor973"/>ollection&lt;Address&gt; Address { get; set; }
    }   </pre></li>
				<li>Here, all the columns<a id="_idIndexMarker784"/> in the database table are represented as a property<a id="_idIndexMarker785"/> with relevant data types. For relationships such as a foreign key, a property<a id="_idIndexMarker786"/> of the child type is created (known as <code>ICollection</code>, while another property of the parent class type is created in the child class. For example, in the preceding code, this is represented in the <code>public Icollection&lt;Address&gt; Addresses</code> and <code>public Employee Employee</code> properties, which define the foreign key constraint between the <code>Employee</code> and <code>Address</code> tables. Any property named <code>ID</code> or <code>&lt;class name&gt;ID (EmployeeID)</code> is automatically considered a primary key. Constraints can be further defined using the Fluent API during <code>OnModelCreating</code> or us<a id="_idTextAnchor974"/>ing annotations in <code>System.ComponentModel.DataAnnotations</code>. For more examples and de<a id="_idTextAnchor975"/>tails<a id="_idIndexMarker787"/> on model creation, refer to <a href="https://docs.microsoft.com/en-us/ef/core/modeling">https://docs.microsoft.com/en-us/ef/core/modeling</a>.</li>
				<li>Add a class <a id="_idTextAnchor976"/>that inherits from <code>Microsoft.EntityFrameworkCore.DbContext</code> and name it <code>EmployeeContext</code>. Add the following code that defines our database context:<pre>    public class EmployeeContext : DbContext
    {
        public DbSet&lt;Employee&gt; Employees { get; set;}
        public DbSet&lt;Address&gt; Addresses { get; set;}
         public EmployeeContext (DbContextOptions
         &lt;EmployeeContext&gt; options)
            : base(options)
        {}
        protected override void OnModelCreating
        (ModelBuilder modelBuilder)
        {
            modelBuilder.Entity&lt;Employee&gt;().ToTable
            ("Employee");
            modelBuilder.Entity&lt;Address&gt;().ToTable
            ("Address");
      <a id="_idTextAnchor977"/>  }
    }</pre></li>
				<li>Add the connect<a id="_idTextAnchor978"/>ion<a id="_idIndexMarker788"/> string in <code>appsettings.json</code>. As we are using SQLite, specifying<a id="_idIndexMarker789"/> the filename in the data source should be good enough. However, this will change as per the provider:<pre>  "ConnectionStrings": {
    "EmployeeContext": "Data Source=Employee.db"
  }</pre></li>
				<li>Now, inject the database context class in the <code>Program</code> class so that it is available across the application. Here, we additionally pass connection<a id="_idIndexMarker790"/> strings and configure any additional options<a id="_idIndexMarker791"/> such as a retry policy and query logging:<pre>builder.Services.AddDbContext&lt;EmployeeContext&gt;(options =&gt;
{ 
 options.UseSqlite(builder.Configuration.GetConnectionString("EmployeeContext"));
});</pre></li>
			</ol>
			<p>We are almost done with the EF Core setup. So now, let's create some sample data that can be used to seed the da<a id="_idTextAnchor979"/>tabase.</p>
			<ol>
				<li value="8">For that, we will create an extension method on our database context and call it during startup. Cr<a id="_idTextAnchor980"/>eate a <code>DbContextExtension</code> static class and add the following code to it. This code does nothing but add a few records to the database:<pre>    public static void SeedData(this EmployeeContext
    context)
    {
        SeedEmployees(context);            
    }
    private static void SeedEmployees(EmployeeContext
    context)
    {
        if (context.Employees.Any())
        {
            return;
        }
        var employees = new Employee[]
        {
            new Employee{EmployeeId = 1, Name =
            "Sample1", Email="Sample@sample.com"},
            new Employee{EmployeeId = 2, Name =
            "Sample2", Email="Sample2@sample.com"},
            new Employee{EmployeeId = 3, Name =
            "Sample3", Email="Sample3@sample.com"}
         };
        context.Employees.AddRange(employees);
        var adresses = new Address[]
        {
         new Address{AddressId = 1, City = "City1",
         EmployeeId = 1},
         new Address{AddressId = 2, City = "City2",
         EmployeeId = 1},
         new Address{AddressId = 3, City = "City1",
         EmployeeId = 2},
        };
        context.Addresses.AddRange(adresses);
  <a id="_idTextAnchor981"/>      context.SaveChange<a id="_idTextAnchor982"/>s();
    }</pre></li>
				<li>Open the <code>Program</code> class and add<a id="_idIndexMarker792"/> the following code<a id="_idIndexMarker793"/> that seeds data during application startup. Since this is for a development environment, we can check whether the environment is a development one and add it. As we are checking<a id="_idIndexMarker794"/> what's on the employee table before inserting, multiple runs<a id="_idIndexMarker795"/> of the application will not overwrite the data:<pre>using (var serviceScope = ((IApplicationBuilder)app).ApplicationServices?.GetService&lt;IServiceScopeFactory&gt;()?.CreateScope())
    {
      using (var context = 
        serviceScope?.ServiceProvider
        .GetRequiredService&lt;EmployeeContext&gt;())
      {
        context?.SeedData();
      }
    }</pre></li>
				<li>Now, run <code>dotnet build</code> in the VS Code terminal and fix any build errors. To generate a database from our models and populate the database, we need to install <code>dotnet-ef</code> either locally or globally and run the migration commands, as follows, in the VS Code terminal, which would generate the <code>Migrations</code> folder and then the <code>Employee.db</code> file, which is our SQLite database:<pre>dotnet tool install --global dotnet-ef --ignore-failed-sources //Installing dotnet ef.
dotnet ef migratio<a id="_idTextAnchor983"/>ns add InitialCreate //Generate DB migrations.
dotnet ef database update //Update database.</pre></li>
				<li><a id="_idTextAnchor984"/>Now, to read the <code>Employee</code> table, navigate to <code>Index.cshtml.cs</code> and paste the following code. Here, we are injecting <code>EmployeeContext</code> and then reading data from the employee table:<pre>public class IndexModel : PageModel
    {
        private readonly EmployeeContext context;
        public IndexModel(EmployeeContext context)
        {
            this.context = context;
        }
         public Ilist&lt;Employee&gt; Employees { get; set; 
         }
         public async Task OnGetAsync()
        {
            this.Employees = await this.context.
            Employees.Include(x =&gt; x.Address).
            AsNoTracking().ToListAsy<a id="_idTextAnchor985"/>nc();
        }
  <a id="_idTextAnchor986"/>  }</pre></li>
				<li>Update <code>Index.cshtml</code> with the following<a id="_idIndexMarker796"/> code, which loops through the employee records<a id="_idIndexMarker797"/> populated in the <code>Employees</code> property of <code>IndexModel</code> and displays them:<pre>&lt;table class="table"&gt;
&lt;tbody&gt;
    @foreach (var item in Model.Employees)
    {&lt;tr&gt;
            &lt;td&gt;@Html.DisplayFor(modelItem =&gt;
            item.EmployeeId)&lt;/td&gt;
            &lt;td&gt;@Html.DisplayFor(modelItem =&gt;
            item.Name)&lt;/td&gt;
            &lt;td&gt;@Html.DisplayFor(modelItem =&gt;
            item.Email)&lt;/td&gt;
            &lt;td&gt;
                @foreach (var address in item.Address)
                {
                    @Html.DisplayFor(modelItem =&gt;
                    address.City) @Html.DisplayName("
                     ")
                }
            &lt;/td&gt;
        <a id="_idTextAnchor987"/>&lt;/tr&gt;
    }
&lt;/tbody&gt;
&lt;/table&gt;</pre></li>
			</ol>
			<p>Once we run this code, we can see<a id="_idIndexMarker798"/> the following output<a id="_idIndexMarker799"/> in the browser:</p>
			<div><div><img src="img/Figure_9.9_18507.jpg" alt="Figure 9.9 – Employee app output&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.9 – Employee app output</p>
			<p>Similarly, there are additional methods available in the <code>DbContext</code> class, such as <code>Add()</code>, <code>Remove()</code>, and <code>Find()</code>, to perform various CRUD o<a id="_idTextAnchor988"/>perations, and methods such as <code>Fro<a id="_idTextAnchor989"/>mSqlRaw()</code> to execute raw SQL queries or stored procedures.</p>
			<p>This is a very simple example, and its main<a id="_idIndexMarker800"/> purpose is to show the capabilities of EF Core<a id="_idIndexMarker801"/> for real-world applications. We can use a repository pattern with a generic repository holding all the CRUD methods and specific repositories to pe<a id="_idTextAnchor990"/><a id="_idTextAnchor991"/>rform specialized queries on a table. Ad<a id="_idTextAnchor992"/>ditionall<a id="_idTextAnchor993"/>y, a unit of wor<a id="_idTextAnchor994"/>k pattern can be used for transactions.</p>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor995"/>Code first versus database first</h2>
			<p>In the previous sample, we have newly<a id="_idIndexMarker802"/> created POCOs and generated a database out of them; this style of generating<a id="_idIndexMarker803"/> a da<a id="_idTextAnchor996"/>tabase from POCOs is known as a <strong class="bold">code-first approach</strong>. As the definition suggests, we have<a id="_idIndexMarker804"/> our POCOs defined first<a id="_idIndexMarker805"/> and then the database is generated.</p>
			<p>However, many times, especially during a migration scenario or in cases where <a id="_idTextAnchor997"/>there is a dedicated database team, we would need<a id="_idIndexMarker806"/> to generate POCOs out of database tables. EF Core supports such scenarios through the <strong class="bold">database-first approach</strong>, where models and the application da<a id="_idTextAnchor998"/>tabase context class are generated from an existing database. </p>
			<p>This process of generating POCOs<a id="_idIndexMarker807"/> from database models is known as <code>Scaffold-DbContext</code> command, which accepts various parameters, such as a database connection string and the name of the application database context class, and then generates all the required classes needed for EF Core.</p>
			<p>The rest of the configuration remains the same as in the code-first approach. A sample scaffolding command with various parameters will look like the following:</p>
			<pre class="source-code">Scaffold-DbContext "Data Source=.;Initial Catalog=Employee.DB;Trusted_Connection=True;" Microsoft.EntityFrameworkCore.SqlServer -Namespace Api.Data.Models -ContextNamespaceApi.Data -ContextDir Api.Data/Abstraction -Context EmployeeContext -Force</pre>
			<p>In this command, we are reading a database, <code>Employee.DB</code>, generating all the models inside <code>Namespace Api.Data.Models</code>, generating context inside <code>Api.Data/Abstraction</code>, and naming the context <code>EmployeeContext</code>. In databas<a id="_idTextAnchor999"/>e-first, the relationship<a id="_idIndexMarker808"/><a id="_idTextAnchor1000"/> between classes is defined <a id="_idTextAnchor1001"/>using<a id="_idIndexMarker809"/> the Fluent API as opposed<a id="_idIndexMarker810"/> to annotations.</p>
			<p>One thing here is every time we run this command, all the POCOs will be overwritten along with the application context class. Secondly, this command generates a context class with the <code>protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)</code> method in it. This method is needed only if the context class needs to maintain the connection string and other EF Core options. However, in most real-world applications, the connection string is maintained in <code>appsettings.json</code> and EF Core is configured in the <code>Program</code> class, so this method can be deleted.</p>
			<p>This means there is a cleanup involved after each time we scaffold, and a better way to avoid any customization is to create a partial class for our application database context and do all the customization there, such as adding specific models for stored procedures or defining any application-specific constraints. This way, any time we scaffold an applicat<a id="_idTextAnchor1002"/>ion, customization won't be overwritten, which still allows us to auto-gene<a id="_idTextAnchor1003"/>rate classes from a database.</p>
			<p>Choosin<a id="_idTextAnchor1004"/>g the database-first approach or code-first approach is completely up to the development team, as both approaches have pros and cons and there isn't any specific feature that is available in one b<a id="_idTextAnchor1005"/>ut not in the other.</p>
			<p class="callout-heading">Note</p>
			<p class="callout"><code>Scaffold-DbContext</code> supports multiple parameters; for example, you can specify a schema for generating<a id="_idIndexMarker811"/> POCOs for a schema. For further reading, please refer to <a href="https://docs.microsoft.com/en-us/ef/core/managing-schemas/scaffolding?tabs=dotnet-core-cli">https://docs.microsoft.com/en-us/ef/core/managing-schemas/scaffolding?tabs=dotnet-core-cli</a>.</p>
			<p>With this under<a id="_idTextAnchor1006"/><a id="_idTextAnchor1007"/>standing, let's create the Data Access service that we will use<a id="_idTextAnchor1008"/> in our enterprise applicatio<a id="_idTextAnchor1009"/>n in the next section.</p>
			<h1 id="_idParaDest-177"><a id="_idTextAnchor1010"/>Designing a Data Access service using Azure Cosmos DB</h1>
			<p>As NoSQL databases<a id="_idIndexMarker812"/> are all about fast access and high scalability, the schema<a id="_idIndexMarker813"/> for NoSQL is denormalized and so there is a high possibility of data redundancy. Let's map our requirements from <a href="B18507_01_Epub.xhtml#_idTextAnchor020"><em class="italic">Chapter 1</em></a>, <em class="italic">Designing and Architecting the Enterprise Application</em>, to various entities. A quick r<a id="_idTextAnchor1011"/>efresher of various services from the architecture is shown in the following figure:</p>
			<div><div><img src="img/Figure_9.10_18507.jpg" alt="Figure 9.10 – Services in an e-commerce application&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.10 – Services in an e-commerce appli<a id="_idTextAnchor1012"/>cation</p>
			<p>For easier understanding, we will represent entities in JSON before moving on to POCOs:</p>
			<ul>
				<li><code>Email</code> field is used as a partition key:<pre>{
  "Id": "1",
  "Name": "John",
  "Email": "John@xyz.com",
  "Address":[{"<a id="_idTextAnchor1013"/>Address1":"Gachibowli","City":
      "Hyderabad","Country":"India"}],
  "PhoneNumber":12345
}</pre></li>
				<li><code>Name</code> field is used as a partition key.</li>
				<li><code>Id</code> field is used as a partition key:<pre>{
  "Id": "1",
  "UserId": "1",
  "Products": [{"Id":"1","Name":
      "T-Shirt","Quantity": 1,"Price": 10}],
  "OrderStatus" : "Processed",
  "OrderPlacedDate" : "20-02-2020T00:00:00Z",
  "ShippingAddress": {"Address1":"Gachibowli",
      "C<a id="_idTextAnchor1015"/>ity":"Hyderabad","Country":"India"},
  "TrackingId": 1,
  "DeliveryDate":"28-02-2020T00:00:00Z"
}</pre></li>
				<li><code>Id</code> field is used as a partition<a id="_idIndexMarker820"/> key:<pre>{
  "Id": "1",
  "OrderId": "1",
  "PaymentMode": "Credit Card",
  "ShippingAddress": {"Address1":"Gachibowli",
     "City":"Hyderabad","Country":"India"},
  "SoldBy": {"SellerName": "Seller1",  "Email":
     "seller@ecommerce.com<a id="_idTextAnchor1016"/>", "Phone": "98765432"},  
  "Products": [{"Id":"1", "Name":<a id="_idTextAnchor1017"/> "T-Shirt", 
     "Quantity": 1, "Price": 10}]
}</pre></li>
			</ul>
			<p>A combination<a id="_idIndexMarker821"/> of <code>Product</code> a<a id="_idTextAnchor1018"/>nd <code>Order</code> is shown in the following screenshot:</p>
			<div><div><img src="img/Figure_9.11_18507.jpg" alt="Figure 9.11 – E-commerce database model's Product and Order schema&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.11 – E-commerce database model's Product and Order schema</p>
			<p>As you can see, all <em class="italic">1:N</em> relationships<a id="_idIndexMarker822"/> are handled by embe<a id="_idTextAnchor1019"/>dding the child item as an array. Similarly, the <code>Invoice</code> and <code>User</code> entities <a id="_idTextAnchor1020"/>schema<a id="_idIndexMarker823"/> is as shown in the following screenshot:</p>
			<div><div><img src="img/Figure_9.12_18507.jpg" alt="Figure 9.12 – E-commerce database model's Invoice and User schema&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 9.12 – E-commerce database model's Invoice and User schema</p>
			<p>In our enterprise application, <a href="https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application">https://github.com/PacktPublishing/Enterprise-Application-Development-with-C-10-and-.NET-6-Second-Edition/tree/main/Enterprise%20Application</a>, we will have one service<a id="_idIndexMarker824"/> interacting with the Azure Cosmos DB database. This service comprises<a id="_idIndexMarker825"/> the following three projects, which are explained next:</p>
			<ul>
				<li><code>Packt.Ecommerce.Data.Models</code></li>
				<li><code>Packt.Ecommerc<a id="_idTextAnchor1022"/>e.DataStore</code></li>
				<li><code>Packt.Ecommerce.DataAccess</code></li>
			</ul>
			<p>The first project is <code>Packt.Ecommerce.Data.Models</code>, which is a .NET Standard 2.1 library and comprises all of our POCOs to communicate with the database. As discussed earlier, all the POCOs will have a common <code>id</code> property and the other properties described in the JSON schema in the previous section.</p>
			<p class="callout-heading">Tip</p>
			<p class="callout">If sample JSON is available, we can make use of<a id="_idTextAnchor1023"/> JSON in C# class generation tools.</p>
			<p><code>Packt.Ecommerce.DataStore</code> is a .NET Standard 2.1 library and is the repository layer that holds a generic repository and entity-specific<a id="_idIndexMarker826"/> repositories. An important class<a id="_idIndexMarker827"/> in this project is <code>BaseRepository</code>, which has the following methods, and each method calls the respective method of the <code>CosmosClient</code> class:</p>
			<ul>
				<li><code>GetAsync(string filterCriteria)</code>: This method gets records from a container based on <code>filterCriteria</code>. If <code>filterCriteria</code> is empty, all the records from that container are retrieved.</li>
				<li><code>GetByIdAsync(string id, string partitionKey)</code>: This method helps in retrieving any record from a container by its ID and partition key.</li>
				<li><code>AddAsync(Tentity entity, string partitionKey)</code>: This method allows us to insert a record into a container.</li>
				<li><code>ModifyAsync(Tentity entity, string partitionKey)</code>: This method allows us to <code>UPSERT</code> (modify if a record is present, otherwise, insert) a record in a container.</li>
				<li><code>RemoveAsync(string id, string partitionKey)</code>: This method allows the deletion of a record from a container.</li>
			</ul>
			<p>Since, in Azure Cosmos DB, each record is uniquely identified by a combination of ID and partition key, all these methods accept a partition key along with <code>id</code>. Since this is a generic repository, the signature of the class would be the following, which allows us to pass any POCO for our application and perform CRUD operations on the corresponding container:</p>
			<pre class="source-code">public class BaseRepository&lt;TEntity&gt; : IBaseRepository&lt;TEntity&gt;</pre>
			<pre class="source-code">where TEntity : class</pre>
			<p>All these methods would require an object of <code>Microsoft.Azure.Cosmos.Continer</code> for which we create a <code>readonly</code> private member, which is initialized<a id="_idIndexMarker828"/> in the constructor of the<a id="_idIndexMarker829"/> class, as follows:</p>
			<pre class="source-code">        private readonly Container container;</pre>
			<pre class="source-code">        public BaseRepository(CosmosClient cosmosClient,</pre>
			<pre class="source-code">        string databaseName, string containerName)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            if (cosmosClient == null)</pre>
			<pre class="source-code">            {</pre>
			<pre class="source-code">                throw new Exception("Cosmos client is</pre>
			<pre class="source-code">                 null");</pre>
			<pre class="source-code">            }</pre>
			<pre class="source-code">            this.container = cosmosClient.GetContainer</pre>
			<pre class="source-code">            (databaseName, containerName);</pre>
			<pre class="source-code">        }</pre>
			<p>Now, <code>CosmosClient</code> would be plumbe<a id="_idTextAnchor1024"/>d into the system through dependency injection and would be configured in the <code>static</code> class. As a best practice, it is recommended to have only one instance of <code>CosmosClient</code> in the lifetime of the application to better reuse connections, so we will be configuring it in our ASP.NET Core 6 dependency injection container as a singleton. We will come to this in a bit.</p>
			<p>Coming back to the repository layer, <code>BaseRepository</code> is additionally inherited in the following concrete classes, with each repository representing a corresponding container:</p>
			<ul>
				<li><code>ProductRepository</code></li>
				<li><code>UserRepository</code></li>
				<li><code>OrderRepository</code></li>
				<li><code>InvoiceRepository</code></li>
			</ul>
			<p>Taking the example of <code>ProductRepository</code>, it will have the following implementation, where we pass the singleton<a id="_idIndexMarker830"/> instance of <code>CosmosClient</code> and additional properties<a id="_idIndexMarker831"/> using the <code>Ioptions</code> pattern:</p>
			<pre class="source-code">    public class ProductRepository :</pre>
			<pre class="source-code">    BaseRepository&lt;Product&gt;, IProductRepository</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        private readonly IOptions&lt;DatabaseSettingsOptions&gt;</pre>
			<pre class="source-code">        databaseSettings;</pre>
			<pre class="source-code">        public ProductRepository(CosmosClient,</pre>
			<pre class="source-code">        IOptions&lt;DatabaseSettingsOptions&gt;</pre>
			<pre class="source-code">        databaseSettingsOption)</pre>
			<pre class="source-code">            : base(cosmosClient, databaseSettingsOption.</pre>
			<pre class="source-code">        <a id="_idTextAnchor1025"/>      Value.DataBaseName, "Products")</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">            this.databaseSettings = databaseSettingsOption;</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">    }</pre>
			<p>All the other repositories will follow a similar structure. Each repository will implement its own interface to supp<a id="_idTextAnchor1026"/>ort dependency injection.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">These repositories will evolve as and when we progress with our application implementation.</p>
			<p>The next project is <code>Packt.Ecommerce.DataAccess</code>, which is a Web API project targeting .NET 6 and will primarily have all the controllers to expose our repositories. Each repository would be a <em class="italic">1:1</em> mapping with the corresponding controller. So, for example, there would be <code>ProductsController</code> exposing <code>ProductRepository</code> methods as a REST API. All the controllers will use constructor injection to instantiate their corr<a id="_idTextAnchor1027"/>esponding repositories. One important thing in <code>Packt.Ecommerce.DataAccess</code> is the configuration<a id="_idIndexMarker832"/> of the Azure Cosmos DB<a id="_idIndexMarker833"/> database. The design of various controllers would be very similar to the design of the <code>Packt.Ecommerce.Product</code> Web API, which is discussed in <a href="B18507_10_Epub.xhtml#_idTextAnchor1040"><em class="italic">Chapter 10</em></a>, <em class="italic">Creating an ASP.NET Core 6 Web API</em>.</p>
			<p>To start with, we will have a corresponding section in <code>appsettings.json</code>, whic<a id="_idTextAnchor1028"/>h is shown as follows:</p>
			<pre class="source-code">  "CosmosDB": {</pre>
			<pre class="source-code">    "DataBaseName": "Ecommerce",</pre>
			<pre class="source-code">    "AccountEndPoint": "",</pre>
			<pre class="source-code">    "AuthKey": ""</pre>
			<pre class="source-code">  }</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">For the local development<a id="_idIndexMarker834"/> environment, we will use <strong class="bold">Manage User Secrets</strong>, as explained here: <a href="https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-6.0">https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-6.0</a>. We will set the following values:</p>
			<p class="callout"><code>{</code></p>
			<p class="callout"><code>  "CosmosDB:AccountEndPoint": "", //Cosmos DB End Point</code></p>
			<p class="callout"><code>  "CosmosDB:AuthKey": "" //Cosmos DB Auth key</code></p>
			<p class="callout"><code>}</code></p>
			<p class="callout">However, once the service is deployed, it should make use of Azure Key Vault, as explained in <a href="B18507_06_Epub.xhtml#_idTextAnchor473"><em class="italic">Chapter 6</em></a>, <em class="italic">Configuration in .NET 6</em>.</p>
			<p>We will define an extension<a id="_idIndexMarker835"/> class that will hold the dependency injection<a id="_idIndexMarker836"/> mapping. A snippet of that is shown here:</p>
			<pre class="source-code">    public static class RepositoryExtensions</pre>
			<pre class="source-code">    {</pre>
			<pre class="source-code">        public static IServiceCollection</pre>
			<pre class="source-code">        AddRepositories(this IServiceCollection services)</pre>
			<pre class="source-code">        {</pre>
			<pre class="source-code">        <a id="_idTextAnchor1029"/>    services.AddScoped&lt;IproductRepository,</pre>
			<pre class="source-code">            ProductRepository&gt;();</pre>
			<pre class="source-code">            return services;</pre>
			<pre class="source-code">        }</pre>
			<pre class="source-code">    }</pre>
			<p>Similarly, all the repositories would be mapped. Then, we will configure this in the <code>Program</code> class, along with Azure Cosmos DB configuration, by adding the following code:</p>
			<pre class="source-code">builder.Services.AddOptions();</pre>
			<pre class="source-code">builder.Services.Configure&lt;DatabaseSettingsOptions&gt;(builder.Configuration.GetSection("CosmosDB"));</pre>
			<pre class="source-code">string accountEndPoint = builder.Configuration.GetValue&lt;string&gt;("CosmosDB:AccountEndPoint");</pre>
			<pre class="source-code">string authKey = builder.Configuration.GetValue&lt;string&gt;("CosmosDB:AuthKey");</pre>
			<pre class="source-code">builder.Services.AddSingleton(s =&gt; new CosmosClient(accountEndPoint, authKey));</pre>
			<pre class="source-code">builder.Services.AddRepositories();</pre>
			<p>Once we are done with the configuration, this service is ready for consumption in other services, such a<a id="_idTextAnchor1030"/>s <code>Products</code>, <code>Orders</code>, and <code>Invoice</code>. This library will have all the necessary REST APIs to perform CRUD operations on various entities.</p>
			<p>This concludes the creation<a id="_idIndexMarker837"/> of a Data Access service that performs CRUD operations<a id="_idIndexMarker838"/> on various entities, and all the operations are exposed<a id="_idTextAnchor1031"/><a id="_idTextAnchor1032"/> as APIs. This service will be called from all the other services that we will develop in <a href="B18507_10_Epub.xhtml#_idTextAnchor1040"><em class="italic">Chapter 10</em></a>, <em class="italic">Creating an ASP.NET Core 6 Web API</em>.</p>
			<h1 id="_idParaDest-178"><a id="_idTextAnchor1033"/>Summary</h1>
			<p>In this chapter, we learned about various persistent options that are available in .NET 6, from APIs to work with files and directories to databases such as Microsoft SQL Server and Azure Cosmos DB.</p>
			<p>We also learned about ORMs, their importance, and how EF Core can be used to build a persistence layer while working with Microsoft SQL Server. Along the way, we built a data access layer for our e-commerce application using the Azure Cosmos DB SDK. Some of the key takeaways are the design decisions we took between SQL versus NoSQL, and how we can abstract a data layer with application logic and a UI layer that will help you to build scalable enterprise applications.</p>
			<p>In the next chapter, we will look at the foundatio<a id="_idTextAnchor1034"/><a id="_idTextAnchor1035"/>n of RESTful APIs and the internals of the ASP.NET Core 6 Web API, and further build various RESTful services for e-commerce applications.</p>
			<h1 id="_idParaDest-179"><a id="_idTextAnchor1036"/>Questions</h1>
			<ol>
				<li value="1">Say you are migrating an existing web application to use EF Core; however, there isn't any change in the database schema and an existing one can be used as-is. What is the preferable mode to use EF Core?</li>
			</ol>
			<p>a. Database-first</p>
			<p>b. Code-first</p>
			<p>c. Both</p>
			<p><strong class="bold">Answer: a</strong></p>
			<ol>
				<li value="2">If we are building a recommendation system for our e-commerce application and we are using Azure Cosmos DB, what API is best recommended in this scenario?</li>
			</ol>
			<p>a. The Core (SQL) API</p>
			<p>b. The Mongo API</p>
			<p>c. The Cassandra API</p>
			<p>d. The Gremlin (graph) API</p>
			<p><strong class="bold">Answer: d</strong></p>
			<ol>
				<li value="3">I created a container in SQL API-based databases to store user profile information and defined <code>Email</code> as the partition key. My system has 100 unique emails. How many logical partitions will my container have?</li>
			</ol>
			<p>a. 1.</p>
			<p>b. 0.</p>
			<p>c. 100.</p>
			<p>d. Azure Cosmos DB does not sup<a id="_idTextAnchor1037"/><a id="_idTextAnchor1038"/>port logical partitions.</p>
			<p><strong class="bold">Answer: c</strong></p>
			<h1 id="_idParaDest-180"><a id="_idTextAnchor1039"/>Further reading</h1>
			<p>A few links to understand the topics of this chapter further are provided as follows:</p>
			<ul>
				<li><a href="https://docs.microsoft.com/en-us/ef/core/saving/transactions">https://docs.microsoft.com/en-us/ef/core/saving/transactions</a></li>
				<li><a href="https://docs.microsoft.com/en-us/ef/core/performance/advanced-performance-topics">https://docs.microsoft.com/en-us/ef/core/performance/advanced-performance-topics</a></li>
				<li><a href="https://docs.microsoft.com/en-us/aspnet/core/security/gdpr?view=aspnetcore-6.0">https://docs.microsoft.com/en-us/aspnet/core/security/gdpr?view=aspnetcore-6.0</a></li>
				<li><a href="https://aws.amazon.com/products/databases/">https://aws.amazon.com/products/databases/</a></li>
			</ul>
		</div>
	</body></html>