- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Testing Your Enterprise Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When developing software, it is essential to ensure that an application is as
    bug-free as possible and that it satisfies all requirements. This can be done
    by testing all the modules while they are being developed or when the overall
    application has been either completely or partially implemented. This need has
    become more and more compelling in today’s agile and DevOps-driven software development
    landscape, where integrating testing at every stage of the development process
    is essential for the continuous delivery of reliable software.
  prefs: []
  type: TYPE_NORMAL
- en: While most of the key concepts covered by this chapter apply to a wide range
    of applications and environments, this chapter focuses on essential testing strategies
    for enterprise-level applications in C# and .NET environments.
  prefs: []
  type: TYPE_NORMAL
- en: Performing all the tests manually is not a feasible option since most of the
    tests must be executed each time the application is modified, and, as explained
    throughout this book, modern software is continuously being modified to adapt
    applications to the needs of a fast-changing market. Therefore, automated tests
    are indispensable in today’s fast-paced environment of continuous development.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter discusses the most common types of tests needed to deliver reliable
    software and how to organize and automate them. More specifically, this chapter
    covers the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding unit and integration tests and their usage, which are the main
    tools to ensure software reliability and stability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the basics of **test-driven development** (**TDD**) and how and
    why it can dramatically reduce the probability of undiscovered bugs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functional tests, which are the main tool for enforcing software specifications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining C# test-specific projects in Visual Studio to take full advantage of
    the testing tools available in the .NET ecosystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating functional tests in C#
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter will not only teach you the different types of tests and how to
    implement them but also how to effectively apply these techniques in your role
    as a .NET software architect to build robust, scalable enterprise applications.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter requires the Visual Studio 2022 free Community Edition or better,
    with all database tools installed. The code for this chapter is available at [https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E](https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding unit and integration tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Testing is an essential part of software development since it verifies both
    that the software is bug-free and that it conforms to the agreed specification.
    Delaying application testing until immediately after most of the application’s
    functionalities have been implemented in their entirety must be avoided for the
    following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: If a class or module has been incorrectly designed or implemented, it might
    have already influenced the way other modules were implemented. Therefore, at
    this point, fixing the problem might have a very high cost.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The possible combination of input that is needed to test all possible paths
    that execution can take grows exponentially with the number of modules or classes
    that are tested together. Thus, for instance, if the execution of a class method
    `A` can take three different paths, while the execution of another method `B`
    can take four paths, then testing `A` and `B` together would require 3 x 4 different
    inputs. In general, if we test several modules together, the total number of paths
    to test is the product of the number of paths to test in each module. If modules
    are tested separately, instead, the number of inputs required is just the sum
    of the paths needed to test each module. That’s why so-called unit tests verify
    each class method separately in an exhaustive way as soon as each class is designed.
    After that, the overall behavior correctness can be verified with an acceptably
    small number of so-called *integration tests*, *because integration tests* just
    need to verify the various classes’ interaction patterns without analyzing all
    methods’ execution paths.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a test of an aggregate made of *N* modules fails, then locating the origin
    of the bug among the *N* modules is usually a very time-consuming activity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When *N* modules are tested together, we have to redefine all tests involving
    the *N* modules, even if just one of the *N* modules changes during the application’s
    life cycle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These considerations show that we need both to test each class method separately
    as soon as possible and to test for correct module integration.
  prefs: []
  type: TYPE_NORMAL
- en: 'That is why tests are organized into three stages, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unit tests**: These verify that all or almost all execution paths of each
    method behave properly. They should be free from external dependencies, such as
    storage and databases, and should be quite complete; that is, they should cover
    most of the possible paths. This is usually feasible at an acceptable time cost
    because there are not too many possible execution paths for each method as compared
    to the possible execution paths of the whole application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration tests**: These are executed once the software passes all its
    unit tests. Integration tests verify that all modules interact properly to get
    the expected results. Integration tests do not need to be complete since unit
    tests will have already verified that all the execution paths of each module work
    properly. They need to verify as many patterns of interaction as possible, that
    is, as many ways in which the various modules may cooperate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Acceptance tests**: These are executed at the end of each sprint and/or before
    releasing the application. They verify that the output of a sprint or the final
    application satisfies both functional and non-functional requirements. Tests that
    verify functional requirements are called **functional tests**, while tests that
    verify performance requirements are called **performance tests**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Usually, each interaction pattern has more than one test associated with it:
    a typical activation of a pattern and some extreme cases of activation. For instance,
    if a whole pattern of interaction receives an array as input, we will write a
    test for the typical size of the array, a test with a `null` array, a test with
    an empty array, and a test with a very big array. This way, we verify that the
    way the single module was designed is compatible with the needs of the whole interaction
    pattern. It is worth pointing out that, in our array example, `null`, `0`, `1`,
    and *many* are equivalence classes that represent the whole universe of array
    values in an efficacious way.'
  prefs: []
  type: TYPE_NORMAL
- en: With the preceding strategy in place, if we modify a single module without changing
    its public interface, we need to change the unit tests for that module.
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, the change involves the way some modules interact, then we also
    have to add new integration tests or modify existing ones. However, usually, this
    is not a big problem since most of the tests are unit tests, so rewriting a large
    percentage of all integration tests does not require too much effort. Moreover,
    if the application was designed according to the **Single Responsibility**, **Open/Closed**,
    **Liskov Substitution**, **Interface Segregation**, or **Dependency Inversion**
    (**SOLID**) principles, the number of integration tests that must be changed after
    a single code modification should be small since the modification should affect
    just a few classes that interact directly with the modified method or class.
  prefs: []
  type: TYPE_NORMAL
- en: Automating unit and integration tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, it should be clear that both unit tests and integration tests
    will be reused during the entire lifetime of the software. That is why it is worth
    automating them. The automation of unit and integration tests avoids the possible
    errors of manual test execution and saves time. A whole battery of several thousand
    automated tests can verify software integrity following each small modification
    in a few minutes, thereby enabling the frequent changes needed in the CI/CD cycles
    of modern software.
  prefs: []
  type: TYPE_NORMAL
- en: As new bugs are found, new tests are added to discover them so that they cannot
    reappear in future versions of the software. This way, automated tests always
    become more reliable and protect the software more from bugs added as a result
    of new changes. Thus, the probability of adding new bugs (that are not immediately
    discovered) is greatly reduced.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection will give us the basics for organizing and designing automated
    unit and integration tests, as well as practical details on how to write a test
    in C# in the *Defining C# test projects in Visual Studio* section.
  prefs: []
  type: TYPE_NORMAL
- en: Writing automated (unit and integration) tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tests are not written from scratch; all software development platforms have
    tools that help us to both write tests and launch them (or some of them). Once
    the selected tests have been executed, these tools usually show a report and offer
    the possibility to debug the code of all failed tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, by and large, all unit and integration test frameworks are
    composed of three important parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Facilities for defining all tests**: They verify whether the actual results
    correspond to the expected results. Usually, a test is organized into test classes,
    where each test call tests either a single application class or a single class
    method. Each test is split into three stages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test preparation (***Arrange***)**: The general environment needed by the
    test is prepared. This stage only prepares the global environment for tests, such
    as objects to inject into class constructors or simulations of database tables;
    it doesn’t prepare the individual inputs for each of the methods we’re going to
    test. Usually, the same preparation procedure is used in several tests, so test
    preparations are factored out into dedicated modules.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Test execution (***Act***/***Assert***)**: The methods to test are invoked
    with adequate input (*Act*), and all results of their executions are compared
    with expected results (*Assert*) with constructs such as `Assert.Equal(x,y)` and
    `Assert.NotNull(x)`.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Tear-down**: The whole environment is cleaned up to avoid the execution of
    a test influencing other tests. This step is the converse of *step 1*.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mock facilities**: While integration tests use all (or almost all) classes
    involved in a pattern of object cooperation, in unit tests, the use of other application
    classes should be avoided because their purpose is to test each isolated method.
    Thus, if a class under test, say, `A`, uses a method of another application class,
    `B`, that is injected into its constructor in one of its methods, `M`, and then,
    in order to test `M`, we must inject a fake implementation of `B`. It is worth
    pointing out that only classes that do some processing cannot be used by other
    classes being unit tested, while pure data classes can. Mock frameworks contain
    facilities to define implementations of interfaces and interface methods that
    return data that can be defined by the test designer. Typically, mock implementations
    are also able to report information on all mock method calls. Such mock implementations
    do not require the definition of actual class files but are done online in the
    test code by calling methods such as `new Mock<IMyInterface>()`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Execution and reporting tool**: This is a visual configuration-based tool
    that the developer may use to decide which tests to launch and when to launch
    them. Moreover, it also shows the final outcome of the tests as a report containing
    all successful tests, all failed tests, each test’s execution time, and other
    information that depends on the specific tool and how it was configured. Usually,
    execution and reporting tools that are executed in development IDEs, such as Visual
    Studio, also give you the possibility of launching a debug session on each failed
    test.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since only interfaces allow a complete mock definition of all their methods,
    we should inject interfaces or pure data classes (that don’t need to be mocked)
    in class constructors and methods if we want to mock all dependencies in our unit
    tests. Therefore, for each cooperating class that we want to inject into another
    class and that we want to mock, we must define a corresponding interface.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, classes should use instances that are injected in their constructors
    or methods and not class instances available in the public static fields of other
    classes; otherwise, the results of the unit tests might appear not to be deterministic
    since these static values might not be set properly during the tests.
  prefs: []
  type: TYPE_NORMAL
- en: The subsection that follows focuses on functional and performance tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Acceptance tests: writing functional and performance tests'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Acceptance tests define the contract between the project stakeholders and the
    development team. They are used to verify that the software developed actually
    behaves as it was agreed it would. Acceptance tests verify not only functional
    specifications but also constraints on the software usability and **user interface**
    (**UI**). Since they also have the purpose of showing how the software appears
    and behaves on actual computer monitors and displays, they are never completely
    automatic but consist mainly of lists of recipes and verifications that must be
    followed by an operator.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, automatic **functional tests** are developed to verify just functional
    requirements, but some of these tests may also bypass the UI and inject the test
    input directly into the logic that is immediately behind the user interface. For
    instance, in the case of an ASP.NET Core MVC application (see *Chapter 17*, *Presenting
    ASP.NET Core*), the whole website can be run in a complete environment that includes
    all the necessary storage filled with test data. Input is not provided to HTML
    pages but is injected directly into the ASP.NET Core controllers. Tests that bypass
    the user interface are called subcutaneous tests. ASP.NET Core supplies various
    tools to perform subcutaneous tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'If possible, most automated acceptance tests should be defined as subcutaneous
    tests for the following reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Automating the actual interaction with the user interface is a very time-consuming
    task.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: User interfaces are changed frequently to improve their usability and to add
    new features, and small changes in a single application screen may force a complete
    rewrite of all tests that operate on that screen.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In a few words, user interface tests are very expansive and have low reusability,
    so usually, complete adherence to specifications is tested with subcutaneous tests,
    and full tests involving the whole user interface are performed just to test the
    more common and/or more error-prone scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: A common approach for testing the user interface is the usage of playback tools
    like **Selenium IDE** ([https://www.selenium.dev/selenium-ide/](https://www.selenium.dev/selenium-ide/))
    during manual tests so that each manual test can be repeated automatically. It’s
    likely that the code generated automatically by such tools is not robust enough
    to resist non-trivial changes in the HTML. The Selenium IDE playback code tries
    to resist HTML changes by attempting several selectors to identify each HTML element,
    but this only helps with small changes. Therefore, in general, playback code can
    be reused only for the parts of the application UI that are not affected by changes.
  prefs: []
  type: TYPE_NORMAL
- en: The Selenium software may also be used programmatically, that is, by describing
    user interface tests directly in the code. Selenium will be discussed in more
    detail in the *Automating functional tests in C#* section, while functional tests,
    in general, are discussed in the *Functional tests* section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance tests** apply a fake load to an application to see whether it
    can handle the typical production load, discover its load limits, and locate bottlenecks.
    The application is deployed in a staging environment that is a copy of the actual
    production environment in terms of hardware resources.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, fake requests are created and applied to the system, and response times
    and other metrics are collected. Fake request batches should have the same composition
    as the actual production batches. They can be generated from the actual production
    request logs if they are available.
  prefs: []
  type: TYPE_NORMAL
- en: If response times are not satisfactory, other metrics are collected to discover
    possible bottlenecks (low memory, slow storage, or slow software modules). Once
    located, a software component that is responsible for the problem can be analyzed
    in the debugger to measure the execution time of the various method calls involved
    in a typical request.
  prefs: []
  type: TYPE_NORMAL
- en: Failures in the performance tests may lead either to a redefinition of the hardware
    needed by the application or to the optimization of some software modules, classes,
    or methods.
  prefs: []
  type: TYPE_NORMAL
- en: Both Azure and Visual Studio offer tools to create fake loads and to report
    execution metrics. However, they have been declared obsolete and will be discontinued,
    so we will not describe them. As an alternative, there are both open-source and
    third-party tools that can be used. Some of them are listed in the *Further reading*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: The next section describes a software development methodology that plays a central
    role in tests.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the basics of test-driven development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Test-driven development** (**TDD**) is a software development methodology
    that gives a central role to unit tests. According to this methodology, unit tests
    are a formalization of the specifications of each class, so they must be written
    before the code of the class. Actually, a full test that covers all code paths
    univocally defines the code behavior, so it can be considered a specification
    for the code. It is not a formal specification that defines the code behavior
    through some formal language but a specification based on examples of behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: The ideal way to test software would be to write formal specifications of the
    whole software behavior and to verify with some wholly automatic tools whether
    the software that was actually produced conforms to them. In the past, some research
    effort was spent defining formal languages for describing code specifications,
    but expressing the behavior the developer has in mind with similar languages was
    a very difficult and error-prone task. Therefore, these attempts were quickly
    abandoned in favor of approaches based on examples. At that time, the main purpose
    was the automatic generation of code.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, automatic code generation has been largely abandoned and survives
    in small application areas, such as the creation of device drivers. In these areas,
    the effort of formalizing the behavior in a formal language is worth the time
    saved in trying to test difficult-to-reproduce behaviors of parallel threads.
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests were initially conceived as a way to encode example-based specifications
    in a completely independent way as part of a specific agile development methodology
    called **extreme programming**. However, since TDD proved to be very efficacious
    in preventing bugs, nowadays, TDD is used independently of extreme programming
    and is included as an obligatory prescription in other agile methodologies.
  prefs: []
  type: TYPE_NORMAL
- en: The practice of TDD proved that well-designed initial unit tests are enough
    to ensure an acceptable level of software stability, despite the fact that, usually,
    initial tests are not a “perfect” specification of the code. However, it is undoubtedly
    true that unit tests refined after finding hundreds of bugs act as reliable and
    substantially perfect code specifications.
  prefs: []
  type: TYPE_NORMAL
- en: Well-designed unit tests can’t be based on random inputs since you might need
    an infinite or at least an immense number of examples to define a code’s behavior
    this way univocally. However, the behavior can be defined with an acceptable number
    of inputs if you have all possible execution paths in mind. In fact, at this point,
    it is enough to select a typical example for each execution path.
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s why writing a unit test for a method after that method has been completely
    coded is easy: it simply requires the selection of a typical instance for each
    execution path of the already-existing code. However, writing unit tests this
    way does not protect from errors in the design of the execution paths themselves.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, a unit test must be written before a method has been completely coded,
    but while writing unit tests, the developer must somehow forecast all execution
    paths by looking for extreme cases and by possibly adding more examples than are
    strictly needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, while writing the code that sorts an array, we might start considering
    all possible extreme cases we are able to forecast before any line of useful method
    code has been written, that is:'
  prefs: []
  type: TYPE_NORMAL
- en: An empty array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A null array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A single-element array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An array with a few elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An array with several elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An already-ordered array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A partially ordered array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An extremely unordered array
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the first version of the algorithm has been written and passes all of
    the above tests, other inputs that might cause different execution paths might
    be discovered by analyzing all execution paths. If this is the case, we add a
    new unit test for each different execution path discovered.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in the case of the array sorting method, suppose that we use a
    divide-and-conquer algorithm, like merge-sort, that recursively splits the array
    into two halves to recursively reduce the problem to a simpler one. For sure,
    the way that arrays with even or odd lengths are processed will be different,
    so we must add at least two new tests, one with an even-length array and the other
    with an odd-length array.
  prefs: []
  type: TYPE_NORMAL
- en: However, as developers can make mistakes while writing application code, they
    can also make mistakes in forecasting all possible execution paths while designing
    unit tests!
  prefs: []
  type: TYPE_NORMAL
- en: 'It seems we have identified a possible drawback of TDD: unit tests themselves
    may be wrong. That is, not only application code but also its associated TDD unit
    tests may be inconsistent with the behavior the developer has in mind. Therefore,
    in the beginning, unit tests can’t be considered software specifications but rather
    a possibly incorrect and incomplete description of the software behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we have two descriptions of the behavior we have in mind: the application
    code itself and its TDD unit tests that were written before the application code.
    However, this is not an issue because the theory of probability helps us!'
  prefs: []
  type: TYPE_NORMAL
- en: What makes TDD work well in practice is the fact that the probability of making
    exactly the same error while writing the tests and while writing the code is very
    low. Therefore, whenever a test fails, there is an error either in the tests or
    in the application code, and conversely, if there is an error either in the application
    code or in the test, there is a very high probability that a test will fail. That
    is, the use of TDD ensures that most bugs are found immediately!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have understood why TDD is efficacious in preventing bugs and have
    learned how to select the inputs for our unit tests, we can move to the description
    of the TDD-based code-writing process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing a class method or a chunk of code, say for finding the maximum of an
    array of integers with TDD, is a loop composed of three stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Red stage**: At this stage, the developer writes an empty method, say `MaximumGrade`,
    that throws `NotImplementedException`, and also writes new unit tests for this
    method. These tests must necessarily fail because, at this time, no code implements
    the behavior they describe:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Green stage**: In this stage, the developer writes the minimum code or makes
    the minimum modifications to existing code necessary to make all unit tests pass.
    Say we test `MaximumGrade` with a null array, an array with `0` elements, an array
    with just one element, and an array with several elements; the code that passes
    all tests might be:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Refactoring stage**: Once the test is passed, the code is refactored to ensure
    good code quality and the application of best practices and patterns. In particular,
    in this stage, some code can be factored out in other methods or other classes.
    During this stage, we may also discover the need for other unit tests because
    new execution paths or new extreme cases are discovered or created. In the case
    of `MaximumGrade`, at this stage, we might notice the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Instead of returning 0 when the array is `null`, it would be better to define
    a new exception and throw it.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`foreach` is more efficient and more readable than `for`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What if all numbers are negative? We must create a new test with an array of
    negative numbers:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The loop stops as soon as all tests pass without writing new code or modifying
    the existing code.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we repeat the red stage, the newly added test for the negative array will
    fail because of our inadequate initialization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we need to replace it with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, all tests pass again, and we move to the green stage again.
    There is no need for further refactoring, so the refactoring stage doesn’t modify
    our code, meaning we can exit the test loop: we are done!'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it is very difficult to design the initial unit tests because it
    is quite difficult to imagine how the code might work and the execution paths
    it might take. In this case, you can get a better understanding of the specific
    algorithm to use by writing an initial sketch of the method code. In this initial
    stage, we need to focus just on the main execution path, completely ignoring extreme
    cases and input verifications. Once we get a clear picture of the main ideas behind
    an algorithm that should work, we can enter the standard three-stage TDD loop.
  prefs: []
  type: TYPE_NORMAL
- en: The next section discusses functional tests in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Functional tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: These tests use the same techniques and tools as unit and integration tests
    but differ from them in that they are run only at the end of each sprint. They
    have the fundamental role of verifying that the current version of the entire
    software complies with its specifications.
  prefs: []
  type: TYPE_NORMAL
- en: Since functional tests also involve the UI, they need further tools to simulate,
    somehow, how the user acts in the UI. The need for extra tools is not the only
    challenge the UI brings with it because UIs also see frequent and major changes.
    Thus, we mustn’t design tests that depend on the UI’s graphical details, or we
    might be forced to rewrite all the tests completely at each UI change. We will
    discuss both the tools and the best practices for optimizing UI tests in the *Automating
    functional tests in C#* section.
  prefs: []
  type: TYPE_NORMAL
- en: Anyway, it is worth pointing out that sometimes it is better to renounce automated
    testing for some UI-related features and fall back to manual tests because the
    time investment is not justified by the short life of the UI code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whether automatic or manual, functional testing must be a formal process that
    is performed for the following purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: Functional tests represent the most important part of the contract between stakeholders
    and the development team, the other part being the verification of non-functional
    specifications. The way this contract is formalized depends on the nature of the
    relationship between the development team and stakeholders.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the case of a supplier-customer relationship, the functional tests become
    part of the supplier-customer business contract for each sprint, and a team that
    works for the customer writes them. If the tests fail, then the sprint is rejected,
    and the supplier must run a supplementary sprint to fix all problems.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If there is no supplier-customer business relationship because the development
    team and the stakeholder belong to the same company, there is no business contract.
    In this case, the stakeholder, together with the team, writes an internal document
    that formalizes the requirements of the sprint. If the tests fail, usually, the
    sprint is not rejected, but the results of the tests are used to drive the specifications
    for the next sprints. Of course, if the failure percentage is high, the sprint
    may be rejected and should be repeated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Formalized functional tests that run at the end of each sprint prevent any results
    achieved in previous sprints from being destroyed by new code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When using an agile development methodology, maintaining an updated battery
    of functional tests is the best way to get a formal representation of the final
    system specifications since, during agile development, the specifications of the
    final system are not decided before development starts but are the result of the
    system’s evolution. Agile development and sprints are discussed in detail in *Chapter
    1*, *Understanding the Importance of Software Architecture*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the output of the first sprints may differ a lot from the final system
    in these early stages, it is not worth spending too much time writing detailed
    manual tests and/or automatized tests. Therefore, you may limit the user stories
    to just a few examples that will be used both as inputs for software development
    and as manual tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'As system functionalities become more stable, it is worth investing time in
    writing detailed and formal functional tests for them. For each functional specification,
    we must write tests that verify their operation in extreme cases. For instance,
    in a cash withdrawal use case, we must write tests that verify all possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Not enough funds
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Card expired
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wrong credentials
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeated wrong credentials
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following diagram sketches the whole process with all possible outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Descrizione: Diagram  Description automatically generated](img/B19820_09_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.1: Withdrawal example'
  prefs: []
  type: TYPE_NORMAL
- en: The user inserts their card, and the card may be accepted or rejected because
    it has expired. Then, the user tries their PIN with possible errors, so they might
    repeat the PIN entry till either they succeed or they reach a maximum number of
    attempts. Finally, the user enters the amount to withdraw and may get their money
    or a “Not enough funds” error.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of manual tests, for each of the preceding scenarios, we must give
    all the details of all the steps involved in each operation and, for each step,
    the expected result.
  prefs: []
  type: TYPE_NORMAL
- en: An important decision is whether you want to automate all or a part of the functional
    tests since it is very expensive to write automated tests that simulate a human
    operator that interacts with a system’s UI. The final decision depends on the
    cost of the test implementation divided by the expected number of times it will
    be used.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of CI/CD, the same functional test can be executed several times,
    but unluckily, functional tests are strictly tied to the way the UI is implemented,
    and, in modern systems, the UI is changed frequently. Therefore, in this case,
    a test is executed with exactly the same UI no more than a couple of times.
  prefs: []
  type: TYPE_NORMAL
- en: In order to overcome most of the problems related to the UI, some functional
    tests can be implemented as **subcutaneous tests**. Subcutaneous tests are a specific
    type of functional test designed to bypass the UI layer of an application. Instead
    of interacting with the application through its UI, like a user would, these tests
    directly interact with the application’s underlying logic. For example, in an
    ASP.NET Core application, a subcutaneous test might directly invoke the methods
    of a controller – the part of the application that handles incoming requests –
    rather than going through the process of sending these requests via a browser.
    This approach helps us focus on testing the core functionality of the application
    without the complexities of the UI.
  prefs: []
  type: TYPE_NORMAL
- en: In the user case in *Chapter 21*, *Case Study*, we will see in practice how
    to design subcutaneous tests for an ASP.NET Core application.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, subcutaneous tests can’t verify all possible implementation errors
    since they can’t detect errors in the UI itself. Moreover, in the case of a web
    application, subcutaneous tests usually suffer from other limitations because
    they bypass the whole HTTP protocol.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, in the case of ASP.NET Core applications, which will be described
    in *Chapter 17*, *Presenting ASP.NET Core*, if we call controller action methods
    directly, we bypass the whole ASP.NET Core pipeline that processes each request
    before passing it to the right action method. Therefore, authentication, authorization,
    CORS, and the behavior of other middleware in the ASP.NET Core pipeline will not
    be analyzed by the tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'A complete automated functional test of a web application should do the following
    things:'
  prefs: []
  type: TYPE_NORMAL
- en: Start an actual browser on the URL to be tested.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wait so that any JavaScript on the page completes its execution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, send commands to the browser that simulate the behavior of a human operator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, after each interaction with the browser, automatic tests should wait
    so that any JavaScript that was triggered by the interaction completes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Such tests can be executed using browser automatization tools like **Selenium,**
    which will be discussed in the *Automating functional tests in C#* section of
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth pointing out that not all user interface tests can be automated
    since no automatic test can verify how the user interface appears and how usable
    it is.
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve explored the intricacies of functional and subcutaneous testing, it’s
    become clear that a comprehensive testing strategy must encompass not only how
    the tests are performed but also how they are conceptualized and communicated.
    This brings us to **Behavior-Driven Development** (**BDD**), a methodology that
    builds upon the principles of functional testing by emphasizing business value
    and client-side behavior. BDD offers a structured approach to creating tests that
    are more closely aligned with user requirements and business objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Behavior-Driven Development (BDD)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: BDD conforms to the rules of TDD we already described but focuses mainly on
    business value and client-side behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'We discussed that the strength of unit tests is as follows: “It is very unlikely
    that when describing a behavior in two completely different ways, that is, with
    code and with examples, we might make exactly the same errors, so errors are discovered
    with a probability that is close to 100%.”'
  prefs: []
  type: TYPE_NORMAL
- en: BDD uses the same approach, but the examples used in TDD must not depend on
    the specific way the functionality might be implemented. That is, examples must
    be as close as possible to pure specifications. This way, we are sure tests can’t
    influence the way functionality is implemented and vice versa; we are not influenced
    by pure technical facilities or constraints when writing specifications but focus
    mainly on the user needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, tests should use a vocabulary that can be understood by stakeholders.
    For these reasons, tests are described by a Given-When-Then syntax. The following
    is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '`Given`, `And`, `When`, and `Then` are keywords, while the remaining text is
    just natural language containing the example data.'
  prefs: []
  type: TYPE_NORMAL
- en: The Given-When-Then formal language is called Gherkin. It can be translated
    into code either manually or with tools that are part of toolsets like Cucumber
    ([https://cucumber.io/](https://cucumber.io/)) or SpecFlow in the case of .NET
    projects. SpecFlow is a Visual Studio extension that can be installed from the
    Visual Studio **Extensions** menu. Once installed, it adds a new kind of test
    project, a SpecFlow project.
  prefs: []
  type: TYPE_NORMAL
- en: 'In SpecFlow, Given-When-Then tests are defined in `.feature` files, while natural
    language clauses contained in the description are transformed into code in the
    so-called step files. Step files are automatically created, but the code inside
    of them must be written by the developer. Below is the method that is in charge
    of translating into code the `"Given the first number is 50"` clause:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The attribute on top of the method is automatically created by SpecFlow, but
    the (.*) regular expression that extracts the datum from the natural language
    clause must be written by the developer.
  prefs: []
  type: TYPE_NORMAL
- en: '`_calculator` is a variable that must be created by the developer and that
    contains a class to test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Once completely defined, SpecFlow tests are run by exploiting an underlying
    test framework supported by .NET. The underlying test framework to use is specified
    when the SpecFlow project is created.
  prefs: []
  type: TYPE_NORMAL
- en: While BDD and the Gherkin syntax can be used in unit, integration, and functional
    tests, the effort of writing tests in natural language and turning them into code
    is worth it only for functional tests because functional tests must be easily
    understood by stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: When writing unit tests, the BDD rule of the independence of tests from the
    implementation improves the tests’ quality and lifetime (fewer tests depend on
    implementation. Thus, they need to be updated less frequently). However, keep
    in mind that the classes that we are unit testing are themselves the result of
    implementation choices, so an excessive obsession with test independence might
    result in a waste of time.
  prefs: []
  type: TYPE_NORMAL
- en: After having described the theory behind testing, we are ready to move to practical
    implementations in C#. In the next section, we will list all test projects available
    in Visual Studio and describe xUnit in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Defining C# test projects in Visual Studio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The .NET SDK contains project templates for three types of unit testing frameworks:
    MSTest, xUnit, and NUnit. When starting the new project wizard in Visual Studio,
    if you want to see the compatible versions of these testing frameworks for .NET
    C# applications, set the **Project type** to **Test**, the **Language** to **C#**,
    and the **Platform** as **Linux**. This configuration will allow you to identify
    and select the appropriate versions of MSTest, xUnit, and NUnit for your project.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the selection that should appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B19820_09_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.2: Adding a test project'
  prefs: []
  type: TYPE_NORMAL
- en: All the preceding projects automatically include the NuGet package for running
    all the tests in the Visual Studio test user interface (Visual Studio test runner).
    However, they do not include any facility for mocking interfaces, so you need
    to add the `Moq` NuGet package, which contains a popular mocking framework.
  prefs: []
  type: TYPE_NORMAL
- en: All these test projects must contain a reference to the project to be tested.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will describe **xUnit**, but all three frameworks
    are quite similar and differ mainly in the names of the assert methods and the
    names of the attributes used to decorate various testing classes and methods.
  prefs: []
  type: TYPE_NORMAL
- en: Using the xUnit test framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In xUnit, tests are methods decorated with either the `[Fact]` or `[Theory]`
    attributes. Tests are automatically discovered by the test runner, which lists
    all of them in the user interface so the user can run either all of them or just
    a selection of them.
  prefs: []
  type: TYPE_NORMAL
- en: A new instance of the test class is created before running each test, so the
    *test preparation* code contained in the class constructor is executed before
    each test of the class. If you also require *tear-down code*, the test class must
    implement the `IDisposable` interface so that the tear-down code can be included
    in the `IDisposable.Dispose` method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The test code invokes the methods to be tested and then tests the results with
    methods from the `Assert` static class, such as `Assert.NotNull(x)`, `Assert.Equal(x,
    y)`, and `Assert.NotEmpty(IEnumerable x)`. Some methods verify whether a call
    throws an exception of a specific type, for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: When an assertion fails, an exception is thrown. A test fails if a not-intercepted
    exception is thrown either by the test code or by an assertion.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a method that defines a single test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The `[Fact]` attribute is used when a method defines just one test, while the
    `[Theory]` attribute is used when the same method defines several tests, each
    on a different tuple of data. Tuples of data can be specified in several ways
    and are injected into the test as method parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous code can be modified to test `MethodToTest` on several inputs
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Each `InlineData` attribute specifies a tuple to be injected into the method
    parameters. Since just simple constant data can be included as attribute arguments,
    xUnit also gives you the possibility to take all data tuples from a class that
    implements `IEnumerable`, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The type of class that provides the test data is specified with the `ClassData`
    attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also possible to take data from a static method of a class that returns
    `IEnumerable` with the `MemberData` attribute, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `MemberData` attribute is passed the method name as the first parameter,
    and the class type in the `MemberType` named parameter. If the static method is
    part of the same test class, the `MemberType` parameter can be omitted.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection shows how to deal with some advanced preparation and tear-down
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced test preparation and tear-down scenarios
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes, the preparation code contains very time-consuming operations, such
    as opening a connection with a database that doesn’t need to be repeated before
    each test but that can be executed once before all the tests contained in the
    same class. In xUnit, this kind of test preparation code can’t be included in
    the test class constructor; since a different instance of the test class is created
    before every single test, it must be factored out in a separate class called a
    fixture class.
  prefs: []
  type: TYPE_NORMAL
- en: If we also need corresponding tear-down code, the fixture class must implement
    `IDisposable`. In other test frameworks, such as NUnit, the test class instances
    are created just once instead, so they don’t need the fixture code to be factored
    out in other classes. However, test frameworks such as **NUnit**, which do not
    create a new instance before each test, may suffer from bugs because of unwanted
    interactions between test methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of an xUnit fixture class that opens and closes
    a database connection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Since a fixture class instance is created just once before all tests associated
    with the fixture are executed and the same instance is disposed of immediately
    after the tests, then the database connection is created just once when the fixture
    class is created and is disposed of immediately after the tests when the fixture
    object is disposed of.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fixture class is associated with each test class by letting the test class
    implement the empty `IClassFixture<T>` interface as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: A fixture class instance is automatically injected into the test class constructor
    in order to make all data computed in the fixture test preparation available for
    the tests. This way, for instance, in our previous example, we can get the database
    connection instance so that all test methods of the class can use it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to execute some test preparation code on all tests contained in
    a collection of test classes instead of a single test class, we must associate
    the fixture class with an empty class that represents the collection of test classes,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The `CollectionDefinition` attribute declares the name of the collection, and
    the `IClassFixture<T>` interface has been replaced with `ICollectionFixture<T>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we declare that a test class belongs to the previously defined collection
    by applying it to the `Collection` attribute with the name of the collection,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `Collection` attribute declares which collection to use, while the `DataBaseFixture`
    argument in the test class constructor provides an actual fixture class instance,
    so it can be used in all class tests.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have seen how to leverage fixture classes to share setup and cleanup
    code across multiple tests, enhancing our test organization and efficiency, we
    turn our attention to another powerful technique in our testing arsenal. The following
    section introduces the use of the `Moq` framework, a tool that allows us to simulate
    the behavior of complex dependencies in our tests through mocking. This approach
    is crucial for isolating the component we are testing and verifying its behavior
    under controlled conditions without the need for the actual implementations of
    its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking interfaces with Moq
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mocking is a technique used in both unit testing to isolate classes from dependencies
    they have on other classes, so we can impute each test failure to the class under
    test. Classes are isolated from their dependencies by creating a mock or a fake
    version of each dependency.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking capabilities are not included in any of the test frameworks we listed
    in this section, as they are not included in xUnit, so we must add another library
    that offers mocking capability. The `Moq` framework, a popular tool in .NET, makes
    the mocking process super-easy.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore how to use `Moq` to create mocks and set up our tests effectively.
    Here, we will discuss just how to use `Moq` to create mock classes. A practical
    and complete example that shows how to use `Moq` in your tests in practice is
    in the *Testing the WWTravelClub application* section of *Chapter 21*, *Case Study*.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, we need to install the `Moq` NuGet package. Then, we need
    to add a `using Moq` statement to our test files. A mock implementation is easily
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The behavior of the mock dependency on specific inputs of the specific method
    can be defined with the `Setup/Return` method pair as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can add several `Setup/Return` instructions for the same method. This way,
    we can specify an indefinite number of input/output behaviors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of specific input values, we may also use wildcards that match a specific
    type as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Where we replaced `5` with its type, `int`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have configured the mock dependency, we may extract the mocked instance
    from its `Object` property and use it as if it were an actual implementation,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: However, mocked methods are usually called by the code under test, so we just
    need to extract the mocked instance and use it as an input in our tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'We may also mock properties and **async** methods as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: With `async` methods, `Returns` must be replaced by `ReturnsAsync`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each mocked instance records all calls to its methods and properties, so we
    may use this information in our tests. The following code shows an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The preceding statement asserts that `MyMethod` has been invoked with the given
    arguments at least twice. There are also `Times.Never`, and `Times.Once` (which
    asserts that the method was called just once), and more.
  prefs: []
  type: TYPE_NORMAL
- en: The `Moq` documentation summarized up to now should cover 99% of the needs that
    may arise in your tests, but `Moq` also offers more complex options. The *Further
    reading* section contains the link to the complete documentation.
  prefs: []
  type: TYPE_NORMAL
- en: The *Testing the WWTravelClub application* section of *Chapter 21*, *Case Study*,
    shows the practical usage of `Moq` in a complex example.
  prefs: []
  type: TYPE_NORMAL
- en: After exploring the capabilities of `Moq` and how it enhances our unit testing
    with effective mock implementations, we now turn our attention to a different
    facet of C# application testing – automating functional tests in ASP.NET Core
    applications. In this next section, we’ll dive into how various testing tools
    and techniques, including some we’ve just discussed, are applied to ensure our
    ASP.NET Core applications function as intended, both in isolation and when integrated
    with other systems and interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: Automating functional tests in C#
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Automated functional tests use the same test tools as unit and integration tests.
    That is, these tests can be embedded in the same xUnit, NUnit, or MSTest projects
    that we described in the previous section. However, in this case, we must add
    further tools that can interact with and inspect the UI.
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this chapter, we will focus on web applications since they
    are the main focus of this book. Accordingly, if we are testing web APIs, we just
    need `HttpClient` instances since they can easily interact with web API endpoints
    in both XML and JSON.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of applications that return HTML pages, the interaction is more
    complex since we also need tools for parsing and interacting with the HTML page
    DOM tree.
  prefs: []
  type: TYPE_NORMAL
- en: The *Selenium* toolset is a great solution since it has drivers for simulating
    user interaction in all mainstream browsers and for programmatically accessing
    the browser DOM.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two basic options for testing a web application with the `HttpClient`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Staging application**: An `HttpClient` instance connects with the actual
    *staging* web application through the internet/intranet, together with all other
    humans who are beta-testing the software. The advantage of this approach is that
    you are testing the *real stuff*, but tests are more difficult to conceive since
    you can’t control the initial state of the application before each test.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Controlled application**: An `HttpClient` instance connects with a local
    application that is configured, initialized, and launched before every single
    test. This scenario is completely analogous to the unit test scenario. Test results
    are reproducible, the initial state before each test is fixed, tests are easier
    to design, and the actual database can be replaced by a faster and easier-to-initialize
    in-memory database. However, in this case, you are far from the actual system’s
    operation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A good strategy is to use a **controlled application**, where you have full
    control of the initial state, for testing the extreme cases, and then use a **staging
    application** for testing random average cases on the *real stuff*.
  prefs: []
  type: TYPE_NORMAL
- en: The two subsections that follow describe both approaches. The two approaches
    differ only in the way that you define the fixtures of your tests.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the staging application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the case of staging applications, your tests just need a class that can issue
    HTTP requests, which in the case of .NET is the `HttpClient` class. It is enough
    to define an efficient fixture that supplies the needed `HttpClient` instances,
    avoiding the risk of running out of operating system connections. Efficient management
    of the underlying operating system connections can be achieved through the `IHttpClientFactory`
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is enough to add an `HttpClient` management factory to a dependency injection
    container that will be used by the tests with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'where the `AddHttpClient` extension belongs to the `Microsoft.Extensions.DependencyInjection`
    namespace and is defined in the `Microsoft.Extensions.Http` NuGet package. Therefore,
    our test fixture must create a dependency injection container, call the `AddHttpClient`
    extension method, and finally build the container. The following fixture class
    does this job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'After the preceding definition, your tests should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: In `Test1`, once you get an HTTP client, you can test the application by issuing
    an HTTP request and then by analyzing the response returned by the application.
  prefs: []
  type: TYPE_NORMAL
- en: The approach described above is adequate when the HTTP endpoints return data,
    for instance, in JSON format that can be turned into .NET data by a data serializer/deserializer
    and then compared with the expected data.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection describes how to test endpoints that return HTML.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the staging application with Selenium
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most endpoints that return HTML are tested either manually or with playback
    tools, like Selenium IDE, on various browsers. Playback tools record all user
    actions performed on an actual browser and generate code that repeats the same
    action sequences with the help of browser drivers.
  prefs: []
  type: TYPE_NORMAL
- en: However, the code generated by playback tools is too sensitive to the DOM structure
    of each page, so most of the tests must be replaced after each relevant change
    in the user interface.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the code of important and stable UI tests is better created manually
    in a way that is more robust to DOM changes.
  prefs: []
  type: TYPE_NORMAL
- en: For this purpose, the Selenium toolset contains the `Selenium.WebDriver` NuGet
    package and a driver for each browser that you would like to adopt, such as, for
    instance, the `Selenium.WebDriver.ChromeDriver` NuGet package for the Chrome browser.
  prefs: []
  type: TYPE_NORMAL
- en: 'Manual tests based on Selenium WebDriver look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Once the page to test has been loaded, `driver` is used to explore the page
    content and to interact with page elements, like buttons, links, and input fields.
    As shown in the preceding code, the syntax for interacting with the browser is
    quite simple and intuitive. `driver.FindElement` can find elements by CSS class
    name, by ID, and also through generic CSS selectors.
  prefs: []
  type: TYPE_NORMAL
- en: Adding CSS classes that characterize their role with HTML elements is a good
    technique for building robust UI tests.
  prefs: []
  type: TYPE_NORMAL
- en: The next subsection explains how to test an application that runs in a controlled
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Testing a controlled application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this case, we create an ASP.NET Core server within the test application and
    test it with an `HttpClient` instance. The `Microsoft.AspNetCore.Mvc.Testing`
    NuGet package contains all that we need to create both an HTTP client and the
    server running the application.
  prefs: []
  type: TYPE_NORMAL
- en: '`Microsoft.AspNetCore.Mvc.Testing` contains a fixture class that does the job
    of launching a local web server and furnishing a client to interact with it. The
    predefined fixture class is `WebApplicationFactory<T>`. The generic `T` argument
    must be instantiated with the `Program` class of your web project, that is, with
    an entry point for the web application.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tests look like the following class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Program` class must exist and must be defined as public. Otherwise, `WebApplicationFactory`
    has no entry point for starting the application. Therefore, if the code in `Program.cs`
    is not enclosed in a public class, as in the default project scaffolded by Visual
    Studio, you must turn the internal `Program` class automatically generated by
    the C# compile into a public class. This is easily achieved by adding the following
    code at the end of the `Program.cs` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: If you want to analyze the HTML of the returned pages, you must also reference
    **Selenium** NuGet packages, as shown in the previous subsection. We will see
    how to use them in the example in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest way to cope with databases in this type of test is to replace them
    with in-memory databases that are faster and automatically cleared whenever the
    local server is shut down and restarted.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, in-memory databases are not 100% compatible with the actual database
    used, so some tests might fail. Therefore, at least some of the tests might require
    the actual database.
  prefs: []
  type: TYPE_NORMAL
- en: 'When performing tests with actual databases, we must also add all the required
    instructions to clear or recreate from scratch a standard database in the constructor
    of a custom fixture that inherits from `WebApplicationFactory<T>`. Note that deleting
    all database data is not as easy as it might appear, owing to integrity constraints.
    You have various options, but none is the best for all cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Delete the whole database and recreate it using SQL scripts or Entity Framework
    Core migrations, which will be analyzed in *Chapter 13*, *Interacting with Data
    in C# – Entity Framework Core*. This always works, but it is slow and requires
    a database user with high privileges.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enclose a test database in a Docker image and recreate a new container at each
    new test (Docker will be discussed in *Chapter 11*, *Applying a Microservice Architecture
    to Your Enterprise Application*). This is faster than recreating a new database
    from scratch but still slow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Disable the database constraints and then clear all tables in any order. This
    technique sometimes doesn’t work and requires a database user with high privileges.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Delete all data in the right order, thus without violating all database constraints.
    This is not difficult if you keep an ordered delete list of all tables while the
    database grows and you add tables to the database. This delete list is a useful
    resource that you may also use to fix issues in database update operations and
    to remove old entries during production database maintenance. Unfortunately, this
    method also fails in the rare case of circular dependencies, such as a table that
    has a foreign key referring to itself.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I prefer method 4 and revert to method 3 only in the rare case of difficulties
    due to circular dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Recording tests with Selenium IDE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Selenium toolset contains browser extensions for recording and replaying
    browser tests. These are called Selenium IDE. You can download the extensions
    for Chrome and Firefox from [https://www.selenium.dev/selenium-ide/](https://www.selenium.dev/selenium-ide/),
    while the extension for Microsoft Edge is available from [https://microsoftedge.microsoft.com/addons/detail/selenium-ide/ajdpfmkffanmkhejnopjppegokpogffp](https://microsoftedge.microsoft.com/addons/detail/selenium-ide/ajdpfmkffanmkhejnopjppegokpogffp).
  prefs: []
  type: TYPE_NORMAL
- en: 'In Chrome, once installed, Selenium IDE can be run by clicking the extensions
    icon and then selecting the Selenium extension from the menu that appears, as
    shown in the screenshot below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_09_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.3: Running Selenium IDE'
  prefs: []
  type: TYPE_NORMAL
- en: You are prompted for the action you would like to perform, whether to create
    a new project, access an existing project, etc.
  prefs: []
  type: TYPE_NORMAL
- en: When you create a new project, you are prompted for the project name. At this
    point, Selenium IDE opens, and you can insert the application URL.
  prefs: []
  type: TYPE_NORMAL
- en: New tests can be created by clicking the plus button next to the tests list.
  prefs: []
  type: TYPE_NORMAL
- en: In order to record a test, select the test name and then click the record icon.
    A new browser window will open with the application URL. From this point, every
    action you perform on the application and its results will be recorded.
  prefs: []
  type: TYPE_NORMAL
- en: You can make assertions on the page content by right-clicking on a page element
    and selecting the appropriate action from the **Selenium** **IDE > Assert** submenu.
    For instance, if you select the **Selenium IDE > Assert > Text** command on a
    text element, the text value will be stored. When the test is executed, the content
    of the same text element will be compared with the previously stored value, and
    the test will fail if the two values are different.
  prefs: []
  type: TYPE_NORMAL
- en: Once all desired actions and assertions have been performed, return to the Selenium
    IDE window, click the stop recording button, and save the project.
  prefs: []
  type: TYPE_NORMAL
- en: Selenium IDE offers the option to run either a selected test or all tests.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explained why it is worth automating software tests, and
    then we focused on the importance of unit tests. We also listed the various types
    of tests and their main features, focusing mainly on unit tests and functional
    tests. We analyzed the advantages of **TDD** and how to use it in practice. With
    this knowledge, you should be able to produce software that is both reliable and
    easy to modify.
  prefs: []
  type: TYPE_NORMAL
- en: Then, this chapter analyzed when it is worth automating some or all functional
    tests and described how to automate them in `ASP.NET` Core applications.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we analyzed the main test tools available for .NET projects, focusing
    on xUnit, `Moq`, `Microsoft.AspNetCore.Mvc.Testing`, and *Selenium*, and showed
    how to use them in practice with the help of the book’s use case.
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 21*, *Case Study*, applies all the test concepts described in this
    chapter to the book’s case study.'
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why is it worth automating unit tests?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main reason why TDD is able to discover most bugs immediately?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the `[Theory]` and `[Fact]` attributes of xUnit?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which xUnit static class is used in test assertions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which methods allow the definition of the `Moq` mocked dependencies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it possible to mock `async` methods with `Moq`? If so, how?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it always worth automating UI functional tests in the case of quick CI/CD
    cycles?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the disadvantage of subcutaneous tests for ASP.NET Core applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the suggested technique for writing code-driven ASP.NET Core functional
    tests?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the suggested way of inspecting the HTML returned by a server?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the documentation on xUnit included in this chapter is quite complete,
    it doesn’t include a few configuration options offered by xUnit. The full xUnit
    documentation is available at [https://xunit.net/](https://xunit.net/). Documentation
    for MSTest and NUnit can be found at [https://github.com/microsoft/testfx](https://github.com/microsoft/testfx)
    and [https://docs.nunit.org/](https://docs.nunit.org/), respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For more information on BDD and SpecFlow, refer to the Cucumber official website
    at [https://cucumber.io/](https://cucumber.io/) and to the SpecFlow documentation
    at [https://docs.specflow.org/](https://docs.specflow.org/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The full Moq documentation is available at [https://github.com/moq/moq4/wiki/Quickstart](https://github.com/moq/moq4/wiki/Quickstart).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some links to performance test frameworks for web applications:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://jmeter.apache.org/ (free and open source)](https://jmeter.apache.org/)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.neotys.com/neoload/overview](https://www.neotys.com/neoload/overview)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview](https://www.microfocus.com/en-us/products/loadrunner-load-testing/overview)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://www.microfocus.com/en-us/products/silk-performer/overview](https://www.microfocus.com/en-us/products/silk-performer/overview)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More details on the `Microsoft.AspNetCore.Mvc.Testing NuGet` package can be
    found in the official documentation at [https://docs.microsoft.com/en-US/aspnet/core/test/integration-tests](https://docs.microsoft.com/en-US/aspnet/core/test/integration-tests).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More information on Selenium IDE can be found on the official website: [https://www.selenium.dev/selenium-ide/](https://www.selenium.dev/selenium-ide/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More information on Selenium WebDriver can be found on the official website:
    [https://www.selenium.dev/documentation/webdriver/](https://www.selenium.dev/documentation/webdriver/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn more on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To join the Discord community for this book – where you can share feedback,
    ask questions to the authors, and learn about new releases – follow the QR code
    below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/SoftwareArchitectureCSharp12Dotnet8](https://packt.link/SoftwareArchitectureCSharp12Dotnet8)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code175081751210902046.png)'
  prefs: []
  type: TYPE_IMG
