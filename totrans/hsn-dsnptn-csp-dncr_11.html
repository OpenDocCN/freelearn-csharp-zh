<html><head></head><body>
        

                            
                    <h1 class="header-title">Concurrent Programming in .NET Core</h1>
                
            
            
                
<p>In the previous chapter (<a href="232b63cb-5006-431d-8378-b7e2ba4c1119.xhtml">Chapter 7</a>, <em>Implementing Design Patterns for Web Applications - Part 2</em>), we created a sample web application with the help of various patterns for the web. We adapted authorization and authentication mechanisms to secure a web application and discussed <strong>Test-driven development</strong> (<strong>TDD</strong>) to make sure that our code has been tested and is working.</p>
<p>This chapter will discuss the best practices to adopt while performing concurrent programming in .NET Core. In the upcoming sections of this chapter, we will learn about the design patterns relevant for well-organized concurrency in C# and .NET Core applications.</p>
<p>The following topics will be covered in this chapter:</p>
<ul>
<li>Async/Await – Why is blocking bad?</li>
<li>Multithreading and asynchronous programming</li>
<li>Concurrent collections</li>
<li>Patterns and practices – TDD and Parallel LINQ</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Technical requirements</h1>
                
            
            
                
<p>This chapter contains various code examples to explain the concepts. The code is kept simple and is only for demonstration purposes. Most of the examples involve a .NET Core console application written in C#.</p>
<p>The complete source code is available at the following link: <a href="https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-C-and-.NET-Core/tree/master/Chapter8">https://github.com/PacktPublishing/Hands-On-Design-Patterns-with-C-and-.NET-Core/tree/master/Chapter8</a>.</p>
<p>To run and execute the code, you will require the following:</p>
<ul>
<li>Visual Studio 2019 (you can also use Visual Studio 2017)</li>
<li>Setting up .NET Core </li>
<li>SQL Server (the Express Edition is used in this chapter)</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing Visual Studio</h1>
                
            
            
                
<p>To run the code examples, you will need to install Visual Studio (preferred IDE). To do so, you can follow these instructions:</p>
<ol>
<li>Download Visual Studio from the download link mentioned with the installation instructions: <a href="https://docs.microsoft.com/en-us/visualstudio/install/install-visual-studio">https://docs.microsoft.com/en-us/visualstudio/install/install-visual-studio</a>.</li>
<li>Follow the installation instructions mentioned.</li>
<li>Multiple options are available for the Visual Studio installation. Here, we are using Visual Studio for Windows.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Setting up .NET Core</h1>
                
            
            
                
<p class="mce-root">If you do not have .NET Core installed, you will need to follow these instructions:</p>
<ol>
<li class="mce-root">Download .NET Core for Windows at <a href="https://www.microsoft.com/net/download/windows">https://www.microsoft.com/net/download/windows</a>.<a href="https://www.microsoft.com/net/download/windows"/></li>
<li>For multiple versions and a related library, visit <a href="https://dotnet.microsoft.com/download/dotnet-core/2.2">https://dotnet.microsoft.com/download/dotnet-core/2.2</a>.</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Installing SQL Server</h1>
                
            
            
                
<p class="mce-root">If you do not have SQL Server  installed, you can follow these instructions:</p>
<ol>
<li>Download SQL Server from the following link: <a href="https://www.microsoft.com/en-in/download/details.aspx?id=1695">https://www.microsoft.com/en-in/download/details.aspx?id=1695</a>.</li>
<li>You can find installation instructions here: <a href="https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-2017">https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-2017</a>.</li>
</ol>
<p>For troubleshooting and for more information, refer to the following link: <a href="https://www.blackbaud.com/files/support/infinityinstaller/content/installermaster/tkinstallsqlserver2008r2.htm">https://www.blackbaud.com/files/support/infinityinstaller/content/installermaster/tkinstallsqlserver2008r2.htm</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Concurrency in the real world</h1>
                
            
            
                
<p><strong>Concurrency</strong> is a part of our life: it exists in the real world. When we are discussing concurrency, we are referring to multitasking.</p>
<p>In the real world, many of us perform multitasking frequently. For example, we can write a program while speaking on a mobile phone, we can watch a movie while having dinner, and we can sing while reading notations. There are a lot of examples of how we as humans can multitask. Without going into too much scientific detail, we can look at our brain trying to grasp new things while also commanding the other organs of the body to work, such as the heart or our sense of smell, as a form of multitasking. </p>
<p>The same approach applies to our systems (computers). If we think about today's computers, every computer that is available has a CPU of multiple cores (more than one core). This is to allow multiple instructions simultaneously, and let us perform multiple tasks at once.</p>
<p>True parallelism is not possible on a single CPU machine because tasks are not switchable, as the CPU has a single core. It is only possible on a machine with multiple CPUs (multiple cores). In simple terms, concurrent programming involves two things:</p>
<ul>
<li><strong>Task management</strong>: Managing/distributing work units to available threads.</li>
<li><strong>Communication</strong>: This sets up the initial parameter of the task and gets the results.</li>
</ul>
<p>Whenever things/tasks are happening at the same time, we call this <em>concurrency</em>. In our programming language, whenever any parts of our program run at the same time, this is called concurrent programming. You can also use <strong>parallel programming</strong> as a synonym for concurrent programming.</p>
<p class="CDPAlignLeft CDPAlign">As an example, imagine a big conference that you need a ticket for, to gain entry into a specific conference hall. At the gate of a conference hall, you have to buy a ticket, making a payment with cash or by card. While you're making a payment, the counter assistant could enter your details into the system, print an invoice, and provide you with the ticket. Now consider that there are more people who want to buy a ticket. Each person has to perform the required activities to collect the ticket from the ticket counter. In this case, only one person can be served at a time from one counter, and the rest of the people wait for their turn. Let's assume that one person takes two minutes to collect their ticket from the counter; the next person, therefore, needs to wait for two minutes for their turn. Consider the wait time of the last person in line if it is a queue of 50 people. Things can be changed here. If there were two more ticket counters and every counter is performing the tasks in two minutes, this means that every two minutes, three people will be able to collect three tickets—or three counters are selling two tickets every two minutes. In other words, every ticket counter is performing the same task (that is, ticket selling) at the same point in time. This means all counters are served in parallel; therefore, they are concurrent. This is depicted in the following diagram:</p>
<div><img src="img/3375a9cf-5b1e-4100-bbe2-078e2b0da4a3.png" style=""/></div>
<p>In the preceding diagram, it is clearly shown that every person who is in the queue is either in the wait position or is active at the counter, and there are three queues in which tasks are happening in a sequence. All three counters (<kbd>CounterA</kbd>, <kbd>CounterB</kbd>, and <kbd>CounterC</kbd>) are performing tasks at the same point in time—they are doing the activities in parallel.</p>
<div><strong>Concurrency</strong> is when two or more tasks start, run, and complete in overlapping time periods.<br/>
<strong>Parallelism</strong> is when two or more tasks run at the same time.</div>
<p>These are concurrent activities, but think of a scenario in which a huge amount of people are in the queue (for example, 10,000 people); there is no use in performing parallelism here, as this would not resolve the issue of a likely bottleneck in this operation. On the other hand, you can increase the number of counters to 50. Will they resolve this problem? These kinds of problems would occur while we work with any software. This is an issue that is related to blocking. In the upcoming sections, we will discuss concurrent programming in more detail.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Multithreading and asynchronous programming</h1>
                
            
            
                
<p>To put it simply, we can say that multithreading means that a program is running parallel on multiple threads. In asynchronous programming, a unit of work runs separately from the main application thread, and it tells the calling thread that the task has completed, failed, or is in progress. The interesting issues to consider around asynchronous programming are when we should use it and what its benefits are.</p>
<p>The potential for more than one thread to access the same shared data and update it with unpredictable results can be referred to as a <strong>race condition</strong>. We have already discussed race condition in <a href="4f644693-85a7-4543-af8c-109d8519b2e5.xhtml">Chapter 4</a>, <em>Implementing Design Patterns - Basics Part 2</em>.</p>
<p>Consider the scenario we discussed in the previous section, in which people from a queue are collecting their tickets. Let's try to capture this scenario in a multithreading program:</p>
<pre>internal class TicketCounter<br/>{<br/>    public static void CounterA() =&gt; Console.WriteLine("Person A is collecting ticket from Counter A");<br/>    public static void CounterB() =&gt; Console.WriteLine("Person B is collecting ticket from Counter B");<br/>    public static void CounterC() =&gt; Console.WriteLine("Person C is collecting ticket from Counter C");<br/>}</pre>
<p>Here, we have a <kbd>TicketCounter</kbd> class that represents our whole set up of ticket collecting counters (we discussed these in the previous section). The three methods: <kbd>CounterA()</kbd>, <kbd>CounterB()</kbd>, and <kbd>CounterC()</kbd> represent an individual ticket collection counter. These methods are simply writing a message to the console, as shown in the following code:</p>
<pre>internal class Program<br/>{<br/>    private static void Main(string[] args)<br/>    {<br/>        var counterA = new Thread(TicketCounter.CounterA);<br/>        var counterB = new Thread(TicketCounter.CounterB);<br/>        var counterC = new Thread(TicketCounter.CounterC);<br/>        Console.WriteLine("3-counters are serving...");<br/>        counterA.Start();<br/>        counterB.Start();<br/>        counterC.Start();<br/>        Console.WriteLine("Next person from row");<br/>        Console.ReadLine();<br/>    }<br/>}</pre>
<p>The preceding code is our <kbd>Program</kbd> class that is initiating the activities from within the <kbd>Main</kbd> method. Here, we declared and started three threads for all the counters. Note that we have started these threads in a sequence/order. As we are expect that these threads will execute in the same sequence, let's run the program and see the output, as shown in the following screenshot:</p>
<div><img src="img/fa77cf94-ea4a-42d7-bc79-a195f4d235f4.png" style=""/></div>
<p>The preceding program is not executed as per the given sequence in the code. As per our code, the execution sequence should be as follows:</p>
<pre>3-counters are serving...<br/>Next person from row<br/>Person A is collecting ticket from Counter A<br/>Person B is collecting ticket from Counter B<br/>Person C is collecting ticket from Counter C</pre>
<p>This is due to threads, and these threads are working simultaneously without the guarantee that these should execute in the order/sequence that they have been declared/started in. </p>
<p>Once again, run the program and see whether we get the same output:</p>
<div><img src="img/90eeaf02-4eb6-48ac-9280-ebae4931624c.png" style=""/></div>
<p>The preceding snapshot is showing a different output from the previous results, so now we have the output in sequence/order:</p>
<pre>3-counters are serving...<br/>Person A is collecting ticket from Counter A<br/>Person B is collecting ticket from Counter B<br/>Next person from row<br/>Person C is collecting ticket from Counter C</pre>
<p>So, the threads are working, but not in the sequence we defined them.</p>
<p>You can set the priorities of threads like this: <kbd>counterC.Priority = ThreadPriority.Highest;</kbd>, <kbd>counterB.Priority = ThreadPriority.Normal;</kbd>, and <kbd>counterA.Priority = ThreadPriority.Lowest;</kbd>.</p>
<p>To run the threads in a synchronized way, let's modify our code as follows:</p>
<pre>internal class SynchronizedTicketCounter<br/>{<br/>    public void ShowMessage()<br/>    {<br/>        int personsInQueue = 5; <strong>//assume maximum persons in queue</strong><br/><strong>        lock (this)</strong><br/>        {<br/>            Thread thread = Thread.CurrentThread;<br/>            for (int personCount = 0; personCount &lt; personsInQueue; personCount++)<br/>            {<br/>                Console.WriteLine($"\tPerson {personCount + 1} is collecting ticket from counter {thread.Name}.");<br/>            }<br/>        }<br/>    }<br/>}</pre>
<p>We created a new <kbd>SynchronizedTicketCounter</kbd>  class with the <kbd>ShowMessage()</kbd> method; please note the <kbd>lock(this){...}</kbd> in the preceding code. Run the program and check the output:</p>
<div><img src="img/485977ff-b745-40fa-9d36-b62b53858573.png" style=""/></div>
<p>We have the output we expected now that our counters are serving in the right sequence/order.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Async/Await – why is blocking bad?</h1>
                
            
            
                
<p>Asynchronous programming is very helpful in cases where we are expecting various activities at the same point in time. With the <kbd>async</kbd> keyword, we define our method/operation as asynchronous. Consider the following code snippet:</p>
<pre>internal class AsyncAwait<br/>{<br/>    public async Task ShowMessage()<br/>    {<br/>        Console.WriteLine("\tServing messages!");<br/>        await Task.Delay(1000);<br/>    }<br/>}</pre>
<p>Here, we have a <kbd>AsyncAwait</kbd> class with an <kbd>async</kbd> method, <kbd>ShowMessage()</kbd>. This method is simply printing a message that would show in the console window. Now, whenever we call/consume this method in another code, that part of the code could wait/hold/block the operation until the <kbd>ShowMessage()</kbd> method executes and completes its task. Refer to the following snapshot:</p>
<div><img src="img/664b9a37-4b9d-492a-9c5c-5bf10071d809.png" style=""/></div>
<p>Our previous screenshot says that we have set a delay of 1,000 milliseconds for our <kbd>ShowMessage()</kbd> method. Here, we instructed the program to complete after 1,000 milliseconds. If we try to remove <kbd>await</kbd> from the previous code, Visual Studio will immediately give the warning to put <kbd>await</kbd> back in; see the following snapshot:</p>
<div><img src="img/90f87239-59f6-4cac-9693-651c66c8facd.png" style=""/></div>
<p>With the help of the <kbd>await</kbd> operator, we are using non-blocking API calls. Run the program and see the following output:</p>
<div><img src="img/773d415b-b503-4812-b93d-36d7d3aeb4ed.png" style=""/></div>
<p>We will get the output that is shown in the preceding snapshot.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Concurrent collections</h1>
                
            
            
                
<p class="mce-root">The .NET Core framework provides a variety of collections with which we can use LINQ queries. As a developer, there are far fewer options when looking for thread-safe collections. Without thread-safe collections, it can become difficult for developers when they have to perform multiple operations. In this case, we would meet the race condition that we have already discussed in <a href="4f644693-85a7-4543-af8c-109d8519b2e5.xhtml">Chapter 4</a>, <em>Implementing Design Patterns - Basics Part 2</em>. To overcome such situations, we need to use the <kbd>lock</kbd> statement, as we have used in the previous section. For example, we can write a code of a simplified implementation of the <kbd>lock</kbd> statement—refer to the following code snippet, where we have used the <kbd>lock</kbd> statement and collection class, <kbd>Dictionary</kbd>:</p>
<pre>public bool UpdateQuantity(string name, int quantity)<br/>{<br/>    <strong>lock (_lock)</strong><br/>    {<br/>        _books[name].Quantity += quantity;<br/>    }<br/><br/>    return true;<br/>}</pre>
<p class="mce-root">The preceding code is from <kbd>InventoryContext</kbd>; in this code, we are blocking other threads from locking the operation in which we are trying to update the quantity.</p>
<p>The main drawback of the <kbd>Dictionary</kbd> collection class is that it is not thread-safe. We have to use this in the <kbd>lock</kbd> statement while we're using <kbd>Dictionary</kbd> with multiple threads. To make our code thread-safe, we can use the <kbd>ConcurrentDictionary</kbd> collection class.</p>
<p class="mce-root"><kbd>ConcurrentDictionary</kbd> is a thread-safe collection class and stores key-value pairs. This class has the implementation for the <kbd>lock</kbd> statement and provides a thread-safe class. Consider the following code:</p>
<pre class="mce-root">private readonly IDictionary&lt;string, Book&gt; _books;<br/>protected InventoryContext()<br/>{<br/>    _books = new ConcurrentDictionary&lt;string, Book&gt;();<br/>}</pre>
<p class="mce-root">The preceding code snippet is from the <kbd>InventoryContext</kbd> class of our FlixOne console application. In this code, we have the <kbd>_books</kbd> field, and it is initialized as a <kbd>ConcurrentDictionary</kbd> collection class.</p>
<p class="mce-root">As we are using the <kbd>UpdateQuantity()</kbd> method of the <kbd>InventoryContext</kbd> class in multithreads, there is a chance that one thread adds the quantity, while the other thread resets the quantity to its initial level. This happens because our object is from a single collection, and any changes to the collection in one thread are not visible to the other threads. All threads are referencing the original unmodified collection, and, in simple terms, our method is not thread-safe, unless we use the <kbd>lock</kbd> statement or the <kbd>ConcurretDictionary</kbd> collection class.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Patterns and practices – TDD and Parallel LINQ</h1>
                
            
            
                
<p>While we work with multithreading, we should follow best practices to write a <strong>smooth code</strong>. A smooth code is where a developer doesn't face deadlock. In other words, multithreading requires a lot of care during the writing process. </p>
<p>While multiple threads are running in a class/program, deadlock occurs when each thread approaches the object or resource written under a <kbd>lock</kbd> statement. The actual deadlock occurs when each thread approaches to lock an object/resource that is already locked by another thread.</p>
<p>A small mistake can result in developers having to tackle unknown bugs that occur due to threads that are blocked. In addition to this, a bad implementation of a few words in the code can impact 100 lines of code. </p>
<p>Let's go back to our example of conference tickets, which we discussed at the beginning of this chapter. What would happen if ticket counters are unable to serve their purpose and distribute tickets? In this scenario, each person would try to reach a ticket counter and obtain a ticket, which could jam the ticket counter. This could cause the ticket counter to become blocked. The same logic applies to our program. We'd meet a deadlock situation in which multiple threads would try to lock our object/resource. The best practice to use to avoid such a condition is using a mechanism that synchronizes access to the object/resource. The .NET Core framework provides a <kbd>Monitor</kbd> class to achieve this. I have rewritten our old code to avoid a deadlock situation—see the following code:</p>
<pre>private static void ProcessTickets()<br/>{<br/>    var ticketCounter = new TicketCounter();<br/>    var counterA = new Thread(ticketCounter.ShowMessage);<br/>    var counterB = new Thread(ticketCounter.ShowMessage);<br/>    var counterC = new Thread(ticketCounter.ShowMessage);<br/>    counterA.Name = "A";<br/>    counterB.Name = "B";<br/>    counterC.Name = "C";<br/>    counterA.Start();<br/>    counterB.Start();<br/>    counterC.Start();<br/>}</pre>
<p>Here, we have the <kbd>ProcessTicket</kbd> method; it starts three threads (each thread represents each ticket counter). Every thread is reaching to <kbd>ShowMessage</kbd> of the <kbd>TicketCounter</kbd> class. There will be a problem of deadlock if our <kbd>ShowMessage</kbd> method is not written well to handle this situation. All three threads will try to acquire a lock for the respective object/resource related to the <kbd>ShowMessage</kbd> method.</p>
<p>The following code is the implementation of the <kbd>ShowMessage</kbd> method, and I have written this code to handle a deadlock situation:</p>
<pre>private static readonly object Object = new object();<br/>public void ShowMessage()<br/>{<br/>    const int personsInQueue = 5;<br/>    if (<strong>Monitor.TryEnter(Object, 300)</strong>)<br/>    {<br/>        try<br/>        {<br/>            var thread = Thread.CurrentThread;<br/>            for (var personCount = 0; personCount &lt; personsInQueue; personCount++)<br/>                Console.WriteLine(<br/>                    $"\tPerson {personCount + 1} is collecting ticket from counter {thread.Name}.");<br/>        }<br/>        finally<br/>        {<br/>            Monitor.Exit(Object);<br/>        }<br/>    }<br/>}</pre>
<p>The preceding is the <kbd>ShowMessage()</kbd> method of our <kbd>TicketCounter</kbd> class. In this method, whenever a thread will try to lock <kbd>Object</kbd>, if <kbd>Object</kbd> is already locked, it tries for 300 milliseconds. The <kbd>Monitor</kbd> class handles this situation automatically. When using the <kbd>Monitor</kbd> class, the developer does not need to worry about a situation in which multiple threads are running, and each of these threads is trying to acquire the lock. Run the program to see the following output:</p>
<div><img src="img/b5992517-e5e5-490e-bb0a-ef9d708e0994.png" style=""/></div>
<p>In the preceding snapshot, you will notice that after <kbd>counterA</kbd>, <kbd>counterC</kbd> is serving and then <kbd>counter B</kbd>. This means that after <kbd>thread A</kbd>, <kbd>thread C</kbd> was initiated, and then <kbd>thread B</kbd>. In other words, <kbd>thread A</kbd> acquires the lock first, and after 300 milliseconds, <kbd>thread C</kbd> tries to lock, and then <kbd>thread B</kbd> tries to lock the object. If you want to set the order or priorities of the thread, you can add the following lines of code:</p>
<pre>counterC.Priority = ThreadPriority.Highest<br/>counterB.Priority = ThreadPriority.Normal;<br/>counterA.Priority = ThreadPriority.Lowest;</pre>
<p>When you add the preceding lines to the <kbd>ProcessTickets</kbd> method, all the threads will work: first <kbd>Thread C</kbd>, then <kbd>Thread B</kbd>, and, finally, <kbd>Thread A</kbd>.</p>
<p>Thread priorities are an enum that tells us how to schedule the thread and <kbd>System.Threading.ThreadPriority</kbd> with the following values:<br/>
<ul>
<li><strong>Lowest</strong>: This is the least priority, which means threads with the <kbd>Lowest</kbd> priority can be scheduled after the threads of any other priority.</li>
<li><strong>BelowNormal</strong>: Threads with a <kbd>BelowNormal</kbd> priority can be scheduled after threads having a <kbd>Normal</kbd> priority, but before threads having the <kbd>Lowest</kbd> priority.</li>
<li><strong>Normal</strong>: All threads are having the default priority as <kbd>Normal</kbd>. Threads with a <kbd>Normal</kbd> priority can be scheduled after threads having an <kbd>AboveNormal</kbd> priority, but before those threads that have a <kbd>BelowNormal</kbd> priority.</li>
<li><strong>AboveNormal</strong>: Threads with an <kbd>AboveNormal</kbd> priority can be scheduled before threads having a <kbd>Normal</kbd> priority, but after threads having the <kbd>Highest</kbd> priority.</li>
<li><strong>Highest</strong>: This is the top-most priority level of threads. Threads with the <kbd>Highest</kbd> priority can be scheduled before threads having any other priority.</li>
</ul>
</p>
<p>After setting a priority level for the threads, execute the program and see the following output:</p>
<div><img src="img/ceaf2e4f-1185-4ac0-aa88-bf90055500bf.png" style=""/></div>
<p>As per the preceding snapshot, after setting the priority, the counters are serving in the order <kbd>C</kbd>, <kbd>B</kbd>, and <kbd>A</kbd>. With a little caution and simple implementation, we can handle a deadlock situation as well as schedule our threads to be served in a specific order/priority.</p>
<p>The .Net Core framework also provides a <strong>Task Parallel Library</strong> (<strong>TPL</strong>) that is a set of public APIs that belong to the <kbd>System.Threading</kbd> and <kbd>System.Threading.Tasks</kbd> namespaces. With the help of TPL, developers can make applications concurrent by adapting its simplification implementation.</p>
<p>Considering the following code, we can see the simplest implementation of a TPL:</p>
<pre>public void PallelVersion()<br/>{<br/>    var books = GetBooks();<br/>    Parallel.ForEach(books, Process);<br/>}</pre>
<p>The preceding is a simple <kbd>ForEach</kbd> loop using a <kbd>Parallel</kbd> keyword. In the preceding code, we are just iterating a collection of <kbd>books</kbd> and processing it with the use of the <kbd>Process</kbd> method:</p>
<pre>private void Process(Book book)<br/>{<br/>    Console.WriteLine($"\t{book.Id}\t{book.Name}\t{book.Quantity}");<br/>}</pre>
<p>The preceding code is our <kbd>Process</kbd> method (again, the simplest one), and it prints the details of the <kbd>books</kbd>. As per their requirement, users can perform as many actions as they want:</p>
<pre>private static void ParallelismExample()<br/>{<br/>    var parallelism = new Parallelism();<br/>    parallelism.GenerateBooks(19);<br/>    Console.WriteLine("\n\tId\tName\tQty\n");<br/>    parallelism.PallelVersion();<br/>    Console.WriteLine($"\n\tTotal Processes Running on the machine:{Environment.ProcessorCount}\n");<br/>    Console.WriteLine("\tProcessing complete. Press any key to exit.");<br/>    Console.ReadKey();<br/>}</pre>
<p>As you can see, we have the <kbd>ParallelismExample</kbd> method, and it generates the book list and processes the books by executing the <kbd>PallelVersion</kbd> method.</p>
<p>Before you execute the program to see the following output, first consider the following code snippet of sequential implementation:</p>
<pre>public void Sequential()<br/>{<br/>    var books = GetBooks();<br/>    foreach (var book in books) { Process(book); }<br/>}</pre>
<p>The preceding code is a <kbd>Sequential</kbd> method; it uses a simple <kbd>foreach</kbd> loop to process the book collections. Execute the program and see the following output:</p>
<div><img src="img/fcc24a14-5414-42e8-b803-a9dc83c0429f.png" style=""/></div>
<p>Take note of the preceding snapshot. First, there are four processes running in the system on which I am running this demo. The second iterated collection is in a sequence/order from 1 to 19. The program does not divide the tasks into different processes running on the machine. Press any key to exit from the current process, execute the program for the <kbd>ParallelismVersion</kbd> method, and see the following output:</p>
<div><img src="img/a2119c1f-765c-4c1f-8350-971f9b585cab.png" style=""/></div>
<p>The preceding screenshot is of an output from a parallel code; you may notice that the code is not processed in sequence and the IDs are not coming through in sequence/order, as we can see <kbd>Id</kbd> <kbd>13</kbd> comes after <kbd>9</kbd> but before <kbd>10</kbd>. If these were running in sequence, then the order of the <kbd>Id</kbd>s would be <kbd>9</kbd>, <kbd>10</kbd>, and then <kbd>13</kbd>.</p>
<p class="mce-root">LINQ was in the .NET world a long time before the birth of .NET Core. <kbd>LINQ-to-Objects</kbd> allows us to perform in-memory query operations by using arbitrary sequences of objects. <kbd>LINQ-to-Objects</kbd> is a collection of extension methods on top of <kbd>IEnumerable&lt;T&gt;</kbd>.</p>
<div><strong>Deferred execution</strong> means execution happens once the data is enumerated.</div>
<p class="mce-root">PLINQ can be used as an alternative to TPL. It is a parallel implementation of LINQ. The PLINQ query operates on in-memory <kbd>IEnumerable</kbd> or <kbd>IEnumerable&lt;T&gt;</kbd> data sources. Also, it has a deferred execution. The LINQ query performs operations in sequence, while PLINQ executes operations in parallel and makes full use of all the processors on the machine. Consider the following code to see the implementation of PLINQ:</p>
<pre class="mce-root">public void Process()<br/>{<br/>    var bookCount = 50000;<br/>    _parallelism.GenerateBooks(bookCount);<br/>    var books = _parallelism.GetBooks();<br/>    var query = from book in books.AsParallel()<br/>        where book.Quantity &gt; 12250<br/>        select book;<br/>    Console.WriteLine($"\n\t{query.Count()} books out of {bookCount} total books," +<br/>                      "having Qty in stock more than 12250.");<br/>    Console.ReadKey();<br/>}</pre>
<p>The preceding code is the process method of our PLINQ class. Here, we are using PLINQ to query any books in stock with a quantity of more than <kbd>12250</kbd>. Execute the code to see this output:</p>
<div><img src="img/e1c27ddb-a490-46ce-8df1-1ade2ec4f248.png" style=""/></div>
<p>PLINQ uses all the processors of a machine, but we can limit the processors in PLINQ by using the <kbd>WithDegreeOfParallelism()</kbd> method. We can use the following code in our <kbd>Process ()</kbd> method of the <kbd>Linq</kbd> class:</p>
<pre>var query = from book in books.AsParallel().WithDegreeOfParallelism(3)<br/>    where book.Quantity &gt; 12250<br/>    select book;<br/>return query;</pre>
<p>The preceding code will use only three processors of the machine. Execute them, and you'll find that you get the same output as in the case of the previous code.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p class="mce-root">In this chapter, we discussed concurrent programming and concurrency in the real world. We looked at how we can handle various scenarios related to concurrency in our day-to-day life. We looked at collecting conference tickets from serving counters, and we understood what parallel programming and concurrent programming are. We have also covered multithreading, <kbd>Async</kbd>/<kbd>Await</kbd>, <kbd>Concurrent</kbd> collection, and PLINQ.</p>
<p>In the upcoming chapter, we will get a taste of functional programming using the C# language. We will dive deeper into the concepts that show us how to use C# in .NET Core to perform functional programming.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Questions</h1>
                
            
            
                
<p class="mce-root">The following questions will allow you to consolidate the information contained in this chapter:</p>
<ol>
<li class="mce-root">What is concurrent programming?</li>
<li>How does true parallelism happen?</li>
<li>What is the race condition?</li>
<li>Why should we use a concurrent dictionary?</li>
</ol>


            

            
        
    

        

                            
                    <h1 class="header-title">Further reading</h1>
                
            
            
                
<p>The following book will help you learn more about the topics that have been covered in this chapter:</p>
<ul>
<li><em>Concurrent Patterns and Best Practices</em>, by <em>Atul S Khot</em>, published by <em>Packt Publishing</em>: <a href="https://www.packtpub.com/in/application-development/concurrent-patterns-and-best-practices">https://www.packtpub.com/in/application-development/concurrent-patterns-and-best-practices</a></li>
</ul>
<p> </p>


            

            
        
    </body></html>