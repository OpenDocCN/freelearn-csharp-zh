- en: Chapter 8. Concurrent and Parallel Programming under .NET
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 .NET下的并发与并行编程
- en: 'So far, we have been mostly focusing on the GoF design patterns. When the catalog
    appeared, the computing world was mostly sequential, and the bias was reflected
    in the catalog. The world has changed a lot since the publication of the catalog
    in 1994\. There was a shift towards language-level concurrency and parallelism
    due to the arrival of the Java and C# programming languages. The processor designers
    understood the limits of constructing powerful single-core CPUs, and began focusing
    on many core CPUs. This brought its own set of complexity in developing software
    using the existing paradigms. Even a language like C++, which relegated concurrency
    to libraries, added language-level concurrency features in its latest avatar,
    C++ 11/14\. With the advent of functional programming features into the OOP world,
    the programming landscape changed drastically. In this chapter, you will learn
    some techniques for writing concurrent and parallel programs using the C# programming
    language and .NET platform features. In this chapter, we will cover the following
    points:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们主要关注GoF设计模式。当目录出现时，计算世界主要是顺序的，这种偏见在目录中得到了体现。自1994年目录出版以来，世界发生了很大变化。由于Java和C#编程语言的到来，语言级别的并发和并行性开始转向。处理器设计师认识到构建强大单核CPU的局限性，并开始关注多核CPU。这给使用现有范式开发软件带来了自己的复杂性。即使是C++这样的语言，也将并发委托给库，也在其最新版本C++
    11/14中增加了语言级别的并发特性。随着函数式编程特性进入面向对象的世界，编程景观发生了巨大变化。在本章中，你将学习使用C#编程语言和.NET平台特性编写并发和并行程序的一些技术。在本章中，我们将涵盖以下内容：
- en: Factors that influenced evolution of concurrency and parallelization models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 影响并发和并行化模型演变的因素
- en: Concurrency versus Parallelism
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发与并行
- en: .NET Parallel Programming libraries
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: .NET并行编程库
- en: Some Parallel/Concurrent memes/idioms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些并行/并发谚语/习语
- en: Embarrassingly parallel
  id: totrans-6
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令人尴尬的并行性
- en: Fork/join parallelism
  id: totrans-7
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fork/join并行性
- en: Producer/consumer paradigm
  id: totrans-8
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产者/消费者范式
- en: Days of Free Lunch
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自由午餐的日子
- en: 'The celebrated Moore''s law went on despite microprocessors hitting the clock-speed
    limits in terms of heat dissipation and achieving fabrications beyond nano-level.
    CPU designers found an intelligent workaround for this roadblock-that of leveraging
    the increased chip densities to scale the computation infrastructure horizontally
    as opposed to the traditional vertical way. This principle has deep consequences
    in modern day architecture and design, where application scalability (both vertical
    and horizontal) inherits natural elasticity with respect to the infrastructure
    that powers them. What resulted was a new generation of CPU architectures including
    hyper-threading, multi-core, and many-core. It wasn''t too late before the developers
    realized that the **Free Lunch** (just leveraging the conventional CPU performance
    gains through clock speed, execution optimization, and cache, with no change in
    their programs) was over. Herb Sutter wrote an influential article in Dr. Dobb''s
    Journal about this, aptly titled, *The Free Lunch Is Over: A Fundamental Turn
    toward Concurrency in Software*!'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 著名的摩尔定律尽管在散热和达到纳米级以下制造工艺方面达到了时钟速度的限制，但仍在继续。CPU设计师找到了一个聪明的解决方案来克服这个障碍——利用增加的芯片密度来水平扩展计算基础设施，而不是传统的垂直方式。这一原则在现代架构和设计中有深远的影响，其中应用程序的可扩展性（垂直和水平）与支持它们的底层基础设施具有自然弹性。结果是新一代CPU架构，包括超线程、多核和众核。开发者意识到“免费午餐”（仅仅通过时钟速度、执行优化和缓存利用传统的CPU性能提升，而无需更改他们的程序）已经结束，这并不算晚。Herb
    Sutter在Dr. Dobb's Journal上发表了一篇有影响力的文章，标题恰为《免费午餐结束：软件向并发的根本转变》！
- en: Note
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备注
- en: This realization that software was the gating factor in terms of achieving more
    with most of what was available was the dawn of a new revolution in software architecture
    and design.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这种认识，即软件是利用现有资源实现更多功能的瓶颈，标志着软件架构和设计领域一场新革命的开始。
- en: This new model helped remove many shortcomings in modeling real-world problem
    scenarios. It seemed though that we (developers) began adding justice to the grand
    concurrent design that went into modelling this world with interactions to be
    parallel as opposed to just being sequential and object-oriented. The prevalent
    parallelization techniques (leveraged mostly by the scientific community for doing
    embarrassingly parallel computations)-that of explicit threading with an affinity
    to hardware threads-was primitive and less scalable. Very few people had expertise
    (or rather felt comfortable) in working with the low-level constructs for leveraging
    multi-threading in their applications. This state of affairs brought in a strong
    imperative for creating better abstractions and the needed APIs to write the next
    generation software that would inherently leverage concurrency and parallelism
    to achieve more with most of what was available.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新模型帮助消除了在建模现实世界问题场景中的许多不足。然而，我们（开发者）似乎开始为用交互并行而不是仅仅顺序和面向对象的方式来建模这个世界的大规模并发设计增添正义。普遍采用的并行化技术（主要被科学界用于进行令人尴尬的并行计算）——即与硬件线程关联的显式线程——是原始的且扩展性较差。很少有人具备（或者更确切地说，感到舒适）使用低级结构来利用多线程在他们的应用程序中的专业知识。这种状况促使我们创造更好的抽象和所需的API来编写下一代软件，这种软件将内在地利用并发和并行性，以实现更多功能。
- en: Days of Sponsored Lunch
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 赞助午餐日
- en: Microsoft's .Net **Common Language Runtime** (**CLR**) came to the rescue with
    the managed thread pool (which stabilized around version 2.0), which paved the
    way for a strong foundation layer on top of which the concurrency and parallelization
    models subsequently evolved.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的.NET **公共语言运行时**（**CLR**）通过托管线程池（大约在2.0版本时稳定）提供了帮助，这为在之上构建强大的基础层铺平了道路，随后并发和并行化模型得以发展。
- en: Note
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The most notable ones include **Asynchronous Programming Model** (**APM**),
    **Concurrency and Coordination Runtime** (**CCR**), **Decentralized Software Services**
    (**DSS**), **Parallel LINQ** (**PLINQ**), **Task Parallel Library** (**TPL**),
    and the Task-based Async/Await model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 其中最值得注意的是**异步编程模型**（**APM**）、**并发和协调运行时**（**CCR**）、**去中心化软件服务**（**DSS**）、**并行LINQ**（**PLINQ**）、**任务并行库**（**TPL**）以及基于任务的异步/等待模型。
- en: Certain functional constructs and language features like Anonymous Methods,
    Lambda Expressions, Extension Methods, Anonymous Types, and **Language Integrated
    Query** (**LINQ**) were the core catalysts that aided this evolution. Major contributors
    and SMEs include Erik Meijer for LINQ, Joe Duffy and Jon Skeet for Multithreading
    in .NET), Stephen Toub, Ade Miller, Colin Campbell, and Ralph Johnson for Parallel
    Extensions, and Jeffrey Richter and George Chrysanthakopoulos for CCR.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 某些功能结构和技术特性，如匿名方法、Lambda表达式、扩展方法、匿名类型和**语言集成查询**（**LINQ**），是推动这一演变的催化剂。主要贡献者和专家包括LINQ的Erik
    Meijer，.NET多线程的Joe Duffy和Jon Skeet，Stephen Toub，Ade Miller，Colin Campbell和Ralph
    Johnson，以及CCR的Jeffrey Richter和George Chrysanthakopoulos。
- en: 'Of the aforementioned notable models, the major ones that matured and are advocated
    today are the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述著名模型中，成熟并被今天推崇的主要有以下几点：
- en: Task-based async/await model for concurrency
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发基于任务的异步/等待模型
- en: '**Parallel Extensions** (**PFX**) including PLINQ and TPL for parallelization'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行扩展**（**PFX**）包括PLINQ和TPL用于并行化'
- en: '![Days of Sponsored Lunch](img/B05691_08_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![赞助午餐日](img/B05691_08_01.jpg)'
- en: Concurrent versus parallel
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发与并行
- en: These are two key constructs are often confused by developers, and warrant clear
    demystification. The authors strongly feel that a thorough understanding of this
    distinction holds the key to effective software design for achieving more by effective
    utilization of the available infrastructure (processors, cores, hardware, and
    software threads). Let's start with the classical definition by Rob Pike (inventor
    of the Go programming language), and try to decode its meaning.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个关键结构经常被开发者混淆，并且需要清晰的解释。作者强烈认为，对这种区别的彻底理解是有效软件设计的关键，通过有效利用现有基础设施（处理器、核心、硬件和软件线程）来实现更多功能。让我们从Go编程语言（Go语言的发明者）的经典定义开始，并尝试解码其含义。
- en: '|   | *Parallelization is doing multiple tasks (related or non-related) at
    the same time whereas concurrency is about dealing with lots of things at once.
    Concurrency is about structure; parallelism is about execution. Concurrency provides
    a way to structure a solution to solve a problem that may (but not necessarily)
    be parallelizable.* |   |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '|   | *并行化是同时执行多个任务（相关或不相关），而并发是关于同时处理很多事情。并发是关于结构；并行化是关于执行。并发提供了一种结构化解决方案的方法来解决可能（但不一定是）可并行化的问题。*
    |   |'
- en: '|   | --*Rob Pike* |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Rob Pike* |'
- en: This clearly articulates the difference between these constructs, and goes further
    to illustrate how concurrency, as a model, helps to structure a program by breaking
    it into pieces that can be executed independently. This powerful consequence of
    a concurrent design model facilitates parallelism depending on the hardware support
    available for the program's runtime or compiler infrastructure.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这清楚地阐述了这些结构之间的区别，并进一步说明了并发作为模型如何通过将程序分解成可以独立执行的部分来帮助结构化程序。并发设计模型的这种强大后果根据程序运行时或编译器基础设施可用的硬件支持来促进并行性。
- en: Note
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This further means **write-once**, **run-anywhere**.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这进一步意味着 **一次编写，到处运行**。
- en: The days of Free Lunch are back with this model, where a concurrent program
    can perform better on multiple cores by leveraging parallelization techniques
    (mostly abstracted or under the hood, and is dependent on the framework library
    or runtime that executes these programs). This could be understood very clearly
    as the way an asynchronous programming model works using `async` and `await`.
    This model helps to structure the program by breaking it into pieces that can
    be executed independently. These independent pieces become **tasks** (part of
    the TPL), and are executed simultaneously, leveraging the available hardware (cores
    and threads). Now you see how parallelism becomes an interesting side-effect of
    a concurrent model. This is managed (in terms of the degree of parallelism that
    determines the number of cores to be leveraged for reducing contention) by the
    TPL API and CLR. So, the developer can focus on the core decomposition (with little
    or no shared state) of the process into independent tasks as opposed to getting
    entangled in the low-level constructs (threads and synchronization) for realizing
    concurrency and parallelization. The APIs have evolved quite intelligently to
    support this, thus making the code-base quite expressive, declarative, and readable.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型让“免费午餐”的日子又回来了，其中并发程序可以通过利用并行化技术（大多数情况下是抽象的或在底层，并且依赖于执行这些程序的框架库或运行时）在多个核心上表现得更好。这可以非常清楚地理解为异步编程模型使用
    `async` 和 `await` 的工作方式。这种模型通过将程序分解成可以独立执行的部分来帮助结构化程序。这些独立的部分成为 **任务**（TPL 的一部分），并可以同时执行，利用可用的硬件（核心和线程）。现在你看到了并行性如何成为并发模型的一个有趣的副作用。这由
    TPL API 和 CLR 管理着（在并行化的程度方面，这决定了要利用多少核心以减少竞争），因此，开发者可以专注于将过程的核心分解（具有很少或没有共享状态）到独立的任务中，而不是陷入实现并发和并行化的低级结构（线程和同步）的纠缠中。API
    已经非常智能地进化来支持这一点，从而使代码库非常具有表现力、声明性和可读性。
- en: On the contrary, if you explicitly try to leverage basic naive parallelism (`Parallel.For`
    and PLINQ) for executing the decomposed tasks, there is a good chance you would
    end up blocking your threads, thus curtailing scalability and availability (especially
    for server-side programs).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果你明确尝试利用基本的简单并行性（`Parallel.For` 和 PLINQ）来执行分解的任务，你很可能会阻塞你的线程，从而降低可扩展性和可用性（尤其是对于服务器端程序）。
- en: '|   | *Don''t Block your threads, Make Async I/O work for you* |   |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|   | *不要阻塞你的线程，让异步 I/O 为你工作* |   |'
- en: '|   | --*Stephen Toub/Scott Hanselman* |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Stephen Toub/Scott Hanselman* |'
- en: This is the founding principle on which concurrent programming models work.
    The classic example is Node.js, which has gained prominence as a middleware and
    backend system with its inherent support for async I/O. Again, one needs to understand
    that the benefits are seen more in I/O and asynchronous service executions as
    opposed to long-running CPU-bound tasks (which wouldn't give you the benefit you
    typically desire, as these tend to block, and, in turn, cause thread starvation).
    This is a classic scenario, where developers complain that their program takes
    more time to execute (compared to the serial implementation) when task parallelism
    is employed with `Parallel.For` loops.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是并发编程模型工作的基础原则。经典的例子是Node.js，它凭借其固有的异步I/O支持，成为了一个备受瞩目的中间件和后端系统。再次强调，这种好处更多地体现在I/O和异步服务执行上，而不是长期运行的CPU密集型任务（这些任务通常会导致阻塞，进而引起线程饥饿）。这是一个经典的场景，当使用`Parallel.For`循环进行任务并行时，开发者会抱怨程序执行时间比串行实现更长。
- en: Again, none of these imply that one shouldn't employ high-and low-level constructs
    for task creation, threading, and parallelism. As long as scalability and availability
    is not a high priority, task parallelism, with appropriate partitioning strategies,
    could be very effectively employed. This is because these libraries effectively
    load balance the work across the CLR threads to minimize contention, and maximize
    throughput through work stealing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这些并不意味着在任务创建、线程和并行性方面不应该使用高级和低级构造。只要可扩展性和可用性不是首要任务，通过适当的分区策略，任务并行性可以非常有效地应用。这是因为这些库有效地在CLR线程之间平衡工作负载，以最小化竞争，并通过工作窃取最大化吞吐量。
- en: The consequence of both these models is something to be kept in mind when designing
    effective algorithms that can leverage the best of what you have, and yet, scale.
    We will try to illustrate these in the coming sections.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当设计能够充分利用现有资源并实现扩展的有效算法时，这两种模型的结果是需要考虑的。我们将在接下来的章节中尝试说明这些内容。
- en: Some common patterns of parallel programming
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行编程的一些常见模式
- en: Now that we understand the power that these two models bring, one needs to be
    wary of the responsibility that this power brings forth. Typical abuse of concurrency
    and parallelism in the form of blanket code refactoring are often found counterproductive.
    Patterns become more pertinent in this paradigm, where developers push the limits
    of computing hardware.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了这两种模型带来的力量，我们需要警惕这种力量带来的责任。在并发和并行性方面，常见的滥用形式是全面的代码重构，这往往事倍功半。在这个范式下，模式变得更加相关，因为开发者正在推动计算硬件的极限。
- en: '|   | *Issues of races, deadlocks, livelocks, priority inversions, two-step
    dances, and lock convoys typically have no place in a sequential world, and avoiding
    such issues makes quality patterns all the more important* |   |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|   | *种族问题、死锁、活锁、优先级反转、两步舞和锁车队通常在顺序世界中没有立足之地，避免这些问题使得质量模式变得更加重要* |   |'
- en: '|   | --*Stephen Toub* |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|   | --*Stephen Toub* |'
- en: The authors wish to put in perspective the modelling/decomposition aspects of
    the problem, and illustrate the applicability of some of the key patterns, data
    structures, and synchronization constructs to these so as to aid the programmer
    to leverage concurrency and parallelism to its full potential. For detailed coverage
    in terms of patterns and primitive constructs, the authors strongly recommend
    developers to read *Patterns of Parallel Programming* by Stephen Toub and *Concurrent
    Programming on Windows* by Joe Duffy.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作者希望从建模/分解的角度来审视这个问题，并展示一些关键模式、数据结构和同步构造的适用性，以便帮助程序员充分利用并发和并行性。关于模式和原始构造的详细内容，作者强烈建议开发者阅读Stephen
    Toub的《并行编程模式》和Joe Duffy的《Windows上的并发编程》。
- en: Embarrassingly or conveniently parallel
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 令人尴尬或方便地并行
- en: This is the foremost pattern we would cover. The candidate programs that can
    leverage these are ones that can be easily decomposed into tasks/operations which
    have little or no dependency. This independence makes parallel execution of these
    tasks/operations very convenient. We will stray a bit from the conventional examples
    (that of a ray tracer and matrix multiplication), plus instill a sense of adventure
    and accomplishment in creating an algorithm, which, in turn, is embarrassingly
    parallel in nature.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将要讨论的首要模式。能够利用这些模式的候选程序是那些可以轻易分解为具有很少或没有依赖关系的任务/操作的程序。这种独立性使得这些任务/操作的并行执行非常方便。我们将稍微偏离传统的例子（例如光线追踪和矩阵乘法），同时激发在创建算法时的冒险感和成就感，而这个算法在本质上是非常容易并行化的。
- en: Tip
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: We would be articulating this pattern by creating a C# implementation of the
    *Schönhage-Strassen* algorithm for rapidly multiplying large integers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过创建一个用于快速乘以大整数的C#实现来阐述这个模式，即*Schönhage-Strassen*算法。
- en: Problem statement
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题陈述
- en: As indicated, the problem statement seems straightforward in terms of having
    an ability to multiply large numbers (let's push ourselves a bit by further stating
    astronomically large numbers), which cannot even be represented (64-bit computing
    limit). We have consciously reduced the scope by restricting ourselves to just
    one operation (multiplication) for outlining the pattern. Nothing prevents any
    interested reader who is game to go ahead and implement other operations thereby
    devising their own `BigInteger` version with support for all mathematical operations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如指示，问题陈述在具有乘以大数的能力方面似乎很简单（让我们进一步提出天文数字），这些数甚至无法表示（64位计算限制）。我们有意缩小了范围，仅限于一个操作（乘法）来概述这个模式。任何有兴趣的读者都可以继续实施其他操作，从而设计出自己的`BigInteger`版本，支持所有数学运算。
- en: Solutions approach
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解决方案方法
- en: 'Let''s start by outlining the algorithm to multiply two three-digit sequences
    (**456** and **789**):'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从概述乘以两个三位数序列（**456**和**789**）的算法开始：
- en: '![Solutions approach](img/B05691_08_02.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![解决方案方法](img/B05691_08_02.jpg)'
- en: The Schönhage-Strassen algorithm depends fundamentally on the convolution theorem,
    which provides an efficient way to compute the cyclic convolution of two sequences.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Schönhage-Strassen算法基本依赖于卷积定理，它提供了一种有效的方法来计算两个序列的循环卷积。
- en: Tip
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'The authors wish to take a disclaimer here: the cyclic convolution computation
    is not done in the most efficient way here. The prescribed steps include that
    of taking the **Discrete Fourier Transform** (**DFT**) of each sequence, multiplying
    the resulting vectors element by element, and then taking the **Inverse Discrete
    Fourier Transform** (**IDFT**). In contrast to this, we adopt a naïve and computationally
    intensive algorithmic way. This results in a runtime bit complexity of O(n²) in
    Big-O notation for two *n* digit numbers. The core idea here is to demonstrate
    the intrinsic parallel nature of the algorithm!'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作者在此处声明：循环卷积的计算并不是以最有效的方式进行。规定的步骤包括对每个序列进行**离散傅里叶变换**（**DFT**），然后逐元素相乘结果向量，最后进行**逆离散傅里叶变换**（**IDFT**）。相比之下，我们采用了一种简单且计算密集的算法方式。这导致在Big-O表示法中，对于两个*n*位数字的运行时位复杂度为O(n²)。这里的核心思想是展示算法的内在并行性！
- en: As illustrated, the algorithm to compute the product of two three-digit sequences
    comprises of three major steps. We will look at the problem decomposition in detail,
    and interlude the steps with code to see this pattern in action, leveraging some
    of the core .NET parallelization constructs (specifically, the `For` method of
    the `Parallel` class in TPL-`Parallel.For`). In this process, you will understand
    how task decomposition is done effectively, taking into consideration the algorithmic
    and structural aspects of your application.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，计算两个三位数序列乘积的算法包括三个主要步骤。我们将详细查看问题分解，并在步骤之间插入代码来展示这个模式在实际中的应用，利用一些.NET并行化核心结构（特别是TPL中的`Parallel`类的`For`方法）。在这个过程中，你将了解如何有效地进行任务分解，考虑到你应用程序的算法和结构方面。
- en: Step 1
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 步骤1
- en: We will start off multiplying the two numbers 456 (sequence-1) and 789 (sequence-2)
    using long multiplication with base 10 digits, without performing any carrying.
    The multiplication involves three further sub-steps as illustrated.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始使用基于10位数字的长乘法来乘以两个数456（序列-1）和789（序列-2），不进行任何进位。这个乘法包括三个进一步的子步骤，如上图所示。
- en: '**Step 1.1**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1.1**'
- en: As part of the long multiplication, we multiply the least significant digit
    (9) from sequence-2 with all the digits of sequence-1, producing a sequence 36,
    45, and 54.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作为长乘法的一部分，我们将序列-2中最不显著的数字（9）与序列-1中的所有数字相乘，得到序列36、45和54。
- en: '**Step 1.2**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1.2**'
- en: We multiply the next least significant digit (8) from sequence-2 with all the
    digits of sequence-1, producing a sequence 32, 40, and 48.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将序列-2中下一个最不显著的数字（8）与序列-1中的所有数字相乘，得到序列32、40和48。
- en: '**Step 1.3**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤1.3**'
- en: Finally, we multiply the most significant digit (7) from sequence-2 with all
    the digits of sequence-1, producing a sequence 28, 35, and 42.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将序列-2中最显著的数字（7）与序列-1中的所有数字相乘，得到序列28、35和42。
- en: Step 2
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 步骤2
- en: Add the respective column elements (again without carrying) to obtain the acyclic/linear
    convolution sequence (28, 67, 118, 93, 54) of sequence 1 and 2.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 将相应的列元素（再次不带进位）相加，以获得序列1和2的循环/线性卷积序列（28、67、118、93、54）。
- en: Step 3
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 步骤3
- en: 'Perform the final step: that of doing the carrying operation (for example,
    in the rightmost column, keep the 4 and add the 5 to the column containing 93).
    In the given example, this yields the correct product, 359,784.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 执行最后一步：进行进位操作（例如，在最右列，保留4，并将5加到包含93的列中）。在给定示例中，这得到了正确的产品，359,784。
- en: 'The following is the serial implementation of this algorithm (it faithfully
    follows the preceding steps for clarity):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是该算法的串行实现（为了清晰起见，它忠实于前面的步骤）：
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: In the following `Power` method, we will employ Exponentiation by Squaring Algorithm,
    which relies on the fact that:  *x^y == (x*x)^(y/2)* Using this, we will continuously
    divide the exponent (in this case *y*) by two while squaring the base (in this
    case *x*).That is, in order to find the result of 2^11, we will do [((2*2)*(2*2))*((2*2)*(2*2))]
    * [(2*2)] * [(2)] or, to put it simply, we will do 2^8 * 2^2 * 2^1.This algorithm
    achieves O(log n) efficiency!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的`Power`方法中，我们将使用平方乘法算法，该算法依赖于以下事实：*x^y == (x*x)^(y/2)* 使用这个，我们将持续将指数（在这种情况下*y*）除以二，同时平方基数（在这种情况下*x*）。也就是说，为了找到2^11的结果，我们将做[((2*2)*(2*2))*((2*2)*(2*2))]
    * [(2*2)] * [(2)]，或者简单地说，我们将做2^8 * 2^2 * 2^1。这个算法达到了O(log n)的效率！
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you closely evaluate the code, Step 1 and Step 2 in our algorithm are embarrassingly,
    or rather, conveniently parallelizable. Listed next is the equivalent lock-free
    parallel implementation of the same algorithm. This leverages the TPL `Parallel.For`
    parallelization construct.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细检查代码，我们的算法中的步骤1和步骤2是令人尴尬的，或者说，方便地可并行化。下面是相同算法的等效无锁并行实现。这利用了TPL `Parallel.For`并行化构造。
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Now, to really understand the leverage we got from the `Parallel.For` parallelization
    construct, we have to do a CPU-intensive operation, which would be best achieved
    by computing the power (as opposed to the product) utilizing the multiplication
    algorithm. Imagine solving the wheat and chess problem, or perhaps more, say,
    2^(100,000) (to the power of 100,000) in place of 2^(32). A recursive divide and
    conquer strategy has been applied to compute the exponential (default implementation
    of the `Power` method in the abstract class/product `BigNumOperations`, which
    further uses the overridden, concrete `Multiply` methods of the respective core
    product implementations).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了真正理解我们从`Parallel.For`并行化构造中获得的杠杆作用，我们必须进行一个CPU密集型操作，这最好通过使用乘法算法来计算幂（而不是乘积）来实现。想象一下解决小麦和棋子问题，或者更多，比如说，2^(100,000)（作为2^(32)的替代）的情况。已经应用了递归的分割征服策略来计算指数（抽象类/产品`BigNumOperations`中`Power`方法的默认实现，它进一步使用各自的核产品实现的覆盖，具体的`Multiply`方法）。
- en: 'Can you really compute 2^(100,000) (given our limit of 64-bit arithmetic operations)?
    Well, take a look at the following invocation code and result:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你真的能计算2^(100,000)（考虑到我们的64位算术运算限制）吗？好吧，看看下面的调用代码和结果：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Step 3](img/B05691_08_03.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![步骤3](img/B05691_08_03.jpg)'
- en: Yes!!! It computed the values, and the parallel implementation took around half
    the time as compared to the serial one.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 是的！！！它计算了这些值，并且并行实现的时间大约是串行实现的一半。
- en: Note
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The qualifier here, that of taking half the time, is relative and will depend
    on the availability of cores and resources; it will also vary with environments.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的限定词，即时间减半，是相对的，将取决于核心和资源的可用性；它也会随着环境的不同而变化。
- en: 'Also see how the task granularity seems to utilize the CPU (with all its available
    cores) to the maximum extent possible in the case of parallel execution (towards
    the right-hand side of the usage spectrum in all of the four cores):'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以看到，在并行执行的情况下，任务粒度似乎最大限度地利用了CPU（包括所有可用核心）：
- en: '![Step 3](img/B05691_08_04.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![第3步](img/B05691_08_04.jpg)'
- en: 'The following is a quick summary of the key applicability of best practices
    and patterns in this implementation:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对本实现中最佳实践和模式关键适用性的简要总结：
- en: This is a classic case, where data parallelism (applying a single operation
    to many data elements/inputs) is exploited to the core, and the parallelization
    construct (`Parallel.For`) we have chosen is best suited for this. We could also
    leverage the synchronization primitive `Barrier` (`System.Threading.Barrier`),
    which would enable various sub-tasks to cooperatively work in parallel through
    multiple phases/tasks. A `Barrier` is recommended when the phases are relatively
    large in number.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个典型的案例，其中数据并行性（对许多数据元素/输入应用单个操作）被充分利用到核心，我们选择的并行化构造（`Parallel.For`）最适合这种情况。我们还可以利用同步原语`Barrier`（`System.Threading.Barrier`），它将使各种子任务能够在多个阶段/任务中协同并行工作。当阶段数量相对较多时，推荐使用`Barrier`。
- en: Choose a lock-free task data structure (here, a two dimensional array has been
    utilized to capture the product sequences from each iteration in step 1). The
    operations (reads/writes) are atomic if you examine them closely (including step
    2). This makes the parallelization process very effective, as there wouldn't be
    any synchronization penalties (**locks,** specifically) but a seamless utilization
    of resources (with the inherent load balancing provided by `Parallel.For`). It
    is best to leave `Parallel.For` to calibrate the **degree of parallelism** (**DOP**)
    itself so as to leverage all the available cores, and thereby prevent side-effects
    because of thread starvation or oversubscription. At best, we could specify `ParallelOptions`
    of `Parallel.For` to use `Environment.ProcessorCount` so as to explicitly state
    the usage of one thread per core (a recommended practice in parallelization).
    The biggest limitation would be in terms of the memory required for array allocation
    in this case. You would tend to hit the `OutOfMemory` exception beyond powers
    of 100,000 (again, specific to this algorithm and the associated data structures
    that it employs).
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个无锁的任务数据结构（在这里，使用一个二维数组来捕获第1步中每个迭代的乘积序列）。如果你仔细观察操作（包括第2步），这些操作（读取/写入）是原子的。这使得并行化过程非常有效，因为没有同步惩罚（**锁**），而是资源无缝利用（`Parallel.For`提供的固有负载均衡）。最好让`Parallel.For`自行调整**并行度**（**DOP**），以利用所有可用的核心，从而防止由于线程饥饿或过度订阅而产生的副作用。最佳做法是指定`Parallel.For`的`ParallelOptions`使用`Environment.ProcessorCount`，以明确表示每个核心使用一个线程（并行化中的推荐做法）。在这种情况下，最大的限制是数组分配所需的内存。当超过100,000的幂时，你可能会遇到`OutOfMemory`异常（这又特定于这个算法及其所采用的相关数据结构）。
- en: Fine-grained partitioning of tasks, as part of the decomposition process, enables
    throughput (again, it's a balance that needs to be achieved with careful analysis;
    any attempt to overdo can swing the performance pendulum to the other side).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务细粒度分区作为分解过程的一部分，使吞吐量（再次强调，这是一个需要通过仔细分析来达到的平衡；任何过度尝试都可能使性能摆锤摆向另一侧）。
- en: Choose the data representation in string format to represent really big numbers.
    Of course, you do incur the penalty of data conversion (a necessary evil in this
    case). You could as well create an extension method for string type to support
    these big number operations (perhaps, with a validation for legal numbers).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择字符串格式来表示非常大的数字。当然，你确实会承担数据转换的代价（在这种情况下，这是一个必要的恶）。你也可以为字符串类型创建一个扩展方法来支持这些大数操作（也许，还需要对合法数字进行验证）。
- en: Use of alternate algorithm (reverse long multiplication; that is, reversing
    steps 1.1 through 1.3) to leverage the parallel loop partition counter, which
    is forward only (as its purpose is only to partition, unlike that of a step counter
    in a conventional `for` loop). Restructuring your algorithm is better than tweaking
    the code that was originally designed to run serially.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用替代算法（反向长乘法；即，反转步骤1.1到1.3），以利用仅向前（因为它的目的只是分区，与传统`for`循环中的步骤计数器不同）的并行循环分区计数器。重构你的算法比调整原本设计为串行运行的代码更好。
- en: And finally, leverage the abstract factory GoF design pattern to seamlessly
    support the various implementations (in this case, serial and parallel).
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，利用抽象工厂GoF设计模式无缝地支持各种实现（在这种情况下，串行和并行）。
- en: Fork/join or master/worker
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分叉/连接或主/工作模式
- en: This is a pattern that you generally associate with task parallelism. When there
    are distinct asynchronous operations that can run simultaneously, you can temporarily
    fork a program's flow of control with tasks that can potentially execute in parallel.
    You can then wait for these forked tasks to complete.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个通常与任务并行性相关联的模式。当有可以同时运行的独立异步操作时，你可以暂时通过可以并行执行的任务分叉程序的控制流。然后你可以等待这些分叉的任务完成。
- en: In the Microsoft® .NET Framework, tasks are implemented by the `Task` class
    in the `System.Threading.Tasks` namespace. Unlike threads, new tasks that are
    forked (using the `StartNew` method) don't necessarily begin executing immediately.
    They are managed internally by a task scheduler, and run based on a FIFO manner
    (from a work queue) as cores become available. The `Wait` (for task) and `WaitAll`
    (for task array) method ensures the join operation.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在Microsoft® .NET Framework中，任务是通过`System.Threading.Tasks`命名空间中的`Task`类实现的。与线程不同，使用`StartNew`方法分叉的新任务并不一定立即开始执行。它们由任务调度器内部管理，并在核心可用时按照FIFO方式（从工作队列中）运行。`Wait`（任务）和`WaitAll`（任务数组）方法确保了连接操作。
- en: 'Now, if you try to apply this pattern holistically to our original problem
    statement (to compute the power of big numbers), you will see the potential to
    leverage this for executing the tasks within the major phases (Steps 1, 2, and
    3) concurrently (by forking off tasks), and have the phases blocking (joining
    these forked tasks within each phase) to mirror the sequential ordering (steps
    1, 2, and 3) as advocated by the algorithm. See the following code that does lock-free
    parallel implementation of Schönhage-Strassen Algorithm by leveraging the `System.Threading.Tasks` concurrency
    construct:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你尝试将这个模式全面应用于我们的原始问题陈述（计算大数的幂），你会发现利用这个模式可以并行执行主要阶段（步骤1、2和3）的任务（通过分叉任务），并且让阶段阻塞（在每个阶段内连接这些分叉的任务）来反映算法所倡导的顺序排列（步骤1、2和3）。请看以下代码，它通过利用`System.Threading.Tasks`并发结构实现了Schönhage-Strassen算法的无锁并行实现：
- en: '[PRE4]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The collective sample output along with the preceding code is as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 与前面的代码一起的集体输出如下：
- en: '![Fork/join or master/worker](img/B05691_08_05.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![分叉/连接或主/工作模式](img/B05691_08_05.jpg)'
- en: What we have done here in the preceding code is essentially explicit macro-range
    partitioning with respect to the available cores, and not spinning off in place
    of micro-range partitioning with respect to the outer loop. This is a strategy
    which has to be dealt with carefully, as results would vary with the resources
    available at your disposal. Deliberate calibration can yield much higher throughputs.
    In this context, we come to the next important pattern.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们所做的是关于可用核心的显式宏范围分区，而不是在微范围分区中代替外循环的旋转。这是一个需要谨慎处理的策略，因为结果会随着你可用的资源而变化。经过深思熟虑的校准可以产生更高的吞吐量。在这种情况下，我们来到了下一个重要模式。
- en: Speculative execution
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 投射执行
- en: Now that we have seen close to three different implementation strategies of
    the Schönhage-Strassen algorithm, how do we perform deliberate calibration, and
    decide which is the best strategy (now that we understand that it has a close
    co-relation with its environment and associated resources)?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了Schönhage-Strassen算法近三种不同的实现策略，我们如何进行深思熟虑的校准，并决定哪种策略是最佳的（既然我们已经了解到它与环境和相关资源有密切关系）？
- en: Note
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This is where this important pattern really helps us make a decision, when deviations
    against anticipated results are unavoidable, and need to be smartly addressed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是这个重要模式真正帮助我们做出决策的地方，当无法避免地出现与预期结果偏差时，需要巧妙地解决这些问题。
- en: 'We would schedule asynchronous tasks for each of these strategies for execution,
    leverage the `WaitAny` method of the `Task` class to wait for one of the operations
    to complete (one that finishes first), and attempt to cancel all others. On a
    smart-learning front, this could be done periodically to continuously calibrate
    and cache your strategy for mass consumption. It''s an aspect of machine learning
    where the program intelligently adapts to sieve and use effective algorithms.
    See the following code that incorporates options to cancel tasks upon determination
    of the winner by working out who is the fastest:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为这些策略中的每一个调度异步任务以执行，利用`Task`类的`WaitAny`方法等待其中一个操作完成（先完成的一个），并尝试取消所有其他操作。在智能学习方面，这可以定期进行，以持续校准和缓存你的策略以供大量消费。这是机器学习的一个方面，程序可以智能地适应筛选并使用有效的算法。请参阅以下代码，该代码包含在确定胜者后取消任务的选择项，通过计算出谁是最快的来工作：
- en: '[PRE5]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Similarly, concrete products 5 and 6 are created based on constructs employed
    in products 2 and 3\. Please refer the relevant code sections in the companion
    website for these implementations.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，具体产品5和6是基于产品2和3中使用的结构创建的。请参考配套网站上的相关代码部分以了解这些实现。
- en: Now that we have executable parallel code that will respond to user interruptions,
    lets understand how we can do speculative execution.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了可以响应用户中断的可执行并行代码，让我们来了解如何进行推测性执行。
- en: 'It''s quite interesting, or rather an art, how we can achieve control over
    these constructs. It''s just that you need to see through your algorithm, and
    determine how the decomposition helps you gain coarser or finer control on execution.
    You will see areas that pose limitations once you get into the finer intricacies
    of task parallelization and concurrency. You will also see the power of abstraction
    that these constructs bring to the table, and better appreciate the instrumentation
    and hooks that need to go in for aiding you in gaining better control of your
    program, as opposed to letting **heisenbugs** haunt your programs. Let''s observe
    the output that determined the fastest implementation:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 很有趣，或者更确切地说，这是一种艺术，我们如何能够控制这些结构。只是你需要看透你的算法，并确定分解如何帮助你获得对执行的更粗或更细的控制。一旦你进入任务并行化和并发的更精细复杂性，你会看到一些具有局限性的区域。你也会看到这些结构带来的抽象力量，并更好地欣赏那些需要加入以帮助你更好地控制程序的工具和钩子，而不是让**海森堡虫**困扰你的程序。让我们观察确定最快实现的输出：
- en: '![Speculative execution](img/B05691_08_06.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![推测性执行](img/B05691_08_06.jpg)'
- en: Though the `Parallel.For` construct emerged the winner in all the three trials.
    This is not a certainty, as the outcome is determined by the available resources
    and the complexity of the algorithm (in terms of control flow and data flow),
    depending on input data provided. Something interesting has occurred here, which
    warrants an explanation, and will, thereby, demystify certain behaviors. Remember,
    everything ought to have an explanation (unless you are not in control, and have
    absolutely no idea how your code behaves)!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在所有三次试验中`Parallel.For`结构都成为了胜者。但这并不一定，因为结果取决于可用资源和算法的复杂性（从控制流和数据流的角度来看），这取决于提供的输入数据。这里发生了一些有趣的事情，这需要解释，并且因此将揭示某些行为背后的神秘面纱。记住，每件事都应该有一个解释（除非你不在控制之中，并且对你代码的行为一无所知）！
- en: In case you are wondering why the serial implementation got cancelled, before
    it started, only once, it's primarily related to the work load in the machine
    and the precedence/sequence in which the tasks started being executed by the CLR
    thread pool. Also, the reason why the **Tasks Implementation - Cancelled** message
    comes only once is because `Console.WriteLine` blocks until the output has been
    written, as it calls the `Write` method of the underlying stream instance; the
    ones that don't get blocked appear on the console. You also need to ensure that
    the token cancellation detection code (`token.IsCancellationRequested`) is set
    at the required control flow points (forks, joins, and so on) to record near real-time
    cancellations, and throw `TaskCanceledException` via the `token.ThrowIfCancellationRequested`
    method (causing the task to transition to the faulted state). Please inspect the
    highlighted areas in the code to understand this.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道为什么串行实现被取消，在它开始之前，只发生了一次，这主要与机器的工作负载以及CLR线程池开始执行任务的优先级/顺序有关。此外，**任务实现
    - 已取消**消息只出现一次的原因是`Console.WriteLine`会阻塞，直到输出被写入，因为它调用了底层流实例的`Write`方法；那些没有阻塞的会出现在控制台上。你还需要确保在所需的控制流点（分支、合并等）设置了令牌取消检测代码（`token.IsCancellationRequested`），以记录接近实时的取消，并通过`token.ThrowIfCancellationRequested`方法抛出`TaskCanceledException`（导致任务过渡到故障状态）。请检查代码中的高亮区域以理解这一点。
- en: The limitation that we noticed in terms of the missing console messages is something
    that we would need to overcome, as, capturing relevant information during program
    execution is an important horizontal concern, irrespective of the execution model
    (synchronous or asynchronous). Ideally, this activity should happen without impacting
    the normal execution flow, or causing any performance penalties (in terms of blocking
    calls). Asynchronous I/O is typically a standard option used by logging libraries
    to capture information (user and system-driven) behind the scenes. We have already
    dealt with the logging library in [Chapter 3](dn-dsnptn_ch03.html "Chapter 3. A
    Logging Library"), *A Logging Library*, and now we will see how to channel data
    and invoke these libraries asynchronously in the next pattern.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到的一个局限性是缺少控制台消息，这是我们需要克服的，因为，在程序执行期间捕获相关信息是一个重要的横向关注点，无论执行模型是同步还是异步。理想情况下，这项活动应该在不影响正常执行流程或造成任何性能惩罚（就阻塞调用而言）的情况下发生。异步I/O通常是日志库捕获信息（用户和系统驱动的）的标准选项。我们已经在[第3章](dn-dsnptn_ch03.html
    "第3章。日志库") *日志库*中处理了日志库，现在我们将看到如何在下一个模式中异步地传输数据和调用这些库。
- en: Another relevant GoF pattern that could be leveraged here is the visitor pattern,
    where new strategic implementation of the algorithms could be declaratively tried
    out, without flooding consumers with concrete products.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可以在此处利用的相关GoF模式是访问者模式，其中可以声明性地尝试新的算法策略实现，而不会向消费者淹没具体的产品。
- en: Producer/consumer
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生产者/消费者
- en: This is a natural pattern that one can easily relate to from the moment you
    start modelling solutions for real-world problems. It is so intuitive that one
    may fail to appreciate the elegance of it, and yet many times we struggle with
    implementations associated with it.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可以从你开始为现实世界问题建模解决方案的那一刻起就很容易与之相关联的自然模式。它是如此直观，以至于人们可能无法欣赏它的优雅，然而很多时候我们却挣扎于与之相关的实现。
- en: A  producer producing something which a consumer wants is a common scenario
    in software modelling. And this can even happen at multiple levels or stages in
    your data flow. This is a typical pipeline in design parlance, and warrants good
    synchronization between stages. A seamless interplay between the stages in a pipeline
    warrants a regulated handshake, where we don't let consumers starve, and at the
    same time, ensure they are not overfed. Throttling this handshake involves laying
    down a communication protocol (publish-subscribe model, queue-based, and so on),
    which requires some of the boiler-plate concurrency constructs (be it data structures
    or synchronization primitives) to be in place, as opposed to one wiring these
    on their own. We have concurrent data structure starting with .NET 4.0, including
    `BlockingCollection<T>`, `ConcurrentBag<T>`, `ConcurrentDictionary(TKey, TValue)`,
    `ConcurrentQueue<T>,` and `ConcurrentStack<T>`, which help us in this task by
    abstracting out the synchronization pain-points, and giving us just the adequate
    blocking features for a seamless integration of concurrent execution scenarios.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者生产消费者想要的东西是软件建模中的常见场景。这甚至可能发生在你的数据流的多级或阶段中。这在设计术语中是一个典型的流水线，并且需要在各个阶段之间进行良好的同步。流水线阶段之间的无缝交互需要一种规范的握手，我们不让消费者饿死，同时确保他们不会过度饱和。限制这种握手需要制定一个通信协议（发布-订阅模型、基于队列的模型等），这需要一些基本的并发结构（无论是数据结构还是同步原语）就位，而不是单独为它们布线。从.NET
    4.0开始，我们有了并发数据结构，包括`BlockingCollection<T>`、`ConcurrentBag<T>`、`ConcurrentDictionary<TKey,
    TValue>`、`ConcurrentQueue<T>`和`ConcurrentStack<T>`，这些数据结构通过抽象出同步痛点，为我们提供了足够的阻塞特性，以实现并发执行场景的无缝集成。
- en: If you really look at our big-number multiplication algorithm, it involves a
    pipeline too, having three stages. The only thing is that our stages aren't concurrent,
    but serial (this is where, irrespective of the cores you have, you tend to reach
    the point of diminishing returns that Amdahl's law predicts). Additionally, our
    data structure (2D Array) gives non-blocking reads/writes for the concurrent producers
    within each stage.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你真正审视我们的大数乘法算法，它也涉及一个流水线，分为三个阶段。唯一不同的是，我们的阶段不是并行的，而是串行的（这就是无论你有多少核心，你往往会达到阿姆达尔定律预测的收益递减点的所在）。此外，我们的数据结构（二维数组）为每个阶段的并发生产者提供了非阻塞的读写操作。
- en: Note
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The performance of a pipeline implementation is purely determined by the performance
    of its individual stages, and for efficiency, we need a concurrent model for each
    stage (which was achieved in our case).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线实现的性能纯粹取决于其各个阶段的性能，为了效率，我们需要为每个阶段提供一个并发模型（在我们的案例中已经实现）。
- en: Let's look at a producer-consumer model-based implementation for non-blocking
    or asynchronous logging in the case of speculative execution. We want this primarily
    to overcome the limitation of blocking, and console-based stream writes (in production
    you can leverage asynchronous I/O for file or db writes).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看基于生产者-消费者模型实现的非阻塞或异步日志记录，在投机执行的情况下。我们希望这样做主要是为了克服阻塞的限制和基于控制台的流写入（在生产中，你可以利用异步I/O进行文件或数据库写入）。
- en: 'The code for the consumer is shown as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者的代码如下所示：
- en: '[PRE6]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here you can see that we are using a blocking collection to record logs. This
    needs to be passed as another parameter to the implementation, and, in turn, collects
    all the log information.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到我们正在使用一个阻塞集合来记录日志。这需要作为另一个参数传递给实现，并且反过来收集所有的日志信息。
- en: 'The following is an indicative code for the logger (handled in the respective
    concrete products):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对日志记录器（在相应的具体产品中处理）的示例代码：
- en: '[PRE7]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: So, we have seen some of the key patterns that play a major role in modelling
    concurrent tasks that could be run in parallel. Though the narration has been
    primarily based on a single example, we believe that, as a developer, you were
    able to understand the applicability of these in a real-world problem scenario.
    In terms of coverage, there is a lot one needs to learn and prototype. Exception
    handling is a chapter on its own, especially when dealing with concurrent scenarios,
    and that has been avoided for brevity. A sea of threads awaits you. Bon Voyage!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经看到了一些在建模可并行运行的任务中扮演重要角色的关键模式。尽管叙述主要基于一个单一示例，但我们相信，作为一个开发者，你能够理解这些在实际问题场景中的应用。在覆盖范围方面，还有很多需要学习和原型设计。异常处理是一个独立的章节，尤其是在处理并发场景时，为了简洁起见，这部分内容被省略了。一片线程的海洋等待着你去探索。祝你一路顺风！
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we just touched the surface of concurrent and parallel programming
    under .NET. The topic warrants a book dedicated for itself. Now you have enough
    background to learn about writing advanced software using features of the C# programming
    language, like LINQ, lambda, expression trees, extension methods, async/await,
    and so on. The next chapter will deal with the issue of better state management
    by leveraging these tools.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们仅仅触及了.NET下并发和并行编程的表面。这个主题值得有一本专门的书来探讨。现在，你已经有了足够的学习背景，可以学习如何利用C#编程语言的特征来编写高级软件，例如LINQ、lambda表达式、表达式树、扩展方法、async/await等等。下一章将探讨如何利用这些工具来更好地管理状态问题。
