<html><head></head><body><div class="chapter" title="Chapter&#xA0;12.&#xA0;Performance"><div class="titlepage" id="aid-2ACBS2"><div><div><h1 class="title"><a id="ch12"/>Chapter 12. Performance</h1></div></div></div><p>In the previous chapter, we covered the most important security issues related to the Top 10 OWASP initiative, whose goal is, in their own words "to raise awareness about application security by identifying some of the most critical risks facing organizations".</p><p>In this chapter, we're going to review the most common issues that a developer encounters in relation to an application's performance, and we'll also look at which techniques and tips are commonly suggested in order to obtain flexible, responsive, and well-behaved software, with a special emphasis on web performance. We will cover the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Reviewing the concepts behind performance (<span class="strong"><strong>Application Performance Engineering</strong></span>)</li><li class="listitem">We'll look at some of the most interesting tools that we have available in Visual Studio to measure and tune performance, including IntelliTrace and new options, such as PerfTips and Diagnostic Tools</li><li class="listitem">We will also check some of the most useful possibilities available in popular modern browsers in the <span class="strong"><strong>Developer's Tools</strong></span> menu (<span class="emphasis"><em>F12</em></span>)</li><li class="listitem">We'll comment on the most accepted well-known practices for performance and some of the software tools to check bottlenecks</li><li class="listitem">Finally, we'll look at the most common problems in a web application's performance, focusing on the ASP.NET optimization</li></ul></div><div class="section" title="Application Performance Engineering"><div class="titlepage"><div><div><h1 class="title"><a id="ch12lvl1sec72"/>Application Performance Engineering</h1></div></div></div><p>According to Jim Metzler and Steve Taylor, <span class="strong"><strong>Application Performance Engineering</strong></span> (<span class="strong"><strong>APE</strong></span>) covers the roles, skills, activities, practices, tools and deliverables applied at every phase of the application life cycle that<a id="id1049" class="indexterm"/> ensure that an application will be designed, implemented and operationally supported to meet the non-functional performance requirements.</p><p>The keyword in the definition is non-functional. It is assumed that the application works, but some aspects, such as the time taken to perform a transaction or a file upload, should be considered from the very beginning of the life cycle.</p><p>So, the problem can, in<a id="id1050" class="indexterm"/> turn, be divided into several parts:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">On the one hand, we have<a id="id1051" class="indexterm"/> to identify which aspects of the application might produce meaningful <span class="strong"><strong>bottlenecks</strong></span>.</li><li class="listitem">This implies testing the application, and tests can vary depending on the type of application, of course: for example line of business, games, web applications, desktop, and so on. These should lead us to state the application's performance goals in relation to the final production environment.</li><li class="listitem">The development team should be able to handle performance problems that can be solved (or ameliorated) using a proven software technique: turning intermediate code into native code, assembly restructuring, optimizing garbage collector, serializing messages for scalability, asynchronous requests, threads of execution, parallel programming, and so on.</li><li class="listitem">Another aspect is performance metrics. These metrics should be measurable using some performance testing in order to have real insight about the performance goal.</li></ul></div><p>There are many possible performance metrics that we could consider: physical/virtual memory usage, CPU utilization, network and disk operations, database access, execution time, start up time, and so on.</p><p>Each type of application will suggest a distinct set of targets to care about. Also, remember that performance tests should not be carried out until all integration tests are completed.</p><p>Finally, let's say that usually, some tests are considered standard when measuring performance:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Load testing</strong></span>: This is intended to<a id="id1052" class="indexterm"/> test software under heavy loads, such as when you test a website simulating lots of <a id="id1053" class="indexterm"/>users to determine at what point the application's response time degrades or even fails.</li><li class="listitem"><span class="strong"><strong>Stress testing</strong></span>: This is one of the<a id="id1054" class="indexterm"/> tests that your application should pass if it wants to obtain the official "Made for Windows X.x" logo. It's based on putting the system to work beyond its specifications to check where (and how) it fails. It might be by using heavy load (beyond the storage capacity, for example), very complex database queries, or continuous data input into the system or in database loading, and so on.</li><li class="listitem"><span class="strong"><strong>Capacity testing</strong></span>: MSDN Patterns and Practices also include this type of test, which is complementary<a id="id1055" class="indexterm"/> to load testing, in order to determine the server's ultimate failure points, while the load testing checks the result at distinct levels of load and traffic.</li></ul></div><p>In these types of tests, it's important to<a id="id1056" class="indexterm"/> clearly determine what loads to target and to also create a contingency plan for special situations (this is more usual in websites, when, for some reason, a peak in users per second is expected).</p><div class="section" title="The tools"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec127"/>The tools</h2></div></div></div><p>Fortunately, we can count<a id="id1057" class="indexterm"/> on of an entire set of tools in the IDE to carry out these tasks in many ways. As we saw in the first chapter, some of them are available directly when we launch an application in Visual Studio 2015 (all versions, including the Community Edition).</p><p>Refer to the <span class="emphasis"><em>A quick tip on execution and memory analysis of an assembly in Visual Studio 2015</em></span> section in <a class="link" title="Chapter 1. Inside the CLR" href="part0015.xhtml#aid-E9OE2">Chapter 1</a>, <span class="emphasis"><em>Inside the CLR</em></span>, of this book for more details about these tools, including the <span class="strong"><strong>Diagnostic Tools</strong></span> launched by default after any application's execution, showing <span class="strong"><strong>Events</strong></span>, <span class="strong"><strong>CPU Usage</strong></span>, and <span class="strong"><strong>Memory Usage</strong></span>.</p><p>As a reminder, the next screenshot shows the execution of a simple application and the predefined analysis that <span class="strong"><strong>Diagnostic Tools</strong></span> show at runtime:</p><div class="mediaobject"><img src="../Images/image00652.jpeg" alt="The tools"/></div><p style="clear:both; height: 1em;"> </p><p>However, keep in mind that some other tools might be useful as well, such as Fiddler, the traffic sniffer that plays an excellent role when analyzing web performance and request/response<a id="id1058" class="indexterm"/> packets' contents.</p><p>Other tools are programmable, such as the <code class="literal">StopWatch</code> class, which allows us to measure the time that a block of code takes to execute with precision, and we also have Performance Counters, available in .NET since the first versions and Event Tracing for Windows (ETW).</p><p>Even in the system itself, we can find useful elements, such as Event Log (for monitoring behavior—totally programmable in .NET), or external tools explicitly thought of for Windows, such as the suite SysInternals, which we have already mentioned in the first chapter. In this case, one of the most useful tools you'll find is <span class="strong"><strong>PerfMon</strong></span> (<span class="strong"><strong>Performance Monitor</strong></span>), although you may remember that we've mentioned FileMon and RegMon as well.</p><div class="section" title="Advanced options in Visual Studio 2015"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec76"/>Advanced options in Visual Studio 2015</h3></div></div></div><p>The IDE, however—especially<a id="id1059" class="indexterm"/> the 2015 and 2017 versions—contains many more functionalities to check the execution and performance at runtime. Most of this functionality is available through the <span class="strong"><strong>Debug</strong></span> menu options (some at runtime and others in the edition).</p><p>However, one of the most ready-to-use tools available in the editor is a new option called <span class="strong"><strong>Performance Tips</strong></span>, which shows how much time a function took to complete and it's presented in the next piece of code.</p><p>Imagine that we have a<a id="id1060" class="indexterm"/> simple method that reads file information from the disk and then selects those files whose names don't contain spaces. It could be something like this:</p><div class="informalexample"><pre class="programlisting">private static void ReadFiles(string path)
{
    DirectoryInfo di = new DirectoryInfo(path);
    var files = di.EnumerateFiles("*.jpg", 
        SearchOption.AllDirectories).ToArray&lt;FileInfo&gt;();
    var filesWoSpaces = RemoveInvalidNames(files);
    //var filesWoSpaces = RemoveInvalidNamesParallel(files);
    foreach (var item in filesWoSpaces)
    {
        Console.WriteLine(item.FullName);
    }
}</pre></div><p>The <code class="literal">RemoveInvalidNames</code> method uses another simple <code class="literal">CheckFile</code> method. Its code is as follows:</p><div class="informalexample"><pre class="programlisting">private static bool CheckFile(string fileName)
{
    return (fileName.Contains(" ")) ? true : false;
}
private static List&lt;FileInfo&gt; RemoveInvalidNames(FileInfo[] files)
{
    var validNames = new List&lt;FileInfo&gt;();
    foreach (var item in files)
    {
        if (CheckFile(item.Name)==true) {
            validNames.Add(item);
        }
    }
    return validNames;
}</pre></div><p>We could have inserted the <code class="literal">CheckFile</code> functionality inside <code class="literal">RemoveInvalidNames</code>, but applying the single responsibility principle has some advantages here, as we will see.</p><p>Since the selection of files will take some time, if we establish a breakpoint right before the <code class="literal">foreach</code> loop, we will be informed of the time in one of these tips:</p><div class="mediaobject"><img src="../Images/image00653.jpeg" alt="Advanced options in Visual Studio 2015"/></div><p style="clear:both; height: 1em;"> </p><p>Of course, the real value in these code fragments is that we can see the whole process and evaluate it. This is not <a id="id1061" class="indexterm"/>only about the time it takes, but also about the behavior of the system. So, let's put another breakpoint at the end of the method and see what happens:</p><div class="mediaobject"><img src="../Images/image00654.jpeg" alt="Advanced options in Visual Studio 2015"/></div><p style="clear:both; height: 1em;"> </p><p>As you can see, the entire process took about 1.2 seconds. And the IDE reminds us that we can open <span class="strong"><strong>Diagnostic Tools</strong></span> to check how this code behaved and have a detailed summary, as the next compound screenshot shows (note that you will see it in three different docked windows inside the tools):</p><div class="mediaobject"><img src="../Images/image00655.jpeg" alt="Advanced options in Visual Studio 2015"/></div><p style="clear:both; height: 1em;"> </p><p>In this manner, we don't need to explicitly create a <code class="literal">StopWatch</code> instance to measure how much the process delayed.</p><p>These <span class="strong"><strong>Performance Tips</strong></span> report the time spent, indicating what is less than or equal to (&lt;=) a certain amount. This means that they consider the overhead of the debugging process (symbol loading, and so on), excluding it from the measurement. Actually, the greatest accuracy is obtained on CLR v4.6 and Windows 10.</p><p>As for the CPU <a id="id1062" class="indexterm"/>graph, it uses all the available cores, and when you find a spike it would be interesting to check, even if doesn't reach 100%, for different types of problems, which we will enumerate later (keep in mind that this feature is not available until debugging ends).</p><div class="section" title="Advanced options in the Diagnostic Tools menu"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec12"/>Advanced options in the Diagnostic Tools menu</h4></div></div></div><p>Actually, we can trace sentences one by one and see exactly where most of the time is spent (and where we should<a id="id1063" class="indexterm"/> revise our code in search for improvements).</p><p>If you reproduce this code on your machine, depending on the number of files read, you'll see that in the bottom window of the <span class="strong"><strong>Diagnostic Tools</strong></span> menu, there is a list that shows every event generated and the time it took to be processed, as shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00656.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>Thanks to IntelliTrace, you can exactly configure the way you want the debugger to behave in general or for a specific application. Just go to <span class="strong"><strong>Tools</strong></span> | <span class="strong"><strong>Options</strong></span> and select <span class="strong"><strong>Intellitrace Events</strong></span> (it has a separate entry in the tree view).</p><p>This allows the developer to <a id="id1064" class="indexterm"/>select the types of events they're interested in. For instance, if we want to monitor the <span class="strong"><strong>Console</strong></span> events, we can select which are the ones we need to target in our application:</p><div class="mediaobject"><img src="../Images/image00657.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>To test this, I coded a very simple Console application to show a couple of values and the number of rows and columns available:</p><div class="informalexample"><pre class="programlisting">Console.WriteLine("Largest number of Window Rows: " + Console.LargestWindowHeight);
Console.WriteLine("Largest number of Window Columns: " + Console.LargestWindowWidth);
Console.Read();</pre></div><p>Once IntelliTrace is configured to show the activities of this application, named <code class="literal">ConsoleApplication1</code>, we can<a id="id1065" class="indexterm"/> follow all its events in <span class="strong"><strong>Event Window</strong></span> and later select an event of our interest to us and check <span class="strong"><strong>Activate Historical Debugging</strong></span> in it:</p><div class="mediaobject"><img src="../Images/image00658.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>Once we do that, the IDE relaunches the execution, and, now, the <span class="strong"><strong>Autos</strong></span>, <span class="strong"><strong>Locals</strong></span>, and <span class="strong"><strong>Watch</strong></span> windows appear again but show the values that the application managed at that precise time during the execution.</p><p>In practice, it's like recording every step given by the application at runtime, including the values of any variable, object, or component that we had previously selected as a target during the process (refer to the next screenshot):</p><div class="mediaobject"><img src="../Images/image00659.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>Also, note that the information provided also includes an exact indication of the time spent by every event at runtime.</p><p>Moreover, other profiles for different aspects of our application are possible. We can configure them in the <span class="strong"><strong>Debugger</strong></span> menu under the <span class="strong"><strong>Start Diagnostic Tools Without Debugging</strong></span> option.</p><div class="note" title="Note"><h3 class="title"><a id="tip20"/>Tip</h3><p>When using <span class="strong"><strong>Start Diagnostic Tools Without Debugging</strong></span>, the IDE will remind us to change the default configuration to <span class="strong"><strong>Release</strong></span> if we want to obtain accurate results.</p></div><p>Observe that profiles<a id="id1066" class="indexterm"/> can be attached to distinct applications in the system, not just the one we're building. A new configuration page opens, and the <span class="strong"><strong>Analysis Target</strong></span> option shows distinct types of applications, as you can see in the next screenshot.</p><p>It could be the current application (<code class="literal">ConsoleApplication1</code>), a Windows Store App (either running or already installed), browsing to a web page on a Windows phone, select any other executable, or launch an ASP.NET application running on IIS:</p><div class="mediaobject"><img src="../Images/image00660.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>And this is not all in relation to performance and IntelliTrace. If you select the <span class="strong"><strong>Show All Tools</strong></span> link, more options are presented, which relate to distinct types of applications and technologies to be measured.</p><p>In this way, in the <span class="strong"><strong>Not Applicable Tools</strong></span> link, we see other interesting features, such as the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Application timeline</strong></span>: To check in which areas more time is spent in the application execution (such as the<a id="id1067" class="indexterm"/> typical low frame rate).</li><li class="listitem"><span class="strong"><strong>HTML UI Responsiveness</strong></span>: Especially useful when you have an application that mixes the server and client <a id="id1068" class="indexterm"/>code, and some actions in the client take too much time (think of frameworks such as Angular, Ext, React, Ember, and so on).</li><li class="listitem"><span class="strong"><strong>Network</strong></span>: A very useful complement to the previous web scenario, where the problem resides in the<a id="id1069" class="indexterm"/> network itself. You can check response headers, timelines for every request, cookies, and much more.</li><li class="listitem"><span class="strong"><strong>Energy consumption</strong></span>: This makes<a id="id1070" class="indexterm"/> sense especially in mobile applications.</li><li class="listitem"><span class="strong"><strong>JavaScript memory</strong></span>: Again, very<a id="id1071" class="indexterm"/> useful when dealing with web apps that use external frameworks in which we don't know exactly where the potential memory leaks are.</li></ul></div><p>The next screenshot shows these<a id="id1072" class="indexterm"/> options:</p><div class="mediaobject"><img src="../Images/image00661.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>As you can see, these options appear as <span class="strong"><strong>Not Applicable</strong></span> since they don't make sense in a Console app.</p><p>Once we launch the profile in the <span class="strong"><strong>Start</strong></span> button, an assistant starts and we have to select the type of target: CPU Sampling, Instrumentation (to measure function calls), .NET Memory Allocation, and Resource Contention Data (concurrency), which can detect threads waiting for other threads.</p><p>In the assistant's last screen, we have a checkbox that indicates whether we want to launch the profiling<a id="id1073" class="indexterm"/> immediately afterwards. The application will be launched and, when the execution is over, a profiling report is generated and presented in a new window:</p><div class="mediaobject"><img src="../Images/image00662.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>We have several views available: <span class="strong"><strong>Summary</strong></span>, <span class="strong"><strong>Marks</strong></span> (which presents all related timing at the execution), and <span class="strong"><strong>Processes</strong></span> (obviously, showing information about any process involved in the execution).</p><p>This latest option is especially interesting in the results we obtain. Using the same <code class="literal">ConsoleApplication1</code> file, I'm going to add a new method that creates a <code class="literal">Task</code> object and sleeps execution until <code class="literal">1500</code> ms:</p><div class="informalexample"><pre class="programlisting">private static void RunANewTask()
{
    Task task = Task.Run(() =&gt;
    {
        Console.WriteLine("Task started at: " + 
            DateTime.Now.ToLongTimeString());
        Thread.Sleep(1500);
        Console.WriteLine("Task ended at: " + 
            DateTime.Now.ToLongTimeString());
    });
    Console.WriteLine("Task finished: " + task.IsCompleted);
    task.Wait();  // Blocked until the task finishes
}</pre></div><p>If we activate this option of processes in the profiler, we're shown a bunch of options to analyze, and the report generated holds information to filter data in distinct ways depending on what we need: <span class="strong"><strong>Time Call Tree</strong></span>, <span class="strong"><strong>Hot Lines</strong></span>, <span class="strong"><strong>Report Comparison</strong></span> (with exports), <span class="strong"><strong>Filters</strong></span>, and even more.</p><p>For example, we can<a id="id1074" class="indexterm"/> view the Call Stack at the time the view was collected by double-clicking on an event inside the <span class="strong"><strong>Diagnostic Tools</strong></span> menu:</p><div class="mediaobject"><img src="../Images/image00663.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>Note how we have presented information related to <span class="strong"><strong>Most Contended Resources</strong></span> and <span class="strong"><strong>Most Contended Threads</strong></span>, with a breakdown of each element monitored: either handles or thread numbers. This is one of the features that, although available in previous versions of Visual Studio, should be managed via Performance Counters, as you can read in Maxim Goldin's article <span class="emphasis"><em>Thread Performance - Resource Contention Concurrency Profiling in Visual Studio 2010</em></span>, available<a id="id1075" class="indexterm"/> as part of MSDN Magazine at <a class="ulink" href="https://msdn.microsoft.com/en-us/magazine/ff714587.aspx">https://msdn.microsoft.com/en-us/magazine/ff714587.aspx</a>.</p><p>Besides the<a id="id1076" class="indexterm"/> information shown in the screenshot, a lot of other views give us more data about the execution: <span class="strong"><strong>Modules</strong></span>, <span class="strong"><strong>Threads</strong></span>, <span class="strong"><strong>Resources</strong></span>, <span class="strong"><strong>Marks</strong></span>, <span class="strong"><strong>Processes</strong></span>, <span class="strong"><strong>Function Details</strong></span>, and so on.</p><p>The next capture shows what you will see if you follow these steps:</p><div class="mediaobject"><img src="../Images/image00664.jpeg" alt="Advanced options in the Diagnostic Tools menu"/></div><p style="clear:both; height: 1em;"> </p><p>To summarize, you just learned how the IDE provides a wide set of modern, updated tools, and it's just a matter of deciding which one is the best solution for the analysis required.</p></div></div></div><div class="section" title="Other tools"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec128"/>Other tools</h2></div></div></div><p>As we saw in the previous chapter, modern browsers offer new and exciting possibilities to analyze web page behavior in distinct ways.</p><p>Since it is assumed that the initial landing<a id="id1077" class="indexterm"/> time is crucial in the user's perception, some of these features relate directly to performance (analyzing content, summarizing request time for every resource, presenting graphical information to catch potential problems with a glimpse, and so on).</p><p>The <span class="strong"><strong>Network</strong></span> tab, usually present in most of the browsers, shows a detailed report of loading times for every element in the current page. In some cases, this report is accompanied by a graphical chart, indicating which elements took more time to complete.</p><p>In some cases, the names might vary slightly, but the functionality is similar. For instance, in Edge, you have a <span class="strong"><strong>Performance</strong></span> tab, which records activity and generates detailed reports, including graphical information.</p><p>In Chrome, we find its <span class="strong"><strong>Timeline</strong></span> tab, a recording of the page performance, which also presents a summary of the results.</p><p>Finally, in Firefox, we have an excellent set of tools to check the performance, starting with the <span class="strong"><strong>Net</strong></span> tab, which analyzes the download time for every request and even presents a detailed summary when<a id="id1078" class="indexterm"/> we pass the cursor over each element in the list, allowing us to filter these requests by categories: HTML, CSS, JS, images, plugins, and so on, as shown in the following screenshot:</p><div class="mediaobject"><img src="../Images/image00665.jpeg" alt="Other tools"/></div><p style="clear:both; height: 1em;"> </p><p>Also, in Chrome, we find another interesting tab: <span class="strong"><strong>Audits</strong></span>. The purpose is to monitor distinct aspects of page behaviors, such as the correct usage (and the impact) of CSS, combining JavaScript files to improve the overall performance (the operation called <span class="strong"><strong>Bundling and Minifying</strong></span>), and, in general, a complete list of issues that Chrome considers improvable, mainly in two aspects: <span class="strong"><strong>Network Utilization</strong></span> and <span class="strong"><strong>Web Page Performance</strong></span>. The next screenshot shows the final report on a simple page:</p><div class="mediaobject"><img src="../Images/image00666.jpeg" alt="Other tools"/></div><p style="clear:both; height: 1em;"> </p><p>To end this review of performance features linked to browsers, also consider that in some browsers, we find<a id="id1079" class="indexterm"/> a <span class="strong"><strong>Performance</strong></span> tab, specifically included to load response times or similar utilities, such as <span class="strong"><strong>PageInsights</strong></span> in the case of Chrome and a similar one in Firefox (I would especially recommend Firefox Developer Edition for its highly useful features for a developer).</p><p>In this case, you can record a session in which Firefox gets all the required information to give a view of the performance, which you can later analyze in many forms:</p><div class="mediaobject"><img src="../Images/image00667.jpeg" alt="Other tools"/></div><p style="clear:both; height: 1em;"> </p><p>Note that performance is mainly focused on JavaScript usage, but it is highly customizable for other aspects of a page's behavior.</p></div><div class="section" title="The process of performance tuning"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec129"/>The process of performance tuning</h2></div></div></div><p>Just like with any other software process, we can conceive performance-tuning as a cycle. During this cycle, we try to<a id="id1080" class="indexterm"/> identify and get rid of any slow feature or bottleneck, up to the point at which the performance objective is reached.</p><p>The process goes through data collection (using the tools we've seen), analyzing the results, and changes in configuration, or sometimes in code, depending on the solution required.</p><p>After each cycle of changes is completed, you should retest and measure the code again in order to check whether the goal has been reached and your application has moved closer to its performance objectives. Microsoft's MSDN suggests a cycle process that we can extrapolate for several distinct scenarios or types of applications.</p><p>Keep in mind that software<a id="id1081" class="indexterm"/> tuning often implies tuning the OS as well. You should not change the system's configuration in order to make a particular application perform correctly. Instead, try to recreate the final environment and the possible (or predictable) ways in which that environment is going to evolve.</p><p>Only when you are absolutely sure that your code is the best possible should you suggest changes in the system (memory increase, better CPUs, graphic cards, and so on).</p><p>The following graphic, taken from the official MSDN documentation, highlights this performance cycle:</p><div class="mediaobject"><img src="../Images/image00668.jpeg" alt="The process of performance tuning"/></div><p style="clear:both; height: 1em;"> </p><div class="section" title="Performance Counters"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec77"/>Performance Counters</h3></div></div></div><p>As you probably know, the operating system uses Performance Counters (a feature installed by default), to check its <a id="id1082" class="indexterm"/>performance and eventually notify the user about performance limitations or poor behavior.</p><p>Although they're still available, the new tools that we've seen in the IDE provide a much better and integrated method to check and analyze the application's performance.</p></div><div class="section" title="Bottleneck detection"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec78"/>Bottleneck detection</h3></div></div></div><p>The official documentation in MSDN gives us some clues that we can keep in mind in the process of bottleneck detection<a id="id1083" class="indexterm"/> and divides the possible origins mainly into four categories (each one proposing a distinct management): CPU, memory, disk I/O, and network I/O.</p><p>For .NET applications, some recommendations are assumed correctly when identifying the possible bottlenecks:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>CPU</strong></span>: As for the CPU, check<a id="id1084" class="indexterm"/> Diagnostic Tools in search of pikes. If you find one, narrow the search to identify the cause and analyze the code. A pike is considered harmful if it increases beyond 75% of the CPU usage for more than a certain amount of time.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The consequence, in this case, might well be associated with the code. Generally speaking, asynchronous processes, tasks, or parallel programming are recognized to have a positive impact on solving these kind of problems.</li></ul></div></li><li class="listitem"><span class="strong"><strong>Memory</strong></span>: Here, a memory<a id="id1085" class="indexterm"/> peak can have several reasons. It may be our code, but it is also a process that implies the extensive use of memory (physical or virtual).<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Possible causes are unnecessary allocations, nonefficient clean-up or garbage collection, lack of a caching system, and others. When virtual memory is used, the results may get worse immediately.</li></ul></div></li><li class="listitem"><span class="strong"><strong>Disk I/O</strong></span>: This refers to the<a id="id1086" class="indexterm"/> number of operations (read/write) performed, either on the local storage system or in the network the application has access to.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">There are multiple causes that can provoke a bottleneck here: reading or writing to long files, accessing a network that is overused or not optimally configured, operations that imply ciphering data, unnecessary<a id="id1087" class="indexterm"/> reads from databases, or an excess of paging activity.</li><li class="listitem">To solve these kind of problems, MSDN recommends the following:</li><li class="listitem">Start by removing any redundant disk I/O operations in your application.</li><li class="listitem">Identify whether your system has a shortage of physical memory, and, if so, add more memory to avoid excessive paging.</li><li class="listitem">Identify whether you need to separate your data onto multiple disks.</li><li class="listitem">Consider upgrading to faster disks if you still have disk I/O bottlenecks after doing all of the preceding options.</li></ul></div></li><li class="listitem"><span class="strong"><strong>Network I/O</strong></span>: This is about the amount of information sent/received by your server. It could be an excessive number of remote calls or the amount of data routed through a single <a id="id1088" class="indexterm"/>network interface card (NIC traffic), or it might have to do with large chunks of data sent or received in a large number of calls.</li></ul></div><p>Every possible bottleneck might have a distinct root cause, and we should carefully analyze the possible origins based on questions such as these: is it because of my code or is it the hardware? If it is a hardware problem, is there a way to accelerate the process implied through software improvements? And so on.</p><div class="section" title="Bottleneck detection in practice"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec13"/>Bottleneck detection in practice</h4></div></div></div><p>At the time of determining bottlenecks<a id="id1089" class="indexterm"/> in .NET, you can still use (besides all those tools we've already seen) Performance Counters, although the previous techniques we've seen are supposed to ease the detection process considerably.</p><p>However, the official recommendations linked to some of the issue detections are still a valuable clue. So, the key here would be to look for the equivalent.</p><p>There are several types depending on the feature to be measured, as MSDN suggests:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Excessive memory consumption</strong></span>: Since<a id="id1090" class="indexterm"/> the cause is usually wrong memory management, we should look for values on the following:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Process/private bytes</li><li class="listitem">.NET CLR memory/# bytes in all heaps</li><li class="listitem">Process/working set</li><li class="listitem">.NET CLR memory/large object heap size</li></ul></div><p>The key with these counters is, if you find out an increase in private bytes while the # of bytes in all heap counters remains the same, that means there is <a id="id1091" class="indexterm"/>some kind of unmanaged memory consumption. If you observe an increase in both counters, then the problem is in the managed memory consumption.</p></li><li class="listitem"><span class="strong"><strong>Large working set size</strong></span>: We should understand <span class="emphasis"><em>working set</em></span> means all memory pages loaded in RAM at a given time. The way to measure this problem is to use process\working set <a id="id1092" class="indexterm"/>Performance Counter. Now we have other features, but the points to look for are the same, basically:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">If you get a high value, it might mean that the number of assemblies loaded is very high as well. There's no specific threshold to watch in this counter; however, a high or frequently changing value could be the key to a memory shortage.</li><li class="listitem">If you see a high rate of page faults, it probably means that your server should have more memory.</li></ul></div></li><li class="listitem"><span class="strong"><strong>Fragmented large object heap</strong></span>: In this case, we have to care about objects allocated in <span class="strong"><strong>large object heap</strong></span> (<span class="strong"><strong>LOH</strong></span>). Generally, objects greater than 85 KB are allocated there, and it was traditionally<a id="id1093" class="indexterm"/> detected using the .NET CLR memory\large object heap size profiler, and now, using the memory diagnostic tools that we've <a id="id1094" class="indexterm"/>already seen.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">They might be buffers (for large strings, byte arrays, and so on) that are common in I/O operations (such as in <code class="literal">BinaryReaders</code>).</li><li class="listitem">These allocations fragment the LOH considerably. So, recycling these buffers is a good practice to avoid fragmentation.</li></ul></div></li><li class="listitem"><span class="strong"><strong>High CPU utilization</strong></span>: This is normally <a id="id1095" class="indexterm"/>caused by managed code that is not optimally written, as happens when the code does the following:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Forces an excessive <a id="id1096" class="indexterm"/>use of GC. The measure of this feature was previously done using <code class="literal">%Time</code> in GC, counter.</li><li class="listitem">Also, when the code provokes many exceptions, you can test that with <code class="literal">.NET CLR exceptions\# of exceptions thrown/sec</code>.</li><li class="listitem">A large number <a id="id1097" class="indexterm"/>of threads is generated. This might cause the CPU to spend a lot of time switching between threads (instead of performing real work). Previously measured using the <code class="literal">Thread\Context Switches/sec</code>, now we can check it with the previously seen <span class="strong"><strong>Analysis Target</strong></span> feature.</li></ul></div></li><li class="listitem"><span class="strong"><strong>Thread contention</strong></span>: This happens when multiple threads try to access a shared resource (remember, a process<a id="id1098" class="indexterm"/> creates an area of shared resources that all threads associated with it can access).<p>The identification <a id="id1099" class="indexterm"/>of this symptom is usually done by observing two performance counters:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">.NET CLR LocksAndThreads\Contention Rate/sec</code></li><li class="listitem"><code class="literal">.NET CLR LocksAndThreads\Total # of Contentions</code></li></ul></div></li></ul></div><p>Your application is said to have a contention rate issue or one that encounters thread contention when there is a meaningful increase in these two values. The responsible code should be identified and rewritten.</p></div></div></div><div class="section" title="Using code to evaluate performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec130"/>Using code to evaluate performance</h2></div></div></div><p>As mentioned earlier, besides the set of tools we've seen, it is possible to combine these techniques <a id="id1100" class="indexterm"/>with software tools especially designed to facilitate our own performance measures.</p><p>The first and best known is<a id="id1101" class="indexterm"/> the <code class="literal">Stopwatch</code> class, which belongs to the <code class="literal">System.Diagnostics</code> namespace, which we've already used in the first chapters to measure sorting algorithms, for example.</p><p>The first thing to remember is that depending on the system, the <code class="literal">Stopwatch</code> class will offer different values. These values can be queried at first if we want to know how far we can get accurate measurements. Actually, this class holds two important properties: <code class="literal">Frequency</code> and <code class="literal">IsHighResolution</code>. Both properties are read-only.</p><p>Additionally, some methods complete a nice set of functionalities. Let's review what they mean:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><code class="literal">Frequency</code>: This gets the frequency of the timer as a number of ticks per second. The higher the number, the <a id="id1102" class="indexterm"/>more precise our <code class="literal">Stopwatch</code> class can behave.</li><li class="listitem"><code class="literal">IsHighResolution</code>: This indicates<a id="id1103" class="indexterm"/> whether the timer is based on a high-resolution performance counter.</li><li class="listitem"><code class="literal">Elapsed</code>: This gets the total <a id="id1104" class="indexterm"/>elapsed time that is measured.</li><li class="listitem"><code class="literal">ElapsedMilliseconds</code>: This is the same <a id="id1105" class="indexterm"/>as <code class="literal">Elapsed</code>, but it is measured in milliseconds.</li><li class="listitem"><code class="literal">ElapsedTicks</code>: This is the same<a id="id1106" class="indexterm"/> as <code class="literal">Elapsed</code>, but it is measured in ticks.</li><li class="listitem"><code class="literal">IsRunning</code>: This is a Boolean value<a id="id1107" class="indexterm"/> that indicates whether <code class="literal">Stopwatch</code> is still in operation.</li></ul></div><p>The <code class="literal">Stopwatch</code> class also <a id="id1108" class="indexterm"/>has some convenient methods to facilitate these tasks: <code class="literal">Reset</code>, <code class="literal">Restart</code>, <code class="literal">Start</code>, and <code class="literal">Stop</code>, whose functionality you can easily infer by their names.</p><p>So let's use our reading file method from the previous and present tests, together with a <code class="literal">Stopwatch</code> to check these features with some basic code:</p><div class="informalexample"><pre class="programlisting">var resolution = Stopwatch.IsHighResolution;
var frequency = Stopwatch.Frequency;
Console.WriteLine("Stopwatch initial use showing basic properties");
Console.WriteLine("----------------------------------------------");
Console.WriteLine("High resolution: " + resolution);
Console.WriteLine("Frequency: " + frequency);
Stopwatch timer = new Stopwatch();
timer.Start();
ReadFiles(pathImages);
timer.Stop();
Console.WriteLine("Elapsed time: " + timer.Elapsed);</pre></div><p>Using this basic approach, we have a simple indication of the total time elapsed in the process, as shown in the next screenshot:</p><div class="mediaobject"><img src="../Images/image00669.jpeg" alt="Using code to evaluate performance"/></div><p style="clear:both; height: 1em;"> </p><p>We can get more precision using the other properties provided by the class. For example, we can measure the basic unit of time <code class="literal">Stopwatch</code> uses in attempting to get the nanosecond thanks to the <code class="literal">Frequency</code> property.</p><p>Besides, the class also has a static <code class="literal">StartNew()</code> method, which we can use for simple cases like these; so, we can<a id="id1109" class="indexterm"/> change the preceding code in this manner:</p><div class="informalexample"><pre class="programlisting">static void Main(string[] args)
{
    //BasicMeasure();
    for (int i = 1; i &lt; 9; i++)
    {
        PreciseMeasure(i);
        Console.WriteLine(Environment.NewLine);
    }
    Console.ReadLine();
}
private static void PreciseMeasure(int step)
{
    Console.WriteLine("Stopwatch precise measuring (Step " + step +")");
    Console.WriteLine("------------------------------------");
    Int64 nanoSecPerTick = (1000L * 1000L * 1000L) / Stopwatch.Frequency;
    Stopwatch timer = Stopwatch.StartNew();
    ReadFiles(pathImages);
    timer.Stop();
    var milliSec = timer.ElapsedMilliseconds;
    var nanoSec = timer.ElapsedTicks / nanoSecPerTick;
    Console.WriteLine("Elapsed time (standard): " + timer.Elapsed);
    Console.WriteLine("Elapsed time (millisenconds): " + milliSec + "ms");
    Console.WriteLine("Elapsed time (nanoseconds): " + nanoSec + "ns");
}</pre></div><p>As you can see, we use a small loop to perform the measure three times. So, we can compare results and have a more accurate measure, calculating the average.</p><p>Also, we're using the static <code class="literal">StartNew</code> method of the class since it's valid for this test (think of some cases in which you might need several instances of the <code class="literal">Stopwatch</code> class to measure distinct aspects or blocks of the application, for instance).</p><p>Of course, the results<a id="id1110" class="indexterm"/> won't be exactly the same in every step of the loop, as we see in the next screenshot showing the output of the program (keep in mind that depending on the task and the machine, these values will vary considerably):</p><div class="mediaobject"><img src="../Images/image00670.jpeg" alt="Using code to evaluate performance"/></div><p style="clear:both; height: 1em;"> </p><p>Also, note that due to the system's caching and allocation of resources, every new loop seems to take less time than the previous one. This is the case in my machine depending on the distinct system's state. If you need close evaluations, it is recommended that you execute these tests at least 15 or 20 times and calculate the average.</p></div><div class="section" title="Optimizing web applications"><div class="titlepage"><div><div><h2 class="title"><a id="ch12lvl2sec131"/>Optimizing web applications</h2></div></div></div><p>Optimizing web applications is, for many<a id="id1111" class="indexterm"/> specialists, a <a id="id1112" class="indexterm"/>sort of a <span class="strong"><strong>black art</strong></span> compound of so many features, that actually, there are a lot of books published on the subject.</p><p>We will focus on .NET, and, therefore, on ASP.NET applications, although some of the recommendations are extensible to any web application no matter how it is built.</p><p>Many studies have been carried on the reasons that move a user to uninstall an application or avoid using it. Four <a id="id1113" class="indexterm"/>factors have been identified:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">The application (or website) freezes</li><li class="listitem">The application crashes</li><li class="listitem">Slow responsiveness</li><li class="listitem">Heavy battery usage (for mobiles and tablets, obviously)</li></ul></div><p>So, battery considerations apart, the application should be fast, fluid and efficient. But what do these keywords really mean for us?</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Fast means that going from a point A to a point B should always be done in minimal time: starting from application launching and going through navigation between pages, orientation changes, and so on.</li><li class="listitem">Fluid has to do with smooth interactions. Panning pages, soft animations intended to indicate changes in the state or information presented, the elimination of glitches, image flickering, and so on.</li><li class="listitem">An application or website is considered efficient when the use of resources is adequate: disk resources, memory footprint, battery life, bandwidth, and so on.</li></ul></div><p>In any case, the overall performance is usually linked to the following areas:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Hosting environment (IIS, usually)</li><li class="listitem">The ASP.NET environment</li><li class="listitem">The application's code</li><li class="listitem">The client side</li></ul></div><p>So, let's quickly review some aspects to keep in mind at the time of optimizing these factors, along with some other tips generally accepted as useful when improving the page's performance.</p><div class="section" title="IIS optimization"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec79"/>IIS optimization</h3></div></div></div><p>There are a few techniques that are <a id="id1114" class="indexterm"/>widely recognized to be useful when optimizing IIS, so I'm going to summarize some of these tips offered by Brian Posey in <span class="emphasis"><em>Top Ten Ways To Pump Up IIS Performance</em></span> (<a class="ulink" href="https://technet.microsoft.com/es-es/magazine/2005.11.pumpupperformance.aspx">https://technet.microsoft.com/es-es/magazine/2005.11.pumpupperformance.aspx</a>) in a Microsoft TechNet article:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><span class="strong"><strong>Make sure HTTP Keep-Alives are enabled</strong></span>: This holds the connection open until all files' requests are finished, avoiding unnecessary opening and closing. This feature is enabled <a id="id1115" class="indexterm"/>by default since IIS6, but it's wise<a id="id1116" class="indexterm"/> to check just in case.</li><li class="listitem"><span class="strong"><strong>Tune connection timeouts</strong></span>: This means that after a period of inactivity, IIS will close the<a id="id1117" class="indexterm"/> connection anyway. Make sure the timeout configured is enough for your site.</li><li class="listitem"><span class="strong"><strong>Enable HTTP compression</strong></span>: This is<a id="id1118" class="indexterm"/> especially useful for static content. But beware of compressing dynamic pages: IIS should compress them each time for every request. If you have heavy traffic, the consequence is a lot of extra work.</li><li class="listitem"><span class="strong"><strong>Consider web gardens</strong></span>: You can assign multiple worker processes to your application's pool using a web <a id="id1119" class="indexterm"/>garden. If one of these processes hangs, the rest can keep attending requests.</li><li class="listitem"><span class="strong"><strong>Object cache TTL (Time to Live)</strong></span>: IIS caches requested objects and assigns a TTL to everyone (so they're removed afterwards). However, note that if this time is not enough, you should <a id="id1120" class="indexterm"/>edit the registry and be very careful with it (the earlier mentioned article explains how to do this).</li><li class="listitem"><span class="strong"><strong>Recycle</strong></span>: You can <a id="id1121" class="indexterm"/>avoid memory leaks in the server by recycling memory. You can specify that IIS recycles the application pool at set intervals (every 3 hours or whatever is fine for you) at a specific time each day or else when you consider that the application pool has received a sufficient number of requests. The <code class="literal">&lt;recycle&gt;</code> element in <code class="literal">web.config</code> allows you to tune this behavior.</li><li class="listitem"><span class="strong"><strong>Limit Queue Length</strong></span>: Just in case you detect an excess in the requests on your server, it might be useful to<a id="id1122" class="indexterm"/> limit the number of requests that IIS is allowed to serve.</li></ul></div></div><div class="section" title="ASP.NET optimization"><div class="titlepage"><div><div><h3 class="title"><a id="ch12lvl3sec80"/>ASP.NET optimization</h3></div></div></div><p>There are many tips to optimize <a id="id1123" class="indexterm"/>ASP.NET in the recent versions that correspond to bug fixes, improvements, and suggestions <a id="id1124" class="indexterm"/>made to the development team by developers all <a id="id1125" class="indexterm"/>over, and you'll find abundant literature on the Web about it. For instance, Brij Bhushan Mishra wrote an interesting article on this subject (refer to <a class="ulink" href="http://www.infragistics.com/community/blogs/devtoolsguy/archive/2015/08/07/12-tips-to-increase-the-performance-of-asp-net-application-drastically-part-1.aspx">http://www.infragistics.com/community/blogs/devtoolsguy/archive/2015/08/07/12-tips-to-increase-the-performance-of-asp-net-application-drastically-part-1.aspx</a>), recommending some not-so-well-known aspects of the ASP.NET engine.</p><p>Generally speaking, we can divide optimization into several areas: <span class="strong"><strong>general and configuration</strong></span>, <span class="strong"><strong>caching</strong></span>, <span class="strong"><strong>load balancing</strong></span>, <span class="strong"><strong>data access</strong></span>, and <span class="strong"><strong>client side</strong></span>.</p><div class="section" title="General and configuration"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec14"/>General and configuration</h4></div></div></div><p>Some general and configuration rules apply at the time of dealing with optimization of ASP.NET applications. Let's see some<a id="id1126" class="indexterm"/> of them:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Always remember to measure your performance<a id="id1127" class="indexterm"/> issues in the <span class="strong"><strong>Release</strong></span> mode. The difference might be noticeable and hides performance issues.</li><li class="listitem">Remember to use the profiling tools we've seen and compare the same sites using these tools and different browsers (sometimes, a specific feature can be affected in one browser but not so much in others).</li><li class="listitem">Revise unused modules in the pipeline: even if they're not used, requests will have to pass through all modules predefined for your application's pool. However, how do I know which modules are active?<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">There's an easy way to code this. We can use the application instance and recover the collection of modules loaded in a variable, as you can see in the following code. Later on, just mark a breakpoint to see the results:<div class="informalexample"><pre class="programlisting">HttpApplication httpApps = HttpContext.ApplicationInstance;
//Loads a list with active modules in the ViewBag
HttpModuleCollection httpModuleCollections = httpApps.Modules;
ViewBag.modules = httpModuleCollections;
ViewBag.NumberOfLoadedModules = httpModuleCollections.Count;</pre></div><p>You should see something like the following screenshot to help you decide which is in use and which is not:</p><div class="mediaobject"><img src="../Images/image00671.jpeg" alt="General and configuration"/></div><p style="clear:both; height: 1em;"> </p></li><li class="listitem">Once you <a id="id1128" class="indexterm"/>see all the modules in action, if your website requires no authentication, you can get rid of these modules, indicating that in the <code class="literal">Web.config</code> file:<div class="informalexample"><pre class="programlisting">&lt;system.webServer&gt;
  &lt;modules&gt;
    &lt;removename="FormsAuthentication" /&gt;
    &lt;removename="DefaultAuthentication" /&gt;
    &lt;removename="AnonymousIdentification" /&gt;
    &lt;removename="RoleManager" /&gt;
  &lt;/modules&gt;
&lt;/system.webServer&gt;</pre></div></li><li class="listitem">In this way, we will use only those modules that our application requires, and that happens with every request the application makes.</li></ul></div></li><li class="listitem">The configuration of Pipeline Mode: Starting from IIS7, there are two pipeline modes available: <span class="strong"><strong>Integrated</strong></span> and <span class="strong"><strong>Classic</strong></span>. However, the latter is only for compatibility purposes <a id="id1129" class="indexterm"/>with versions migrated from IIS 6. If your application doesn't have to cope with compatibility issues, make <a id="id1130" class="indexterm"/>sure <span class="strong"><strong>Integrated</strong></span> is active in the <span class="strong"><strong>Edit Application Pool</strong></span> option of IIS Management.</li><li class="listitem">A good idea is to flush your HTML as soon as it is generated (in your <code class="literal">web.config</code>) and disable <a id="id1131" class="indexterm"/><span class="strong"><strong>ViewState</strong></span> if you are not using it: <code class="literal">&lt;pages buffer="true" enableViewState="false"&gt;</code>.</li><li class="listitem">Another option to <a id="id1132" class="indexterm"/>optimize ASP.NET application's performance is to remove unused View Engines. By default, the engine searches for views in different formats and different extensions:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">If you're using only Razor and C#, it doesn't make sense to have activated options that you'll never use. So, an option is to disable all engines at the beginning and only enable Razor. Just add the following code to the <code class="literal">application_start</code> event:<div class="informalexample"><pre class="programlisting">// Removes view engines
ViewEngines.Engines.Clear();
//Add Razor Engine
ViewEngines.Engines.Add(newRazorViewEngine());</pre></div></li><li class="listitem">Another configuration option to keep in mind is the feature called <code class="literal">runAllManagedModulesForAllRequests</code>, which we can find in <code class="literal">Web.config</code> or <code class="literal">applicationHost.config</code> files. It's similar to the previous one in a way since it forces the ASP.NET engine to run for every request, including those that are not necessary, such as CSS, image files, JavaScript files, and so on.</li><li class="listitem">To configure this without interfering with other applications that might need it, we can use a local directory version of <code class="literal">Web.config</code>, where these resources are located, and indicate it in the same modules section that we used earlier, assigning this attribute value to <code class="literal">false</code>:<div class="informalexample"><pre class="programlisting">&lt;modulesrunAllManagedModulesForAllRequests="false"&gt;</pre></div></li></ul></div></li><li class="listitem">Use Gzip to make sure the content is compressed. In your <code class="literal">Web.config</code>, you can add the following:<div class="informalexample"><pre class="programlisting">&lt;urlCompression doDynamicCompression="true" doStaticCompression="true" dynamicCompressionBeforeCache="true"/&gt;</pre></div></li></ul></div></div><div class="section" title="Caching"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec15"/>Caching</h4></div></div></div><p>First of all, you should <a id="id1133" class="indexterm"/>consider the <span class="strong"><strong>Kernel Mode Cache</strong></span>. It's an optional feature that might not be activated by default.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Requests go through<a id="id1134" class="indexterm"/> several layers in the pipeline and caching can be done at different levels as well. Refer to the next figure:<div class="mediaobject"><img src="../Images/image00672.jpeg" alt="Caching"/></div><p style="clear:both; height: 1em;"> </p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">We can go to <span class="strong"><strong>Cache Configuration</strong></span> in <span class="strong"><strong>IIS Administration Tools</strong></span> and add a new configuration, enabling the <span class="strong"><strong>Kernel Model Caching</strong></span> checkbox.</li></ul></div></li><li class="listitem">In relation to this, you <a id="id1135" class="indexterm"/>also have the choice of using client caching. If you add a definition in a folder that holds static content, most of the time, you'll improve the web performance:<div class="informalexample"><pre class="programlisting">&lt;system.webServer&gt;
  &lt;staticContent&gt;
    &lt;clientCachecacheControlMode="UseMaxAge"cacheControlMaxAge="1.00:00:00" /&gt;
  &lt;/staticContent&gt;
&lt;/system.webServer&gt;</pre></div></li><li class="listitem">Another option is to use the <code class="literal">&lt;OutputCache&gt;</code> attribute linked to an <code class="literal">action</code> method. In this case, caching can be more granular using only information linked to a given function.<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">It's easy to indicate this:<div class="informalexample"><pre class="programlisting">[OutputCache(Duration=10, VaryByParam="none")]
public ActionResult Index()
{
  return View();
}</pre></div></li><li class="listitem">Just remember that most of the properties of this attribute are compatible with the <code class="literal">&lt;OutputCache&gt;</code> directive, except <code class="literal">VaryByControl</code>.</li></ul></div></li><li class="listitem">Besides cookies, you can use the new JavaScript 5 API's <code class="literal">localStorage</code> and <code class="literal">sessionStorage</code> attribute, which offer the same functionality but with a number of advantages in security and very fast access:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">All data stored<a id="id1136" class="indexterm"/> using <code class="literal">sessionStorage</code> is automatically erased from the local browser's cache when you abandon the website, while the <code class="literal">localStorage</code> values are permanent.</li></ul></div></li></ul></div></div><div class="section" title="Data access"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec16"/>Data access</h4></div></div></div><p>We've already mentioned some<a id="id1137" class="indexterm"/> techniques for faster data access in this book, but in general, just remember that good practices almost always have a positive impact on access, such as some of the patterns we've seen in <a class="link" title="Chapter 10. Design Patterns" href="part0055.xhtml#aid-1KEEU1">Chapter 10</a>, <span class="emphasis"><em>Design Patterns</em></span>. Also, consider using repository patterns.</p><p>Another good idea is the use of <code class="literal">AsQueryable</code>, which only creates a query that can be changed later on using <code class="literal">Where</code> clauses.</p></div><div class="section" title="Load balancing"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec17"/>Load balancing</h4></div></div></div><p>Besides what we can obtain using<a id="id1138" class="indexterm"/> web gardens and web farms, asynchronous controllers are recommended by MSDN all over the documentation, whenever an action depends on external resources.</p><p>Using the async/await structure that we've seen, we create non-blocking code that is always more responsive. Your code should then look like the sample provided by the ASP.NET site (<a class="ulink" href="http://www.asp.net/mvc/overview/performance/using-asynchronous-methods-in-aspnet-mvc-4">http://www.asp.net/mvc/overview/performance/using-asynchronous-methods-in-aspnet-mvc-4</a>):</p><div class="informalexample"><pre class="programlisting">public async Task&lt;ActionResult&gt;GizmosAsync()
{
  var gizmoService = newGizmoService();
  returnView("Gizmos", await gizmoService.GetGizmosAsync());
}</pre></div><p>As you can see, the big difference is that the <code class="literal">Action</code> method returns <code class="literal">Task&lt;ActionResult&gt;</code> instead of <code class="literal">ActionResult</code> itself. I recommend that you read the previously mentioned article for more details.</p></div><div class="section" title="Client side"><div class="titlepage"><div><div><h4 class="title"><a id="ch12lvl4sec18"/>Client side</h4></div></div></div><p>Optimization in the client side can<a id="id1139" class="indexterm"/> be a huge topic, and you'll find hundreds of references on the Internet. The following are some of the most used and accepted practices:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">Use the optimization techniques that we've seen included in modern browsers in order to determine possible bottlenecks.</li><li class="listitem">Use the Single Page Application architecture based on AJAX queries to partially refresh your pages' contents.</li><li class="listitem">Use CDNs for scripts and media content. This improves the loading time on the client side since these sites are already highly optimized.</li><li class="listitem">Use bundling<a id="id1140" class="indexterm"/> and minification techniques. If your application is built using ASP.NET 4.5 or higher, this technique is enabled by default. These two techniques improve the request load time by reducing the number of requests to the server and reducing the size of the requested resources (such as CSS and JavaScript).<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem">This technique has to do with the functionality of modern browsers, which usually limit the number of simultaneous requests to six per hostname. So, every additional request is queued by the browser.</li><li class="listitem">In this case, check the loading time, using what we saw in the browser tools to get detailed information about every request.</li><li class="listitem">Bundling allows you to combine or bundle multiple files into a single file. This can be done for certain types of assets for which merging content does not provoke malfunctioning.</li><li class="listitem">You can create CSS, JavaScript, and other bundles because fewer files mean fewer requests and that improves the first-page load performance.</li><li class="listitem">The official <a id="id1141" class="indexterm"/>documentation of ASP.NET shows the following comparative table of results with and without this technique and the percentage of change obtained (refer to <a class="ulink" href="http://www.asp.net/mvc/overview/performance/bundling-and-minification%20for%20the%20complete%20explanation">http://www.asp.net/mvc/overview/performance/bundling-and-minification for the complete explanation</a>):<div class="informaltable"><table border="1"><colgroup><col/><col/><col/><col/></colgroup><thead><tr><th valign="bottom"> </th><th valign="bottom">
<p>Using B/M</p>
</th><th valign="bottom">
<p>Without B/M</p>
</th><th valign="bottom">
<p>Change</p>
</th></tr></thead><tbody><tr><td valign="top">
<p>File requests</p>
</td><td valign="top">
<p>9</p>
</td><td valign="top">
<p>34</p>
</td><td valign="top">
<p>256%</p>
</td></tr><tr><td valign="top">
<p>KB sent</p>
</td><td valign="top">
<p>3.26</p>
</td><td valign="top">
<p>11.92</p>
</td><td valign="top">
<p>266%</p>
</td></tr><tr><td valign="top">
<p>KB received</p>
</td><td valign="top">
<p>388.51</p>
</td><td valign="top">
<p>530</p>
</td><td valign="top">
<p>36%</p>
</td></tr><tr><td valign="top">
<p>Load time</p>
</td><td valign="top">
<p>510 MS</p>
</td><td valign="top">
<p>780 MS</p>
</td><td valign="top">
<p>53%</p>
</td></tr></tbody></table></div></li></ul></div></li></ul></div><p>As the documentation explains: The bytes sent had a significant reduction with bundling as browsers are fairly verbose with the HTTP headers they apply on requests. The received reduction in bytes is <a id="id1142" class="indexterm"/>not as large because the largest files (<code class="literal">Scripts\jquery-ui-1.8.11.min.js</code> and <code class="literal">Scripts\jquery-1.7.1.min.js</code>) are already minified. Note that the timings on the sample program used the Fiddler tool to simulate a slow network. (From the Fiddler <span class="strong"><strong>Rules</strong></span> menu, select <span class="strong"><strong>Performance</strong></span> and then select <span class="strong"><strong>Simulate Modem Speeds</strong></span>.)</p></div></div></div></div></div>
<div class="section" title="Summary" id="aid-2BASE1"><div class="titlepage"><div><div><h1 class="title"><a id="ch12lvl1sec73"/>Summary</h1></div></div></div><p>In this chapter, we looked at distinct tools and techniques related to the optimization of applications and performance.</p><p>First, we saw the concepts of Application Performance Engineering and we went through the tools available inside Visual Studio 2015 (any version) and the modern browsers.</p><p>Then, we covered some of the most important processes to follow in order to detect issues and performance problems and explored how to use classes to fine-tune measurement.</p><p>Finally, we reviewed some of the most important techniques recommended for the optimization of websites, especially those written with ASP.NET MVC.</p><p>In the final chapter, we will cover many features that are difficult to include in any of the previous chapters, including advanced techniques, such as parallelism, <span class="strong"><strong>platform invoke </strong></span>and an introduction to the new .NET Core.</p></div></body></html>