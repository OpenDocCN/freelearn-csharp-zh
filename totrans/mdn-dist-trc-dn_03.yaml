- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The .NET Observability Ecosystem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we explored .NET observability features included into
    the platform and frameworks, but there are more instrumentations covering other
    libraries and environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll learn how to find and evaluate instrumentations and
    then take a closer look at instrumentations for a few specific libraries: StackExchange.Redis,
    Azure, and AWS SDKs. We’ll also explore tracing and metrics coming from infrastructure
    using **Dapr** (**distributed application runtime**) as an example. Finally, we’ll
    see how to configure tracing in serverless environments where we have less control,
    but observability is even more important.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Through this chapter, you’ll learn:'
  prefs: []
  type: TYPE_NORMAL
- en: How to find, evaluate, and enable OpenTelemetry instrumentations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What Dapr and service meshes are capable of when it comes to observability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to enable tracing in serverless environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll get hands-on experience with different kinds
    of instrumentations and you will be able to configure and use distributed tracing
    for a wide range of backend applications. Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to evolve our meme application and use a cloud
    object store, Amazon S3 or Azure Blob Storage, along with a local Redis cache.
    The code for this chapter is available in the book’s GitHub repository at [https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter3](https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/tree/main/chapter3),
    which has the following folder structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`libraries`: Contains library instrumentation sample app for the first section
    of this chapter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dapr`: Contains Dapr instrumentation sample for the second section'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`serverless`: Contains `aws` and `azure` folders with examples of AWS Lambda
    and Azure Functions instrumentations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To run these applications, you would need the following tools:'
  prefs: []
  type: TYPE_NORMAL
- en: .NET SDK 7.0 or later
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual Studio or VS Code, but any text editor would work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker and `docker-compose`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dapr CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An Azure subscription (optional):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’re going to use Blob Storage and Application Insights.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: With Blob Storage, we’re going to stay well within free-tier limits. Application
    Insights does not have a free tier, but you can still try it out with Azure promotional
    credits.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll use Azure Function Tools v4 and (optionally) Azure CLI.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An AWS subscription (optional):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’re going to use S3, Lambda, and X-Ray. We’ll stay well within free-tier limits
    for each of them.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll need AWS toolkit for VS or Lambda .NET CLI and (optionally) AWS CLI.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring cloud storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you don’t want to create an Azure or AWS subscription, you can still run
    `libraries` and `dapr` samples locally by setting `CloudStorage.Type` to `Local`
    in `storage/appsettings.json`. There is no local setup for serverless demos.
  prefs: []
  type: TYPE_NORMAL
- en: Otherwise, set `CloudStorage.Type` to the storage of your choice, `AwsS3` or
    `AzureBlob`, and let’s see how to configure them.
  prefs: []
  type: TYPE_NORMAL
- en: AWS S3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Create a new bucket using AWS console or CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then, add bucket info to `libraries/storage/appsettings.json`.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll also need credentials to access blob storage and we’re going to use the
    credentials file where we can. You can generate one using the `aws configure`
    command. Applications would search for AWS credentials file at `${HOME}/.aws/credentials`.
  prefs: []
  type: TYPE_NORMAL
- en: Replace the `HOME` environment variable in `docker-compose.yml` in the `libraries/`
    and `serverless/aws` folders.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Blob Storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Create a new storage account. You can use Azure portal or Azure CLI and then
    obtain a connection string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the connection string to `.env` file next to `libraries/docker-compose.yml`
    in the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Using instrumentations for popular libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we saw how to enable tracing for the .NET platform,
    ASP.NET Core, and Entity Framework to cover the basics, but anyone can create
    instrumentation for a popular library and share it with the community. Also, with
    tracing and metrics primitives being part of .NET and OpenTelemetry to collect
    data in a vendor-agnostic way, libraries can add native instrumentation.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple terms that describe different kinds of instrumentations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Auto-instrumentation** *sometimes* implies that instrumentation can be enabled
    without *any* modification of application code, but is sometimes used to describe
    any shared instrumentation that is easy to enable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Instrumentation library** means that you can enable instrumentation by installing
    the corresponding NuGet package and configuring it with a few lines of code at
    startup time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Native instrumentation** implies that instrumentation code is a part of the
    library, so no additional NuGet package is necessary, but you may still need to
    enable instrumentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manual instrumentation** is the one that you write yourself as a part of
    your application code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The boundaries between automatic, native, and instrumentation libraries are
    blurry. For example, the HTTP client contains native instrumentation starting
    with .NET 7.0, but you might still enable it in a more convenient way with the
    corresponding instrumentations. Or, with some bytecode rewrite that configures
    OpenTelemetry, we can enable library instrumentations without changing any of
    the application code. In this book, we use a relaxed version of the auto-instrumentation
    term (for the lack of a better one) to describe all non-manual instrumentations,
    but we mention a specific kind when it’s relevant.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several sources where we can find available instrumentations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**OpenTelemetry registry** ([https://opentelemetry.io/registry):](https://opentelemetry.io/registry):)
    You can filter the instrumentations by language and component. Many instrumentations
    are not added to the registry though. It lists all kinds of instrumentation regardless
    of their kind.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenTelemetry .NET repo** ([https://github.com/open-telemetry/opentelemetry-dotnet):](https://github.com/open-telemetry/opentelemetry-dotnet):)
    Contains library instrumentation for .NET frameworks and libraries. The ASP.NET
    Core and HTTP client instrumentations we used in the previous chapter live here
    along with SQL, gRPC, and exporters for OSS backends. These are instrumentation
    libraries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenTelemetry Contrib repo** ([https://github.com/open-telemetry/opentelemetry-dotnet-contrib):](https://github.com/open-telemetry/opentelemetry-dotnet-contrib):)
    Contains different OpenTelemetry components: instrumentation libraries, exporters,
    and other utilities. You can find instrumentations for AWS SDK, ElasticSearch,
    WCF, StackExchange.Redis, and more there. The Entity Framework instrumentation
    we used in the previous chapter also lives in this repo.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenTelemetry instrumentation repo** ([https://github.com/open-telemetry/opentelemetry-dotnet-instrumentation):](https://github.com/open-telemetry/opentelemetry-dotnet-instrumentation):)
    Contains fully codeless auto-instrumentations that work via different mechanism
    - .NET profiling API. You can find GraphGL and MongoDB instrumentation there.
    In addition to auto-instrumentations for specific libraries; it provides a mechanism
    to configure OpenTelemetry in a codeless way that includes a set of common instrumentation
    libraries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Other sources**: If you didn’t find what you’re looking for in the registry
    or the OpenTelemetry repos, search for issues in OpenTelemetry repos and don’t
    forget to check your library repo. For example, you can find MongoDB instrumentation
    at [https://github.com/jbogard/MongoDB.Driver.Core.Extensions.DiagnosticSources](https://github.com/jbogard/MongoDB.Driver.Core.Extensions.DiagnosticSources),
    which is leveraged in the *instrumentation* repo but can be used as a standalone
    instrumentation library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When adding instrumentations, pay attention to their stability and maturity.
    Instrumentations in the `opentelemetry-dotnet` repo are widely used but are not
    yet stable (it could have changed by the time you read this).
  prefs: []
  type: TYPE_NORMAL
- en: Instrumentations in the *contrib* repo have different statuses; for example,
    AWS is stable, while MySQL is in alpha and works for relatively old versions of
    the `MySQL.Data` package at the time of writing.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs: []
  type: TYPE_NORMAL
- en: If you decide to take dependency on a less common preview package, make sure
    to test it well. Compatibility with your version of the client library, stability,
    and performance should be the main concerns. All of them should be covered with
    integration and stress-testing—just make sure to enable instrumentation!
  prefs: []
  type: TYPE_NORMAL
- en: It’s good to get a basic idea of how the instrumentation works and check whether
    the mechanism behind it satisfies your performance requirements. For example,
    native instrumentations rely on `ActivitySource` or `DiagnosticSource`, and MongoDB
    and AWS instrumentations rely on hooks in corresponding libraries. All of these
    methods should work reasonably well, but the `MySQL.Data` instrumentation relies
    on `System.Diagnostics.TraceListener`, which is not thread-safe by default, and,
    when configured to be thread-safe, is not performant.
  prefs: []
  type: TYPE_NORMAL
- en: Even the most efficient instrumentations come with some performance hit. You
    should expect throughput to drop a few percent compared to non-instrumented code.
    Specific numbers heavily depend on your scenarios and OpenTelemetry configuration,
    such as sampling.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Many developers consider auto-instrumentations to be magical and avoid them
    for this reason. By learning the mechanisms behind instrumentation, you can identify
    areas for additional testing, understand limitations, and gain confidence to use
    it (or not).
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s instrument the new version of the meme service and dig deep into each
    instrumentation we’re going to use.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our new demo application stores memes in Azure Blob Storage or AWS S3 and caches
    them in Redis, as shown in *Figure 3**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.1 – Meme service with configurable cloud storage](img/B19423_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – Meme service with configurable cloud storage
  prefs: []
  type: TYPE_NORMAL
- en: You can also set it up to store memes in Redis if you don’t want to configure
    a cloud subscription.
  prefs: []
  type: TYPE_NORMAL
- en: There are no changes on **frontend** from the previous chapter—we already enabled
    OpenTelemetry with HTTP instrumentations there. On **storage**, though we still
    need to add a few more instrumentations for AWS, Redis, and Azure SDK.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to install `OpenTelemetry.Contrib.Instrumentation.AWS` and `OpenTelemetry.Instrumentation.StackExchangeRedis`
    and then configure them:'
  prefs: []
  type: TYPE_NORMAL
- en: libraries\storage\Program.cs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/libraries/storage/Program.cs](https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/libraries/storage/Program.cs)'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s unpack it and explore instrumentations one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Redis instrumentation is available via the `OpenTelemetry.Instrumentation.StackExchangeRedis`
    package and comes from the *contrib* repo—documentation and examples are available
    there.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how we can evaluate this instrumentation. While any details about
    it might change, the approach can be applied to any other instrumentation library.
  prefs: []
  type: TYPE_NORMAL
- en: Redis instrumentation is not stable at the time of writing but it has a fair
    number of downloads on NuGet and no bugs reported. If we investigate how it works,
    we’ll see that it leverages the `StackExchange.Redis` profiling APIs—hooks allowing
    the start of a profiling session and recording events that happen during its execution.
    Despite the name, it doesn’t need the profiler attached.
  prefs: []
  type: TYPE_NORMAL
- en: It’s a relatively complex instrumentation—a profiling API is not designed for
    distributed tracing, so instrumentation must cover the gaps by maintaining an
    internal cache of sessions and cleaning them up.
  prefs: []
  type: TYPE_NORMAL
- en: To enable instrumentation, we call the `AddRedisInstrumentation` extension method
    on `TracerProviderBuilder` and pass the connection instance. If you have more
    than one connection, you’ll have to enable instrumentation for each of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also passed instrumentation options and enabled verbose database statements
    to collect additional data including Redis keys and scripts by setting `SetVerboseDatabaseStatements`
    flag to `true`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: It’s a good idea to check how this configuration might affect application performance
    and the verbosity of the output before deploying it to production. If we look
    into the Redis instrumentation code, this flag guards reflection-based (but efficient)
    calls to obtain the command key and script.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on what we store in Redis, we should also make sure it does not record
    any secrets or sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: You probably noticed that instrumentations follow a common pattern, but unlike
    Redis ones, most of them are global and don’t require a per-client instance setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are other options that control tracing on Redis: you can specify callback
    to enrich activities, disable events with additional timings, and configure intervals
    to clean up completed profiling sessions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we start the application now and upload and download several memes on http://localhost:5051/,
    we’d see traces like the one shown in *Figure 3**.2* for meme download flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.2 – Meme download with Redis span](img/B19423_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – Meme download with Redis span
  prefs: []
  type: TYPE_NORMAL
- en: You can see the standard `net.peer.*` attributes describing generic network
    endpoint and `db.*` attributes describing database call with `db.statement` matching
    Redis command and key. We only see the key (`this_is_fine`) since we set `SetVerboseDatabaseStatements`
    to `true`, otherwise `db.statement` would match the command `HMGET`.
  prefs: []
  type: TYPE_NORMAL
- en: You can also see three logs (span events in Jaeger) describing additional timings
    for the Redis command. Since Redis is quite fast, you might find these events
    to be not very useful and disable them by setting `EnrichActivityWithTimingEvents`
    to `false`, which should decrease your observability bill and slightly improve
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: AWS SDK
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AWS SDK instrumentation is available in the `OpenTelemetry.Contrib.Instrumentation.AWS`
    NuGet package with the code residing in the *contrib* repo. Let’s try to evaluate
    it using the same approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is stable and relies on a global tracing handler that applies to all AWS
    clients and instances, not just S3\. This handler in turn leverages .NET tracing
    primitives: `Activity` and `ActivitySource`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable AWS instrumentation, just call the `AddAWSInstrumentation` extension
    method on `TracerProviderBuilder`. At this moment, there’s just one configurable
    option that controls whether nested HTTP calls should be traced:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 3**.3* shows the meme upload trace: `PutObject` that in turn makes
    an `HTTP PUT` request to S3\. After the meme is uploaded, it’s cached on Redis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – Upload meme to S3](img/B19423_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – Upload meme to S3
  prefs: []
  type: TYPE_NORMAL
- en: The nested HTTP span is coming from the HTTP Client instrumentation, and we
    only see it because `SuppressDownstreamInstrumentation` is set to `false`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we expand `S3.PutObject`, we’ll see attributes that describe this operation,
    as shown in *Figure 3**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – AWS S3 span attributes](img/B19423_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – AWS S3 span attributes
  prefs: []
  type: TYPE_NORMAL
- en: Azure SDK
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure SDK instrumentation is native—it’s baked into modern libraries—and you
    don’t need to install any additional packages. Tracing code for all client libraries
    is available in the [https://github.com/Azure/azure-sdk-for-net/](https://github.com/Azure/azure-sdk-for-net/)
    repo. Still, it’s not stable because of tracing semantic conventions being experimental.
    For example, attribute names, types, and relationships between activities may
    change in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can enable it with `AppContext` switch either in `csproj` or by adding
    the following code before Azure clients’ initialization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Instrumentation uses `ActivitySource` and `Activity` directly, so all we need
    to enable it is to call the `AddSource("Azure.*")` method on `TracerProviderBuilder`.
    It enables all sources that start with `Azure`, but you can also enable individual
    sources.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3**.5* shows the Azure SDK blob upload trace—logical upload operation
    and nested HTTP request. We see one there, but for chunked downloads, complex
    calls, or in case of retries, we’d see multiple nested HTTP calls:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.5 –  Azure Blob upload](img/B19423_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 – Azure Blob upload
  prefs: []
  type: TYPE_NORMAL
- en: We explored tracing for several libraries and learned how to discover and evaluate
    instrumentations. Let’s now discover what we can get from infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll explore Dapr for microservices. Dapr provides service
    discovery, component bindings, secret management, locking, state management, observability,
    and more building blocks helping developers to focus on application logic. We’ll
    focus on distributed tracing.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our demo application, we’re going to handle all network calls with Dapr
    and enable tracing and metrics on it. We’ll also keep telemetry enabled on the
    microservices. *Figure 3**.6* shows the new application layout:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.6 – Meme application with Dapr runtime](img/B19423_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 – Meme application with Dapr runtime
  prefs: []
  type: TYPE_NORMAL
- en: Dapr runs as a sidecar—a separate process wrapping each application instance.
    **Frontend** in our setup calls into **storage** via Dapr, which handles service
    discovery, error handling, encryption, load balancing, and more. **Storage**,
    in turn, uses Dapr output **binding** to communicate to Azure, AWS, or store memes
    locally.
  prefs: []
  type: TYPE_NORMAL
- en: Dapr integrates well with Kubernetes, but we’ll use self-hosted mode and `docker-compose`
    to keep things simple.
  prefs: []
  type: TYPE_NORMAL
- en: Dapr supports distributed tracing and metrics for incoming and outgoing calls
    that applications make through Dapr. Let’s see what it means in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Dapr secrets configuration needs a different approach than we used for the
    libraries demo. We’ll need to update `darp/configs/dapr/storage-components/secrets.json`
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For AWS, put your access keys in `{"awsKey": <key>, "``awsSecret": <secret>}`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For Azure, set `{"azStorageAccount": <account>, "azStorageKey": <key>}.` If
    you don''t have Azure credentials, remove the `binding-azure.yaml` file from the
    `dapr/configs/dapr/storage-components` folder, otherwise samples will not work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For local runs, set `CloudStorage.Type` to `Local` in `storage/appsettings.json`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring observability on Dapr
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To enable tracing and metrics, let’s add corresponding sections to `Configuration
    spec`:'
  prefs: []
  type: TYPE_NORMAL
- en: ./dapr/configs/dapr/config.yml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/dapr/configs/dapr/config.yml](https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/dapr/configs/dapr/config.yml)'
  prefs: []
  type: TYPE_NORMAL
- en: We also added Dapr sidecars to `docker-compose.yml`, enabled the Zipkin trace
    receiver on the OpenTelemetry collector, and added Dapr metrics endpoints to Prometheus
    targets to scrape from. As a result, we receive traces and metrics from the application
    and Dapr at the same time. Let’s check them out.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s run the application now with `docker-compose up --build`, hit `http://localhost:16686`
    and find some upload requests, you should see something like the trace shown in
    *Figure 3**.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.7 – Trace from the application and Dapr ](img/B19423_03_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 – Trace from the application and Dapr
  prefs: []
  type: TYPE_NORMAL
- en: The first two spans coming from `frontend /memes/d8…` and `CallLocal/storage/memes/d8…`
    spans—they are new and are coming from Dapr.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we expand them as shown in *Figure 3**.8*, we’ll also see the attributes
    it set:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.8 – Dapr spans and attributes ](img/B19423_03_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 – Dapr spans and attributes
  prefs: []
  type: TYPE_NORMAL
- en: You would probably wonder if we still need distributed tracing on the service—let’s
    check it.
  prefs: []
  type: TYPE_NORMAL
- en: Stop containers and comment out the `OTEL_EXPORTER_OTLP_ENDPOINT` environment
    variable in `docker-compose.yml` for **frontend** and **storage**; we don’t enable
    OpenTelemetry if the endpoint is not provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, restart the application and upload some memes again, and the result is
    shown in *Figure 3**.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.9 – Dapr tracing without OpenTelemetry enabled in the application](img/B19423_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 – Dapr tracing without OpenTelemetry enabled in the application
  prefs: []
  type: TYPE_NORMAL
- en: So, we see the spans coming from Dapr, but the trace does not look right—upload
    to Azure Blob is not a child of an incoming request represented with `CallLocal/storage`
    span. What happened there?
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B19423_02.xhtml#_idTextAnchor038), *Native Monitoring in .NET*,
    we have shown that ASP.NET Core and `HttpClient` in .NET create activities regardless
    of OpenTelemetry presence. This is what happened here—`CallLocal` is a grandparent
    to `/v1.0/bindings/azureblob`, but the span between them is not recorded and causation
    is lost.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, if you use Dapr on an application that does not enable distributed
    tracing by default, the context will not be propagated within the `CallLocal`
    and `/v1.0/bindings/azureblob` would disappear.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Dapr or service mesh, such as Istio, can trace network calls, but they cannot
    propagate trace context within the application process and rely on applications
    to do it. They also can’t stamp context on the logs if your application does not
    do it.
  prefs: []
  type: TYPE_NORMAL
- en: If you can’t instrument your application, traces coming from Dapr or service
    mesh are still handy, despite being semi-correlated.
  prefs: []
  type: TYPE_NORMAL
- en: If you use Dapr for reasons beyond observability and your application is instrumented,
    then Dapr tracing gives you observability into Dapr itself to see how it handles
    requests, so you can compare latencies, debug configuration issues, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Dapr reports extensive metrics about application communication and bindings
    such as HTTP and gRPC request count, duration, and request and response size histograms.
    You could also find Go runtime stats for the Dapr itself.
  prefs: []
  type: TYPE_NORMAL
- en: These metrics look quite promising but by default they use the HTTP request
    path as an attribute on metrics, which has high cardinality. While they allow
    to reduce cardinality with a regular expression and convert path to an API route,
    it would be a problem in high-scale production application. Once they become production
    ready, they could be a great alternative to many in-process metrics covering network
    communication.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumenting serverless environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Serverless environments need observability more than other systems—they are
    frequently used to integrate different services with little-to-no user code, making
    debugging and local testing difficult. With load balancing, scaling, and other
    common infrastructure pieces handled for us, we still need to understand what’s
    going on when things don’t work as expected.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, as users, we are very limited with telemetry collection options—we
    can’t install agents, configure runtime, or run something in privileged mode—we
    can only use what cloud providers expose. At the same time, cloud providers have
    a great opportunity to instrument code for us. Let’s see what AWS Lambda and Azure
    Functions provide out of the box and what we can do on top of it.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Lambda
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'AWS Lambda supports invocation tracing with X-Ray out of the box; you just
    need to enable active tracing via console or CLI to trace incoming calls to your
    function and see basic invocation metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.10 – AWS X-Ray service map showing default Lambda instrumentation](img/B19423_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 – AWS X-Ray service map showing default Lambda instrumentation
  prefs: []
  type: TYPE_NORMAL
- en: To go further than this and trace what happens in your code, you’d need to use
    X-Ray SDK as a stable solution or OpenTelemetry, which is in beta at this point.
    We’re going to play with OpenTelemetry in this demo.
  prefs: []
  type: TYPE_NORMAL
- en: The configuration around OpenTelemetry is likely to change. So, we will kindly
    ask you to check out the latest instructions for **ADOT Collector** (**AWS Distro
    for OpenTelemetry Collector**), available at [https://aws-otel.github.io/docs/getting-started/lambda/lambda-dotnet](https://aws-otel.github.io/docs/getting-started/lambda/lambda-dotnet).
  prefs: []
  type: TYPE_NORMAL
- en: ADOT Collector is based on OpenTelemetry Collector; it’s also compatible with
    AWS environments and comes with a preselected set of community components. We’re
    going to send traces to X-Ray, which is a default configuration for ADOT Collector,
    but you can configure it to send data to your observability backend.
  prefs: []
  type: TYPE_NORMAL
- en: Now we’re ready to explore the tracing experience in Lambda.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling additional tracing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Tracing configuration in Lambda is like any other service. First, we need to
    install the `OpenTelemetry.Instrumentation.AWSLambda` NuGet package and then configure
    it along with the exporter and other instrumentations:'
  prefs: []
  type: TYPE_NORMAL
- en: Function.cs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs](https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs)'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s unpack what happens here. First, we set `AWSXRayPropagator` as a default
    context propagator—it enables context propagation over the `X-Amzn-Trace-Id` header.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we enabled Lambda instrumentation with `AddAWSLambdaConfigurations`.
    If we look under the hood, this method does a couple of things:'
  prefs: []
  type: TYPE_NORMAL
- en: Detects and configures resource attributes such as cloud provider, region, function
    name, and version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enables `ActivitySource` that reports Lambda invocations and stitches context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that we do it in the static constructor to optimize performance and reduce
    costs. Despite being serverless, Lambda uses one process for multiple invocations.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the last step, we need to implement the tracing handler that wraps our Lambda
    logic:'
  prefs: []
  type: TYPE_NORMAL
- en: Function.cs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs](https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/aws/memefunc/Function.cs)'
  prefs: []
  type: TYPE_NORMAL
- en: Note that we configured Lambda to invoke `TracingHandler` instead of inner `MemeHandler`.
  prefs: []
  type: TYPE_NORMAL
- en: If we get back to the configuration, the rest enables AWS SDK and HTTP Client
    instrumentation. We also configured the OTLP exporter without parameters—it uses
    the default endpoint (`localhost:4317`) and the default protocol (`gRPC`).
  prefs: []
  type: TYPE_NORMAL
- en: We also configured **frontend** to send data to ADOT with the X-Ray exporter,
    so we get all traces in the same place.
  prefs: []
  type: TYPE_NORMAL
- en: If you didn’t deploy your Lambda function yet, deploy it now, for example, with
    AWS Toolkit for Visual Studio or Lambda tools for .NET CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to configure the function URL on `Storage__Endpoint` environment variable—you
    can set it in `./frontend/docker-compose.yml`. We don’t use authorization in the
    demo, but make sure to secure your real-life applications.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s start `docker-compose up --build`, then upload and download some
    memes at `http://localhost:5051`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s switch to AWS X-Ray and check out the traces. You should see something
    similar to *Figure 3**.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.11 – Lambda tracing with OpenTelemetry](img/B19423_03_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 – Lambda tracing with OpenTelemetry
  prefs: []
  type: TYPE_NORMAL
- en: If you check the service map, it now shows S3 in addition to Lambda nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know how to enable tracing for AWS Lambda, let’s see what Azure
    Functions are capable of.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Azure Functions support distributed tracing with Azure Monitor (Application
    Insights) out-of-the-box. It includes triggers and most bindings. If you use in-process
    functions, tracing covers user code too, with isolated workers, you need to enable
    and configure tracing in the worker process yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Functions rely on the instrumentations in client SDKs used for triggers
    and bindings. For example, they reuse ASP.NET Core Activities in HTTP Trigger
    and Azure SDK instrumentation for Azure Blob Storage inputs and outputs.
  prefs: []
  type: TYPE_NORMAL
- en: The Azure Functions runtime does not support OpenTelemetry for in-process functions
    yet, but your observability vendor may provide an extension that covers this gap.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our sample, Azure Functions host automatically reports triggers and binding
    calls to Application Insights – this auto-collection lights up in presence of
    the `APPLICATIONINSIGHTS_CONNECTION_STRING` environment variable, which we can
    set in the `local.settings.json` file, as shown in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: ./serverless/azure/memefunc/local.settings.json
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/local.settings.json](https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/local.settings.json)'
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to enable OpenTelemetry for the worker process with the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: ./serverless/azure/memefunc/Program.cs
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/Program.cs](https://github.com/PacktPublishing/Modern-Distributed-Tracing-in-.NET/blob/main/chapter3/serverless/azure/memefunc/Program.cs)'
  prefs: []
  type: TYPE_NORMAL
- en: Here we use a familiar way to enable OpenTelemetry, but `the Microsoft.Azure.Functions.Worker`
    activity source is new. The source is part of Azure Functions Worker and propagates
    trace context from the host to isolated worker. It creates an activity representing
    worker invocation.
  prefs: []
  type: TYPE_NORMAL
- en: On the `Azure.Monitor.OpenTelemetry.Exporter` to send data to Application Insights
    endpoint directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the sample, we’ll need an Application Insights resource. You can create
    one with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'It will return JSON output containing `connectionString`, which we’ll need
    to configure Functions. Let’s now set Azure Blob Storage and Application Insights
    connection strings in `memefunc/local.setting.json` and we’re ready to run the
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Hit `http://localhost:5051` to upload and download some memes, and then go
    to your Application Insights resource and search for recent requests. *Figure
    3**.12* shows an example of captured trace:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.12 – Azure Functions trace ](img/B19423_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 – Azure Functions trace
  prefs: []
  type: TYPE_NORMAL
- en: We traced this call from `storage-download` function that in turn downloaded
    a blob. We used Azure Blob Storage bindings, so all the communication with blob
    storage was handled by Azure Functions host and outside of the worker process.
    As a result, the Azure Functions invocation span (`storage-download`) and all
    spans related to blobs are reported by the Functions host.
  prefs: []
  type: TYPE_NORMAL
- en: The `Invoke` span is recorded by `Microsoft.Azure.Functions.Worker` activity
    source; it represents function invocation on the worker side. If we had any nested
    operations done inside worker, we’d see them reported as children of the `Invoke`
    span.
  prefs: []
  type: TYPE_NORMAL
- en: Even though most of the application logic happened outside of the application
    code, we can see what happened under the hood because of tracing.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored instrumentations in the .NET ecosystem. You learned
    how to evaluate and configure different kinds of instrumentation libraries, how
    to enable and use tracing on Dapr, and what serverless environments can provide
    with different levels of configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Client library auto-instrumentations can be found in OpenTelemetry repositories
    or registries, while some libraries don’t need instrumentations, providing tracing
    natively. Instrumentations’ maturity and stability levels vary, so it’s important
    to review and test them as a part of your normal integration and stress testing.
    Instrumentations usually provide configuration options to control the amount of
    details they capture, allowing you to find the right cost-value ratio for your
    system. Client libraries and frameworks are not the only sources of traces—your
    infrastructure such as service meshes, web servers, load balancers, and proxies
    can emit them. We checked out the tracing story in Dapr and confirmed that it
    provides insights into Dapr itself but can’t propagate the context and stamp it
    on the logs and other signals in the application. So, infrastructure traces complement
    but cannot substitute in-process tracing.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless environments provide integration with tracing and monitoring tools;
    it’s critical for them since users are limited in the configuration of serverless
    runtime.
  prefs: []
  type: TYPE_NORMAL
- en: We explored AWS Lambda, which supports OpenTelemetry, with ADOT Collector and
    in-code configuration, and Azure Functions that supports vendor-specific codeless
    instrumentation for in-process mode, while out-of-the-box OpenTelemetry support
    is yet to come.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know how to discover and use third-party instrumentations in different
    environments, you should be able to get observability into a broad spectrum of
    distributed applications. However, to debug in-process issues such as deadlocks,
    memory leaks, or inefficient code, we’ll need lower-level telemetry—this is what
    we’re going to explore in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How would you find instrumentation for a popular library you use? When you find
    one, what would you check for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a typical mechanism behind OpenTelemetry tracing instrumentations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What service mesh can and cannot do in terms of tracing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
