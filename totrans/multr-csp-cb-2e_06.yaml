- en: Chapter 6. Using Concurrent Collections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will look through the different data structures for concurrent
    programming included in the .NET Framework base class library. You will learn
    the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Using `ConcurrentDictionary`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing asynchronous processing using `ConcurrentQueue`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changing the asynchronous processing order with `ConcurrentStack`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a scalable crawler with `ConcurrentBag`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generalizing asynchronous processing with `BlockingCollection`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Programming requires understanding and knowledge of basic data structures and
    algorithms. To choose the best-suited data structure for a concurrent situation,
    a programmer has to know about many things, such as algorithm time, space complexity,
    and the big O notation. In different, well-known scenarios, we always know which
    data structures are more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: For concurrent computations, we need to have appropriate data structures. These
    data structures have to be scalable, avoid locks when possible, and at the same
    time provide thread-safe access. .NET Framework, since version 4, has the `System.Collections.Concurrent`
    namespace with several data structures in it. In this chapter, we will cover several
    data structures and show you very simple examples of how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start with `ConcurrentQueue`. This collection uses atomic **Compare and
    Swap** (**CAS**) operations, which allow us to safely exchange values of two variables,
    and `SpinWait` to ensure thread safety. It implements a **First In, First Out**
    (**FIFO**) collection, which means that the items go out of the queue in the same
    order in which they were added to the queue. To add an item to a queue, you call
    the `Enqueue` method. The `TryDequeue` method tries to take the first item from
    the queue, and the `TryPeek` method tries to get the first item without removing
    it from the queue.
  prefs: []
  type: TYPE_NORMAL
- en: The `ConcurrentStack` collection is also implemented without using any locks
    and only with CAS operations. This is the **Last In, First Out** (**LIFO**) collection,
    which means that the most recently added item will be returned first. To add items,
    you can use the `Push` and `PushRange` methods; to retrieve, you use `TryPop`
    and `TryPopRange`, and to inspect, you can use the `TryPeek` method.
  prefs: []
  type: TYPE_NORMAL
- en: The `ConcurrentBag` collection is an unordered collection that supports duplicate
    items. It is optimized for a scenario where multiple threads partition their work
    in such a way that each thread produces and consumes its own tasks, dealing with
    other threads' tasks very rarely (in which case, it uses locks). You add items
    to a bag using the `Add` method; you inspect with `TryPeek`, and take items from
    a bag with the `TryTake` method.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Avoid using the `Count` property on the collections mentioned. They are implemented
    using linked lists, and therefore, `Count` is an `O(N)` operation. If you need
    to check whether the collection is empty, use the `IsEmpty` property, which is
    an `O(1)` operation.
  prefs: []
  type: TYPE_NORMAL
- en: '`ConcurrentDictionary` is a thread-safe dictionary collection implementation.
    It is lock-free for read operations. However, it requires locking for write operations.
    The concurrent dictionary uses multiple locks, implementing a fine-grained locking
    model over the dictionary buckets. The number of locks could be defined using
    a constructor with the `concurrencyLevel` parameter, which means that an estimated
    number of threads will update the dictionary concurrently.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since a concurrent dictionary uses locking, there are a number of operations
    that require acquiring all the locks inside the dictionary. These operations are:
    `Count`, `IsEmpty`, `Keys`, `Values`, `CopyTo`, and `ToArray`. Avoid using these
    operations without need.'
  prefs: []
  type: TYPE_NORMAL
- en: '`BlockingCollection` is an advanced wrapper over the `IProducerConsumerCollection`
    generic interface implementation. It has many features that are more advanced
    and is very useful for implementing pipeline scenarios when you have some steps
    that use the results from processing the previous steps. The `BlockingCollection`
    class supports features such as blocking, bounding inner collections capacity,
    canceling collection operations, and retrieving values from multiple blocking
    collections.'
  prefs: []
  type: TYPE_NORMAL
- en: The concurrent algorithms can be very complicated, and covering all the concurrent
    collections—whether more or less advanced—would require writing a separate book.
    Here, we illustrate only the simplest examples of using concurrent collections.
  prefs: []
  type: TYPE_NORMAL
- en: Using ConcurrentDictionary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows you a very simple scenario, comparing the performance of a
    usual dictionary collection with the concurrent dictionary in a single-threaded
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter6\Recipe1`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the difference between the performance of a usual dictionary
    collection and the concurrent dictionary, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the program starts, we create two collections. One of them is a standard
    dictionary collection, and the other is a new concurrent dictionary. Then, we
    start adding to them, using a standard dictionary with a lock and measuring the
    time it takes for one million iterations to complete. Then, we measure the `ConcurrentDictionary`
    collection's performance in the same scenario, and we finally compare the performance
    of retrieving values from both collections.
  prefs: []
  type: TYPE_NORMAL
- en: In this very simple scenario, we find that `ConcurrentDictionary` is significantly
    slower on write operations than a usual dictionary with a lock but is faster on
    retrieval operations. Therefore, if we need many thread-safe reads from a dictionary,
    the `ConcurrentDictionary` collection is the best choice.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you need just read-only multithreaded access to the dictionary, it may not
    be necessary to perform thread-safe reads. In this scenario, it is much better
    to use just a regular dictionary or the `ReadOnlyDictionary` collections.
  prefs: []
  type: TYPE_NORMAL
- en: The `ConcurrentDictionary` collection is implemented using the **fine-grained
    locking** technique, and this allows it to scale better on multiple writes than
    using a regular dictionary with a lock (which is called **coarse-grained locking**).
    As we saw in this example, when we use just one thread, a concurrent dictionary
    is much slower, but when we scale this up to five-six threads (if we have enough
    CPU cores that could run them simultaneously), the concurrent dictionary will
    actually perform better.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing asynchronous processing using ConcurrentQueue
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe will show you an example of creating a set of tasks to be processed
    asynchronously by multiple workers.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter6\Recipe2`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the working of creating a set of tasks to be processed asynchronously
    by multiple workers, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the program runs, we create a queue of tasks with an instance of the `ConcurrentQueue`
    collection. Then, we create a cancelation token, which will be used to stop work
    after we are done posting tasks to the queue. Next, we start a separate worker
    thread that will post tasks to the tasks queue. This part produces a workload
    for our asynchronous processing.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's define a task-consuming part of the program. We create four workers
    that will wait a random time, get a task from the task queue, process it, and
    repeat the whole process until we signal the cancelation token. Finally, we start
    the task-producing thread, wait for its completion, and then signal the consumers
    that we've finished work with the cancelation token. The last step will be to
    wait for all our consumers to complete, to finish processing all tasks.
  prefs: []
  type: TYPE_NORMAL
- en: We see that we have tasks being processed from start to end, but it is possible
    that a later task will be processed before an earlier one because we have four
    workers running independently and the task processing time is not constant. We
    see that the access to the queue is thread-safe; no work item was taken twice.
  prefs: []
  type: TYPE_NORMAL
- en: Changing asynchronous processing order with ConcurrentStack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe is a slight modification of the previous one. We will, once again,
    create a set of tasks to be processed asynchronously by multiple workers, but
    this time, we implement it with `ConcurrentStack` and see the differences.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter6\Recipe3`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand the processing of a set of tasks implemented with `ConcurrentStack`,
    perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When the program runs, we now create an instance of the `ConcurrentStack` collection.
    The rest is almost like in the previous recipe, except instead of using the `Push`
    and `TryPop` methods on the concurrent stack, we use `Enqueue` and `TryDequeue`
    on a concurrent queue.
  prefs: []
  type: TYPE_NORMAL
- en: We now see that the task processing order has been changed. The stack is a LIFO
    collection, and workers process the latter tasks first. In case of a concurrent
    queue, tasks were processed in almost the same order in which they were added.
    This means that by depending on the number of workers, we will surely process
    the task that was created first in a given time frame. In the case of a stack,
    the tasks that were created earlier will have lower priority and may be not processed
    until a producer stops giving more tasks to the stack. This behavior is very specific
    and it is much better to use a queue in this scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a scalable crawler with ConcurrentBag
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe shows you how to scale workload between a number of independent
    workers that both produce work and process it.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. There are no
    other prerequisites. The source code for this recipe can be found at `BookSamples\Chapter6\Recipe4`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following steps demonstrate how to scale workload between a number of independent
    workers that both produce work and process it:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The program simulates web page indexing with multiple web crawlers. A web crawler
    is a program that opens a web page by its address, indexes the content, tries
    to visit all the links that this page contains, and indexes these linked pages
    as well. At the beginning, we define a dictionary containing different web-page
    URLs. This dictionary simulates web pages containing links to other pages. The
    implementation is very naive; it does not care about indexing the already visited
    pages, but it is simple and allows us to focus on the concurrent workload.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we create a concurrent bag, containing crawling tasks. We create four
    crawlers and provide a different site root URL to each of them. Then, we wait
    for all crawlers to compete. Now, each crawler starts to index the site URL it
    was given. We simulate the network I/O process by waiting for some random amount
    of time; then, if the page contains more URLs, the crawler posts more crawling
    tasks to the bag. Then, it checks whether there are any tasks left to crawl in
    the bag. If not, the crawler is complete.
  prefs: []
  type: TYPE_NORMAL
- en: If we check the output below the first four lines, which are root URLs, we will
    see that usually, which were root URLs, we will see that usually a task posted
    by the crawler number *N* is processed by the same crawler. However, the later
    lines will be different. This happens because internally, `ConcurrentBag` is optimized
    for exactly this scenario where there are multiple threads that both add items
    and remove them. This is achieved by letting each thread work with its own local
    queue of items, and thus, we do not need any locks while this queue is occupied.
    Only when we have no items left in the local queue will we perform some locking
    and try to *steal* the work from another thread's local queue. This behavior helps
    to distribute the work between all workers and avoid locking.
  prefs: []
  type: TYPE_NORMAL
- en: Generalizing asynchronous processing with BlockingCollection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This recipe will describe how to use `BlockingCollection` to simplify implementation
    of workload asynchronous processing.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To work through this recipe, you will need Visual Studio 2015\. No other prerequisites
    are required. The source code for this recipe can be found at `BookSamples\Chapter6\Recipe5`.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To understand how `BlockingCollection` simplifies the implementation of workload
    asynchronous processing, perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Start Visual Studio 2015\. Create a new C# console application project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the `Program.cs` file, add the following `using` directives:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet below the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the following code snippet inside the `Main` method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the program.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we take exactly the first scenario, but now, we use a `BlockingCollection`
    class that provides many useful benefits. First of all, we are able to change
    the way the tasks are stored inside the blocking collection. By default, it uses
    a `ConcurrentQueue` container, but we are able to use any collection that implements
    the `IProducerConsumerCollection` generic interface. To illustrate this, we run
    the program twice, using `ConcurrentStack` as the underlying collection the second
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Workers get work items by iterating the `GetConsumingEnumerable` method call
    result on a blocking collection. If there are no items inside the collection,
    the iterator will just block the worker thread until an item is posted to the
    collection. The cycle ends when the producer calls the `CompleteAdding` method
    on the collection. It signals that the work is done.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is very easy to make a mistake and just iterate `BlockingCollection` as it
    implements `IEnumerable` itself. Do not forget to use `GetConsumingEnumerable`,
    or else, you will just iterate a "snapshot" of a collection and get completely
    unexpected program behavior.
  prefs: []
  type: TYPE_NORMAL
- en: The workload producer inserts the tasks into `BlockingCollection` and then calls
    the `CompleteAdding` method, which causes all the workers to get completed. Now,
    in the program output, we see two result sequences illustrating the difference
    between the concurrent queue and stack collections.
  prefs: []
  type: TYPE_NORMAL
