<html><head></head><body>
        

                            
                    <h1 class="header-title">Evaluating Performance Problems</h1>
                
            
            
                
<p class="CDPAlignLeft CDPAlign"> Performance evaluation for most software products is a very scientific process. First, we determine the maximum/minimum supported performance metrics, such as the allowed memory usage, acceptable CPU consumption, and the number of concurrent users. Next, we perform load testing against the application in scenarios with a version of the application built for the target platform, and test it while gathering instrumentation data. Once this data is collected, we analyze and search it for performance bottlenecks. If problems are discovered, we complete a <strong>Root Cause Analysis</strong> (<strong>RCA</strong>), and then make changes in the configuration or application code to fix the issue and repeat it.</p>
<p>Although game development is a very artistic process, it is still exceptionally technical. Our game should have a target audience in mind, which can tell us what hardware limitations our game might be operating under and, perhaps, tell us exactly what performance targets we need to meet (particularly in the case of console and mobile games). We can perform runtime testing on our application, gather performance data from multiple subsystems (CPU, GPU memory, the physics engine, the Rendering Pipeline, and so on), and compare them against what we consider to be acceptable. We can then use this data to identify bottlenecks in our application, perform additional instrumentation measurements, and determine the root cause of the issue. Finally, depending on the type of problem, we should be capable of applying a number of solutions to improve our application's performance.</p>
<p>However, before we spend even a single moment making performance fixes, we will first need to prove that a performance problem exists. It is unwise to spend time rewriting and refactoring code until there is a good reason to do so since pre-optimization is rarely worth the hassle. Once we have proof of a performance issue, the next task is figuring out exactly where the bottleneck is located. It is important to ensure that we understand why the performance issue is happening; otherwise, we could waste even more time applying fixes that are little more than educated guesses. Doing so often means that we only fix a symptom of the issue, not its root cause, and so we risk it manifesting itself in other ways in the future, or in ways we haven't yet detected.</p>
<p>In this chapter, we will explore the following:</p>
<ul>
<li>How to gather profiling data using the Unity Profiler</li>
<li>How to analyze Profiler data for performance bottlenecks</li>
<li>Techniques to isolate a performance problem and determine its root cause</li>
</ul>
<p>With a thorough understanding of the problems you're likely to face, you will then be ready for the information presented in the remaining chapters, where you will learn what solutions are available for the types of issue we detect.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Gathering profiling data using the Unity Profiler</h1>
                
            
            
                
<p>The Unity Profiler is built into the Unity Editor itself and provides an expedient way of narrowing down our search for performance bottlenecks by generating usage and statistics reports on a multitude of Unity3D subsystems during runtime. The different subsystems for which it can gather data are listed as follows:</p>
<ul>
<li>CPU consumption (per-major subsystem)</li>
<li>Basic and detailed rendering and GPU information</li>
<li>Runtime memory allocations and overall consumption</li>
<li>Audio source/data usage</li>
<li>Physics engine (2D and 3D) usage</li>
<li>Network messaging and operation usage</li>
<li>Video playback usage</li>
<li>Basic and detailed user interface performance</li>
<li><strong>Global Illumination</strong> (<strong>GI</strong>) statistics</li>
</ul>
<p>There are generally two approaches to making use of a profiling tool: <strong>instrumentation</strong> and <strong>benchmarking</strong> (although, admittedly, the two terms are often used interchangeably).</p>
<p><strong>Instrumentation</strong> typically means taking a close look into the inner workings of the application by observing the behavior of targeted function calls, where/how much memory is being allocated, and, generally getting an accurate picture of what is happening with the hope of finding the root cause of a problem. However, this is normally not an efficient way of starting to identify performance problems because profiling of any application comes with a performance cost of its own.</p>
<p>When a Unity application is compiled in Development Mode (determined by the Development Build flag in the Build Settings menu), additional compiler flags are enabled causing the application to generate special events at runtime, which get logged and stored by the Profiler. Naturally, this will cause additional CPU and memory overhead at runtime due to all of the extra workload the application takes on. Even worse, if the application is being profiled through the Unity Editor, then even more CPU and memory use will be incurred, ensuring that the Editor updates its interface, renders additional windows (such as the Scene window), and handles background tasks. This profiling cost is not always negligible. In excessively large projects, it can sometimes cause all kinds of inconsistent and unexpected behavior when the Profiler is enabled: Unity can go out of memory, some scripts may refuse to run, physics may stop being updated (the time used for a frame may be so large that the physics engine reaches the maximum allowed updates per frame), and more. This is a necessary price we pay for a deep analysis of our code's behavior at runtime, and we should always be aware of its implications. Therefore, before we get ahead of ourselves and start analyzing every line of code in our application, it would be wiser to do some <strong>benchmarking.</strong></p>
<p><strong>Benchmarking</strong> involves performing a surface-level measurement of the application. We should gather some rudimentary data and perform test scenarios during a runtime session of our game while it runs on the target hardware; the test case could simply be, for example, a few seconds of gameplay, playback of a cutscene, or a partial playthrough of a level. The idea of this activity is to get a general feel for what the user might experience and keep watching for moments when performance becomes noticeably worse. Such problems may be severe enough to warrant further analysis.</p>
<p>The important metrics we're interested in when we carry out a benchmarking process are often the number of <strong>frames per-second</strong> (<strong>FPS</strong>) being rendered, overall memory consumption, how CPU activity behaves (looking for large spikes in activity), and sometimes CPU/GPU temperature. These are all relatively simple metrics to collect and can be used as a go-to first approach to performance analysis for one important reason: it will save us an enormous amount of time in the long run. It ensures that we only spend our time investigating problems that users would notice.</p>
<p>We should dig deeper into instrumentation only after a benchmarking test indicates that further analysis is required. It is also very important to benchmark by simulating actual platform behavior as much as possible if we want a realistic data sample. As such, we should never accept benchmarking data that was generated through Editor mode as being representative of real gameplay, since Editor mode comes with some additional overhead costs that might mislead us, or hide potential race conditions in a real application. Instead, we should hook the profiling tool into the application while it is running in a standalone format on the target hardware. </p>
<p class="mce-root">Many Unity developers are surprised to find that the Editor sometimes calculates the results of operations much faster than a standalone application does. This is particularly common when dealing with serialized data such as audio files, Prefabs, and scriptable objects. This is because the Editor will cache previously imported data and is able to access it much faster than a real application would.</p>
<p>Now, let's cover how to access the Unity Profiler and connect it to the target device so that we can start to make accurate benchmarking tests.</p>
<p>Users who are already familiar with connecting the Unity Profiler to their applications can skip to the section entitled <em>The Profiler window</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Launching the Profiler</h1>
                
            
            
                
<p>We will begin with a brief tutorial on how to connect our game to the Unity Profiler within a variety of contexts:</p>
<ul>
<li>Local instances of the application, either through the Editor or a standalone instance</li>
<li>Local instances of a WebGL application running in a browser</li>
<li>Remote instances of the application on an iOS device (for example, iPhone or iPad)</li>
<li>Remote instances of the application on an Android device (for example, an Android tablet or phone)</li>
<li>Profiling the Editor itself</li>
</ul>
<p>We will briefly cover the requirements for setting up the Profiler in each of these contexts.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Editor or standalone instances</h1>
                
            
            
                
<p>In this instance, the only way to access the Profiler is to launch it through the Unity Editor and connect it to a running instance of our application. We will use the same Profiler windows irrespective of whether we execute our game in Playmode within the Editor, running a standalone application on the local or remote device, or wish to profile the Editor itself.</p>
<p>To open Profiler, navigate to Window | Analysis | Profiler within the Editor or use <em>Ctrl </em>+ <em>7</em> (or <em>cmd</em> + <em>7</em> on macOS):</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/b1530dce-4911-423e-914d-10a6f3dd19c5.png"/></p>
<p class="mce-root">If the Editor is already running in Playmode, then we should see profiling data continuously populating the Profiler window.</p>
<p>To profile standalone projects, ensure that the Development Build and Autoconnect Profiler flags are enabled when the application is built.</p>
<p>Choosing whether to profile an Editor-based instance (through the Editor's Playmode) or a standalone instance (built and running separately from the Editor) can be achieved through the <strong>Connected Player</strong> option in the Profiler window:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/e7529962-08ce-4474-85ed-d192f8e7178f.png"/></p>
<p>Note that switching back to the Unity Editor while profiling a separate standalone project will halt all data collection since the application will not be updated while it is in the background.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Connecting to a WebGL instance</h1>
                
            
            
                
<p>The Profiler can also be connected to an instance of the Unity WebGL Player. This can be achieved by ensuring that the Development Build and Autoconnect Profiler flags are enabled when the WebGL application is built and run from the Editor. The application will then be launched through the operating system's default browser. This enables us to profile our web-based application in a more real-world scenario through the target browser and test multiple browser types for inconsistencies in behavior (although this requires us to keep changing the default browser).</p>
<p>Unfortunately, the Profiler connection can only be established when the application is first launched from the Editor. It currently cannot be connected to a standalone WebGL instance already running in a browser. This limits the accuracy of benchmarking WebGL applications since there will be some Editor-based overhead, but it's the only option we have available for the moment.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Remote connection to an iOS device</h1>
                
            
            
                
<p>The Profiler can also be connected to an active instance of an application running remotely on an iOS device, such as an iPad or iPhone. This can be achieved through a shared Wi-Fi connection. </p>
<p>Note that remote connection to an iOS device is only possible when Unity (and hence the Profiler) is running on an Apple Mac device.</p>
<p>Observe the following steps to connect the Profiler to an iOS device:</p>
<ol>
<li>Ensure that the Development Build and Autoconnect Profiler flags are enabled when the application is built</li>
<li>Connect both the iOS device and macOS device to a local Wi-Fi network, or to an ad hoc Wi-Fi network</li>
<li>Attach the iOS device to the macOS via the USB or Lightning Cable</li>
<li>Begin building the application with the Build &amp; Run option as usual</li>
<li>Open the Profiler window in the Unity Editor and select the device under Connected Player</li>
</ol>
<p>You should now see the iOS device's profiling data gathering in the Profiler window.</p>
<p>The Profiler uses ports <kbd>54998</kbd> to <kbd>55511</kbd> to broadcast profiling data. Ensure that these ports are available for outbound traffic if there is a firewall on the network.</p>
<p>To troubleshoot problems with building iOS applications and connecting the Profiler to them, consult the following documentation page: <a href="https://docs.unity3d.com/Manual/TroubleShootingIPhone.html">https://docs.unity3d.com/Manual/TroubleShootingIPhone.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Remote connection to an Android device</h1>
                
            
            
                
<p>There are two different methods for connecting an Android device to the Unity Profiler: either through a Wi-Fi connection or by using the <strong>Android Debug Bridge</strong> (<strong>ADB</strong>) tool. Either of these approaches will work from an Apple macOS, or a Windows PC.</p>
<p>Perform the following steps to connect an Android device over a Wi-Fi connection:</p>
<ol>
<li>Ensure that the Development Build and Autoconnect Profiler flags are enabled when the application is built</li>
<li>Connect both the Android and desktop devices to a local Wi-Fi network</li>
<li>Attach the Android device to the desktop device via a USB cable</li>
<li>Begin building the application with the Build &amp; Run option as usual</li>
<li>Open the Profiler window in the Unity Editor and select the device under Connected Player</li>
</ol>
<p>The application should then be built and pushed to the Android device through the USB connection, and the Profiler should connect through the Wi-Fi connection. You should then see the Android device's profiling data gathering in the Profiler window.</p>
<p>The second option is to use ADB. This is a suite of debugging tools that comes bundled with the Android <strong>Software Development Kit</strong> (<strong>SDK</strong>). For ADB profiling, perform the following steps:</p>
<ol>
<li>Ensure that the Android SDK is installed by following Unity's guide for Android SDK/NDK setup: <a href="https://docs.unity3d.com/Manual/android-sdksetup.html">https://docs.unity3d.com/Manual/android-sdksetup.html</a></li>
<li>Connect the Android device to your desktop machine via the USB cable</li>
<li>Ensure that the Development Build and Autoconnect Profiler flags are enabled when the application is built</li>
<li>Begin building the application with the Build &amp; Run option as usual</li>
<li>Open the Profiler window in the Unity Editor and select the device under Connected Player</li>
</ol>
<p>You should now see the Android device's profiling data gathering in the Profiler window.</p>
<p>To troubleshoot problems with building Android applications and connecting the Profiler to them, consult the following documentation page: <a href="https://docs.unity3d.com/Manual/TroubleShootingAndroid.html">https://docs.unity3d.com/Manual/TroubleShootingAndroid.html</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Editor profiling</h1>
                
            
            
                
<p>We can profile the Editor itself. This is normally used when trying to profile the performance of custom editor scripts. This can be achieved by enabling the Profile Editor option in the Profiler window and configuring the Connected Player option to Editor, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/53496738-08bf-402c-a280-93be2f816519.png" style="width:24.08em;height:13.42em;"/></p>
<p>Note that both options must be configured if we want to profile the Editor: if nothing happens in the graph, then it is possible you have not selected the Profile Editor button, or you may accidentally be connected to another game build! </p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Profiler window</h1>
                
            
            
                
<p>We will now cover the essential features of the Profiler as they can be found within the interface.</p>
<p>The Profiler window is split into four main sections:</p>
<ul>
<li><strong>Profiler Controls</strong></li>
<li><strong>Timeline View</strong></li>
<li><strong>Breakdown View Controls</strong></li>
<li><strong>Breakdown View</strong></li>
</ul>
<p>These sections are shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/eb1c0875-e544-4354-b637-6defaad06c16.png" style="width:53.75em;height:18.08em;"/></p>
<p>We'll now cover each of these sections in detail.</p>
<p>Timeline View has a lot of colors, but not everyone sees colors in the same way. Luckily, if you are colorblind, Unity has thought of you! In the top-right hamburger menu, you can enable Color Blind Mode:</p>
<div><img src="img/66f6144d-0dfd-4b8c-889a-df58c9552b2d.png" style="width:23.50em;height:21.25em;"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Profiler controls</h1>
                
            
            
                
<p>The top bar in the previous screenshot contains multiple drop-down and toggle buttons we can use to affect what is being profiled and how deeply in the subsystem that data is gathered from. These are covered in the next subsections.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Add Profiler</h1>
                
            
            
                
<p>By default, the Profiler will collect data for several different subsystems that cover the majority of the Unity engine's subsystems in Timeline View. These subsystems are organized into various areas containing relevant data. The Add Profiler option can be used to add additional areas or restore them if they have been removed. Refer to the Timeline View section for a complete list of subsystems we can profile.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Playmode</h1>
                
            
            
                
<p>The Playmode drop-down lets us select the target instance of Unity we want to profile. This can be the current Editor application, a local standalone instance of our application, or an instance of our application running on a remote device.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Record</h1>
                
            
            
                
<p>Enabling the Record option (the record icon) makes the Profiler record profiling data. This will happen continuously while this option is enabled. Note that runtime data can only be recorded if the application is actively running. For an app running in the Editor, this means that Playmode must be enabled and it should not be paused; alternatively, for a standalone app, it must be the active window. If Profile Editor is enabled, then the data that appears will be collected for the Editor itself.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Deep Profile</h1>
                
            
            
                
<p>Ordinary profiling will only record the time and memory allocations made by common Unity callback methods, such as <kbd>Awake()</kbd>, <kbd>Start()</kbd>, <kbd>Update()</kbd>, and <kbd>FixedUpdate()</kbd>. Enabling the Deep Profile option recompiles our scripts with a much deeper level of instrumentation, allowing it to measure each and every invoked method. This causes a significantly greater instrumentation cost during runtime than normal, and uses substantially more memory since data is being collected for the entire callstack at runtime. As a consequence, deep profiling may not even be possible in large projects, as Unity may run out of memory before testing even begins, or the application may run so slowly as to make the test pointless.</p>
<p>Note that toggling Deep Profile requires the entire project to be completely recompiled before profiling can begin again, so it is best to avoid toggling the option back and forth between tests.</p>
<p>Since this option blindly measures the entire callstack, it would be unwise to keep it enabled during most of our profiling tests. This option is best reserved for when default profiling does not provide sufficient detail to figure out the root cause, or if we're testing the performance of a small test scene, which we're using to isolate certain activities.</p>
<p class="mce-root">If deep profiling is required for larger projects and scenes, but the Deep Profile option is too much of a hindrance during runtime, then there are alternative approaches that can be used to perform more detailed profiling; see the upcoming section entitled <em>Targeted profiling of code segments</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Allocation Callstack</h1>
                
            
            
                
<p>By activating the Allocation Callstack option, Unity Profiler will collect more info about the game's memory allocations without requiring Deep Profile:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/501b0f1a-c916-4fd5-9122-f885a8edcf1d.png"/></p>
<p>If the option is enabled, you can click on the red boxes representing memory allocations and Profiler will show you the origin and the cause of that memory allocation:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/e335a8b7-6a99-45be-ada0-4839996ffc9d.png"/></p>
<p>In Hierarchy view, instead, you still need to select an allocation call. Then, you need to switch to Show Related Objects in the drop-down menu in the upper-right corner and then select one of the N/A objects. After that, you'll see Callstack info in the box underneath.</p>
<p>We will talk more about memory allocations in <a href="eb7d9924-d92d-4cfa-ae68-ddd0f77a15a0.xhtml">Chapter 8</a>, <em>Masterful Memory Management</em>.</p>
<p>At the time of writing, in Unity 2019.1, Allocation Callstack works only when profiling in the Editor.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Clear</h1>
                
            
            
                
<p>The Clear button clears all profiling data from Timeline View.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Load</h1>
                
            
            
                
<p>The Load icon button will open up a dialog window to load in any previously saved profiling data (by using the Save option).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Save</h1>
                
            
            
                
<p>The Save icon button saves any Profiler data currently presented in Timeline View to a file. Only 300 frames of data can be saved in this fashion at a time, and a new file must be manually created for any more data. This is typically sufficient for most situations, since, when a performance spike occurs, we then have about five to ten seconds to pause the application and save the data for future analysis (such as attaching it to a bug report) before it gets pushed off the left-hand side of Timeline View. Any saved Profiler data can be loaded into the Profiler for future examination using the Load option.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Frame Selection</h1>
                
            
            
                
<p>The frame selection area is composed of several sub-elements. The Frame Counter shows how many frames have been profiled and which frame is currently selected in Timeline View. There are two buttons to move the currently selected frame forward or backward by one frame and a third button (the Current button) that resets the selected frame to the most recent frame and keeps that position. This will cause Breakdown View to always show profiling data for the current frame during runtime profiling; it will display the word Current.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Timeline View</h1>
                
            
            
                
<p>Timeline View reveals during runtime,</p>
<ul>
<li>A graphical representation of profiling data on the right</li>
<li>A series of checkboxes (the colored squares in the following screenshot) to enable/disable different activities/data types on the left:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="img/3d14efc5-d723-440e-a9b2-b6fed6dddede.png"/></p>
<p>These colored boxes can be toggled, which changes the visibility of the corresponding data types within the graphical section of Timeline View.</p>
<p>When an area is selected in Timeline View, more detailed information for that subsystem will be revealed in Breakdown View (beneath Timeline View) for the currently selected frame. The kind of information displayed in Breakdown View varies depending on which area is currently selected in Timeline View.</p>
<p>Areas can be removed from Timeline View by clicking on the X in the top-right corner of an area. If you want to show an area that you removed again, you can use the Add Profiler option in the Controls bar.</p>
<p>At any time, we can click a location in the graphical part of Timeline View to reveal information about a given frame. A large vertical white bar will appear (usually with some additional information on either side coinciding with the line graphs), showing us which frame is selected.</p>
<p>Depending on which area is currently selected (determined by which area is currently highlighted in blue), different information will be available in Breakdown View, and different options will be available in Breakdown View Controls. Changing the area that is selected is as simple as clicking on the relevant box on the left-hand side of Timeline View or on the graphical side; however, clicking inside the graphical area might also change which frame has been selected, so be careful clicking in the graphical area if you wish to see Breakdown View information for the same frame.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Breakdown View Controls</h1>
                
            
            
                
<p>Different dropdowns and toggle button options will appear within Breakdown View Controls, depending on which area is currently selected in Timeline View. Different areas offer different controls, and these options dictate what information is available, and how that information is presented in Breakdown View.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Breakdown View</h1>
                
            
            
                
<p>The information revealed in Breakdown View will vary enormously based on which area is currently selected and which Breakdown View Controls options are selected. For instance, some areas offer different modes in a dropdown within Breakdown View Controls, which can provide Simple or Detailed views of the information or even a graphical layout of the same information so that it can be parsed more easily.</p>
<p>Now, let's cover each area and the different kinds of information and options available in Breakdown View.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The CPU Usage area</h1>
                
            
            
                
<p>This area shows data for all CPU Usage and statistics. It is perhaps the most complex and useful since it covers a large number of Unity subsystems, such as <kbd>MonoBehaviour</kbd> components, cameras, some rendering and physics processes, the user interface (including the Editor's interface, if we're running through the Editor), audio processing, the Profiler itself, and more.</p>
<p>There are three different modes for displaying CPU Usage data in Breakdown View:</p>
<ul>
<li>Hierarchy mode</li>
<li>Raw Hierarchy mode</li>
<li>Timeline mode</li>
</ul>
<p>Let's take a look at each of these modes individually:</p>
<ul>
<li>Hierarchy mode reveals most callstack invocations, while grouping similar data elements and global Unity function calls together for convenience. For instance, rendering delimiters, such as <kbd>BeginGUI()</kbd> and <kbd>EndGUI()</kbd> calls, are combined together in this mode. Hierarchy mode is helpful as an initial first step for determining which function calls take the most CPU time to execute.</li>
<li>Raw Hierarchy mode is similar to Hierarchy mode, except it will separate global Unity function calls into separate entries rather than their being combined into one bulk entry. This will tend to make Breakdown View more difficult to read, but may be helpful if we're trying to count how many times a particular global method is invoked, or for determining whether one of these calls is costing more CPU/memory than anticipated. For example, each <kbd>BeginGUI()</kbd> and <kbd>EndGUI()</kbd> call will be separated into different entries, making it clearer how many times each is being called compared to the Hierarchy mode.</li>
</ul>
<p style="padding-left: 60px">Perhaps the most useful mode for the CPU Usage area is the Timeline mode option (not to be confused with the main Timeline View). This mode organizes CPU Usage during the current frame in line with how the callstack expanded and contracted during processing.</p>
<ul>
<li>Timeline mode organizes Breakdown View vertically into different sections that represent different threads at runtime, such as Main Thread, Render Thread, and various background job threads called the Unity Job System, used for loading activities such as scenes and other assets. The horizontal axis represents time, so wider blocks are consuming more CPU time than narrower blocks. The horizontal size also represents relative time, making it easy to compare how much time one function call took compared to another. The vertical axis represents the callstack, so deeper chains represent more calls in the callstack at that time.</li>
</ul>
<p style="padding-left: 60px">Under Timeline mode, blocks at the top of Breakdown View are functions (or, technically, callbacks) called by the Unity Engine at runtime (such as <kbd>Start()</kbd>, <kbd>Awake()</kbd>, or <kbd>Update()</kbd> ), whereas blocks beneath them are functions that those functions had called into, which can include functions on other components or regular C# objects.</p>
<p>The Timeline mode offers a very clean and organized way to determine which particular method in the callstack consumes the most time and how that processing time measures up against other methods being called during the same frame. This allows us to gauge the method that is the biggest cause of performance problems with minimal effort.</p>
<p>For example, let's assume that we are looking at a performance problem in the following screenshot. We can tell, with a quick glance, that there are three methods that are causing a problem, and they each consume similar amounts of processing time, due to their similar widths:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/23efdf47-d188-4d77-95dc-00c75d64bb89.png"/></p>
<p>In the previous screenshot, we have exceeded our 16.667 ms budget with calls to three different <kbd>MonoBehaviour</kbd> components. The good news is that we have three possible methods through which we can find performance improvements, which means lots of opportunities to find code that can be improved. The bad news is that increasing the performance of one method will only improve about one-third of the total processing for that frame. Hence, all three methods may need to be examined and optimized in order get back under budget.</p>
<p>It's a good idea to collapse the Unity Job System list when using Timeline mode, as it tends to obstruct the visibility of items shown in the Main Thread block, which is probably what we're most interested in.</p>
<p class="mce-root">In general, the CPU Usage area will be most useful for detecting issues that can be solved by solutions that will be explored in <a href="">Chapter 2</a>, <em>Scripting Strategies</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The GPU Usage area</h1>
                
            
            
                
<p>The GPU Usage area is similar to the CPU Usage area, except that it shows method calls and processing time as it occurs on the GPU. Relevant Unity method calls in this area will relate to cameras, drawing, opaque and transparent geometry, lighting and shadows, and so on.</p>
<p>The GPU Usage area offers hierarchical information similar to the CPU Usage area and estimates the time spent calling into various rendering functions such as <kbd>Camera.Render()</kbd> (provided rendering actually occurs during the frame currently selected in Timeline View).</p>
<p>The GPU Usage area will be a useful tool to refer to when you go through <a href="">Chapter 6</a>, <em>Dynamic Graphics</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Rendering area</h1>
                
            
            
                
<p>The Rendering area provides some generic rendering statistics that tend to focus on activities related to preparing the GPU for rendering, which involves a set of activities that occur on the CPU (as opposed to the act of rendering, which is an activity handled within the GPU and is detailed in the GPU Usage area). Breakdown View offers useful information, such as the number of SetPass calls (otherwise known as draw calls), the total number of batches used to render the scene, the number of batches saved from dynamic batching and static batching and how they are being generated, and memory consumed for textures.</p>
<p>The Rendering area also offers a button to open Frame Debugger, which will be explored more in <a href="" target="_blank">Chapter 3</a>, <em>The Benefits of Batching</em>. The remainder of this area's information will prove useful when you go through <a href="">Chapter 3</a>, <em>The Benefits of Batching</em>, and <a href="">Chapter 6</a>, <em>Dynamic Graphics</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Memory area</h1>
                
            
            
                
<p>The Memory area allows us to inspect the memory usage of the application in Breakdown View in the following two modes: </p>
<ul>
<li>Simple mode</li>
<li>Detailed mode</li>
</ul>
<p class="mce-root"/>
<p>Simple mode provides only a high-level overview of the memory consumption of subsystems. This include Unity's low-level Engine, the Mono framework (total heap size that is being watched by the garbage collector), graphical assets, audio assets and buffers, and even memory used to store data collected by the Profiler.</p>
<p>Detailed mode shows memory consumption of individual GameObjects and MonoBehaviours for both their native and managed representations. It also has a column explaining the reason why an object may be consuming memory and when it might be deallocated.</p>
<p>The garbage collector is a common feature provided by C#—the Unity's scripting language of choice—that automatically releases any memory we have allocated to store data; but, if it is handled poorly, it has the potential to stall our application for brief moments. This topic, and many more related topics, such as native and managed memory spaces, will be explored in <a href="">Chapter 8</a>, <em>Masterful Memory Management</em>.</p>
<p>Note that information only appears in Detailed mode through manual sampling by clicking on the Take Sample &lt;TargetName&gt; button. This is the only way to gather information when using Detailed mode, since performing this kind of analysis automatically for each update would be prohibitively expensive:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/03671341-5f59-4a15-83b8-2ecce6434164.png" style="width:45.83em;height:11.08em;"/></p>
<p>Breakdown View also provides a button labelled Gather Object References, which can gather more in-depth memory information pertaining to some objects.</p>
<p class="mce-root">The Memory area will be a useful tool to use when we dive into the complexities of memory management, native versus managed memory, and the garbage collector in <a href="">Chapter 8</a>, <em>Masterful Memory Management</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Audio area</h1>
                
            
            
                
<p>The Audio area grants an overview of audio statistics and can be used both to measure CPU Usage from the audio system and total memory consumed by audio sources (both for those that are playing or paused) and audio clips.</p>
<p>Breakdown View provides lots of useful insights into how the audio system is operating and how various audio channels and groups are being used.</p>
<p>The Audio area may come in handy as we explore art assets in <a href=""/><a href="">Chapter 4</a>, <em>Optimizing Your Art Assets</em>.</p>
<p class="mce-root"/>
<p>Audio is often overlooked when it comes to performance optimization, but audio can become a surprisingly large source of bottlenecks if it is not managed properly due to the potential amount of hard disk access and CPU processing required. Don't neglect it!</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Physics 3D and Physics 2D areas</h1>
                
            
            
                
<p>There are two different physics areas, one for Physics 3D  (NVIDIA 's PhysX), and another for the Physics 2D system (<strong>Box2D</strong>). This area provides various physics statistics, such as Rigidbody, Collider, and Contact counts.</p>
<p>The Breakdown View for each physics area provides some rudimentary insight into the subsystem's inner workings, but we can gain further insight by exploring the physics debugger, which we will introduce in <a href="">Chapter 5</a>, <em>Faster Physics</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The network messages and network operations areas</h1>
                
            
            
                
<p>These two areas provide information about Unity's networking system, which was introduced during the Unity 5 release cycle. The information present will depend on whether the application is using the <strong>High-Level API</strong> (<strong>HLAPI</strong>) or <strong>Transport Layer API</strong> (<strong>TLAPI</strong>) provided by Unity. HLAPI is an easier-to-use system for managing player and <kbd>GameObject</kbd> network synchronization automatically, whereas TLAPI is a thin layer that operates just above the socket level, allowing Unity developers to conjure up their own networking system.</p>
<p>Optimizing network traffic is a subject that fills an entire book all by itself, where the right solution is typically very dependent on the particular needs of the application. This will not be a Unity-specific problem, and, as such, the topic of network traffic optimization will not be explored in this book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Video area</h1>
                
            
            
                
<p>If our application happens to make use of Unity's VideoPlayer API, then we might find this area useful for profiling video playback behavior.</p>
<p>Optimization of media playback is also a complex, non-Unity-specific topic and will not be explored in this book.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The UI and UI Details areas</h1>
                
            
            
                
<p>These areas provide insight into applications making use of Unity's built-in user interface system. If we're using a custom-built or third-party user interface system (such as the popular Asset Store plugin <strong>Next-Gen UI</strong> (<strong>NGUI</strong>)), then these areas will probably provide little benefit.</p>
<p>A poorly optimized user interface can often affect one or both of the CPU and GPU, so we will investigate some code optimization strategies for UIs in <a href="">Chapter 2</a>, <em>Scripting Strategies</em>, and graphics-related approaches in <a href="">Chapter 6</a>, <em>Dynamic Graphics</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Global Illumination area</h1>
                
            
            
                
<p>The Global Illumination area gives us a very detailed insight into Unity's GI system. If our application makes use of GI, then we should refer to this area to verify that it is performing properly.</p>
<p>This area may prove useful as we explore lighting and shadowing in <a href="">Chapter 6</a>, <em>Dynamic Graphics</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Best approaches to performance analysis</h1>
                
            
            
                
<p>Good coding practices and project asset management often make finding the root cause of a performance issue relatively simple, at which point the only real problem is figuring out how to improve the code. For instance, if the method only processes a single gigantic <kbd>for</kbd> loop, then it will be a pretty safe assumption that the problem is either with how many iterations the loop is performing, whether or not the loop is causing cache misses by reading memory in a non-sequential fashion, how much work is done in each iteration, or how much work it takes to prepare for the next iteration.</p>
<p>Of course, whether we're working individually or in a group setting, a lot of our code is not always written in the cleanest way possible, and we should expect to have to profile some poor coding work from time to time. Sometimes, we are forced to implement a hacky solution for the sake of speed, and we don't always have the time to go back and refactor everything to keep up with our best coding practices. In fact, many code changes made in the name of performance optimization tend to appear very strange or arcane, often making our code base more difficult to read. The common goal of software development is to make code that is clean, feature-rich, and fast. Achieving one of these is relatively easy, but the reality is that achieving two will cost significantly more time and effort, while achieving all three is a near-impossibility.</p>
<p>At its most basic level, performance optimization is just another form of problem solving, and when we overlook the obvious while problem solving, it can be an expensive mistake. Our goal is to use benchmarking to observe our application looking for instances of problematic behavior, and to then use instrumentation to hunt through the code for clues about where the problem originates. Unfortunately, it's often very easy to get distracted by invalid data or jump to conclusions because we're being too impatient or have overlooked a subtle detail. Many of us have run into occasions during software debugging where we could have found the root cause of the problem much faster if we had simply challenged and verified our earlier assumptions. Hunting down performance issues is no different.</p>
<p>A checklist of tasks would be helpful to keep us focused on the issue, and ensure we don't waste time by trying to implement any possible optimization that has no effect on the main performance bottleneck. Of course, every project is different, with its own unique challenges to overcome, but the following checklist is general enough that it should be able to apply to any Unity project:</p>
<ul>
<li>Verify that the target script is present in the scene</li>
<li>Verify that the script appears in the scene the correct number of times</li>
<li>Verify the correct order of events</li>
<li>Minimize ongoing code changes</li>
<li>Minimize internal distractions</li>
<li>Minimize external distractions</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Verifying script presence</h1>
                
            
            
                
<p>Sometimes, there are things we expect to see, but don't. These are usually easy to spot because the human brain is very good at pattern recognition and spotting differences we didn't expect. However, there are also times where we assume that something has been happening, but it didn't. These are generally more difficult to notice, because we're often scanning for the first kind of problem, and we’re assuming that the things we don't see are working as intended. In the context of Unity, one problem that manifests itself this way is verifying that the scripts we expect to be operating are actually present in the scene.</p>
<p>Script presence can be quickly verified by typing the following into the Hierarchy window textbox:</p>
<pre>t:&lt;monobehaviour name&gt;</pre>
<p>For example, typing <kbd>t:mytestmonobehaviour</kbd> (note that it is not case-sensitive) into the Hierarchy textbox will show a shortlist of all GameObjects that currently have at least one <kbd>MyTestMonoBehaviour</kbd> script attached as a component.</p>
<p>Note that this shortlist feature also includes any GameObjects with components that derive from the given script name.</p>
<p>We should also double check that the GameObjects they are attached to are still enabled, since we may have disabled them during earlier testing since someone or something may have accidentally deactivated the object.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Verifying script count</h1>
                
            
            
                
<p>If we're looking at our Profiler data and note that a certain <kbd>MonoBehaviour</kbd> method is being executed more times than expected, or is taking longer than expected, we might want to double-check that it only occurs as many times in the scene as we expect it to. It's entirely feasible that someone created the object more times than expected in the scene file, or that we accidentally instantiated the object more than the expected number of times from code. If so, the problem could be due to conflicting or duplicated method invocations generating a performance bottleneck. We can verify the count using the same shortlist method used in the <em>Best approaches to performance analysis</em> section.</p>
<p>If we expected a specific number of components to appear in the scene, but the shortlist revealed more (or  fewer!) of these components, then it might be wise to write some initialization code that prevents this from ever happening again. We could also write some custom Editor helpers to display warnings to any level designers who might be making this mistake.</p>
<p>Preventing casual mistakes such as this is essential for good productivity, since experience tells us that, if we don't explicitly disallow something, then someone, somewhere, at some point, for whatever reason, will do it anyway. This is likely to cost us a frustrating afternoon hunting down a problem that eventually turned out to be caused by human error.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Verifying the order of events</h1>
                
            
            
                
<p>Unity applications mostly operate as a series of callbacks from <em>Native code</em> to <em>Managed code</em>. This concept will be explained in more detail in <a href="">Chapter 8</a>, <em>Masterful Memory Management</em>, but for the sake of a brief summary, Unity's main thread doesn't operate as a simple console application would. In such applications, code would be executed with some obvious starting point (usually a <kbd>main()</kbd> function), and we would then have direct control of the game engine, where we initialize major subsystems, and then the game runs in a big <kbd>while</kbd> loop (often called the game loop) that checks for user input, updates the game, renders the current scene, and repeats. This loop only exits once the player chooses to quit the game.</p>
<p>Instead, Unity handles the game loop for us, and we expect callbacks such as <kbd>Awake()</kbd>, <kbd>Start()</kbd>, <kbd>Update()</kbd>, and <kbd>FixedUpdate()</kbd> to be called at specific moments. The big difference is that we don't have fine-grained control over the order in which events of the same type are called. When a new scene is loaded (whether it's the first scene of the game or a later scene), every <kbd>MonoBehaviour</kbd> component's <kbd>Awake()</kbd> callback gets called, but there's no way of predicting the order in which this will happen.</p>
<p>So, if we take one set of objects that configure some data in their <kbd>Awake()</kbd> callback, and then another set of objects does something with that configured data in its own <kbd>Awake()</kbd> callback, some reorganization or recreation of scene objects or a random change in the code base or compilation process (it's unclear what exactly causes it) may cause the order of these <kbd>Awake()</kbd> calls to change, and then the dependent objects will probably try to do things with data that wasn't initialized how we expected. The same goes for all other callbacks provided by <kbd>MonoBehaviour</kbd> components, such as <kbd>Start()</kbd> and <kbd>Update()</kbd>.</p>
<p>In any sufficiently complex project, there's no way of telling the order in which the same type of callback gets called among a group of <kbd>MonoBehaviour</kbd> components, so we should be very careful not to assume that object callbacks are happening in a specific order. In fact, it is essential practice to never write code in a way that assumes these callbacks will need to be called in a certain order because it could break at any time.</p>
<p>A better place to handle late-stage initialization is in a <kbd>MonoBehaviour</kbd> component's <kbd>Start()</kbd> callback, which is always called after every object's <kbd>Awake()</kbd> callback is called and just before its first <kbd>Update()</kbd> call. Late-stage updates can also be done in the <kbd>LateUpdate()</kbd> callback.</p>
<p>If you're having trouble determining the actual order of events, then this is best handled by either step-through debugging with an IDE (MonoDevelop, Visual Studio, and so on) or by printing simple logging statements with <kbd>Debug.Log()</kbd>.</p>
<p>Be warned that Unity's logger is notoriously expensive. Logging is unlikely to change the order of the callbacks, but it can cause some unwanted spikes in performance if used too aggressively. Be smart and do targeted logging only on the most relevant parts of the code base.</p>
<p>Coroutines are typically used to script some sequence of events, and when they're triggered will depend on what <kbd>yield</kbd> types are being used. The most difficult and unpredictable type to debug is perhaps the <kbd>WaitForSeconds</kbd> yield type. The Unity Engine is non-deterministic, meaning that you'll get a slightly different behavior from one session to the next, even on the same hardware. For example, you might get 60 updates called during the first second of application runtime during one session, 59 in the next, and 62 in the one after that. In another session, you might get 61 updates in the first second, followed by 60, and then 59.</p>
<p>A variable number of <kbd>Update()</kbd> callbacks will be called between when the coroutine starts and when it ends, and so if the coroutine depends on the <kbd>Update()</kbd> function of something being called a specific number of times, we will run into problems. It's best to keep a coroutine's behavior dead simple and dependency-free of other behavior once it begins. Breaking this rule may be tempting, but it's essentially guaranteed that some future change is going to interact with the coroutine in an unexpected way, leading to a long, painful debugging session for a game-breaking bug that's very hard to reproduce.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Minimizing ongoing code changes</h1>
                
            
            
                
<p>Making code changes to the application in order to hunt down performance issues is best done carefully, as the changes are easy to forget as time wears on. Adding debug logging statements to our code can be tempting, but remember that it costs us time to introduce these calls, recompile our code, and remove these calls once our analysis is complete. In addition, if we forget to remove them, then they can incur unnecessary runtime overhead in the final build since Unity's debug Console window logging can be prohibitively expensive in terms of both CPU and memory.</p>
<p>A good way to combat this problem is to add a flag or comment anywhere we made a change with our name so that it's easy to find and remove it later. Hopefully, we're also wise enough to use a source control tool for our code base, making it easy to differentiate between the content of any modified files and revert them to their original state. This is an excellent way to ensure that unnecessary changes don't make it into the final version. Of course, this is by no means a guaranteed solution if we also applied a fix at the same time and didn't double-check all of our modified files before committing the change.</p>
<p>Making use of breakpoints during runtime debugging is the preferred approach, as we can trace the full callstack, variable data, and conditional code paths (for example, <kbd>if-else</kbd> blocks), without risking any code changes or wasting time on recompilation. Of course, this is not always an option if, for example, we're trying to figure out what causes something strange to happen in one out of a thousand frames. In this case, it's better to determine a threshold value to look for and add an <kbd>if</kbd> statement, with a breakpoint inside, which will be triggered when the value has exceeded the threshold.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Minimizing internal distractions</h1>
                
            
            
                
<p>The Unity Editor has its own little quirks and nuances, which can sometimes make it confusing to debug some kinds of problems.</p>
<p>Firstly, if a single frame takes a long time to process, such that our game noticeably freezes, then the Profiler may not be capable of picking up the results and recording them in the Profiler window. This can be especially annoying if we wish to catch data during application/scene initialization. The <em>Custom CPU profiling</em>, section later will offer some alternatives to explore with a view to solving this problem.</p>
<p>One common mistake (that I have admittedly fallen victim to multiple times during the writing of this book) is that if we are trying to initiate a test with a keystroke and have the Profiler window open, we should not forget to click back into the Editor's Game window before triggering the keystroke. If the Profiler is the most recently clicked window, then the Editor will send keystroke events to that, instead of the runtime application, and hence, no <kbd>GameObject</kbd> will catch the event for that keystroke. This can also apply to the GameView for rendering tasks and even coroutines using the <kbd>WaitForEndOfFrame</kbd> yield type. If the Game window is not visible and active in the Editor, then nothing is being rendered to that view, and therefore, no events that rely on Game window rendering will be triggered. Be warned!</p>
<p>Vertical sync (otherwise known as VSync) is used to match the application's frame rate to the frame rate of the device it is being displayed to; for example, a monitor may run at 60 Hertz (60 cycles per second, about 16 ms). If a rendering loop in our game is running faster than a monitor cycle – for instance, 10 ms – then the game will sit and wait for another 6 ms before outputting the rendered frame. This feature reduces screen tearing, which occurs when a new image is pushed to the monitor before the previous image was finished, and, for a brief moment, part of the new image overlaps the old image.</p>
<p>Executing the Profiler with VSync enabled will probably generate a lot of noisy spikes in the CPU Usage area under the WaitForTargetFPS heading, as the application intentionally slows itself down to match the frame rate of the display. These spikes often appear very large in Editor mode, since the Editor is typically rendering to a very small window, which doesn’t take a lot of CPU or GPU work to render.</p>
<p>This will generate unnecessary clutter, making it harder to spot the real issue(s). We should ensure that we disable the VSync checkbox under the CPU Usage area when we're on the lookout for CPU spikes during performance tests. We can disable the VSync feature entirely by navigating to Edit | Project Settings | Quality and then to the sub-page for the currently selected platform.</p>
<p>We should also ensure that a drop in performance isn't a direct result of a massive number of exceptions and error messages appearing in the Editor Console window. Unity's <kbd>Debug.Log()</kbd> and similar methods, such as <kbd>Debug.LogError()</kbd> and<br/>
<kbd>Debug.LogWarning()</kbd>, are notoriously expensive in terms of CPU Usage and heap memory consumption, which can then cause garbage collection to occur resulting in even more lost CPU cycles (refer to <a href="">Chapter 8</a>, <em>Masterful Memory Management</em>, for more information on these topics).</p>
<p>This overhead is usually unnoticeable to a human being looking at the project in Editor mode, where most errors come from the compiler or misconfigured objects. However, they can be problematic when used during any kind of runtime process, especially during profiling, where we wish to observe how the game runs in the absence of external disruptions. For example, if we are missing an object reference that we were supposed to assign through the Editor, and it is being used in an <kbd>Update()</kbd> callback, then a single <kbd>MonoBehaviour</kbd> instance could throw new exceptions every single update. This adds lots of unnecessary noise to our profiling data.</p>
<p>Note that we can hide different log level types with the buttons shown in the next screenshot. The extra logging still costs CPU and memory to execute, even though they are not being rendered, but it does allow us to filter out the junk we don't want. However, it is often good practice to keep all of these options enabled to verify that we're not missing anything important:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/dc862c86-4275-48b0-9ebc-e547a0490e38.png"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Minimizing external distractions</h1>
                
            
            
                
<p>This one is simple, but absolutely necessary. We should double-check that there are no background processes eating away CPU cycles or consuming vast swathes of memory. Being low on available memory will generally interfere with our testing, as it can cause more cache misses, hard drive access for virtual memory page-file swapping, and generally slow responsiveness on the part of the application. If our application is suddenly behaving significantly worse than anticipated, double-check the system's task manager (or equivalent) for any CPU/memory/hard disk activity that might be causing problems.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Targeted profiling of code segments</h1>
                
            
            
                
<p>If our performance problem isn't resolved by the checklist mentioned previously, then we probably have a real issue on our hands that demands further analysis. The Profiler window is effective at showing us a broad overview of performance; it can help us find specific frames to investigate and can quickly inform us which <kbd>MonoBehaviour</kbd> and/or method may be causing issues. We would then need to figure out whether the problem is reproducible, under what circumstances a performance bottleneck arises, and from where exactly within the problematic code block the issue is originating.</p>
<p>To accomplish these, we will need to perform some profiling of targeted sections of our code, and there are a handful of useful techniques we can employ for this task. For Unity projects, they essentially fit into two categories:</p>
<ul>
<li>Controlling the Profiler from script code</li>
<li>Custom timing and logging methods</li>
</ul>
<p>Note that the next section focuses on how to investigate scripting bottlenecks through C# code. Detecting the source of bottlenecks in other engine subsystems will be discussed in their related chapters.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Profiler script control</h1>
                
            
            
                
<p>The Profiler can be controlled in script code through the <kbd>Profiler</kbd> class. There are several useful methods in this class that we can explore within the Unity documentation, but the most important methods are the delimiter methods that activate and deactivate profiling at runtime. These can be accessed through the <kbd>UnityEngine.Profiling.Profiler</kbd> class through its <kbd>BeginSample()</kbd> and <kbd>EndSample()</kbd> methods.</p>
<p>Note that the delimiter methods, <kbd>BeginSample()</kbd> and <kbd>EndSample()</kbd>, are only compiled in development builds, and, as such, they will not be compiled or executed in release builds where Development Mode is unchecked. This is commonly known as <strong>non-operation</strong>, or <strong>no-op</strong>, code.</p>
<p>The <kbd>BeginSample()</kbd> method has an overload that allows a custom name for the sample to appear in the CPU Usage area's Hierarchy mode. For example, the following code will profile invocations of this method and make the data appear in Breakdown View under a custom heading, as follows:</p>
<pre>void DoSomethingCompletelyStupid() { <br/>  Profiler.BeginSample("My Profiler Sample");  <br/>  List&lt;int&gt; listOfInts = new List&lt;int&gt;();  <br/>  for(int i = 0; i &lt; 1000000; ++i) {    <br/>    listOfInts.Add(i);  <br/>  }<br/>  Profiler.EndSample();<br/>}</pre>
<p>You can download the example code files from your account at <a href="http://www.packtpub.com">http://www.packtpub.com</a> for all the <em>Packt Publishing</em> books you have purchased. If you purchased this book elsewhere, you can visit <a href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files emailed directly to you.</p>
<p>We should expect that invoking this poorly designed method (which generates a <kbd>List</kbd> containing a million integers, and then does absolutely nothing with it) will cause a huge spike in CPU Usage, chew up several megabytes of memory, and appear in the Profiler Breakdown View under the My Profiler Sample heading, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/d8dc0c20-ec0f-44a7-80e9-21dd1dec1d94.png"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Custom CPU profiling</h1>
                
            
            
                
<p>The Profiler is just one tool at our disposal. Sometimes, we may want to perform customized profiling and logging of our code. Maybe we're not confident that the Unity Profiler is giving us the right answer, maybe we consider its overhead cost too great, or maybe we just like having complete control of every single aspect of our application. Whatever our motivations, knowing some techniques to perform an independent analysis of our code is a useful skill to have. It's unlikely we'll only be working with Unity for the entirety of our game development careers, after all.</p>
<p>Profiling tools are generally very complex, so it's unlikely we would be able to generate a comparable solution on our own within a reasonable time frame. When it comes to testing CPU Usage, all we should really need is an accurate timing system, a fast, low-cost way of logging that information, and some piece of code to test against. It just so happens that the .NET library (or, technically, the Mono framework) comes with a <kbd>Stopwatch</kbd> class under the <kbd>System.Diagnostics</kbd> namespace. We can stop and start a <kbd>Stopwatch</kbd> object at any time, and we can easily acquire a measure of how much time has passed since the <kbd>Stopwatch</kbd> object was started.</p>
<p>Unfortunately, this class is not perfectly accurate; it is accurate only to milliseconds, or tenths of a millisecond, at best. Counting in a high-precision, real-time manner with a CPU clock can be a surprisingly difficult task when we start to get into it. So, in order to avoid a detailed discussion of the topic, we should try to find a way for the <kbd>Stopwatch</kbd> class to satisfy our needs.</p>
<p>If precision is important, then one effective way to increase it is by running the same test multiple times. Assuming that the test code block is both easily repeatable and not exceptionally long, we should be able to run thousands, or even millions, of tests within a reasonable time frame and then divide the total elapsed time by the number of tests we just performed to get a more accurate time for a single test.</p>
<p>Before we get obsessed with the topic of high precision, we should first ask ourselves if we even need it. Most games expect to run at 30 FPS or 60 FPS, which means that they only have around 33 ms or 16 ms, respectively, to compute everything for the entire frame. So, hypothetically, if we need to bring only the performance of a particular code block under 10 ms, then repeating the test thousands of times to get microsecond precision is too many orders of magnitude away from the target to be worthwhile.</p>
<p>The following is a class definition for a custom timer that uses a <kbd>Stopwatch</kbd> object to count time for a given number of tests:</p>
<pre>using System;<br/>using System.Diagnostics;<br/><br/>public class CustomTimer : IDisposable {<br/>  private string _timerName;<br/>  private int _numTests;<br/>  private Stopwatch _watch;<br/><br/>  // give the timer a name, and a count of the <br/>  // number of tests we're running<br/>  public CustomTimer(string timerName, int numTests) {<br/>    _timerName = timerName;<br/>    _numTests = numTests;<br/>    if (_numTests &lt;= 0) {<br/>      _numTests = 1;<br/>    }<br/>    _watch = Stopwatch.StartNew();<br/>  }<br/><br/>    // automatically called when the 'using()' block ends<br/>    public void Dispose() {<br/>    _watch.Stop();<br/>    float ms = _watch.ElapsedMilliseconds;<br/>    UnityEngine.Debug.Log(string.Format("{0} finished: {1:0.00} " + <br/>        "milliseconds total, {2:0.000000} milliseconds per-test " + <br/>        "for {3} tests", _timerName, ms, ms / _numTests, _numTests));<br/>    }<br/>}</pre>
<p>Adding an underscore before member variable names is a common and useful way of distinguishing a class's member variables (also known as fields) from a method's arguments and local variables.</p>
<p class="mce-root">The following is an example of <kbd>CustomTimer</kbd> class usage:</p>
<pre>const int numTests = 1000;<br/>using (new CustomTimer("My Test", numTests)) {<br/>  for(int i = 0; i &lt; numTests; ++i) {<br/>    TestFunction();<br/>  }<br/>} // the timer's Dispose() method is automatically called here</pre>
<p>There are three things to note when using this approach:</p>
<ul>
<li>Firstly, we are only making an average of multiple method invocations. If processing time varies enormously between invocations, then that will not be well represented in the final average.</li>
<li>Secondly, if memory access is common, then repeatedly requesting the same blocks of memory will result in an artificially higher cache hit rate (where the CPU can find data in memory very quickly because it's accessed the same region recently), which will bring the average time down when compared to a typical invocation.</li>
<li>Thirdly, the effects of <strong>Just-In-Time</strong> (<strong>JIT</strong>) compilation will be effectively hidden for similarly artificial reasons, as it only affects the first invocation of the method. JIT compilation is a .NET feature that will be covered in more detail in <a href="">Chapter 8</a>, <em>Masterful Memory Management</em>.</li>
</ul>
<p>The <kbd>using</kbd> block is typically used to safely ensure that unmanaged resources are properly destroyed when they go out of scope. When the <kbd>using</kbd> block ends, it will automatically invoke the object's <kbd>Dispose()</kbd> method to handle any cleanup operations. In order to achieve this, the object must implement the <kbd>IDisposable</kbd> interface, which forces it to define the <kbd>Dispose()</kbd> method.</p>
<p>However, the same language feature can be used to create a distinct code block, which creates a short-term object, which then automatically processes something useful when the code block ends; this is how it is being used in the preceding code block.</p>
<p>Note that the <kbd>using</kbd> block should not be confused with the <kbd>using</kbd> statement, which is used at the start of a script file to pull in additional namespaces. It's extremely ironic that the keyword for managing namespaces in C# has a naming conflict with another keyword.</p>
<p>As a result, the <kbd>using</kbd> block and the <kbd>CustomTimer</kbd> class give us a clean way of wrapping our test code that makes it obvious when and where it is being used.</p>
<p>Something else to worry about is application warm-up time. Unity has a significant start-up cost when a scene begins, given the amount of data that needs to be loaded from disk, the initialization of complex subsystems, such as the physics and rendering systems, and the number of calls to various <kbd>Awake()</kbd> and <kbd>Start()</kbd> callbacks that need to be resolved before anything else can happen. This early overhead might only last a second, but that can have a significant effect on the results of our testing if the code is also executed during this early initialization period. This makes it crucial that, if we want an accurate test, then any runtime testing should begin only after the application has reached a steady state.</p>
<p>Ideally, we would be able to execute the target code block in its own scene after its initialization has completed. This is not always possible; so, as a backup plan, we could wrap the target code block in an <kbd>Input.GetKeyDown()</kbd> check in order to assume control over it when it is invoked. For example, the following code will execute our test method only when the spacebar is pressed:</p>
<pre>if (Input.GetKeyDown(KeyCode.Space)) {<br/>  const int numTests = 1000;<br/>  using (new CustomTimer("Controlled Test", numTests)) {<br/>    for(int i = 0; i &lt; numTests; ++i) {<br/>      TestFunction();<br/>    }<br/>  }<br/>}</pre>
<p>As mentioned previously, Unity's Console window logging mechanism is prohibitively expensive. As a result, we should try not to use these logging methods in the middle of a profiling test (or during gameplay, for that matter). If we find ourselves absolutely in need of detailed profiling data that prints out lots of individual messages (such as performing a timing test on a loop to figure out which iteration is costing more time than the rest), then it would be wiser to cache the logging data and print it all out at the end, as the <kbd>CustomTimer</kbd> class does. This will reduce runtime overhead, at the cost of some memory consumption. The alternative is that many milliseconds are lost to printing each <kbd>Debug.Log()</kbd> message in the middle of the test, which pollutes the results.</p>
<p>The <kbd>CustomTimer</kbd> class also makes use of <kbd>string.Format()</kbd>. This will be covered in more detail in <a href="">Chapter 8</a>, <em>Masterful Memory Management</em>, but a short explanation is that this method is used because generating a custom <kbd>string</kbd> object using the <kbd>+</kbd> operator (for example, code such as <kbd>Debug.Log("Test: " + output);</kbd>) can result in a surprisingly large number of memory allocations, which attracts the attention of the garbage collector. Doing otherwise would conflict with our goal of achieving accurate timing and analysis and should be avoided.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Final thoughts on profiling and analysis</h1>
                
            
            
                
<p>One way of thinking about performance optimization is <em>the act of stripping away unnecessary tasks that waste valuable resources</em>. We can do the same and maximize our own productivity by minimizing any wasted effort. Effective use of the tools we have at our disposal is of paramount importance. It would serve us well to optimize our own workflow by remaining aware of some best practices and techniques.</p>
<p>Most, if not all, advice for using any kind of data-gathering tool properly can be summarized into three different strategies:</p>
<ul>
<li>Understanding the tool</li>
<li>Reducing noise</li>
<li>Focusing on the issue</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding the Profiler</h1>
                
            
            
                
<p>The Profiler is a well-designed and intuitive tool, so understanding the majority of its feature set can be gained by simply spending an hour or two exploring its options with a test project and reading its documentation. The more we know about a tool in terms of its benefits, pitfalls, features, and limitations, the more sense we can make of the information it is giving us, so it is worth spending the time to use it in a playground setting. We don't want to be two weeks away from release, with a hundred performance defects to fix, with no idea how to do performance analysis efficiently.</p>
<p>For example, always remain aware of the relative nature of Timeline View graphical display. Timeline View does not provide values on its vertical axis and automatically readjusts this axis based on the content of the last 300 frames; it can make small spikes appear to be a bigger problem than they really are because of the relative change. So, just because a spike or resting state in the timeline seems large and threatening does not necessarily mean there is a performance issue.</p>
<p>Several areas in Timeline View provide helpful benchmark bars, which appear as horizontal lines with a timing and FPS value associated with them. These should be used to determine the magnitude of the problem. Don't let the Profiler trick us into thinking that big spikes are always bad. As always, it's only important if the user will notice it.</p>
<p>As an example, if a large CPU Usage spike does not exceed the 60 FPS or 30 FPS benchmark bars (depending on the application's target frame rate), then it would be wise to ignore it and search elsewhere for CPU performance issues, since no matter how much we improve the offending piece of code, it will probably never be noticed by the end user, and therefore isn't a critical issue that affects user experience.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Reducing noise</h1>
                
            
            
                
<p>The classical definition of noise (at least in the realm of computer science) is meaningless data, and a batch of profiling data that was blindly captured with no specific target in mind is always full of data that won't interest us. More sources of data take more time to mentally process and filter, which can be very distracting. One of the best methods to avoid this is to simply reduce the amount of data we need to process by stripping away any data deemed non-vital to the current situation.</p>
<p>Reducing the clutter in the Profiler's graphical interface will make it easier to determine which subsystems are causing a spike in resource usage. Remember to use the colored checkboxes in each Timeline View area to narrow the search.</p>
<p>Be warned that these settings are autosaved in the Editor, so ensure that you re-enable them for the next profiling session, as this might cause us to miss something important next time.</p>
<p>Also, GameObjects can be deactivated to prevent them from generating profiling data, which will also help to reduce clutter in our profiling data. This will naturally cause a slight performance boost for each object we deactivate. However, if we're gradually deactivating objects and performance suddenly becomes significantly more acceptable when a specific object is deactivated, then clearly that object is related to the root cause of the problem.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Focusing on the issue</h1>
                
            
            
                
<p>This category may seem redundant, given that we've already covered reducing noise. All we should have left is the issue at hand, right? Not exactly. Focus is the skill of not letting ourselves become distracted by inconsequential tasks and wild-goose chases.</p>
<p>You will recall that profiling with the Unity Profiler comes with a minor performance cost. This cost is even more severe when using the Deep Profile option. We might even introduce more minor performance costs into our application with additional logging. It's easy to forget when and where we introduced profiling code if the hunt continues for several hours.</p>
<p>We are effectively changing the result by measuring it. Any changes we implement during data sampling can sometimes lead us to chase after non-existent bugs in the application when we could have saved ourselves a lot of time by attempting to replicate the scenario without additional profiling instrumentation. If the bottleneck is reproducible and noticeable without profiling, then it's a candidate for beginning an investigation. However, if new bottlenecks keep appearing in the middle of an existing investigation, then keep in mind that they could be bottlenecks we introduced with our test code and not an existing problem that's been newly exposed.</p>
<p>Finally, when we have finished profiling, completed our fixes, and are now ready to move on to the next investigation, we should make sure to profile the application one last time to verify that the changes have had the intended effect.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>You learned a great deal throughout this chapter on how to detect and analyze performance issues within your applications. You learned about many of the Profiler's features and secrets, explored a variety of tactics to investigate performance issues with a more hands-on approach, and have been introduced to a variety of different tips and strategies to follow. You can use these to improve your productivity immensely, so long as you appreciate the wisdom behind them and remember to exploit them when the situation makes it possible.</p>
<p>This chapter has introduced us to the tips, tactics, and strategies we need in order to identify a performance issue that requires improvement. In the remaining chapters, we will explore methods on how to fix issues and improve performance whenever possible. So, give yourself a pat on the back for getting through the boring part first. We will now move on to best practices for C# development and how to avoid common performance pitfalls in your Unity scripts. </p>


            

            
        
    </body></html>