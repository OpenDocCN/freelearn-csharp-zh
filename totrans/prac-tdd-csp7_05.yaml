- en: Tabula Rasa – Approaching an Application with TDD in Mind
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It might seem a daunting task to develop an entire application with **Test-Driven
    Development** (**TDD**). Until now, all of the examples have been relatively small.
    The functions and methods have had a tiny, limited scope. How does TDD translate
    when developing full-fledged applications? Quite well, actually.
  prefs: []
  type: TYPE_NORMAL
- en: 'Topics discussed in this chapter include:'
  prefs: []
  type: TYPE_NORMAL
- en: Yak shaving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big design up front
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: YAGNI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test small
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Devil's advocate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where to begin
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best place to begin is at the beginning. Before a developer can start coding,
    they must know what the goal of the program is. What is the purpose of the application?
    Without a clear understanding of the problem that they are attempting to solve,
    it can be difficult to get started. At the very least, it is ill-advised to begin
    without some kind of plan.
  prefs: []
  type: TYPE_NORMAL
- en: The sooner you start to code, the longer the program will take.
  prefs: []
  type: TYPE_NORMAL
- en: – Roy Carlson, University of Wisconsin
  prefs: []
  type: TYPE_NORMAL
- en: Have you ever started a craft project without any objective in mind? How did
    you know what it was you were making? Did the project turn out well? If it did,
    you more than likely picked a direction at some point and set out to achieve a
    goal. You may have even had to start over or make adjustments along the way in
    order to complete the project.
  prefs: []
  type: TYPE_NORMAL
- en: Now, imagine starting the same craft project with the desired result defined
    ahead of time. Perhaps you wanted to make a drawing. Maybe you developed a set
    of plans.It isn't until a clear understanding is achieved before you start the
    physical act of beginning the project. In this example, the likelihood of success
    is much greater. The chance for stumbling blocks along the way are minimized.
  prefs: []
  type: TYPE_NORMAL
- en: Does this mean that all questions need to be asked ahead of time? Should all
    answers be obtained before you begin? Certainly not. Sometimes just a cursory
    understanding of a problem is enough to get started. But, the clearer the objectives,
    the better the likelihood of developing the proper solution.
  prefs: []
  type: TYPE_NORMAL
- en: Yak shaving
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the examples provided in previous chapters, you may have noticed there was
    a lot of moving around of code that didn't seem to have any immediate benefit.
    In TDD, especially at the beginning of a project, some work must be done that
    doesn't seem to make much sense. Tests are written that do nothing more than prove
    the existence of a class or method. The code is refactored in a way that only
    pushes hard-coded values into another dependency. This means that more files are
    created, and you may find yourself writing a significant amount of helper classes.
    All of these activities are referred to as yak shaving.
  prefs: []
  type: TYPE_NORMAL
- en: Yak shaving has two meanings that pertain to software development. The first
    and the one to be avoided is writing things that aren't needed as a means of procrastination.
    The second is the act of doing all the things that must be done to prepare the
    code. The difference between the two is a fine line. The side of the line you
    are on is determined by your intent in writing your code. Are you avoiding the
    code that you should be writing or are you laying the groundwork for efficient
    and effective software development using TDD?
  prefs: []
  type: TYPE_NORMAL
- en: In our case, as discussed in earlier chapters, we are either laying the groundwork
    for future tests, or we are implementing a known technique for preventing writer's
    block in our tests. Sometimes, the process of preparing an application for being
    tested can take quite a while.
  prefs: []
  type: TYPE_NORMAL
- en: When working in a legacy application, you could spend the better part of a week
    simply creating factories, adding interfaces to existing classes, writing test
    doubles, or doing safe refactoring techniques. All of these activities can help
    to improve testability and ensure a smooth testing experience. It is important
    to avoid getting carried away with these activities though.  We only want to do
    them as a means of driving the next test forward.
  prefs: []
  type: TYPE_NORMAL
- en: Big design up front
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It used to be common practice to have a lengthy, and expensive, **Software Development
    Life Cycle** (**SDLC**). Large teams were assembled. Meetings were scheduled and
    discussions had, ad nauseam. Requirements were gathered and documents were created
    which consumed reams of paper that would fill the filing cabinets of each and
    every team member. A design for the system would often be democratically assembled
    and a plan laid out for the system.
  prefs: []
  type: TYPE_NORMAL
- en: Once management and/or executive teams were satisfied, development could start.
    This long and cumbersome process often meant that budgets had already been significantly
    depleted with the cost of everyone’s time in the planning stages. If for some
    reason, a flaw in the design was discovered during the development cycle, change
    orders and a slew of meetings would often occur.
  prefs: []
  type: TYPE_NORMAL
- en: Should the requirements change due to a change in markets or other external
    conditions it could potentially derail an entire program. If the SDLC did not
    allow for quick adaptation to change and rapid course correction, it would often
    spell doom for the entire project. Worse, if the change were significant enough
    it could render the need for the application obsolete.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, developing software in this manner was quite costly and would
    end in failure more often than success. The cost of change was too great and the
    resulting disruption was often detrimental to the process. These days software
    projects are more likely to be developed in some sort of Agile fashion.
  prefs: []
  type: TYPE_NORMAL
- en: A clean slate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So where do we begin a new application with TDD? Starting with TDD in mind is
    really no different from beginning any software development project. A developer
    must have some idea as to the goal of the application. The basic requirements
    should be understood. Just as we grow our application with tests, the requirements
    should grow with time.
  prefs: []
  type: TYPE_NORMAL
- en: One bite at a time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How do you eat an elephant? One bite at a time.
  prefs: []
  type: TYPE_NORMAL
- en: It is a massive undertaking to try to define and develop a monolithic application
    all at once. If you were tasked with creating Facebook you might not know where
    to begin. But, if you break the application down into logical portions such as
    *Login*, *User Dashboard*, and *News Feed*, it becomes much more manageable.
  prefs: []
  type: TYPE_NORMAL
- en: Minimum Viable Product
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each definition of work should be broken down into small deliverables. The concept
    of a **Minimum Viable Product** can apply to all aspects of our code. As the requirements
    for the monolithic application are broken down into manageable chunks, it might
    be possible to start coding. If a programming task is small enough to take only
    a couple of hours to complete, it's quite difficult to deliver something that
    wildly misses the mark.  However, if a change is required, feedback should be
    given, and adjustments can be made quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Different mindset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an application is being developed with a view towards TDD, you should take
    the same approach to small deliverables. Write a little test, write just enough
    code to make it pass, then refactor. If you're constantly running your test suite,
    or better yet, you are using a continuous test runner such as NCrunch, your feedback
    cycles should be quite quick indeed.
  prefs: []
  type: TYPE_NORMAL
- en: Never leave an ignored test, or ignore more than one test at a time.
  prefs: []
  type: TYPE_NORMAL
- en: If a test begins to fail during the development cycle it should be easy to recover.
    The code just written must be at fault. Pause the current effort and evaluate.
    Is the change necessary? Does the failing test need to change? *Skip* (xUnit)
    or *Ignore* (MSTest) your current test, if needed. Fix the code and resume by
    un-ignoring your test. Never leave an ignored test, or ignore more than one test
    at a time. Doing so will only risk the test (or worse, tests) never being completed,
    fixed, or recovered. An ignored test has no value. If a test is un-ignored at
    a later date by you or someone else and is now (or still) failing, it may be difficult
    to determine if the test is valid and indicates a true failure, or invalid and
    possibly sending you on a wild goose chase. Make sure your tests are valid, accurate,
    and provide value.
  prefs: []
  type: TYPE_NORMAL
- en: YAGNI – you aren't gonna need it
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At times, you might be compelled to write some code because you think you''ll
    need it. It''s just a simple method. If you have a table full of data you''ll
    probably need a `GetAll` method and a `GetById` method. A word of caution here:
    don''t write any code until you have a true need for it. The more code that is
    written, the more code needs to be maintained. If you write code that you think
    you might need, but never actually use, you''ve wasted effort. Worse yet, you''ve
    introduced code that must be maintained until or unless it is removed.'
  prefs: []
  type: TYPE_NORMAL
- en: Don't write code in anticipation of a future need. This is wasteful and often
    costly to develop and maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Test small
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most important things to consider when doing TDD is the size and
    scope of your tests. TDD is an exercise in fully understanding the problem you
    are trying to solve and being able to break the solution up into as many tiny
    little pieces as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let us consider something simple: an application to manage a
    list of items that need to be done. How can we break up the use cases for this
    application?'
  prefs: []
  type: TYPE_NORMAL
- en: First, using what we discussed with yak shaving, we can verify that the application
    even exists.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, verify that you are able to retrieve a listing of items to be done.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Devil's advocate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will continue to demonstrate testing small, but already we have hit our next
    example. Playing devil's advocate is a useful technique in many circumstances.
    The way that we play devil's advocate in TDD is by imagining the simplest, and
    possibly most erroneous, approach to making the test pass. We want to force the
    test to make the code right instead of writing the code that we believe to be
    correct. For instance, in this case the desire is to make the test that was just
    written pass by adding an *Items* list. But the test doesn't require that at this
    point. It only requires that Items exists as a property on the class. There is
    no designation of a type in the test. So, to play devil's advocate, make the test
    pass by using *Object* as the type and setting the `Items` object to a simple
    non-null value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Okay, now all the tests pass but that clearly isn''t a proper solution. Thinking
    small steps, we could force the implementation to have a count, surely that will
    require it to be a list of *Todos*. Add the following to the last test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To make that pass, `Items` must change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Remember what we discussed about the SOLID principles in [Chapter 4](part0142.html#47DFS0-d186949d2da74f5c95dd1712efae1195),
    *What to Know Before Getting Started*. We want to use interface segregation and
    limit ourselves only to the interface we need. We don't need the full `IList`
    interfaces capability so we don't need to use it. All that is needed is the ability
    to iterate over a collection of items. The simplest interface for doing this is
    `IEnumerable`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We still have a problem though: we are using an `Object` as our enumerable
    type. We want to use only a specific class. Let''s fix that now. Modify the last
    test one more time to include a type assertion.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, update the class, shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we added what seemed to be a fairly small test and ended up
    creating a property, assigning a default value, and creating a class. Can you
    think of any way we could have made this smaller?
  prefs: []
  type: TYPE_NORMAL
- en: Our next test might verify that the Todo items start as empty, but if we think
    back to the laws of TDD, the first law is to write a failing test. Right now,
    if we wrote a test that verified `Items` to be empty we would expect that test
    to pass. So, what test should we write?
  prefs: []
  type: TYPE_NORMAL
- en: The test we have decided to write next is a test to verify a means to add a
    Todo item.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Up to this point, we have been taking steps that would likely resemble the same
    steps you would take in normal development, cutting giant swathes of functionality
    into the code. This is the first test where we stop before we have actually achieved
    valuable functionality. This is part of taking those small steps though. We could
    deploy the application right now. It wouldn't be very useful but we do have that
    option. If we had reached the end of our sprint, the product owner might request
    that, in order to deploy as soon as possible, we hard-code in some Todo items
    just so something is available in the UI.
  prefs: []
  type: TYPE_NORMAL
- en: Our next test seems to be fairly straightforward. We will verify that we can
    actually add a Todo using our new method. There is a catch though because this
    test is testing functionality and not general class structure. We suggest having
    a test class specifically for this method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Now, that really was a flying leap off a cliff. That one test nearly changed
    all of our application code. We just completely changed the implementation of
    `Items`, and we added code to the `AddTodo` method. Is there a way that we could
    have broken those into two or more steps? We still have a lot to do with this
    application, and we will cover some of it. But, before we go on, write down the
    next few tests that you think you would write. Try not to skip this exercise because
    breaking up functionality into small chunks like this is one of the areas where
    most developers struggle when learning TDD.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to temporarily pause the forward progress of this sample application
    because we have already begun to work ourselves into a corner. To prevent getting
    blocked, we should be testing negative cases first.
  prefs: []
  type: TYPE_NORMAL
- en: Test negative cases first
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What does it mean to test negative cases first? In many computer games, especially
    role-playing games, it is common for the game designers to make it very difficult
    to win the game if you simply go straight to the boss. Instead, you must make
    side quests, make wrong turns, and get lost in the story before you can fight
    the boss. Testing is no different. Before the problem can be solved, we must first
    handle bad input, prevent exceptions, and resolve conflicts in the business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the Todo application, we mistakenly flew through and added an item to the
    Todo list without verifying that the item was valid. Now, the sprint is over and
    our user interface developers are mad at us because they do not know what to do
    with a Todo item that has no details at all. What we should have done is handle
    the cases where we receive bad data first. Let's rewind and temporarily skip the
    test we just made.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: The test we need to write now should go above the test that was just ignored,
    but in the same file. Remembering that we need to have small test increments,
    we can write a test that guards against the simplest bad data, `null`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we have removed the code that was in place for `AddTodo`. We could
    have left the code in place, but at this point it is clutter and there is currently
    no test that forces that code to be present. Sometimes, when you ignore a test,
    it is easier to remove the functionality that test was verifying instead of working
    around the functionality. There are times when the clutter could restrict your
    refactoring efforts and could result in worse code. Don't be afraid to delete
    code for tests that are being skipped, and don't be afraid to delete skipped tests
    that make their way into source control.
  prefs: []
  type: TYPE_NORMAL
- en: One other issue that we encountered when making this change is that the `AddTodoExists`
    method defined earlier in the `TodoApplicationTests` class is now failing. This
    test was a yak shaving test to start with and does not add any real value to the
    test suite, so just remove it.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the null case covered by our method, what is the next thing
    that could go wrong? Thinking about it, are there any required fields for a Todo?
    We should probably make sure the Todo has a title or description at least before
    we add it to the list.
  prefs: []
  type: TYPE_NORMAL
- en: First, before we can verify that the field has been populated, we need to verify
    that the field exists on the model. Writing model tests might seem a bit like
    overkill to you, but we find that having these tests helps to better define the
    application for others coming into it. They also provide a good attachment point
    for field validation tests later on when your business decides that the description
    field of a Todo has a maximum length of 255 characters. Let's create a new class
    for the Todo model tests.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, there is no real assert for this type of test. Simply verifying
    that we can set the description value without throwing an error will suffice.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a description field, we can verify that it is required.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We are long overdue for some refactoring and this is a good place to pause our
    testing efforts and refactor. We would like to move the model validation into
    the model. Let's create a quick test for a validation method on the Todo model
    and then move that logic into the `Todo` class.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now, at least for the moment, we want to move our validation logic over from
    the Todo list into the model. In creating the validation test and moving the logic,
    we have caused our yak shaving test to fail. The test is failing because, although
    the required method exists, it is throwing an exception because we have not populated
    the description of our Todo. We will have to remove this test as it no longer
    adds value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the tests we needed to write before we could make the refactoring change
    we wanted to make are complete. Now we can simply replace the exception logic
    dealing with model validation in the `TodoList` class with a call to `Validate`
    on the model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This change should have no effect on our tests or our resulting logic. We are
    simply relocating the validation code. There are many more validations that could
    happen. Can you think of a few that might be valuable?
  prefs: []
  type: TYPE_NORMAL
- en: It is now time to add back in our skipped test, with some minor modifications
    to pass validation.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: When testing is painful
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There may come a time when you may encounter some pain. Perhaps you've forced
    yourself into a corner with your design. Maybe you're unsure what the next, most
    interesting test would be. Sure, you didn't mean to, but conceivably you could
    have taken too great a leap between tests. Whatever the case may be, there may
    come a time when testing becomes painful.
  prefs: []
  type: TYPE_NORMAL
- en: A spike
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you find that you're stuck or you're debating between options on how to proceed,
    it might be beneficial to run a spike. A spike is a means with which you can investigate
    an idea. Give yourself a time-limit or some other limiting metric. Once sufficient
    knowledge or insight has been gained by the exercise, throw away the results.
    The purpose of the spike is not to walk away with working code. The goal should
    be to gain understanding and provide a better idea of a path forward.
  prefs: []
  type: TYPE_NORMAL
- en: Assert first
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At times, you may know the next test you want to write without being quite sure
    how to start. If this happens, start with *Assert* to determine the expected result.
    With the expectation defined, set out to make the actual value match the expected
    value. You might want to take this approach more often to assure that you’re only
    writing enough code to make the desired test pass.
  prefs: []
  type: TYPE_NORMAL
- en: Stay organized
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Remember, tests are the first consumer of your application. The best and most
    accurate documentation you can provide is a thorough and well-maintained set of
    tests. Within your test suite, create folders, nested classes, or utilize features
    of your test framework to make your tests more readable. Remember, if you do encounter
    a test failure at a later date, a descriptive test name and proper assertion will
    go a long way in describing how the result came to be.
  prefs: []
  type: TYPE_NORMAL
- en: Use `Describe` to better organize your JavaScript tests. Nest multiple levels
    by using more than one `Describe` within your tests.
  prefs: []
  type: TYPE_NORMAL
- en: Breaking down Speaker Meet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Speaker Meet application started with a simple goal: connecting technology
    speakers, communities, and conferences. The idea was simple but could evolve into
    broad complexity. It was decided at an early stage to start small and add features
    if and when it made sense. New ideas should be able to be implemented and tested
    with little effort. If an idea turned out to be the wrong direction for the site,
    the new functionality could easily be removed and abandoned. Start simply and
    release small features for quick feedback.'
  prefs: []
  type: TYPE_NORMAL
- en: Three main sections of the initial site were defined as *Speakers*, *Communities*,
    and *Conferences*. Each would need to have a listing of all speakers/communities/conferences,
    provide a way to view details about a selected item, and provide a way to search
    items based on a predefined set of criteria. This would be the Minimum Viable
    Product for the initial release.
  prefs: []
  type: TYPE_NORMAL
- en: Speakers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the beginning, it was decided that speakers would be the initial focus. Speakers
    would contain a name, email address, technology selections, and location. *Gravatar*
    would be used to provide an avatar. Future enhancements that were excluded from
    the Minimum Viable Product include a list of talks, travel distance, and ratings.
    By focusing on this limited functionality, initial feedback can be collected and
    future effort can be directed appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: Communities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The secondary focus of the Speaker Meet application revolved around technology
    communities. Meetups and user groups are typically run by dedicated volunteers
    that are always looking for new and interesting speakers for their meetings. The
    main goal of the community section of the website is to define a name, location,
    meeting day/times, and technology selections of member communities.
  prefs: []
  type: TYPE_NORMAL
- en: Conferences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Technology conferences are the third and final focus of the Speaker Meet site.
    Conferences have similar requirements to communities, in that they require a name,
    location, dates, and technology selections. They differ primarily in size, scope,
    and dates. User groups typically will have one meeting per month where one speaker
    may present to a small crowd. Conferences typically occur once a year, from one
    to many days, with many speakers presenting to many more attendees.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The technologies to be used for this project were decided early on, based on
    the knowledge and experience of the team. JavaScript and ReactJS were to be utilized
    for the front-end website. The back-end would utilize C# and WebAPI with .NET
    Core, Entity Framework, and SQL Server. All would be hosted in Azure. Knowing
    these technical requirements before coding starts goes long way towards defining
    parts of your system.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, you should have a basic understanding of Yak shaving and how it might help
    you get started. You've been cautioned about *Big design up front* and creating
    things that you might not need in anticipation of a time when they might be needed
    (YAGNI). Be sure to test small, play devil's advocate, and test negative cases.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](part0205.html#63G3A0-d186949d2da74f5c95dd1712efae1195), *Approaching
    the Problem*, the three sections of the Speaker Meet site will be discussed in
    much greater detail. More effort will be put into breaking down these initial
    statements into meaningful requirements and manageable units of work.
  prefs: []
  type: TYPE_NORMAL
