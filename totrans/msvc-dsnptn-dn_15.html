<html><head></head><body>
<div id="_idContainer073">
<h1 class="chapter-number" id="_idParaDest-216"><a id="_idTextAnchor231"/><span class="koboSpan" id="kobo.1.1">15</span></h1>
<h1 id="_idParaDest-217"><a id="_idTextAnchor232"/><span class="koboSpan" id="kobo.2.1">Wrapping It All Up</span></h1>
<p><span class="koboSpan" id="kobo.3.1">At this point, we have discovered several patterns and nuances surrounding microservices design. </span><span class="koboSpan" id="kobo.3.2">Now, let us explore our patterns at a high level and tie all the concepts together. </span><span class="koboSpan" id="kobo.3.3">It is essential to scope which pattern fits best into each situation.</span></p>
<p><span class="koboSpan" id="kobo.4.1">The microservices architectural approach to software development promotes loose coupling of autonomous processes and creating standalone software components that handle these processes. </span><span class="koboSpan" id="kobo.4.2">An excellent approach to scoping these processes is to employ the </span><strong class="bold"><span class="koboSpan" id="kobo.5.1">domain-driven design</span></strong><span class="koboSpan" id="kobo.6.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.7.1">DDD</span></strong><span class="koboSpan" id="kobo.8.1">) pattern. </span><span class="koboSpan" id="kobo.8.2">In DDD, we categorize the system’s functionality into sub-sections called domains and then use these domains to govern what services or standalone apps are needed to support each domain. </span><span class="koboSpan" id="kobo.8.3">We then use the aggregator pattern to attempt to scope the domain objects needed per service.</span></p>
<h1 id="_idParaDest-218"><a id="_idTextAnchor233"/><span class="koboSpan" id="kobo.9.1">Aggregator pattern</span></h1>
<p><span class="koboSpan" id="kobo.10.1">We scope the datas needed</span><a id="_idIndexMarker763"/><span class="koboSpan" id="kobo.11.1"> in each domain and what data needs to be shared between domains. </span><span class="koboSpan" id="kobo.11.2">At this point, we do risk duplicating data points across domains. </span><span class="koboSpan" id="kobo.11.3">Still, it is a condition we accept, given the need to promote autonomy across the services and their respective databases.</span></p>
<p><span class="koboSpan" id="kobo.12.1">In scoping the data requirements, we use the aggregator pattern, which allows us to define the various data requirements and relationships the different entities will have. </span><span class="koboSpan" id="kobo.12.2">An aggregate represents a cluster of domain objects that can be seen as a single unit. </span><span class="koboSpan" id="kobo.12.3">In this scoping exercise, we seek to find a root element in this cluster, and all other entities are seen as domain objects with associations with the root.</span></p>
<p><span class="koboSpan" id="kobo.13.1">The general idea in scoping our domain objects per service is to capture the minimum amount of data needed for each service to operate. </span><span class="koboSpan" id="kobo.13.2">This means we will try to avoid storing entire domain records in several services and instead allow our services to communicate to retrieve details that might be domain-specific and reside in another service. </span><span class="koboSpan" id="kobo.13.3">This is where we need our services to communicate.</span></p>
<h1 id="_idParaDest-219"><a id="_idTextAnchor234"/><span class="koboSpan" id="kobo.14.1">Synchronous and asynchronous communication</span></h1>
<p><span class="koboSpan" id="kobo.15.1">Our microservices </span><a id="_idIndexMarker764"/><span class="koboSpan" id="kobo.16.1">need to communicate from time to time. </span><span class="koboSpan" id="kobo.16.2">The type</span><a id="_idIndexMarker765"/><span class="koboSpan" id="kobo.17.1"> of communication that we employ is based on the type of operation that we need to complete in the end. </span><span class="koboSpan" id="kobo.17.2">Synchronous communication means that one service will directly call another and wait for a response. </span><span class="koboSpan" id="kobo.17.3">It will then use this response to inform the process it sought to complete. </span><span class="koboSpan" id="kobo.17.4">This approach is ideal for situations where one service might have some data and needs the rest from another. </span><span class="koboSpan" id="kobo.17.5">For instance, the appointment booking service knows the patient’s ID number but has no other information. </span><span class="koboSpan" id="kobo.17.6">It will then need to make a synchronous API call to the patients’ service and GET the patient’s details. </span><span class="koboSpan" id="kobo.17.7">It can then carry one to process those details as necessary.</span></p>
<p><span class="koboSpan" id="kobo.18.1">Synchronous communication is great when we need instant feedback from another service. </span><span class="koboSpan" id="kobo.18.2">Still, it can introduce issues and increase response time when several other services must be consulted. </span><span class="koboSpan" id="kobo.18.3">We also run the risk of failures with each API call attempt, and one failure might lead to a total failure. </span><span class="koboSpan" id="kobo.18.4">We need to handle partial or complete failures gracefully and relative to the rules governing the business process. </span><span class="koboSpan" id="kobo.18.5">To mitigate this risk, we must employ asynchronous communication strategies to hand it off to a more stable and always-on intermediary that will transport data to the other services as needed.</span></p>
<p><span class="koboSpan" id="kobo.19.1">Asynchronous communication is better used in processes that need another service’s participation but not necessarily immediate feedback. </span><span class="koboSpan" id="kobo.19.2">The process of booking an appointment, for instance, will need to complete several operations that involve other microservices and third-party services. </span><span class="koboSpan" id="kobo.19.3">The process, for instance, will take and save the appointment information, make a calendar entry, and send several emails and notifications. </span><span class="koboSpan" id="kobo.19.4">We can then use an asynchronous messaging system (such as RabbitMQ or Azure Service Bus) as the intermediary system that will receive the information from the microservice. </span><span class="koboSpan" id="kobo.19.5">The other services that need participation are configured to monitor the messaging system and process any data that appears. </span><span class="koboSpan" id="kobo.19.6">Each service can then individually complete its operation in its own time and independently. </span><span class="koboSpan" id="kobo.19.7">The appointment service can also confirm success based on its needs without worrying about whether everything has been done.</span></p>
<p><span class="koboSpan" id="kobo.20.1">As we separate our business process and scope and figure out which operations require synchronous communication and which ones require asynchronous communication, we find that we need better ways to format our code and properly separate the moving parts of our application’s code. </span><span class="koboSpan" id="kobo.20.2">This is where we begin looking at more complex design patterns</span><a id="_idIndexMarker766"/><span class="koboSpan" id="kobo.21.1"> such </span><a id="_idIndexMarker767"/><span class="koboSpan" id="kobo.22.1">as </span><strong class="bold"><span class="koboSpan" id="kobo.23.1">Command and Query Responsibility Separation</span></strong><span class="koboSpan" id="kobo.24.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.25.1">CQRS</span></strong><span class="koboSpan" id="kobo.26.1">).</span></p>
<h1 id="_idParaDest-220"><a id="_idTextAnchor235"/><span class="koboSpan" id="kobo.27.1">CQRS</span></h1>
<p><span class="koboSpan" id="kobo.28.1">CQRS is a popular</span><a id="_idIndexMarker768"/><span class="koboSpan" id="kobo.29.1"> pattern employed to allow developers to better organize application logic. </span><span class="koboSpan" id="kobo.29.2">It is an improvement to the originally drafted pattern called </span><strong class="bold"><span class="koboSpan" id="kobo.30.1">Command Query Separation </span></strong><span class="koboSpan" id="kobo.31.1">(</span><strong class="bold"><span class="koboSpan" id="kobo.32.1">CQS</span></strong><span class="koboSpan" id="kobo.33.1">), which</span><a id="_idIndexMarker769"/><span class="koboSpan" id="kobo.34.1"> sought to give developers a clean way to separate logic that augments data in the database (commands) from the logic that retrieves data (query).</span></p>
<p><span class="koboSpan" id="kobo.35.1">By introducing this level of separation, we can introduce additional abstractions and adhere to our SOLID principles more easily. </span><span class="koboSpan" id="kobo.35.2">Here, we introduce the concept of handlers, which represent individual units of work to be done. </span><span class="koboSpan" id="kobo.35.3">These handlers are implemented to specifically complete an operation using the minimum needed and fewest number of dependencies. </span><span class="koboSpan" id="kobo.35.4">This allows the code to become more scalable and easier to maintain.</span></p>
<p><span class="koboSpan" id="kobo.36.1">One downside to introducing this level of separation and abstraction is a major increase in the number of files and folders. </span><span class="koboSpan" id="kobo.36.2">To fully implement CQRS based on the recommended approach, we might also have several databases to support a single application. </span><span class="koboSpan" id="kobo.36.3">This is because the database used for the query operations needs to be optimized, which usually means we need a denormalized and high-speed lookup database structure. </span><span class="koboSpan" id="kobo.36.4">Our command operations might use a different database since storing data generally has stricter guidelines than reading it.</span></p>
<p><span class="koboSpan" id="kobo.37.1">Using the </span><strong class="bold"><span class="koboSpan" id="kobo.38.1">MediatR</span></strong><span class="koboSpan" id="kobo.39.1"> pattern</span><a id="_idIndexMarker770"/><span class="koboSpan" id="kobo.40.1"> with CQRS helps us more easily refer to the specific handlers needed without introducing too many lines of code to make a simple function call. </span><span class="koboSpan" id="kobo.40.2">We have access to </span><strong class="source-inline"><span class="koboSpan" id="kobo.41.1">NuGet</span></strong><span class="koboSpan" id="kobo.42.1"> packages that help us to easily implement this pattern and reduce our overall development overhead.</span></p>
<p><span class="koboSpan" id="kobo.43.1">Ultimately, this pattern should be leveraged for applications that have more complex business logic needs. </span><span class="koboSpan" id="kobo.43.2">It is not a recommended approach for standard applications that do the </span><a id="_idIndexMarker771"/><span class="koboSpan" id="kobo.44.1">basic </span><strong class="bold"><span class="koboSpan" id="kobo.45.1">Create, Read, Update, and Delete</span></strong><span class="koboSpan" id="kobo.46.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.47.1">CRUD</span></strong><span class="koboSpan" id="kobo.48.1">) operations, given the complexity level and project bloat it brings with it from an application code and supporting infrastructure perspective. </span><span class="koboSpan" id="kobo.48.2">It also introduces a new problem: keeping our read and write databases in sync.</span></p>
<p><span class="koboSpan" id="kobo.49.1">Let us take the approach where we use separate databases for query and command operations. </span><span class="koboSpan" id="kobo.49.2">We run the risk of having out-of-date data available for read operations in between</span><a id="_idIndexMarker772"/><span class="koboSpan" id="kobo.50.1"> operations. </span><span class="koboSpan" id="kobo.50.2">The best solution for the disconnect between the databases is called event sourcing.</span></p>
<h1 id="_idParaDest-221"><a id="_idTextAnchor236"/><span class="koboSpan" id="kobo.51.1">Event sourcing patterns</span></h1>
<p><span class="koboSpan" id="kobo.52.1">Event sourcing</span><a id="_idIndexMarker773"/><span class="koboSpan" id="kobo.53.1"> patterns bridge the gap between databases that need to be in sync. </span><span class="koboSpan" id="kobo.53.2">They help us track the changes across the system and act as a behind-the-scenes transport or lookup system to ensure that we always have the best data representation at any time.</span></p>
<p><span class="koboSpan" id="kobo.54.1">First, an event represents a moment in time. </span><span class="koboSpan" id="kobo.54.2">The data contained in the event will indicate the type of action taken and the resulting data. </span><span class="koboSpan" id="kobo.54.3">This information can then be used for several reasons within the system:</span></p>
<ul>
<li><span class="koboSpan" id="kobo.55.1">Complete tasks for third-party services that need the resulting data for their operations</span></li>
<li><span class="koboSpan" id="kobo.56.1">Update the database for query operations with the latest copy of the augmented record</span></li>
<li><span class="koboSpan" id="kobo.57.1">Add to an event store as a versioning mechanism</span></li>
</ul>
<p><span class="koboSpan" id="kobo.58.1">Event sourcing can play several roles in a system and can aid us in completing several routines and unique tasks. </span><span class="koboSpan" id="kobo.58.2">Routine tasks within the context could include updating our read-only query database and acting as a source of truth for services that need to be executed based on the latest data after an operation.</span></p>
<p><span class="koboSpan" id="kobo.59.1">Less routine operations would depend on implementing an event store, another database provisioned to keep track of each event and its copy of the data. </span><span class="koboSpan" id="kobo.59.2">This acts as a versioning mechanism that allows us to easily facilitate auditing activities, point-in-time lookups, and even business intelligence and analytics operations. </span><span class="koboSpan" id="kobo.59.3">By keeping track of each data version over time, we can see the precise evolution of the records and use it to inform business decisions.</span></p>
<p><span class="koboSpan" id="kobo.60.1">Not surprisingly, this pattern works naturally with CQRS, as we can easily and naturally trigger our events from our handlers. </span><span class="koboSpan" id="kobo.60.2">We can even use the event store as our query database lookup location, easing the tension associated with reading stale data. </span><span class="koboSpan" id="kobo.60.3">We can then extend our query capabilities and leverage the version and point-in-time lookups we now have access to.</span></p>
<p><span class="koboSpan" id="kobo.61.1">Through the previously mentioned </span><strong class="source-inline"><span class="koboSpan" id="kobo.62.1">NuGet</span></strong><span class="koboSpan" id="kobo.63.1"> packages that allow us to implement the MediatR pattern, we can raise events at the end of an operation. </span><span class="koboSpan" id="kobo.63.2">We can also implement handlers that subscribe to specific events and carry out their operations once an event is raised. </span><span class="koboSpan" id="kobo.63.3">This allows us to easily scale the number of subscribers per event and individually and uniquely implement operations that execute per event.</span></p>
<p><span class="koboSpan" id="kobo.64.1">These patterns are implemented per service and in no way unify code spread across several individual applications. </span><span class="koboSpan" id="kobo.64.2">Ensure that the patterns you choose are warranted for the microservice. </span><span class="koboSpan" id="kobo.64.3">Between event sourcing and CQRS, we have increased the number of scoped databases</span><a id="_idIndexMarker774"/><span class="koboSpan" id="kobo.65.1"> from one to potentially three. </span><span class="koboSpan" id="kobo.65.2">This can introduce hefty infrastructural requirements and costs.</span></p>
<p><span class="koboSpan" id="kobo.66.1">Now, let us review how we should handle database requirements in our microservices application.</span></p>
<h1 id="_idParaDest-222"><a id="_idTextAnchor237"/><span class="koboSpan" id="kobo.67.1">Database per service pattern</span></h1>
<p><span class="koboSpan" id="kobo.68.1">The microservices </span><a id="_idIndexMarker775"/><span class="koboSpan" id="kobo.69.1">architecture promotes autonomy and loose coupling of services. </span><span class="koboSpan" id="kobo.69.2">This concept of loose coupling should ideally be implemented throughout the entire code base and infrastructure. </span><span class="koboSpan" id="kobo.69.3">Sadly, this is only sometimes possible for cost reasons, especially at the database level.</span></p>
<p><span class="koboSpan" id="kobo.70.1">Databases can be expensive to license, implement, host, and maintain. </span><span class="koboSpan" id="kobo.70.2">The costs also vary based on the needs of the service that the database supports and the type of storage that is needed. </span><span class="koboSpan" id="kobo.70.3">One compelling reason to have individual databases is that we always want to choose the best technology stack for each microservice. </span><span class="koboSpan" id="kobo.70.4">Each one needs to retain its individuality, and the database choice is integral to the implementation process.</span></p>
<p><span class="koboSpan" id="kobo.71.1">We have different types of databases, and it is important to appreciate the nuances between each and use that knowledge to scope the best database solution for the data we can expect to store for each microservice. </span><span class="koboSpan" id="kobo.71.2">Let us look at some of the more popular options.</span></p>
<h2 id="_idParaDest-223"><a id="_idTextAnchor238"/><span class="koboSpan" id="kobo.72.1">Relational databases</span></h2>
<p><span class="koboSpan" id="kobo.73.1">Relational</span><a id="_idIndexMarker776"/><span class="koboSpan" id="kobo.74.1"> databases store data in a tabular </span><a id="_idIndexMarker777"/><span class="koboSpan" id="kobo.75.1">format and have strict measures to ensure that stored data is of the highest possible quality by its standards. </span><span class="koboSpan" id="kobo.75.2">They are best for systems that need to ensure data accuracy and might have several entities they need to store data for. </span><span class="koboSpan" id="kobo.75.3">They generally rely on a language called SQL to interact with data and, through a normalization process, will force us to spread data across several tables. </span><span class="koboSpan" id="kobo.75.4">This way, we can avoid repeating data and establish references to a record found in one table in other tables.</span></p>
<p><span class="koboSpan" id="kobo.76.1">The downside is that the strict rules make it difficult to scale on demand, which leads to slower read times for data related to several entities.</span></p>
<h2 id="_idParaDest-224"><a id="_idTextAnchor239"/><span class="koboSpan" id="kobo.77.1">Non-relational databases</span></h2>
<p><span class="koboSpan" id="kobo.78.1">Non-relational </span><a id="_idIndexMarker778"/><span class="koboSpan" id="kobo.79.1">databases are also referred to</span><a id="_idIndexMarker779"/><span class="koboSpan" id="kobo.80.1"> as NoSQL databases, given their structural differences from traditional relational databases. </span><span class="koboSpan" id="kobo.80.2">They are not as strict regarding data storage and allow for greater scalability. </span><span class="koboSpan" id="kobo.80.3">They are best used for systems that require flexible data storage options, given rapidly changing requirements and functionality. </span><span class="koboSpan" id="kobo.80.4">They are also popularly used as read-only databases, given that they support the data being structured acutely to the system’s needs. </span><span class="koboSpan" id="kobo.80.5">The most popular implementations of these kinds of databases include </span><a id="_idIndexMarker780"/><span class="koboSpan" id="kobo.81.1">document </span><a id="_idIndexMarker781"/><span class="koboSpan" id="kobo.82.1">databases (such as </span><strong class="bold"><span class="koboSpan" id="kobo.83.1">MongoDB</span></strong><span class="koboSpan" id="kobo.84.1"> or </span><strong class="bold"><span class="koboSpan" id="kobo.85.1">Azure Cosmos DB</span></strong><span class="koboSpan" id="kobo.86.1">), key-value databases (such </span><a id="_idIndexMarker782"/><span class="koboSpan" id="kobo.87.1">as </span><strong class="bold"><span class="koboSpan" id="kobo.88.1">Redis</span></strong><span class="koboSpan" id="kobo.89.1">), and graph </span><a id="_idIndexMarker783"/><span class="koboSpan" id="kobo.90.1">databases (such as </span><strong class="bold"><span class="koboSpan" id="kobo.91.1">Neo4j</span></strong><span class="koboSpan" id="kobo.92.1">).</span></p>
<p><span class="koboSpan" id="kobo.93.1">Each type has its strengths and weaknesses. </span><span class="koboSpan" id="kobo.93.2">The document databases option is most popularly used as an alternative to a relational database, given that it offers a more flexible way to store all the data points but keeps them in one place. </span><span class="koboSpan" id="kobo.93.3">This, however, can lead to data duplications and a reduction in overall quality if not managed properly.</span></p>
<p><span class="koboSpan" id="kobo.94.1">When considering the best database option for services, we must consider maintainability, technology maturity and ease of use, and general appropriateness for the task. </span><span class="koboSpan" id="kobo.94.2">One size certainly does not fit all, but we must also consider costs and feasibility. </span><span class="koboSpan" id="kobo.94.3">We have several approaches to implementing supporting databases for our services; each has pros and cons.</span></p>
<h2 id="_idParaDest-225"><a id="_idTextAnchor240"/><span class="koboSpan" id="kobo.95.1">One database for all services</span></h2>
<p><span class="koboSpan" id="kobo.96.1">This is the ideal </span><a id="_idIndexMarker784"/><span class="koboSpan" id="kobo.97.1">solution from a cost analysis and maintenance perspective. </span><span class="koboSpan" id="kobo.97.2">Database engines are powerful and designed to perform under heavy workloads, so having several services using the same database is not the most difficult to implement. </span><span class="koboSpan" id="kobo.97.3">The team also doesn’t need a diverse skill set to maintain the database and work with the technology.</span></p>
<p><span class="koboSpan" id="kobo.98.1">This approach, however, gives us one point of failure for all services. </span><span class="koboSpan" id="kobo.98.2">If this database goes offline, then all services will be affected. </span><span class="koboSpan" id="kobo.98.3">We also forfeit the flexibility of choosing the best database technology to support the technology stack that best implements each service. </span><span class="koboSpan" id="kobo.98.4">While most technology stacks have drivers to support most databases, the fact remains that some languages work best with certain databases. </span><span class="koboSpan" id="kobo.98.5">Be very careful when choosing this approach.</span></p>
<h2 id="_idParaDest-226"><a id="_idTextAnchor241"/><span class="koboSpan" id="kobo.99.1">One database per service</span></h2>
<p><span class="koboSpan" id="kobo.100.1">This solution </span><a id="_idIndexMarker785"/><span class="koboSpan" id="kobo.101.1">provides maximum flexibility in our per-service implementations. </span><span class="koboSpan" id="kobo.101.2">Here, we can use the database technology that best serves the programming language and framework used and the microservice’s data storage needs. </span><span class="koboSpan" id="kobo.101.3">Services requiring a tabular data storage structure can rely on a relational database. </span><span class="koboSpan" id="kobo.101.4">By extension, microservices developed using PHP technology may favor a MySQL database, and using ASP.NET Core may favor Microsoft SQL Server. </span><span class="koboSpan" id="kobo.101.5">This will ease the attrition in supporting a database because a language might have less than adequate tooling. </span><span class="koboSpan" id="kobo.101.6">On the other hand, a NodeJS-based microservice might favor MongoDB since its data doesn’t need to be as structured and might evolve faster than the other services.</span></p>
<p><span class="koboSpan" id="kobo.102.1">The obvious drawbacks here are that we need to be able to support multiple database technologies, and the skill sets must be present for routine maintenance and upkeep activities. </span><span class="koboSpan" id="kobo.102.2">We also incur additional costs for licensing and hosting options since the databases may (ideally, will) require separate server hosting arrangements.</span></p>
<p><span class="koboSpan" id="kobo.103.1">Individually, each service needs to ensure its data is as accurate and reliable as possible. </span><span class="koboSpan" id="kobo.103.2">Therefore, we use a concept called transactions to ensure that data either gets augmented successfully or not. </span><span class="koboSpan" id="kobo.103.3">This is especially useful for relational databases where the data might be spread across several tables. </span><span class="koboSpan" id="kobo.103.4">By enforcing this all-or-nothing mechanism, we mitigate partial successes and ensure that the data is consistent across all tables.</span></p>
<p><span class="koboSpan" id="kobo.104.1">Always choose the best technologies for the microservice you are constructing to address the business problem or domain. </span><span class="koboSpan" id="kobo.104.2">This flexibility is one of the more publicized benefits of having a loosely coupled application where the different parts do not need to share assets or functionality.</span></p>
<p><span class="koboSpan" id="kobo.105.1">Conversely, having separate databases supporting autonomous services can lead to serious data quality issues. </span><span class="koboSpan" id="kobo.105.2">Recall that some operations need the participation of several services, and sometimes, if one service fails to augment its data store, there is no real way to track what has failed and take corrective measures. </span><span class="koboSpan" id="kobo.105.3">Each service will handle its transaction, but an operation involving several independent databases will run the risk of partial </span><a id="_idIndexMarker786"/><span class="koboSpan" id="kobo.106.1">completion, which is bad. </span><span class="koboSpan" id="kobo.106.2">This is where we can look to the Saga pattern to help us manage this risk.</span></p>
<h1 id="_idParaDest-227"><a id="_idTextAnchor242"/><span class="koboSpan" id="kobo.107.1">Using the saga pattern across services</span></h1>
<p><span class="koboSpan" id="kobo.108.1">The saga pattern is </span><a id="_idIndexMarker787"/><span class="koboSpan" id="kobo.109.1">generally implemented to assist with the concept of all-or-nothing in our microservices application. </span><span class="koboSpan" id="kobo.109.2">Each service will do this for itself, but we need mechanisms to allow the services to communicate their success or failure to others and, by extension, act when necessary.</span></p>
<p><span class="koboSpan" id="kobo.110.1">Take, for instance, if we have an operation that requires the participation of four services, and each one will store bits of data along the way; we need a way to allow the services to report on whether their database operations were successful. </span><span class="koboSpan" id="kobo.110.2">If not, we trigger rollback operations. </span><span class="koboSpan" id="kobo.110.3">Two ways we can implement our saga patterns are through choreography or orchestration.</span></p>
<p><span class="koboSpan" id="kobo.111.1">Using choreography, we implement a messaging system (such as RabbitMQ or Azure Services Bus) where services notify each other of the completion or failure of their operations. </span><span class="koboSpan" id="kobo.111.2">There is no central control of the flow of messages. </span><span class="koboSpan" id="kobo.111.3">Still, each service is configured to act on the receipt of certain messages and publish messages based on the outcome of its internal operation. </span><span class="koboSpan" id="kobo.111.4">This is a good model where we want to retain each service’s autonomy, and no service needs any knowledge of the other.</span></p>
<p><span class="koboSpan" id="kobo.112.1">Choreography seems straightforward in theory but can be complex to implement and extend when new services need to be added to the saga. </span><span class="koboSpan" id="kobo.112.2">In the long run, each time the saga needs modification, several touchpoints will need attention. </span><span class="koboSpan" id="kobo.112.3">These factors promote the orchestration approach as a viable alternative.</span></p>
<p><span class="koboSpan" id="kobo.113.1">Using the orchestration method, we can establish a central observer that will coordinate the activities related to the saga. </span><span class="koboSpan" id="kobo.113.2">It will orchestrate each call to each service and decide on the next step based on the service’s success or failure response. </span><span class="koboSpan" id="kobo.113.3">The saga in the orchestrator is implemented to follow specific service calls in a specific order along a success track and, separately, along a failure track. </span><span class="koboSpan" id="kobo.113.4">If a failure occurs in the middle of the saga, the orchestrator will begin calling the rollback operations for each service that previously reported success.</span></p>
<p><span class="koboSpan" id="kobo.114.1">Comparably, the orchestrator approach allows for better control and oversight of what is happening at each step of the saga but might be more challenging to implement and maintain in the long run. </span><span class="koboSpan" id="kobo.114.2">We will have just as many touchpoints to maintain as the saga evolves.</span></p>
<p><span class="koboSpan" id="kobo.115.1">Your chosen approach should match your system’s needs and your desired operational behavior. </span><span class="koboSpan" id="kobo.115.2">Choreography promotes service autonomy but can lead to a spaghetti-like implementation for a large saga where we need to track which service consumes which message. </span><span class="koboSpan" id="kobo.115.3">This also makes it very difficult to debug. </span><span class="koboSpan" id="kobo.115.4">The orchestrator method forces us to introduce a central point of failure since if the orchestrator fails, nothing else can happen.</span></p>
<p><span class="koboSpan" id="kobo.116.1">Both approaches, however, hinge on the overall availability of the services and dependencies</span><a id="_idIndexMarker788"/><span class="koboSpan" id="kobo.117.1"> involved in completing the operation. </span><span class="koboSpan" id="kobo.117.2">We need to ensure that we do not take the first failure as the final response and implement logic that will try an operation several times before giving up.</span></p>
<h1 id="_idParaDest-228"><a id="_idTextAnchor243"/><span class="koboSpan" id="kobo.118.1">Resilient microservices</span></h1>
<p><span class="koboSpan" id="kobo.119.1">Building resilient </span><a id="_idIndexMarker789"/><span class="koboSpan" id="kobo.120.1">services is very important. </span><span class="koboSpan" id="kobo.120.2">This acts as a safety net against transient failures that otherwise break our system and lead to poor user experiences. </span><span class="koboSpan" id="kobo.120.3">No infrastructure is bulletproof. </span><span class="koboSpan" id="kobo.120.4">Every network has failure points, and services that rely on an imperfect network are inherently also imperfect. </span><span class="koboSpan" id="kobo.120.5">Beyond the imperfections of the infrastructure, we also need to consider the general application load and the act that our request now might be one too many. </span><span class="koboSpan" id="kobo.120.6">This doesn’t mean that the service is offline; it just means that it is stressed out.</span></p>
<p><span class="koboSpan" id="kobo.121.1">Not all failure reasons are under our control, but how our services react can be. </span><span class="koboSpan" id="kobo.121.2">By implementing retry logic, we can force a synchronous call to another service to make the call again until a successful call has been made. </span><span class="koboSpan" id="kobo.121.3">This helps us reduce the number of failures in the application and gives us more positive and accurate outcomes in our operations. </span><span class="koboSpan" id="kobo.121.4">Typical retry logic involves us making an initial call and observing the response. </span><span class="koboSpan" id="kobo.121.5">We try the call again when the response is something other than the expected outcome. </span><span class="koboSpan" id="kobo.121.6">We continue this until we receive a response that we can work with. </span><span class="koboSpan" id="kobo.121.7">This very simplified take on retry logic has some flaws, however.</span></p>
<p><span class="koboSpan" id="kobo.122.1">We should only retry for a while since we are unsure if the service is experiencing an outage. </span><span class="koboSpan" id="kobo.122.2">In that case, we need to implement a policy that will stop making the retry calls after a certain number of attempts. </span><span class="koboSpan" id="kobo.122.3">We call this a circuit-breaker policy. </span><span class="koboSpan" id="kobo.122.4">We also want to consider that we want to add some time between the retry attempts.</span></p>
<p><span class="koboSpan" id="kobo.123.1">Policies this complex can be implemented using simple code through a </span><strong class="source-inline"><span class="koboSpan" id="kobo.124.1">NuGet</span></strong><span class="koboSpan" id="kobo.125.1"> package called Polly. </span><span class="koboSpan" id="kobo.125.2">This package allows us to declare global policies that can be used to govern how our </span><strong class="source-inline"><span class="koboSpan" id="kobo.126.1">HttpClient</span></strong><span class="koboSpan" id="kobo.127.1"> services make API calls. </span><span class="koboSpan" id="kobo.127.2">We can also define specific policies for each API call.</span></p>
<p><span class="koboSpan" id="kobo.128.1">Retries go a long way in helping us maintain the appearance of a healthy application. </span><span class="koboSpan" id="kobo.128.2">Still, prevention is </span><a id="_idIndexMarker790"/><span class="koboSpan" id="kobo.129.1">better than a cure, and we prefer to track and mitigate failures before they become serious. </span><span class="koboSpan" id="kobo.129.2">For this, we need to implement health checks.</span></p>
<h1 id="_idParaDest-229"><a id="_idTextAnchor244"/><span class="koboSpan" id="kobo.130.1">Importance of health checks</span></h1>
<p><span class="koboSpan" id="kobo.131.1">A health check, as the </span><a id="_idIndexMarker791"/><span class="koboSpan" id="kobo.132.1">name suggests, allows us to track and report on the health of a service. </span><span class="koboSpan" id="kobo.132.2">Each service is a potential point of failure in an application, and each service has dependencies that can influence its health. </span><span class="koboSpan" id="kobo.132.3">We need a mechanism that allows us to probe the overall status of our services to be more proactive in solving issues.</span></p>
<p><span class="koboSpan" id="kobo.133.1">ASP.NET Core has a built-in mechanism for reporting on the health of a service, and it can very simply tell us if the service is healthy, degraded, or unhealthy. </span><span class="koboSpan" id="kobo.133.2">We can extend this functionality to report the health of not only the service but to also account for the health of the connections to dependent services such as databases and caches.</span></p>
<p><span class="koboSpan" id="kobo.134.1">We can also establish various endpoints that can be used to check different outcomes, such as general runtime versus startup health. </span><span class="koboSpan" id="kobo.134.2">This categorization comes in handy when we want to categorize monitoring operations based on the tools we are using, monitoring teams in place, or general application startup operations.</span></p>
<p><span class="koboSpan" id="kobo.135.1">We can establish liveness checks, which can be probed at regular intervals to report on the overall health of an application that is expected to be running. </span><span class="koboSpan" id="kobo.135.2">We act whenever there is an unhealthy result, which will be a part of our daily maintenance and upkeep activities. </span><span class="koboSpan" id="kobo.135.3">When a distributed application is starting up, however, and several services depend on each other, we want to accurately determine which dependent service is healthy and available before we launch the service that depends on it. </span><span class="koboSpan" id="kobo.135.4">These kinds of checks are called readiness checks.</span></p>
<p><span class="koboSpan" id="kobo.136.1">Given the complexity and often overwhelming number of services to keep track of in a distributed application, we tend to automate our hosting, deployment, and monitoring duties as much as possible. </span><span class="koboSpan" id="kobo.136.2">Containerization, which we will discuss shortly, is a standard way of hosting our applications in a lightweight and stable manner, and orchestration tools such as Kubernetes make it easy for us to perform health probes on the services and the container, which will inform us of the infrastructure’s health. </span><span class="koboSpan" id="kobo.136.3">Ultimately, we can leverage several automated tools to monitor and report on our services and dependencies.</span></p>
<p><span class="koboSpan" id="kobo.137.1">We have spent some time exploring nuances surrounding our microservices and how they relate to each </span><a id="_idIndexMarker792"/><span class="koboSpan" id="kobo.138.1">other. </span><span class="koboSpan" id="kobo.138.2">However, we have yet to discuss the nuances surrounding having one client or more client applications that need to relate to several services.</span></p>
<h1 id="_idParaDest-230"><a id="_idTextAnchor245"/><span class="koboSpan" id="kobo.139.1">API Gateways and backend for frontend</span></h1>
<p><span class="koboSpan" id="kobo.140.1">An application </span><a id="_idIndexMarker793"/><span class="koboSpan" id="kobo.141.1">based on </span><a id="_idIndexMarker794"/><span class="koboSpan" id="kobo.142.1">the microservices architecture will have a user interface that will interact with several web services. </span><span class="koboSpan" id="kobo.142.2">Recall that our services have been designed to rule over a business domain, and many operations that users complete span several domains. </span><span class="koboSpan" id="kobo.142.3">Because of this, the client application will need to have knowledge of the services and how to interact with them to complete one operation. </span><span class="koboSpan" id="kobo.142.4">By extension, we can have several clients in web and mobile applications.</span></p>
<p><span class="koboSpan" id="kobo.143.1">The problem is that we will need to implement too much logic in the client application to facilitate all the service calls, which can lead to a chatty client app. </span><span class="koboSpan" id="kobo.143.2">Then, maintenance becomes more painful with each new client that we introduce. </span><span class="koboSpan" id="kobo.143.3">The solution here is to consolidate a point of entry to our microservices. </span><span class="koboSpan" id="kobo.143.4">This is called an API gateway, and it will sit between the services and the client app.</span></p>
<p><span class="koboSpan" id="kobo.144.1">An API gateway allows us to centralize all our services behind a single endpoint address, making it easier to implement API logic. </span><span class="koboSpan" id="kobo.144.2">After a request is sent to the central endpoint, it is routed to the appropriate microservice, which exists at a different endpoint. </span><span class="koboSpan" id="kobo.144.3">The API gateway allows us to create a central register for all endpoint addresses in our application and add intermediary operations to massage request and response data in between requests as needed. </span><span class="koboSpan" id="kobo.144.4">Several technologies exist to facilitate this operation, including a lightweight ASP.NET Core application </span><a id="_idIndexMarker795"/><span class="koboSpan" id="kobo.145.1">called </span><strong class="bold"><span class="koboSpan" id="kobo.146.1">Ocelot</span></strong><span class="koboSpan" id="kobo.147.1">. </span><span class="koboSpan" id="kobo.147.2">As far as cloud options go, we can turn to Azure API Management.</span></p>
<p><span class="koboSpan" id="kobo.148.1">Now that we have a gateway, we have another issue where we have multiple clients, and each client has different API interaction needs. </span><span class="koboSpan" id="kobo.148.2">For instance, mobile devices will need different caching and security allowances than the web and smart device client apps. </span><span class="koboSpan" id="kobo.148.3">In this case, we can implement the backend for frontend pattern. </span><span class="koboSpan" id="kobo.148.4">This is much simpler than it sounds, but it needs to be properly implemented to be effective and can lead to additional hosting and maintenance costs.</span></p>
<p><span class="koboSpan" id="kobo.149.1">This pattern behooves us to provide a specially configured gateway to cater to the targeted client app’s needs. </span><span class="koboSpan" id="kobo.149.2">If our healthcare application needs to be accessed by web and mobile clients, we will implement two gateways. </span><span class="koboSpan" id="kobo.149.3">Each gateway will expose a specific API</span><a id="_idIndexMarker796"/><span class="koboSpan" id="kobo.150.1"> endpoint</span><a id="_idIndexMarker797"/><span class="koboSpan" id="kobo.151.1"> that the relevant client will consume.</span></p>
<p><span class="koboSpan" id="kobo.152.1">Now that we are catering to various client applications and devices, we need to consider security options that facilitate any client application.</span></p>
<h1 id="_idParaDest-231"><a id="_idTextAnchor246"/><span class="koboSpan" id="kobo.153.1">Bearer token security</span></h1>
<p><span class="koboSpan" id="kobo.154.1">Security is one of the</span><a id="_idIndexMarker798"/><span class="koboSpan" id="kobo.155.1"> fundamental parts of application development that we need to get right. </span><span class="koboSpan" id="kobo.155.2">Releasing software that does not control user access and permissions can have adverse side effects in the long run and allow for the exploitation of our application.</span></p>
<p><span class="koboSpan" id="kobo.156.1">Using ASP.NET Core, we have access to an authentication library called </span><strong class="source-inline"><span class="koboSpan" id="kobo.157.1">Identity Core</span></strong><span class="koboSpan" id="kobo.158.1">, which supports several authentication methods and allows us to easily integrate authentication into our application and supporting database. </span><span class="koboSpan" id="kobo.158.2">It has optimized implementations for the various authentication methods and authorization rules we implement in web applications and allows us to easily protect certain parts of our application.</span></p>
<p><span class="koboSpan" id="kobo.159.1">Typically, we use authentication to identify the user attempting to gain access to our system. </span><span class="koboSpan" id="kobo.159.2">This usually requires the user to input a username and a password. </span><span class="koboSpan" id="kobo.159.3">If their information can be validated, we can check what they are authorized to do and then create a session using their basic information. </span><span class="koboSpan" id="kobo.159.4">All of this is done to streamline an experience for the user where they can freely use different parts of the application as needed without reauthenticating each step. </span><span class="koboSpan" id="kobo.159.5">This session is also referred to as a state.</span></p>
<p><span class="koboSpan" id="kobo.160.1">In API development, we do not have the luxury of creating a session or maintaining a state. </span><span class="koboSpan" id="kobo.160.2">Therefore, we require that a user authenticates each request to secured API endpoints. </span><span class="koboSpan" id="kobo.160.3">This means we need an efficient way to allow the user to pass their information with each request, evaluate it, and then send an appropriate response.</span></p>
<p><span class="koboSpan" id="kobo.161.1">Bearer tokens are the current industry standard method of supporting this form of stateless authentication needs. </span><span class="koboSpan" id="kobo.161.2">A bearer token gets generated after the initial authentication attempt, where the user shares their username and password. </span><span class="koboSpan" id="kobo.161.3">Once the information is validated, we retrieve bits of information about the user, which we call claims, and combine them into an encoded string value, which we call a token. </span><span class="koboSpan" id="kobo.161.4">This token is then returned in the API response.</span></p>
<p><span class="koboSpan" id="kobo.162.1">The application that triggered the authentication call initially will need to store this token for future use.</span></p>
<p><span class="koboSpan" id="kobo.163.1">Now that the user has been issued a token, any follow-up API calls will need to include this token. </span><span class="koboSpan" id="kobo.163.2">When the API receives subsequent requests to secure endpoints, it will check for the presence of the token in the header section of the API request and then seek to validate the </span><a id="_idIndexMarker799"/><span class="koboSpan" id="kobo.164.1">token for the following:</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.165.1">Audience</span></strong><span class="koboSpan" id="kobo.166.1">: This is a value that depicts the expected receiving application of the token</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.167.1">Issuer</span></strong><span class="koboSpan" id="kobo.168.1">: This states the application that was issued to the token</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.169.1">Expiration Date and Time</span></strong><span class="koboSpan" id="kobo.170.1">: Tokens have a lifespan, so we ensure that the token is still usable</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.171.1">User claims</span></strong><span class="koboSpan" id="kobo.172.1">: This information usually includes the user’s roles and what they are authorized to do</span></li>
</ul>
<p><span class="koboSpan" id="kobo.173.1">We can gauge all the points we wish to validate each time a request comes in with a token; the stricter the validation rules, the more difficult it is for someone to fake or reuse a token on an API.</span></p>
<p><span class="koboSpan" id="kobo.174.1">Securing one API is simple enough, but this becomes very tedious and difficult to manage when this effort is spread across several APIs, as in a microservice-based application. </span><span class="koboSpan" id="kobo.174.2">It is not a good experience to have a user required to authenticate several times when accessing different parts of an application that might be using different services to complete a task. </span><span class="koboSpan" id="kobo.174.3">We need a central authority for token issuance and validation that all services can leverage. </span><span class="koboSpan" id="kobo.174.4">Essentially, we need to be able to use one token and validate a user across several services.</span></p>
<p><span class="koboSpan" id="kobo.175.1">Considering this new challenge, we need to use an OAuth provider to secure our services centrally and handle our user information and validation. </span><span class="koboSpan" id="kobo.175.2">An OAuth provider application can take some time to configure and launch, so several companies offer OAuth services as SaaS applications. </span><span class="koboSpan" id="kobo.175.3">Several options exist to set up and host your OAuth provider instance, but this will require more maintenance and configuration efforts. </span><span class="koboSpan" id="kobo.175.4">The benefit of self-hosting is that you have more control over the system and the security measures you implement.</span></p>
<p><span class="koboSpan" id="kobo.176.1">Duende IdentityServer is the more famed self-hosted option for an OAuth provider. </span><span class="koboSpan" id="kobo.176.2">It is based on ASP.NET Core and leverages Identity Core capabilities to deliver industry-standard security measures. </span><span class="koboSpan" id="kobo.176.3">It is free for small organizations and can be deployed as a simple web service and the central security authority for our microservices. </span><span class="koboSpan" id="kobo.176.4">They do also have a hosted model and can be compared with other hosted options, such as Microsoft Azure AD, and Auth0, to name a few.</span></p>
<p><span class="koboSpan" id="kobo.177.1">Now that we have</span><a id="_idIndexMarker800"/><span class="koboSpan" id="kobo.178.1"> explored securing our microservices, we need to figure out the best way to host them alongside their various dependencies. </span><span class="koboSpan" id="kobo.178.2">Do we use a team of web servers, or do more efficient options exist?</span></p>
<h1 id="_idParaDest-232"><a id="_idTextAnchor247"/><span class="koboSpan" id="kobo.179.1">Containers and microservices</span></h1>
<p><span class="koboSpan" id="kobo.180.1">We can typically </span><a id="_idIndexMarker801"/><span class="koboSpan" id="kobo.181.1">host a web </span><a id="_idIndexMarker802"/><span class="koboSpan" id="kobo.182.1">application or API and its supporting database on one server. </span><span class="koboSpan" id="kobo.182.2">This makes sense because everything is in one place and is easy to get to and maintain. </span><span class="koboSpan" id="kobo.182.3">But this server will also need to be very powerful and be outfitted to several applications and processes to support the different moving parts of the application.</span></p>
<p><span class="koboSpan" id="kobo.183.1">Therefore, we should consider splitting the host considerations and placing the API and the database on separate machines. </span><span class="koboSpan" id="kobo.183.2">This costs more, but we get to maintain or host better and ensure that we do not burden either the machine or the environment with applications that are not needed.</span></p>
<p><span class="koboSpan" id="kobo.184.1">When dealing with microservices, we will run into a challenging situation when attempting to replicate these hosting considerations for several services. </span><span class="koboSpan" id="kobo.184.2">We want each microservice to be autonomous functionally and from a hosting standpoint. </span><span class="koboSpan" id="kobo.184.3">Our services should share as little infrastructure as possible, so we don’t want to risk placing more than one service on the same machine. </span><span class="koboSpan" id="kobo.184.4">We also don’t want to burden a single device with supporting several hosting environment requirements since each microservice might have different needs.</span></p>
<p><span class="koboSpan" id="kobo.185.1">We turn to container hosting as a lightweight alternative to provisioning several machines. </span><span class="koboSpan" id="kobo.185.2">Each container represents a slice of machine resources with optimized storage and performance resources needed for an application to run. </span><span class="koboSpan" id="kobo.185.3">Translating this concept into our hosting needs, we can create slices of these optimized environments for each microservice, database, and another third-party service as needed.</span></p>
<p><span class="koboSpan" id="kobo.186.1">The advantage here is that we can still create optimal hosting environments for each service and supporting database, requiring far fewer machines to support this endeavor. </span><span class="koboSpan" id="kobo.186.2">Another benefit here is that each container is based on an image, representing the exact needs of the environment for the container. </span><span class="koboSpan" id="kobo.186.3">This image is reusable and repeatable, so we have less to worry about when transitioning between environments and trying to provision an environment per service. </span><span class="koboSpan" id="kobo.186.4">The image will always produce the same container, and there be no surprises during deployments.</span></p>
<p><span class="koboSpan" id="kobo.187.1">Containers are widely used and supported in the development community. </span><span class="koboSpan" id="kobo.187.2">The premiere container hosting option is Docker, an industry-leading container technology provider. </span><span class="koboSpan" id="kobo.187.3">Docker</span><a id="_idIndexMarker803"/><span class="koboSpan" id="kobo.188.1"> provides an extensive repository of container images that we can leverage</span><a id="_idIndexMarker804"/><span class="koboSpan" id="kobo.189.1"> for safe and maintained images from popular third-party applications that we typically leverage during development. </span><span class="koboSpan" id="kobo.189.2">It is also an open community, so we can create containers for our own needs and add them to the community repository for later access, whether for public or private use.</span></p>
<p><span class="koboSpan" id="kobo.190.1">When using .NET, we can generate a </span><strong class="source-inline"><span class="koboSpan" id="kobo.191.1">Dockerfile</span></strong><span class="koboSpan" id="kobo.192.1">, a file containing declarations about the image that should be used to create a container for the service we wish to host. </span><span class="koboSpan" id="kobo.192.2">This </span><strong class="source-inline"><span class="koboSpan" id="kobo.193.1">dockerfile</span></strong><span class="koboSpan" id="kobo.194.1">, written using a language called </span><strong class="bold"><span class="koboSpan" id="kobo.195.1">Yet Another Markup Language</span></strong><span class="koboSpan" id="kobo.196.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.197.1">YAML</span></strong><span class="koboSpan" id="kobo.198.1">), outlines </span><a id="_idIndexMarker805"/><span class="koboSpan" id="kobo.199.1">a base image, and then special build and deploy instructions. </span><span class="koboSpan" id="kobo.199.2">The base image states that we are borrowing information from an existing image and then we state that we wish to deploy our application to a container after combining the existing image and this application.</span></p>
<p><span class="koboSpan" id="kobo.200.1">When we use container hosting, we generate a </span><strong class="source-inline"><span class="koboSpan" id="kobo.201.1">dockerfile</span></strong><span class="koboSpan" id="kobo.202.1"> for each service, and we need to orchestrate the order in which they are started and their dependencies. </span><span class="koboSpan" id="kobo.202.2">For instance, we probably don’t want to start a service before its supporting database’s container starts. </span><span class="koboSpan" id="kobo.202.3">For this, we must use an orchestrator. </span><span class="koboSpan" id="kobo.202.4">Industry-leading options include </span><strong class="source-inline"><span class="koboSpan" id="kobo.203.1">docker-compose</span></strong><span class="koboSpan" id="kobo.204.1"> and Kubernetes.</span></p>
<p><strong class="source-inline"><span class="koboSpan" id="kobo.205.1">docker-compose</span></strong><span class="koboSpan" id="kobo.206.1"> is a simple and easy-to-understand option for container orchestration operations. </span><strong class="source-inline"><span class="koboSpan" id="kobo.207.1">docker-compose</span></strong><span class="koboSpan" id="kobo.208.1"> will refer to each </span><strong class="source-inline"><span class="koboSpan" id="kobo.209.1">dockerfile</span></strong><span class="koboSpan" id="kobo.210.1"> and allow us to outline any unique parameters we wish to include when executing this </span><strong class="source-inline"><span class="koboSpan" id="kobo.211.1">dockerfile</span></strong><span class="koboSpan" id="kobo.212.1">. </span><span class="koboSpan" id="kobo.212.2">We can also outline dependencies and provide specific configuration values for the execution of that </span><strong class="source-inline"><span class="koboSpan" id="kobo.213.1">dockerfile</span></strong><span class="koboSpan" id="kobo.214.1"> and the resulting container. </span><span class="koboSpan" id="kobo.214.2">Now, we can orchestrate the provisioning of the containers to support our web services, databases, and other applications with one command. </span><span class="koboSpan" id="kobo.214.3">We can even reuse dockerfiles to create more than one container and have several containers with the same service on a different port and possibly with different configurations. </span><span class="koboSpan" id="kobo.214.4">We can see where this can come in handy when implementing the backend for frontend pattern.</span></p>
<p><span class="koboSpan" id="kobo.215.1">Container hosting is platform-agnostic – we can leverage several hosting options, including cloud hosting options. </span><span class="koboSpan" id="kobo.215.2">Major cloud hosting providers such as Microsoft Azure and Amazon Web Services provide container hosting and orchestration support.</span></p>
<p><span class="koboSpan" id="kobo.216.1">Now that we have</span><a id="_idIndexMarker806"/><span class="koboSpan" id="kobo.217.1"> our </span><a id="_idIndexMarker807"/><span class="koboSpan" id="kobo.218.1">hosting sorted out, we need to be able to track what is happening across the application. </span><span class="koboSpan" id="kobo.218.2">Each service should provide logs of its activities, and more importantly, we need to be able to trace the logs across the various services.</span></p>
<h1 id="_idParaDest-233"><a id="_idTextAnchor248"/><span class="koboSpan" id="kobo.219.1">Centralized logging</span></h1>
<p><span class="koboSpan" id="kobo.220.1">Logging is an</span><a id="_idIndexMarker808"/><span class="koboSpan" id="kobo.221.1"> essential part of post-deployment and maintenance operations. </span><span class="koboSpan" id="kobo.221.2">Once our application has been deployed, we need to be able to track and trace errors and bottlenecks in our application. </span><span class="koboSpan" id="kobo.221.3">This is easy enough to accomplish when we have one application and one logging source. </span><span class="koboSpan" id="kobo.221.4">We can always go to one space and retrieve the logs of what has happened.</span></p>
<p><span class="koboSpan" id="kobo.222.1">.NET has native support for simple to advanced logging options. </span><span class="koboSpan" id="kobo.222.2">We can leverage the native logging operations and support powerful integrations for several logging destinations, such as the following:</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.223.1">Console</span></strong><span class="koboSpan" id="kobo.224.1">: Shows the</span><a id="_idIndexMarker809"/><span class="koboSpan" id="kobo.225.1"> log outputs in a native console window. </span><span class="koboSpan" id="kobo.225.2">Usually used during development.</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.226.1">Windows Event Log</span></strong><span class="koboSpan" id="kobo.227.1">: Also knowns as Event Viewer, this is a convenient way to view logs of several applications on a Windows-based machine.</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.228.1">Azure Log Stream</span></strong><span class="koboSpan" id="kobo.229.1">: Azure has a central logging service that supports logging for the application.</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.230.1">Azure Application Insights</span></strong><span class="koboSpan" id="kobo.231.1">: A power log aggregation service provided by Microsoft Azure.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.232.1">When writing logs, we need to decide on the type of information we are logging. </span><span class="koboSpan" id="kobo.232.2">We want to avoid logging sensitive information such as compromising user or system information since we want to protect the integrity of our system and user secrets as much as possible. </span><span class="koboSpan" id="kobo.232.3">This will be relative to the context under which the application operates. </span><span class="koboSpan" id="kobo.232.4">Still, responsibility, wisdom, and maturity must be exercised during this scoping exercise. </span><span class="koboSpan" id="kobo.232.5">We also want to consider that we do not want to include too much clutter in the logs. </span><span class="koboSpan" id="kobo.232.6">Having</span><a id="_idIndexMarker810"/><span class="koboSpan" id="kobo.233.1"> chatty logs can be as bad as having no logs at all.</span></p>
<p><span class="koboSpan" id="kobo.234.1">We also want to ensure we choose the correct classification for each log message. </span><span class="koboSpan" id="kobo.234.2">We can log messages as being any of the following levels:</span></p>
<ul>
<li><strong class="bold"><span class="koboSpan" id="kobo.235.1">Information</span></strong><span class="koboSpan" id="kobo.236.1">: General information about an operation.</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.237.1">Debug</span></strong><span class="koboSpan" id="kobo.238.1">: Usually used for development purposes. </span><span class="koboSpan" id="kobo.238.2">Should not be visible in a live environment.</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.239.1">Warning</span></strong><span class="koboSpan" id="kobo.240.1">: Depicts that something might not have gone as expected but is not a system error.</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.241.1">Error</span></strong><span class="koboSpan" id="kobo.242.1">: This occurs when an operation fails. </span><span class="koboSpan" id="kobo.242.2">They are usually used when an exception is caught and/or handled.</span></li>
<li><strong class="bold"><span class="koboSpan" id="kobo.243.1">Critical/Fatal</span></strong><span class="koboSpan" id="kobo.244.1">: Used to highlight that an operation has failed and led to a system failure.</span></li>
</ul>
<p><span class="koboSpan" id="kobo.245.1">Choosing the correct classification for the log messages goes a long way in helping the operations team to monitor and track messages that need to be prioritized.</span></p>
<p><span class="koboSpan" id="kobo.246.1">We can also add unique configurations for each logging destination and fine-tune the types of messages each will receive. </span><span class="koboSpan" id="kobo.246.2">This ability becomes relevant if we only wish to log messages that are informational to the Windows event log and all warnings, errors, and critical messages should be visible in Azure Log Stream and Application Insights. </span><span class="koboSpan" id="kobo.246.3">.NET Core allows us to make these granular adjustments.</span></p>
<p><span class="koboSpan" id="kobo.247.1">We can further extend the capabilities of the native logging libraries by using extension packages such as </span><strong class="source-inline"><span class="koboSpan" id="kobo.248.1">Serilog</span></strong><span class="koboSpan" id="kobo.249.1">. </span><strong class="source-inline"><span class="koboSpan" id="kobo.250.1">Serilog</span></strong><span class="koboSpan" id="kobo.251.1"> is the most popular logging extension library used in .NET applications. </span><span class="koboSpan" id="kobo.251.2">It supports more logging destinations such as rolling text files, databases (SQL Server, MySQL, PostgreSQL, and more), and cloud providers (Microsoft Azure, Amazon Web Services, and Google Cloud Platform), to name a few. </span><span class="koboSpan" id="kobo.251.3">We can write to multiple destinations with each log message by including this extension package in our application.</span></p>
<p><span class="koboSpan" id="kobo.252.1">Individual application logging can be set up relatively quickly, but this concept becomes complex when we attempt to correlate the logs. </span><span class="koboSpan" id="kobo.252.2">When a user has trouble accessing one feature, we need to check several possible points of failure, considering that our microservice application will trigger several actions across several services. </span><span class="koboSpan" id="kobo.252.3">We need an efficient way to collate the logs produced by each service and, by extension, be able to trace and relate calls associated with a single operation.</span></p>
<p><span class="koboSpan" id="kobo.253.1">Now, we turn to log aggregation platforms. </span><span class="koboSpan" id="kobo.253.2">Simply put, they act as log destinations and are designed to store all logs that are written to them. </span><span class="koboSpan" id="kobo.253.3">They also provide a user interface with advanced querying support. </span><span class="koboSpan" id="kobo.253.4">This is needed for a distributed application since we can now configure the aggregator as a central logging destination for several applications, and </span><a id="_idIndexMarker811"/><span class="koboSpan" id="kobo.254.1">we can more easily query the logs to find logs that might be related but from different sources. </span><span class="koboSpan" id="kobo.254.2">We can also configure them to monitor and alert when logs of specific categorizations are received.</span></p>
<p><span class="koboSpan" id="kobo.255.1">Popular options for log aggregation </span><a id="_idIndexMarker812"/><span class="koboSpan" id="kobo.256.1">include </span><strong class="bold"><span class="koboSpan" id="kobo.257.1">Seq</span></strong><span class="koboSpan" id="kobo.258.1">, the </span><strong class="bold"><span class="koboSpan" id="kobo.259.1">Elastisearch, Logstash, and Kibana</span></strong><span class="koboSpan" id="kobo.260.1"> (</span><strong class="bold"><span class="koboSpan" id="kobo.261.1">ELK</span></strong><span class="koboSpan" id="kobo.262.1">) stack, and </span><a id="_idIndexMarker813"/><span class="koboSpan" id="kobo.263.1">hosted </span><a id="_idIndexMarker814"/><span class="koboSpan" id="kobo.264.1">options such as </span><strong class="bold"><span class="koboSpan" id="kobo.265.1">Azure Application Insights</span></strong><span class="koboSpan" id="kobo.266.1"> and </span><strong class="bold"><span class="koboSpan" id="kobo.267.1">DataDog</span></strong><span class="koboSpan" id="kobo.268.1">. </span><span class="koboSpan" id="kobo.268.2">Each </span><a id="_idIndexMarker815"/><span class="koboSpan" id="kobo.269.1">platform has its strengths and weaknesses and can be leveraged for small to large applications. </span><span class="koboSpan" id="kobo.269.2">Seq is a popular option for small to medium-sized applications, and it has easy-to-use tools and supports robust querying operations. </span><span class="koboSpan" id="kobo.269.3">Still, aggregators have some limitations, and those come up when we need to properly trace logs from several sources.</span></p>
<p><span class="koboSpan" id="kobo.270.1">Tracing logs from several sources is referred to as distributed logging. </span><span class="koboSpan" id="kobo.270.2">It involves us using common information in our log messages and tracing related tags and trace IDs to correlate logs to a single event. </span><span class="koboSpan" id="kobo.270.3">This requires us to write more enriched logs containing more details and headers that a log tracing tool can use and give us the best possible information about. </span><span class="koboSpan" id="kobo.270.4">An emerging technology to support this concept is </span><strong class="bold"><span class="koboSpan" id="kobo.271.1">OpenTelemetry</span></strong><span class="koboSpan" id="kobo.272.1">, which </span><a id="_idIndexMarker816"/><span class="koboSpan" id="kobo.273.1">will produce logs with greater detail and correlation from our various applications.</span></p>
<p><span class="koboSpan" id="kobo.274.1">We can now use more specialized tools, such</span><a id="_idIndexMarker817"/><span class="koboSpan" id="kobo.275.1"> as </span><strong class="bold"><span class="koboSpan" id="kobo.276.1">Jaeger</span></strong><span class="koboSpan" id="kobo.277.1">, to sift through the enriched logs and perform even more complex queries across the logs. </span><span class="koboSpan" id="kobo.277.2">Jaeger is a free, lightweight, and </span><a id="_idIndexMarker818"/><span class="koboSpan" id="kobo.278.1">open source tool that can get us started with this concept, but we can once again use Microsoft Azure Insights for production workloads.</span></p>
<h1 id="_idParaDest-234"><a id="_idTextAnchor249"/><span class="koboSpan" id="kobo.279.1">Summary</span></h1>
<p><span class="koboSpan" id="kobo.280.1">In this chapter, we explored the various moving parts of microservices and how we can leverage different development patterns to ensure that we deliver a stable and extendable solution. </span><span class="koboSpan" id="kobo.280.2">We saw where the microservices architecture has a problem for every solution it introduces, and we need to ensure that we are aware of all the caveats of each decision we make.</span></p>
<p><span class="koboSpan" id="kobo.281.1">Ultimately, we need to ensure that we properly assess and scope the needs of our application and refrain from introducing a microservices architecture where it might not be required. </span><span class="koboSpan" id="kobo.281.2">If we end up using one, we must ensure that we make the best use of the various technologies and techniques that support our application. </span><span class="koboSpan" id="kobo.281.3">Always seek to do the minimum necessary to address an issue before introducing complexity in the name of advanced architecture.</span></p>
<p><span class="koboSpan" id="kobo.282.1">I hope you enjoyed this journey and have enough information to inform the decision-making and development processes that will be involved when you start developing microservices with ASP.NET.</span></p>
</div>
</body></html>