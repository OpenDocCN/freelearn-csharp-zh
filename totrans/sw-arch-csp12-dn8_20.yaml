- en: '20'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is dedicated to describing the Kubernetes container orchestrator
    and its implementation in Azure, called **Azure Kubernetes Service** (**AKS**).
    We discussed the importance and the tasks handled by orchestrators in the *Which
    tools are needed to manage microservices?* section of *Chapter 11, Applying a
    Microservice Architecture to Your Enterprise Application*. Here, it is worth recalling
    just that Kubernetes is the de facto standard for orchestrators.
  prefs: []
  type: TYPE_NORMAL
- en: We will show also how to install and use minikube on your local machine, which
    is a one-node Kubernetes simulator you can use to try out all of the examples
    in this chapter, and also to test your own applications. Simulators are useful
    both to avoid wasting too much money on an actual cloud-based Kubernetes cluster,
    and to provide a different Kubernetes cluster to each developer.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter explains the fundamental Kubernetes concepts and then focuses on
    how to interact with a Kubernetes cluster and how to deploy a Kubernetes application.
    All concepts are put into practice with simple examples. We recommend reading
    *Chapter 11*, *Applying a Microservice Architecture to Your Enterprise Application*,
    before reading this chapter, since we will use concepts explained in previous
    chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, in this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interacting with Azure Kubernetes clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced Kubernetes concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you will have learned how to implement and deploy
    a complete solution using Azure Kubernetes Service.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you will require the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Visual Studio 2022 free Community Edition or better, with all the database tools
    installed, or any other `.yaml` file editor, such as Visual Studio Code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A free Azure account. The *Creating an Azure account* section in *Chapter 1*,
    *Understanding the Importance of Software Architecture*, explains how to create
    one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An optional minikube installation. Installation instructions will be given in
    the *Using minikube* section of this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code for this chapter is available at [https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E](https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is an advanced open source software for managing distributed applications
    running on a computer network. Kubernetes can be used on your private machine’s
    cluster, or you can use hardware-scalable Kubernetes offerings from all main cloud
    providers. This kind of software is called an **orchestrator** since it dynamically
    allocates microservices to the available hardware resources in order to maximize
    performance. Moreover, orchestrators like Kubernetes provide stable virtual addresses
    to microservices that they move around from one machine to another, thus changing
    their physical addresses. At the time of writing, Kubernetes is the most widespread
    orchestrator and the *de facto* standard for cluster orchestration that can be
    used with a wide ecosystem of tools and applications. While not being tied to
    specific languages or frameworks, Kubernetes is a fundamental tool for managing
    hardware resources and communications in .NET distributed applications based on
    microservices. This section introduces the basic Kubernetes concepts and entities.
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes cluster is a cluster of virtual machines running the Kubernetes
    orchestrator.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_20_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.1: Computer network equipped with Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: Generally, Kubernetes is installed on specific machines referred to as **master
    nodes**, while all other computers simply run an interface software that connects
    with the software running on the master nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The virtual machines composing the cluster are called **nodes**. The smallest
    software unit we can deploy on Kubernetes is not a single application, but an
    aggregate of containerized applications called **Pod**. While Kubernetes supports
    various types of containers, the most commonly used container type is Docker,
    which we analyzed in *Chapter 11*, *Applying a Microservice Architecture to Your
    Enterprise Application*, so we will confine our discussion here to Docker. Pods
    are aggregates of Docker images, each containing one of your .NET microservices
    or microservices implemented with other technologies.
  prefs: []
  type: TYPE_NORMAL
- en: More specifically, Pods are sets of Docker images constrained to be placed together
    on the same node during the overall life of the application. They can be moved
    to other nodes, but they must be moved together. This means that they can easily
    communicate through localhost ports. Communication between different Pods, however,
    is more complex since the IP addresses of Pods are ephemeral resources because
    Pods have no fixed node where they run, but rather are moved from one node to
    another by the orchestrator. Moreover, Pods may be replicated to increase performance,
    so, in general, it makes no sense to address a message to a specific Pod; instead,
    we address it to any of the identical replicas of the same Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cluster nodes and Pods are managed by master nodes that communicate with cluster
    administrators through an API server, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_20_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.2: Kubernetes cluster'
  prefs: []
  type: TYPE_NORMAL
- en: The scheduler allocates Pods to nodes according to the administrator constraints,
    while the controller manager groups several daemons that monitor the cluster’s
    actual state and try to move it toward the desired state declared through the
    API server. There are controllers for several Kubernetes resources, from Pod replicas
    to communication facilities. In fact, each resource has some target objectives
    to be maintained while the application runs, and the controller verifies these
    objectives are actually achieved, possibly triggering corrective actions if not,
    such as moving some Pods running too slowly to less crowded nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The kubelet manages the interaction of each non-master node with the master
    nodes.
  prefs: []
  type: TYPE_NORMAL
- en: In Kubernetes, communication between Pods is handled by resources called **Services**
    that are assigned virtual addresses by the Kubernetes infrastructure and that
    forward their communications to sets of identical Pods. In short, Services are
    Kubernetes’ way of assigning consistent virtual addresses to sets of Pod replicas.
  prefs: []
  type: TYPE_NORMAL
- en: All Kubernetes entities may be assigned name-value pairs called **labels** that
    are used to reference them through a pattern-matching mechanism. More specifically,
    Selectors select Kubernetes entities by listing labels they must have.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, for instance, all Pods that receive traffic from the same Service are
    selected by specifying labels that they must have in the Service definition.
  prefs: []
  type: TYPE_NORMAL
- en: The way a Service routes its traffic to all connected Pods depends on the way
    Pods are organized. Stateless Pods are organized in so-called `ReplicaSets`. `ReplicaSets`
    have a unique virtual address assigned to the whole group and traffic is split
    equally among all Pods of the group.
  prefs: []
  type: TYPE_NORMAL
- en: 'Stateful Kubernetes Pod replicas are organized into so-called `StatefulSets`.
    `StatefulSets` use sharding to split the traffic between all their Pods. For this
    reason, Kubernetes Services assign a different name to each Pod of the `StatefulSet`
    they are connected to. These names look like the following: `basename-0.<base
    URL>`, `basename-1.<base URL>`, ..., `basename-n.<base URL>`. This way, message
    sharding is easily accomplished as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Each time a message must be sent to a `StatefulSet` composed of *N* replicas,
    you compute a hash between `0` and `N-1`, say `X`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add the postfix `X` to a base name to get a cluster address, such as `basename-x.<base
    URL>`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Send the message to the `basename-x.<base URL> cluster address`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes has no predefined storing facilities, and you can’t use node disk
    storage since Pods are moved between the available nodes, so long-term storage
    must be provided with sharded cloud databases or with other kinds of cloud storage.
    While each Pod in a StatefulSet can access a sharded cloud database with the usual
    connection string technique, Kubernetes offers a technique to abstract disk-like
    cloud storage provided by the external Kubernetes cluster environment. We will
    describe this storage in the *Advanced Kubernetes concepts* section.
  prefs: []
  type: TYPE_NORMAL
- en: All Kubernetes entities mentioned in this short introduction can be defined
    in a `.yaml` file, which, once deployed to a Kubernetes cluster, causes the creation
    of all entities defined in the file. The subsection that follows describes `.yaml`
    files, while the other subsections thereafter describe in detail all the basic
    Kubernetes objects mentioned so far, and explain how to define them in a `.yaml`
    file. Other Kubernetes objects will be described throughout the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: .yaml files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The desired configuration of a cluster and the structure of Kubernetes objects
    are described by the developer with a language called YAML, and are packaged in
    files with a `.yaml` extension.
  prefs: []
  type: TYPE_NORMAL
- en: '`.yaml` files, like JSON files, can be used to describe nested objects and
    collections in a human-readable way, but they do it with a different syntax. You
    have objects and lists, but object properties are not surrounded by `{}`, and
    lists are not surrounded by `[]`. Instead, nested objects are declared by simply
    indenting their content with spaces. The number of spaces can be freely chosen,
    but once they’ve been chosen, they must be used consistently.'
  prefs: []
  type: TYPE_NORMAL
- en: List items can be distinguished from object properties by preceding them with
    a hyphen (`-`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example involving nested objects and collections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The preceding `Person` object has a `Spouse` nested object and a nested collection
    of addresses.
  prefs: []
  type: TYPE_NORMAL
- en: 'The same example in JSON would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the syntax is more readable, since it avoids the overhead of
    parentheses.
  prefs: []
  type: TYPE_NORMAL
- en: '`.yaml` files can contain several sections, each defining a different entity,
    that are separated by a line containing the `---` string. Comments are preceded
    by a `#` symbol, which must be repeated on each comment line.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each section starts with the declaration of the Kubernetes API group and version.
    In fact, not all objects belong to the same API group. For objects that belong
    to the `core` API group, we can specify just the API version, as in the following
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'While objects belonging to different API groups must also specify the API name,
    as in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the next subsection, we analyze ReplicaSets and the Deployments that are
    built on top of them.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSets and Deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most important building block of Kubernetes applications is the ReplicaSet,
    that is, a Pod replicated *N* times. Usually, however, you use a more complex
    object that is built on top of the ReplicaSet – the Deployment. Deployments not
    only create a ReplicaSet, but also monitor them to ensure that the number of replicas
    is kept constant regardless of hardware faults and other events that might involve
    the ReplicaSets. In other words, they are a declarative way of defining ReplicaSets
    and Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Replicating the same functionalities, and thus the same Pods, is the simplest
    operation to optimize for performance: the more replicas we create of the same
    Pod, the more hardware resources and threads must be made available for the functionality
    encoded by that Pod. Thus, when we discover that a functionality becomes a bottleneck
    in the system, we may just increase the number of replicas of the Pod that encodes
    that functionality.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Each Deployment has a name (`metadata->name`), an attribute that specifies
    the desired number of replicas (`spec->replicas`), a key-value pair (`spec ->
    selector-> matchLabels`) that selects the Pods to monitor, and a template (`spec->template`)
    that specifies how to build the Pod replicas:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`namespace` is optional and, if not provided, a namespace called `default`
    is assumed. Namespaces are a way of keeping separate the objects of a Kubernetes
    cluster. For instance, a cluster can host the objects of two completely independent
    applications, each placed in a separate `namespace` in order to prevent possible
    name collisions. In a few words, Kubernetes namespaces have the same purpose as
    .NET namespaces: preventing name collisions.'
  prefs: []
  type: TYPE_NORMAL
- en: Indented inside the template is the definition of the Pod to replicate. Complex
    objects such as Deployments can also contain other kinds of templates, for instance,
    a template of disk-like memory required by the external environment. We will discuss
    this in more detail in the *Advanced Kubernetes concepts* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'In turn, the Pod template contains a `metadata` section with the labels used
    to select the Pods, and a `spec` section with a list of all of the containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Each container has a name and must specify the name of the Docker image to use
    to create the containers. If the Docker image is not contained in the public Docker
    registry, the name must be a URI that also includes the repository’s location.
  prefs: []
  type: TYPE_NORMAL
- en: Then, containers must specify the memory and CPU resources that they need to
    be created in the `resources->requests` object. A Pod replica is created only
    if these resources are currently available. The `resources->limits` object, instead,
    specifies the maximum resources a container replica can use. If, during the container
    execution, these limits are exceeded, action is taken to limit them. More specifically,
    if the CPU limit is exceeded, the container is throttled (its execution is stopped
    to restore its CPU consumption), while, if the memory limits are exceeded, the
    container is restarted. `containerPort` must be the port exposed by the container.
    Here, we can also specify further information, such as the protocol used.
  prefs: []
  type: TYPE_NORMAL
- en: CPU time is expressed in millicores; `1,000` millicores means `100%` of the
    CPU time, while memory is expressed in mebibytes (`1Mi` `=` `1,024*1,024 bytes`),
    or other units. `env` lists all the operating system environment variables to
    pass to the containers with their values.
  prefs: []
  type: TYPE_NORMAL
- en: Both containers and Pod templates can contain other fields, such as properties
    that define virtual files, and properties that define commands that return the
    readiness and the health state of the container. We will analyze these fields
    in the *Advanced Kubernetes concepts* section.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsection describes Pod sets conceived to store state information.
  prefs: []
  type: TYPE_NORMAL
- en: StatefulSets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: StatefulSets are very similar to ReplicaSets, but while the Pods of a ReplicaSet
    are indistinguishable processors that contribute in parallel to the same workload
    through load-balancing strategies, Pods in a StatefulSet have a unique identity
    and can contribute to the same workload only through sharding. This is because
    StatefulSets were conceived to store information, and information cannot be stored
    in parallel, merely split among several stores through sharding.
  prefs: []
  type: TYPE_NORMAL
- en: For the same reason, each Pod instance is always kept tied to any virtual disk
    space it requires (see the *Advanced Kubernetes concepts* section) so that each
    Pod instance is responsible for writing to a specific store.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, StatefulSets’ Pod instances have ordinal numbers attached to them.
    They are started in sequence according to these numbers, and they are stopped
    in reverse order. If the StatefulSet contains *N* replicas, these numbers go from
    `0` to `N-1`. Moreover, a unique name for each instance is obtained by chaining
    the Pod name specified in the template with the instance ordinal, in the following
    way – `<pod name>-<instance ordinal>`. Thus, instance names will be something
    like `mypodname-0`, `mypodname-1`, and so on. As we will see in the *Services*
    subsection, instance names are used to build unique cluster network URIs for all
    instances, so that other Pods can communicate with a specific instance of a StateFulSet
    Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Since Pods in a StateFulSet have memory, each of them can only serve the requests
    that can be processed with the data contained in them. Therefore, in order to
    take advantage of several Pods in a StatefulSets, we must share the whole data
    space in easy-to-compute subsets. This technique is called sharding. For instance,
    Pods of a StatefulSet that handle customers could each be assigned a different
    set of customer names according to their first letters. One could handle all customers
    whose names start with letters in the interval A-C, another the names in the interval
    D-F, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a typical StatefulSet definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The template part is the same as that of Deployments. The main difference between
    StatefulSets and Deployments is the `serviceName` field. This specifies the name
    of a service that must be connected with the StatefulSet to provide unique network
    addresses for all Pod instances. We will discuss this subject in more detail in
    the *Services* subsection. Moreover, usually, StatefulSets use some form of storage.
    We will discuss this in detail in the *Advanced Kubernetes concepts* section.
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth pointing out that the default order of the creation and stop
    strategy of StatefulSets can be changed by specifying an explicit `Parallel` value
    for the `spec->podManagementPolicy` property (the default value is `OrderedReady`).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table summarizes the differences between StatefulSets and ReplicaSets:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Features** | **StatefulSets** | **ReplicaSets** |'
  prefs: []
  type: TYPE_TB
- en: '| Unique address for the whole set | No. Each Pod in the set has a different
    address and takes care of a different kind of requests. | Yes. Pods in ReplicaSets
    are indistinguishable so each request can be served by any of them. |'
  prefs: []
  type: TYPE_TB
- en: '| Number of replicas can be increased during application lifetime | No. Since
    each Pod is in charge of a specific kind of requests and has a unique address,
    we can''t add more Pods. | Yes. Since Pods are indistinguishable, more Pods can''t
    cause problems, but just improve the performance of the whole set. |'
  prefs: []
  type: TYPE_TB
- en: '| Pods can store permanent data inside of them | Yes, they are designed for
    this. Requests are issued to Pods with the sharding technique. | No, because they
    are designed to be undistinguishable, and storing a specific datum in a specific
    Pod would make a Pod different from the others in the set. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 20.1: StataefulSets versus ReplicaSets'
  prefs: []
  type: TYPE_NORMAL
- en: The following subsection describes how to provide stable network addresses to
    both ReplicaSets and StatefulSets.
  prefs: []
  type: TYPE_NORMAL
- en: Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since Pod instances can be moved between nodes, they have no stable IP address
    attached to them. Services take care of assigning a unique and stable virtual
    address to a whole ReplicaSet and of load balancing the traffic to all its instances.
    Services are not software objects created in the cluster, but just an abstraction
    of the various settings and activities needed to implement their functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: Services work at level 4 of the protocol stack, so they understand protocols
    such as TCP, but they aren’t able to perform, for instance, HTTP-specific actions/transformations,
    such as ensuring a secure HTTPS connection. Therefore, if you need to install
    HTTPS certificates on the Kubernetes cluster, you need a more complex object that
    is capable of interacting at level 7 of the protocol stack. The `Ingress` object
    was conceived for this. We will discuss this in the next subsection.
  prefs: []
  type: TYPE_NORMAL
- en: Services also handle assigning a unique virtual address to each instance of
    a StatefulSet. In fact, there are various kinds of Services; some were conceived
    for ReplicaSets and others for StatefulSets.
  prefs: []
  type: TYPE_NORMAL
- en: A `ClusterIP` service type is assigned a unique cluster internal IP address.
    It specifies the ReplicaSets or Deployments it is connected to through label pattern
    matching. It uses tables maintained by the Kubernetes infrastructure to load balance
    the traffic it receives between all the Pod instances to which it is connected.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, other Pods can communicate with the Pods connected to a Service by
    interacting with this Service that is assigned the stable network name `<service
    name>.<service namespace>.svc.cluster.local`. Since they are just assigned local
    IP addresses, a `ClusterIP` service can’t be accessed from outside the Kubernetes
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: A ClusterIP is the usual communication choice for Deployments and ReplicaSets
    that do not communicate with anything outside of their Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the definition of a typical `ClusterIP` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Each Service can work on several ports and can route any port (`port`) to the
    ports exposed by the containers (`targetPort`). However, it is very often the
    case that `port = targetPort`. Ports can be given names, but these names are optional.
    Also, the specification of the protocol is optional; when not explicitly specified,
    all supported level 4 protocols are allowed. The `spec->selector` property specifies
    all the name/value pairs that select the Pods for the Service to which to route
    the communications it receives.
  prefs: []
  type: TYPE_NORMAL
- en: Since a `ClusterIP` service can’t be accessed from outside the Kubernetes cluster,
    we need other Service types to expose a Kubernetes application on a public IP
    address.
  prefs: []
  type: TYPE_NORMAL
- en: '`NodePort`-type Services are the simplest way to expose Pods to the outside
    world. In order to implement a `NodePort` service, the same port `x` is opened
    on all nodes of the Kubernetes cluster and each node routes the traffic it receives
    on this port to a newly created `ClusterIP` service.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In turn, the `ClusterIP` service routes its traffic to all Pods selected by
    the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram  Description automatically generated](img/B19820_20_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.3: NodePort service'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, you can simply communicate with port `x` through a public IP of any
    cluster node in order to access the Pods connected to the `NodePort` service.
    Of course, the whole process is completely automatic and hidden from the developer,
    whose only preoccupation is getting the port number `x` so they know where to
    forward the external traffic.
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition of a `NodePort` service is similar to the definition of a `ClusterIP`
    service, the only difference being that they specify a value of `NodePort` for
    the `spec->type` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As a default, a node port `x` in the range 30000-32767 is automatically chosen
    for each `targetPort` specified by the `Service`. The `port` property associated
    with each `targetPort` is meaningless for `NodePort` Services since all traffic
    passes through the selected node port `x`, and, by convention, is set to the same
    value as the `targetPort`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The developer can also set the NodePort `x` directly through a `nodePort` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: When the Kubernetes cluster is hosted on a cloud, the more convenient way to
    expose some Pods to the outside world is through a `LoadBalancer` service, in
    which case the Kubernetes cluster is exposed to the outside world through a level
    4 load balancer of the selected cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: A LoadBalancer is the usual communication choice for Deployments and ReplicaSets
    that do communicate outside of their Kubernetes cluster but don’t need advanced
    HTTP features.
  prefs: []
  type: TYPE_NORMAL
- en: 'The definition of a `LoadBalancer` service is similar to that of a `ClusterIp`
    service, the only difference being that the `spec->type` property must be set
    to `LoadBalancer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'If no further specification is added, a dynamic public IP is randomly assigned.
    However, if a specific public IP address is required, it can be set as a public
    IP address for the cluster load balancer by specifying it in the `spec->loadBalancerIP`
    property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In **Azure Kubernetes Service** (**AKS**), you must also specify the resource
    group where the IP address was allocated in an annotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'In AKS, you can remain with a dynamic IP address, but you can get a public
    static domain name of the type `<my-service-label>.<location>.cloudapp.azure.com`,
    where `<location>` is the geographic label you have chosen for your resources.
    `<my-service-label>` is a label that you have verified that makes the previous
    domain name unique. The chosen label must be declared in an annotation of your
    service, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'StatefulSets don’t need any load balancing since each Pod instance has its
    own identity, but do require a unique URL address for each Pod instance. This
    unique URL is provided by the so-called **headless Services**. Headless Services
    are defined like `ClusterIP` services, the only difference being that they have
    their `spec->clusterIP` property set to `none`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: All StatefulSets handled by a headless Service must place the Service name in
    their `spec-> serviceName` property, as already stated in the *StatefulSets* subsection.
  prefs: []
  type: TYPE_NORMAL
- en: The unique name provided by a headless Service to all `StatefulSets` Pod instances
    it handles is `<unique pod name>.<service name>.<namespace>.svc.cluster.local`.
  prefs: []
  type: TYPE_NORMAL
- en: Services only understand low-level protocols, such as TCP/IP, but most web applications
    are situated on the more sophisticated HTTP protocol. That’s why Kubernetes offers
    higher-level entities called I**ngresses** that are built on top of services.
  prefs: []
  type: TYPE_NORMAL
- en: Ingresses are fundamental in the implementation of all web-based applications
    that need support for HTTP. Moreover, since at the moment, a substantial amount
    of applications are web applications, ingresses are a **must** for all microservices
    applications. In particular, they are needed by all microservices based on ASP.NET
    Core, which we will discuss in the remainder of the book.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsection describes these and explains how to expose a set of
    Pods through a level 7 protocol load balancer, which can be used to get access
    to typical HTTP services, instead of through a `LoadBalancer` Service.
  prefs: []
  type: TYPE_NORMAL
- en: Ingresses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ingresses were conceived to enable each application running in a Kubernetes
    cluster to expose an HTTP-based interface. This is a fundamental requirement for
    any orchestrator, since nowadays all microservices applications are web applications
    that interact with their clients through HTTP-based protocols. Moreover, Ingresses
    must be very efficient since all communications with the Kubernetes cluster will
    pass through them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Accordingly, ingresses offer all of the typical services offered by an advanced
    and efficient web server. They provide the following services:'
  prefs: []
  type: TYPE_NORMAL
- en: HTTPS termination. They accept HTTPS connections and route them in HTTP format
    to any service in the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Name-based virtual hosting. They associate several domain names with the same
    IP address and route each domain, or `<domain>/<path prefix>`, to a different
    cluster Service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ingress is the usual communication choice for Deployments and ReplicaSets
    that do communicate outside of their Kubernetes cluster and need advanced HTTP
    features.
  prefs: []
  type: TYPE_NORMAL
- en: Since rewriting all functionalities of an advanced web server from scratch would
    be substantially impossible, Ingresses rely on existing web servers to offer their
    services. More specifically, Kubernetes offers the possibility to add an interface
    module called Ingress Controllers to connect each Kubernetes cluster with an existing
    web server, such as NGINX and Apache.
  prefs: []
  type: TYPE_NORMAL
- en: Ingress Controllers are custom Kubernetes objects that must be installed in
    the cluster. They handle the interface between Kubernetes and the pre-existing
    web server software, which can be either an external web server or a web server
    that is part of the Ingress Controller installation.
  prefs: []
  type: TYPE_NORMAL
- en: We will describe the installation of an Ingress Controller based on the NGINX
    web server software in the *Advanced Kubernetes concepts* section, as an example
    of the use of Helm. However, there are Ingress Controllers for all main web servers.
    The *Further reading* section contains information on how to install also an Ingress
    Controller that interfaces an external Azure Application Gateway.
  prefs: []
  type: TYPE_NORMAL
- en: HTTPS termination and name-based virtual hosting (see the explanation of these
    terms at the beginning of this subsection) can be configured in the Ingress definition
    in a way that is independent of the chosen Ingress Controller, while the way load
    balancing is achieved depends on the specific Ingress Controller chosen and on
    its configuration. Some Ingress Controller configuration data can be passed in
    the `metadata-> annotations` field of the Ingress definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Name-based virtual hosting is defined in the `spec-> rules` section of the
    Ingress definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Each rule specifies an optional hostname that can contain the `*` wildcard.
    If no hostname is provided, the rule matches all hostnames. For each rule, we
    can specify several paths, each redirected to a different service/port pair, where
    the service is referenced through its name. The way the match with each `path`
    is carried out depends on the value of `pathType`; if this value is `Prefix`,
    the specified `path` must be a prefix of any matching path. Otherwise, if this
    value is `Exact`, the match must be exact. Matches are case-sensitive.
  prefs: []
  type: TYPE_NORMAL
- en: 'HTTPS termination on a specific hostname is specified by associating it with
    a certificate encoded in a Kubernetes secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: HTTPS certificates can be obtained free of charge at [https://letsencrypt.org/](https://letsencrypt.org/).
    The procedure is explained on the website, but basically, as with all certificate
    authorities, you provide a key and they return the certificate based on that key.
    It is also possible to install a **certificate manager** that takes care of automatically
    installing and renewing the certificate. The way a key/certificate pair is encoded
    in a Kubernetes secret string is detailed in the *Advanced Kubernetes concepts*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The whole Ingress definition is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `namespace` is optional, and if not specified, is assumed to be `default`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will put into practice some of the concepts explained
    here by defining an Azure Kubernetes cluster and deploying a simple application.
  prefs: []
  type: TYPE_NORMAL
- en: Interacting with Kubernetes clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explain both how to create an Azure Kubernetes cluster,
    and how to install minikube, a Kubernetes simulator, on your local machine. All
    examples can be run on both Azure Kubernetes and your local minikube instance.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Azure Kubernetes cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create an AKS cluster, do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Type `AKS` into the Azure search box.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Kubernetes services**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then click the **Create** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After that, the following form will appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_20_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.4: Creating a Kubernetes cluster'
  prefs: []
  type: TYPE_NORMAL
- en: It is worth mentioning that you can get help simply by hovering over any ![](img/B19820_20_001.png)
    with the mouse.
  prefs: []
  type: TYPE_NORMAL
- en: As usual, you are required to specify a subscription, resource group, and region.
    Then, you can choose a unique name (**Kubernetes cluster name**) and the version
    of Kubernetes you would like to use. For computational power, you are asked to
    select a machine template for each node (**Node size**) and the number of nodes.
    While for an actual application, it is recommended to select at least three nodes,
    let’s select just two nodes for our exercise in order to save our free Azure credit.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the default virtual machine should also be set to a cheap one, so
    click **Change size** and select **DS2 v2**. Finally, set **Scale method** to
    **Manual** to prevent the number of nodes from being automatically changed, which
    might quickly burn through your free Azure credit.
  prefs: []
  type: TYPE_NORMAL
- en: The **Availability zones** setting allows you to spread your nodes across several
    geographic zones for better fault tolerance. The default is three zones. Please
    change it to two zones since we have just two nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'After implementing the preceding changes, you should see the following settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B19820_20_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.5: Chosen settings'
  prefs: []
  type: TYPE_NORMAL
- en: Now you can create your cluster by clicking the **Review + create** button.
    A review page should appear. Confirm and create the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: If you click **Next** instead of **Review + create**, you can also define other
    node types, and then you can provide security information, namely, a *service
    principal*, and specify whether you wish to enable role-based access control.
    In Azure, service principals are accounts that are associated with services you
    may use to define resource access policies. You may also change the default network
    settings and other settings.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment may take a little while (10-20 minutes). After that time, you will
    have your first Kubernetes cluster! At the end of the chapter, when the cluster
    is no longer required, please don’t forget to delete it in order to avoid wasting
    your free Azure credit.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, you will learn how to install and use minikube, a single-node
    Kubernetes simulator, on your local machine.
  prefs: []
  type: TYPE_NORMAL
- en: Using minikube
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The easiest way to install minikube is the usage of the Windows installer you
    can find in the official installation page: [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/).'
  prefs: []
  type: TYPE_NORMAL
- en: During the installation you will be prompted on the kind of virtualization tool
    to use. If you already installed Docker Desktop and WSL, please specify Docker.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a different operating system, please follow the default choices,
    instead.
  prefs: []
  type: TYPE_NORMAL
- en: The installation of Docker Desktop is explained in the technical requirements
    of *Chapter 11, Applying a Microservice Architecture to Your Enterprise Application*.
    Please note that both WSL and Docker Desktop must be installed and Docker must
    be configured to use Linux containers by default.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have minikube installed, you must add its binary to your computer
    `PATH`. The easiest way to do it is to open a PowerShell console and run the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Once installed, your cluster can be run with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'When you have finished working with the cluster, it can be stopped with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the next subsection, you will learn how to interact with your minikube instance
    or Azure cluster through Kubernetes’ official client, kubectl.
  prefs: []
  type: TYPE_NORMAL
- en: Using kubectl
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you have created your Azure Kubernetes cluster, you can interact with
    it via the Azure Cloud Shell. Click on the console icon in the top right of your
    Azure portal page. The following screenshot shows the Azure Shell icon:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_20_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.6: Azure Shell icon'
  prefs: []
  type: TYPE_NORMAL
- en: When prompted, select the **Bash Shell**. Then you will be prompted to create
    a storage account, so confirm and create it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use this shell to interact with our cluster. At the top of the shell
    there is a file icon that we will use to upload our `.yaml` files:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B19820_20_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.7: How to upload files in Azure Cloud Shell'
  prefs: []
  type: TYPE_NORMAL
- en: It is also possible to download a client called Azure CLI and to install it
    on your local machine (see [https://docs.microsoft.com/en-US/cli/azure/install-azure-cli](https://docs.microsoft.com/en-US/cli/azure/install-azure-cli)),
    but, in this case, you also need to install all the tools needed to interact with
    the Kubernetes cluster (kubectl and Helm) that are pre-installed in Azure Cloud
    Shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve created a Kubernetes cluster, you can interact with it through
    the `kubectl` command-line tool. `kubectl` is integrated into Azure Cloud Shell,
    so you just need to activate your cluster credentials to use it. You can do this
    with the following Azure Cloud Shell command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command stores the credentials that were automatically created
    to enable your interaction with the cluster in a `/.kube/config` configuration
    file. From now on, you can issue your `kubectl` commands with no further authentication.
  prefs: []
  type: TYPE_NORMAL
- en: If, instead, you need to interact with your local minikube cluster, you need
    a local installation of `kubectl`, but minikube installs it automatically for
    you.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use the automatically-installed `kubectl`, all `kubectl` commands
    must be preceded by the `minikube` command and `kubectl` must be followed by --.
    Thus, for instance, if you wanted to run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you would have to write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In the remainder of the chapter, we will write commands that work on actual
    Kubernetes clusters such as Azure Kubernetes. Therefore, when using minikube,
    remember to replace `kubectl` with `minikube kubectl` -- in your commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you issue the `kubectl get nodes` command, you get a list of all your Kubernetes
    nodes. In general, `kubectl get <object type>` lists all objects of a given type.
    You can use it with `nodes`, `pods`, `statefulset`, and so on. `kubectl get all`
    shows a list of all the objects created in your cluster. If you also add the name
    of a specific object, you will get information on just that specific object, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: If you add the `--watch` option, the object list will be continuously updated,
    so you can see the state of all the selected objects changing over time. You can
    leave this watch state by hitting *Ctrl* + *C*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command shows a detailed report on a specific object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'All objects described in a `.yaml` file, say `myClusterConfiguration.yaml`,
    can be created with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, if you modify the `.yaml` file, you can reflect all the modifications
    in your cluster with the `apply` command, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '`apply` does the same job as `create` but, if the resource already exists,
    `apply` overrides it, while `create` exits with an error message.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can destroy all objects that were created with a `.yaml` file by passing
    the same file to the `delete` command, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The `delete` command can also be passed an object type and a list of names
    of objects of that type to destroy, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The preceding `kubectl` commands should suffice for most of your practical needs.
    For more details, the *Further reading* section contains a link to the official
    documentation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we will use `kubectl create` to install a simple demo
    application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the demo Guestbook application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Guestbook application is a demo application used in the examples in the
    official Kubernetes documentation. We will use it as an example of a Kubernetes
    application since its Docker images are available in the public Docker repository,
    so we don’t need to write software.
  prefs: []
  type: TYPE_NORMAL
- en: The Guestbook application stores the opinions of customers who visit a hotel
    or a restaurant.
  prefs: []
  type: TYPE_NORMAL
- en: It is composed of a UI, and an in-memory database, based on Redis. Moreover,
    updates are sent to the master copy of the Redis database, which is automatically
    replicated in *N* read-only Redis replicas.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B19820_20_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.8: Architecture of the Guestbook application'
  prefs: []
  type: TYPE_NORMAL
- en: The UI application can be deployed in Kubernetes as a Deployment, since it is
    memoryless.
  prefs: []
  type: TYPE_NORMAL
- en: The Redis master store is deployed as a single pod `Deployment`. We can’t implement
    it with an *N*-pods `Deployment` since we need sharding for parallelizing updates.
    However, we might have used a `StatefulSet` assigning a different data shard to
    each different master Pod. However, since this is your first Kubernetes exercise
    and since write operations should not be predominant, a single master database
    should suffice in the practical case of a single restaurant/hotel.
  prefs: []
  type: TYPE_NORMAL
- en: Since all slave copies contain the same data and consequently are undistinguishable,
    they can be implemented with a `Deployment`, too.
  prefs: []
  type: TYPE_NORMAL
- en: The whole application is composed of three `.yaml` files that you can find in
    the GitHub repository associated with this book ([https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E](https://github.com/PacktPublishing/Software-Architecture-with-C-Sharp-12-and-.NET-8-4E)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the code for the master storage based on Redis that is contained in
    the `redis-master.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The file is composed of two object definitions separated by a line containing
    just `---`, that is, the object definition separator of `.yaml` files. It is common
    to group related objects, such as a Deployment with its associated Service, in
    the same file separated by the `---` objects separator symbol in order to increase
    code readability.
  prefs: []
  type: TYPE_NORMAL
- en: The first object is a `Deployment` with a single replica, and the second object
    is a `ClusterIP` Service that exposes the `Deployment` on the `6379` port at the
    internal `redis-leader.default.svc.cluster.local` network address. The Deployment
    pod template defines the three `app`, `role`, and `tier` labels with values that
    are used in the `selector` definition of the Service to connect the Service with
    the unique Pod defined in the `Deployment`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s upload the `redis-master.yaml` file to Azure Cloud Shell, and then deploy
    it in the cluster with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Once the operation is complete, you can inspect the contents of the cluster
    with `kubectl get all`.
  prefs: []
  type: TYPE_NORMAL
- en: The slave storage is defined in the `redis-slave.yaml` file and is created in
    the same way, the only difference being that this time we have two replicas, and
    a different Docker image. The full code is in the GitHub repository associated
    with this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s upload this file as well and deploy it with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The code for the UI tier is contained in the `frontend.yaml` file. `Deployment`
    has three replicas and a different Service type. Let’s upload and deploy this
    file with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'It is worthwhile analyzing the Service code in the `frontend.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Again, the full code is in the GitHub repository associated with the book.
  prefs: []
  type: TYPE_NORMAL
- en: This Service is of the `LoadBalancer` type. Since this Pod is the application
    interface with the world outside of the Kubernetes cluster, its service must have
    a fixed IP and must be load balanced. Therefore, we must use a `LoadBalancer`
    service since this is the unique service type that satisfies those requirements.
    (See the *Services* section of this chapter for more information.)
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are in Azure Kubernetes or any other cloud Kubernetes service, in order
    to get the public IP address assigned to the service, and then to the application,
    use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The preceding command should display information on all the installed services.
    You should find the public IP in the `EXTERNAL-IP` column of the list. If you
    see only `<none>` values, please repeat the command until the public IP address
    is assigned to the load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: 'If no IP is assigned after a few minutes, please verify whether there is some
    error or warning in any of the service descriptions. If not, please check whether
    all deployments are actually running using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'If, instead, you are on minikube, `LoadBalancer` services can be accessed by
    issuing this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Thus, in our case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The command should automatically open the browser.
  prefs: []
  type: TYPE_NORMAL
- en: Once you get the IP address, navigate with the browser to this address. The
    application’s home page should now appear!
  prefs: []
  type: TYPE_NORMAL
- en: 'If the page doesn’t appear, verify whether any service has an error by issuing
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'If not, also verify that all deployments are in the running state with the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'If you find problems, please look for errors in the `.yaml` files, correct
    them, and then update the object defined in the file with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have finished experimenting with the application, make sure to remove
    the application from the cluster to avoid wasting your free Azure credit (public
    IP addresses cost money) with the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl delete deployment frontend redis-master redis-slave`'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl delete service frontend redis-leader redis-follower`'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will analyze other important Kubernetes features.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Kubernetes concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss other important Kubernetes features, including
    how to assign permanent storage to StatefulSets; how to store secrets such as
    passwords, connection strings, or certificates; how a container can inform Kubernetes
    about its health state; and how to handle complex Kubernetes packages with Helm.
    All of these subjects are organized into dedicated subsections. We will start
    with the problem of permanent storage.
  prefs: []
  type: TYPE_NORMAL
- en: Requiring permanent storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since Pods are moved between nodes, they can’t store data on the disk storage
    offered by the current node where they are running, or they would lose that storage
    as soon as they are moved to a different node. This leaves us with two options:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using external databases**: With the help of databases, ReplicaSets can also
    store information. However, if we need better performance in terms of write/update
    operations, we should use distributed sharded databases based on non-SQL engines
    such as Cosmos DB or MongoDB (see *Chapter 12*, *Choosing Your Data Storage in
    the Cloud*). In this case, in order to take maximum advantage of table sharding,
    we need StatefulSets, where each Pod instance takes care of a different table
    shard.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Using cloud storage**: Not being tied to a physical cluster node, cloud storage
    can be associated permanently with specific Pod instances of StatefulSets. Cloud
    storage is discussed in the *Redis* and *Azure storage accounts* sections of *Chapter
    12*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since access to external databases doesn’t require any Kubernetes-specific techniques
    but can be done with the usual connection strings, we will concentrate on cloud
    storage.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes offers an abstraction of storage called **PersistentVolumeClaim**
    (**PVC**) that is independent of the underlying storage provider. More specifically,
    PVCs are allocation requests that are either matched to predefined resources or
    allocated dynamically. When the Kubernetes cluster is in the cloud, typically,
    you use dynamic allocation carried out by dynamic providers installed by the cloud
    provider. For more information on cloud storage, please refer to *Chapter 12*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud providers such as Azure offer different storage classes with different
    performance and different costs. Moreover, the PVC can also specify the `accessMode`,
    which can be:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ReadWriteOnce`: The volume can be mounted as read-write by a single Pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ReadOnlyMany`: The volume can be mounted as read-only by many Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ReadWriteMany`: The volume can be mounted as read-write by many Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume claims can be added to StatefulSets in a specific `spec->volumeClaimTemplates`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: The `storage` property contains the storage requirements. `volumeMode` set to
    `Filesystem` is a standard setting that means the storage will be available as
    a file path. The other possible value is `Block`, which allocates the memory as
    `unformatted`. `storageClassName` must be set to an existing storage class offered
    by the cloud provider. If it’s omitted, the default storage class will be assumed.
  prefs: []
  type: TYPE_NORMAL
- en: 'All available storage classes can be listed with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Once `volumeClaimTemplates` has defined how to create permanent storage, then
    each container must specify which file path to attach that permanent storage to
    in the `spec->containers->volumeMounts` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Here, `name` must correspond to the name given to the PVC.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsection shows how to use Kubernetes secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some data, such as passwords and connection strings, cannot be exposed but
    need to be protected by some kind of encryption. Kubernetes handles private sensitive
    data that need encryption through specific objects called **secrets**. **Secrets**
    are sets of key-value pairs that are encrypted to protect them. They can be created
    by putting each value in a file, and then invoking the following `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the filenames become the keys and the files’ contents are the
    values.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the values are strings, they can be specified directly in the `kubectl`
    command, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: In this case, keys and values are listed one after the other, separated by the
    `=` character. In the previous example, the actual password is enclosed between
    single quotes to escape special characters like `$` that are usually required
    to build strong passwords.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once defined, secrets can be referred to in the `spec->volume` property of
    a Pod (Deployment or StatefulSet template), as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, each container can specify on which path to mount them in the `spec->containers->volumeMounts`
    property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, each key is seen as a file with the same name as the
    key. The content of the file is the secret value, base64-encoded. Therefore, the
    code that reads each file must decode its content (in .NET, `Convert.FromBase64`
    will do the job).
  prefs: []
  type: TYPE_NORMAL
- en: 'When secrets contain strings, they can also be passed as environment variables
    in the `spec->containers->env` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Here, the `name` property must match the secret’s name. Passing secrets as environment
    variables is very convenient when containers host ASP.NET Core applications, since,
    in this case, environment variables are all immediately available in the configuration
    object (see the *Loading configuration data and using it with the options framework*
    section of *Chapter 17*, *Presenting ASP.NET Core*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Secrets can also encode the key/certificate pair of an HTTPS certificate with
    the following `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Secrets defined in this way can be used to enable HTTPS termination in Ingresses.
    You can do this by placing the secret names in the `spec->tls->hosts->secretName`
    properties of an Ingress.
  prefs: []
  type: TYPE_NORMAL
- en: Liveness and readiness checks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes automatically monitors all containers to ensure they are still alive
    and that they keep their resource consumption within the limits declared in the
    `spec->containers->resources->limits` object. When some conditions are violated,
    the container is either throttled, or restarted, or the whole Pod instance is
    restarted on a different node. How does Kubernetes know that a container is in
    a healthy state? While it can use the operating system to check the healthy state
    of nodes, it has no universal check that works with all containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the containers themselves must inform Kubernetes of their health,
    otherwise Kubernetes cannot verify them. Containers can inform Kubernetes of their
    health in two ways: either by declaring a console command that returns their health,
    or by declaring an endpoint that provides the same information.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Both declarations are provided in the `spec-> containers-> livenessProb` object.
    The console command check is declared as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: If `command` returns `0`, the container is considered healthy. In the preceding
    example, the software running in the container records its state of health in
    the `/tmp/healthy` file, so the `cat/tmp/healthy` command returns it. `PeriodSeconds`
    is the time between checks, while `initialDelaySeconds` is the initial delay before
    performing the first check. An initial delay is always necessary so as to give
    the container time to start.
  prefs: []
  type: TYPE_NORMAL
- en: 'The endpoint check is quite similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The test is successful if the HTTP response contains the declared header with
    the declared value. You may also use a pure TCP check, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the check succeeds if Kubernetes is able to open a TCP socket
    to the container on the declared port.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the readiness of containers once they are installed is monitored
    with a readiness check. The readiness check is defined in a similar way as the
    liveness check, the only difference being that `livenessProbe` is replaced with
    `readinessProbe`.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsection explains how to autoscale Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of manually modifying the number of replicas in a Deployment to adapt
    it to a decrease or increase in load, we can let Kubernetes decide for itself
    the number of replicas needed to keep a declared resource’s consumption constant.
    Thus, for instance, if we declare a target of 10% CPU consumption, then when the
    average resource consumption of each replica exceeds this limit, a new replica
    will be created. If the average CPU consumption falls below this limit, a replica
    is destroyed. The typical resource used to monitor replicas is CPU consumption,
    but we can also use memory consumption.
  prefs: []
  type: TYPE_NORMAL
- en: In actual high-traffic production systems, autoscaling is a **must**, because
    it is the only way to adapt quickly the system to changes in the load.
  prefs: []
  type: TYPE_NORMAL
- en: 'Autoscaling is achieved by defining a `HorizontalPodAutoscaler` object. Here
    is an example of the `HorizontalPodAutoscaler` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '`spec-> scaleTargetRef->name` specifies the name of the Deployment to autoscale,
    while `targetAverageUtilization` specifies the target resource (in our case, `cpu`)
    percentage usage (in our case, 25%).'
  prefs: []
  type: TYPE_NORMAL
- en: The following subsection gives a short introduction to the Helm package manager
    and Helm charts and explains how to install Helm charts on a Kubernetes cluster.
    An example of how to install an Ingress Controller is given as well.
  prefs: []
  type: TYPE_NORMAL
- en: Helm – installing an Ingress Controller
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Helm charts are a way to organize the installation of complex Kubernetes applications
    that contain several `.yaml` files. A Helm chart is a set of `.yaml` files organized
    into folders and subfolders. Here is a typical folder structure of a Helm chart
    taken from the official documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Text  Description automatically generated](img/B19820_20_09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20.9: Folder structure of a Helm chart'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `.yaml` files specific to the application are placed in the top `templates`
    directory, while the `charts` directory may contain other Helm charts used as
    helper libraries. The top-level `Chart.yaml` file contains general information
    on the package (name and description), together with both the application version
    and the Helm chart version. The following is a typical example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Here, `type` can be either `application` or `library`. Only `application` charts
    can be deployed, while `library` charts are utilities for developing other charts.
    `library` charts are placed in the `charts` folder of other Helm charts.
  prefs: []
  type: TYPE_NORMAL
- en: In order to configure each specific application installation, Helm chart `.yaml`
    files contain variables that are specified when Helm charts are installed. Moreover,
    Helm charts also provide a simple templating language that allows some declarations
    to be included only if some conditions depending on the input variables are satisfied.
    The top-level `values.yaml` file declares default values for the input variables,
    meaning that the developer needs to specify just the few variables for which they
    require values different from the defaults. We will not describe the Helm chart
    template language because it would be too extensive, but you can find it in the
    official Helm documentation referred to in the *Further reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Helm charts are usually organized in public or private repositories in a way
    that is similar to Docker images. There is a Helm client that you can use to download
    packages from a remote repository and to install charts in Kubernetes clusters.
    The Helm client is immediately available in Azure Cloud Shell, so you can start
    using Helm for your Azure Kubernetes cluster without needing to install it.
  prefs: []
  type: TYPE_NORMAL
- en: 'A remote repository must be added before using its packages, as shown in the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command makes the packages of a remote repository available and
    gives a local name to that remote repository. After that, any package from the
    remote repository can be installed with a command such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `<namespace>` is the namespace in which to install the application. As
    usual, if it’s not provided, the `default` namespace is assumed. `<instance name>`
    is the name that you give to the installed application. You need this name to
    get information about the installed application with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'You can get also information about all applications installed with Helm with
    the help of the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The application name is also needed to delete the application from the cluster
    by means of the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'When we install an application, we may also provide a `.yaml` file with all
    the variable values we want to override. We can also specify a specific version
    of the Helm chart, otherwise the most recent version is used. Here is an example
    with both the version and values overridden:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, value overrides can also be provided in-line with the `--set` option,
    as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also upgrade an existing installation with the `upgrade` command, as
    shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The `upgrade` command may be used to specify new value overrides with the `–f`
    option or with the `--set` option, and a new version with `--version`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use Helm to provide an Ingress for the Guestbook demo application. More
    specifically, we will use Helm to install an Ingress Controller based on Nginx.
    The detailed procedure to be observed is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the remote repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the Ingress Controller:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: When the installation is complete, you should see an entry for the installed
    Ingress Controller among the installed services if you type `kubectl get service`.
    The entry should contain a public IP. Please make a note of this IP since it will
    be the public IP of the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open the `frontend.yaml` file and remove the `type: LoadBalancer` line. Save
    and upload this to Azure Cloud Shell. We changed the service type of the frontend
    application from `LoadBalancer` to `ClusterIP` (the default). This service will
    be connected to the new Ingress you are going to define.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Deploy `redis-master.yaml`, `redis-slave.yaml`, and `frontend.yaml` with `kubectl`,
    as detailed in the *Deploying the demo Guestbook application* subsection. Create
    a `frontend-ingress.yaml` file and place the following code in it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Upload `frontend-ingress.yaml` to Azure Cloud Shell and deploy it with the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Open the browser and navigate to the public IP you made a note of in *step 3*.
    There, you should see the application running.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The public IP allocated to the `Ingress-Controller` at *Step 3* is listed also
    in the **Azure Public IP Addresses** section of Azure. You can find it by searching
    for this section in the Azure search box. Once in this section, you should see
    this IP address listed. There you can also assign it a hostname of the type `<a
    name you can choose>.<your Azure region>.cloudeapp.com`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We recommend studying the [https://letsencrypt.org/](https://letsencrypt.org/)
    documentation on how to require a certificate, assign a hostname to the application’s
    public IP, and then use this hostname to get a free HTTPS certificate from [https://letsencrypt.org/](https://letsencrypt.org/).
    Unfortunately, we can’t give more details since the procedure to require a certificate
    is too extensive. Once you get a certificate, you can generate a secret from it
    with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Then you can add the preceding secret to your `frontend-ingress.yaml Ingress`
    by adding the following `spec->tls` section to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Following the correction, upload the file to your Azure Cloud Shell instance
    and update the previous Ingress definition with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: At this point, you should be able to access the Guestbook application with HTTPS.
  prefs: []
  type: TYPE_NORMAL
- en: 'When you are done experimenting, please don’t forget to delete everything from
    your cluster to avoid wasting your free Azure credit. You can do this by means
    of the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we described Kubernetes’ basic concepts and objects, and then
    we explained how to create an AKS cluster. We also showed how to deploy applications
    and how to monitor and inspect the state of your cluster with a simple demo application.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter also described more advanced Kubernetes features that have fundamental
    roles in practical applications, including how to provide persistent storage to
    the containers running on Kubernetes, how to inform Kubernetes of the health state
    of your containers, and how to offer advanced HTTP services, such as HTTPS and
    name-based virtual hosting.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we reviewed how to install complex applications with Helm, and gave
    a short description of Helm and Helm commands.
  prefs: []
  type: TYPE_NORMAL
- en: Up next, we have the book’s case study.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why are Services needed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is an Ingress needed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is Helm needed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it possible to define several Kubernetes objects in the same `.yaml` file?
    If yes, how?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does Kubernetes detect container faults?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are persistent volume claims needed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between a ReplicaSet and a StatefulSet?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A good book for extending the knowledge acquired in this chapter is the following:
    [https://www.packtpub.com/product/hands-on-kubernetes-on-azure-second-edition/9781800209671](https://www.packtpub.com/product/hands-on-kubernetes-on-azure-second-edition/9781800209671).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The official documentation for Kubernetes and `.yaml` files can be found here:
    [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More information on Helm and Helm charts can be found in the official documentation.
    This is extremely well written and contains some good tutorials: [https://helm.sh/](https://helm.sh/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The official documentation for Azure Kubernetes can be found here: [https://docs.microsoft.com/en-US/azure/aks/](https://docs.microsoft.com/en-US/azure/aks/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The official documentation on the Azure Application Gateway-based Ingress Controller
    is available here: [https://github.com/Azure/application-gateway-kubernetes-ingress](https://github.com/Azure/application-gateway-kubernetes-ingress).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ingress certificate release and renewal can be automated as explained here:
    [https://docs.microsoft.com/azure/application-gateway/ingress-controller-letsencrypt-certificate-application-gateway](https://docs.microsoft.com/azure/application-gateway/ingress-controller-letsencrypt-certificate-application-gateway).
    While the procedure specifies an Azure Application Gateway-based ingress controller,
    it is adequate for any Ingress Controller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leave a review!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Enjoying this book? Help readers like you by leaving an Amazon review. Scan
    the QR code below for a 20% discount code.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/Leave_a_review_QR.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Limited Offer*'
  prefs: []
  type: TYPE_NORMAL
