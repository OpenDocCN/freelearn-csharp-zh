<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">How to Choose Your Data Storage in the Cloud</h1>
                </header>
            
            <article>
                
<p>Azure, like other clouds, offers a wide range of storage devices. The simplest approach is to define a scalable set of virtual machines hosted in the cloud where we can implement our custom solutions. For instance, we can create a SQL Server cluster on our cloud-hosted virtual machines to increase reliability and computational power. However, usually, custom architectures aren't the optimal solution and don't take full advantage of the opportunities offered by the cloud infrastructure.</p>
<p>Therefore, this chapter will not discuss such custom architectures but will focus mainly on the various <strong>Storage as a Service</strong> (<strong>SaaS</strong>) offerings that are available in the cloud and, in particular, on Azure. These offers include scalable solutions based on plain disk space, relational databases, NoSQL databases, and in-memory data stores such as Redis.</p>
<p>Choosing a more adequate storage type is based not only on the application's functional requirements but also on performance and scaling-out requirements. In fact, while scaling-out when processing resources causes a linear increase in performance, scaling-out storage resources doesn't necessarily imply an acceptable increase in performance. In a few words, no matter how much you duplicate your data storage devices, if several requests affect exactly the same chunk of data, they will always queue the same amount of time to access it!</p>
<p>Scaling-out data causes linear increases of read operation throughput since each copy can serve a different request, but it doesn't imply the same increase in the throughput for write operations since all copies of the same chunk of data must be updated! Accordingly, more sophisticated techniques are required to scale-out storage devices, and not <span>all storage engines scale equally well.</span></p>
<p><span>In particular, relational databases don't scale well in all scenarios. Therefore, scaling needs and the need to</span><span> </span><span>distribute data geographically play a fundamental role in the choice of a storage engine, as well as in the choice of a SaaS offering.</span></p>
<p class="mce-root"/>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li><span>Understanding the different repositories for different purposes</span></li>
<li><span>Choosing between structure or NoSQL storage</span></li>
<li><span>Azure Cosmos DB – an opportunity to manage a multi-continental database</span></li>
<li><span>Use case – storing data</span></li>
</ul>
<p>Let's get started:</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p><span>This chapter requires that you have the following:</span></p>
<ul>
<li><span>Visual Studio 2017 or 2019 free Community Edition or better with all its database tools installed.</span></li>
<li>A free Azure account. The <em>Creating an Azure account</em> subsection in <a href="14b5c5da-4042-439e-9e5a-2e19ba4c4930.xhtml">Chapter 1</a>, <em>Understanding the Importance of Software Architecture</em>, explains how to create one.</li>
<li>For a better development experience, we advise that you also install the local emulator of Cosmos DB, which can be found at <a href="https://aka.ms/cosmosdb-emulator">https://aka.ms/cosmosdb-emulator</a>.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Understanding the different repositories for different purposes</h1>
                </header>
            
            <article>
                
<p>This section describes the functionalities that are offered by the most popular data storage techniques. Mainly, we will focus on the functional requirements they are able to satisfy. Performance and scaling-out features will be analyzed in the next section, which is dedicated to comparing relational and NoSQL databases. In Azure, the various offerings can be found by typing product names into the search bar at the top of all Azure portal pages.</p>
<p>The following subsections describe the various kinds of database that we can use in our C# projects. </p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Relational databases</h1>
                </header>
            
            <article>
                
<p>Usually, clouds offer several database engines. Azure offers a variety of popular database engines, such as SQL Server (Azure <span>SQL Server</span>), MySQL, and Oracle.</p>
<p>With regard to the Oracle database engine, Azure offers configurable virtual machines with <span>various Oracle editions</span> installed on them, which you can easily verify by the suggestions you get after typing <kbd>Oracle</kbd> into the Azure portal search bar. Azure fees don't include Oracle licenses; they just bring computation time, so you must bring your own license to Azure.</p>
<p>With MySQL on Azure, you pay to use a private server instance. The fees you incur depend on the number of cores you have, how much memory has to be allocated, and on backup retention time. MySQL instances are redundant and you can choose between a local or geographically distributed redundancy:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3a871e4b-5bbe-4c0f-906e-5e2a3377be2d.png"/></p>
<p>Azure <span>SQL Server</span> is the most flexible offer. Here, you can configure resources that are used by every single database. When you create a database, you have the option to place it on an existing server instance or create a new instance. Fees are based on the database memory that's been reserved and on the required <strong>Database Transaction Units</strong> (<strong>DTUs</strong>). Here, a DTU is a linear combination of I/O operations, CPU usage, and memory usage that's determined by a reference workload. Roughly, maximal DB performance increases linearly when you increase DTUs:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/04490184-bfc4-4eec-9eee-281af77ed4d3.png"/></p>
<p>You can <span>also </span>configure data replication by enabling <span class="packt_screen">Read scale-out</span>. This way, you can improve the performance of read operations. Backup retention is fixed for each offering level (basic, standard, and premium).</p>
<p>If you select <span class="packt_screen">Yes</span> for <span class="packt_screen">Want to use SQL elastic pool?</span>, the database will be added to an elastic pool. Databases that are added to the same elastic pool will share their resources, so resources that aren't used by a database can be used during the <em>usage peaks</em> of other databases. Elastic pools can contain databases hosted on different server instances. E<span>lastic pools </span>are an efficient way to optimize resource usage in order to reduce costs.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NoSQL databases</h1>
                </header>
            
            <article>
                
<p>In NoSQL databases, relational tables are replaced with more general collections that can contain heterogeneous JSON objects. That is, collections have no predefined structure and no predefined fields with length constraints (in the case of strings) but can contain any type of object. The only structural constraint associated with each collection is the name of the property that acts as a primary key.</p>
<p>More specifically, each collection entry can contain nested objects and object collections nested in object properties, that is, related entities that, in relational databases, are contained in different tables and connected through external keys. In NoSQL, databases can be nested in their father entities. Since collection entries contain complex nested objects instead of simple property/value pairs, <span>as is the case with relational databases</span>, entries aren't called tuples or rows<span>, but <em>documents</em>.</span></p>
<p>No relations and/or external key constraints can be defined between documents that belong to the same collection or to different collections. If a document contains the primary key of another document in one of its properties, it does so at its own risk. The developer has the responsibility of maintaining and keeping these coherent references.</p>
<p>Finally, since NoSQL storage is quite cheap, whole binary files can be stored as the values of document properties as Base64 strings. The developer can define rules to decide what properties to index in a collection. Since documents are nested objects, properties are actually tree paths. Usually, by default, all the paths are indexed, but you can specify which collection of paths and subpaths to index.</p>
<p>NoSQL databases are queried either with a subset of SQL or with a JSON-based language where queries are JSON objects whose paths represent the properties to query, and whose values represent the query constraints that have been applied to them.</p>
<p>The possibility of nesting children objects inside documents can be simulated in relational databases with the help of one-to-many relationships. However, with relational databases, we are forced to redefine the exact structure of all the related tables, while NoSQL collections don't impose any predefined structure on the objects they contain. The only constraint is that each document must provide a unique value for the primary key property. Therefore, NoSQL databases are the only option when the structure of our objects is extremely variable. However, often they are chosen for the way they scale-out read and write operations and, more generally, for their performance advantages in distributed environments. Their performance features will be discussed in the next section, which compares them to relational databases.</p>
<p>The graph data model is an extreme case of a completely unstructured document. The whole database is a graph where queries can add, change, and delete graph documents. </p>
<p>In this case, we have two kinds of document: nodes and relations. While relationships have a well-defined structure (the primary key of the nodes connected by the relationship, plus the relationship's name), nodes have no structure at all since properties and their values are added together during node update operations. Graph data models were conceived to represent the features of people and the objects they manipulate (media, posts, and so on), along with their relationships in <em>social applications</em>. The Gremlin language was conceived specifically to query graph data models. We won't discuss this in this chapter, but references are available in the <em>Further reading</em> section.</p>
<p>NoSQL databases will be analyzed in detail in the remaining sections of this chapter, which are dedicated to describing Azure Cosmos DB and comparing it with relational databases.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Redis</h1>
                </header>
            
            <article>
                
<p>Redis is a distributed concurrent in-memory storage based on key-value pairs and supports distributed queuing. It can be used as permanent in-memory storage and as a web application cache for database data. Alternatively, it can render pages whose content doesn't change very often.</p>
<p>Redis can also be used to store a web application's user session data. In fact, ASP.NET MVC, Pages, and WebForms support session data to overcome the fact that the HTTP protocol is stateless. More specifically, user data that's kept between page changes is maintained in server-side stores such as Redis and indexed <span>by a session key stored in cookies</span>.</p>
<p>Interaction with the Redis server in the cloud is typically based on a REST interface; that is, each Redis resource is accessed via HTTP GET at a URI and commands are passed in the query string, while answers are returned in JSON format. However, clients that offer an easy-to-use interface are available in all popular languages. The client for .NET and .NET Core is available through the <kbd>StackExchange.Redis</kbd> NuGet package. The basic operations of the <span><kbd>StackExchange.Redis</kbd> client have been documented at </span><a href="https://stackexchange.github.io/StackExchange.Redis/Basics">https://stackexchange.github.io/StackExchange.Redis/Basics</a>, while the full documentation can be found at <a href="https://stackexchange.github.io/StackExchange.Redis">https://stackexchange.github.io/StackExchange.Redis</a>.</p>
<p>The user interface for defining a Redis server on Azure is quite simple:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/df820d64-6224-4523-94ef-2c30f6a9e50d.png" style="width:42.33em;height:31.92em;"/></p>
<p>The <span class="packt_screen">Pricing tier</span> dropdown allows us to select one of the available memory/replication options. A quick-start guide that explains how to use Azure Redis credentials and the URI with the <kbd>StackExchange.Redis</kbd> .NET Core client can be found at <a href="https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-dotnet-core-quickstart">https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-dotnet-core-quickstart</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Disk memory</h1>
                </header>
            
            <article>
                
<p>All clouds offer scalable and redundant general-purpose disk memory that you can use as virtual disks in virtual machines and/or as external file storage. Azure <em>storage account</em> disk space can also be structured in <span class="packt_screen">Tables</span> and <span class="packt_screen">Queues</span>. However, these two storage options are only supported for backward compatibility since Azure NoSQL databases are a better option than tables and Azure Redis is a better option than Azure storage queues:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/67b90062-5d45-4cec-8625-9fa827a64189.png"/></p>
<p>In the rest of this chapter, we will focus on NoSQL databases and how they differ from relational databases. Next, we will look at how to choose one over the other.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Choosing between structured or NoSQL storage</h1>
                </header>
            
            <article>
                
<p>In the previous section, we stated that NoSQL databases should be preferred when data has almost no predefined structure. Actually, unstructured data can be represented in relational databases since variable properties of a tuple, <kbd>t</kbd>, can be placed in a connected table containing the property name, property value, and the external key of <kbd>t</kbd>. However, the problem is performance. In fact, property values that belong to a single object would be spread all over the available memory space. In a small database, <em>all over the available memory space</em> means far away but on the same disk; in a bigger database, this means far away but in different disk units; in a distributed cloud environment, this means far away but in different <span>–</span> and possibly geographically distributed <span>–</span> servers.</p>
<p>On the other hand, NoSQL databases not only keep variable attributes close to their owners, but they also keep some related objects close since they allow related objects to be nested inside properties and collections.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Therefore, we can conclude that relational databases perform well when tables that are usually accessed together can be stored close in memory. NoSQL databases, on the other hand, automatically ensure that related data is kept close <span>since each entry keeps most of the data it is related to inside it as nested objects. Therefore, NoSQL databases perform better when </span>they are distributed to a different memory and also to different geographically distributed servers.</p>
<p>Unfortunately, the only way to scale out storage write operations is to split collection entries across several servers according to the values of <em>shard keys</em>. For instance, we can place all the records containing usernames that start with <span class="packt_screen">A</span> in a server, the records containing usernames that start with <span class="packt_screen">B</span> on another server, and so on. This way, write operations for usernames with different start letters may be executed in parallel, ensuring that the write throughput increases linearly with the number of servers.</p>
<p>However, if a <em>shard</em> collection is related to several other collections, there is no guarantee that related records will be placed on the same server. Also, putting different collections on different servers without using collection sharding increases write throughput linearly until we reach the limit of a single collection per server, but it doesn't solve the issue of being forced to perform several operations on different servers to retrieve or update data that's usually processed together.</p>
<p>This issue becomes catastrophic for performance if access to related distributed objects must be transactional and/or must ensure structural constraints (such as external key constraints) aren't violated. In this case, all related objects must be blocked during the transaction, preventing other requests from accessing them during the whole lifetime of a time-consuming distributed operation.</p>
<p>NoSQL databases <span>don't suffer from this problem and </span><span>perform better with sharding and consequently with write-scaled out</span>put. This is because they don't distribute related data to different storage units and instead store them as nested objects of the same database entry.</p>
<p>In NoSQL database design, we always try to put all related objects that are likely to be processed together into a single entry. Related objects that are accessed less frequently are placed in different entries. Since external key constraints aren't enforced automatically and NoSQL transactions are very flexible, the developer can choose the best compromise between performance and coherence.</p>
<p>It is worth mentioning that there are situations where relational databases perform well with sharding. A typical instance is a multi-tenant application. In a multi-tenant application, all entries collections can be partitioned into non-overlapping sets called <strong>tenants</strong>. Only entries belonging to the same tenant can refer to each other, so if all the collections are sharded in the same way according to their object tenants, all related records end up in the same shard, that is, in the same server, and can be navigated efficiently.</p>
<p>Multi-tenant applications aren't rare in the cloud since all applications that offer the same services to several different users are often implemented as multi-tenant applications, where each tenant corresponds to a user subscription. Accordingly, relational databases are conceived to work in the cloud, such as Azure SQL Server, and usually offer sharding options for multi-tenant applications. Typically, sharding isn't a cloud service and must be defined with database engine commands. Here, we won't describe how to define shards with Azure SQL Server, but the <em>Further reading</em> section contains a link to the official Microsoft documentation.</p>
<p>In conclusion, relational databases offer a pure, logical view of data that's independent of the way they are actually stored, and use a declarative language to query and update them. This simplifies development and system maintenance, but it may cause performance issues in a distributed environment that requires write scale-out. In NoSQL databases, you must handle more details about how to store data, as well as some procedural details for all the update and query operations, manually, but this allows <span>you to optimize performance in distributed environments that require both read and write scale-out.</span></p>
<p>In the next section, we will look at Azure Cosmos DB, the main Azure NoSQL offering.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Azure Cosmos DB – an opportunity to manage a multi-continental database</h1>
                </header>
            
            <article>
                
<p>Azure Cosmos DB is Azure's main NoSQL offering. Azure Cosmos DB has its own interface that is a subset of SQL, but it can be configured with a MongoDB interface. It<span> can be also configured as a graph data model that can be queried with Gremlin. Cosmos DB allows replication for fault tolerance and read scale-out, and replicas can be distributed geographically to optimize communication performance. Moreover, you can specify which data center all the replicas are placed in. The user also has the option to write-enable all the replicas so that writes are immediately available in the geographical area where they are done. Write scale-up is achieved with sharding, which the user can configure by defining which properties to use as shard keys. </span></p>
<p class="CDPAlignLeft CDPAlign">You can define a Cosmos DB account by typing Cosmos DB into the Azure portal search bar and clicking <span class="packt_screen">Add</span>. The following page will appear: </p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="assets/83d9ca9f-5a23-4509-8a8a-5487e31c2409.png"/></p>
<p>The account name you choose is used in the resource URI as <kbd>{account name}.documents.azure.com</kbd>. The API dropdown lets you choose the kind of interface you prefer (SQL, MongoDB, or Gremlin). Then, you can decide which data center the main database will be placed in and whether you want to enable geographically distributed replication. Once you've enabled <span>geographically distributed replication,</span> you can choose the number of replicas you want to use and where to place them.</p>
<p>Finally, the <span class="packt_screen">Multi-region Writes</span> toggle lets you enable writes on geographically distributed replicas. If you don't do this, all write operations will be routed to the main data center.</p>
<ol>
<li><strong>Going to the resource</strong>: Once you've created your account, select <span class="packt_screen">Data Explorer</span> to create your databases and collections inside of them:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3893d21f-a74e-491d-9845-4563487b5afb.png" style="width:8.83em;height:2.25em;"/></p>
<ol start="2">
<li><strong>Creating a collection</strong>: Since databases just <span>have </span>a name and no configuration, you can directly add a collection and then the database where you wish to place it:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6e63a071-b4a1-48b4-80b2-db48df1aff90.png" style="width:24.92em;height:34.00em;"/></p>
<p style="padding-left: 60px">Here, you can decide on database and collection names and the property to use for sharding (partition key). Since NoSQL entries are object trees, property names are specified as paths. You can also add properties whose values are required to be unique. However, uniqueness IDs are checked inside each shard, so this option is only useful in certain<span> </span>situations, such as multi-tenant applications (where each tenant is included in a single shard). The fees depend on the collection throughput that you choose.</p>
<ol start="3">
<li><strong>Targeting all resource parameters to your needs</strong>: Throughput is expressed in <span class="packt_screen">Request Unit per second</span>, where <span><span class="packt_screen">Request Unit per second</span></span> is defined as the throughput we have when performing a read of 1 KB per second<span>. Hence, if you check the <span class="packt_screen">Provision database throughput</span> option, the chosen throughput is shared with the whole database, instead of being reserved as a single collection.</span></li>
<li><strong>Getting connection information</strong>: By selecting the <span class="packt_screen">Keys</span> menu, you will see all the information you need in order to connect with your Cosmos DB account from your application:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/2d565e3b-bb79-41aa-aa36-09615968a7c7.png" style="width:5.42em;height:2.08em;"/></p>
<ol start="5">
<li><strong>Connection information page</strong>: Here, you will find the account URI and two connection keys, which can be used interchangeably to connect with the account:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/503dcd27-b61c-450e-871a-0232bedf3cab.png"/></p>
<p style="padding-left: 60px">There are also keys with read-only privileges. Every key can be regenerated and each account has two equivalent keys so that this operation can be handled efficiently; that is, when a key is changed, the other one is kept. Therefore, existing applications can continue using the other key before upgrading to the new key.</p>
<ol start="6">
<li><strong>Selecting the default consistency level</strong>: By selecting the <span class="packt_screen">Default consistency</span>, you can choose the default replication consistency that you wish to apply to all of your collections:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/32f7d541-7f05-4246-962b-6f83293c0d75.png" style="width:11.08em;height:2.33em;"/></p>
<p>This default can be overridden in each collection, either from the Data Explorer or programmatically. Consistency problems in read/write operations are a consequence of data replication. More specifically, the results of various read operations may be incoherent if the read operations are executed on different replicas that have received different partial updates.</p>
<p>The following are the available consistency levels. These have been ordered from the weakest to the strongest:</p>
<ul>
<li><strong>Eventual</strong>: After enough time has passed, if no further write operations are done, all the reads converge and apply all the writes.</li>
<li><strong>Consistent Prefix</strong>: All the writes are executed in the same order on all the replicas. So, if there are <kbd>n</kbd> write operations, each read is consistent with the result of applying the first <kbd>m</kbd> writes for some <kbd>m</kbd> less or equal to <kbd>n</kbd>.</li>
<li><strong>Session</strong>: This is the same as the consistency prefix but also guarantees that each writer sees the result of its own writes in all subsequent read operations and that subsequent reads of each reader are coherent (either the same database or a more updated version of it).</li>
<li><strong>Bounded Staleness</strong>: This is associated either with a delay time, <kbd>Delta</kbd>, or with a number of operations, <kbd>N</kbd>. Each read sees the results of all the write operations that were performed before a time <kbd>Delta</kbd> (or before the last <kbd>N</kbd> operations). That is, its reads converge with the result of all the writes with a maximum time delay of <kbd>Delta</kbd> (or a maximum operations delay of <kbd>N</kbd>).</li>
<li><strong>Strong</strong>: This is bounded staleness combined with <kbd>Delta = 0</kbd>. Here, each read reflects the result of all previous write operations.</li>
</ul>
<p>The strongest consistency can be obtained to the detriment of performance. By default, the consistency is set to <span class="packt_screen">Session</span>, which is a good compromise between coherence and performance. A lower level of consistency is difficult to handle in applications and is only usually acceptable if sessions are either read-only or write-only.</p>
<p>If you select the <span class="packt_screen">Scale &amp; settings</span> option in the Data Explorer, you can configure which paths to index and which kind of indexing to apply to each data type of each path. The configuration consists of a JSON object. Let's analyze its various properties:</p>
<pre>{<br/>    "indexingMode": "consistent",<br/>    "automatic": true,<br/>    ...</pre>
<p><span>If you set <kbd>indexingMode</kbd> to <kbd>none</kbd> instead of <kbd>consistent</kbd>, no index is generated and the collection can be used as a key-value dictionary that's indexed by the collection primary key. When <kbd>automatic</kbd> is set to <kbd>true</kbd>, all document properties are automatically indexed:</span></p>
<pre>{<br/>    ...<br/>    "includedPaths": [<br/>        {<br/>            "path": "/*",<br/>            "indexes": [<br/>                {<br/>                    "kind": "Range",<br/>                    "dataType": "Number",<br/>                    "precision": -1<br/>                },<br/>                {<br/>                    "kind": "Range",<br/>                    "dataType": "String",<br/>                    "precision": -1<br/>                },<br/>                {<br/>                    "kind": "Spatial",<br/>                    "dataType": "Point"<br/>                }<br/>            ]<br/>        }<br/>    ]<br/>},<br/>...</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>Each entry in the <em>Included paths</em> specifies a path pattern such as <span><kbd>/subpath1/subpath2/?</kbd> (settings apply just to the <kbd>/subpath1/subpath2/</kbd> property)</span> or <kbd>/subpath1/subpath2/*</kbd> (settings apply to all the paths starting with <kbd><span>/subpath1/subpath2/</span></kbd>).</p>
<p>Patterns contain the <kbd>[]</kbd> symbol when settings must be applied to child objects contained in collection properties; for example, <span><kbd>/subpath1/subpath2/[]/?</kbd>, <kbd>/subpath1/subpath2/[]/childpath1/?</kbd>, and so on. Settings specify the index type to apply to each data type (string, number, geographic point, and so on). Range indexes are needed for comparison operations, while hash indices are more efficient if we need equality comparisons.</span></p>
<p><span>It is possible to specify a precision, that is, the maximum number of characters or digits to use in all the index keys. <kbd>-1</kbd> means no limit. <kbd>-1</kbd> is acceptable for strings, while a finite precision should be used for numbers. On the other hand, using finite precision with strings may result in unexpected behavior since string keys are truncated. In hash indexes, precision may vary from 1 to 8, while in range indexes, it may vary from 1 to 100:</span></p>
<pre>    ...<br/>    "excludedPaths": [<br/>        {<br/>            "path": "/\"_etag\"/?"<br/>        }<br/>    ]</pre>
<p><span>Paths contained in <kbd>excludedPaths</kbd> aren't indexed at all. </span>Index settings can also be specified programmatically.</p>
<p>Here, you have two options to connect to Cosmos DB: use a version of its official client for your preferred programming language or use Cosmos DB's Entity Framework Core provider, which at the time of writing this book, is still in preview. In the following subsections, we will have a look at both options. Then, we will describe how to use Cosmos DB's Entity Framework Core provider with a practical example.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cosmos DB client</h1>
                </header>
            
            <article>
                
<p>The Cosmos DB client for .NET Core is available through the <kbd>Microsoft.Azure.DocumentDB.Core</kbd> NuGet package. It offers full control of all Cosmos DB features, while the Cosmos DB Entity Framework provider is easier to use but hides some Cosmos DB peculiarities. Follow these steps to interact with Cosmos DB through the official <span class="packt_screen">Cosmos DB client for .NET Core</span>:</p>
<ol>
<li>Any operation requires the creation of a client object:</li>
</ol>
<pre>var client = new DocumentClient(new Uri("service endpoint"), "auth key")</pre>
<ol start="2">
<li>Don't forget that the client must be disposed of by calling its <kbd>Dispose</kbd> method (or by enclosing the code that references it in a <kbd>using</kbd> statement) when you don't need it anymore.</li>
<li>Then, you can get a reference to a database and create it if it doesn't exist with the following code:</li>
</ol>
<pre>Database db = client.CreateDatabaseIfNotExistsAsync(new Database { Id = "MyDatabase" }).Result;</pre>
<ol start="4">
<li>Finally, you can get a reference to a collection or create it if it doesn't exist with the following code:</li>
</ol>
<pre>var collection = client.CreateDocumentCollectionIfNotExistsAsync(<br/>    UriFactory.CreateDatabaseUri("MyDatabase"), <br/>    new DocumentCollection { Id = "MyCollection" }).Result;</pre>
<ol start="5">
<li>During collection creation, you can pass an <kbd>option</kbd> object, where you can specify the consistency level, how to index properties, and all the other collection features.</li>
<li>Then, you must define the .NET classes that correspond to the structure of the JSON document you need to manipulate in your collections. You can also use the <kbd>JsonProperty</kbd> <span>attribute to map class property names to JSON names if they aren't equal.</span></li>
<li>Once you have all the necessary classes, you can use client methods to add, update, and write collection entries, as well as the client <kbd>CreateDocumentQuery</kbd> <span>method, which returns an</span> <kbd>IQueryable</kbd><span> value that you can query with LINQ. </span></li>
</ol>
<p class="mce-root"/>
<p>When you read a document, apply some modifications, and then try to upload your modified version of the document, someone else may have modified the same document. Often, you only need to perform an update if no one else has modified the same document. This can be done using the <kbd>_etag</kbd> property, which Cosmos DB <span>automatically </span>attaches to each document. This property value changes after each update, so you need to follow these steps:</p>
<ol>
<li>Map the <kbd>_etag</kbd> JSON property to a property on your .NET class so that you get its value when you read a document.</li>
<li>Pass the original value of the <kbd>_etag</kbd> property as the value of the <kbd>AccessCondition</kbd> property of the <kbd>option</kbd> object you pass to the <kbd>ReplaceDocumentAsync</kbd> client method.</li>
<li>If the <kbd>_etag</kbd> has changed <kbd>ReplaceDocumentAsync</kbd>, abort the operation and return an exception.</li>
</ol>
<p>There is also the <kbd>MvcControlsToolkit.Business.DocumentDB</kbd> NuGet package, which simplifies and automates all operations that are required by the <kbd>Microsoft.Azure.DocumentDB.Core</kbd> library and overcomes some limitations of Cosmos DB SQL. The <em>Further reading</em> section contains references to tutorials for <kbd>Microsoft.Azure.DocumentDB.Core</kbd> and <kbd>MvcControlsToolkit.Business.DocumentDB</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Cosmos DB Entity Framework Core provider</h1>
                </header>
            
            <article>
                
<p>The Cosmos DB provider for Entity Framework Core is contained in the <kbd>Microsoft.EntityFrameworkCore.Cosmos</kbd> NuGet package. Once you've added this to your project, you can proceed in a similar way to when you used the SQL Server provider in <a href="8c8a9dbc-3bfc-4291-866f-fdd1a62c16ef.xhtml">Chapter 6</a>, <em>Interacting with Data in C# - Entity Framework Core</em>, but with a few differences. Let's take a look:</p>
<ol>
<li class="mce-root"><span>There are no migrations since Cosmos DB databases have no structure to update. Instead, they have a method that ensures that the database, along with all the necessary collections, is created:</span></li>
</ol>
<pre style="color: black;padding-left: 60px">context.Database.EnsureCreated();</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="2">
<li><kbd>DbSet&lt;T&gt;</kbd> <kbd>DBContext</kbd> properties don't map one-to-one to database collections, but several <kbd>DbSet&lt;T&gt;</kbd> properties can map to the same collection since collections can contain objects with different structures. Moreover, by default, all <kbd>DbSet&lt;T&gt;</kbd> properties are mapped to a unique collection since this is the cheapest option, but you can override this default by explicitly specifying which collection you want to map some entities to by using the following configuration instruction:</li>
</ol>
<pre style="padding-left: 60px">builder.Entity&lt;MyEntity&gt;()<br/>     .ToContainer("collection-name");</pre>
<ol start="3">
<li>The only useful annotation on entity classes is the <kbd>Key</kbd> attribute, which becomes obligatory when the principal keys are is called <kbd>Id</kbd>.</li>
<li>Principal keys must be strings and can't be auto-incremented to avoid synchronization issues in a distributed environment. The uniqueness of primary keys can be ensured by generating GUIDs and transforming them into strings.</li>
<li>When defining relationships between entities, you can specify that an entity or a collection of entities is owned by another entity, in which case it is stored together with the father entity.</li>
</ol>
<p>We will look at the usage of Cosmos DB's Entity Framework provider in the next section.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Use case – storing data</h1>
                </header>
            
            <article>
                
<p>Now that we've learned how to use NoSQL, we have to decide whether NoSQL databases are adequate for our WWTravelClub application. We need to store the following families of data:</p>
<ul>
<li><strong>Information about available destinations and packages</strong>: Relevant operations for this data are reads since packages and destinations don't change very often. However, they must be accessed as fast as possible from all over the World in order to ensure a pleasant user experience when users browse the available options. Therefore, a distributed relational database with geographically distributed replicas is possible, but not necessary, since packages can be stored inside their destinations in a cheaper NoSQL database.</li>
<li><strong>Destination reviews</strong>: In this case, distributed write operations have a non-negligible impact. Moreover, most writes are additions, since reviews aren't usually updated. Additions benefit a lot from sharding and don't cause consistency issues like updates do. Accordingly, the best option for this data is a NoSQL collection.</li>
<li><strong>Reservations</strong>: In this case, consistency errors aren't acceptable because they may cause overbooking. Reads and writes have a comparable impact, but we need reliable transactions and good consistency checks. Luckily, data can be organized in a multi-tenant database where tenants are destinations since reservation information belonging to different destinations is completely unrelated. Accordingly, we may use sharded SQL Azure database instances.</li>
</ul>
<p>In conclusion, the best option for data in the first and second bullet points is Cosmos DB, while the best option for the third point is Azure SQL Server. Actual applications may require a more detailed analysis of all data operations and their frequencies. In some cases, it is worth implementing prototypes for various possible options and executing performance tests with typical workloads on all of them.</p>
<p>In the remainder of this section, we will migrate the destinations/packages data layer we looked at in <a href="8c8a9dbc-3bfc-4291-866f-fdd1a62c16ef.xhtml">Chapter 6</a><span>, <em>Interacting with Data in C# - Entity Framework Core</em></span><span>,</span> to Cosmos DB.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Implementing the destinations/packages database with Cosmos DB</h1>
                </header>
            
            <article>
                
<p>Let's move on to the database example we built in <a href="8c8a9dbc-3bfc-4291-866f-fdd1a62c16ef.xhtml">Chapter 6</a><span>, </span><em>Interacting with Data in C# <span>–</span> Entity Framework Core</em><span>,</span> to Cosmos DB by following these steps:</p>
<ol>
<li>First of all, we need to make a copy of the WWTravelClubDB project and make <kbd>WWTravelClubDBCosmo</kbd> the new root folder.</li>
<li>Open the project and delete the migrations folder since migrations aren't required anymore.</li>
<li>We need to replace the SQL Server Entity Framework provider with the Cosmos DB provider. To do this, go to <span class="packt_screen">Manage NuGet Packages</span> and uninstall the <kbd>Microsoft.EntityFrameworkCore.SqlServer</kbd> NuGet package. Then, install the <kbd>Microsoft.EntityFrameworkCore.Cosmos</kbd> NuGet package.</li>
<li>Then, do the following on the <kbd>Destination</kbd> and <kbd>Package</kbd> entities:
<ul>
<li>Remove all data annotations. </li>
<li>Add the <kbd>[Key]</kbd> attribute to their <kbd>Id</kbd> properties since this is obligatory for Cosmos DB providers.</li>
</ul>
</li>
</ol>
<ul>
<li style="list-style-type: none">
<ul>
<li>Transform the type of the <kbd>Id</kbd> properties of both <kbd>Package</kbd> and <kbd>Destination</kbd>, and the <kbd>PackagesListDTO</kbd> classes from <kbd>int</kbd> to <kbd>string</kbd>. We need to turn into <kbd>string</kbd> also the <kbd>DestinationId</kbd> external references in the <kbd>Package</kbd>, and in the <kbd>PackagesListDTO</kbd> classes.  In fact, the best option for keys in distributed databases is a string generated from a GUID, because it is hard to maintain an identity counter when table data is distributed among several servers.</li>
</ul>
</li>
</ul>
<ol start="5">
<li>In the <kbd>MainDBContext</kbd> file, we need to specify that packages related to a destination must be stored inside the destination document itself. This can be achieved by replacing the Destination-Package relation configuration in the <kbd>OnModelCreatingmethod</kbd> method with the following code:</li>
</ol>
<pre style="padding-left: 60px">builder.Entity&lt;Destination&gt;()<br/>    .OwnsMany(m =&gt; m.Packages); </pre>
<ol start="6">
<li>Here, we must replace <kbd>HasMany</kbd> with <kbd>OwnsMany</kbd>. There is no equivalent to <kbd>WithOne</kbd> since once an entity is owned, it must have just one owner, and the fact that the <kbd>MyDestination</kbd> property contains a pointer to the father entity is evident from its type. Cosmos DB also allows the use of <kbd>HasMany</kbd>, but in this case, the two entities aren't nested one in the other. There is also an <kbd>OwnOne</kbd> configuration method for nesting single entities inside other entities.</li>
<li>Actually, both <kbd>OwnsMany</kbd> <span>and</span> <kbd>OwnsOne</kbd> <span>are available for relational databases, but in this case, the difference between </span><kbd>HasMany</kbd> <span>and</span> <kbd>HasOne</kbd> <span>is that children entities are automatically included in all queries that return their father entities, with no need to specify an</span> <kbd>Include</kbd> <span>LINQ clause. However, child entities are still stored in separate tables.</span></li>
<li><kbd>LibraryDesignTimeDbContextFactory</kbd> <span>must be modified to use Cosmos DB connection data, as shown in the following code:</span></li>
</ol>
<pre style="padding-left: 60px">using Microsoft.EntityFrameworkCore;<br/>using Microsoft.EntityFrameworkCore.Design;<br/><br/>namespace WWTravelClubDB<br/>{<br/>    public class LibraryDesignTimeDbContextFactory<br/>        : IDesignTimeDbContextFactory&lt;MainDBContext&gt;<br/>    {<br/>        private const string endpoint = "&lt;your account endpoint&gt;";<br/>        private const string key = "&lt;your account key&gt;";<br/>        private const string datbaseName = "packagesdb";<br/>        public MainDBContext CreateDbContext(params string[] args)<br/>        {<br/>            var builder = new DbContextOptionsBuilder&lt;Main<br/>            DBContext&gt;();<br/><br/>            builder.UseCosmos(endpoint, key, datbaseName);<br/>            return new MainDBContext(builder.Options);<br/>        }<br/>    }<br/>}</pre>
<ol start="9">
<li>Finally, in our test console, we must explicitly <span>create </span>all entity principal keys using GUIDS:</li>
</ol>
<pre style="padding-left: 60px">var context = new LibraryDesignTimeDbContextFactory()<br/>    .CreateDbContext();<br/>context.Database.EnsureCreated();<br/>var firstDestination = new Destination<br/>{<br/>    Id = Guid.NewGuid().ToString(),<br/>    Name = "Florence",<br/>    Country = "Italy",<br/>    Packages = new List&lt;Package&gt;()<br/>    {<br/>    new Package<br/>    {<br/>        Id=Guid.NewGuid().ToString(),<br/>        Name = "Summer in Florence",<br/>        StartValidityDate = new DateTime(2019, 6, 1),<br/>        EndValidityDate = new DateTime(2019, 10, 1),<br/>        DuratioInDays=7,<br/>        Price=1000<br/>    },<br/>    new Package<br/>    {<br/>        Id=Guid.NewGuid().ToString(),<br/>        Name = "Winter in Florence",<br/>        StartValidityDate = new DateTime(2019, 12, 1),<br/>        EndValidityDate = new DateTime(2020, 2, 1),<br/>        DuratioInDays=7,<br/>        Price=500<br/>    }<br/>    }<br/>};</pre>
<p style="padding-left: 60px">Here, we call <kbd>context.Database.EnsureCreated()</kbd> instead of applying migrations since we only need to create the database. Once the database and collections have been created, we can fine-tune their settings from the Azure Portal. Hopefully, future versions of Cosmos DB Entity Framework Core provider will allow us to specify all collection options.</p>
<ol start="10">
<li>Finally, the final query that starts with <kbd>context.Packages.Where...</kbd> must be modified since queries can't start from entities that are nested in other documents (in our case, <kbd>Package</kbd> entities). Therefore, we must start our query from the unique root <kbd>DbSet&lt;T&gt;</kbd> property we have in our <kbd>DBContext</kbd>, that is, <kbd>Destinations</kbd>. We can move from listing the external collection to listing all the internal collections with the help of the <kbd>SelectMany</kbd> method, which performs a logical merge of all nested <kbd>Packages</kbd> collections. However, since <kbd>CosmosDB</kbd> SQL doesn't support <kbd>SelectMany</kbd>, we must force <kbd>SelectMany</kbd> to be simulated on the client with <kbd>AsIenumerable()</kbd>, as shown in the following code:</li>
</ol>
<pre style="padding-left: 60px">var list = context.Destinations<br/>    .AsEnumerable() // move computation on the client side<br/>    .SelectMany(m =&gt; m.Packages)<br/>    .Where(m =&gt; period &gt;= m.StartValidityDate....)<br/>    ...</pre>
<ol start="11">
<li>The remainder of the query remains unchanged. If you run the project now, you should see the same outputs that were received in the case of SQL Server (with the exception of the primary key values).</li>
</ol>
<ol start="12">
<li>After executing the program, go to your Cosmos DB account. You should see something like the following:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="assets/32c20c41-6c2d-466e-9048-f45ae8d0d406.png"/></p>
<p>The packages have been nested inside their destinations as required and Entity Framework Core creates a unique collection that has the same name as the <kbd>DBContext</kbd> class.</p>
<p>If you would like to continue experimenting with Cosmos DB development without wasting all your free Azure Portal credit, you can install the Cosmos DB emulator available at this link: <a href="https://aka.ms/cosmosdb-emulator">https://aka.ms/cosmosdb-emulator</a>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we looked at the main storage options available in Azure and learned when to use them. Then, we compared relational and NoSQL databases. We pointed out that relational databases offer automatic consistency checking and transaction isolation, but NoSQL databases are cheaper and offer better performance, especially when distributed writes form a high percentage of the average workload.</p>
<p>Then, we described Azure's main NoSQL option, Cosmos DB, and explained how to configure it and how to connect with a client.</p>
<p>Finally, we learned how to interact with Cosmos DB with Entity Framework Core <span>and </span>looked at a practical example based on the WWTravelClubDB use case. Here, we learned how to decide between relational and NoSQL databases for all families of data involved in an application. This way, you can choose the kind of data storage that ensures the best compromise between data coherence, speed, and parallel access to data in each of your applications.</p>
<p>In the next chapter, we will learn all about Serverless and Azure Functions.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Questions</h1>
                </header>
            
            <article>
                
<ol>
<li>Is Redis a valid alternative to relational databases?</li>
<li>Are NoSQL databases a valid alternative to relational databases?</li>
<li>What operation is more difficult to scale out in relational databases?</li>
<li>What is the main weakness of NoSQL databases? What is their main advantage?</li>
<li>Can you list all Cosmos DB consistency levels?</li>
<li>Can we use auto-increment integer keys with Cosmos DB?</li>
<li>Which Entity Framework configuration method is used to store an entity inside its related father document?</li>
<li>Can nested collections be searched efficiently with Cosmos DB?</li>
</ol>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Further reading</h1>
                </header>
            
            <article>
                
<ul>
<li>In this chapter, we didn't talk about how to define sharding with SQL Azure. Here is the link to the official documentation if you want to find out more: <a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-scale-introduction">https://docs.microsoft.com/en-us/azure/sql-database/sql-database-elastic-scale-introduction</a>.</li>
<li>Cosmos DB was described in detail in this chapter, but further details can be found in the official documentation: <a href="https://docs.microsoft.com/en-us/azure/cosmos-db/">https://docs.microsoft.com/en-us/azure/cosmos-db/</a>.</li>
<li>The following is a reference to the Gremlin language, which is supported by Cosmos DB: <a href="http://tinkerpop.apache.org/docs/current/reference/#graph-traversal-steps">http://tinkerpop.apache.org/docs/current/reference/#graph-traversal-steps</a>.</li>
<li>The following is a general description of the Cosmos DB Graph Data Model: <a href="https://docs.microsoft.com/en-us/azure/cosmos-db/graph-introduction">https://docs.microsoft.com/en-us/azure/cosmos-db/graph-introduction</a>.</li>
<li>Details on how to use Cosmos DB's official .NET client can be found at <a href="https://docs.microsoft.com/en-us/azure/cosmos-db/sql-api-dotnetcore-get-started">https://docs.microsoft.com/en-us/azure/cosmos-db/sql-api-dotnetcore-get-started</a>. A good introduction to the <kbd>MvcControlsToolkit.Business.DocumentDB</kbd> NuGet package we mentioned in this chapter is the <span><em>Fast Azure Cosmos DB Development with the DocumentDB Package</em> article contained in </span>Issue 34 of DNCMagazine. This can be downloaded from <a href="http://www.dotnetcurry.net/s/dnc-mag-34th-single">http://www.dotnetcurry.net/s/dnc-mag-34th-single</a>.</li>
</ul>


            </article>

            
        </section>
    </body></html>