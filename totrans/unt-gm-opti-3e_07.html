<html><head></head><body>
        

                            
                    <h1 class="header-title">Faster Physics</h1>
                
            
            
                
<p>Each of the performance-enhancing suggestions we've explored so far has been primarily centered on reducing resource costs and avoiding frame rate issues. However, at its most fundamental level, seeking peak performance means improving the user experience. This is because every frame rate hiccup, every crash, and every system requirement that is too costly for a given market ultimately detracts from the quality of the product. Physics engines are a unique category of subsystems whose behavior and consistency contributes a significant factor toward product quality. Spending the time to improve their behavior is often worth the cost.</p>
<p>If important collision events get missed, the game freezes while it calculates a complex physics event, or the player falls through the floor, these scenarios have an obvious and significant negative impact on the quality of gameplay. A few glitches are often bearable, but continuous problems will get in the way of gameplay. This often results in pulling the player out of the experience, and it's a coin-toss whether the user finds it inconvenient, obnoxious, or hilarious. Unless our game is explicitly targeting the Comedy Physics genre (games such as <em>QWOP</em> or <em>Goat Simulator</em>), these are situations we should strive to avoid.</p>
<p>Some games may not use physics at all, whereas others require the physics engine to handle a considerable number of tasks during gameplay, such as collision detection between hundreds of objects, trigger volumes to initiate cutscenes, raycasting for player attacks and UI behavior, gathering lists of objects in a given region, or even just using physics as eye candy with lots of physical particles flying around. Its importance also varies depending on the type of game being created. For example, it is essential in platformer and action games to tune the physics properly—how the player character reacts to input and how the world reacts to the player character are two of the most critical aspects that make the game feel responsive and fun, whereas accurate physics may be somewhat less important in <strong>Massively Multiplayer Online</strong> (<strong>MMO</strong>) games, which tend to have limited physics interaction.</p>
<p>Therefore, in this chapter, we will cover ways to reduce CPU spikes, overhead, and memory consumption through Unity's physics engine, but also include ways to alter physics behavior to improve, or at least maintain, gameplay quality while optimizing performance. In this chapter, we will cover the following areas:</p>
<ul>
<li>Understanding how Unity's physics engine works:
<ul>
<li>Timesteps and fixed updates</li>
<li>Collider types</li>
<li>Collisions</li>
<li>Raycasting</li>
<li>Rigidbody active states</li>
</ul>
</li>
<li>Physics performance optimizations:
<ul>
<li>How to structure scenes for optimal physics behavior</li>
<li>Using the most appropriate types for a collider</li>
<li>Optimizing the Collision Matrix</li>
<li>Improving physics consistency and avoiding error-prone behavior</li>
<li>Ragdolls and other joint-based objects</li>
</ul>
</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding the physics engine</h1>
                
            
            
                
<p>Unity technically features two different physics engines: Nvidia's PhysX for 3D physics and the open source project Box2D for 2D physics. However, their implementations are highly abstracted, and from the perspective of the higher-level Unity API that we configure through the main Unity engine, both physics engine solutions operate in a functionally identical fashion.</p>
<p class="CDPAlignLeft CDPAlign">In either case, the more we understand about Unity's physics engines, the more sense we can make of possible performance enhancements. So, first, we'll cover the theory about how Unity implements these systems.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Physics and time</h1>
                
            
            
                
<p>Physics engines generally operate under the assumption that time advances by fixed values, and both of Unity's physics engines operate in this manner. Each of these iterations is known as a <strong>timestep</strong>. The physics engine will only resolve each timestep using precise values of time, which is independent of how much time it took to render the previous frame. This is known in Unity as the <strong>fixed update timestep</strong>, and it is set to a value of 20 milliseconds by default (50 updates per second).</p>
<p>It can be challenging to generate consistent results for collisions and forces between two different computers if a physics engine uses a variable timestep due to differences in architecture (in how floating-point values are represented) as well as the latency between clients. Such physics engines tend to generate very inconsistent results between multiplayer clients or during recorded replays.</p>
<p>The following diagram shows an important snippet of the Unity order of execution diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/15c8dbf6-83b9-4918-be4f-c86059890645.png" style="width:32.17em;height:31.33em;"/></p>
<p>The full execution order diagram can be found at <a href="http://docs.unity3d.com/Manual/ExecutionOrder.html">http://docs.unity3d.com/Manual/ExecutionOrder.html</a>.</p>
<p>As we can see in the preceding diagram, fixed updates are processed just before the physics engine performs its update, and the two are inextricably linked. The process begins with determining whether enough time has passed to start the next fixed update. Once this is determined, the outcome will vary depending on how much time has passed since the last fixed update.</p>
<p>If enough time has passed, then the fixed update processes will invoke all <kbd>FixedUpdate()</kbd> callbacks defined across all active MonoBehaviours in the scene, followed by any coroutines tied to fixed updates (specifically those that <kbd>yield</kbd> to <kbd>WaitForFixedUpdate</kbd>). Note that there is no guarantee of execution order for methods invoked during either of these processes, so we should never write code under this assumption. Once these tasks are done, the physics engine can begin to process the current timestep and invoke any necessary trigger and collider callbacks.</p>
<p>Conversely, if too little time has passed since the last fixed update (that is, less than 20 milliseconds), then the current fixed update is skipped, and all of the tasks listed previously don't happen during the current iteration. At this point, input, gameplay logic, and rendering will be allowed to happen as normal. Once this activity is complete, Unity checks whether the next fixed update is required.</p>
<p>At high frame rates, rendering updates are likely to complete multiple times before the physics engine gets a chance to update itself. As a consequence, fixed updates and the physics engine get a higher priority over rendering while also forcing the physics simulation into a fixed frame rate.</p>
<p>To ensure that objects move smoothly between fixed updates, physics engines (including Unity's) interpolate the visible location of each object between where it was during the previous state and where it should be after resolving the current state based on how much time remains until the next fixed update. This interpolation ensures that objects appear to move smoothly even though their physical positions, velocities, and so on are being updated less frequently than the render frame rate.</p>
<p>The <kbd>FixedUpdate()</kbd> callback is a useful place to define any gameplay behavior that we want to be frame-rate independent. AI calculations are commonly resolved in fixed updates since they tend to be easier to work with if we assume a fixed update frequency.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Maximum Allowed Timestep</h1>
                
            
            
                
<p>It is important to note that if a lot of time has passed since the last fixed update (for example, the game froze momentarily), then fixed updates will continue to be calculated within the same fixed update loop until the physics engine has caught up with the current time. For example, if the previous frame took 100 ms to render (for example, a sudden CPU spike caused the main thread to block for a long time), then the physics engine will need to be updated five times. The <kbd>FixedUpdate()</kbd> method will, therefore, be called five times before <kbd>Update()</kbd> can be called again due to the default fixed update timestep of 20 ms. Of course, if there is a lot of physics activity to process during these five fixed updates, such that it takes more than 20 ms to resolve them all, then the physics engine will need to invoke a sixth update.</p>
<p>Consequently, it's possible during moments of heavy physics activity that the physics engine takes more time to process a fixed update than the amount of time it is simulating. For example, if it took 30 ms to process a fixed update simulating 20 ms of gameplay, then it has fallen behind, requiring it to handle more timesteps to try and keep up, but this could cause it to fall back even further, requiring it to process even more timesteps, and so on. In these situations, the physics engine is never able to escape the fixed update loop and allow another frame to render. This problem is often known as the <strong>spiral of death</strong>. However, to prevent the physics engine from locking up our game during these moments, there is a maximum amount of time that the physics engine is allowed to process each fixed update loop. This threshold is called the <strong>Maximum Allowed Timestep</strong>, and if the current batch of fixed updates takes too long to process, then it will simply stop and forgo further processing until the next render update completes. This design allows the Rendering Pipeline to at least render the current state and allow for user input and gameplay logic to make some decisions during rare moments where the physics engine has gone ballistic (pun intended).</p>
<p>This setting can be accessed through Edit | Project Settings | Time | Maximum Allowed Timestep.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Physics updates and runtime changes</h1>
                
            
            
                
<p>When the physics engine processes a given timestep, it must move any active <kbd>Rigidbody</kbd> objects (GameObjects with a <kbd>Rigidbody</kbd> component), detect any new collisions, and invoke the collision callbacks on the corresponding objects. The Unity documentation makes an explicit note that changes to <kbd>Rigidbody</kbd> objects should be handled within <kbd>FixedUpdate()</kbd> and other physics callbacks for precisely this reason. These methods are tightly coupled with the update frequency of the physics engine as opposed to other parts of the game loop, such as <kbd>Update()</kbd>.</p>
<p>This means that callbacks such as <kbd>FixedUpdate()</kbd> and <kbd>OnTriggerEnter()</kbd> are safe places to make <kbd>Rigidbody</kbd> changes, whereas methods such as <kbd>Update()</kbd> and coroutines yielding on <kbd>WaitForSeconds</kbd> or <kbd>WaitForEndOfFrame</kbd> are not. Ignoring this advice could cause unexpected physics behavior, as multiple changes may be made to the same object before the physics engine is given a chance to catch and process all of them.</p>
<p>It's particularly dangerous to apply forces or impulses to objects in <kbd>Update()</kbd> callbacks without taking into account the frequency of those calls. For instance, imagine applying a 10 Newton force in the <kbd>Update</kbd> function while the player holds down a key: the resultant velocity will be completely different between two different devices than if we did the same thing in a fixed update. In fact, we can't rely on the number of <kbd>Update()</kbd> calls being consistent. However, doing so in a <kbd>FixedUpdate()</kbd> callback will be much more consistent. Therefore, we must ensure that all physics-related behavior is handled in the appropriate callbacks, or we will risk introducing some especially confusing gameplay bugs that are very hard to reproduce.</p>
<p>It logically follows that the more time we spend in any given fixed update iteration, the less time we have for the next gameplay and rendering pass. Most of the time this results in minor, unnoticeable background processing tasks, since the physics engine barely has any work to do, and the <kbd>FixedUpdate()</kbd> callbacks have a lot of time to complete their work. However, in some games, the physics engine could be performing a lot of calculations during each fixed update. This bottlenecking in physics processing time will affect our frame rate, causing it to plummet as the physics engine is tasked with greater and higher workloads. Essentially, the Rendering Pipeline will try to proceed as usual, but whenever it's time for a fixed update, in which the physics engine takes a long time to process, the Rendering Pipeline would have very little time to generate the current display before the frame is due, causing a sudden stutter. This is in addition to the visual effect of the physics engine stopping early because it hit Maximum Allowed Timestep. All of this together would generate an inferior user experience.</p>
<p>Hence, to keep a smooth and consistent frame rate, we will need to free up as much time as we can for rendering by minimizing the amount of time the physics engine takes to process any given timestep. This applies in both the best-case scenario (nothing moving) and worst-case scenario (everything smashing into everything else at once). There are several time-related features and values we can tweak within the physics engine to avoid performance pitfalls such as these.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Static colliders and dynamic colliders</h1>
                
            
            
                
<p>There is a rather extreme namespace conflict with the terms <strong>static</strong> and <strong>dynamic</strong> in Unity. When static is used, it usually means that the object or process under discussion is not moving, remains unchanged, or exists in only one location, whereas dynamic means the opposite—objects or processes that tend to move or change. However, it's important to remember that each of these is a separate topic, and usage of the terms static and dynamic means something different in each case. We have already introduced the Static sub flags for GameObjects, the dynamic batching and static batching systems, and the concepts of static classes, static variables, and static functions in the C# language. So, just to be extra-confusing, Unity also has the concept of static and dynamic colliders.</p>
<p>Dynamic colliders mean GameObjects that contain both a <kbd>Collider</kbd> component (which could be one of several types) and a <kbd>Rigidbody</kbd> component. By attaching <kbd>Rigidbody</kbd> to the same object as a collider, the physics engine will treat that collider as the bounding volume of a physical object that must react to outside forces (such as gravity) and collisions with other Rigidbodies. If we collide one dynamic collider into another, they will both react based on Newton's laws of motion (or at least as best as a computer using floating-point arithmetic is capable of).</p>
<p>We can also have colliders that do not have a <kbd>Rigidbody</kbd> component attached, and these are called static colliders. These effectively work as invisible barriers that dynamic colliders can collide into, but the static collider will not react in response. To think of it another way, imagine objects without a <kbd>Rigidbody</kbd> component as having infinite mass. No matter how hard you throw a rock into an object of infinite mass, it will never move, but you can still expect the rock to react like it just hit a solid wall. This makes static colliders ideal for world barriers and other obstacles that must not move.</p>
<p>The physics engine automatically separates dynamic and static colliders into two different data structures, each optimized to handle the types of collider present. This helps to simplify future processing tasks since, for example, there's no point in resolving collisions and impulses between two static colliders.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Collision detection</h1>
                
            
            
                
<p>There are three settings for collision detection in Unity, which can be configured in a <kbd>RigidBody</kbd> component's Collision Detection property: Discrete, Continuous, and ContinuousDynamic.</p>
<p>The Discrete setting enables Discrete Collision Detection, which effectively teleports objects a small distance every timestep based on their velocity and how much time has passed. Once all of the objects have been moved, it then performs a bounding volume check for any overlaps, treats them as collisions, and resolves them based on their physical properties and how they overlap. This method risks collisions being missed if small objects move too quickly.</p>
<p class="CDPAlignLeft CDPAlign">The following diagram shows how Discrete Collision Detection works to catch two objects as they teleport from one location to the next:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/fd505db6-74a1-4214-a3c8-9c070ca7d3e8.png" style="width:43.42em;height:17.83em;"/></p>
<p>Either of the remaining settings will enable Continuous Collision Detection, which works by interpolating colliders from their starting and ending positions for the current timestep and checking for any collisions along the way. This reduces the risk of missed collisions and generates a more accurate simulation at the expense of a significantly higher CPU overhead compared to Discrete Collision Detection.</p>
<p>The Continuous setting enables Continuous Collision Detection only between the given collider and static colliders. Collisions between the same collider and dynamic colliders will still make use of Discrete Collision Detection.</p>
<p>Meanwhile, the ContinuousDynamic setting enables Continuous Collision Detection between the collider and all static and dynamic colliders, making it the most expensive in terms of resources.</p>
<p>The following diagram shows how the Discrete Collision Detection and Continuous Collision Detection methods work for a pair of small, fast-moving objects:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/1de57846-1533-4fea-8ce1-93e3235da907.png"/></p>
<p>This is an extreme example for the sake of illustration. In the case of Discrete Collision Detection, we can observe that the objects are teleporting a distance around four times their size in a single timestep, which would typically only happen with very small objects with very high velocities, and is, hence, very rare if our game is running optimally. In the overwhelming majority of cases, the distances the objects travel in a single 20 ms timestep are much smaller relative to the size of the object, and so the collision is easily caught by Discrete Collision Detection methods.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Collider types</h1>
                
            
            
                
<p>There are four different types of 3D colliders in Unity. In order of the lowest performance cost to the greatest, they are as follows:</p>
<ul>
<li>Sphere</li>
<li>Capsule</li>
<li>Box</li>
<li>Mesh</li>
</ul>
<p>The first three collider types are often called <strong>primitives</strong> and maintain precise shapes, although they can generally be scaled in different directions to meet specific needs. Mesh Colliders can, however, be customized to a particular shape depending on the assigned mesh. There are also three types of 2D Collider—Circle, Box, and Polygon—that are functionally similar to Sphere, Box, and Mesh Colliders, respectively. All of the following information is mostly transferable to the equivalent 2D shape.</p>
<p>Note that we can also generate cylindrical 3D objects in Unity, but this is only for its graphical representation. Auto-generated cylinder shapes use Capsule Colliders to represent their physical bounding volume, which may not create the expected physics behavior.</p>
<p>Also, there are two varieties of Mesh Collider: <strong>Convex</strong> and <strong>Concave</strong>. The difference is that a Concave shape features at least one internal angle (an angle between two inside edges of the shape) of greater than 180 degrees. To illustrate this, the following diagram shows the difference between <strong>Convex</strong> and <strong>Concave</strong> shapes:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/5c79077d-411e-41e8-adb2-68f957287e8a.png" style="width:43.08em;height:17.17em;"/></p>
<p>An easy way to remember the difference between a Convex and Concave shape is that a Concave shape has at least one cave within it.</p>
<p>Both Mesh Collider types use the same component (a <kbd>MeshCollider</kbd> component). The type of Mesh Collider that gets generated is toggled using the Convex checkbox. Enabling this option will allow the object to collide with all primitive shapes (Spheres, Boxes, and so on) as well as other Mesh Colliders with Convex enabled.</p>
<p>Also, if the Convex checkbox is enabled for a Mesh Collider with a Concave shape, then the physics engine will automatically simplify it, generating a collider with the nearest Convex shape it can.</p>
<p>In the preceding example, if we imported the Concave mesh on the right and enable the Convex checkbox, it would generate a collider shape closer to the Convex shape on the left. In either case, the physics engine will attempt to generate a collider that matches the shape of the attached mesh with an upper limit of 255 vertices. If the target mesh has more vertices than this, it will throw an error during mesh generation.</p>
<p><kbd>Collider</kbd> components also contain the <kbd>IsTrigger</kbd> property, allowing them to be treated as nonphysical objects but still invoke physics events when other colliders enter or leave them. These are called <strong>trigger volumes</strong>. Normally, a collider's <kbd>OnCollisionEnter()</kbd>, <kbd>OnCollisionStay()</kbd>, and <kbd>OnCollisionExit()</kbd> callbacks are called when another collider touches, keeps touching (each timestep), or stops touching it, respectively. However, when the collider is used as a trigger volume, the <kbd>OnTriggerEnter()</kbd>, <kbd>OnTriggerStay()</kbd>, and <kbd>OnTriggerExit()</kbd> callbacks will be used instead.</p>
<p>Note that due to the complexity of resolving inter-object collisions, Concave Mesh Colliders cannot also be dynamic colliders. Concave shapes can only be used as static colliders or trigger volumes. If we attempt to add a <kbd>Rigidbody</kbd> component to a Concave Mesh Collider, Unity will ignore it.</p>
<p>What if you <em>really</em> need a Concave Mesh Collider acting as a <kbd>Rigidbody</kbd> component? The solution is to divide the object into a composition of separate Convex Mesh Colliders: for instance, you may want to compose an L-shaped <kbd>Rigidbody</kbd> by combining two convex boxes. Unfortunately, because this is a delicate decision, there is no automatic way to do that, and you need to perform such decomposition by hand.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">The Collision Matrix</h1>
                
            
            
                
<p>The physics engine features a Collision Matrix that defines which objects are allowed to collide with which other objects. Objects that do not fit this matrix are automatically ignored by the physics engine when the time comes to resolve bounding volume overlaps and collisions. This saves on physics processing during collision detection stages and allows the objects to move through one another without any collisions taking place.</p>
<p>The Collision Matrix can be accessed through Edit | Project Settings | (Physics / Physics2D) | Layer Collision Matrix.</p>
<p>The Collision Matrix system works through Unity's Layer system. The matrix represents every possible Layer-to-Layer combination that might be possible, and enabling a checkbox means that colliders in both of those Layers will be checked during the collision detection phase. Note that there's no way to allow only one of the two objects to respond to the collision. If one Layer can collide with another, then they must both respond to the collision. However, static colliders are an exception since they aren't allowed to react physically to collisions (although they still receive the <kbd>OnCollision...()</kbd> callbacks).</p>
<p>Note that we are limited to only 32 total Layers for our entire project (since the physics engine uses a 32-bit bitmask to determine inter-Layer collision opportunities), so we must organize our objects into sensible Layers that will extend throughout the entire lifetime of the project. If for whatever reason, 32 Layers are not enough for our project, then we might need to find cunning ways to reuse Layers or remove Layers that aren't necessary.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Rigidbody active and sleeping states</h1>
                
            
            
                
<p>Every modern physics engine shares a standard optimization technique, where by objects that have come to rest have their internal state changed from an active state to a sleeping state. While <kbd>Rigidbody</kbd> is in the sleeping state, little to no processor time will be spent during fixed updates to update the object until an external force or collision event has awoken it.</p>
<p>The value of measurement that is used to determine what at rest means tends to vary among different physics engines; it could be calculated using linear and rotational speed, kinetic energy, momentum, or some other physical properties of <kbd>Rigidbody</kbd>. Both of Unity's physics engines work by evaluating the object's mass-normalized kinetic energy, which essentially boils down to the magnitude of its velocity, squared.</p>
<p>If the object's velocity has not exceeded some threshold value after a short time, then the physics engine will assume that the object will no longer need to move again until it has undergone a new collision, or a new force has been applied to it. Until then, the sleeping object will maintain its current position. Setting the threshold value too low would mean objects are much less likely to go to sleep, so we will keep paying a small processing cost within the physics engine every fixed update, even though it is not doing anything important. Meanwhile, setting the threshold value too high would mean slow-moving objects will appear to jerk to a sudden stop once the physics engine decides that they need to go to sleep. The threshold value that controls the sleeping state can be modified under Edit | Project Settings | Physics | Sleep Threshold. We can also get a count of the total number of active <kbd>Rigidbody</kbd> objects from the Physics Area of the Profiler window.</p>
<p>Note that sleeping objects are not removed entirely from the simulation. If a moving <kbd>Rigidbody</kbd> approaches the sleeping object, then it must still perform checks to see whether nearby objects have collided with it, which would reawaken the sleeping object, reintroducing it to the simulation for processing.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Ray and object casting</h1>
                
            
            
                
<p>Another common feature of physics engines is the ability to cast a ray from one point to another and generate collision information with one or more of the objects in its path. This is known as <strong>raycasting</strong>. It is pretty common to implement several gameplay mechanics through raycasting, such as firing a gun. This is typically implemented by performing raycasts from the player to the target location and finding any viable targets in its path (even if it's just a wall).</p>
<p>We can also obtain a list of targets within a finite distance of a fixed point in space using a <kbd>Physics.OverlapSphere()</kbd> check. This is typically used to implement area-of-effect gameplay features, such as grenade or fireball explosions. We can even cast entire objects forward in space using <kbd>Physics.SphereCast()</kbd> and <kbd>Physics.CapsuleCast()</kbd>. These methods are often used to simulate wide laser beams, or if we want to see what would be in the path of a moving character.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Debugging physics</h1>
                
            
            
                
<p>Physics bugs usually fall into two categories: an object pair collided/didn't collide when it shouldn't have/should have, or the objects collided but something unexpected happened after the fact. The former case is generally easier to debug; it is often either due to mistakes in the Collision Matrix, incorrect Layers used in raycasting, or object colliders being the wrong size or shape. The latter case is often much more challenging to resolve because of three big problems:</p>
<ul>
<li>Determining which collided objects caused the issue</li>
<li>Determining the conditions of the collision just before the resolution</li>
<li>Reproducing the collision</li>
</ul>
<p>Any of these three pieces of information would make resolution much easier, but they can all be difficult to obtain in some circumstances.</p>
<p>The Profiler provides some measure of information in the Physics and Physics (2D) Areas (for 3D and 2D physics, respectively), which can be moderately useful. We can get a measure of how much CPU activity is being spent on all Rigidbodies and groups of Rigidbodies isolated to different types such as dynamic colliders, static colliders, kinematic objects, trigger volumes, constraints (used to simulate hinges and other connected physics objects), and contacts.</p>
<p>The Physics 2D Area contains a little more information such as the number of sleeping and active Rigidbodies and how long processing the Timestep took. The Detailed Breakdown View provides even more information in both cases. This information helps us to keep an eye on the physics performance, but it doesn't tell us much about what went wrong in the event we find a bug in our physics behavior.</p>
<p>A tool that is better suited to the task of helping us to debug physics issues is the Physics Debugger, which can be opened via Window | Analysis | Physics Debugger. This tool can help us to filter out different types of colliders from the Scene window to give us a better idea of which objects collide with one another. Of course, this does not help too much in determining the conditions of the problem and reproducing issues.</p>
<p>Note that settings in the Physics Debugger do not affect object visibility in the Game window.</p>
<div><p>Unfortunately, there isn't much secret advice to be given for the remaining problems. Catching information about collisions before or when they happen involves typically a lot of targeted breakpoints in an <kbd>OnCollisionEnter()</kbd> or <kbd>OnTriggerEnter()</kbd> callback to catch the problem in the act and using step-through debugging until the source of the issue becomes apparent. As a last resort, we can add <kbd>Debug.Log()</kbd> statements to log important information just before the problem occurs, although this can be a frustrating exercise because we sometimes don't know what information we need to log or which objects to log from, and so we end up adding logs to everything.</p>
<p>Another frequent source of headaches is trying to reproduce physics problems. Reproducing collisions is always a challenge due to the non-deterministic nature between user input (typically handled in <kbd>Update()</kbd>) and physics behavior (processed in <kbd>FixedUpdate()</kbd>). Even though physics timesteps occur with relative regularity, the simulation will have different timings on each <kbd>Update()</kbd> between one session and the next, so also, if we recorded user input timings and automatically replayed the scene, trying to apply the recorded inputs at the moments they were applied isn't going to be precisely the same every time, and so we may not get the same result.</p>
<p>Moving user input handling to <kbd>FixedUpdate()</kbd> is possible, and helpful if user input controls <kbd>Rigidbody</kbd> behavior such as applying forces in different directions while the player holds down certain keys. However, this will tend to lead to input latency or <em>lag</em>, since it will be anywhere from 0 to 20 ms (based on the fixed update timestep frequency) before the physics engine can respond to the key being pressed. Instantaneous inputs, such as jumping or activating an ability, are always best handled in <kbd>Update()</kbd> to avoid<br/>
missing keystrokes.</p>
<p>Helper functions such as <kbd>Input.GetKeyDown()</kbd> would only return <kbd>true</kbd> for the frame the player presses the given key and will return <kbd>false</kbd> during the next <kbd>Update()</kbd>. If we tried to read a key-down event during <kbd>FixedUpdate()</kbd>, we would never know that the user pressed the key, unless a physics timestep just happens to occur between these two frames. This can be worked around with an input buffering/tracking system, but this is certainly more trouble than its worth if we're implementing it merely to replicate a physics bug.</p>
<p>Ultimately, experience and persistence are the only right ways to debug most physics problems. The more knowledge we have with the physics engine, the more intuition we will have to find the source of the problem, but unfortunately they almost always take a lot of time to resolve due to their limited reproducibility and sometimes nebulous behavior, and so we should expect physics issues to take longer than most logic bugs to fix and plan extra time before it can be resolved.</p>
<p>Now that we have an understanding of the majority of features of the Unity physics engine, we can cover several optimization techniques to improve our game's physics performance.</p>
</div>


            

            
        
    

        

                            
                    <h1 class="header-title">Physics performance optimizations</h1>
                
            
            
                
<p>In this section, we will go over several techniques, optimizations, tricks, and settings that will allow your game to extract every drop of physics performance from your game. This includes how to set up your scene, learn when to use static colliders, how to configure the Collision Matrix, when to use triggers instead of Rigidbodies, and much more. Let's go over all of these, one by one.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Scene setup</h1>
                
            
            
                
<p>Firstly, there are several best practices we can apply to our scenes to improve the consistency of the physics simulation. Note that several of these techniques will not necessarily improve CPU or memory usage, but they will result in a reduced likelihood of instability from the physics engine.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Scaling</h1>
                
            
            
                
<p>We should try to keep all physics object scales in the world as close to <kbd>(1,1,1)</kbd> as we possibly can. By default, Unity assumes that we are trying to simulate gameplay equivalent to being on the surface of the Earth. The force of gravity at the surface of the Earth is 9.81 meters-per-second squared, and hence the default gravity value is set to <kbd>-9.81</kbd> to match. One unit in Unity's world space is equivalent to 1 meter, and the negative sign means that it will pull the object downward. Our object sizes should reflect our effective world scale since scaling them too large will cause gravity to appear to move the objects much more slowly than we would expect. If all of our objects are scaled five times too big, then gravity will appear to be five times weaker. The converse is also true; scaling objects too small will make them look to fall too quickly and will not seem realistic.</p>
<p>We can tweak the world's implied scale by modifying the strength of gravity under Edit | Project Settings | Physics / Physics 2D | Gravity. However, note that any floating-point arithmetic will be more accurate with values closer to <kbd>0</kbd>, so if we have some objects that have scale values far above <kbd>(1,1,1)</kbd>, even if they match the implied world scale, then we could still observe erratic physics behavior. So, early in the project, we should import and scale our most common physics objects around a scale value of <kbd>(1,1,1)</kbd> and then adjust the value of gravity to match. This will give us a reference point to work with as we introduce new objects.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Positioning</h1>
                
            
            
                
<p>Similarly, keeping all objects close to <kbd>(0,0,0)</kbd> in the world-space position will result in better floating-point accuracy, improving the consistency of the simulation. Space simulator and free-running games try to simulate incredibly large spaces and typically use a trick of either secretly teleporting the player back toward the center of the world or fixing their position there, in which case, either volumes of space are compartmentalized so that physics calculations are always calculated with values close to <kbd>0</kbd>, or everything else is moved to simulate travel, and the player's motion is only an illusion.</p>
<p>Most games are not at risk of introducing floating-point inaccuracy, since most game levels tend to last around 10 to 30 minutes, which doesn't give the player much time to travel absurdly long distances, but if we're working with exceptionally large scenes or asynchronously loading scenes throughout the course of the entire game to the point that the player travels tens of thousands of meters, then we may start to notice some strange physics behavior the further they go.</p>
<p>So, unless we're already far too deep into our project so that changing and retesting everything at a late stage would be too much hassle, we should try to keep all of our physics objects close to <kbd>(0,0,0)</kbd>. Plus, this is good practice for our project workflow, as it makes it much quicker to find objects and tweak things in our game world.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Mass</h1>
                
            
            
                
<p>Mass is stored as a floating-point value under a <kbd>Rigidbody</kbd> component's mass property, and documentation on its usage has changed a fair amount over the years due to updates in its physics engine. Since late Unity 5, we are essentially free to choose whatever we want the <kbd>1.0</kbd> value to represent and then scale other<br/>
values appropriately.</p>
<p>Traditionally, a mass value of <kbd>1.0</kbd> is used to represent a mass of 1 kilogram, but we could decide that a human being has a mass of <kbd>1.0</kbd> (~80 kilograms), in which case, a car would be given a mass value of <kbd>15.0</kbd> (~1,200 kilograms), and physics collisions will resolve similarly to what we expect. The most important part is the relative difference in mass, which allows collisions between these objects to look believable without stressing the engine too much. Floating-point precision is also a concern, so we don't want to use large mass values that are too ridiculous.</p>
<p>Note that if we intend to use Wheel Colliders, their design assumes that a mass of <kbd>1.0</kbd> represents 1 kilogram, so we should assign our mass values appropriately.</p>
<p>Ideally, we would maintain mass values around <kbd>1.0</kbd> and ensure a maximum relative mass-ratio of around <kbd>100</kbd>. If two objects collide with a mass ratio much higher than this, then large momentum differences can turn into sudden, immense velocity changes from the impulse, resulting in some unstable physics and potential loss of floating-point precision. Object pairs that have a significant scale difference should probably be culled with the Collision Matrix to avoid problems (more on this shortly).</p>
<p>Improper mass ratios are the most common cause of physics instability and erratic behavior in Unity. This is particularly true when using joints for objects such as ragdolls.</p>
<p>Note that the force of gravity at the center of the Earth affects all objects equally, regardless of their mass, so it does not matter if we consider a mass property value of <kbd>1.0</kbd> to be the mass of a rubber ball or the mass of a warship. There's no need to adjust the force of gravity to compensate. What does matter, however, is the amount of air resistance the given object undergoes while falling (which is why a parachute falls slowly). So, to maintain realistic behavior, we may need to customize the drag property for such objects or customize the force of gravity on a per-object basis. For example, we could disable the Use Gravity checkbox and apply our custom gravitational force during fixed updates.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using static colliders appropriately</h1>
                
            
            
                
<p>As mentioned previously, the physics engine automatically generates two separate data structures to contain static colliders separately from dynamic colliders. Unfortunately, if new objects are introduced into the static collider data structure at runtime, then it must be regenerated, similar to calling <kbd>StaticBatchingUtility.Combine()</kbd> for static batching. This is likely to cause a significant CPU spike. This makes it vital that we avoid instantiating new static colliders during gameplay.</p>
<p>Also, merely moving, rotating, or scaling static colliders triggers this regeneration process and should be avoided. If we have colliders that we wish to move around without physically reacting to other objects colliding with them, then we should attach <kbd>Rigidbody</kbd> to make it a dynamic collider and enable the Kinematic flag. This flag prevents the object from reacting to external impulses from inter-object collisions, similar to static colliders, except the object can still be moved through its <kbd>transform</kbd> component or through forces applied to its <kbd>Rigidbody</kbd> component (preferably during fixed updates). Since a kinematic object won't respond to other objects hitting it, it will tend to push other dynamic colliders out of its way as it moves.</p>
<p>It's for this reason that player character objects are often made into Kinematic Colliders.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using trigger volumes responsibly</h1>
                
            
            
                
<p>As mentioned previously, we can treat our physics objects as normal colliders or as trigger volumes. An important distinction between these two types is that the <kbd>OnCollider...()</kbd> callbacks provide a <kbd>Collision</kbd> object as a parameter to the callback, which contains useful information such as the exact location of collision (helpful to position a particle effect) and the contact normal (useful if we want to move the object after the collision manually). However, the <kbd>OnTrigger...()</kbd> callbacks do not provide this kind of information.</p>
<p>As a result, we should not try to use trigger volumes for collision-reactive behavior since we won't have enough information to make the collision appear accurate. trigger volumes are best used for their intended purpose of tracking when an object enters/exits a specific area, such as dealing with damage while a player stays in a lava pit, triggering a cutscene when a player enters a building, and initiating asynchronous loading/unloading of a scene when the player approaches/moves far enough away from another major area.</p>
<p>If the contact information is absolutely needed for a trigger volume collision, then common workarounds are to do any of the following:</p>
<ul>
<li>Generate a rough estimate for the contact point by halving the distance between the trigger volume and colliding objects' centers of mass (this assumes that they're of roughly equal size).</li>
<li>Perform a raycast upon collision from the center of the trigger volume to the center of mass of the colliding object (works best if both of the objects are spherical).</li>
<li>Create a non-trigger volume object, give it an infinitesimally small mass (so that its presence barely affects the colliding object), and immediately destroy it upon collision (since a collision with such a large mass differential will probably send this small object into orbit).</li>
</ul>
<p>Of course, each of these approaches has its drawbacks—limited physical accuracy, extra CPU overhead during the collision, and/or additional scene setup (and rather hacky-looking collision code)—but they can be useful in a pinch.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Optimizing the Collision Matrix</h1>
                
            
            
                
<p>As we know, the physics engine's Collision Matrix defines which objects assigned to specific Layers are allowed to collide with objects assigned to other Layers. To put it more succinctly, which object collision pairs are even considered viable by the physics engine. Every other object-Layer pair is simply ignored by the physics engine, which makes this an important avenue for minimizing physics engine workload since it reduces the number of bounding volume checks that must be performed every fixed update and how many collisions would ever need to be processed during the life cycle of the application (which would save on battery life for a mobile device).</p>
<p>Note that the Collision Matrix can be accessed through Edit | Project Settings | Physics (or Physics2D) | Layer Collision Matrix.</p>
<p>The following screenshot shows a standard Collision Matrix for an arcade shooter game:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f38af74f-4ff1-4885-8259-2668226e75f4.png"/></p>
<p>In the preceding example, we have objects flagged as Player, Enemies, Player Missiles, Enemy Missiles, and Powerups, and we have minimized the number of possible inter-object collisions for the physics engine to check.</p>
<p>Starting with the first row of checkmarks labeled Player, we want the Player object to be able to collide with World objects, pick up Powerups, get hit by Enemy Missiles, and collide with Enemies. However, we do not want them to collide with their Player Missiles or themselves (although there would probably only be one object in this Layer, anyway). Hence, the enabled checkboxes in the Player row reflect these requirements. We only want Enemies to collide with World objects and Player Missiles, so these are checked in the Enemies row. Note that the Player-to-Enemies collision pair would have been handled already by the previous row; hence, there is no need for it to appear in the Enemies row. We also want both Player Missiles and Enemy Missiles to explode when they hit World objects, so these are marked, and finally we don't care about Powerups colliding with anything but the Player, nor do we want World objects to collide with other World objects, so no checkboxes are marked on the final two rows.</p>
<p>At any given moment, we might have a single Player object, 2 Powerups, 7 Player Missiles, 10 Enemies, and 20 Enemy Missiles, which is 780 potential collision pairs (this is calculated as each of 40 different objects could collide with 39 other ones, giving us 1,560 likely collision pairs, but then we divide the total by 2 to ignore duplicate pairs). By merely optimizing this matrix, we have reduced this to less than 100, for an almost 90% reduction in potential collision checks. Of course, the Unity physics engine efficiently culls away many of these object pairs if they are too far apart from one another. Hence, there is little to no chance that they could collide (this is calculated during a hidden process known as <strong>Broadphase culling</strong>), so the actual savings will probably never be this good, but it will free up some CPU cycles with next to no effort. Another significant benefit is that it simplifies our game logic coding; there's no need to figure out what's supposed to happen if Powerups and Enemy Missiles collide if we tell the physics engine to ignore collisions between them.</p>
<p>We should perform logical sanity checks like this for all potential Layer combinations in the Collision Matrix to see whether we're wasting precious time checking for inter-object collisions between object pairs that aren't necessary. </p>


            

            
        
    

        

                            
                    <h1 class="header-title">Preferring discrete collision detection</h1>
                
            
            
                
<p>Discrete collision detection is relatively cheap since teleporting objects once and performing a single overlap check between nearby object pairs is a relatively trivial amount of work to perform in a single timestep. The amount of calculation required to perform continuous collision detection is significantly higher since it involves interpolating both objects between their starting and ending positions while analyzing for any slight bounding volume overlaps between these points as they might occur during the timestep.</p>
<p>Consequently, the Continuous collision detection option is an order of magnitude more expensive than the Discrete detection method, whereas the ContinuousDynamic collision detection setting is an order of magnitude even more costly than Continuous. Having too many objects configured to use either of the continuous collision detection types will cause severe performance degradation in complex scenes. In both cases, the cost for collision detection grows exponentially with the number of objects that need to be compared during any given frame with a steep increase if the collider is dynamic instead of static.</p>
<p>Ergo, we should favor the Discrete collision detection setting for the overwhelming majority of our objects, while using either of the continuous collision detection settings only in extreme circumstances. The Continuous setting should be used when important collisions are frequently missed with the more static parts of our game world. For instance, if we wish to be sure that the player characters never fall through the game world or never accidentally teleport through walls if they move too quickly, then we might want to apply continuous collision detection only for those objects. Finally, the ContinuousDynamic setting should only be used if the same situation applies, and we wish to catch collisions between pairs of very fast-moving dynamic colliders.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Modifying the fixed update frequency</h1>
                
            
            
                
<p>In some cases, Discrete collision detection might not work well enough on a large scale. Perhaps our entire game revolves around a lot of small physics objects, and discrete collision detection simply isn't catching enough collisions to maintain product quality. However, applying one of the continuous collision detection settings to everything would be far too prohibitive on performance. In this case, there is one option we can try: we can customize the physics timestep to give the Discrete collision detection system a better chance of catching such collisions by modifying how frequently the engine checks for fixed updates.</p>
<p>As mentioned previously, fixed updates and physics timestep processing are strongly coupled; so, by modifying the frequency of fixed update checks, we not only change the rate that the physics engine will calculate and resolve the next callback, but we also change how frequently the <kbd>FixedUpdate()</kbd> callbacks and coroutines are being invoked. Consequently, changing this value can be risky if we're deep into our project and have a lot of behavior that depends on these callbacks since we will be changing a fundamental assumption about how often these methods are invoked.</p>
<p>Altering the fixed update frequency can be accomplished using the Edit | Project Settings | Time | Fixed Timestep property in the Editor or through the <kbd>Time.fixedDeltaTime</kbd> property in script code.</p>
<p>Reducing this value (increasing the frequency) will force the physics engine to process more frequently, giving it a better chance of catching collisions with discrete collision detection. Naturally, this comes with an added CPU cost since we're invoking more <kbd>FixedUpdate()</kbd> callbacks and asking the physics engine to update more frequently, having it move objects and verify collisions more often.</p>
<p>Conversely, increasing this value (decreasing the frequency) provides more time for the CPU to complete other tasks before it must handle physics processing again, or, looking at it from another perspective, it gives the physics engine more time to process the last timestep before it begins processing the next one. Unfortunately, lowering the fixed update frequency would necessarily reduce the maximum velocity at which objects can move before the physics engine can no longer capture collisions with discrete collision detection (depending on the objects' sizes). We might also start to see objects changing velocities in strange ways because it is essentially becoming a weaker approximation of real-world physics behavior.</p>
<p>This makes it vital to perform a significant amount of testing each time the Fixed Timestep value is changed. Even with a complete understanding of how this value works, it is difficult to predict the overall outcome during gameplay and whether the result is passable for quality purposes. Hence, changes to this value should be made early in the project's life cycle and then made infrequently to get a sufficient amount of testing against as many physics situations as possible.</p>
<p>It might help to create a test scene that flings some of our high-velocity objects at one another to verify that the results are acceptable and run through this scene whenever Fixed Timestep changes are made. However, actual gameplay tends to be rather complicated, with many background tasks and unanticipated player behavior that causes additional work for the physics engine or gives it less time to process the current iteration. Actual gameplay conditions are impossible to replicate in a vacuum. Also, there's no substitute for the real thing, so the more testing we can accomplish against the current value of the Fixed Timestep, the more confident we can be that the changes meet acceptable quality standards.</p>
<p>Take it from someone who's in the career of developing software automation tools: automation of software testing is helpful in a lot of situations, but when it comes to real-time event- and user input-driven applications that synchronize with multiple hardware devices and complex subsystems such as physics engines and tend to change rapidly due to iterations on feedback, the support and maintenance costs of automated testing often becomes more effort than its worth, making manual testing the most sensible approach.</p>
<p>We always have continuous collision detection as a last resort to offset some of the resulting instability we're observing. Unfortunately, even if the changes are targeted, it is more likely that this will cause further performance issues than we started with due to the overhead costs of continuous collision detection. It would be wise to profile our scene before and after enabling continuous collision detection to verify that the benefits are outweighing the costs.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Adjusting the Maximum Allowed Timestep</h1>
                
            
            
                
<p>If we're regularly exceeding the Maximum Allowed Timestep (which, as a reminder, determines how much time the physics engine has to resolve a timestep before it must exit early), then it will result in some pretty bizarre-looking physics behavior. Rigidbodies will appear to slow down or jerk to a stop since the physics engine needs to keep exiting timestep calculations early before it has fully resolved its entire time quota. In this case, it is a clear sign that we need to optimize our physics behavior from other angles. However, at the very least, we can be confident that the threshold will prevent the game from completely locking up from a spike in the middle of physics processing.</p>
<p>Reminder: this setting can be accessed through Edit | Project Settings | Time | Maximum Allowed Timestep.</p>
<p>The default setting is to consume a maximum of 0.333 seconds, which would manifest itself as a very noticeable drop in frame rate (a mere 3 FPS) if it were exceeded. If you ever feel the need to change this setting, then you obviously have some big problems with your physics workload, so it is recommended that you only tweak this value if you have exhausted all other approaches.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Minimizing raycasting and bounding-volume checks</h1>
                
            
            
                
<p>All of the raycasting methods are incredibly useful, but they are relatively expensive, particularly <kbd>CapsuleCast()</kbd> and <kbd>SphereCast()</kbd>. We should avoid calling these methods regularly within the <kbd>Update()</kbd> callbacks or coroutines, saving them only for critical events in our script code.</p>
<p>If we're making use of persistent line, ray, or area-of-effect collision areas in our scene (examples include security lasers, continuously burning fires, and beam weapons), and the object remains relatively stationary, then they would perhaps be better simulated using a simple trigger volume.</p>
<p>If such replacements are not possible, and we truly need persistent casting checks using these methods, we should minimize the amount of processing each raycast makes by exploiting <kbd>LayerMasks</kbd>. This is particularly true if we're making use of <kbd>Physics.RaycastAll()</kbd>. For example, a poorly optimized usage of this kind of raycasting would look as follows:</p>
<pre>void PerformRaycast() {<br/> RaycastHit[] hits;<br/>  hits = Physics.RaycastAll(transform.position, transform.forward, <br/>  100.0f);<br/>  for (int i = 0; i &lt; hits.Length; ++i) {<br/>    RaycastHit hit = hits[i];<br/>    EnemyComponent e = hit.transform.GetComponent&lt;EnemyComponent&gt;();<br/>    if (e.GetType() == EnemyType.Orc) {<br/>        e.DealDamage(10);<br/>    }<br/>  }<br/>}</pre>
<p>In the preceding example, we're collecting raycast collision data for every object in the path of this ray, but we're only processing its effects on objects that hold a specific <kbd>EnemyComponent</kbd> instance. Consequently, we're asking the physics engine to complete much more work than is necessary. </p>
<p>A better approach will be to use a different overload of <kbd>RaycastAll()</kbd>, which accepts a <kbd>LayerMask</kbd> value as an argument. This will filter collisions for the ray in much the same way as the Collision Matrix so that it only tests against objects in the given Layer(s). The following code contains a subtle improvement by providing an additional <kbd>LayerMask</kbd> property; we would configure <kbd>LayerMask</kbd> through the Inspector window for this Component, and it will filter the list much faster and only contain <kbd>hits</kbd> for objects matching the mask:</p>
<pre><strong>[SerializeField] LayerMask _layerMask;</strong><br/><br/>void PerformRaycast() {<br/>  RaycastHit[] hits;<br/>  hits = Physics.RaycastAll(transform.position, transform.forward, 100.0f<strong>, _layerMask</strong>);<br/>  for (int i = 0; i &lt; hits.Length; ++i) {<br/>    // as before ...<br/>  }<br/>}</pre>
<p>This optimization doesn't work as well for the <kbd>Physics.RaycastHit()</kbd> function since that version only provides ray collision information for the first object the ray collides with, regardless of whether we're using <kbd>LayerMask</kbd> or not.</p>
<p>Note that because the <kbd>RaycastHit</kbd> and <kbd>Ray</kbd> classes are managed by the native memory space of the Unity engine, they don't result in memory allocations that draw the attention of the garbage collector. We will learn more about such activity in <a href="">Chapter 8</a>, <em>Masterful Memory Management</em>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Avoiding complex Mesh Colliders</h1>
                
            
            
                
<p>In order of collision detection efficiency, the various colliders are Spheres, Capsules, Boxes, Convex Mesh Colliders, and Concave Mesh Colliders, the last being far and away the most expensive. Collisions always involve pairs of objects, and the amount of work (math) needed to resolve the collision will depend on the complexity of both objects. Detecting collisions between two primitive objects can be reduced down to a relatively simple set of mathematical equations that are highly optimized. Performing comparisons against a pair of Convex Mesh Colliders is a much more complex equation, making them an order of magnitude more expensive than collisions between two primitives. Then, there are collisions between two Concave Mesh Colliders, which are so complex that they cannot be reduced down to a simple formula and require collision checks to be resolved between each pair of triangles across both meshes, easily making them orders of magnitude more expensive than collisions between other collider types. The amount of work involved scales similarly when we resolve collisions between shapes of different groups. For example, a collision between a primitive and Concave Mesh Collider would be slower than a collision between two primitives, but faster than a collision between two Concave Mesh Colliders.</p>
<p>There is also the question of whether one—or both—of the objects involved in the collision is moving (one of the objects being a static collider is easier to process than both objects being dynamic colliders). There is also the matter of how many of these objects are within our scene since the total processing costs of collision detection will snowball if we're not careful with how many shapes we introduce into the simulation.</p>
<p>A great irony between representing physics and graphics in 3D applications is how difficult it is to handle spherical and cube objects between the two of them. The perfect spherical mesh would require an infinite number of polygons to be generated, making such an object impossible to represent graphically.</p>
<p>However, handling collisions between two spheres in a physics engine is perhaps the most straightforward problem to solve for contact points and collisions (the contact point is always at the edge of either of the sphere's radius, and the contact normal is always the vector between their centers of mass). Conversely, a cube is one of the simplest objects to represent graphically (as little as 8 vertices and 12 triangles) and yet takes significantly more mathematics and processing power to find contact points and resolve collisions for (and the mathematics to resolve it depends on whether the collision occurred between faces, edges, corners, or a mixed pairing). Anecdotally, this implies that the most efficient way of creating the largest number of objects would be to populate our world with cube objects that use spherical colliders. However, this would make absolutely no sense to a human observer, as they would witness cubes rolling around like balls.</p>
<p>The previous anecdote serves as a reminder that the physical representation of an object does not necessarily need to match its graphical representation. This is beneficial, as a graphical mesh can often be condensed down into a much simpler shape, while still generating very similar physics behavior and simultaneously removing the need to use an overly complex Mesh Collider.</p>
<p>This separation of representations between graphics and physics allows us to optimize the performance of one system without (necessarily) negatively affecting the other. So long as there are no noticeable repercussions on gameplay (or we're willing to make the sacrifice), then we are free to represent complex graphical objects with much simpler physics shapes without players noticing. Also, if the player never notices, then no harm is done.</p>
<p>So, we can solve this problem in one of the two ways: either by approximating the physics behavior of the complex shape using one (or more) of the standard primitives or by using a much simpler Mesh Collider.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using simpler primitives</h1>
                
            
            
                
<p>Most shapes can be approximated using one of the three primitive colliders. In fact, we do not need to represent the object using only a single collider. We are free to use several colliders if they serve our needs for creating a complex collision shape by attaching additional child GameObjects with their colliders. This is almost always less expensive than using a single Mesh Collider and should be preferred.</p>
<p>The following screenshot shows a handful of complex graphical objects represented by one or more simpler primitive collider shapes:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/9fb5fecd-178c-4e6a-8e2d-11539bc179ea.png"/></p>
<p>Using a Mesh Collider for any one of these objects would be significantly more expensive than the primitive colliders shown here due to the number of polygons they contain. It is worth exploring all opportunities to simplify our objects down using these primitives as much as we can, as they can provide significant performance gains.</p>
<p>For example, Concave Mesh Colliders are unique in that they can feature gaps or holes that allow other meshes to fall into or even through them, which introduces opportunities for the objects to fall through the world if such colliders are used for world collision areas. It is often better to place Box Colliders in strategic locations for this purpose.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using simpler Mesh Colliders</h1>
                
            
            
                
<p>Similarly, the mesh assigned to a Mesh Collider does not necessarily need to match the graphical representation of the same object (Unity simply picks it as the default). This allows us to assign a simpler mesh to the Mesh Collider's <kbd>mesh</kbd> property, which is different from the one we use for its graphical representation.</p>
<p>The following screenshot shows an example of a sophisticated graphical mesh that has been given a much more simplified mesh for its Mesh Collider:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/88d9b137-df0a-4a4a-93bf-b0bed46c6bc4.png" style="width:45.25em;height:26.25em;"/></p>
<p>Simplifying the rendered mesh into convex shapes with lower polygon counts in this way will significantly reduce the overhead needed to determine bounding volume overlaps with other colliders. Depending on how well the original object is estimated, there should be minimal noticeable gameplay differences, especially in the case of this ax, which we expect to be moving quickly as creatures swing it during attacks, making it unlikely that players will notice the difference between the two meshes as colliders. In fact, the simplified mesh is much less likely to be missed by discrete collision detection and is preferable for that reason.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Avoiding complex physics components</h1>
                
            
            
                
<p>Certain special physics <kbd>Collider</kbd> components, such as <kbd>TerrainCollider</kbd>, <kbd>Cloth</kbd>, and <kbd>WheelCollider</kbd>, are orders of magnitude more expensive than all primitive colliders and even Mesh Colliders in some cases. We should not include such components in our Scenes unless they are absolutely necessary. For instance, if we have terrain objects in the distance that the player will never approach, there's little reason to include an attached <kbd>TerrainCollider</kbd> component.</p>
<p>Games featuring <kbd>Cloth</kbd> components should consider instantiating different objects without them when running in lower-quality settings or simply animating cloth behavior (although it is totally understandable if the team has grown attached to and fallen in love with how the stuff moves around).</p>
<p>Games using <kbd>WheelCollider</kbd> components should simply try to use fewer Wheel Colliders. Large vehicles, with more than four wheels, may be able to simulate similar behavior using only four wheels, while faking the graphical representation of additional wheels.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Letting physics objects sleep</h1>
                
            
            
                
<p>The physics engine's sleep feature can pose several problems for our game. Firstly, some developers don't realize that many of their Rigidbodies are sleeping during most of the lifetime of their application. This tends to lead developers to assume that they can get away with (for example) doubling the number of Rigidbodies in their game, and the overall costs would simply double to match it. This is unlikely. The frequency of collisions and the total accumulated time of active objects is more likely to increase in an exponential fashion rather than a linear one. This leads to unexpected performance costs every time new physics objects are introduced into the simulation. We should keep this in mind when we decide to increase the physical complexity of our scenes.</p>
<p>Secondly, changing any properties on a <kbd>Rigidbody</kbd> component at runtime, such as mass, drag, and useGravity, will also reawaken an object. If we're regularly changing these values (such as a game where object sizes and masses change over time), then they will remain active for more extended periods than usual. This is also the case for applying forces, so if we're using a custom gravity solution (such as suggested in the mass section), we should try to avoid applying the gravitational force every fixed update; otherwise, the object will be unable to fall asleep. We could check its mass-normalized kinetic energy (just take the value of <kbd>velocity.sqrMagnitude</kbd>) and manually disable our custom gravity when we detect that it is very low.</p>
<p>Thirdly, there is the danger of islands of sleeping physics objects being generated. Islands are created when a large number of Rigidbodies are touching one another and have gradually gone to sleep once the kinetic energy of the system has fallen low enough. However, because they're all still touching one another, as soon as one of these objects is awoken, it will start a chain reaction, awakening all other nearby Rigidbodies. Suddenly, we have a large spike in CPU usage because dozens of objects have re-entered the simulation. Even worse, because the objects are so close together, there will be many potential collision pairs that must keep being resolved until the objects fall asleep again.</p>
<p>Avoiding these situations is best done by reducing the complexity of our scenes, but if we find ourselves unable to do so, we could look for ways to detect that islands are forming, and then strategically destroy/despawn some of them to prevent too many large islands from being generated. However, performing regular distance comparisons between all of our Rigidbodies is not a cheap task to accomplish and could be costly. The physics engine already performs such checks itself, during Broadphase culling, but, unfortunately, Unity doesn't expose this data through the physics engine API. Any workarounds for this problem will be dependent on how the game is designed; for example, a game that requires the player to move lots of physics objects into an area (for example, a game that involves herding sheep into a pen) could choose to remove the sheep's collider as soon as the player moves it into position, locking the object to its final destination, easing the workload on the physics engine and preventing islands from becoming a problem.</p>
<p>Sleeping objects can be a blessing and a curse. They can save us a lot of processing power, but if too many of them reawaken at the same time or our simulation is too busy to allow enough of them to fall asleep, then we could be incurring some unfortunate performance costs during gameplay. We should strive to limit these situations as much as possible by letting our objects enter the sleeping state as much as possible and avoiding grouping them in large clusters.</p>
<p>Note that the sleep threshold can be modified under Edit | Project Settings | Physics | Sleep Threshold.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Modifying the solver iteration count</h1>
                
            
            
                
<p>Using joints, springs, and other ways to connect Rigidbodies are fairly complex simulations in physics engines. Owing to the codependent interactivity (internally represented as movement constraints) that occurs due to joining two objects together, the system must often make several attempts at solving the necessary mathematical equations. This multi-iteration approach is required to calculate an accurate result whenever there is a change in velocity to any single part of the object chain.</p>
<p>It, therefore, becomes a balancing act of limiting the maximum number of attempts the solver makes to resolve a particular situation versus how accurate a result we can get away with. We don't want the solver to spend too much time on a single collision because there are a lot of other tasks that the physics engine has to complete within the same iteration. However, we also don't want to reduce the maximum number of iterations too far, as it will only approximate what the final solution would have been, making its motion look much less believable than if it had been given more time to calculate the result.</p>
<p>The same solver also gets involved when resolving inter-object collisions and contacts. It can almost always determine the correct result for simple collisions with a single iteration, except for some very rare and complex collision situations with Mesh Colliders. It is mostly when attached objects will be affected through joints that the solver requires additional effort to integrate the final result.</p>
<p>The maximum number of iterations the solver is allowed to attempt is called the <strong>solver iteration count</strong>, which can be modified under Edit | Project Settings | Physics | Default Solver Iterations. In most cases, the default value of six iterations is perfectly acceptable. However, games that include very complex joint systems may wish to increase this count to suppress any erratic (or downright explosive) <kbd>CharacterJoint</kbd> behaviors, whereas some projects may be able to get away with reducing this count. Testing must be performed after changing this value to check whether the project still maintains the intended levels of quality. Note that this value is the default solver iteration count—the value that gets applied to any newly created Rigidbodies. We can change this value at runtime through the <kbd>Physics.defaultSolverIterations</kbd> property, but this still won't affect preexisting Rigidbodies. If necessary, we can modify their solver iteration count after they are constructed through the <kbd>Rigidbody.solverIterations</kbd> property.</p>
<p>If we find our game regularly runs into jarring, erratic, and physics-breaking situations with complex joint-based objects (such as ragdolls), then we should consider gradually increasing the solver iteration count until the problems are suppressed. These problems typically occur if our ragdolls absorb too much energy from colliding objects, and the solver is unable to iterate the solution down to something reasonable before it is asked to give up. At this point, one of the joints goes supernova, dragging the rest of them into orbit along with it. Unity has a separate setting for this problem, which can be found under Edit | Project Settings | Physics | Default Solver Velocity Iterations. Increasing this value will give the solver more opportunity to calculate a sensible velocity during joint-based object collisions and help to avoid the above scenario. Again, this is a default value; hence, it is only applied to newly created Rigidbodies. The value can be modified at runtime through the <kbd>Physics.defaultSolverVelocityIterations</kbd> property and can be customized on specific Rigidbodies through the <kbd>Rigidbody.solverVelocityIterations</kbd> property.</p>
<p>In either case, increasing the number of iterations will consume more CPU resources during every fixed update where the joint objects remain active.</p>
<p>Note that the Physics 2D settings for solver iterations are named Position Iterations and Velocity Iterations.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Optimizing ragdolls</h1>
                
            
            
                
<p>Speaking of joint-based objects, ragdolls are incredibly popular features for a good reason; they're tons of fun! Ignoring the morbidity of flinging corpses around a game world for the moment, there's something about watching a complex chain of objects flail around and smash into things that hits a lot of fun psychological buttons. This makes it very tempting to allow many ragdolls to coexist within our scene at the same time, but as we quickly discover, this risks an enormous performance hit when too many ragdolls are in motion and/or collide with other objects due to the amount of iterations the solver would need to resolve them all. So, let's explore some ways to improve the performance of ragdolls.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Reducing joints and colliders</h1>
                
            
            
                
<p>Unity provides a simple ragdoll-generation tool (the Ragdoll Wizard) under GameObject | 3D Object | Ragdoll…. This tool can be used to create ragdolls from a given object by selecting the appropriate child GameObjects to attach <kbd>Joint</kbd> and <kbd>Collider</kbd> components for any given body part or limb. This tool always creates 13 different colliders and associated joints (pelvis, chest, head, two colliders per arm, and three colliders per leg).</p>
<p>Note that a bug causes the Ragdoll Wizard not to complain if nothing is assigned to Left Foot or Right Foot <kbd>transform</kbd> component references as it does for the rest of them, but Unity will throw <kbd>NullReferenceException</kbd> if we try to create the mesh without them assigned. Ensure that all 13 <kbd>transform</kbd> component references have been assigned when we try to create a ragdoll.</p>
<p>However, it's possible to use only seven colliders (pelvis, chest, head, and one collider per limb) to greatly reduce the overhead cost at the expense of ragdoll realism. This can be achieved by deleting unwanted colliders and manually reassigning the character joint's <kbd>connectedBody</kbd> properties to the proper parent joints (connect the arm colliders to the chest, and connect the leg colliders to the pelvis).</p>
<p>Note that we assign a mass value during ragdoll creation using the Ragdoll Wizard. This mass value is spread across the various joints as appropriate and, therefore, represents the total mass of the object. We should ensure that we don't apply a mass value too high or too low compared to other objects in our game to avoid potential instability.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Avoiding inter-ragdoll collisions</h1>
                
            
            
                
<p>The performance cost of ragdolls grows exponentially when they are allowed to collide with other ragdolls. In fact, any joint collision requires the solver to calculate the resultant velocity applied to all of the joints connected to it, and then each of the joints connected to the other ragdoll. That means, in practice, that both ragdolls must be resolved entirely multiple times. Moreover, it gets significantly more complicated if various parts of the ragdolls are likely to collide with one another during the same collision.</p>
<p>This is a tough task for the solver to handle, so we should avoid it. The best way to do this is to use the Collision Matrix. It is wise to assign all ragdolls to their own Layer and uncheck the corresponding checkbox in the Collision Matrix so that objects in the given Layer cannot collide with objects in the same Layer.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Replacing, deactivating, or removing inactive ragdolls</h1>
                
            
            
                
<p>In some games, once a ragdoll has reached its final destination, we no longer need it to remain in the game world as an interactable object. We could then either deactivate, destroy, or replace the ragdoll with a more straightforward alternative when they are no longer needed (a good trick is to replace them with the simpler version that uses only seven joints as suggested earlier). Such simplifications are often implemented as a means of reducing overhead for weaker hardware/lower quality settings or as a compromise to allow more ragdolls to coexist in our scene. It could even be used dynamically if a particular number of ragdolls is already present.</p>
<p>We would need some object to keep track of all of our ragdolls, being notified any time a ragdoll is created, keeping track of how many ragdolls currently exist, watching each of them until they fall asleep through <kbd>RigidBody.IsSleeping()</kbd> and then do something appropriate with them. The same object could also choose to instantiate simpler ragdoll variations if the scene already contains more ragdolls than is reasonable. This would be another good opportunity to make use of the messaging system we explored in <a href="">Chapter 2</a>, <em>Scripting Strategies</em>.</p>
<p>Whichever approach we choose to improve the performance of our ragdolls will no doubt result in limiting ragdolls as a gameplay feature, either by instantiating fewer of them, giving them less complexity, or giving them a shorter lifetime, but these are reasonable compromises to make given the performance-saving opportunities.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Knowing when to use physics</h1>
                
            
            
                
<p>The most obvious method to improve the performance of a feature is to avoid using it as much as possible. For all movable objects in our game, we should take a moment to ask ourselves if getting the physics engine involved is even necessary. If not, we should look for opportunities to replace them with something simpler and less costly.</p>
<p>Perhaps we're using physics to detect whether the player fell into a kill-zone (water, lava, a death-plummet, and so on), but our game is simple enough that we only have kill-zones at a specific height. In this case, we could avoid physics colliders altogether and get away with only checking whether the player's <em>y</em>-position falls below a particular value.</p>
<p>Consider the following example—we're trying to simulate a meteor shower, and our first instinct was to have many falling objects that move via physics Rigidbodies, detect collisions with the ground via colliders, and then generate an explosion at the point of impact. However, perhaps the ground is consistently flat, or we have access to the Terrain's heightmap for some rudimentary collision detection. In this case, object travel could be simplified by manually tweening the objects' <kbd>transform.position</kbd> over time to simulate the same traveling behavior without requiring any physics components. In both cases, we can reduce the physics overhead by simplifying the situation and pushing the work into the script code.</p>
<div><strong>Tweening</strong> is a common shorthand term for in-betweening, which is the act of interpolating variables from one value to another gradually over time. There are many useful (and free) tweening libraries available on the Unity Asset Store that can provide a lot of useful functionality. Although, be careful of potentially poor optimization in these libraries.</div>
<p>The reverse is also possible. There might be occasions where we're performing a great deal of calculation through script code that could be handled through physics relatively simply. For example, we might have implemented an inventory system with many objects that can be picked up. When the player hits the pick up Object key, each of these objects might be compared against the player's position to figure out which object is the closest.</p>
<p>We could consider replacing all of the script code with a single <kbd>Physics.OverlapSphere()</kbd> call to get nearby objects when the key is pressed, and then figure out the closest pickup object from the result (or, better yet, just automatically pick up all of them. Why make the player repeatedly click more than necessary?). This could greatly reduce the total number of objects that must be compared each time the key is pressed although comparisons should be made to ensure that this is the case.</p>
<p>Ensure that you seek to remove unnecessary physics grunt work from your scenes or use physics to replace behavior that is costly when performed through script code. The opportunities are as wide and far-reaching as your own ingenuity. The ability to recognize opportunities like this takes experience but is a vital skill that will serve you well when saving performance in current and future game development projects.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>We've covered numerous methods to improve our game's physics simulation both in terms of performance and consistency. The best technique when it comes to costly systems such as physics engines is simply avoidance. The less we need to use the system, the less we need to worry about it generating bottlenecks. In the worst-case scenario, we may need to reduce the scope of our game to condense physics activity down to only the essentials, but as we've learned, there are plenty of ways to reduce physics complexity without causing any noticeable gameplay effects.</p>
<p>In the next chapter, we will immerse ourselves in Unity's Rendering Pipeline and discover how to maximize the graphical fidelity of our application, by making use of all of the CPU cycles we've freed up using the performance enhancements from earlier chapters.</p>


            

            
        
    </body></html>