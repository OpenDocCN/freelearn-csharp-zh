<html><head></head><body>
<div><h1 class="chapter-number" id="_idParaDest-130"><a id="_idTextAnchor024"/>7</h1>
<h1 id="_idParaDest-131">Adding Sound and Visual Effects</h1>
<p>Creating immersive XR experiences requires more than just importing 3D assets and scripting interactivity. For a truly natural and captivating experience, we need to integrate sound and visual effects. Imagine an AR monster hunt game. You’ve built the logic, but without sound and visual effects, the blend of real world and virtual reality feels off. Adding subtle monster sounds can provide direction and distance clues. Integrating a particle effect such as gray fog can enhance the spooky, mysterious atmosphere. By stimulating multiple senses and adapting these elements to a user’s movements, we can significantly enhance the overall immersion and user experience of the AR monster hunt game.</p>
<p>This chapter aims to enhance your XR design skills, targeting more user senses for natural, immersive experiences. We’ll delve into sound theory and particle behavior basics, making these physics concepts accessible to all. We will delve into Unity’s audio and particle systems to understand how they can help us recreate real-world phenomena. In line with our hands-on approach, you’ll apply these concepts in a practical VR project in Unity, creating your most immersive VR experience yet.</p>
<p>Let’s dive into this thrilling exploration of creating realistic XR experiences! This chapter guides you on your way through these four sections:</p>
<ul>
<li>Understanding sound theory and Unity’s audio system</li>
<li>Preparing the VR drum scene and adding sound effects</li>
<li>Understanding particle behavior and Unity’s particle system</li>
<li>Adding particles to VR scenes with varying properties</li>
</ul>
<h1 id="_idParaDest-132">Technical requirements</h1>
<p>To fully engage with and benefit from the VR application development process outlined in this chapter, your hardware must meet certain technical specifications. If you followed the tutorial in <a href="B20869_03.xhtml#_idTextAnchor009"><em class="italic">Chapter 3</em></a> and your Unity setup remains the same, you can bypass this section.</p>
<p>To follow along with this book’s content and examples, ensure your computer system can accommodate <em class="italic">Unity 2021.3 LTS</em> or a more recent edition, with <em class="italic">Android</em> or <em class="italic">Windows/Mac/Linux Build Support</em>, depending on the nature of your VR headset and PC.</p>
<h1 id="_idParaDest-133">Understanding sound theory and Unity’s audio system</h1>
<p>In the subsequent sections, we will delve into the fascinating physics of sound waves and explore how Unity’s robust audio system<a id="_idIndexMarker535"/> allows us to manipulate these properties with its diverse range of audio components. Our journey begins with an introduction to the fundamentals of sound, the nature of sound itself, and its defining features – frequency and amplitude.</p>
<h2 id="_idParaDest-134">What are frequency and amplitude?</h2>
<p>Sound, in essence, is a<a id="_idIndexMarker536"/> form of mechanical energy that propagates as a wave through a medium – most commonly, air. Simply put, mechanical energy is energy associated with the motion of objects. When an object vibrates, it displaces the surrounding air particles, setting off a chain reaction of particle displacement that travels outward in the form of a sound wave.</p>
<p>The two main parameters describing a sound wave are frequency and amplitude.</p>
<p><strong class="bold">Frequency</strong> is the <a id="_idIndexMarker537"/>number of complete wave cycles per second, measured<a id="_idIndexMarker538"/> in <strong class="bold">Hertz</strong> (<strong class="bold">Hz</strong>). It determines the pitch of the sound – a higher frequency corresponds to a higher pitch, and a lower frequency corresponds to a lower pitch. In game development, understanding frequency is crucial. For instance, a small, light creature such as a bird would have a high-pitched (high-frequency) chirp, while a large creature such as an elephant would have a low-pitched (low-frequency) roar.</p>
<p><strong class="bold">Amplitude</strong> refers <a id="_idIndexMarker539"/>to the maximum displacement of particles by the sound wave. In simpler terms, it’s how far the particles are pushed when the wave passes through. It corresponds to the loudness of the sound – a larger amplitude means a louder sound, and a smaller amplitude means a quieter sound. In games and XR applications, amplitude can be used to create a sense of distance. A sound source far from the player would have a smaller amplitude and thus sound quieter, while a source close to the player would sound louder.</p>
<h2 id="_idParaDest-135">Understanding other properties of sound</h2>
<p>While frequency and amplitude are fundamental, several other properties can add depth to the sound experience in XR. These include timbre (pronounced <em class="italic">tamber</em>), envelope, spatial audio, reverberation, and echo. Let’s go through them step by step:</p>
<ul>
<li><strong class="bold">Timbre</strong>: This <a id="_idIndexMarker540"/>describes the color or quality of a sound and allows us to distinguish between different sound sources that may have the same pitch and loudness. Here, <em class="italic">color</em> refers to the unique characteristics and tonal nuances of a sound that differentiate it from other sounds. It’s what allows us to tell the difference between a violin and a flute, even if they’re playing the same note at the same volume. In game development, timbre<a id="_idIndexMarker541"/> can be used to give different characters or environments their unique sound signatures.</li>
<li><strong class="bold">Envelope</strong>: The envelope<a id="_idIndexMarker542"/> of a sound refers to how it evolves over time. It’s traditionally<a id="_idIndexMarker543"/> broken down into four parts – <strong class="bold">Attack, Decay, Sustain, and Release</strong> (<strong class="bold">ADSR</strong>). ADSR<a id="_idIndexMarker544"/> describes the initial spike of a sound (attack), the subsequent decrease to a stable level (decay), the maintenance of that level for a duration (sustain), and the eventual fading away of the sound (release). In XR, modifying the ADSR envelope can make sounds seem more realistic or can be used creatively to give sounds a stylized feel.</li>
<li><strong class="bold">Spatial audio</strong>: This <a id="_idIndexMarker545"/>refers to the perception of the direction and distance of a sound source. Our brains use<a id="_idIndexMarker546"/> several cues to pinpoint the location of a sound source, such as the time difference between the sound reaching our two ears (binaural cues), the change in frequency caused by the shape of our ears (spectral cues), and the change in sound as we move our heads (dynamic cues). Game and XR developers can simulate these effects to create immersive 3D soundscapes, where players can locate a sound source within the game environment. For instance, in a VR horror game, you could use spatial audio to make it sound like eerie whispers are coming from just over the player’s shoulder, or like the ominous footsteps of a monster are getting closer and closer. These techniques can significantly enhance immersion and even gameplay, as players could use sound to navigate their environment or detect threats.</li>
<li><strong class="bold">Reverberation</strong> or <strong class="bold">reverb</strong>: This is the <a id="_idIndexMarker547"/>persistence of sound in a particular space after the original sound is removed. It’s caused by sound waves reflecting off surfaces in the<a id="_idIndexMarker548"/> environment, such as walls and floors, creating a multitude of echoes that gradually fade out. This can give players a sense of the size and material of the space they’re in – a large, stone-walled cathedral would have a long, bright reverb, while a small, carpeted room would have a short, dull reverb.</li>
<li><strong class="bold">Echo</strong>: This is the <a id="_idIndexMarker549"/>distinct, delayed reflection of sound that can be clearly identified as a <a id="_idIndexMarker550"/>repetition of the original source. It’s caused when sound waves bounce off distant obstacles and return to the listener after a noticeable time gap. The time it takes for the reflection to return can give listeners an impression of the distance to the reflecting surface – a mountain range would produce a long-delayed echo, while a closer building might yield a quicker, more immediate echo. Different surfaces can also affect the tonal quality of the echo, with hard surfaces such as concrete producing clearer echoes compared to softer surfaces such as dense foliage.</li>
</ul>
<p>Understanding and manipulating these aspects of sound can allow you to create rich, immersive, and interactive soundscapes in your XR applications. With careful design, sound can be not only an accompaniment to the visual experience but also a key element of gameplay and immersion. The following section introduces you to Unity’s audio system, which we will use throughout this chapter to breathe even more life and immersion into our XR experiences.</p>
<h2 id="_idParaDest-136">Exploring Unity’s audio system</h2>
<p>Sound design is an essential part of creating immersive XR experiences. With Unity’s audio system, you can create dynamic, spatialized audio that reacts to the player’s actions and movements, enhancing immersion and even guiding gameplay.</p>
<p>For instance, in a VR horror game, you could use spatialized sound to create an ominous atmosphere and build tension. Distant, eerie noises could hint at unseen dangers, while sudden, nearby sounds could provide jump scares. As the player navigates the environment, the sounds change based on their position and orientation, making the virtual world feel alive and reactive.</p>
<p>Understanding and effectively using Unity’s audio system<a id="_idIndexMarker551"/> is a crucial skill for any XR developer. Sound isn’t just an accessory to the visuals; it’s also a powerful tool for storytelling, player guidance, and world-building.</p>
<p>Let’s now take a more detailed look at the three core components of Unity’s audio system – AudioClips, AudioSources, and AudioListeners.</p>
<ul>
<li><code>AudioClip</code> represents<a id="_idIndexMarker552"/> a sound file that can be played back in your application. It holds the data for the sound, but on its own, it can’t actually produce sound. Think of an <code>AudioClip</code> file like a CD – it holds music, but you need a CD player to actually hear the music. <code>AudioClip</code> files are versatile – you can use them for short sound effects, such as a character’s footsteps, or for longer pieces of audio, such as background music or dialogue. Unity supports a range of audio file formats, including <code>.wav</code>, <code>.mp3</code>, and <code>.ogg</code>. When designing sound for XR, remember that audio quality is important for immersion. High-quality <code>AudioClip</code> files can make a virtual environment feel more real.</li>
<li><code>AudioSource</code> is like a CD player for your <code>AudioClip</code> file. It’s a component that can be attached<a id="_idIndexMarker553"/> to a GameObject to play sounds. You can think of it as a point in your 3D space where sound originates. Every sound you hear in a Unity application originates from an <code>AudioSource</code> component. An <code>AudioSource</code> component plays back an <code>AudioClip</code> file in the scene and controls how that sound is played. The <code>AudioSource</code> component offers several properties that you can manipulate:<ul><li><code>AudioClip</code> file that will be played.</li><li><code>AudioSource</code> component will start playing its <code>AudioClip</code> file as soon as the scene starts.</li><li><code>AudioSource</code> component will loop its <code>AudioClip</code> file, starting it again as soon as it ends.</li><li><code>AudioSource</code> component, and can be used to fade sounds in or out.</li><li><code>AudioSource</code>. Higher values result in a higher pitch, and lower values result in a lower pitch. This can be used to create a <strong class="bold">Doppler effect</strong>, which<a id="_idIndexMarker559"/> is a change in the frequency or wavelength of a wave for an observer moving relative to its source – for instance, the sound of a passing car changing from high to low pitch.</li><li><strong class="bold">3D Sound Settings</strong>: These<a id="_idIndexMarker560"/> settings control how the sound is affected by distance. You can make the sound get quieter with distance, change the pitch with distance, and so on. This is critical for XR applications, as it helps to create a sense of space and realism.</li></ul></li>
<li><code>AudioSource</code> components in the scene and processes them to create the final mixed sound that the player will hear. In most games and XR applications, the <code>AudioListener</code> is attached to the main camera or the player’s avatar. As the player moves through the environment, different sounds will get louder or quieter based on their distance and direction from the <code>AudioListener</code>, creating a dynamic soundscape.</li>
</ul>
<p class="callout-heading">Important note</p>
<p class="callout">It’s important to note that you should generally only have one <code>AudioListener</code> in your scene. Having more than one can cause sounds to be duplicated, which can result in distortion and other audio artifacts.</p>
<p>The following sections guide you on how to implement these components into your Unity scene through a new, hands-on VR project.</p>
<h1 id="_idParaDest-137">Preparing the VR drum scene and adding sound effects</h1>
<p>After exploring the <a id="_idIndexMarker562"/>physical properties of sound waves and Unity’s audio system, you will finally put this theoretical knowledge into use by building your own VR drum scene.</p>
<p>Once you’ve created a VR scene featuring various drums, which can be struck by a player equipped with VR drumsticks in each hand, you’ll discover how to augment your setup by assigning distinct sound files to each drum that gets hit. Moreover, you’ll learn how to adjust the sound volume based on the intensity of the strike delivered by the VR drumsticks, adding an extra layer of realism. This refined VR drumming environment will plunge users into an impressively accurate and engaging drumming experience. Let us now set up and prepare our VR drum scene.</p>
<h2 id="_idParaDest-138">Setting up and preparing your VR drum scene</h2>
<p>The following steps guide you on <a id="_idIndexMarker563"/>how to create your project, set up the needed<a id="_idIndexMarker564"/> VR settings in the Unity Editor, and add a player with a ground floor:</p>
<ol>
<li>Create a new project with the URP by selecting <code>Drum Scene</code>.</li>
<li>Once the scene has loaded, navigate to <strong class="bold">Edit</strong> | <strong class="bold">Project Settings</strong> | <strong class="bold">XR Plugin</strong> <strong class="bold">Management</strong> and click the <strong class="bold">Install</strong> button. After the installation, enable the <strong class="bold">OpenXR</strong> checkbox. If you are prompted to restart the Editor, follow the instructions to do so.</li>
<li>Under <strong class="bold">Edit</strong> | <strong class="bold">Project Settings</strong> | <strong class="bold">XR Plugin Management</strong>, go to the <strong class="bold">OpenXR</strong> submenu. Under the <strong class="bold">Windows/Linux/Mac</strong> tab, select the interaction profile that matches your headset.</li>
<li>To add the required<a id="_idIndexMarker565"/> prefabs for our VR player to our scene, we need<a id="_idIndexMarker566"/> to install the XR Interaction Toolkit. To do so, go to <code>com.unity.xr.interaction.toolkit</code> and <code>2.5.1</code>, and then click the <strong class="bold">Add</strong> button. This will automatically install the XR Interaction Toolkit into your scene. Once the installation process is finished, select <strong class="bold">XR Interaction Toolkit</strong> in the <strong class="bold">Package Manager</strong> window, and click the <strong class="bold">Import</strong> buttons next to <strong class="bold">Starter Assets</strong> and <strong class="bold">XR Device Simulator</strong>, as shown in <em class="italic">Figure 7</em><em class="italic">.1</em>.</li>
</ol>
<div><div><img alt="Figure 7.1 – The XR Interaction Toolkit successfully installed alongside the imported Starter Assets and XR Device Simulator in the Package Manager window" src="img/B20869_07_01.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – The XR Interaction Toolkit successfully installed alongside the imported Starter Assets and XR Device Simulator in the Package Manager window</p>
<ol>
<li value="5">Delete the existing main camera in the hierarchy, as the VR player we will add comes with a point-of-view camera. Now, navigate to the <code>Assets</code> folder in the <code>floor</code>, and place it at the origin (<code>0</code>, <code>0</code>, <code>0</code>).</li>
</ol>
<p>Hurray! You’ve set up the framework for a VR-enabled drum scene in Unity! The subsequent section will guide you through the process of adding the drums and drumsticks to your scene.</p>
<h2 id="_idParaDest-139">Creating and importing 3D models for your VR drum scene</h2>
<p>Although<a id="_idIndexMarker569"/> Unity Asset Store provides an extensive <a id="_idIndexMarker570"/>collection of different 3D models, it doesn’t offer free drum models that are suitable for our project. Therefore, we’ll utilize 3D models available on <em class="italic">Sketchfab</em>, another rich platform that allows you to download free and paid 3D models from a wide range of creators.</p>
<p>The selected drum models for this chapter were found at <a href="https://skfb.ly/o8QvS">https://skfb.ly/o8QvS</a> and were created by Bora Özakaltun. Open the link and download the free models in the <code>.fbx</code> file format, as shown in <em class="italic">Figure 7</em><em class="italic">.2</em>.</p>
<div><div><img alt="Figure 7.2 – ﻿The required mouse clicks (highlighted in yellow) to download the drum models as a﻿n .fbx file" src="img/B20869_07_02.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – The required mouse clicks (highlighted in yellow) to download the drum models as an .fbx file</p>
<p class="callout-heading">Important note</p>
<p class="callout">Should the models be unavailable at your time of reading, you can clone the entire project from the GitHub repository for this book and extract the assets from there.</p>
<p>Once the<a id="_idIndexMarker571"/> folder is downloaded, unzip all the child folders. Then, drag <a id="_idIndexMarker572"/>the unzipped drum folder into your <strong class="bold">Project</strong> window, completing the model importation. Now, it’s time to integrate the drums into your virtual environment. Follow these steps to position the drums in your scene:</p>
<ol>
<li>In the <code>Assets</code> folder, and then to <code>drum</code> | <code>source directory</code>. Here, you will find the drum model that you previously imported.</li>
<li>Select the <strong class="bold">drum</strong> file and drag it into your scene. Upon doing so, you might observe that the drum appears disproportionately large for the environment.</li>
<li>To rectify the size issue, select the drum in the hierarchy and scale it down to the dimensions (<code>0.02</code>, <code>0.02</code>, <code>0.02</code>). Place the drum at the origin coordinates (<code>0</code>, <code>0</code>, <code>0</code>), aligning it perfectly within the virtual space.</li>
</ol>
<p>Once these adjustments are complete, your scene should resemble the depiction in <em class="italic">Figure 7</em><em class="italic">.3</em>.</p>
<div><div><img alt="Figure 7.3 – ﻿How your drum scene should currently look in the Game ﻿view of the Unity Editor" src="img/B20869_07_03.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – How your drum scene should currently look in the Game view of the Unity Editor</p>
<p>Now, we need <a id="_idIndexMarker573"/>drumsticks to interact with the drums. By<a id="_idIndexMarker574"/> following these steps, we will create our own drumsticks within Unity:</p>
<ol>
<li>Right-click in the Scene Hierarchy, navigate to <code>0.01</code>, <code>0.2</code>, <code>0.01</code>). Rename this GameObject <code>Drum Stick</code>.</li>
<li>As you can see in the <strong class="bold">Inspector</strong> window, the drumstick automatically includes a <strong class="bold">Capsule Collider</strong> component. A <strong class="bold">Capsule Collider</strong> is a 3D shape used in Unity that resembles a capsule or pill-like<a id="_idIndexMarker575"/> shape, used to detect collisions between objects. Additionally, it is essential to add a <strong class="bold">Rigidbody</strong> component to the drumstick. This allows the object to be affected by forces and physics within the Unity environment, enabling dynamic interactions such as the ones needed for an immersive drumming experience. With the drumstick selected, head over to its <strong class="bold">Inspector</strong> window and select the <strong class="bold">Add Component</strong> button. Now, add a <strong class="bold">Rigidbody</strong> component by searching for it and selecting it. This component allows Unity’s physics engine to treat the drumstick as a physical object, simulating interactions and reactions to forces, which is critical to realistically model the drumstick’s behavior when striking a drum.</li>
<li>Set <strong class="bold">Collision Detection</strong> of the <strong class="bold">Rigidbody</strong> component to <strong class="bold">Continuous Speculative</strong>. This mode enables more accurate and efficient handling of collisions between the drumstick and other objects, particularly when dealing with fast motions typical of drumming.</li>
<li>Create a<a id="_idIndexMarker576"/> new material in the <code>Assets</code> folder, and<a id="_idIndexMarker577"/> name it <code>Drum Stick Material</code>. Download <code>Balsa_Wood_Texture.jpg</code> from <a href="https://commons.wikimedia.org/wiki/File:Balsa_Wood_Texture.jpg">https://commons.wikimedia.org/wiki/File:Balsa_Wood_Texture.jpg</a> and import it into the project. Select <code>Drum Stick Material</code>, go to <code>Balsa_Wood_Texture.jpg</code> into the <strong class="bold">Base Map</strong> field. Apply this material to the drumstick.</li>
<li>Select <code>Drum Stick</code>, and click on the <code>Drum</code>, and save the tag. We will need this tag to address the drumsticks in our scene later on.</li>
<li>In the <code>Prefabs</code>, and drag the drumstick into it. This will create a prefab, allowing easy duplication and modification.</li>
<li>Finally, attach the prefab as a child to both the left controller and the right controller, as detailed in <em class="italic">Figure 7</em><em class="italic">.4</em>.</li>
</ol>
<div><div><img alt="Figure 7.4 – ﻿Each drumstick being successfully attached to the respective controller of the XR Origin in the Scene Hierarchy window" src="img/B20869_07_04.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – Each drumstick being successfully attached to the respective controller of the XR Origin in the Scene Hierarchy window</p>
<p>You have<a id="_idIndexMarker578"/> successfully completed all the steps to set up and <a id="_idIndexMarker579"/>prepare your VR drum scene. In the following section, you will learn how you can utilize Unity’s audio system to add sound effects to your scene.</p>
<h2 id="_idParaDest-140">Adding sound effects to your VR drum scene</h2>
<p>This section <a id="_idIndexMarker580"/>guides you through <a id="_idIndexMarker581"/>the process of adding sound effects to your VR drum scene. The first step involves triggering audio when hitting an instrument, adding realism and engagement to the scene.</p>
<h3>Scripting sound playback on collision for your VR drum scene</h3>
<p>To trigger a sound <a id="_idIndexMarker582"/>playback once our drumsticks collide with the drums, we must use C# scripting. Follow these steps to correctly prepare your drums for it:</p>
<ol>
<li>In the Unity Editor, press <em class="italic">Ctrl</em> / <em class="italic">Cmd</em> on your keyboard, and <em class="italic">left-click</em> to select all the drums in your Scene Hierarchy.</li>
<li>With the drums selected, add a <strong class="bold">Box Collider</strong> component via the <strong class="bold">Inspector</strong> window by clicking the <strong class="bold">Add Component</strong> button and searching for and selecting the <strong class="bold">Box </strong><strong class="bold">Collider</strong> component.</li>
<li>Then, we must ensure that the collider functions as a trigger, allowing it to initiate actions rather than physical interactions. To do this, select the <strong class="bold">Is Trigger</strong> checkbox in the <strong class="bold">Box Collider</strong> component of each drum in the <strong class="bold">Inspector</strong> window. This option transforms the collider into a non-physical boundary that can detect when objects pass through, making it instrumental in triggering sound upon collision.</li>
<li>Select all the<a id="_idIndexMarker583"/> drums in the Scene Hierarchy, and click on the <code>PlaySoundOnCollision</code>, and click on <strong class="bold">New Script</strong>. This action automatically associates the script with all selected drums.</li>
<li><em class="italic">Double-click</em> on the <code>PlaySoundOnCollision</code> script in the <strong class="bold">Inspector</strong> window to open it.</li>
</ol>
<p>Once the script opens in your preferred IDE, define the following three variables:</p>
<pre class="source-code">
public AudioClip soundClip;
private AudioSource _soundSource;
public string tag;</pre>
<p>We will use the public <code>AudioClip</code> variable to play the audio, the private <code>AudioSource</code> variable to play the clip, and assign a public <code>tag</code> variable to the drumsticks so that only these GameObjects trigger the sound.</p>
<p class="callout-heading">Important note</p>
<pre>tag</strong> variable to trigger sound.</pre>
<p>In the <code>Start()</code> function of the <code>PlaySoundOnCollision</code> script, add the following line of code to access <code>AudioSource</code> at the beginning of the experience:</p>
<pre class="source-code">
_soundSource = GetComponent&lt;AudioSource&gt;();</pre>
<p>Since we are not<a id="_idIndexMarker585"/> continuously checking for changes, we don’t need an <code>Update()</code> function in this script. Instead, we will implement an <code>OnTriggerEnter()</code> method, which is called when something collides with the trigger collider:</p>
<pre class="source-code">
private void OnTriggerEnter(Collider other) {
    if (other.CompareTag(tag))
    {
        _soundSource.PlayOneShot(soundClip);
    }
}</pre>
<p><code>OnTriggerEnter()</code> is a special Unity method that is automatically called by the Unity engine itself when a collision with a trigger occurs. This is also why we don’t need to call this function within our script and why we selected the <strong class="bold">Is Trigger</strong> checkbox earlier in this setup.</p>
<p>Within the <code>OnTriggerEnter()</code> method, we call <code>CompareTag()</code>, a built-in Unity function from the <code>GameObject</code> class. By calling it inside of an <code>if</code> statement, we compare the tag of the colliding object to a string. The use of a tag helps ensure that the sound is played only when the drumsticks collide with the drum, and not when other objects might collide with it. By assigning a unique tag to the drumsticks, similar to the <code>Drum</code> tag we used, we can easily and efficiently identify them within the <code>OnTriggerEnter()</code> method and play the sound only in response to their collisions with the drum.</p>
<p class="callout-heading">Important note</p>
<p class="callout">At this point, you might be wondering why we are using <code>CompareTag()</code> instead of directly comparing the tags with the equality operator (<code>==</code>). The reason for this is that using <code>CompareTag()</code> is more computationally efficient. Tags in Unity are stored in an internal hashed format, and <code>CompareTag()</code> compares these hashes, while the equality operator would first convert the hash to a string, making the comparison slower.</p>
<p>If the tag comparison returns <code>true</code>, the next line is executed. The <code>_soundSource</code> variable refers to the <code>AudioSource</code> component that we will attach to the drums later on. The <code>PlayOneShot()</code> method is another Unity function from the <code>AudioSource</code><code>AudioSource</code>. This functionality is essential for the authenticity of our drum scene. Instead of hearing each drum hit in isolation, we seek to create a continuous flow of sound. The ability to layer individual hits allows for a more immersive and realistic experience, reflecting the natural overlap that occurs when drums are played in quick succession. The use of the <code>PlayOneShot()</code> method ensures that the sounds meld together harmoniously, capturing the essence of a live drumming performance.</p>
<p>By combining <a id="_idIndexMarker586"/>these elements, the <code>OnTriggerEnter()</code> method ensures that when the drumstick comes into contact with the drum, the specified sound is played, creating an immediate and realistic response within the virtual environment. It’s a powerful way to add immersion and interactivity to your VR experience. After finalizing the <code>PlaySoundOnCollision</code> script, it is finally time to add sound files for each drum to your scene.</p>
<h3>Adding sound files to your VR drum scene</h3>
<p>In this <a id="_idIndexMarker587"/>section, you will learn how to import sound files and<a id="_idIndexMarker588"/> assign <code>AudioSource</code> components for each drum. Let’s go through this process step by step:</p>
<ol>
<li>Download the appropriate sound files for each of the drums in your Unity scene. You can find royalty-free <code>.mp3</code> sound files on websites such as <a href="https://www.freesoundslibrary.com/">https://www.freesoundslibrary.com/</a> or <a href="https://pixabay.com/sound-effects/">https://pixabay.com/sound-effects/</a>. Alternatively, you have the option to utilize the sound files provided within the Unity project linked with this chapter. These files are readily available in this book’s GitHub repository.</li>
<li>Once you have the necessary sound files on your local system, go to <code>Assets</code> | <code>Import New Assets</code> in the Unity Editor. Navigate to the location of your sound files and select the ones you want to import. Click the <strong class="bold">Import</strong> button, and the sound files will now be available in your Unity project.</li>
<li>Select all drums in the <strong class="bold">Hierarchy</strong> window (<em class="italic">Ctrl</em> / <em class="italic">Cmd</em> + <em class="italic">left-click</em>). In the <strong class="bold">Inspector</strong> window, click the <strong class="bold">Add Component</strong> button, search for the <strong class="bold">Audio Source</strong> component, and select it.</li>
<li>Now, select each drum individually in the Scene Hierarchy, and navigate to their<code>PlaySoundOnCollision</code> script in the <strong class="bold">Inspector</strong> window. Click on the small circle next to the <strong class="bold">Sound Clip</strong> field that we defined earlier, and choose an appropriate <a id="_idIndexMarker589"/>sound<a id="_idIndexMarker590"/> file for each drum.</li>
</ol>
<p>Upon testing, you’ll find that the drum scene is already quite immersive. However, a few adjustments can heighten its realism. The following section guides you on how to fine-tune your drum scene.</p>
<h3>Fine-tuning the VR drum scene to heighten its realism</h3>
<p>The current <a id="_idIndexMarker591"/>setup plays the sound at a constant volume, regardless of how hard or soft the drum is hit. To enhance realism, we need to adjust the volume in relation to the collision velocity. To achieve this, we can utilize an existing script from Valve called <em class="italic">VelocityEstimator</em>. In case you aren’t familiar, Valve is the prominent video game developer and distributor behind the Steam gaming platform, and they offer a SteamVR plugin for Unity, along with interesting VR scripts available on GitHub. The <code>VelocityEstimator</code> script is available in the GitHub repository of SteamVR’s Unity Plugin at this link: <a href="https://github.com/ValveSoftware/steamvr_unity_plugin/blob/9442d7d7d447e07aa21c64746633dcb5977bdd1e/Assets/SteamVR/InteractionSystem/Core/Scripts/VelocityEstimator.cs#L13">https://github.com/ValveSoftware/steamvr_unity_plugin/blob/9442d7d7d447e07aa21c64746633dcb5977bdd1e/Assets/SteamVR/InteractionSystem/Core/Scripts/VelocityEstimator.cs#L13</a>.</p>
<p class="callout-heading">Tip</p>
<p class="callout">When dealing with complex physical calculations (such as the relationship between volume and collision), searching the internet for existing solutions or scripts can save time and effort. In XR development, understanding every aspect of physics is not always necessary, but knowing how to implement physical calculations accurately is crucial.</p>
<p>The<a id="_idIndexMarker592"/> purpose of Valve’s <code>VelocityEstimator</code> script is to calculate and estimate the speed and direction of the GameObject we attach it to – in this case, the drumsticks. When applied to our VR drum scene, this script will facilitate the adjustment of the sound volume based on the drumstick’s striking speed, thereby imitating the natural correlation between the force of a drum hit and the resulting sound volume. To add the <code>VelocityEstimator</code> script to our drumsticks, let’s perform the following steps:</p>
<ol>
<li>Download the <code>VelocityEstimator</code> script from GitHub (by selecting <em class="italic">Cmd</em> / <em class="italic">Ctrl</em> + <em class="italic">Shift</em> + <em class="italic">S</em>).</li>
<li>In the <code>Scripts</code> folder, and drag and drop your downloaded file from your local file manager into it.</li>
<li>Now, add the <code>VelocityEstimator</code> script to both drumsticks as a component by clicking the <code>VelocityEstimator</code> script component should look in the <strong class="bold">Inspector</strong> window.</li>
</ol>
<div><div><img alt="Figure 7.5 – ﻿How the drumsticks’ fully configured VelocityEstimator script component should look in the Inspector window" src="img/B20869_07_05.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.5 – How the drumsticks’ fully configured VelocityEstimator script component should look in the Inspector window</p>
<p>To take<a id="_idIndexMarker593"/> advantage of the drumsticks’ speed in our existing <code>PlaySoundOnCollision</code> script, we must modify it a bit. Open the script again in an IDE, such as Visual Studio, and add the following three lines of code to your script:</p>
<pre class="source-code">
public bool enableVelocity = true;
public float minimumVelocity = 0;
public float maximumVelocity = 3;</pre>
<p>The first<a id="_idIndexMarker594"/> variable allows us to decide whether we want to take velocity into account when playing the sound. By setting this to <code>true</code>, we enable the feature. The <code>minimumVelocity</code> variable defines the lower threshold for velocity, allowing us to specify the minimum speed that will impact the volume. Any velocity below this value won’t lead to a decrease in volume. Conversely, the <code>maximumVelocity</code> parameter sets the upper limit of velocity that will influence the volume. Speeds above this threshold won’t result in further increases in volume.</p>
<p>These new parameters grant us control over how the velocity of the drumsticks influences the volume of the sounds produced. By adjusting the minimum and maximum velocity values, we can fine-tune the responsiveness of the drum sounds to create a nuanced and realistic drumming simulation.</p>
<p>Now, we must modify the <code>OnTriggerEnter()</code> method to use the <code>VelocityEstimator</code> script component if the <code>enableVelocity</code> variable is set to <code>true</code> like this:</p>
<pre class="source-code">
    private void OnTriggerEnter(Collider other) {
        if (other.CompareTag(tag))
        {
            VelocityEstimator velEstimator = other.GetComponent&lt;VelocityEstimator&gt;();
            if (velEstimator &amp;&amp; enableVelocity)
            {
                float v = velEstimator.GetVelocityEstimate().magnitude;
                float soundVolume = Mathf.InverseLerp(minimumVelocity, maximumVelocity, v);
                _soundSource<a id="_idTextAnchor025"/>.PlayOneShot(soundClip, soundVolume);
            }
            else
                _soundSource.PlayOneShot(soundClip);
        }
    }</pre>
<p>Let’s go <a id="_idIndexMarker595"/>through the newly added parts of the <code>OnTriggerEnter()</code> method. By calling <code>other.GetComponent&lt;VelocityEstimator&gt;()</code>, we try to get a component of the <code>VelocityEstimator</code> type from the object with the <code>Drum</code> tag. If the <code>VelocityEstimator</code> component is found and the <code>enableVelocity</code> variable is set to <code>true</code>, the code inside the <code>if</code> statement will be executed. In this case, the code first calls the <code>GetVelocityEstimate</code> method from the <code>VelocityEstimator</code> component to get the velocity estimate, and then it takes the magnitude of that vector to get the speed as a single float value. Then, the volume of the sound based on the speed is calculated and stored in the <code>soundVolume</code> variable. The <code>InverseLerp()</code> method returns a value between <code>0</code> and <code>1</code>, representing where the value of <code>v</code> falls between <code>minimumVelocity</code> and <code>maximumVelocity</code>. By calling <code>_soundSource.PlayOneShot(soundClip, soundVolume)</code> on the next line, a one-time sound is played at the calculated volume.</p>
<p>The <code>else</code> statement at the end of <code>OnTriggerEnter()</code> is executed if the previous <code>if</code> statement is not met. The <code>if</code> statement is not met if the <code>VelocityEstimator</code> script component is not found, or if the <code>enableVelocity</code> variable is set to <code>false</code>. The code inside this block will play the sound at its default volume because the velocity of the object was not considered.</p>
<p>If we run the scene right now, we will not hear anything at all when we hit the drumsticks against the drums. This is because, in the original <code>VelocityEstimator</code> script from Valve, the velocity estimation routine was meant to start by calling <code>BeginEstimatingVelocity()</code>. However, in our <code>PlaySoundOnCollision</code> script, this function wasn’t being called at all; hence, no velocity estimation took place. This is why we consistently get a velocity of zero right now when testing out the scene and do not hear anything.</p>
<p>To solve this<a id="_idIndexMarker596"/> problem, we need to ensure that <code>BeginEstimatingVelocity()</code> is called when the script starts. This can be done by adding the following code lines to the <code>Start()</code> method of our <code>VelocityEstimator</code> script:</p>
<pre class="source-code">
private VelocityEstimator velocityEstimator;
{
    private void Start()
    {
        velocityEstimator = GetComponent&lt;VelocityEstimator&gt;();
        if (velocityEstimator != null)
        {
            velocityEstimator.BeginEstimatingVelocity();
        }
    }
}</pre>
<p>By putting the call to <code>BeginEstimatingVelocity()</code> inside the <code>Start()</code> method, we ensure that the velocity estimation begins as soon as the drumstick object is ready, which is exactly what we want.</p>
<p>We’ve successfully executed all necessary steps to add a sound to each drum that reflects the intensity of each hit. Now, it’s time to put on your VR headset and put the final scene <a id="_idIndexMarker597"/>to the test. Pay close attention to the variation in volume for each drum sound, depending on the collision velocity with the drumstick. Also, keenly observe the sound dynamics when you strike two drums simultaneously or hit several drums in rapid succession. You’ll be amazed by how incredibly realistic our VR drum scene has become.</p>
<p>The next sections will teach you yet another valuable skill to make your scenes more natural and immersive – adding particles!</p>
<h1 id="_idParaDest-141">Understanding particle behavior and Unity’s particle system</h1>
<p>When designing immersive XR experiences, understanding the physics of particle behavior plays an important role. By leveraging Unity’s particle system and the fundamentals of particle physics, you can create rich, dynamic, and realistic effects that enhance the immersion of your virtual environments. In this section, you will learn everything you need to know about real-world<a id="_idIndexMarker598"/> particle behavior.</p>
<h2 id="_idParaDest-142">Understanding the behavior of particles in the real world</h2>
<p>Particle behavior in the <a id="_idIndexMarker599"/>physical world refers to the ways in which small fragments or quantities of matter move and interact, based on forces, environmental conditions, and intrinsic properties. Particles in the natural environment behave according to certain laws and principles. Key factors include gravity, air resistance, life span, and collision behavior. Here is an overview of what all these terminologies mean:</p>
<ul>
<li><strong class="bold">Gravitational forces</strong>: Particles<a id="_idIndexMarker600"/> are affected by gravitational forces, which pull them toward the center of mass. However, it’s important to note that not all particles are affected by gravity in the same way. Consider two common particle systems – rain falling from the sky, and sparks rising from a fire. In the case of rain, gravity pulls the raindrops down toward the ground. Conversely, sparks from a fire rise upward because the heat decreases their effective gravitational pull (hot air rises).</li>
<li><strong class="bold">Air resistance</strong>: Air resistance, also known as <strong class="bold">drag</strong>, is the <a id="_idIndexMarker601"/>resistance a particle experiences<a id="_idIndexMarker602"/> when moving through a medium such as air. It affects both the speed and the direction of particles, often resulting in less linear, more natural-looking motion. Smoke from a fire or a chimney provides a good example. While the heat and updraft may initially propel the smoke upward, air resistance and wind can cause it to billow, curve, and sway. Similarly, consider a particle system representing leaves blowing in the wind. Air resistance causes the leaves to flutter and spin, rather than moving directly in the direction of the wind.</li>
<li><strong class="bold">Life span</strong>: Every particle has a <a id="_idIndexMarker603"/>life span, a duration of existence after which it disappears or changes state. This life span, along with changes that happen during it, contributes to the believability of a particle effect. Consider a firefly effect, where each firefly would be a particle that appears, glows brightly for a few seconds (reaching peak brightness midway through its life), and then fades away. A snowflake particle system offers another example. As snowflakes, which are represented by particles in your Unity scene, fall toward the ground, they could fade or shrink to give the illusion of snowflakes melting as they touch the warmer ground.</li>
<li><strong class="bold">Collision behavior</strong>: When<a id="_idIndexMarker604"/> particles come into contact with a surface or another particle, they react in a manner that depends on their nature and the surface they collide with. This is known as collision behavior. Raindrops, for example, splash and disappear upon hitting a hard surface, creating smaller droplet particles. Conversely, confetti pieces bounce and scatter instead of splashing when they hit a surface.</li>
</ul>
<p>Incorporating these principles of particle physics into your Unity Particle System will significantly enhance the realism and immersion of your XR experiences. You will learn about Unity’s Particle System in the following section.</p>
<h2 id="_idParaDest-143">Exploring Unity’s Particle System</h2>
<p>Unity’s Particle System<a id="_idIndexMarker605"/> is a powerful tool for XR developers that adds another level of immersion to the user experience. It is used to create a wide range of special effects such as fire, smoke, sparks, and magic spells, as well as more abstract visual elements. Understanding and utilizing Unity’s Particle System effectively can significantly enhance the visual appeal of your application and deepen the sense of presence within the virtual environment.</p>
<p>The following is a detailed exploration of the core components of Unity’s Particle System – specifically, the Particle System component and the Particle System Renderer component. Both of these components will be vital later on when we add a particle system to our drum scene:</p>
<ul>
<li>The <strong class="bold">Particle System component</strong> is the <a id="_idIndexMarker606"/>main engine of the particle system in Unity. The Particle System component itself is attached to a GameObject and controls how particles are generated and behave over their lifetime. It offers a multitude of modules, each controlling a different aspect of the particle’s behavior:<ul><li><strong class="bold">Emission Module</strong>: This<a id="_idIndexMarker607"/> controls the rate at which new particles are spawned. Whether you need a constant trickle of particles or a sudden burst, this module has you covered.</li><li><strong class="bold">Shape Module</strong>: This <a id="_idIndexMarker608"/>defines the region and the form from which particles are birthed. This could be a simple point, a complex mesh, or anything in between, offering a flexible start to your particles’ life journey.</li><li><strong class="bold">Gravity Modifier</strong>: This<a id="_idIndexMarker609"/> is a setting within the Particle System component that emulates the influence of gravity on particles. You can adjust this setting to make the particles fall faster or slower, allowing you to create effects such as floating dust or rapid rainfall.</li><li><strong class="bold">Velocity over Lifetime Module</strong>: This<a id="_idIndexMarker610"/> dictates how a particle’s speed and direction change over its lifetime. Coupled with the Gravity Modifier, this can create lifelike effects of particles being caught in wind or turbulence.</li><li><strong class="bold">Drag</strong>: Found <a id="_idIndexMarker611"/>under the <strong class="bold">Forces over Lifetime</strong> module, which in Unity’s Particle System allows users to apply varying forces to particles throughout their life span, this property lets you simulate the effect of air or fluid resistance. By modifying the Drag property, you can make particles move as if they are in a heavier medium, providing a sense of weight and depth to the particles.</li><li><strong class="bold">Color over Lifetime Module</strong>: This <a id="_idIndexMarker612"/>specifies how a particle’s color evolves over its life span. This module, in conjunction with the Size over Lifetime module, allows you to create a natural fade-in and fade-out effect, enhancing the realism of particles.</li><li><strong class="bold">Size over Lifetime Module</strong>: This<a id="_idIndexMarker613"/> determines how a particle’s scale changes over its life cycle. By making particles shrink or grow over time, the environment seems to evolve and be dynamic to observers.</li><li><strong class="bold">Collision Module</strong>: This module governs how particles interact with other GameObjects in<a id="_idIndexMarker614"/> the scene upon collision. You can control properties such as bounce (restitution), dampen (loss of speed), and lifetime loss on collision. This can offer a high degree of realism to how particles respond to their environment, such as sparks bouncing off a surface or water droplets splashing.</li></ul><p class="list-inset">To illustrate the application of these principles, consider the example of a simple campfire. In this case, embers rising from the fire can be created as a particle effect where the particles move upward, affected by a slightly randomized velocity to simulate the effect of heat and air resistance. Gravity’s influence would be negative here (pulling particles upward) due to the heat, and particles could have a reddish color at birth, fading to dark as they cool, simulating the life cycle of real embers. The smoke, however, can be created with particles moving upward with a higher randomized velocity, simulating the churning effect of fire. These particles would be less affected by gravity and have a longer life span. They could also use a color gradient, changing from dark gray near the fire to a lighter color as they rise and cool. Lastly, the fire itself can be simulated with a high rate of small, bright particles with short lifetimes and high randomized velocity. The effect would be a vibrant, dynamic flickering fire.</p></li>
<li>The <strong class="bold">Particle System Renderer component</strong> is responsible for rendering the particles on the<a id="_idIndexMarker615"/> screen. This component can be customized to fit the specific visual needs of your application. Some of its properties include the following:<ul><li><strong class="bold">Material</strong>: This defines the<a id="_idIndexMarker616"/> appearance of the particles and can include textures, colors, and shaders</li><li><strong class="bold">Render Mode</strong>: This <a id="_idIndexMarker617"/>determines how the particles are rendered and can be in the form of billboards (always facing the camera), meshes, or other similar entities</li><li><strong class="bold">Sorting Mode</strong>: This <a id="_idIndexMarker618"/>determines the order in which particles are rendered and is especially important when particles overlap</li></ul></li>
</ul>
<p>Remember, particles aren’t just visual fluff. They can play a crucial role in your storytelling, player guidance, and world-building efforts. For instance, a trail of mystical sparkles might guide a player toward a hidden treasure, or a plume of smoke could hint at a recently extinguished campfire nearby.</p>
<p>Now that we’ve explored the key components of Unity’s particle system, let’s dive into the following section, which explains how to implement a particle system into our drum scene. The goal is that every time we hit a drum, fog is released, proportionate to how hard we hit it.</p>
<h1 id="_idParaDest-144">Adding particles to VR scenes with varying properties</h1>
<p>Do you recall the last time you attended a live concert when, at the pinnacle of a legendary song, the stage was enveloped by a blanket of white fog while you were lost in the music with your friends? Taking inspiration from the theatrical smoke often utilized in real-world concerts, we’re going to apply our recently acquired knowledge about Unity’s Particle System to create a similar effect. Our objective is to integrate a particle system into our drum scene to release fog every time a drum is hit, with the intensity of the fog corresponding to the velocity of the strike. The more frequently the drums are played, the more the fog should saturate our scene, and vice versa, thereby fully replicating the euphoric sensation of being at a genuine concert.</p>
<p>To achieve this objective, we need to first initialize a Particle System in our scene.</p>
<h2 id="_idParaDest-145">Initializing a Particle System in your VR drum scene</h2>
<p>Follow these <a id="_idIndexMarker619"/>steps to establish a Particle<a id="_idIndexMarker620"/> System in your VR drum scene:</p>
<ol>
<li>In your Unity scene, <em class="italic">right-click</em> on the <strong class="bold">Hierarchy</strong> window, navigate to <strong class="bold">Effects</strong>, and select <strong class="bold">Particle System</strong>. This will instantiate a new Particle System within your scene.</li>
<li>The existing Particle System employs Unity’s standard particle material, which isn’t ideal for creating fog. However, we can easily customize our own material for the Particle System. Go to the <code>Fog</code>.</li>
<li>Download a transparent image of a cloud or fog. We will use a cloud image, which is available for download at this link: <a href="https://pixlok.com/images/clouds-png-image-free-download/">https://pixlok.com/images/clouds-png-image-free-download/</a>. You can also access it through the GitHub folder for this chapter. Drag and drop this image into the <code>Fog</code> folder you just created.</li>
<li>Within the <code>Fog</code> folder, generate a new material by <em class="italic">right-clicking</em> and then selecting <code>Fog</code>. Now, drag and drop the previously downloaded image from your local filesystem into the base map of the material. Next, modify the <strong class="bold">Shader </strong>field<strong class="bold"> </strong>of the material to <strong class="bold">Mobile/Particles/Alpha Blended</strong> in the <strong class="bold">Inspector</strong> window. This setting allows the particles to overlap with each other and blend seamlessly, creating a more realistic fog effect.</li>
<li>Select the<a id="_idIndexMarker621"/> Particle System, and drag<a id="_idIndexMarker622"/> the <code>Fog</code> material into its <strong class="bold">Inspector</strong> window. This will automatically update the material. As a result, your scene should now resemble the scene shown in <em class="italic">Figure 7</em><em class="italic">.6</em>.</li>
</ol>
<div><div><img alt="Figure 7.6 – ﻿How your current Unity scene and the Inspector window of the Particle System should look with the newly added fog" src="img/B20869_07_06.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.6 – How your current Unity scene and the Inspector window of the Particle System should look with the newly added fog</p>
<p>After successfully<a id="_idIndexMarker623"/> adding the Particle System to <a id="_idIndexMarker624"/>our VR drum scene, let’s modify its properties a bit to achieve a more dynamic behavior for the fog, which is dependent on the collision velocity of the drums and drumsticks in the next section.</p>
<h2 id="_idParaDest-146">Modifying the properties of the Particle System in your VR drum scene</h2>
<p>Let’s explore the <a id="_idIndexMarker625"/>properties of the Particle System in the <strong class="bold">Inspector</strong> window by expanding it. There are a few critical properties that you need to modify to make the fog on your VR drum scene behave naturally. The modified properties can be observed in <em class="italic">Figure 7</em><em class="italic">.7</em>. </p>
<div><div><img alt="Figure 7.7 – ﻿The expanded Particle System in its modified form in the Inspector window" src="img/B20869_07_07.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.7 – The expanded Particle System in its modified form in the Inspector window</p>
<p>These<a id="_idIndexMarker626"/> properties are explained in the following list in detail:</p>
<ul>
<li><code>5</code> seconds to make the scene more dynamic.</li>
<li><code>PlaySoundOnCollision</code> script.</li>
<li><code>0</code>.</li>
<li><code>5</code>-second life span should be sufficient.</li>
<li><code>0</code> and <code>2</code>. This randomizes the speed of each particle within these limits, creating a more naturalistic fog effect. <strong class="bold">Curve</strong> and <strong class="bold">Random between Two Curves</strong> are two alternative options that you could also choose. They provide even more nuanced control over speed variation, allowing you to define how the values change over time and within specific ranges.</li>
<li><code>2</code>,<code>2</code>,<code>2</code>) to double the size in all dimensions.</li>
<li><strong class="bold">Start Color</strong>: This determines the initial color of each particle. To enhance the visual appeal and make our fog effect more dynamic, we’ll introduce some color variations. Click on the arrow symbol next to <strong class="bold">Start Color</strong> and select the <strong class="bold">Random between Two Gradients</strong> option. This option allows us to define two color gradients, with the color of each individual particle being randomly assigned a value somewhere within these two gradients. After switching the option to <strong class="bold">Random between Two Gradients</strong>, two color gradient preview fields appear. To customize the color gradients, you can click on these fields to open the <strong class="bold">Gradient Editor</strong> window. In the <strong class="bold">Gradient Editor</strong> window, you can add, remove, or rearrange color markers to achieve the color gradient you desire. <em class="italic">Figure 7</em><em class="italic">.8</em> provides a visual guide on how to modify a color gradient.</li>
</ul>
<div><div><img alt="Figure 7.8 – ﻿How to modify the Gradient Editor of the start color" src="img/B20869_07_08.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.8 – How to modify the Gradient Editor of the start color</p>
<p class="list-inset">Initially, you <a id="_idIndexMarker628"/>can set <strong class="bold">Mode</strong> to either <strong class="bold">Blend</strong> or <strong class="bold">Fixed</strong>. The <strong class="bold">Fixed</strong> mode presents a solid color, whereas the <strong class="bold">Blend</strong> mode enables smooth transitions between colors. You can then add multiple keyframes by simply <em class="italic">left-clicking</em> either above or below the color space. The upper keyframes establish the alpha values, dictating the transparency, while the lower keyframes determine the colors themselves.</p>
<p class="list-inset">At the bottom of the window, you’ll see two existing gradient presets, with a third, labeled <strong class="bold">New</strong>, that corresponds to the gradient we’re currently editing. Create two gradient presets as per your preference, and assign them to the start color. In our case, we will choose to use the two pre-existing presets that we had (the white and rainbow gradients). At runtime, this configuration will yield a captivatingly vibrant and dynamic color spectrum in our fog effect, as shown in <em class="italic">Figure 7</em><em class="italic">.9</em>.</p>
<div><div><img alt="Figure 7.9 – ﻿The visual appearance of the fog when choosing two pre-existing presets for the start color" src="img/B20869_07_09.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.9 – The visual appearance of the fog when choosing two pre-existing presets for the start color</p>
<ul>
<li><code>0</code>.</li>
<li><code>0.4</code>. If the simulation speed is adjusted to a value lower than <code>0.4</code>, the fog’s movement will be even slower, creating a more languid appearance, whereas a value higher than <code>0.4</code> will make the fog move more rapidly, giving it a brisker motion.</li>
<li>Expand the <code>13</code>. <code>13</code> is chosen as the ideal rate to achieve the desired particle density and appearance for our purpose. By keeping <code>0</code>, we ensure that particles are emitted based on time alone, not movement, giving us precise control over the number of particles being emitted.</li>
<li>Further down, expand the <code>3</code>,<code>3</code>,<code>1</code>) to create a larger fog effect. Due to the Particle System’s -90-degree rotation on the <em class="italic">X</em> axis, the <em class="italic">Z</em> axis now points in the <em class="italic">Y</em> direction and doesn’t need to be scaled.</li>
<li>Enable the <code>30</code>. This will gradually fade the particles, adding to the realistic fog effect. <em class="italic">Figure 7</em><em class="italic">.10</em> provides you with a comparison of how the fog looks with and without the <strong class="bold">Color over Lifetime</strong> module enabled, and with<a id="_idIndexMarker630"/> a low <strong class="bold">Alpha</strong> setting.</li>
</ul>
<div><div><img alt="Figure 7.10 – ﻿Comparing the visual appearance of the fog with or without the Color over Lifetime module enabled" src="img/B20869_07_10.jpg"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.10 – Comparing the visual appearance of the fog with or without the Color over Lifetime module enabled</p>
<p>While the Particle System provides a plethora of parameters to play around with, the ones we’ve discussed are the most crucial to creating a realistic fog effect. If you’re interested in diving deeper into Particle Systems, Unity offers a short, free course that we highly recommend: <a href="https://learn.unity.com/tutorial/introduction-to-particle-systems#">https://learn.unity.com/tutorial/introduction-to-particle-systems#</a>.</p>
<h2 id="_idParaDest-147">Scripting fog appearance on collision for your VR drum scene</h2>
<p>After setting<a id="_idIndexMarker631"/> up the particle system, we need to go back to the <code>PlaySoundOnCollision</code> script and make a few adjustments.</p>
<p>Firstly, we need to create a <code>public</code> variable that can reference the Particle System we want the particles to emit from. The code for this is relatively simple:</p>
<pre class="source-code">
public ParticleSystem fogParticleSystem;</pre>
<p>Then, whenever the drum gets struck, we should call a method that enables the emission of particles from the Particle System. We base the number of emitted particles on the speed of the drumstick’s impact. Since we already have the <code>OnTriggerEnter()</code> method that adjusts the sound volume based on the velocity of the drumstick, we can simply apply the same logic to the particle system. To do this, we add three lines of code to the <code>if</code> statement in the <code>OnTriggerEnter()</code> method:</p>
<pre class="source-code">
if (velEstimator &amp;&amp; enableVelocity)
{
    float velocityMagnitude = velEstimator.GetVelocityEstimate().magnitude;
    float soundVolume = Mathf.InverseLerp(minimumVelocity, maximumVelocity, velocityMagnitude);
    _soundSource.PlayOneShot(soundClip, soundVolume);
    // Convert the velocity to an integer representing the number of particles
    int numParticles = Mathf.RoundToInt(velocityMagnitude * 10f);
    // Create an EmitParams instance
    ParticleSystem.EmitParams emitParams = new ParticleSystem.EmitParams();
    // Emit the particles
    fogParticleSystem.Emit(emitParams, numParticles);
}
else
{
    _soundSource.PlayOneShot(soundClip);
}</pre>
<p><code>fogParticleSystem</code> is a reference to the Particle System GameObject we set up previously, which will be assigned through the <code>int numParticles = Mathf.RoundToInt(velocityMagnitude * 10f);</code> line translates the velocity’s magnitude into a corresponding number of particles, multiplying it by <code>10</code> – an arbitrary factor that can be adjusted for your specific needs. The number is rounded to the nearest integer, as the particle emission method requires an integer input.</p>
<p>The <code>ParticleSystem.EmitParams emitParams = new ParticleSystem.EmitParams();</code> line initializes an instance of <code>EmitParams</code>. This struct can be used to change specific parameters of the Particle System when particles are emitted via scripting. In our case, we will use the default settings of the created <a id="_idIndexMarker632"/>Particle System.</p>
<p>Finally, <code>fogParticleSystem.Emit(emitParams, numParticles);</code> calls the <code>Emit()</code> method to instantly emit a defined number of particles. It uses the previously created <code>EmitParams</code> instance and the calculated number of particles derived from the object’s velocity.</p>
<p>With these adjustments, the desired functionality is added. Back in the Unity Editor, simply drag and drop the Particle System into the <code>fogParticleSystem</code> field in your <code>PlaySoundOnCollision</code> script component of your drums via the <strong class="bold">Inspector</strong> window. Once done, run your scene, and test the implementation while wearing your VR headset. Note how the more frequently the drums are hit, the more the fog saturates the scene, and vice versa.</p>
<p>Congratulations! You now know how to fully replicate the euphoric sensation of being at a concert featuring a real-life drummer!</p>
<h1 id="_idParaDest-148">Summary</h1>
<p>In this chapter, we embarked on a fascinating journey through the world of sound and particles, understanding their physical properties and delving into the implementation of these real-world phenomena in Unity scenes for heightened immersive experiences in XR.</p>
<p>Upon reaching the end of this chapter, you should now be capable of not only constructing end-to-end XR applications with intricate interactions or animations but also feel comfortable enhancing these creations, by effectively using Unity’s audio and Particle Systems to introduce an additional layer of realism to your XR scenes.</p>
<p>The XR development concepts we’ve covered so far in this book have largely been aimed at those at the beginner to intermediate levels. However, as we move forward, we have something truly unique and enriching in store for you. The following chapter will further elevate your XR development skills by introducing you to some of the most significant and advanced techniques in this field, such as hand-tracking, eye- and head-tracking, and multiplayer functionalities. This crucial knowledge will refine your skillset, transforming you into a more versatile XR developer and enabling you to create an even broader array of sophisticated XR applications.</p>
</div>


<div><h1 id="_idParaDest-149" lang="en-US" xml:lang="en-US">Part 3 – Advanced XR Techniques: Hand-Tracking, Gaze-Tracking, and Multiplayer Capabilities</h1>
<p>Congratulations on completing your journey from being a beginner in XR development and Unity to becoming highly proficient in creating various XR technologies with sophisticated logic! In this final part of our book, we aim to further enhance your skills to become an intermediate-level XR developer. We will introduce you to advanced XR techniques that are not only cutting-edge in the XR application landscape but will also elevate your XR scenes to a new level of intuitiveness and enjoyment.</p>
<p>This section will also introduce you to the different phases and aspects of the XR development life cycle. It will provide you with a precise, research-based overview of the current state of the art and future trends in XR development. By delving into additional XR toolkits and plugins beyond those covered earlier in this book, we will prepare you with the knowledge needed to dive deeper into your preferred area of XR development once you’ve completed this book.</p>
<p>This part contains the following chapters:</p>
<ul>
<li><a href="B20869_08.xhtml#_idTextAnchor026"><em class="italic">Chapter 8</em></a>, <em class="italic">Building Advanced XR Techniques</em></li>
<li><a href="B20869_09.xhtml#_idTextAnchor028"><em class="italic">Chapter 9</em></a>, <em class="italic">Best Practices and Future Trends in XR Development</em></li>
</ul>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
<div><div></div>
</div>
</body></html>