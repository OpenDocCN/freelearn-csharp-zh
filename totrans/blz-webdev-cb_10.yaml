- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Integrating with OpenAI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成OpenAI
- en: In this chapter, we will explore how to integrate advanced AI capabilities into
    your applications using OpenAI’s powerful language models. You will learn to set
    up the Azure OpenAI service and deploy models, laying the foundation for integrating
    AI into your applications. By implementing AI-enhanced features in web applications,
    such as smart-pasting and smart text areas, you will enhance the user experience
    with intelligent data processing and content generation. Additionally, you’ll
    build and integrate a ChatGPT-like chatbot for interactive AI-driven conversations.
    Finally, you will enable seamless data analysis by connecting your Azure OpenAI
    service to an existing Azure Search service data index.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何使用OpenAI强大的语言模型将高级AI功能集成到您的应用程序中。您将学习如何设置Azure OpenAI服务并部署模型，为将AI集成到您的应用程序中打下基础。通过在Web应用程序中实现AI增强功能，如智能粘贴和智能文本区域，您将利用智能数据处理和内容生成来提升用户体验。此外，您还将构建并集成一个类似ChatGPT的聊天机器人，用于交互式AI驱动对话。最后，您将通过将Azure
    OpenAI服务连接到现有的Azure Search服务数据索引，实现无缝数据分析。
- en: Before we dive into recipes, it’s crucial to highlight the ethical implications
    of using AI models, particularly concerning user data. In some cases, by using
    and deploying AI models, you consent to training those models on your application
    content. You must be vigilant about the privacy and security of your users’ data
    and implement clear warnings and acceptance forms within your applications, allowing
    users to consent to or opt out of data sharing. By prioritizing transparency and
    user autonomy, you safeguard user trust and adhere to responsible AI practices.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入食谱之前，强调使用AI模型，尤其是关于用户数据的道德影响至关重要。在某些情况下，通过使用和部署AI模型，您同意在您的应用程序内容上训练这些模型。您必须对用户数据的隐私和安全保持警惕，并在您的应用程序中实施清晰的警告和接受表格，允许用户同意或退出数据共享。通过优先考虑透明度和用户自主权，您保护了用户信任并遵守了负责任的AI实践。
- en: 'Here are the recipes we will cover in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是本章我们将涵盖的食谱：
- en: Setting up an Azure OpenAI service
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Azure OpenAI服务
- en: Implementing smart pasting
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现智能粘贴
- en: Implementing a smart text area
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现智能文本区域
- en: Adding a ChatBot
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加聊天机器人
- en: Connecting an Azure OpenAI service to an existing data index
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Azure OpenAI服务连接到现有数据索引
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we will rely heavily on the Azure services and a few NuGet
    packages that may still be in preview when you install them. You will find all
    the details and warnings described in detail in each of the impacted recipes,
    so you have nothing to worry about. Before you dive in, make sure you have the
    following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将大量依赖Azure服务和一些可能仍在预览中的NuGet包。您将在每个受影响的食谱中找到详细描述的所有细节和警告，因此您无需担心。在您开始之前，请确保您有以下内容：
- en: An active Azure account with access to the Azure Portal (if you don’t have one
    yet, you can start with a time-limited, free account at [https://azure.microsoft.com/en-us/free](https://azure.microsoft.com/en-us/free)
    )
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个活跃的Azure账户，可以访问Azure门户（如果您还没有，您可以从[https://azure.microsoft.com/en-us/free](https://azure.microsoft.com/en-us/free)提供的限时免费账户开始）
- en: A pre-created resource group in Azure
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure中预创建的资源组
- en: A pre-installed Npm package manager, with globally available **npm** command
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预装了Npm包管理器，拥有全局可用的**npm**命令
- en: A Blazor Web App project with per component/page render modes
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有组件/页面渲染模式的Blazor Web App项目
- en: You can find all the code examples (and data samples) from the following recipes
    in a dedicated GitHub repository at [https://github.com/PacktPublishing/Blazor-Web-Development-Cookbook/tree/main](https://github.com/PacktPublishing/Blazor-Web-Development-Cookbook/tree/main)
    . Just be aware that we will implement some recipes only on the server side –
    you’ll understand why as you read through the chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下食谱中找到所有代码示例（和数据样本），在专门的GitHub仓库[https://github.com/PacktPublishing/Blazor-Web-Development-Cookbook/tree/main](https://github.com/PacktPublishing/Blazor-Web-Development-Cookbook/tree/main)中。只需注意，我们将只实现一些食谱在服务器端
    – 当您阅读本章时，您将理解为什么。
- en: Setting up an Azure OpenAI service
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Azure OpenAI服务
- en: Azure OpenAI Service is a cloud-based offering from Microsoft Azure that provides
    access to OpenAI’s powerful language models. A **large language model** ( **LLM**
    ) is an optimized cost-function, trained on human texts, that can generate human-like
    text, allowing you to take chatbots, content generation, or language translation
    to the next level. By leveraging the Azure OpenAI service, you can integrate advanced
    AI capabilities into your Blazor application without managing the underlying infrastructure.
    You’re also getting access to existing GPT models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Azure OpenAI服务是来自Microsoft Azure的基于云的服务，提供对OpenAI强大语言模型的访问。**大型语言模型**（**LLM**）是一个在人类文本上训练的优化成本函数，可以生成类似人类的文本，使您能够将聊天机器人、内容生成或语言翻译提升到新的水平。通过利用Azure
    OpenAI服务，您可以将高级AI功能集成到您的Blazor应用程序中，而无需管理底层基础设施。您还将获得对现有GPT模型的访问权限。
- en: Let’s set up an Azure OpenAI service in the Azure cloud using the Azure portal,
    deploy a dedicated GPT-4 model, and locate access details required for integration
    on the application side.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Azure门户在Azure云中设置一个Azure OpenAI服务，部署一个专用的GPT-4模型，并在应用端定位所需的集成访问详情。
- en: Getting ready
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, we won’t write any code just yet; instead, we will focus on
    setting up the Azure OpenAI service. To get started, here are some prerequisites:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个菜谱中，我们暂时不会编写任何代码；相反，我们将专注于设置Azure OpenAI服务。要开始，以下是一些先决条件：
- en: You will need an Azure account and access to the Azure Portal
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要一个Azure账户和对Azure门户的访问权限
- en: You should create a resource group beforehand; we will use one named **blazor-cookbook**
    dedicated to this chapter
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您应该事先创建一个资源组；我们将使用一个名为**blazor-cookbook**的资源组，专门用于本章
- en: At the time of writing, the process of setting up the Azure OpenAI service consists
    of two phases.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，设置Azure OpenAI服务的流程包括两个阶段。
- en: 'In the first phase, do the following:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一阶段，执行以下操作：
- en: You must complete a request form to gain access to the Azure OpenAI service.
    To find the request form, follow the first two steps outlined in the *How to do
    it* section that follows.
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您必须完成一个请求表单才能访问Azure OpenAI服务。要找到请求表单，请遵循以下“如何做”部分中概述的前两步。
- en: After submitting the form, you will need to wait for approval from the **Azure
    Cognitive Services team** . You will receive a confirmation email once your request
    has been approved, marking the end of the first phase.
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交表单后，您需要等待**Azure认知服务团队**的批准。一旦您的请求被批准，您将收到一封确认邮件，标志着第一阶段结束。
- en: We will walk through the second phase in the *How to do* *it* section.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在“如何做”部分中介绍第二阶段。
- en: How to do it…
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Follow these steps to add the Azure OpenAI service to your Azure resources:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤将Azure OpenAI服务添加到您的Azure资源中：
- en: Open your resource group in Azure Portal and navigate to the Azure Marketplace
    by clicking the **Create** button in the top navigation bar.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Azure门户中打开您的资源组，并点击顶部导航栏中的**创建**按钮，导航到Azure市场。
- en: '![Figure 10.1: Navigating to Azure Marketplace from the resource group overview](img/B22020_10_1.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图10.1：从资源组概览导航到Azure市场](img/B22020_10_1.jpg)'
- en: 'Figure 10.1: Navigating to Azure Marketplace from the resource group overview'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：从资源组概览导航到Azure市场
- en: In the Azure Marketplace, use the search bar in the top panel to find the **Azure
    OpenAI** service and start the creation process by clicking the **Create** button
    on the resulting tab.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Azure市场，使用顶部面板中的搜索栏查找**Azure OpenAI**服务，然后通过点击结果标签页上的**创建**按钮开始创建过程。
- en: '![Figure 10.2: Navigating to the Azure OpenAI service creation panel](img/B22020_10_2.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图10.2：导航到Azure OpenAI服务创建面板](img/B22020_10_2.jpg)'
- en: 'Figure 10.2: Navigating to the Azure OpenAI service creation panel'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：导航到Azure OpenAI服务创建面板
- en: 'In the **Create Azure OpenAI** panel, provide the necessary details to create
    an Azure OpenAI instance:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**创建Azure OpenAI**面板中，提供创建Azure OpenAI实例所需的必要详细信息：
- en: Select the subscription for the service in the **Subscription** field.
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**订阅**字段中选择服务的订阅。
- en: Select the resource group where you want to create the service in the **Resource**
    **Group** field.
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**资源****组**字段中选择您想要创建服务的资源组。
- en: Select the hosting region in the **Region** field.
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**区域**字段中选择托管区域。
- en: Provide a unique name for the service in the **Name** field.
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**名称**字段中为服务提供一个唯一的名称。
- en: Select the pricing plan in the **Pricing** **tier** field.
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**定价****层级**字段中选择定价计划。
- en: '![Figure 10.3: First step of the Azure OpenAI service creation process – defining
    instance details](img/B22020_10_3.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3：Azure OpenAI服务创建过程的第一步 - 定义实例详情](img/B22020_10_3.jpg)'
- en: 'Figure 10.3: First step of the Azure OpenAI service creation process – defining
    instance details'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：Azure OpenAI服务创建过程的第一步 - 定义实例详情
- en: After reviewing the terms and conditions, click **Next** to proceed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 审阅条款和条件后，点击**下一步**继续。
- en: In the **Network** step, select the network availability for the service that
    best suits your needs and confirm by clicking **Next** .
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**网络**步骤中，选择最适合您需求的网络可用性并通过点击**下一步**确认。
- en: '![Figure 10.4: Second step of the Azure OpenAI service creation process – configuring
    network](img/B22020_10_4.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图10.4：Azure OpenAI服务创建过程的第二步 - 配置网络](img/B22020_10_4.jpg)'
- en: 'Figure 10.4: Second step of the Azure OpenAI service creation process – configuring
    network'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4：Azure OpenAI服务创建过程的第二步 - 配置网络
- en: Leave the **Tags** step unchanged unless you have tag policies to follow in
    your organization and proceed by clicking **Next** .
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您的组织有标签策略要遵循，请保持**标签**步骤不变，然后通过点击**下一步**继续。
- en: In the **Review + submit** step, review the service summary and confirm the
    creation request by clicking the **Create** button.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**审查 + 提交**步骤中，审查服务摘要并通过点击**创建**按钮确认创建请求。
- en: '![Figure 10.5: Last step of the Azure OpenAI creation process – reviewing instance
    details](img/B22020_10_5.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图10.5：Azure OpenAI创建过程的最后一步 - 审查实例详情](img/B22020_10_5.jpg)'
- en: 'Figure 10.5: Last step of the Azure OpenAI creation process – reviewing instance
    details'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：Azure OpenAI创建过程的最后一步 - 审查实例详情
- en: Once the deployment completes, open your resource group overview and select
    the **Azure** **OpenAI** service.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署完成后，打开资源组概览并选择**Azure** **OpenAI**服务。
- en: '![Figure 10.6: Selecting the Azure OpenAI instance from the resource group
    overview](img/B22020_10_6.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图10.6：从资源组概览中选择Azure OpenAI实例](img/B22020_10_6.jpg)'
- en: 'Figure 10.6: Selecting the Azure OpenAI instance from the resource group overview'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6：从资源组概览中选择Azure OpenAI实例
- en: Find the **Model deployments** feature in the **Resource Management** section
    in the left menu. Open the Azure OpenAI Studio by clicking the **Manage** **deployments**
    button.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧菜单的**资源管理**部分找到**模型部署**功能。通过点击**管理** **部署**按钮打开Azure OpenAI Studio。
- en: '![Figure 10.7: Navigating to Azure OpenAI Studio to manage model deployments](img/B22020_10_7.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图10.7：导航到Azure OpenAI Studio以管理模型部署](img/B22020_10_7.jpg)'
- en: 'Figure 10.7: Navigating to Azure OpenAI Studio to manage model deployments'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7：导航到Azure OpenAI Studio以管理模型部署
- en: In the Azure OpenAI Studio, find the **Deployments** feature in the **Management**
    section on the left menu and start the deployment process by clicking the **Create
    new** **deployment** button.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Azure OpenAI Studio中，在左侧菜单的**管理**部分找到**部署**功能，并通过点击**创建新** **部署**按钮开始部署过程。
- en: '![Figure 10.8: Initiating model deployment through the Azure OpenAI Studio](img/B22020_10_8.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图10.8：通过Azure OpenAI Studio启动模型部署](img/B22020_10_8.jpg)'
- en: 'Figure 10.8: Initiating model deployment through the Azure OpenAI Studio'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8：通过Azure OpenAI Studio启动模型部署
- en: 'Fill out the **Deploy model** form with the details of the model you intend
    to use:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您打算使用的模型的详细信息填写**部署模型**表单：
- en: Name the deployment in the **Deployment** **name** field.
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**部署名称**字段中命名部署。
- en: Choose the model you want to deploy from the **Select a** **model** dropdown.
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从**选择一个** **模型**下拉菜单中选择您想要部署的模型。
- en: Select a specific model version or the **Auto-update to default** option in
    the **Model** **version** dropdown.
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**模型版本**下拉菜单中选择特定的模型版本或**自动更新到默认**选项。
- en: Choose the type of deployment in the **Deployment** **type** dropdown.
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**部署类型**下拉菜单中选择部署类型。
- en: '![Figure 10.9: Filling the model deployment details and deploying the model](img/B22020_10_9.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图10.9：填写模型部署详情并部署模型](img/B22020_10_9.jpg)'
- en: 'Figure 10.9: Filling the model deployment details and deploying the model'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9：填写模型部署详情并部署模型
- en: After filling out all required fields, confirm the deployment by clicking **Create**
    .
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在填写所有必填字段后，通过点击**创建**按钮确认部署。
- en: How it works…
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In *step 1* , we open the Azure Portal and find the resource group where we
    want to deploy the Azure OpenAI service. From the top bar of the overview panel,
    we select the **Create** option. Azure will redirect us to the Azure Marketplace,
    where we can choose the services to install.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 1*中，我们打开 Azure 门户，并找到我们想要部署 Azure OpenAI 服务的资源组。从概览面板的顶部栏，我们选择**创建**选项。Azure
    将我们重定向到 Azure 市场place，在那里我们可以选择要安装的服务。
- en: In *step 2* , we utilize the search bar at the top of the Azure Marketplace
    to look for Azure OpenAI. The result tab has a **Create** button, which we use
    to start the creation process.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 2*中，我们使用 Azure 市场place 顶部的搜索栏查找 Azure OpenAI。结果选项卡有一个**创建**按钮，我们使用它来启动创建过程。
- en: In *step 3* , we arrive at the first step of the Azure OpenAI creation – **Basics**
    . In this step, we fill out all the basic details of the instance we’re about
    to create. We choose the Azure subscription to define the owner of the service.
    Then, we select the appropriate resource group from the list assigned to the subscription.
    Next, we define the instance details, such as the hosting region and pricing tier.
    Be careful, as different areas have different AI models available. Also, depending
    on the pricing tier you select, you may incur service usage costs. To avoid that,
    opt for a free pricing tier (it has restricted scalability and request limits
    but will be enough for the recipes in this chapter). You can review the availability
    and pricing details by clicking the **View full pricing details** link. Then,
    we provide the instance name and a pricing tier. Once we have filled in all required
    fields, we move to the next step by clicking **Next** .
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 3*中，我们到达 Azure OpenAI 创建的第一步——**基础**。在这一步中，我们填写即将创建的实例的所有基本详细信息。我们选择 Azure
    订阅来定义服务的所有者。然后，我们从分配给订阅的列表中选择合适的资源组。接下来，我们定义实例的详细信息，例如托管区域和定价层。请注意，不同地区可用的 AI
    模型不同。此外，根据您选择的定价层，您可能会产生服务使用费用。为了避免这种情况，选择免费定价层（它具有受限的可扩展性和请求限制，但对于本章中的配方来说已经足够了）。您可以通过点击**查看完整定价详情**链接来查看可用性和定价详情。然后，我们提供实例名称和定价层。一旦填写了所有必填字段，我们通过点击**下一步**来进入下一步。
- en: In *step 4* , we arrive at the **Network** step of the Azure OpenAI creation.
    In the **Network** tab, we define the discoverability of the service. We can disable
    network access entirely, configure private endpoints, set up network security
    within Azure, or make the instance publicly accessible. To keep it simple, we
    allow the instance access from any network, including the internet, and confirm
    by clicking **Next** to proceed.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 4*中，我们到达 Azure OpenAI 创建的**网络**步骤。在**网络**选项卡中，我们定义服务的可发现性。我们可以完全禁用网络访问，配置私有端点，在
    Azure 内部设置网络安全，或使实例公开可访问。为了简化，我们允许实例从任何网络访问，包括互联网，并通过点击**下一步**来确认继续。
- en: In *step 5* , we arrive at the **Tags** step of the Azure OpenAI creation. The
    **Tags** tab allows defining custom tags describing services. Unless you have
    tag-based policies defined in your organization, tags won’t have any functional
    impact. Hence, we leave the **Tags** panel unchanged and proceed to the last step
    by clicking **Next** .
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 5*中，我们到达 Azure OpenAI 创建的**标签**步骤。**标签**选项卡允许定义描述服务的自定义标签。除非您的组织中有基于标签的策略定义，否则标签不会产生任何功能影响。因此，我们保持**标签**面板不变，并通过点击**下一步**继续到最后一步。
- en: In *step 6* , we arrive at the **Review + submit** panel, where we get the last
    chance to review the details of the instance we’re about to create. When everything
    checks out, we confirm the creation by clicking **Create** .
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 6*中，我们到达**审查 + 提交**面板，在这里我们有最后一次机会审查即将创建的实例的详细信息。当一切检查无误时，我们通过点击**创建**来确认创建。
- en: It will take some time for the service deployment to complete. When completed,
    we proceed to *step 7* . We navigate to the overview panel of the resource group
    and select the Azure OpenAI instance.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 服务部署完成需要一些时间。完成之后，我们继续进行*步骤 7*。我们导航到资源组的概览面板，并选择 Azure OpenAI 实例。
- en: In *step 8* , we find the **Resource Management** submenu and navigate to the
    **Model deployments** feature. In that panel, we click the **Manage Deployments**
    button and get redirected to the Azure OpenAI Studio for further steps.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤 8*中，我们找到**资源管理**子菜单，并导航到**模型部署**功能。在该面板中，我们点击**管理部署**按钮，并被重定向到 Azure OpenAI
    Studio 以进行下一步操作。
- en: In *step 9* , in the Azure OpenAI Studio, we find the **Management** submenu
    and navigate to the **Deployments** panel. In the **Deployments** navigation bar,
    we click the **Create new deployment** button to initialize a model deployment
    for the Azure OpenAI service.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 9* 中，在 Azure OpenAI Studio 中，我们找到 **管理** 子菜单并导航到 **部署** 面板。在 **部署** 导航栏中，我们点击
    **创建新部署** 按钮以初始化 Azure OpenAI 服务的模型部署。
- en: In *step 10* , we arrive at the **Deploy model** submission form, where we must
    configure the deployment details. First, we define the deployment name – we will
    later use that name to specify which model to use for executing requests from
    the Blazor app. Next, we choose the model to deploy. Depending on the region where
    the Azure OpenAI instance is hosted, we can choose from a different set of AI
    models provided by Azure. To keep it simple, we opt to deploy GPT-4o. After choosing
    the model, we specify the version to use. From the dropdown, we can select a specific
    GPT model version or choose **Auto-update to default** to use the latest stable
    model. In the deployment form, we can fine-tune a rate limit for requests and
    a content filter, which we leave at default values. We can also enable **Dynamic
    quota** , allowing Azure to automatically scale up the tokens per minute limit
    when there’s higher traffic. When we have filled in all deployment details, we
    can start the process by clicking **Create** .
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 10* 中，我们到达 **部署模型** 提交表单，在那里我们必须配置部署详情。首先，我们定义部署名称——稍后我们将使用该名称来指定从 Blazor
    应用程序执行请求时使用哪个模型。接下来，我们选择要部署的模型。根据 Azure OpenAI 实例所在的区域，我们可以从 Azure 提供的不同 AI 模型集中进行选择。为了简化，我们选择部署
    GPT-4o。选择模型后，我们指定要使用的版本。从下拉菜单中，我们可以选择特定的 GPT 模型版本或选择 **自动更新为默认** 以使用最新稳定的模型。在部署表单中，我们可以微调请求的速率限制和内容过滤器，我们将它们保留为默认值。我们还可以启用
    **动态配额**，允许 Azure 在流量较高时自动增加每分钟令牌限制。当我们填写完所有部署详情后，我们可以通过点击 **创建** 来开始该过程。
- en: 'When the deployment completes, you’ll see the model in the **Deployments**
    panel of Azure OpenAI Studio:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当部署完成后，您将在 Azure OpenAI Studio 的 **部署** 面板中看到该模型：
- en: '![Figure 10.10: Azure OpenAI model deployments overview, showing the deployed
    model](img/B22020_10_10.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.10：Azure OpenAI 模型部署概览，显示已部署的模型](img/B22020_10_10.jpg)'
- en: 'Figure 10.10: Azure OpenAI model deployments overview, showing the deployed
    model'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10：Azure OpenAI 模型部署概览，显示已部署的模型
- en: There’s more…
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: To communicate with the Azure OpenAI instance and the deployed AI model, you
    will need the model deployment name (which we set in *step 10* ) and the Azure
    OpenAI API access details.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要与 Azure OpenAI 实例和部署的 AI 模型进行通信，您需要模型部署名称（我们在 *步骤 10* 中设置）和 Azure OpenAI API
    访问详情。
- en: To find those details, navigate to the resource group and the created Azure
    OpenAI instance. In the menu on the left, select the **Keys and Endpoint** item
    in the **Resource** **Management** section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到这些详情，请导航到资源组以及创建的 Azure OpenAI 实例。在左侧菜单中，选择 **资源** **管理** 部分的 **密钥和端点** 项。
- en: '![Figure 10.11: Navigating to the panel with the Azure OpenAI instance API
    access details](img/B22020_10_11.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.11：导航到包含 Azure OpenAI 实例 API 访问详情的面板](img/B22020_10_11.jpg)'
- en: 'Figure 10.11: Navigating to the panel with the Azure OpenAI instance API access
    details'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11：导航到包含 Azure OpenAI 实例 API 访问详情的面板
- en: You’ll arrive at the API details panel, which includes the **Endpoint** pointing
    to the Azure OpenAI instance, the location where it’s hosted, and two API keys.
    Having two API keys ensures continuous service availability when you need to regenerate
    one of them.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您将到达包含指向 Azure OpenAI 实例的 **端点**、它所在的位置以及两个 API 密钥的 API 详情面板。拥有两个 API 密钥可以确保在需要重新生成其中一个时，服务可以持续可用。
- en: '![Figure 10.12: API access details panel, with API keys and URI](img/B22020_10_12.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.12：API 访问详情面板，包含 API 密钥和 URI](img/B22020_10_12.jpg)'
- en: 'Figure 10.12: API access details panel, with API keys and URI'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.12：API 访问详情面板，包含 API 密钥和 URI
- en: You will need the endpoint, API key, and deployed model name for all the upcoming
    recipes, so store them securely in your secrets storage or keep them handy in
    a notepad for quick access as we proceed through the implementations.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有即将到来的食谱，您将需要端点、API 密钥和部署的模型名称，因此请将它们安全地存储在您的密钥存储中，或者将它们保存在便签簿中以便快速访问，随着我们进入实现过程。
- en: See also
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'We’ve only touched on the Azure OpenAI service, covering the scope required
    to integrate OpenAI into a Blazor application. If you’d like to learn more, access
    the Microsoft Learn resource here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是简要介绍了Azure OpenAI服务，涵盖了将OpenAI集成到Blazor应用程序所需的范围。如果您想了解更多信息，请访问Microsoft
    Learn资源：
- en: '[https://learn.microsoft.com/en-us/azure/ai-services/openai/overview](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview
    )'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://learn.microsoft.com/en-us/azure/ai-services/openai/overview](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview)'
- en: Implementing smart pasting
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现智能粘贴
- en: One common challenge in web development is dealing with unstandardized data,
    such as when you receive an email or other data that needs to be accurately input
    into a claim form. This task can quickly become tedious and frustrating, as manually
    copying and pasting data into the correct fields is time-consuming and prone to
    errors.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 网络开发中一个常见的挑战是处理非标准化数据，例如当你收到需要准确输入到索赔表中的电子邮件或其他数据时。这项任务很快就会变得繁琐和令人沮丧，因为手动将数据复制和粘贴到正确的字段既耗时又容易出错。
- en: The **SmartComponents** repository is an open-source repository with components
    enabling you to add AI-driven features to your .NET applications quickly and without
    an in-depth knowledge of prompt engineering. Among other features, **SmartComponents**
    can enhance the pasting of the unstructured data to fit the expected form. Even
    though **SmartComponents** is not in the **Microsoft** namespace, it is under
    the official .NET Platform GitHub account and is fully endorsed, developed, and
    maintained by the Microsoft Team.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**SmartComponents**仓库是一个开源仓库，其中包含组件，可以帮助您快速将AI驱动功能添加到.NET应用程序中，而无需深入了解提示工程。在众多功能中，**SmartComponents**可以增强非结构化数据的粘贴，以适应预期的表单。尽管**SmartComponents**不在**Microsoft**命名空间中，但它位于官方.NET平台GitHub账户下，并由Microsoft团队官方支持、开发和维护。'
- en: Let’s implement a smart-pasting feature allowing users to paste copied text
    directly into designated fields without any preprocessing.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现一个智能粘贴功能，允许用户直接将复制的文本粘贴到指定的字段中，无需任何预处理。
- en: Getting ready
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Before we dive into making the pasting smarter, do the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入实现智能粘贴之前，请执行以下操作：
- en: Create a **Chapter10** / **Recipe02** directory – this will be your working
    directory
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个**Chapter10** / **Recipe02**目录 - 这将是你的工作目录
- en: Copy the **Models** file from the **Chapter10** / **Data** directory in the
    GitHub repository to the working directory
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将GitHub仓库中**Chapter10** / **Data**目录下的**Models**文件复制到工作目录
- en: Copy the **SmartComponents** folder from the GitHub repository to your solution
    folder, and add all projects inside to your solution. The **SmartComponents**
    folder contains a clone of the **SmartComponents** repository, updated to support
    the latest Azure OpenAI updates
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将GitHub仓库中的**SmartComponents**文件夹复制到您的解决方案文件夹中，并将所有项目添加到解决方案中。**SmartComponents**文件夹包含**SmartComponents**仓库的副本，已更新以支持最新的Azure
    OpenAI更新
- en: Have the Azure OpenAI details ready (you can see how to get them in the *There’s
    more…* section of the *Setting up Azure OpenAI* *service* recipe)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备好Azure OpenAI的详细信息（你可以在“设置Azure OpenAI *服务*配方中的*更多内容…*部分中查看如何获取它们”）
- en: How to do it…
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Follow these instructions to enhance pasting in your application with AI:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下说明使用AI增强您的应用程序中的粘贴功能：
- en: 'Navigate to the **csproj** file of the server-side project and include two
    required **SmartComponents** projects:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到服务器端项目的**csproj**文件，并包含两个必需的**SmartComponents**项目：
- en: '[PRE0]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Still on the server side, open the **Program.cs** file and register **SmartComponents**
    with the OpenAI backend:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仍然在服务器端，打开**Program.cs**文件，并使用OpenAI后端注册**SmartComponents**：
- en: '[PRE1]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Locate the **appSettings** file of the server-side project and extend the application
    settings with an area for **SmartComponents** configuration:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定位到服务器端项目的**appSettings**文件，并在应用程序设置中扩展一个用于**SmartComponents**配置的区域：
- en: '[PRE2]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Navigate to the **csproj** file of the client-side project and include the
    **SmartComponents** project required by the WebAssembly renderer:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到客户端项目的**csproj**文件，并包含WebAssembly渲染器所需的**SmartComponents**项目：
- en: '[PRE3]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create a new routable **FillClaim** component, referencing the **SmartComponents**
    assembly:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的可路由的**FillClaim**组件，引用**SmartComponents**程序集：
- en: '[PRE4]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the **@code** block of the **FillClaim** component, declare a **Claim**
    form parameter of the **ClaimViewModel** type:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**FillClaim**组件的**@code**块中，声明一个**Claim**表单参数，其类型为**ClaimViewModel**：
- en: '[PRE5]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the **FillClaim** markup, construct an **EditForm** frame, binding it to
    the **Claim** parameter. If **EditForm** is not recognized as a component, include
    a **@using Microsoft.AspNetCore.Components.Forms** reference at the top of the
    **FillClaim** component:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **FillClaim** 标记中，构建一个绑定到 **Claim** 参数的 **EditForm** 框架。如果 **EditForm** 不是一个已识别的组件，请在
    **FillClaim** 组件的顶部包含一个 **@using Microsoft.AspNetCore.Components.Forms** 引用：
- en: '[PRE6]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Inside the **FillClaim** form, add fields for entering event and customer details:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **FillClaim** 表单内，添加用于输入事件和客户详情的字段：
- en: '[PRE7]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Add a submit button within the form to confirm the input:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在表单内添加一个提交按钮以确认输入：
- en: '[PRE8]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Lastly, below the submit button, embed a **SmartPasteButton** component with
    a default icon:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在提交按钮下方嵌入一个带有默认图标的 **SmartPasteButton** 组件：
- en: '[PRE9]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: How it works…
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In *step 1* , we start by configuring the server side of the application. We
    navigate to the project configuration file and add references to two projects
    required to make **SmartComponents** work on the server. The **SmartComponents.AspNetCore**
    project contains server components powered by AI, while the **SmartComponents.Inference.OpenAI**
    project contains an implementation of services to communicate with OpenAI backend.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 中，我们首先配置应用程序的服务器端。我们导航到项目配置文件并添加两个项目的引用，这两个项目是使 **SmartComponents**
    在服务器上工作所必需的。**SmartComponents.AspNetCore** 项目包含由 AI 驱动的服务器组件，而 **SmartComponents.Inference.OpenAI**
    项目包含与 OpenAI 后端通信的服务实现。
- en: In *step 2* , we navigate to the **Program.cs** file in the server-side project
    and register **SmartComponents** in the dependency-injection container. We also
    register an **OpenAIInferenceBackend** implementation as the default prompts configuration
    for **SmartComponents** to use. Custom inference implementations come in handy
    when you leverage the AI to generate texts. We will explore that later, in the
    *Implementing a smart text* *area* recipe.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 2* 中，我们导航到服务器端项目的 **Program.cs** 文件并在依赖注入容器中注册 **SmartComponents**。我们还注册了一个
    **OpenAIInferenceBackend** 实现作为 **SmartComponents** 的默认提示配置。当您利用 AI 生成文本时，自定义推理实现非常有用。我们将在
    *实现智能文本* *区域* 菜谱中稍后探讨这一点。
- en: In *step 3* , we complete the setup of **SmartComponents** by navigating to
    the **appSettings.json** file on the server side. As **appSettings.json** is a
    configuration source of the application, we extend the JSON with a **SmartComponents**
    section and key nodes, representing the API key and endpoint and the model deployment
    name that the **SmartComponents** components must use.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 3* 中，我们通过导航到服务器端的 **appSettings.json** 文件来完成 **SmartComponents** 的设置。由于
    **appSettings.json** 是应用程序的配置源，我们通过添加一个 **SmartComponents** 部分和键节点来扩展 JSON，这些节点代表
    API 密钥和端点以及 **SmartComponents** 组件必须使用的模型部署名称。
- en: In *step 4* , we jump to the client side of the application. In-line with default
    Blazor component packages, **SmartComponents** also has component counterparts
    for rendering in WebAssembly mode. We navigate to the configuration file of the
    client-side project and add a **SmartComponents.AspNetCore.Components** project
    reference there.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 4* 中，我们跳转到应用程序的客户端。与默认的 Blazor 组件包一致，**SmartComponents** 也提供了用于在 WebAssembly
    模式下渲染的组件对应物。我们导航到客户端项目的配置文件并在其中添加一个 **SmartComponents.AspNetCore.Components**
    项目引用。
- en: In *step 5* , we create a routable **FillClaim** component and reference the
    **SmartComponents** assembly. Next, we build a form where the support team can
    fill in claim details with the help of AI.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 5* 中，我们创建了一个可路由的 **FillClaim** 组件并引用了 **SmartComponents** 程序集。接下来，我们构建了一个表单，支持团队可以在
    AI 的帮助下填写索赔详情。
- en: In *step 6* , we initialize an **@code** block and declare a **Claim** parameter
    that will also act as the backing model of the claim form. If you’re new to form
    creation in Blazor, we covered that in detail in [*Chapter 6*](B22020_06.xhtml#_idTextAnchor203)
    .
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 6* 中，我们初始化一个 **@code** 块并声明一个 **Claim** 参数，该参数也将作为索赔表单的后备模型。如果您对在 Blazor
    中创建表单不熟悉，我们已在 [*第 6 章*](B22020_06.xhtml#_idTextAnchor203) 中详细介绍了这一点。
- en: In *step 7* , we construct a form frame using **EditForm** and bind it to the
    **Claim** model.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 7* 中，我们使用 **EditForm** 构建一个表单框架并将其绑定到 **Claim** 模型。
- en: In *step 8* , we build a simple form body, allowing the user to fill in an event
    name, date, customer name, and email – enough to identify and process the claim.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 8* 中，我们构建了一个简单的表单主体，允许用户填写事件名称、日期、客户名称和电子邮件 – 足以识别和处理索赔。
- en: In *step 9* , we complete the form by adding a submit button.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 9* 中，我们通过添加提交按钮来完成表单。
- en: Lastly, in *step 10* , we enhance the form with AI by embedding the **SmartPasteButton**
    component within the form’s body. We also declare the **SmartPasteButton** component
    to render with a default icon. With that simple setup, you can now transform unstructured
    data into a ready-to-send form with the help of a ( smart) button.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在*步骤10*中，我们通过在表单的主体中嵌入**SmartPasteButton**组件来增强表单的AI功能。我们还声明**SmartPasteButton**组件以默认图标进行渲染。有了这个简单的设置，你现在可以使用（智能）按钮将非结构化数据转换成可发送的表单。
- en: '![Figure 10.13: A result of smart pasting an e-mail with a claim into a form](img/B22020_10_13.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图10.13：将带有声明的电子邮件智能粘贴到表单中的结果](img/B22020_10_13.jpg)'
- en: 'Figure 10.13: A result of smart pasting an e-mail with a claim into a form'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13：将带有声明的电子邮件智能粘贴到表单中的结果
- en: There’s more…
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: '**SmartComponents** can also work with the OpenAI API key. If you already have
    an OpenAI account, navigate to the following URL:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**SmartComponents**也可以与OpenAI API密钥一起工作。如果你已经有了OpenAI账户，请导航到以下URL：'
- en: '[https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)'
- en: 'Here, you’ll be able to create an API key that allows you to access the ChatGPT
    API:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以创建一个API密钥，允许你访问ChatGPT API：
- en: '![Figure 10.14: Creating an API key to access the OpenAI API](img/B22020_10_14.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图10.14：创建API密钥以访问OpenAI API](img/B22020_10_14.jpg)'
- en: 'Figure 10.14: Creating an API key to access the OpenAI API'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14：创建API密钥以访问OpenAI API
- en: 'Once you have the API key, open the **appSettings.json** file of the server-side
    application and update the **SmartComponents** section:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了API密钥，打开服务器端应用程序的**appSettings.json**文件并更新**SmartComponents**部分：
- en: '[PRE10]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the preceding configuration, the **ApiKey** node still represents your API
    key, while the **DeploymentName** node now defines the GPT model you want to use.
    Notice that the **Endpoint** node is no longer needed. When you don’t provide
    an **Endpoint** value explicitly, **SmartComponents** will fall back to the default
    OpenAI API URI.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的配置中，**ApiKey**节点仍然代表你的API密钥，而**DeploymentName**节点现在定义了你想要使用的GPT模型。请注意，**Endpoint**节点不再需要。当你没有明确提供**Endpoint**值时，**SmartComponents**将回退到默认的OpenAI
    API URI。
- en: Implementing a smart text area
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现智能文本区域
- en: You’ve probably seen the generative power of AI in action – you provide a context,
    and a wall of sensible text appears. No more writer’s block, right? Generative
    AI is a game-changer for all text-driven features in your application. You can
    take store item descriptions or event descriptions from a list of bullet points
    into well-written copy in seconds. With **SmartComponents** , we can easily connect
    to an AI model and leverage the generative power, making content creation faster
    and more intuitive.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经看到了AI的生成能力在实际中的应用 – 你提供上下文，就会出现一堵有意义的文本墙。不再有写作障碍，对吧？生成AI是改变你应用程序中所有文本驱动功能的游戏改变者。你可以将商品描述或事件描述从列表中的项目点转换为高质量的副本只需几秒钟。通过**SmartComponents**，我们可以轻松连接到AI模型并利用其生成能力，使内容创作更快、更直观。
- en: Let’s implement a text area where the support team can fill in a message attached
    to a response to a client’s claim.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现一个文本区域，支持团队可以在回复客户的声明时填写消息。
- en: Getting ready
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Before we explore the AI-powered text area implementation, we must do the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探索AI驱动的文本区域实现之前，我们必须做以下事情：
- en: Create a **Chapter10** / **Recipe03** directory – this will be our working directory
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个**Chapter10** / **Recipe03**目录 – 这将是我们的工作目录
- en: Copy the **FillClaim** component from the *Implementing smart pasting* recipe
    or from the **Chapter10** / **Recipe02** directory in the GitHub repository
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从*实现智能粘贴*配方或从GitHub仓库中的**Chapter10** / **Recipe02**目录复制**FillClaim**组件
- en: Copy the **Models** from the **Chapter10** / **Data** directory in the GitHub
    repository
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从GitHub仓库中的**Chapter10** / **Data**目录复制**Models**
- en: If you’re starting here, review instructions from *step 1* to *step 4* of the
    *Implementing smart pasting* recipe for an initial **SmartComponents** configuration
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你从这里开始，请回顾*实现智能粘贴*配方中的*步骤1*到*步骤4*的说明，以进行初始**SmartComponents**配置
- en: How to do it…
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Follow these instructions to add a smart text area to your application:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下说明将智能文本区域添加到你的应用程序中：
- en: 'Navigate to the **@code** block of the **FillClaim** component and add a **replier**
    variable that defines the person filling out the claim form:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到**FillClaim**组件的**@code**块并添加一个**replier**变量，该变量定义填写声明表单的人：
- en: '[PRE11]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Jump to the **EditForm** body in the **FillClaim** markup and extend the form
    by embedding a **SmartTextArea** component above the submission button. Attach
    the **replier** variable to the **UserRole** parameter of the **SmartTextArea**
    component and bind the text area value to the **Message** property of the **Claim**
    instance:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **FillClaim** 标记的 **EditForm** 主体中跳转到，并通过嵌入一个位于提交按钮上方的 **SmartTextArea** 组件来扩展表单。将
    **replier** 变量附加到 **SmartTextArea** 组件的 **UserRole** 参数，并将文本区域值绑定到 **Claim** 实例的
    **Message** 属性：
- en: '[PRE12]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works…
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In *step 1* , we jump straight to the **FillClaim** component. First, we move
    to the **@code** block and declare a **replier** variable, where we put a brief
    but detailed description of the persona that we want the AI to represent. Considering
    that AI models learn from content written by humans, you should strive to make
    the **replier** description as natural as you would sound when speaking to a friend.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 中，我们直接跳转到 **FillClaim** 组件。首先，我们移动到 **@code** 块并声明一个 **replier** 变量，在那里我们放置一个简短但详细的描述，描述我们希望
    AI 代表的角色。考虑到 AI 模型从人类编写的内容中学习，您应该努力使 **replier** 描述听起来像您与朋友交谈时一样自然。
- en: In *step 2* , we locate the **EditForm** markup in the **FillClaim** markup.
    Above the submission button, we embed a **SmartTextArea** component. The **SmartTextArea**
    component supports the bind-value binding pattern (you can learn more about binding
    in [*Chapter 3*](B22020_03.xhtml#_idTextAnchor095) ) and allows defining standard
    **textarea** attributes, such as **rows** or **cols** , representing the default
    size of the text box. It also allows setting a **UserRole** parameter – that’s
    where we attach our persona definition stored in **replier** .
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 2* 中，我们在 **FillClaim** 标记中定位 **EditForm** 标记。在提交按钮上方嵌入一个 **SmartTextArea**
    组件。**SmartTextArea** 组件支持绑定值绑定模式（您可以在 [*第 3 章*](B22020_03.xhtml#_idTextAnchor095)
    中了解更多关于绑定的信息），并允许定义标准 **textarea** 属性，如 **rows** 或 **cols**，代表文本框的默认大小。它还允许设置一个
    **UserRole** 参数——这就是我们将存储在 **replier** 中的角色定义附加到的地方。
- en: 'That’s all it takes to add a generative field to your application:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要将生成字段添加到您的应用程序中，只需这样做：
- en: '![Figure 10.15: AI helping to write a claim response as user types the message](img/B22020_10_15.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.15：用户在输入消息时，AI 帮助撰写索赔响应](img/B22020_10_15.jpg)'
- en: 'Figure 10.15: AI helping to write a claim response as user types the message'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15：用户在输入消息时，AI 帮助撰写索赔响应
- en: There’s more…
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: So far, we used the default inference configuration provided by the **SmartComponents**
    package. However, you can customize the prompt and AI behavior by implementing
    a custom **SmartTextAreaInference** logic. Since AI communication and processing
    only happen on the server, you must keep prompt customization in the server-side
    project.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用了 **SmartComponents** 包提供的默认推理配置。然而，您可以通过实现自定义的 **SmartTextAreaInference**
    逻辑来自定义提示和 AI 行为。由于 AI 通信和处理仅在服务器上发生，您必须在服务器端项目中保留提示自定义。
- en: 'Let’s create a **ClaimReplyInference** class, inheriting from **SmartTextAreaInference**
    , and customize suggestions coming in the **FillClaim** form:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个继承自 **SmartTextAreaInference** 的 **ClaimReplyInference** 类，并自定义来自 **FillClaim**
    表单的建议：
- en: '[PRE13]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In **ClaimReplyInference** , we override the **BuildPrompt()** method. We leverage
    the base implementation to build the prompt but customize it afterward. First,
    we append an additional **ChatMessage** instance to the **Messages** collection
    the **prompt** already has. We define that new **ChatMessage** role as **System**
    . The **System** message sets the overall behavior of the AI model, indicating
    that we expect a professional tone of suggestions. Lastly, we customize the value
    of the prompt’s **Temperature** property. The **Temperature** setting controls
    the randomness of the AI responses, with lower values making the output more focused
    and deterministic and higher values making it more creative and varied.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **ClaimReplyInference** 中，我们重写了 **BuildPrompt()** 方法。我们利用基本实现来构建提示，但之后进行自定义。首先，我们将一个额外的
    **ChatMessage** 实例追加到 **prompt** 已经拥有的 **Messages** 集合中。我们定义这个新的 **ChatMessage**
    角色为 **System**。**System** 消息设置了 AI 模型的整体行为，表明我们期望得到专业建议的语气。最后，我们自定义了提示的 **Temperature**
    属性值。**Temperature** 设置控制 AI 响应的随机性，较低的值使输出更集中和确定，而较高的值则使其更具创造性和多样性。
- en: 'Having **ClaimReplyInference** in place, we must add it to the dependency injection
    container:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **ClaimReplyInference** 就位后，我们必须将其添加到依赖注入容器中：
- en: '[PRE14]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In the **Program** entry class, we register the **SmartTextAreaInference** class
    as a singleton. The **SmartTextArea** component will automatically discover the
    new implementation.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Program**入口类中，我们将**SmartTextAreaInference**类注册为单例。**SmartTextArea**组件将自动发现新的实现。
- en: 'Now, users will get more official-sounding suggestions:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，用户将获得更多官方口吻的建议：
- en: '![Figure 10.16: AI generating suggestions in a professional tone, to help a
    user replay to a claim](img/B22020_10_16.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图10.16：AI以专业口吻生成建议，帮助用户回复主张](img/B22020_10_16.jpg)'
- en: 'Figure 10.16: AI generating suggestions in a professional tone, to help a user
    replay to a claim'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16：AI以专业口吻生成建议，帮助用户回复主张
- en: See also
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关内容
- en: You can customize all available **SmartComponents** components and fine-tune
    the AI behavior to your application needs. If you want to learn more, check out
    the official **SmartComponents** docs on GitHub at [https://github.com/dotnet-smartcomponents/smartcomponents/tree/main](https://github.com/dotnet-smartcomponents/smartcomponents/tree/main)
    .
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以自定义所有可用的**SmartComponents**组件，并根据应用程序需求微调AI行为。如果您想了解更多信息，请查看GitHub上的官方**SmartComponents**文档，网址为[https://github.com/dotnet-smartcomponents/smartcomponents/tree/main](https://github.com/dotnet-smartcomponents/smartcomponents/tree/main)。
- en: Adding a ChatBot
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加聊天机器人
- en: ChatGPT, developed by OpenAI, is an advanced conversational AI model that has
    gained significant attention since its release. It’s designed to understand and
    generate human-like text based on the input it receives, making interactions with
    it feel natural and intuitive. The versatility of the GPT models enables their
    application in numerous contexts, from customer support and personal assistants
    to educational tools and entertainment.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 由OpenAI开发的ChatGPT是一个先进的对话AI模型，自发布以来受到了广泛关注。它旨在根据接收到的输入理解和生成类似人类的文本，使其与用户的互动感觉自然直观。GPT模型的通用性使其能够应用于多种场景，从客户支持和个人助理到教育工具和娱乐。
- en: Let’s construct a primitive chat UI and connect it to the Azure OpenAI service
    to embed a ChatGPT-like chat functionality in the Blazor application.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个原始的聊天UI并将其连接到Azure OpenAI服务，以便在Blazor应用程序中嵌入类似ChatGPT的聊天功能。
- en: Getting ready
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Similar to **SmartComponents** , which we explored in previous chapters, the
    chat will require Azure OpenAI API access. To avoid leaking API access details,
    we move to the server side of the application.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在前几章中探讨的**SmartComponents**类似，聊天将需要Azure OpenAI API访问权限。为了避免泄露API访问详情，我们将转向应用程序的服务器端。
- en: 'Before we dive into building AI-powered chat, we must do the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入构建AI聊天之前，我们必须做以下几件事：
- en: Create a **Chapter10** / **Recipe04** directory – this will be your working
    directory
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建**Chapter10** / **Recipe04**目录——这将成为您的工作目录
- en: Copy the **InputModel** from the **Chapter10** / **Data** directory in the GitHub
    repository
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从GitHub仓库中的**Chapter10** / **Data**目录复制**InputModel**
- en: Prepare the Azure OpenAI Service connection details (you can see how to get
    them in the *There’s more…* section of the *Setting up an Azure OpenAI* *service*
    recipe)
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备Azure OpenAI服务连接详情（您可以在*更多内容…*部分查看如何获取它们，该部分位于*设置Azure OpenAI服务*配方中）
- en: How to do it…
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Follow these steps to add an AI-powered chat to an application:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤将AI聊天添加到应用程序中：
- en: 'Navigate to the configuration file of the server-side project and include the
    latest version of the **Azure.AI.OpenAI** package (at the time of writing, it’s
    still in preview):'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到服务器端项目的配置文件，并包含**Azure.AI.OpenAI**包的最新版本（截至编写时，它仍在预览中）：
- en: '[PRE15]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Open the **appsettings.json** file with the server project configuration and
    add a **ChatBot** section with the required nodes:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用服务器项目配置打开**appsettings.json**文件，并添加一个包含所需节点的**ChatBot**部分：
- en: '[PRE16]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Move to the **Program.cs** entry file of the server-side project, and right
    after the **builder** instance is initialized, intercept the chat configuration
    into variables:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移动到服务器端项目的**Program.cs**入口文件，并在**builder**实例初始化后，将聊天配置拦截到变量中：
- en: '[PRE17]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Below the configuration variables, register an **AzureOpenAIClient** service
    as a singleton by passing the **endpoint** and **apiKey** variables into the service
    constructor:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在配置变量下方，通过将**endpoint**和**apiKey**变量传递给服务构造函数，将**AzureOpenAIClient**服务注册为单例：
- en: '[PRE18]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After registering **AzureOpenAIClient** , add a **ChatClient** service to the
    dependency injection container as scoped. Leverage the **AzureOpenAIClient** API
    and **deploymentName** to construct the **ChatClient** instance:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在注册 **AzureOpenAIClient** 后，将一个 **ChatClient** 服务添加到依赖注入容器中作为作用域。利用 **AzureOpenAIClient**
    API 和 **deploymentName** 构建一个 **ChatClient** 实例：
- en: '[PRE19]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create a routable **ChatBot** component, rendering in the **InteractiveServer**
    mode and referencing the **OpenAI.Chat** assembly:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个可路由的 **ChatBot** 组件，以 **InteractiveServer** 模式渲染并引用 **OpenAI.Chat** 程序集：
- en: '[PRE20]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Initialize the **@code** block in the **ChatBot** component and inject the
    **ChatClient** service as **Chat** :'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **ChatBot** 组件中初始化 **@code** 块，并将 **ChatClient** 服务注入为 **Chat**：
- en: '[PRE21]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Below the service injection, initialize a **Model** instance to bind to the
    input form and **Messages** collection to persist chat messages to display on
    the UI:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在服务注入下方，初始化一个 **Model** 实例以绑定到输入表单和 **Messages** 集合以持久化聊天消息并在 UI 上显示：
- en: '[PRE22]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Below the **Messages** collection, initialize a **_messages** collection to
    hold messages in a form transferable to the Azure OpenAI Service. Start the **_messages**
    collection with a system prompt, defining the chatbot’s persona:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **Messages** 集合下方，初始化一个 **_messages** 集合来存储可以传输到 Azure OpenAI 服务的消息。以系统提示开始
    **_messages** 集合，定义聊天机器人的角色：
- en: '[PRE23]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next to the backing variables, implement a **SendMessage()** method. Start
    by checking the validity of the **Model** state. If the input is valid, convert
    it to the **UserChatMessage** object and add the message to the backing collections:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在支持变量旁边，实现一个 **SendMessage()** 方法。首先检查 **Model** 状态的有效性。如果输入有效，将其转换为 **UserChatMessage**
    对象并将其添加到支持集合中：
- en: '[PRE24]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Still within the **SendMessage()** method, request chat completion by passing
    the **_messages** collection to the **CompleteChatAsync()** method of the **Chat**
    service and resolve the response payload:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仍然在 **SendMessage()** 方法中，通过将 **_messages** 集合传递给 **Chat** 服务的 **CompleteChatAsync()**
    方法来请求聊天完成，并解析响应有效负载：
- en: '[PRE25]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Complete the **SendMessage()** method by persisting the received response in
    the **Messages** collection and in the **_messages** collection as an **AssistantChatMessage**
    object. Lastly, reset **Value** of the **Model** object:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在 **Messages** 集合和 **_messages** 集合中持久化接收到的响应作为 **AssistantChatMessage** 对象来完成
    **SendMessage()** 方法。最后，重置 **Model** 对象的 **Value**：
- en: '[PRE26]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Move to the **ChatBot** markup and construct a simple **EditForm** form with
    a single input field bound to the **Model** variable, triggering **SendMessage()**
    when submitted. If **EditForm** is not recognized as a component, include a **@using
    Microsoft.AspNetCore.Components.Forms** reference at the top of the **FillClaim**
    component:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到 **ChatBot** 标记，构建一个简单的 **EditForm** 表单，其中包含一个绑定到 **Model** 变量的输入字段，提交时触发
    **SendMessage()**。如果 **EditForm** 被识别为组件，则在 **FillClaim** 组件的顶部包含一个 **@using Microsoft.AspNetCore.Components.Forms**
    引用：
- en: '[PRE27]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Below the input form, iterate over the elements in the **Messages** collection
    and render them in separate paragraphs:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在输入表单下方，遍历 **Messages** 集合中的元素，并在单独的段落中渲染它们：
- en: '[PRE28]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: How it works…
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何工作……
- en: In *step 1* , we start by adding the **Azure.AI.OpenAI** package to the server
    side of the application. If you’ve been using the **NuGet Package Manager** ,
    you’ll have to include prerelease versions of the packages, as **Azure.AI.OpenAI**
    is still in preview at the time of writing.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 中，我们首先将 **Azure.AI.OpenAI** 包添加到应用程序的客户端。如果你一直在使用 **NuGet 包管理器**，你将不得不包含预发布版本的包，因为
    **Azure.AI.OpenAI** 在写作时仍在预览中。
- en: In *step 2* , we add a chatbot configuration section to the **appsettings.json**
    file. We will need an **ApiKey** node, an API **Endpoint** node, and a **DeploymentName**
    node, to specify the name of the model we want to use.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 2* 中，我们将聊天机器人配置部分添加到 **appsettings.json** 文件中。我们需要一个 **ApiKey** 节点、一个
    API **Endpoint** 节点和 **DeploymentName** 节点，以指定我们想要使用的模型名称。
- en: In *step 3* , we navigate to the **Program.cs** file of the server-side project,
    where we register the necessary services in the dependency injection container.
    First, we intercept the chatbot configuration values into **endpoint** , **apiKey**
    , and **deploymentName** by accessing the configuration reader from the **builder**
    instance.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 3* 中，我们导航到服务器端项目的 **Program.cs** 文件，在该文件中注册必要的依赖注入容器中的服务。首先，通过访问 **builder**
    实例的配置读取器，将聊天机器人配置值拦截到 **endpoint**、**apiKey** 和 **deploymentName**：
- en: In *step 4* , we register the **AzureOpenAIClient** service as a singleton,
    passing the **endpoint** value as the Azure OpenAI URI and initializing **AzureKeyCredentials**
    with an **apiKey** value. We can have a shared instance of the **AzureOpenAIClient**
    service as it’s thread- and scope-safe by design but consider the memory impact
    in your implementations.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第4步*中，我们将**AzureOpenAIClient**服务注册为单例，传递**endpoint**值作为Azure OpenAI URI，并使用**apiKey**值初始化**AzureKeyCredentials**。由于设计上它是线程和作用域安全的，我们可以有一个共享的**AzureOpenAIClient**服务实例，但在实现时请考虑内存影响。
- en: In *step 5* , we add one more service to the dependency injection container
    – we register a **ChatClient** service as scoped. We construct the **ChatClient**
    object by resolving the **AzureOpenAIClient** instance from the services collection
    and invoking its **GetChatClient()** method with the **deploymentName** value.
    Having services in place, we construct the UI part.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第5步*中，我们将一个额外的服务添加到依赖注入容器中——我们将**ChatClient**服务注册为作用域内的服务。我们通过从服务集合中解析**AzureOpenAIClient**实例并使用**deploymentName**值调用其**GetChatClient()**方法来构建**ChatClient**对象。有了服务，我们构建UI部分。
- en: In *step 6* , we create a routable **ChatBot** component that references the
    **OpenAI.Chat** assembly, as we will need access to the **ChatClient** class definition.
    We also need the **ChatBot** component to render in **InteractiveServer** mode,
    since our users will interact with the chat.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第6步*中，我们创建了一个可路由的**ChatBot**组件，该组件引用**OpenAI.Chat**程序集，因为我们需要访问**ChatClient**类的定义。我们还需要**ChatBot**组件以**InteractiveServer**模式渲染，因为我们的用户将与聊天进行交互。
- en: In *step 7* , we initialize the **@code** block and inject the **ChatClient**
    service from the dependency injection.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第7步*中，我们初始化**@code**块并从依赖注入中注入**ChatClient**服务。
- en: In *step 8* , we initialize a **Model** instance to bind the input form where
    users fill in their messages, as well as a **Messages** collection, where we persist
    the text representation of the chat and user messages to render them in the markup.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第8步*中，我们初始化一个**Model**实例以绑定用户填写消息的输入表单，以及一个**Messages**集合，我们将聊天和用户消息的文本表示持久化到该集合中，以便在标记中渲染它们。
- en: In *step 9* , we initialize one more collection – **_messages** . In **_messages**
    , we persist messages in the form of **ChatMessage** objects. With that, we can
    easily provide the full context of the conversation when requesting a new response
    from the Azure OpenAI service; without the history of the messages, we would limit
    the chat context to the last message the user sends. We also start off **_messages**
    with a predefined **SystemChatMessage** object. The **SystemChatMessage** object
    allows us to inject a prompt, where we define how the chatbot should behave, but
    the prompt itself is not a part of the conversation.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第9步*中，我们初始化另一个集合——**_messages**。在**_messages**中，我们将消息以**ChatMessage**对象的形式持久化。这样，我们可以在请求Azure
    OpenAI服务的新响应时轻松提供对话的完整上下文；如果没有消息的历史记录，我们将限制聊天上下文为用户发送的最后一条消息。我们还以预定义的**SystemChatMessage**对象开始**_messages**。**SystemChatMessage**对象允许我们注入提示，其中我们定义聊天机器人应该如何表现，但提示本身不是对话的一部分。
- en: In *step 9* , we implement a **SendMessage()** method where all the chatting
    logic goes. At the beginning, we check whether the submitted **Model** value is
    valid and fast-return when there’s nothing to process. Then, we wrap the user
    input into a **UserChatMessage** object. We must use the **UserChatMessage** objects
    when sending user inputs so the AI can interpret them accordingly. Next, we add
    the **UserChatMessage** instance to the **_messages** context collection and format
    the user input into a chat-like version to add it to the renderable **Messages**
    collection.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第9步*中，我们实现了一个**SendMessage()**方法，其中包含所有聊天逻辑。一开始，我们检查提交的**Model**值是否有效，如果没有要处理的内容则快速返回。然后，我们将用户输入包装成一个**UserChatMessage**对象。在发送用户输入时，我们必须使用**UserChatMessage**对象，以便AI能够相应地解释它们。接下来，我们将**UserChatMessage**实例添加到**_messages**上下文集合中，并将用户输入格式化为类似聊天的版本，以便将其添加到可渲染的**Messages**集合中。
- en: In *step 10* , we leverage the **Chat** instance and its **CompleteChatAsync()**
    method to request a new chat response from the Azure OpenAI. Notice that we send
    the entire **_messages** collection as part of the request so that GPT in the
    cloud has the full context of the conversation. Then, we unpack the message from
    the received response **Content** property.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第10步*中，我们利用**Chat**实例及其**CompleteChatAsync()**方法从Azure OpenAI请求新的聊天响应。请注意，我们将整个**_messages**集合作为请求的一部分发送，以便云中的GPT拥有对话的完整上下文。然后，我们从接收到的响应的**Content**属性中解包消息。
- en: In *step 11* , we push the unpacked payload to the backing variables. This time,
    we wrap the received message in an **AssistantChatMessage** object before adding
    it to the **_messages** collection. The **AssistantChatMessage** type represents
    responses from the AI itself. Next, we construct a chat-like message to add to
    the **Messages** collection to render it for the user to see. Finally, we clear
    the **Model** value to accept another message from the user.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 11* 中，我们将解包后的有效载荷推送到后端变量。这次，我们在将其添加到 **_messages** 集合之前，将接收到的消息包装在一个 **AssistantChatMessage**
    对象中。**AssistantChatMessage** 类型代表来自 AI 自身的响应。接下来，我们构建一个类似聊天的消息以添加到 **Messages**
    集合，以便用户可以看到。最后，我们清除 **Model** 的值以接受来自用户的另一条消息。
- en: In *step 12* , we implement a primitive markup so the user can interact with
    the chat. We add a call to action at the top and construct an **EditForm** form.
    We bind the form to the **Model** instance and attach the **SendMessage()** method
    to its submission callback. Within the **EditForm** markup, we add a single **InputText**
    field where the user provides their chat requests and a button allowing them to
    submit the form and trigger the chat generation.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 12* 中，我们实现了一个原始的标记，以便用户可以与聊天交互。我们在顶部添加了一个行动号召，并构建了一个 **EditForm** 表单。我们将表单绑定到
    **Model** 实例，并将 **SendMessage()** 方法附加到其提交回调。在 **EditForm** 标记内，我们添加了一个单独的 **InputText**
    字段，用户可以在其中提供他们的聊天请求，以及一个按钮，允许他们提交表单并触发聊天生成。
- en: In *step 13* , below the **EditForm** component, we construct a simple loop
    where we iterate over the chat-like messages in the **Messages** collection and
    render them in separate paragraphs.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 13* 中，在 **EditForm** 组件下方，我们构建了一个简单的循环，遍历 **Messages** 集合中的类似聊天消息，并在单独的段落中渲染它们。
- en: 'With that simple implementation, you already get a ready-to-talk chat prototype:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个简单的实现，你已经得到了一个准备就绪的聊天原型：
- en: '![Figure 10.17: Primitive chat UI with a powerful AI-powered backend in action](img/B22020_10_17.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.17：具有强大 AI 后端的原始聊天 UI 在行动中](img/B22020_10_17.jpg)'
- en: 'Figure 10.17: Primitive chat UI with a powerful AI-powered backend in action'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17：具有强大 AI 后端的原始聊天 UI 在行动中
- en: There’s more…
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Depending on the session or message length that you expect to handle with the
    chat, you should consider cleaning the context of the conversation periodically.
    This will help maintain the efficiency and effectiveness of the chat functionality.
    Managing the length of the chat context impacts both the cost and responsiveness
    of the chat. Longer contexts can lead to higher costs due to increased API usage
    and potentially slower response times as more data is processed.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你期望通过聊天处理的会话或消息长度，你应该考虑定期清理对话上下文。这将有助于保持聊天功能的效率和有效性。管理聊天上下文的长度会影响聊天的成本和响应速度。较长的上下文可能导致由于
    API 使用增加而成本更高，并且由于处理更多数据而可能响应时间变慢。
- en: One effective strategy is to implement a **circular buffer** of a fixed size.
    In a circular buffer, new elements are added to the end of the buffer while the
    oldest elements are overwritten when the buffer reaches its capacity. This approach
    ensures that the chat context remains within a manageable size, keeping the conversation
    relevant and efficient.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一种有效策略是实现一个固定大小的 **循环缓冲区**。在循环缓冲区中，新元素添加到缓冲区的末尾，而当缓冲区达到其容量时，最旧的元素将被覆盖。这种方法确保聊天上下文保持在一个可管理的范围内，使对话保持相关和高效。
- en: See also
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: If you’d want to explore the **Azure.AI.OpenAI** possibilities further, visit
    the package docs at [https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md](https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md)
    .
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要进一步探索 **Azure.AI.OpenAI** 的可能性，请访问包文档 [https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md](https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/openai/Azure.AI.OpenAI/README.md)。
- en: Connecting an Azure OpenAI service to an existing data index
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 Azure OpenAI 服务连接到现有的数据索引
- en: In Azure, you can have multiple existing data sources, ranging from Azure Cosmos
    DB to various Azure Cognitive services with tokenized and indexed data. While
    the Azure OpenAI service works with commonly available GPT models, it also allows
    you to connect a chosen model to your specific data source. With this integration,
    you can analyze and extract data more intuitively by interacting with your application
    through natural language.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure 中，您可以有多个现有的数据源，从 Azure Cosmos DB 到各种带有标记和索引数据的 Azure 认知服务。虽然 Azure OpenAI
    服务与常见的 GPT 模型一起工作，但它还允许您将选定的模型连接到您的特定数据源。通过这种集成，您可以通过与应用程序的自然语言交互来更直观地分析和提取数据。
- en: Let’s connect the Azure OpenAI service to an existing Azure Search service data
    index. By doing so, we will leverage the power of AI to analyze our internal data
    seamlessly.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将 Azure OpenAI 服务连接到现有的 Azure Search 服务数据索引。通过这样做，我们将利用 AI 的力量无缝地分析我们的内部数据。
- en: Getting ready
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Before we explore connecting Azure Search data to Azure OpenAI, we must do
    the following:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索将 Azure Search 数据连接到 Azure OpenAI 之前，我们必须执行以下操作：
- en: On the server-side on your application, create a **Chapter10** / **Recipe05**
    directory – this will be your working directory
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您的应用程序的服务器端，创建一个 **Chapter10** / **Recipe05** 目录 – 这将是您的工作目录
- en: Copy the **ChatBot** component from the *Adding a ChatBot* recipe or from the
    **Chapter10** / **Recipe04** directory in the GitHub repository
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 *Adding a ChatBot* 菜谱或从 GitHub 仓库中的 **Chapter10** / **Recipe04** 目录复制 **ChatBot**
    组件
- en: If you’re starting here, register all the Azure services as shown in the **Configure**
    file, in the **Chapter10** / **Recipe04** directory in the GitHub repository
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您从这里开始，请按照 GitHub 仓库中 **Chapter10** / **Recipe04** 目录中的 **Configure** 文件所示注册所有
    Azure 服务
- en: How to do it…
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Follow these instructions to connect Azure OpenAI to the Azure Search data
    and enable analyzing the data:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下说明将 Azure OpenAI 连接到 Azure Search 数据并启用数据分析：
- en: 'Open the **appsettings.json** file on the server side and add a new **Search**
    section with **ApiKey** , **Endpoint** , and **Index** :'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在服务器端打开 **appsettings.json** 文件并添加一个新的 **Search** 部分，包含 **ApiKey**、**Endpoint**
    和 **Index**：
- en: '[PRE29]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Move to the **Program.cs** file of the server-side project. Below the builder
    and Azure OpenAI services initializations, intercept the search data access details
    into **searchEndpoint** , **searchApiKey** , and **searchIndex** variables:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移动到服务器端项目的 **Program.cs** 文件。在构建器和 Azure OpenAI 服务初始化下方，将搜索数据访问详细信息拦截到 **searchEndpoint**、**searchApiKey**
    和 **searchIndex** 变量：
- en: '[PRE30]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Below the intercepted search configuration, register **ChatCompletionOptions**
    as a singleton. As part of the **ChatCompletionOptions** initialization, build
    an **AzureSearchChatDataSource** instance and attach it to the constructed completion
    options:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在截获的搜索配置下方，将 **ChatCompletionOptions** 注册为单例。作为 **ChatCompletionOptions** 初始化的一部分，构建一个
    **AzureSearchChatDataSource** 实例并将其附加到构建的完成选项：
- en: '[PRE31]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'At the time of writing, the **Azure.AI.OpenAI** package is in preview and your
    IDE may interpret using the **AddDataSource()** method of the **ChatCompletionOptions**
    class as a compilation error. To suppress the error, add the required **#pragma**
    directive at the top of the **Program.cs** file:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在撰写本文时，**Azure.AI.OpenAI** 包处于预览阶段，并且您的 IDE 可能会将使用 **ChatCompletionOptions**
    类的 **AddDataSource()** 方法解释为编译错误。为了抑制错误，在 **Program.cs** 文件的顶部添加所需的 **#pragma**
    指令：
- en: '[PRE32]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Navigate to the **@code** block of the **ChatBot** component and inject the
    **ChatCompletionOptions** instance next to the **Chat** client:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **ChatBot** 组件的 **@code** 块并在 **Chat** 客户端旁边注入 **ChatCompletionOptions**
    实例：
- en: '[PRE33]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Still within the **@code** block, inside the **SendMessage()** method, locate
    where we invoke the **CompleteChatAsync()** method of the **Chat** service and
    pass **ChatOptions** as a second parameter:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仍然在 **@code** 块内，在 **SendMessage()** 方法中找到我们调用 **Chat** 服务的 **CompleteChatAsync()**
    方法并传递 **ChatOptions** 作为第二个参数的位置：
- en: '[PRE34]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: How it works…
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In *step 1* , we navigate to the **appsettings.json** configuration file of
    the server-side project. We extend the configuration file with a **Search** section
    where we require the **ApiKey** , **Endpoint** , and **Index** values.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *步骤 1* 中，我们导航到服务器端项目的 **appsettings.json** 配置文件。我们通过添加一个 **Search** 部分扩展配置文件，其中需要
    **ApiKey**、**Endpoint** 和 **Index** 值。
- en: In *step 2* , we stay on the server side but move to the **Program.cs** project
    entry file. We intercept the search configuration into **searchEndpoint** , **searchApiKey**
    , and **searchIndex** variables, so we can use them to connect data to the Azure
    OpenAI.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 2**中，我们停留在服务器端，但移动到**Program.cs**项目入口文件。我们将搜索配置拦截到**searchEndpoint**、**searchApiKey**和**searchIndex**变量中，这样我们就可以使用它们将数据连接到Azure
    OpenAI。
- en: In *step 3* , we register a singleton **ChatCompletionOptions** object in the
    application’s dependency injection container. **ChatCompletionOptions** is used
    to configure the behavior of chat completions, allowing us to customize and extend
    the functionality of our chat service. As part of the **ChatCompletionOptions**
    initialization logic, we construct an instance of **AzureSearchChatDataSource**
    , which represents the search data connection details and requires providing an
    endpoint, API key, and index name. We’ve intercepted this from the **appsettings.json**
    file. We use the **AddDataSource()** method of the **ChatCompletionOptions** instance
    to attach the search data access.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 3**中，我们在应用程序的依赖注入容器中注册了一个单例**ChatCompletionOptions**对象。**ChatCompletionOptions**用于配置聊天完成的行为，允许我们自定义和扩展聊天服务的功能。作为**ChatCompletionOptions**初始化逻辑的一部分，我们构建了一个**AzureSearchChatDataSource**实例，它代表搜索数据连接细节，需要提供端点、API密钥和索引名称。我们已经从**appsettings.json**文件中拦截了这些信息。我们使用**ChatCompletionOptions**实例的**AddDataSource()**方法来附加搜索数据访问。
- en: As **Azure.AI.OpenAI** is still in preview at the time of writing, your IDE
    may flag the use of the **AddDataSource()** method as a compilation error – that’s
    nothing to worry about. The Azure team will adjust this before releasing the stable
    package. For now, we can suppress the warning by adding a **#pragma** directive
    at the top of the **Program.cs** file with the **AOAI001** validation code we
    need to suppress, as we do in *step 4* . Next, we move to the **ChatBot** component
    and attach the enhanced completion options to our chatbot.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 由于**Azure.AI.OpenAI**在撰写本文时仍处于预览阶段，你的IDE可能会将**AddDataSource()**方法的用法标记为编译错误——这没有什么好担心的。Azure团队将在发布稳定包之前进行调整。目前，我们可以通过在**Program.cs**文件顶部添加一个带有我们需要抑制的**AOAI001**验证代码的**#pragma**指令来抑制警告，就像我们在**步骤
    4**中所做的那样。接下来，我们转向**ChatBot**组件，并将增强的完成选项附加到我们的聊天机器人上。
- en: In *step 5* , we go straight to the **@code** block of the **ChatBot** component
    and inject the **ChatCompletionOptions** instance from the dependency injection
    container as **ChatOptions** .
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 5**中，我们直接进入**ChatBot**组件的**@code**块，并将从依赖注入容器中注入的**ChatCompletionOptions**实例作为**ChatOptions**注入。
- en: In *step 6* , we locate the **SendMessage()** method and find where we invoke
    the **CompleteChatAsync()** method of the **Chat** service to get a response from
    the Azure OpenAI. We’re already passing a **_messages** collection to the **CompleteChatAsync()**
    method, but it also accepts a second parameter of the **ChatCompletionOptions**
    type – that’s where we pass the injected **ChatOptions** instance with access
    to the Azure Search data.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在**步骤 6**中，我们定位到**SendMessage()**方法，并找到我们调用**Chat**服务的**CompleteChatAsync()**方法以从Azure
    OpenAI获取响应的地方。我们已经在**CompleteChatAsync()**方法中传递了一个**_messages**集合，但它还接受一个**ChatCompletionOptions**类型的第二个参数——这就是我们传递带有访问Azure
    Search数据的注入**ChatOptions**实例的地方。
- en: There’s more…
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: You don’t have to have the data source and Azure OpenAI in the same resource
    group. In fact, you don’t even have to own the data source. Azure OpenAI will
    work correctly and generate contextualized results as long as you provide a valid
    set of configuration details. This flexibility allows you to leverage existing
    data sources and integrate them with Azure OpenAI seamlessly, enhancing the functionality
    of your applications without needing to consolidate or migrate resources.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要将数据源和Azure OpenAI放在同一个资源组中。实际上，你甚至不需要拥有数据源。只要提供有效的配置详细信息，Azure OpenAI就能正确工作并生成上下文化的结果。这种灵活性允许你利用现有的数据源，并与Azure
    OpenAI无缝集成，增强你应用程序的功能，而无需合并或迁移资源。
- en: See also
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见
- en: 'In the recipe implementation, we’ve used a **#pragma** preprocessor directive.
    Preprocessor directives have different purposes and allow adjusting your code
    behavior on a lower level. If you’re curious to learn more, check out this Microsoft
    Learn resource:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在配方实现中，我们使用了**#pragma**预处理器指令。预处理器指令有不同的用途，允许在较低级别调整你的代码行为。如果你想了解更多，请查看这个Microsoft
    Learn资源：
- en: '[https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/preprocessor-directives](https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/preprocessor-directives)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '[C# 预处理器指令](https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/preprocessor-directives)'
