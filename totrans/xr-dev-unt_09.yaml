- en: '9'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Best Practices and Future Trends in XR Development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, you have acquired and mastered a diverse set of skills
    for XR development in Unity. While you should feel comfortable creating a wide
    array of VR, MR, and AR applications in Unity by now using the XR Interaction
    Toolkit, AR Foundation, ARKit, and ARCore using all the techniques you learned
    about in this book, we also want to help you and guide you on your XR development
    journey from here onward. This chapter is specifically designed for this goal.
    It will not only provide you with best practices in XR development that you should
    familiarize yourself with to become a more versatile and powerful XR developer,
    but also offer a comprehensive overview of XR toolkits and plugins that you might
    want to focus on mastering next to deepen your XR development knowledge in a particular
    field.
  prefs: []
  type: TYPE_NORMAL
- en: You will also learn about current trends in XR technology and applications,
    and we will even provide you with future trend predictions in XR made by some
    leading professionals and researchers in this area. By the end of this chapter,
    you will not only be a great XR developer, but will also feel comfortable evaluating
    the future path of XR technology. You will be able to better assess how you can
    match your XR projects to be in line with and at the forefront of these developments,
    as well as which skills might be interesting for you to acquire next.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter is split into the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Exploring current and future trends in XR technology and applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning the best practices for XR development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other useful toolkits and plugins for XR development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring current and future trends in XR technology and applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Did you know that in 2023, consumer XR headset shipments reached 17.8 million,
    which is over triple the number of commercial XR shipments, at 5.6 million? The
    business-to-consumer XR market surged to 31.1 billion US dollars, marking a 23%
    growth from 2022\. Mobile AR dominates the XR landscape with a market value of
    21.1 billion US dollars, overshadowing the VR market, which stands at 15.8 billion
    US dollars ([https://www.statista.com/topics/6072/extended-reality-xr](https://www.statista.com/topics/6072/extended-reality-xr)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Being armed with the capabilities and tools to create immersive XR experiences
    and witnessing the rapid expansion of the XR market, you might ponder which XR
    niche to prioritize. This section will explore the primary domains employing XR.
    You’ll gain insights into ongoing XR research, discover leading companies in each
    segment, and understand emerging trends and applications. Let’s begin by examining
    a sector showing significant XR adoption: education.'
  prefs: []
  type: TYPE_NORMAL
- en: Learning in new realities – XR in education
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine a world where classrooms aren’t limited by four walls, and where students
    can traverse the universe, delve into the human body, or explore limestone caves
    from the other side of the globe – not through textbooks, but through immersive
    experiences. This isn’t the realm of science fiction, but a rapidly evolving frontier
    in education made possible by XR, and your skills as an XR developer are crucial
    in bringing it to life.
  prefs: []
  type: TYPE_NORMAL
- en: An innovative technology itself is worth nothing if no one is keen on using
    it. At a Mexican university, more than 90% of the students involved in a research
    study concluded that VR aided in their understanding of 3D vectors, visualization
    of vector-related mathematical problems, and comprehension of angles between vectors
    and 3D axes ([https://repositorio.unab.cl/xmlui/handle/ria/24387](https://repositorio.unab.cl/xmlui/handle/ria/24387)).
    Additionally, over 80% expressed an interest in seeking out courses with VR integration
    in the future and felt that getting acquainted with the VR tool was quick and
    straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: The same also goes for teachers. A large-scale survey investigated the attitudes
    of over 20,000 teachers toward the use of VR for education ([https://link.springer.com/article/10.1007/s10639-022-11061-0](https://link.springer.com/article/10.1007/s10639-022-11061-0)).
    This survey found that educators held a moderately favorable view of VR’s role
    in education. The findings also revealed that as the level of VR integration increased,
    so did its usage frequency.
  prefs: []
  type: TYPE_NORMAL
- en: VR has been found to enhance collaborative learning by boosting engagement and
    motivation, facilitating remote teamwork, offering interdisciplinary collaboration
    spaces, cultivating social skills, and aligning with collaborative learning strategies
    ([https://www.frontiersin.org/articles/10.3389/frvir.2023.1159905/full](https://www.frontiersin.org/articles/10.3389/frvir.2023.1159905/full)).
  prefs: []
  type: TYPE_NORMAL
- en: There’s been a year-on-year increase in publications revolving around immersive
    VR in education over the past 20 years. This is especially true of the time period
    from 2017 to 2022, with an annual publication volume of 2.6 times more than the
    preceding period ([https://www.mdpi.com/2071-1050/15/9/7531](https://www.mdpi.com/2071-1050/15/9/7531)).
    These findings prove a growing research interest in using XR for educational purposes.
    When quantitative learning outcomes from VR applications are compared to those
    of less immersive teaching techniques, such as desktop computers and presentations,
    VR is found to provide a notable benefit in most cases ([https://link.springer.com/article/10.1007/s40692-020-00169-2](https://link.springer.com/article/10.1007/s40692-020-00169-2)).
  prefs: []
  type: TYPE_NORMAL
- en: Several companies are leveraging the recent research findings to enhance educational
    experiences through VR and AR. *ClassVR* provides an immersive educational platform
    that pairs VR headsets with a library of curriculum-matched content. This content,
    known as *Avanti’s World*, can also be accessed without the headsets. It’s a comprehensive
    virtual learning environment set in a theme park format, containing six VR lands,
    each dedicated to various educational areas ([https://www.classvr.com/](https://www.classvr.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, *zSpace* offers an integrated XR solution with both software and
    unique hardware, enhancing hands-on learning. Students, using lightweight glasses,
    can interact with 3D virtual models via a stylus pen. The platform offers rich
    content across diverse subjects, from K-8 and high-school courses in math, science,
    biology, and more, to vocational topics such as health science and manufacturing
    ([https://zspace.com/](https://zspace.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: '*Kai XR* is an educational XR platform crafted specifically for teachers. This
    platform offers 360-degree virtual excursions, enabling students to virtually
    traverse global locations from their classrooms. With a commitment to child-friendly,
    immersive experiences, *Kai XR* offers diverse VR content, from historical sites
    to modern marvels. The company emphasizes its adaptability, inviting educators
    to either use pre-designed lessons or craft their own using *Kai XR*’s resources.
    The aim is to facilitate enriched learning experiences for middle-school students
    while honing their skills for the modern world. The platform is compatible with
    numerous devices, from smart TVs to VR headsets such as *Oculus Quest*.'
  prefs: []
  type: TYPE_NORMAL
- en: Numerous educational XR applications have emerged on platforms such as Apple’s
    App Store and Google’s Play Store. Noteworthy examples include apps such as *Human
    Anatomy Atlas* and *Catchy Words*, which utilize AR, and *Ancient Egypt*, a VR
    experience. Additionally, VR headset manufacturers such as Meta offer a range
    of educational VR apps on their native platforms. This includes offerings such
    as *Mondly* for language learning, *Star Chart* for space exploration, and *Painting
    VR* for art enthusiasts.
  prefs: []
  type: TYPE_NORMAL
- en: If you are an XR developer and enthusiast, there’s never been a better time
    to specialize in educational VR. The demand is escalating, research is encouraging,
    and the pedagogical implications are profound. The education sector is ripe for
    an XR revolution, and your expertise could shape its future.
  prefs: []
  type: TYPE_NORMAL
- en: Another driving force of XR innovation is industrial and manufacturing use cases,
    about which you will learn more in the upcoming section.
  prefs: []
  type: TYPE_NORMAL
- en: XR in industrial settings and smart manufacturing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Almost 13% of entrepreneurs in the US are currently integrating XR solutions
    into their companies. This percentage underscores a growing interest in and acceptance
    of the technology. Moreover, projections indicate that close to 23% of companies
    plan to incorporate these technologies within the next three years. This provides
    a substantial window of opportunity for XR developers to capitalize on a market
    that’s set to expand.
  prefs: []
  type: TYPE_NORMAL
- en: One of the significant benefits of integrating XR technologies into the industrial
    sector is the potential for a drastic reduction in workplace accidents – by up
    to 70%. By identifying potential hazards and dangerous maneuvers using XR, industries
    can create a safer working environment. This focus on safety and efficiency is
    likely to drive demand for XR solutions that can deliver such results.
  prefs: []
  type: TYPE_NORMAL
- en: Data captured from the US market suggests that around 2.5% of companies are
    fully utilizing XR technologies. These modern entities, often referred to as *smart
    factories of the future*, have a holistic technological ecosystem that’s conducive
    to XR solutions. Tapping into this segment allows developers to push the boundaries
    of what’s possible with XR, setting benchmarks for the industry ([https://doi.org/10.1016/j.procs.2022.09.357](https://doi.org/10.1016/j.procs.2022.09.357)).
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of smart manufacturing, AR in particular is making strides. By
    using AR devices such as smartphones or headsets, workers receive real-time information
    and guidance while executing tasks. For instance, an AR headset can display step-by-step
    assembly instructions and provide feedback if an error occurs or if a tool is
    nearing the end of its usability. Another useful application of AR in manufacturing
    is one where a customer, requiring assistance with repairs, is guided remotely
    by an expert using AR glasses, such as Microsoft’s *HoloLens*.
  prefs: []
  type: TYPE_NORMAL
- en: As the usage of AR increases workers’ accuracy and efficiency, adopting this
    technology in a smart manufacturing context leads to overall increased productivity
    in manufacturing facilities. For onboarding and training of new staff, AR can
    visually represent intricate tasks and processes, ensuring better understanding
    and retention. Managers can quickly ascertain the production status via their
    mobile devices as they navigate the factory floor ([https://www.mdpi.com/2079-9292/12/7/1719](https://www.mdpi.com/2079-9292/12/7/1719)).
  prefs: []
  type: TYPE_NORMAL
- en: In recent literature, assembly has been found to be a leader in AR adoption
    in manufacturing. This prominence stems from assembly activities being visual-centric,
    demanding significant operator involvement. Comparative studies have shown AR
    improves efficiency in maintenance and assembly, shortens maintenance time, and
    enhances task quality over conventional tools.
  prefs: []
  type: TYPE_NORMAL
- en: Quality assurance, too, has benefited from AR. Initially using AR for projecting
    2D information, it now uses spatial AR for quality checks, as with welding spot
    inspections. Spatial AR, combined with real-time 3D metrology data, aids in assessing
    parts’ surface quality, ensuring precise welding, and supporting packaging sectors
    such as die-cutter setups, reducing errors and costs.
  prefs: []
  type: TYPE_NORMAL
- en: Recent studies have also utilized AR for quality control on automotive parts,
    eliminating the need for operators to constantly refer to static documentation,
    streamlining processes, and increasing efficiency. Tests have revealed that AR
    systems reduced execution time for complex quality control procedures by 36%.
    Other applications, based on a user-centered design, have showcased AR’s potential
    in assisting workers with design discrepancy detection. The AR tool’s efficiency
    is evidenced by the minimized cognitive load it places on users, as they must
    no longer split their attention between design data and physical prototypes.
  prefs: []
  type: TYPE_NORMAL
- en: Another study in the automotive domain developed an AR system to correct alignment
    errors during car body fitting, significantly expediting the process. The AR system
    provided real-time guidance, making the procedure almost four times quicker, with
    more consistent results regardless of operator experience. Future enhancements
    aim to further minimize setup times and implement artificial neural networks for
    error detection ([https://www.mdpi.com/2076-3417/12/4/1961](https://www.mdpi.com/2076-3417/12/4/1961)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In industrial AR settings, tracking techniques play a pivotal role in accurately
    determining the position and orientation of objects and devices, ensuring an immersive
    and interactive AR experience. Based on the provided information, the most used
    tracking techniques in these industrial scenarios are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Marker-based tracking:** Among the most prevalent tracking methods in the
    manufacturing context, marker-based tracking holds a dominant position. We discussed
    this technique in great detail in the *What are marker-based and markerless AR?*
    section of [*Chapter 4*](B20869_04.xhtml#_idTextAnchor011). The primary advantages
    of marker-based tracking for industrial use cases are its speed, simplicity, and
    robustness. It has been extensively applied in scenarios such as facilitating
    AR instructional systems for assembly processes, assisting maintenance processes,
    guiding shop-floor operators, and supporting welding processes in the automotive
    industry. The method’s wide application can be attested by the fact that out of
    200 selected research articles related to AR usage in an industrial setting, 63
    articles (31.5%) focused on marker-based tracking, indicating its significance
    in AR-based manufacturing applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Markerless tracking**: Markerless tracking, another method that we discussed
    extensively in the *What are marker-based and markerless AR?* section of [*Chapter
    4*](B20869_04.xhtml#_idTextAnchor011), takes the second spot in terms of the dominance
    of frequently used AR tracking techniques in industrial settings. Examples of
    its application include using 3D point clouds of workstations for quality control
    procedures in the automotive industry, or integrating cloud databases for fault
    diagnosis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hybrid tracking**: An emergent trend, hybrid tracking combines the strengths
    of computer vision-based techniques, such as marker-based or markerless methods,
    with sensor-based approaches. By doing so, it achieves faster tracking speeds,
    reduces latency, and alleviates the computational burden inherent in markerless
    tracking algorithms. Incorporating additional sensor data can also enhance the
    performance of other tracking methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model-based tracking**: Used when a 3D CAD model of the tracked object or
    part is available, this method analyzes and recognizes the pose and position of
    objects based on these models. Even though its popularity has been on the rise
    due to its integration into AR software development platforms such as Unity and
    *Vuforia*, it’s still less dominant than the other methods, with 13 out of 200
    research articles (6.5%) implementing this technique.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sensor-based tracking**: This method is relatively less favored in AR solutions
    for manufacturing, primarily because of the complexities and costs associated
    with deploying sensors, especially in indoor environments. Challenges include
    potential blockages of sensor signals by equipment, machines, or other objects,
    making it less effective ([https://www.mdpi.com/2076-3417/12/4/1961](https://www.mdpi.com/2076-3417/12/4/1961)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While various tracking techniques cater to different AR applications in manufacturing,
    marker-based tracking remains the most favored due to its simplicity and robustness.
    However, as industrial settings evolve and technology continues to advance, we’re
    witnessing a gradual shift toward more complex yet versatile tracking techniques
    such as markerless and hybrid methods. If you’re interested in exploring the world
    of industrial XR, getting to know the pros and cons of these tracking techniques
    first-hand should be one of your main priorities moving forward.
  prefs: []
  type: TYPE_NORMAL
- en: A rising star in the industrial XR space called *RealWear* specializes in hands-free
    AR wearable solutions. Its AR wearable devices allow workers in fields such as
    energy and manufacturing to access crucial information while keeping their hands
    free for tasks ([https://www.realwear.com/](https://www.realwear.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: '*TeamViewer* is also betting on AR for industrial use cases. Its AR platform
    *TeamViewer Frontline* is designed to usher the deskless industrial workforce
    into the digital age. Leveraging state-of-the-art wearable technology, *Frontline*
    streamlines manual processes across industries, bridging the gap between digitally
    proficient office workers and hands-on industrial teams. Its suite of XR solutions
    offers seamless integration, extensive hardware compatibility, and user-friendly
    interfaces ([https://www.teamviewer.com/en/products/frontline/](https://www.teamviewer.com/en/products/frontline/)).'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, *PTC*’s Vuforia offers a comprehensive suite of AR solutions tailored
    for industrial use cases. From enabling service technicians to visualize and get
    insights about machinery using AR to assisting in design reviews and factory layout,
    Vuforia’s AR platform caters to a vast array of industrial needs.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the industrial sector presents a fertile ground for XR developers
    that’s ripe with opportunities for innovation, disruption, and growth. The tangible
    benefits of XR, coupled with the trends in adoption and the challenges faced by
    industries, make it a lucrative domain for XR developers to focus their efforts
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Another sector that benefits hugely from the integration of XR is healthcare.
  prefs: []
  type: TYPE_NORMAL
- en: Bridging the gap from real bodies to virtual worlds – XR in healthcare
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: VR has been garnering attention for its potential in medical education. A comprehensive
    meta-analysis, spanning studies from 1990 to 2019, aimed to gauge VR’s efficacy
    in anatomy teaching. The study’s findings revealed that VR adoption in anatomy
    instruction improves students’ test results compared to traditional methods. The
    authors’ analysis underscores the potential of VR as a valuable tool in elevating
    students’ grasp of anatomy ([https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-020-1994-z](https://bmcmededuc.biomedcentral.com/articles/10.1186/s12909-020-1994-z)).
  prefs: []
  type: TYPE_NORMAL
- en: '*UbiSim* is an interesting company in this domain. It provides nursing students
    with a fully virtual simulation lab, immersing them in environments where they
    engage with realistic patients. This tool aims to refine their patient engagement,
    clinical reasoning, and decision-making abilities, offering varied scenarios from
    emergency responses to childcare ([https://www.ubisimvr.com/](https://www.ubisimvr.com/)).
    Other companies offering similar platforms for surgical VR trainings are *PeriopSim
    VR*, *Osso VR*, and *Oxford Medical Simulation*. The latter delivers comprehensive
    VR training for both the medical and nursing sectors. The platform’s content is
    available on regular computers or VR headsets. Emphasizing learner-centric methods,
    it offers realistic patient care scenarios and teamwork simulations. Several esteemed
    institutions such as Oxford, Manchester, and Edinburgh Universities have incorporated
    this platform into their curricula ([https://careers.oxfordmedicalsimulation.com/](https://careers.oxfordmedicalsimulation.com/)).'
  prefs: []
  type: TYPE_NORMAL
- en: Another big leap in XR technologies for healthcare is the use of VR for rehabilitation
    purposes. There’s been a surge in the number of individuals requiring rehabilitation,
    especially among older individuals and those with disabilities, chronic diseases,
    and functional and cognitive impairments. These individuals face challenges in
    movement, sensation, balance, and cognition, which significantly impact their
    quality of life, careers, and social engagements.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional rehabilitation encounters issues such as stationary rehabilitation
    centers, resource scarcity, monotony in the training process, soaring treatment
    expenses, and a lack of self-driven encouragement and automatic guidance. This
    often leads to decreased confidence and diminished outcomes in the rehabilitation
    journey.
  prefs: []
  type: TYPE_NORMAL
- en: With VR, the rehabilitation process is being completely transformed. VR provides
    an immersive experience, motivating patients and enhancing their active involvement.
    This not only overcomes the stationary nature of traditional centers but also
    fills the gap of lacking resources. Moreover, VR-based systems paired with appropriate
    sensors can closely monitor and record patient movements and biological data,
    offering an avenue for refining and personalizing rehabilitation programs.
  prefs: []
  type: TYPE_NORMAL
- en: Contributions to this research domain stem from 63 countries and 1,921 institutes,
    highlighting the global attention and collaboration that VR rehabilitation is
    garnering. Research trends in VR rehabilitation are areas such as kinematics,
    neurorehabilitation, brain injury, exergames, aging, motor rehabilitation, and
    cerebral palsy, among others. This diversity underscores the broad applications
    and scope of VR in various rehabilitation sectors ([https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10028519/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10028519/)).
  prefs: []
  type: TYPE_NORMAL
- en: An interesting company in this space that specializes in offering a wide range
    of different rehabilitation programs in VR, from chronic back pain to Parkinson’s
    disease, is *Penumbra* ([https://www.realsystem.com/](https://www.realsystem.com/)).
  prefs: []
  type: TYPE_NORMAL
- en: VR development for surgical trainings, rehabilitation, or other fields of healthcare
    is not just an exciting intersection of healthcare and technology, but also an
    area that’s ripe for innovation, collaboration, and immense growth potential.
    Given the evident gaps and burgeoning demand, there’s a compelling reason for
    XR enthusiasts and developers like you to specialize in this field, driving the
    next wave of meaningful XR applications.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of enriching the gaming industry with XR applications may not initially
    seem as profound as developing VR trainings for surgical procedures. However,
    as you’ll discover in the following section, XR holds the potential to enable
    entirely novel gaming experiences, thereby influencing this multi-billion-dollar
    industry in ways that we cannot fully predict at this moment.
  prefs: []
  type: TYPE_NORMAL
- en: Gaming across realities – XR trends in gaming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Gaming has a historical symbiosis with XR; it is in the rich and diverse gaming
    landscapes that XR found its early applications and extensive testing grounds.
    The industry has continually pushed the boundaries, seeking to offer increasingly
    immersive, interactive, and realistic experiences, which naturally positioned
    it at the forefront of XR adoption and innovation.
  prefs: []
  type: TYPE_NORMAL
- en: Top-tier companies and gaming studios have been pivotal in nurturing this space.
    Renowned for its graphics processing units, *NVIDIA* is pivotal in the XR world.
    Its *RTX* series GPUs, designed with ray tracing capabilities, offer enhanced
    realism in VR environments. It has also worked on AI-driven advancements that
    improve XR experiences, such as *deep learning* *super sampling*.
  prefs: []
  type: TYPE_NORMAL
- en: Sony introduced the *PlayStation VR*, a VR headset that integrates with its
    PlayStation gaming consoles. Games such as *Astro Bot Rescue Mission* and *Blood
    & Truth* offer immersive VR experiences exclusive to the platform.
  prefs: []
  type: TYPE_NORMAL
- en: Renowned game studios such as *Ubisoft*, *EA Sports*, and *Epic Games* have
    also been proactive in infusing XR into their gaming ecosystems, thereby transforming
    the way we game today. They’ve partnered with other tech leaders to create XR-supported
    games that offer unprecedented levels of immersion and interactivity.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from these tech and gaming giants, several start-ups and smaller entities
    are throwing their hats into the ring, eager to carve niches for themselves. Companies
    such as *Magic Leap* and *Niantic* (the name behind *Pokémon GO*) have been working
    tirelessly to build ARs that merge the physical and digital worlds in gaming scenarios.
    Other companies to watch include *Resolution Games*, a studio focusing on VR games
    and publisher of well-known VR games such as *Demeo*, and *Rec Room Inc.*, known
    for its VR social platform that integrates gaming elements.
  prefs: []
  type: TYPE_NORMAL
- en: For XR developers looking to immerse themselves in an arena rife with opportunity,
    the gaming industry presents a landscape fertile with potential. The industry
    offers a rich variety of genres and narratives to explore and innovate upon, from
    fantasy worlds to simulations grounded in reality.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, with gaming being a multi-billion-dollar industry, it promises
    not only creative satisfaction but also substantial financial rewards. Developers
    have the chance to work on cutting-edge technology, pushing the boundaries of
    what is possible and shaping the future of entertainment.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the gaming audience, traditionally receptive to new technologies and
    innovations, provides a ready market that is eager to embrace the novelties that
    XR can bring to the gaming space. This receptive audience can offer a particularly
    straightforward path to commercial success for well-conceived XR gaming products.
  prefs: []
  type: TYPE_NORMAL
- en: A research study explored the factors that influence people’s acceptance and
    use of VR games through an online survey involving 473 VR gamers. The researchers
    investigated the impact of hedonic and utilitarian aspects on VR gaming. Hedonic
    aspects refer to the pleasure and enjoyment derived from playing VR games. It
    encompasses aspects such as fun, enjoyment, and the immersive experience that
    these games offer. Utilitarian aspects relate to the practical benefits that can
    be derived from playing VR games, such as health and well-being improvements that
    some games can facilitate. The findings of this study showed that the hedonic
    aspects were a stronger driver for people playing VR games compared to the utilitarian
    aspects. Despite potential inconveniences such as physical discomfort and VR sickness,
    the researchers found that these factors did not significantly reduce the intention
    to use VR games or the level of immersion experienced by the players. The ease
    of using VR systems was found to be crucial in encouraging both the pleasure-driven
    (hedonic) and practical (utilitarian) usage of VR games ([https://link.springer.com/article/10.1007/s10055-023-00749-4](https://link.springer.com/article/10.1007/s10055-023-00749-4)).
  prefs: []
  type: TYPE_NORMAL
- en: The results provide XR developers with important insights; understanding that
    players prioritize enjoyable and immersive experiences over practical benefits
    could guide the design process. Additionally, ensuring the system is user friendly
    can foster both enjoyment and practical utility. Thus, XR developers aiming to
    specialize in gaming should focus on creating immersive, fun, and easy-to-use
    experiences, while not being overly concerned with the potential physical discomfort
    and VR sickness that might be associated with VR gaming.
  prefs: []
  type: TYPE_NORMAL
- en: Another study aimed to understand player complaints about PC-based VR games
    by carrying out an empirical study of 750 PC-based VR games and 17,635 user reviews
    on the gaming platform *Steam*. It found that most newly released VR games support
    multiple headset categories and play areas. There has been an increase in support
    for smaller-scale play areas over time. Even though the median price for VR games
    has doubled, complaints about games being overpriced for their content have sharply
    decreased. Similarly, complaints about cybersickness are low and have been declining
    steadily over time. From 2018 onward, most of the complaints have shifted from
    VR comfort issues to game-specific problems ([https://ieeexplore.ieee.org/document/9347709/](https://ieeexplore.ieee.org/document/9347709/)).
  prefs: []
  type: TYPE_NORMAL
- en: The findings suggest that the PC-based VR gaming market is becoming more sophisticated.
    Concerns traditionally centered on VR comfort, such as cybersickness, have lessened
    in prevalence. This means XR developers specializing in gaming should now prioritize
    enhancing game design and gameplay aspects, while ensuring VR comfort remains
    at its current standard or better.
  prefs: []
  type: TYPE_NORMAL
- en: A study using data from 515 Pokémon GO players found that nostalgic feelings
    about the Pokémon franchise fueled the players’ imagination of AR game content
    in the real world. This, in turn, nurtured affection toward the AR content, enhancing
    the sense of meaningfulness derived from playing. Similarly, social involvement,
    including community identification and social self-efficacy, elevated the meaningfulness
    of the gaming experience ( [https://www.sciencedirect.com/science/article/pii/S0747563221001394#sec7](https://www.sciencedirect.com/science/article/pii/S0747563221001394#sec7)).
  prefs: []
  type: TYPE_NORMAL
- en: Researchers from another study developed *ARQuiz*, a game for public exhibition
    attendees of a Finnish science center. The ARQuiz game enabled visitors to engage
    in a virtual quiz related to the exhibits. During the exhibition visit, players
    used their smartphones to locate AR hints for answers to the quiz questions related
    to the nearby exhibits. In addition to the main quiz gameplay, users could interact
    socially by leaving messages for other players. Their study found that the AR
    application positively influenced the overall visitor experience at the public
    exhibition. Visitors who enjoyed ARQuiz also enjoyed the exhibition more, performed
    better in the quiz, and felt more sociable after the exhibition. ARQuiz was perceived
    as enjoyable and offered a different user experience compared to traditional exhibitions
    ([https://ieeexplore.ieee.org/document/8861040](https://ieeexplore.ieee.org/document/8861040)).
  prefs: []
  type: TYPE_NORMAL
- en: The gaming industry emerges as yet another compelling avenue for XR developers.
    Regardless of the specific industry you intend to target with XR applications,
    there exist certain essential best practices and design principles that your XR
    applications should consistently follow. These will be presented in the upcoming
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Learning the best practices for XR development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will provide you with best practices and design patterns for all
    your XR projects, regardless of the industry you are creating them for. With this
    knowledge, you will be able to make the right hardware, software, and design decisions
    for each of your XR projects. Let’s start by exploring the hardware considerations
    you should keep in mind at the beginning of your XR projects.
  prefs: []
  type: TYPE_NORMAL
- en: Hardware considerations in XR development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the realm of XR, hardware is more than just a vessel for experiences; it’s
    a determinant of their quality. The most powerful VR device isn’t universally
    ideal for every XR application, much like how buying a supercomputer would be
    overkill for the sake of creating a PowerPoint presentation. Consider a fair scenario:
    would you prefer a lengthy VR setup with external sensors, demanding PC requirements,
    and full-body tracking to show off a VR representation of a solar panel? Or would
    standalone VR devices such as those from Meta or PICO, known for their user-friendly
    operation, be more adequate for this task?'
  prefs: []
  type: TYPE_NORMAL
- en: The right hardware strikes a harmony of performance, adaptability, and ease
    of use. Some pivotal factors to consider are the device type, performance, and
    testing. Let’s have a closer look at different device types and their strengths
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: XR device types and their strengths
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Understanding the constraints of XR devices is essential for XR developers aiming
    to craft immersive and smooth experiences. Each XR device, whether it’s a smartphone,
    AR glasses, or a dedicated VR headset, is tailored for different scenarios based
    on its computational power.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, a smartphone, with its versatility and widespread use, is ideal
    for AR applications such as Pokémon GO or AR-driven shopping experiences where
    the user can visualize products in their real environment. AR glasses, such as
    Microsoft’s HoloLens, are more suitable for specialized tasks such as hands-free
    work instructions or architectural visualizations. In contrast, dedicated VR headsets,
    such as the Oculus Quest or the *HTC Vive*, are designed for deep, immersive experiences
    where the user is transported into an entirely virtual world. The following are
    some of the most common use cases that suit the different types of XR hardware:'
  prefs: []
  type: TYPE_NORMAL
- en: 'VR headsets:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fully immersive gaming experiences with a 360-degree field of view
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Simulation training where users can practice tasks such as surgeries or navigating
    airplanes in safe virtual spaces
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Experiencing places and historic sites without leaving home
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Architectural visualization to walk through your future home before it’s built
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Virtual offices where global teams can collaborate in real time with avatars
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AR glasses:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step-by-step overlay guidance for complex tasks
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-time directions overlay on the real world, combined in an industrial setting
    where users should move hands-free
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Surgeons receiving overlays of important info while operating without the need
    to move their heads constantly between the patient and a screen
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Technicians getting schematics or guidance overlaid on machinery they’re fixing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Smartphones (AR):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gaming experiences such as Pokémon GOwhere players interact with real-world
    locations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Previewing furniture or clothing items in your space before buying
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: AR-driven walking or driving directions such as the ones offered by Google Maps
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing tourists with historical info on landmarks or interactive learning
    modules
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Augmenting video calls or video content with digital enhancements
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-time guidance on tasks such as home repairs
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you have chosen the right hardware for your XR project, you will need to
    be aware of the performance challenges that are common in this field. Let’s go
    through them in the upcoming section.
  prefs: []
  type: TYPE_NORMAL
- en: Performance challenges of XR devices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creating XR applications that depict detailed 3D environments, such as architectural
    visualizations in VR, requires addressing performance challenges. Older devices
    or entry-level VR headsets with limited computational capabilities may not render
    these details smoothly, resulting in lags or visual disturbances. Similarly, an
    AR application loaded with high-resolution textures and complex 3D models may
    run effortlessly on advanced devices such as the latest iPhone, but might falter
    on older ones due to memory constraints.
  prefs: []
  type: TYPE_NORMAL
- en: The preliminary step in creating an XR application is to assess the 3D models
    you’re incorporating. Unity, for example, provides information on the polygon
    or triangle count of an imported 3D model. Typically, a 3D model’s polygon often
    equates to a triangle consisting of three vertices. Thus, a model’s intricacy
    directly relates to its polygon count, which becomes pivotal for devices with
    limited processing capabilities such as standalone VR headsets or smartphones.
  prefs: []
  type: TYPE_NORMAL
- en: Referencing documentation provides an understanding of device-specific polygon
    count limitations. For example, the Oculus Quest 1 documentation suggests a triangle
    count cap of 350,000-500,000, while Quest 2 can handle 750,000 to 1 million polygons
    ([https://developer.oculus.com/documentation/unity/unity-perf/](https://developer.oculus.com/documentation/unity/unity-perf/)).
    Note that this pertains to the cumulative polygons rendered in a scene, not just
    an individual model. Hence, for optimal performance, the aggregate polygon count
    of all entities in a scene shouldn’t surpass this figure, though exceptions exist
    based on other optimized factors such as shaders or physics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose a client wants to showcase five high-resolution car prototypes in VR
    using the standalone mode of the Quest 2 headset. However, each car model has
    1 million polygons, so the total number of polygons for the five models would
    be 5 million, which exceeds Quest 2’s recommended limit of 2 million polygons.
    There are a few things that developers can do to address this issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use PC VR mode**: Opt to run Quest 2 in PC VR mode paired with a robust computer,
    sidestepping the need for optimizations. The reasoning behind this is that PCs
    possess greater computational prowess, eliminating the typical hardware constraints
    of standalone VR headsets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Utilize mesh decimation**: Mesh decimation is a powerful technique to significantly
    diminish a model’s polygon count without notably downgrading its visual appeal.
    Implementing this method requires proficiency in 3D modeling software and an understanding
    of the underlying geometry of the models being simplified. There’s no hard limit,
    but the key is to strike a balance: reducing polygons effectively while ensuring
    the model retains its essential characteristics and aesthetic value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To learn more about mesh decimation, please refer to this insightful blog post:
    [https://odgy.medium.com/mesh-decimation-done-right-95245c4b5f52](https://odgy.medium.com/mesh-decimation-done-right-95245c4b5f52)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Optimization techniques**: Although standalone VR headsets can accommodate
    scenes exceeding their recommended polygon count, achieving this demands numerous
    optimizations. Adopting straightforward shaders, implementing baked lighting,
    and opting for reduced texture resolution are a few methods of doing so. However,
    from our experience, it’s advisable to stay within a million polygons over the
    stipulated limit for such optimizations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, you should continuously test and assess your XR application throughout
    its entire development process to make sure it is in line with your hardware’s
    capabilities. Tools such as Unity’s **Profiler** serve as valuable aids. In the
    next section, you will learn how you can use it.
  prefs: []
  type: TYPE_NORMAL
- en: Testing and profiling the application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Unity’s Profiler is an invaluable tool for diagnosing performance issues and
    optimizing your VR experiences. The Profiler provides real-time data about your
    application, capturing details on CPU, GPU, memory usage, rendering, physics,
    and more. Implementing and using the Profiler within a VR experience is similar
    to using it for any other Unity project, with some VR-specific considerations.
    The following is a step-by-step guide on how to implement Unity’s Profiler for
    your VR experience:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your project in Unity. Go to **Window** | **Analysis** | **Profiler**,
    or simply press *Ctrl/Cmd* + *7* to open the **Profiler** window. If you are using
    a standalone headset, ensure that both your PC and the headset are on the same
    network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you have a PC-based VR headset, simply click the **Play** button in Unity
    to start your VR experience. While your VR experience is running, the **Profiler**
    window will update in real time, showing data captured from your application.
    For standalone VR headsets, you must first build and deploy your application to
    your VR device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In Unity’s **Profiler** window, click on the **Active Profiler** dropdown. You
    should see your VR device listed there (given it’s on the same network). If not,
    ensure Unity and your device can communicate over your network. Select your VR
    device from the list. Unity will start profiling directly from the device, and
    the **Profiler** window will update in real time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'While many of the metrics in the Profiler are applicable to all Unity applications,
    with VR, you should pay special attention to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Frame time**: Ensure you’re consistently hitting the frame rate required
    for your VR headset (e.g., 90 Hz for Oculus Rift, 72 Hz for Oculus Quest). Missing
    frame rates can lead to motion sickness in VR. You will find the recommended frame
    rate in the documentation of your VR hardware.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Render thread**: VR requires rendering two views (one for each eye), which
    can be more demanding. Look for any spikes or bottlenecks here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GPU**: High-quality shaders and post-processing effects can be especially
    demanding in VR due to the need to render them twice (for each eye). Always test
    their impact in VR.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you’ve identified areas where your VR experience might be encountering
    performance hitches, you can dive deeper into the specific sections (such as **CPU**,
    **GPU**, and **Memory**) in the Profiler to get a detailed performance breakdown.
    Look for any unexpected spikes or prolonged high usage. These could be indicators
    of potential issues such as inefficient scripts, too many active physics objects,
    or overly detailed models. Make adjustments in your project based on your findings.
    For instance, simplify complex meshes, optimize shaders, and reduce the number
    of active physics objects. After making changes, test your VR experience again
    to see whether the issue has been resolved and to ensure no new issues have cropped
    up.
  prefs: []
  type: TYPE_NORMAL
- en: Tips
  prefs: []
  type: TYPE_NORMAL
- en: 'These three important aspects are often forgotten when profiling XR applications
    in Unity:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Unity has a *Deep Profiling* mode that provides more detailed information,
    but it comes at a performance cost. Use it when you need an in-depth analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Remember to turn off any debug logs in the final build as they can impact
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. For VR, always strive for consistent and smooth performance. Even minor
    hitches can be disorienting and uncomfortable for users.
  prefs: []
  type: TYPE_NORMAL
- en: 'By using the Profiler regularly throughout your VR development process, you
    can ensure that your applications run smoothly and provide the best possible experience
    for your users. However, a smooth-running experience does not guarantee that users
    will enjoy your app. Let’s have a closer look at the most important aspect to
    focus on before designing your app: your audience.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding your audience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the foundational steps in crafting a successful XR application is understanding
    who will be using it. Just as a carpenter wouldn’t start building without a blueprint,
    a developer shouldn’t start creating without a clear picture of their audience.
    This section will guide you through the process of identifying and understanding
    your target users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you dive into the development of your VR application, you need to ask:
    “Who is this for?” The answer will influence almost every other decision you make.
    For instance, a VR application for children might prioritize colorful graphics
    and simplicity, whereas one for professionals in a given industry might focus
    on functionality and data visualization. Consider age, gender, education, and
    occupation. A VR game targeted at teenagers will have different design elements
    and challenges than one aimed at adults.'
  prefs: []
  type: TYPE_NORMAL
- en: Another important question to answer in this context is whether your audience
    is familiar with VR. If not, your application might need to incorporate introductory
    tutorials or more intuitive controls. A tech-savvy user might crave advanced features
    and customizations, while others might want a more streamlined, plug-and-play
    experience. By identifying these user needs, you can ensure that your application
    will be relevant, user friendly, and appealing to your audience.
  prefs: []
  type: TYPE_NORMAL
- en: It’s always wise to assess the landscape before planting your flag. Look at
    the VR applications currently available that serve a similar purpose or target
    audience to yours. Identify what’s missing in current offerings. Is there a feature
    or an experience that users are asking for in the reviews but isn’t yet available?
    Staying with user reviews, the insights you will receive just by reading through
    reviews of similar applications are invaluable. Users will often detail what they
    love, what they hate, and what they wish was included.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating user personas is another common method in product design, and its
    importance is magnified in the world of VR, where experiences are so personal
    and immersive. A user persona is a fictional character that represents a segment
    of your target audience. They come with a name, a background, preferences, and
    challenges. Personas help make abstract user needs more tangible. When making
    decisions, you can ask: “Would this feature benefit Anna, the tech-savvy college
    student who loves gaming?” or “Would this interface be intuitive for Raj, the
    middle-aged architect who’s new to VR?” Incorporating user personas into your
    planning phase can be the difference between a VR application that feels generic
    and one that feels tailor-made for the user.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding your audience isn’t just the first step in VR application development;
    it’s a compass that should guide every subsequent decision. Making the effort
    to truly understand your users ensures that the final product will not only meet
    but exceed their expectations. After you’ve understood your audience, you must
    also ensure that you can cater to its needs. No matter whether you’re working
    alone or in a team, efficient project management is crucial to completing your
    XR application in a reasonable time and manner. Let’s dive deeper into this topic
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Efficient project management for XR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every great creation begins with an intention, a clear vision of what one hopes
    to achieve. Setting tangible goals ensures that the development process remains
    focused and the end product aligns with the envisioned purpose. This section sheds
    light on how to set effective goals, prioritize features, and determine the criteria
    for success.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as a sailor wouldn’t set out without a destination in mind, developers
    should have a clear objective for their VR application. Begin by asking: “Why
    are we building this?” Are you looking to entertain, educate, train, or provide
    a unique service? Pinpointing the purpose will shape the app’s design, content,
    and user experience. Once you can answer this question, determine the boundaries
    of your application. If it’s an educational VR app, will it cover one subject
    or offer a broad curriculum? Setting the scope ensures your efforts remain targeted
    and manageable. In this context, you should also specify what the target user
    hopes to achieve with your application. Whether it’s mastering a new skill, being
    entertained, or solving a specific problem, understanding this can help refine
    your objectives.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With all of these questions settled and an array of possible features to integrate,
    you need a strategy to prioritize. The following are some important considerations
    you should make:'
  prefs: []
  type: TYPE_NORMAL
- en: List out all the features you envision for your application. Then, categorize
    them into essential functions and those that are additional enhancements. This
    helps in focusing on what’s crucial first.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use your user personas or early feedback to determine which features are most
    desired by your audience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be realistic about time, budget, and technical constraints. Some features might
    be fantastic on paper but could be resource-intensive to implement. Keep in mind
    the number of people and the competencies within your team.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining success is as crucial as setting the initial goals. How will you know
    whether your VR application meets, or hopefully exceeds, expectations? For this,
    we recommend you establish success metrics right at the start of your XR endeavor
    that you can evaluate post-launch, as well as during user testing. Track metrics
    such as the average session duration, frequency of use, and user progression within
    the application to gauge engagement levels. Likewise, monitor crash rates, glitches,
    and other performance-related issues. A technically sound application is key to
    retaining users. Use your metrics not just as a report card but as a roadmap for
    future updates, refinements, and even potential expansions.
  prefs: []
  type: TYPE_NORMAL
- en: 'For your XR endeavors to succeed, you should also be familiar with some essential
    techniques and tools for managing your projects in XR. Let’s go through them step
    by step:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mind mapping and brainstorming sessions**: These enable you to harness collective
    intelligence, propelling the clarity and creativity of your concept. For these
    sessions, assemble a diverse group of people, combining technical developers,
    designers, and even potential end users. You should do this even if you are a
    solo developer. Their combined insights can lead to enriched ideas. For these
    sessions, we recommend you use tools such as *Miro* or *Lucidchart*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Game design documentation (GDD)**: A GDD acts as a project’s blueprint, weaving
    together the narrative, mechanics, interactions, and level designs. Rather than
    just sketching a user’s journey, as with traditional storyboarding, a GDD delves
    deeper. It outlines the intricacies of user interactions in the XR environment,
    lists mechanics, sets the governing rules, maps out the challenges within each
    level, and ensures a seamless user experience by detailing menus. This holistic
    approach streamlines development and sets the stage for a successful project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creating 3D wireframes**: While traditional wireframing tools assist in plotting
    out digital interfaces, XR demands a more 3D approach. Tools such as *Sketchbox*
    and *Gravity Sketch* let developers and designers craft 3D wireframes, allowing
    a spatial understanding of the XR environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing your code base**: Once the project is planned, it needs to be managed.
    In particular, managing code base changes in complex XR projects can be a daunting
    task. **Git**, a distributed version control system, will become your daily companion
    in such scenarios. Git allows developers to work simultaneously on different features
    or bugs without affecting the main code base. Once a feature or fix is ready,
    it can be merged back into the main branch. Every change, every merge, and every
    version is tracked. This means if something goes wrong, you can revert to a previous
    state of your application easily. Git provides a platform where multiple developers
    can contribute without stepping on each other’s toes. Each contributor can work
    on their local copy and then push changes to a shared repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both *GitLab* and *GitHub* offer platforms that extend the capabilities of Git,
    making the collaborative process even smoother. Beyond just version control, these
    platforms offer a suite of tools such as code reviews, continuous integration,
    and continuous deployment, which streamline the development process. You can also
    report, track, and assign bugs or features with them. This keeps the team aligned
    on priorities and ensures that issues are resolved methodically. Both tools also
    come with **kanban boards**. A kanban board is a visual tool to manage tasks and
    workflows. As tasks move from one stage to another, such as from **To Do** to
    **In Progress** or **Completed**, they can be dragged across columns on the board.
    This provides a quick overview of project progress and bottlenecks and is perfectly
    suited for agile projects.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Planning an XR application is a multifaceted process, blending traditional techniques
    with XR-specific tools. This integration ensures that the foundation of the XR
    application is robust, clear, and primed for successful development. Whether you’re
    sketching out the user’s journey or building a 3D prototype, each planning stage
    is a step closer to realizing a compelling and impactful XR experience.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we are focusing on best practices that ensure a good user
    experience.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring a good user experience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring a good user experience in XR applications goes beyond just graphics
    and performance; it delves deep into intuitive design and user interaction. From
    grasping the basics of XR UI/UX design to creating inclusive interfaces and understanding
    the importance of feedback, every aspect plays a pivotal role in defining a seamless
    and immersive experience for the user.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional UI/UX, whether for web or mobile apps, focuses on the spatial relation
    on a flat screen. Designers ask: “How does one element look next to another?”
    In XR, the questions evolve. The spatial relation is not just side-to-side, but
    also in-depth. It’s about how one element exists in relation to another within
    a 3D space.'
  prefs: []
  type: TYPE_NORMAL
- en: XR environments also introduce challenges not found in conventional design.
    For instance, how do you ensure that a user can comfortably read text in VR? Or
    in AR, how do you design an interface that complements, rather than clashes with,
    the real world?
  prefs: []
  type: TYPE_NORMAL
- en: 'As XR has matured, certain patterns and guidelines have emerged that aid in
    creating intuitive and immersive experiences. Just as a hamburger icon signifies
    a menu in traditional apps, certain gestures or symbols are becoming standardized
    in XR. For instance, a hand pinch in VR might signify selection, while a swipe
    in AR might rotate an object. Physical feedback, such as a controller’s vibration
    in response to an action, can significantly reinforce a user’s actions within
    the XR environment. No matter what kind of XR application you are developing,
    a good rule of thumb is the following: leverage familiar actions from the real
    world (such as grabbing or throwing) to make virtual interactions in your XR application
    instantly understandable.'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, XR interfaces need to be designed with user comfort at the forefront.
    Elements should be within a comfortable reach and view, ensuring users don’t need
    to make awkward movements or strain their eyes. This also involves considering
    ergonomics, ensuring that interactions don’t lead to physical strain over extended
    periods. There’s a temptation to include a plethora of interactions and details
    in XR applications, but this can often lead to confusion. Clarity and simplicity
    should be the watchwords. If an interface element or interaction doesn’t serve
    a clear purpose, it’s worth reconsidering its inclusion.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the digital revolution, one would assume that accessibility barriers have
    been significantly reduced. However, without careful design, XR can inadvertently
    introduce new ones. It’s essential that XR applications are not just for the many
    but for all. There are three important things to keep in mind for any of your
    future XR applications:'
  prefs: []
  type: TYPE_NORMAL
- en: Not all users interact with XR in the same way. Some might have visual impairments,
    others could have auditory challenges, and yet others might face mobility restrictions.
    For instance, subtitled audio can aid those with hearing impairments, while voice
    commands can help those with mobility challenges.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One-size-fits-all rarely works in design, especially in XR. Providing users
    with the ability to adjust settings to their comfort can make a massive difference.
    This includes scaling the UI for those who might find default sizes hard to read
    or adjusting brightness for those sensitive to intense light. Audio levels, especially
    in VR, can be adjusted to ensure users can comfortably immerse themselves in the
    environment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inclusivity in XR is not just about adding features; it’s about adopting a mindset.
    When the design process starts with considering all potential users, regardless
    of their challenges, it leads to a product that’s not only more robust but also
    more universally enjoyable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The potential of XR is boundless. However, this potential can only be realized
    when designers place users at the heart of the design process. By focusing on
    intuitive interactions and championing inclusivity, XR applications can offer
    transformative experiences for everyone.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important aspect to ensure a good user experience is the gathering
    of user feedback. The development of any XR application is only as good as the
    feedback it receives. In XR, where users are navigating complex 3D environments
    and engaging in novel interactions, understanding their experiences is crucial.
    There are a couple of possible ways in which to collect user feedback:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Playtesting**: This is one of the most direct ways to gather insights. By
    observing users as they navigate through an XR experience, you can identify pain
    points, moments of confusion, or elements that work exceptionally well. It provides
    a firsthand look into how users engage with your application, making it invaluable
    for XR development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Surveys and questionnaires**: These can be used post-experience to gather
    structured feedback. They can focus on specific aspects of the XR application,
    such as the intuitiveness of interactions, visual aesthetics, or overall user
    satisfaction. Tailored questions can extract deep insights into particular elements,
    while open-ended questions can provide unexpected but valuable perspectives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spontaneous feedback**: Beyond structured playtests, sometimes just allowing
    users to interact with an XR application and share their thoughts spontaneously
    can yield the most candid feedback. These sessions can be more free-form, letting
    users explore at their own pace, with developers noting reactions, comments, and
    behaviors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not all feedback will be actionable, and some might even be contradictory. The
    key is to look for patterns and consistent pain points or praises across users.
    Tools such as heat maps in combination with eye-tracking, to visually represent
    where users look or interact the most, can be invaluable. Likewise, feedback about
    physical discomfort, confusion, or moments of delight should be given priority.
  prefs: []
  type: TYPE_NORMAL
- en: Based on such analyses, your XR experience should undergo adjustments. This
    could mean redesigning certain UI elements, optimizing performance, or even introducing
    new features. The goal is to enhance what works and fix or eliminate what doesn’t.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid criticism on interactions not feeling natural or intuitive, you should
    focus on choosing common input configurations from the beginning. Let’s discuss
    them in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Input devices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the realm of XR, the mode of interaction is a pivotal aspect that can significantly
    influence user immersion and engagement. Modern XR experiences offer a spectrum
    of interaction modalities, from controllers to direct hand-tracking and gesture
    recognition. As developers, ensuring seamless, intuitive, and robust interactions
    is paramount. Let’s delve into the best practices for these XR interaction methods
    by starting with VR controller input configurations.
  prefs: []
  type: TYPE_NORMAL
- en: VR controller input configuration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the dynamic world of VR, the way the user interacts with the environment
    can significantly shape their overall experience. VR controllers are central to
    this interaction, and there are general conventions that many developers follow
    to ensure a consistent and intuitive user experience. The following is a look
    at common VR controller inputs and their frequently associated actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **VR** **controller input** | **Primary actions** | **Secondary actions**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Trigger button | Grabbing or picking up objects | Shooting or activating
    a highlighted item |'
  prefs: []
  type: TYPE_TB
- en: '| Grip button | Grasping or holding objects, mimicking the action of closing
    one’s hand | Object manipulation, such as scaling or rotating |'
  prefs: []
  type: TYPE_TB
- en: '| Thumbstick/touchpad | Navigation, usually through teleportation or smooth
    locomotion | Rotating the user’s view, scrolling through menus, or adjusting settings
    |'
  prefs: []
  type: TYPE_TB
- en: '| Face buttons (A, B, X, Y, or equivalent) | In-game actions, such as jumping,
    interacting, or accessing menus | Secondary modes or tools within the VR experience
    |'
  prefs: []
  type: TYPE_TB
- en: '| Menu or system button | Accessing in-game menus, pausing, or pulling up system
    settings | Often a shortcut to calibrate or reset the VR view |'
  prefs: []
  type: TYPE_TB
- en: '| Haptic feedback | While not a button, haptic feedback provides tactile responses
    to the user, signaling successful interactions, collisions, or other in-game events
    |  |'
  prefs: []
  type: TYPE_TB
- en: Table 9.1 – The actions associated with different VR controller inputs
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will dive into common hand gestures in VR.
  prefs: []
  type: TYPE_NORMAL
- en: Hand gesture recognition in VR
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As VR technology has evolved, hand-tracking and gesture recognition have emerged
    as powerful tools for a more natural and intuitive user interaction. Unlike traditional
    controller inputs, hand gestures utilize the nuances of human hand movement, creating
    a more immersive and direct interaction within the virtual environment. The following
    is a breakdown of commonly recognized hand gestures and their typical VR actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Hand gesture** | **Primary actions** | **Secondary actions** |'
  prefs: []
  type: TYPE_TB
- en: '| Open hand | Often signifies a relaxed state or neutral position | Hovering
    over objects or menu items |'
  prefs: []
  type: TYPE_TB
- en: '| Closed fist | Grasping, holding, or picking up objects; mirrors the action
    of clenching one’s hand | Can sometimes trigger a punch or hit, especially in
    combat-oriented experiences |'
  prefs: []
  type: TYPE_TB
- en: '| Pinch (thumb and index finger) | Selecting or interacting with a specific
    item or UI element | Fine-tuning or adjusting objects, such as resizing or rotating
    |'
  prefs: []
  type: TYPE_TB
- en: '| Point (extended index finger) | Pointing to or highlighting specific items
    or areas | Initiating teleportation or drawing attention in social VR settings
    |'
  prefs: []
  type: TYPE_TB
- en: '| Thumbs up | Often represents affirmation, agreement, or a positive response
    within social VR contexts | Can sometimes trigger specific in-game actions or
    emotes |'
  prefs: []
  type: TYPE_TB
- en: '| Palm facing outward | Stopping or blocking, particularly in narrative-driven
    experiencesPushing objects away or activating barriers |'
  prefs: []
  type: TYPE_TB
- en: '| Swipe (horizontal or vertical) | Navigating through menus, scrolling, or
    changing views | Can also be employed in certain games for actions such as slashing
    |'
  prefs: []
  type: TYPE_TB
- en: '| Rotation (twisting hand from side to side) | Rotating objects or adjusting
    settings, such as volume or brightness | Might be used to change perspective or
    view in some applications |'
  prefs: []
  type: TYPE_TB
- en: Table 9.2 – The actions associated with different hand gestures
  prefs: []
  type: TYPE_NORMAL
- en: To round off this topic, let’s have a look at common input methods for mobile
    AR applications.
  prefs: []
  type: TYPE_NORMAL
- en: Mobile AR input methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Mobile AR has opened a world of possibilities by blending the digital realm
    with our physical environment, all through the lens of a mobile device. Interactivity
    in mobile AR varies from traditional VR since it often doesn’t involve specialized
    controllers or hand-tracking hardware. Instead, it capitalizes on the existing
    capabilities of smartphones and tablets. The following is a breakdown of commonly
    utilized mobile AR inputs and their standard actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Mobile** **AR input** | **Primary actions** | **Secondary actions** |'
  prefs: []
  type: TYPE_TB
- en: '| Touch (single tap) | Selecting or interacting with an AR object or UI element
    | Triggering animations, accessing information, or playing videos |'
  prefs: []
  type: TYPE_TB
- en: '| Touch (double tap) | Resetting or recentering an AR experience | Toggling
    between AR modes or views |'
  prefs: []
  type: TYPE_TB
- en: '| Touch (long press) | Initiating a drag or move function for AR objects |
    Can also activate context-specific menus or options |'
  prefs: []
  type: TYPE_TB
- en: '| Pinch and zoom | Scaling AR objects, making them larger or smaller | Zooming
    into detailed information or images |'
  prefs: []
  type: TYPE_TB
- en: '| Swipe | Rotating AR objects or navigating through AR menus or slides | Dismissing
    AR elements or accessing additional content |'
  prefs: []
  type: TYPE_TB
- en: '| Device movement (tilting or panning) | Exploring the AR environment, changing
    the view, or influencing AR object behavior | Can also be employed in games or
    experiences to control avatars or vehicles |'
  prefs: []
  type: TYPE_TB
- en: '| Camera feed | Scanning or recognizing markers, patterns, or objects to initiate
    AR overlays | Capturing images or videos with AR elements superimposed |'
  prefs: []
  type: TYPE_TB
- en: '| Voice commands | Controlling the AR experience or interacting with AR objects
    through speech | Searching for information, initiating calls, or accessing device
    functions |'
  prefs: []
  type: TYPE_TB
- en: '| Gyroscope and accelerometer | Detecting device orientation and movement,
    which can influence the AR content’s positioning and behavior | Used in games
    or simulations to steer, navigate, or control AR elements based on device tilt
    |'
  prefs: []
  type: TYPE_TB
- en: Table 9.3 – The actions associated with different mobile AR inputs
  prefs: []
  type: TYPE_NORMAL
- en: Having delved into the best practices in the XR space, the next section of this
    chapter explores some useful toolkits and plugins that you might want to consider
    for your upcoming XR endeavors.
  prefs: []
  type: TYPE_NORMAL
- en: Other useful toolkits and plugins for XR development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After learning about the trends and best practices of XR development in this
    chapter, you’re likely already formulating an idea about which area of XR development
    you’re passionate about. As you venture further into your chosen specialization,
    this section will guide you by offering a detailed look at valuable XR toolkits
    and plugins for Unity. While we’ve already discussed the XR Interaction Toolkit,
    AR Foundation, ARKit, and ARCore, there’s a plethora of other tools out there.
    Some of these toolkits are tailored for specific projects, while others might
    become staple tools for a wide range of your XR endeavors, depending on the direction
    you take.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring powerful AR toolkits from the Unity Asset Store
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within the expansive **Unity Asset Store**, there exists a multitude of AR toolkits,
    each bringing its own unique capabilities to the table. This chapter will introduce
    you to four powerful AR toolkits and help you discern the best fit for your project
    needs. One of these toolkits is the **Vuforia Engine**.
  prefs: []
  type: TYPE_NORMAL
- en: Vuforia Engine, the AR pioneer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Vuforia Engine stands as one of the most widely used AR platforms globally,
    renowned for its robust capabilities in developing cross-platform AR applications.
    It targets both handheld devices and digital eyewear and offers advanced computer
    vision capabilities, including recognition of images, objects, and spaces.
  prefs: []
  type: TYPE_NORMAL
- en: Powering over 80,000 apps, Vuforia Engine boasts a clientele that includes big
    names such as *EA*, *Square Enix*, *LEGO*, and *Activision*. If giants in the
    industry are putting their trust in Vuforia, there’s a compelling reason to consider
    it for your AR endeavors. If you are looking to find a job in the field of AR,
    gaining experience with the Vuforia Engine should be at the top of your list once
    you start working on further AR projects beyond this book. From adding Vuforia
    Engine to your Unity project and setting up **Image Targets** to testing your
    AR app, every step is detailed in its documentation ([https://library.vuforia.com/getting-started/getting-started-vuforia-engine-unity](https://library.vuforia.com/getting-started/getting-started-vuforia-engine-unity)).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the toolkit by searching for it on the Unity Asset Store or by
    clicking on the following link: [https://assetstore.unity.com/packages/templates/packs/vuforia-engine-163598](https://assetstore.unity.com/packages/templates/packs/vuforia-engine-163598)'
  prefs: []
  type: TYPE_NORMAL
- en: Another non-negotiable toolkit for anyone who’s serious about AR development
    is **AR Foundation Remote 2.0**, which facilitates testing AR applications on
    smartphones a lot. You will learn more about it in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: AR Foundation Remote 2.0 toolkit, the AR development life cycle companion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Alongside the Vuforia Engine, the AR Foundation Remote 2.0 toolkit is one of
    those tools you should familiarize yourself with if you want to venture further
    into the world of AR development. This tool will dramatically transform your AR
    development journey as it allows for rapid iteration and an efficient workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional AR development involves making changes, building the project, deploying
    it to a device, and then testing it. This cycle, while essential, is time-consuming.
    With AR Foundation Remote 2.0, developers can run and debug AR apps directly within
    the Unity Editor. This drastically cuts down development time, enabling more focus
    on refining and improving the AR experience.
  prefs: []
  type: TYPE_NORMAL
- en: The toolkit goes beyond the basic `Debug.Log()` method by offering real-time
    debugging capabilities. One of the challenges of AR development is visualizing
    how an app looks and feels on a real device. AR Foundation Remote 2.0 streams
    video from the Unity Editor to a real AR device such as a smartphone, letting
    you preview your work without a full build. This real-time feedback is invaluable
    for fine-tuning the user experience. With full access to the scene hierarchy and
    all object properties right in the Unity Editor, the debugging process becomes
    more intuitive and comprehensive.
  prefs: []
  type: TYPE_NORMAL
- en: Another notable feature of this tool is its **Input Remoting** feature, which
    lets you stream multi-touch inputs from an AR device such as a smartphone or even
    simulate touch using a mouse within the Unity Editor. This flexibility makes testing
    and tweaking user interactions more thorough and efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Written in pure C# without third-party libraries, and with full source code
    available, this toolkit offers developers the freedom to tweak, modify, and customize
    according to their specific needs. It also offers seamless integration with ARKit
    and ARCore.
  prefs: []
  type: TYPE_NORMAL
- en: Given all of these and many more features that this toolkit offers, we highly
    recommend you invest in this asset to continue diving into the world of AR development.
    By slashing the development and debugging time, the toolkit will provide a tangible
    return on investment for you. Your initial cost is quickly offset by the saved
    hours and the elevated quality of your AR apps, and by making you a more specialized
    AR developer.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the toolkit by searching for `AR Foundation Remote 2.0` in the
    Unity Asset Store or by clicking on this link: [https://assetstore.unity.com/packages/tools/utilities/ar-foundation-remote-2-0-201106](https://assetstore.unity.com/packages/tools/utilities/ar-foundation-remote-2-0-201106)'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have gained insights into which toolkits will elevate your AR development
    capabilities, let’s have a look at some more specialized toolkits that will help
    you to develop specific AR applications more quickly and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: GO Map – 3D Map for AR Gaming, a hidden gem for location-based AR apps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Whenever you are developing a location-based AR game or require a rich selection
    of map visualization styles, such as terrains, satellite imagery, and hybrid maps,
    the **GO Map – 3D Map for AR Gaming** asset from the Unity Asset Store will be
    invaluable to you. It is also loaded with demo scenes showcasing a myriad of styles
    – from classic flat maps to hybrid maps, and from real building renderings to
    terrains.
  prefs: []
  type: TYPE_NORMAL
- en: The GO Map package allows a seamless integration of points of interest and real-world
    landscapes into the gameplay. As every setting and graphic control can be manipulated
    directly from the **Inspector** window, you can save precious development time,
    allowing you to focus on the content and gameplay.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the toolkit by visiting the Unity Asset Store and searching for
    `GO Map - 3D Map for AR Gaming` or by directly navigating to its URL ([https://assetstore.unity.com/packages/tools/integration/go-map-3d-map-for-ar-gaming-68889](https://assetstore.unity.com/packages/tools/integration/go-map-3d-map-for-ar-gaming-68889)).
  prefs: []
  type: TYPE_NORMAL
- en: If you are more interested in real-world AR navigation or tours instead of 3D
    maps, the next toolkit is for you.
  prefs: []
  type: TYPE_NORMAL
- en: AR+GPS Location, enabling navigation, tours, and location-based games of the
    future
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If games such as Pokémon GO and features such as Google Maps’ AR navigation
    excite you, Unity’s **AR+GPS Location** package will be a very interesting asset
    for you, as it allows you to create similar applications of your own in a relatively
    short amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: At the forefront of this asset’s offering is its AR navigation system. Drawing
    its strength from the *Mapbox Directions API*, the system allows developers to
    not just create, but also visualize routes within real-world landscapes. Whether
    it’s a path charted by Mapbox or a personalized route crafted for lesser-known
    terrains, the user’s journey is augmented with detailed signposts, arrows, and
    visual cues. A complementary feature provides a simultaneous 2D map view alongside
    the AR display using the integrated Mapbox SDK, offering an enriched navigational
    experience.
  prefs: []
  type: TYPE_NORMAL
- en: With the asset, the world truly becomes your canvas. Developers can anchor 3D
    objects within specific geographical locations. Whether it’s a monument in a bustling
    city or an artifact in a remote village, these objects can be virtually situated
    with latitude, longitude, and altitude coordinates, breathing life into the surroundings.
  prefs: []
  type: TYPE_NORMAL
- en: Further enhancing user engagement are the AR hotspots. These are specialized
    zones that, when entered or approached, activate specific AR manifestations. Imagine
    walking through a historic alley and having a virtual guide recount its rich past,
    all triggered by your mere presence in that location.
  prefs: []
  type: TYPE_NORMAL
- en: Textual representations get a makeover with the asset’s ability to establish
    3D text markers over real-world landmarks. A tourist navigating a city could instantly
    get information about a site, with hovering textual cues guiding their exploration.
  prefs: []
  type: TYPE_NORMAL
- en: As the user moves, the AR overlays respond naturally and with precision, ensuring
    a harmonious blend between the user’s movement and the augmented display. Additionally,
    objects can be orchestrated to move or remain stationary along intricate paths.
  prefs: []
  type: TYPE_NORMAL
- en: Adopting the AR+GPS Location asset necessitates a certain alignment of tools
    and hardware. Compatibility with AR Foundation versions 4.x or 5.x, or Vuforia
    version 10 or newer, is essential. Devices must either support ARKit for iOS or
    ARCore for Android when deploying with AR Foundation. For those working with Vuforia,
    a device with ground plane capabilities is mandatory.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find this asset in the Unity Asset Store by searching for `AR + GPS
    Location` or by clicking this link: [https://assetstore.unity.com/packages/tools/integration/ar-gps-location-134882](https://assetstore.unity.com/packages/tools/integration/ar-gps-location-134882)'
  prefs: []
  type: TYPE_NORMAL
- en: By exploring the AR toolkits mentioned in this section, you are on your way
    to mastering AR development. The next section introduces you to similarly powerful
    VR toolkits that you should keep an eye on if you want to venture further into
    the world of VR development.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring powerful VR toolkits from the Unity Asset Store
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The XR Interaction Toolkit is undeniably a cornerstone for VR development in
    Unity and should be the tool you focus most of your time and energy on. However,
    there are several other toolkits that can complement or even substitute it in
    certain contexts. These alternatives often provide specialized features not currently
    found in the XR Interaction Toolkit. Diving into these toolkits can not only enhance
    your VR development expertise, making you a more versatile VR developer, but it
    can also optimize your workflow based on each project’s requirements. Although
    the XR Interaction Toolkit is continuously evolving, getting acquainted with other
    hardware- or software-specific toolkits and plugins remains a crucial step for
    any committed VR developer, as you will learn in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Oculus Integration, SteamVR, VIVE Input Utility, and similar VR toolkits
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Delving into the XR Interaction Toolkit is a great starting point, but to truly
    advance your VR development prowess, it’s beneficial to explore the toolkits and
    plugins offered by VR hardware manufacturers directly. This encompasses the Oculus
    Integration package tailored for Meta Quest series devices, the PICO Unity Integration
    SDK for PICO headsets, the SteamVR plugin compatible with a broad range of VR
    devices, and the VIVE Input Utility asset, suitable for various headsets from
    VIVE and other brands. Let’s explore each of these in depth to understand their
    significance in your journey to further refine your VR expertise:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Oculus Integration package**: This package provides comprehensive support
    for Oculus VR devices and some devices compatible with OpenVR. It enables seamless
    handling of all in-app audio and sound effects, provides the tools to incorporate
    Oculus Avatars into apps, facilitates the synchronization of avatar lip movements
    with speech to enhance realism, allows the inclusion of Oculus platform solutions
    in apps to broaden their functionality, and introduces immersive voice interactions
    to let players interact with the virtual world using their voice, among many other
    powerful features. As you can see, diving into this toolkit is pivotal for XR
    developers targeting Oculus devices, as it provides a comprehensive suite of tools
    that ensures apps are optimized for this platform ([https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022](https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PICO Unity Integration SDK**: This is a dedicated Unity SDK crafted by PICO.
    It offers a wide array of features, ranging from rendering and tracking to MR
    features. The SDK comes packed with resources tailored for spatial audio, **eye-tracked
    foveated rendering**, which optimizes rendering based on the eye’s gaze, **fixed
    foveated rendering**, which is a static gaze-centric rendering method to decrease
    the resolution from center to edge, eye, face, hand, and body tracking, the ability
    to capture mixed reality videos, passthrough, and many other features. Similar
    to the Oculus Integration package, this SDK is an all-inclusive package for developers
    aiming to create XR experiences tailored to the PICO ecosystem ([https://developer-global.pico-interactive.com/resources/#sdk](https://developer-global.pico-interactive.com/resources/#sdk)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SteamVR plugin**: Maintained by Valve, this plugin is a universal interface
    compatible with a variety of PC VR headsets. It streamlines the representation
    of VR controllers in the virtual space, offers skeletal hand data, and enables
    intricate hand-object interactions. While this plugin has many intersections with
    the XR Interaction Toolkit, VR developers should feel comfortable with it too,
    as the toolkit or parts of its scripts are still used by various companies ([https://assetstore.unity.com/packages/tools/integration/steamvr-plugin-32647](https://assetstore.unity.com/packages/tools/integration/steamvr-plugin-32647)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**VIVE Input Utility**: This is a versatile toolkit especially oriented toward
    VIVE devices but it also supports a multitude of platforms. It empowers developers
    to create immersive movement and object interactions. It also facilitates specific
    device-role associations, promotes standardized VR development, and provides cross-platform
    hand-tracking. For those XR developers eyeing the VIVE ecosystem, VIVE Input Utility
    is an essential toolkit ([https://assetstore.unity.com/packages/tools/integration/vive-input-utility-64219](https://assetstore.unity.com/packages/tools/integration/vive-input-utility-64219)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are many other interesting VR plugins provided by each of these manufacturers
    and companies. We advise you to explore each company’s Unity Asset Store page
    to discover additional VR plugins that may spark your interest:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Meta Quest: [https://assetstore.unity.com/publishers/25353](https://assetstore.unity.com/publishers/25353)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Valve: [https://assetstore.unity.com/publishers/12026](https://assetstore.unity.com/publishers/12026)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'HTC Vive: [https://assetstore.unity.com/publishers/21581](https://assetstore.unity.com/publishers/21581)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you’re keen on delving further into VR game development, the toolkit presented
    in the next section will certainly interest you.
  prefs: []
  type: TYPE_NORMAL
- en: Hurricane VR, an XR Interaction Toolkit alternative for VR game development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While the XR Interaction Toolkit is the leading toolkit for handling interactions
    in XR, its generalist approach can sometimes fall short for specific VR gaming
    applications. If you want to venture into the avenue of VR game development, **Hurricane
    VR** could be an interesting alternative for you as it leans heavily into the
    gaming domain.
  prefs: []
  type: TYPE_NORMAL
- en: This toolkit offers a rich palette of features tailored for VR games such as
    weapon systems, specialized physics interactions such as flipping a knife in your
    hand, or intricate player controllers. While the XR Interaction Toolkit provides
    a wide array of movements, Hurricane VR offers more nuanced player controller
    features for VR gaming, such as seamlessly switching between sitting and standing
    modes, sprinting, crouching, and many more.
  prefs: []
  type: TYPE_NORMAL
- en: The toolkit isn’t just a toolbox; it’s an entire workshop. With diverse samples
    ranging from physics interactables (such as doors and dials) to over-the-shoulder
    backpack inventories and weapons, developers get a hands-on experience of the
    toolkit’s potential. Moreover, it seamlessly integrates with other assets such
    as *VR - Physics Interactions Bundle* and *Final IK*, amplifying its utility.
    You can find the toolkit when searching for it via the Unity Asset Store or directly
    navigating to [https://assetstore.unity.com/packages/tools/physics/hurricane-vr-physics-interaction-toolkit-177300](https://assetstore.unity.com/packages/tools/physics/hurricane-vr-physics-interaction-toolkit-177300).
  prefs: []
  type: TYPE_NORMAL
- en: Having delved deep into toolkits that enhance your XR capabilities, it’s now
    time to refine your XR development process. In the upcoming section, you’ll discover
    how to elevate your XR development efficiency by leveraging the strengths of AI.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring powerful AI toolkits from the Unity Asset Store
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regardless of your specific interest within the realm of XR, it’s essential
    to utilize cutting-edge tools throughout the development life cycle of your XR
    projects. Leveraging AI allows you to concentrate on the core game mechanics and
    logic of your XR application, eliminating the need to spend countless hours on
    basic scripting. To be a proficient XR developer who remains updated with contemporary
    trends and advancements, we advise you to explore the AI toolkit outlined in the
    following section.
  prefs: []
  type: TYPE_NORMAL
- en: AI Toolbox for ChatGPT and DALL·E, your companion for XR development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The interplay of game development and AI has never been so seamless or potent.
    The **AI Toolbox for ChatGPT and DALL·E** is an embodiment of this evolution,
    presenting a paradigm shift in how developers perceive, interact with, and utilize
    code in their projects.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine, instead of manually crafting each line of your C# script or shader,
    you simply write your requirements in human language. **ChatGPT** translates your
    requirements into functional and contextually relevant code, directly inside Unity.
    By using this toolkit, seasoned developers can streamline their workflows, dedicating
    more time to the heart and soul of game design.
  prefs: []
  type: TYPE_NORMAL
- en: The power of this toolkit doesn’t end at scripting. **DALL·E**, a cutting-edge
    diffusion model, can easily transform your text descriptions into vivid images
    inside the Unity Engine as well. Whether it’s a unique texture for your terrains
    or a defining logo for your game’s brand, it’s all achievable via a simple description.
  prefs: []
  type: TYPE_NORMAL
- en: With this asset, the Unity environment remains unaltered. Just replace your
    traditional **Add Script** button with the new **Generate Script** option inside
    the Unity Editor after installing the toolkit, and watch ChatGPT in action.
  prefs: []
  type: TYPE_NORMAL
- en: While this toolbox revolutionizes the XR development process, it’s pivotal to
    understand its boundaries. The AI, remarkable as it is, may not consistently achieve
    precision for intricate requirements. It is a complement to your developmental
    journey, not an outright replacement.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, AI Toolbox for ChatGPT and DALL·E is less a tool and more a partner,
    ready to share the load and elevate your game development pursuits to unparalleled
    heights. You can find it in the Unity Asset Store by searching for `AI Toolbox
    for ChatGPT and DALL·E` or by directly navigating to its URL ([https://assetstore.unity.com/packages/tools/ai-ml-integration/ai-toolbox-for-chatgpt-and-dall-e-250892](https://assetstore.unity.com/packages/tools/ai-ml-integration/ai-toolbox-for-chatgpt-and-dall-e-250892)).
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing this book, this asset provides experimental support for
    Google Bard. As you are reading this, the asset might fully support Google Bard
    and hence might be renamed slightly. If you have trouble finding this asset in
    the Unity Asset Store, search for the asset’s publisher, Dustyroom ([https://assetstore.unity.com/publishers/16150](https://assetstore.unity.com/publishers/16150)),
    in the Unity Asset Store and check out its assets to find the potentially renamed
    asset.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, you will discover another powerful AI tool for creating
    characters in your XR scene.
  prefs: []
  type: TYPE_NORMAL
- en: Blaze AI Engine, a powerhouse for universal AI character creation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Whether you are sketching out a simple cube that metamorphoses into a vigilant
    patrolling agent or sculpting a tactically advanced enemy that adapts to the game
    environment, the **Blaze AI Engine** toolkit allows you to add these characters
    into your project with ease. It infuses any GameObject with intelligent and realistic
    behaviors without requiring you to write a single line of code.
  prefs: []
  type: TYPE_NORMAL
- en: The beauty of this asset is that you don’t have to abide by a strict framework.
    You’re free to sculpt AI behaviors as you envision them. This asset is compatible
    with virtually any system or asset, including visual scripting.
  prefs: []
  type: TYPE_NORMAL
- en: This toolkit isn’t only about intelligent enemy creation. It also enables you
    to craft loyal companions to accompany players through their quests, responding
    dynamically to a variety of commands.
  prefs: []
  type: TYPE_NORMAL
- en: To enrich your future XR endeavors with an endless range of AI characters, check
    out the asset in the Unity Asset Store ([https://assetstore.unity.com/packages/tools/behavior-ai/blaze-ai-engine-194525](https://assetstore.unity.com/packages/tools/behavior-ai/blaze-ai-engine-194525))
    by searching for `Blaze` `AI Engine`.
  prefs: []
  type: TYPE_NORMAL
- en: The next section introduces you to a useful tool that simplifies prototyping
    your XR applications.
  prefs: []
  type: TYPE_NORMAL
- en: Prototyping XR applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**ShapesXR** ([https://www.shapesxr.com](https://www.shapesxr.com)) offers
    a range of features for UI/UX and spatial model prototyping. It simplifies 3D
    creation, allowing users to start with basic elements or choose from an extensive
    library of primitives. With the ability to customize colors, materials, and text,
    the platform offers precise control through its snapping system.'
  prefs: []
  type: TYPE_NORMAL
- en: Collaboration is also a central focus of ShapesXR. It facilitates real-time
    co-creation by enabling team members to enter VR environments easily. This immersive
    approach to designing reviews can enhance understanding and productivity.
  prefs: []
  type: TYPE_NORMAL
- en: ShapesXR supports various 2D and 3D formats, simplifying the integration of
    assets. A *Figma* plugin keeps assets synchronized, and you can import and export
    assets seamlessly from your browser.
  prefs: []
  type: TYPE_NORMAL
- en: ShapesXR also offers MR capabilities, enabling designs to be brought into the
    real world. Features such as passthrough materials provide valuable insights for
    XR development.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reflecting on your journey through this book, it began with you mastering the
    foundational elements of Unity, progressed to the creation of your first VR and
    AR applications, and culminated in the development of an immersive drumming experience,
    experimenting with eye-tracking, multiplayer functionalities, and sound and visual
    effects. With this chapter’s close, you should not only possess the confidence
    to design, develop, and launch intermediate XR applications but also be primed
    to delve deeper into XR development. Armed with thoughts of toolkits you’re eager
    to discover next and comprehensive guidance on structuring your XR initiatives,
    you’re now poised to not just create XR solutions on your own, but also oversee
    or guide them.
  prefs: []
  type: TYPE_NORMAL
